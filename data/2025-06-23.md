<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 79]
- [cs.CV](#cs.CV) [Total: 117]
- [cs.DC](#cs.DC) [Total: 6]
- [cs.AR](#cs.AR) [Total: 6]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.AI](#cs.AI) [Total: 10]
- [cs.CY](#cs.CY) [Total: 3]
- [astro-ph.EP](#astro-ph.EP) [Total: 1]
- [cs.RO](#cs.RO) [Total: 8]
- [cs.SE](#cs.SE) [Total: 2]
- [eess.SY](#eess.SY) [Total: 1]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.PF](#cs.PF) [Total: 1]
- [cs.LG](#cs.LG) [Total: 17]
- [math.NA](#math.NA) [Total: 1]
- [eess.IV](#eess.IV) [Total: 20]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 1]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.CG](#cs.CG) [Total: 1]
- [q-bio.QM](#q-bio.QM) [Total: 1]
- [physics.ins-det](#physics.ins-det) [Total: 1]
- [cs.MM](#cs.MM) [Total: 1]
- [cs.CR](#cs.CR) [Total: 3]
- [cs.HC](#cs.HC) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Veracity: An Open-Source AI Fact-Checking System](https://arxiv.org/abs/2506.15794)
*Taylor Lynn Curtis,Maximilian Puelma Touzel,William Garneau,Manon Gruaz,Mike Pinder,Li Wei Wang,Sukanya Krishna,Luda Cohen,Jean-François Godbout,Reihaneh Rabbany,Kellin Pelrine*

Main category: cs.CL

TL;DR: Veracity是一个开源AI系统，结合大语言模型和网络检索工具，提供透明的事实核查，支持多语言和交互式界面。


<details>
  <summary>Details</summary>
Motivation: 解决生成式AI加剧的虚假信息问题，提升公众的媒体素养。

Method: 利用大语言模型和网络检索工具分析用户提交的声明，提供直观的可信度评估和解释。

Result: 系统能检测虚假信息并解释其推理过程，支持多语言和交互功能。

Conclusion: Veracity通过透明的事实核查促进信息素养，助力构建更明智的社会。

Abstract: The proliferation of misinformation poses a significant threat to society,
exacerbated by the capabilities of generative AI. This demo paper introduces
Veracity, an open-source AI system designed to empower individuals to combat
misinformation through transparent and accessible fact-checking. Veracity
leverages the synergy between Large Language Models (LLMs) and web retrieval
agents to analyze user-submitted claims and provide grounded veracity
assessments with intuitive explanations. Key features include multilingual
support, numerical scoring of claim veracity, and an interactive interface
inspired by familiar messaging applications. This paper will showcase
Veracity's ability to not only detect misinformation but also explain its
reasoning, fostering media literacy and promoting a more informed society.

</details>


### [2] [Rethinking LLM Training through Information Geometry and Quantum Metrics](https://arxiv.org/abs/2506.15830)
*Riccardo Di Sipio*

Main category: cs.CL

TL;DR: 论文探讨了在大语言模型（LLM）优化中，信息几何学如何通过Fisher信息度量提供更原则性的学习方法，并讨论了曲率感知方法对LLM训练的理解。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在高维参数空间中的优化问题，利用信息几何学框架提供更有效的学习方法。

Method: 使用Fisher信息度量和自然梯度下降方法，分析非欧几里得结构中的优化问题。

Result: 几何视角解释了尖锐极小值、泛化性和缩放规律等现象，曲率感知方法深化了对LLM训练的理解。

Conclusion: 论文提出量子类比（基于Fubini-Study度量和量子Fisher信息）可能为量子增强系统中的高效优化提供启示。

Abstract: Optimization in large language models (LLMs) unfolds over high-dimensional
parameter spaces with non-Euclidean structure. Information geometry frames this
landscape using the Fisher information metric, enabling more principled
learning via natural gradient descent. Though often impractical, this geometric
lens clarifies phenomena such as sharp minima, generalization, and observed
scaling laws. We argue that curvature-aware approaches deepen our understanding
of LLM training. Finally, we speculate on quantum analogies based on the
Fubini-Study metric and Quantum Fisher Information, hinting at efficient
optimization in quantum-enhanced systems.

</details>


### [3] [MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents](https://arxiv.org/abs/2506.15841)
*Zijian Zhou,Ao Qu,Zhaoxuan Wu,Sunghwan Kim,Alok Prakash,Daniela Rus,Jinhua Zhao,Bryan Kian Hsiang Low,Paul Pu Liang*

Main category: cs.CL

TL;DR: MEM1是一个基于强化学习的框架，通过紧凑的内部状态实现长序列任务中的恒定内存使用，显著提升性能和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM系统因全上下文提示导致的内存增长、计算成本增加和推理性能下降的问题。

Method: 采用强化学习框架MEM1，动态更新内部状态并丢弃无关信息，同时通过组合现有数据集构建多轮任务环境。

Result: 在多个领域实验中，MEM1-7B性能提升3.5倍，内存使用减少3.7倍，并能泛化到训练范围之外的任务。

Conclusion: MEM1展示了推理驱动的内存整合作为长序列交互代理的高效解决方案的潜力。

Abstract: Modern language agents must operate over long-horizon, multi-turn
interactions, where they retrieve external information, adapt to observations,
and answer interdependent queries. Yet, most LLM systems rely on full-context
prompting, appending all past turns regardless of their relevance. This leads
to unbounded memory growth, increased computational costs, and degraded
reasoning performance on out-of-distribution input lengths. We introduce MEM1,
an end-to-end reinforcement learning framework that enables agents to operate
with constant memory across long multi-turn tasks. At each turn, MEM1 updates a
compact shared internal state that jointly supports memory consolidation and
reasoning. This state integrates prior memory with new observations from the
environment while strategically discarding irrelevant or redundant information.
To support training in more realistic and compositional settings, we propose a
simple yet effective and scalable approach to constructing multi-turn
environments by composing existing datasets into arbitrarily complex task
sequences. Experiments across three domains, including internal retrieval QA,
open-domain web QA, and multi-turn web shopping, show that MEM1-7B improves
performance by 3.5x while reducing memory usage by 3.7x compared to
Qwen2.5-14B-Instruct on a 16-objective multi-hop QA task, and generalizes
beyond the training horizon. Our results demonstrate the promise of
reasoning-driven memory consolidation as a scalable alternative to existing
solutions for training long-horizon interactive agents, where both efficiency
and performance are optimized.

</details>


### [4] [Finance Language Model Evaluation (FLaME)](https://arxiv.org/abs/2506.15846)
*Glenn Matlin,Mika Okamoto,Huzaifa Pardawala,Yang Yang,Sudheer Chava*

Main category: cs.CL

TL;DR: 本文提出了一种用于评估金融语言模型（FLaME）的全面基准测试套件，填补了现有评估框架的不足，并展示了语言模型在金融NLP任务中的潜力。


<details>
  <summary>Details</summary>
Motivation: 由于现有评估框架的方法论存在重大缺陷，导致对语言模型在金融NLP任务中性能的低估，本文旨在填补这一空白并展示其潜力。

Method: 提出了首个金融语言模型评估（FLaME）的全面基准测试套件，并对23个基础语言模型在20个核心金融NLP任务上进行了实证研究。

Result: 研究表明，语言模型在金融NLP任务中具有显著潜力，并开源了框架软件、数据和结果。

Conclusion: FLaME为金融语言模型评估提供了标准化工具，展示了语言模型在金融领域的广泛应用前景。

Abstract: Language Models (LMs) have demonstrated impressive capabilities with core
Natural Language Processing (NLP) tasks. The effectiveness of LMs for highly
specialized knowledge-intensive tasks in finance remains difficult to assess
due to major gaps in the methodologies of existing evaluation frameworks, which
have caused an erroneous belief in a far lower bound of LMs' performance on
common Finance NLP (FinNLP) tasks. To demonstrate the potential of LMs for
these FinNLP tasks, we present the first holistic benchmarking suite for
Financial Language Model Evaluation (FLaME). We are the first research paper to
comprehensively study LMs against 'reasoning-reinforced' LMs, with an empirical
study of 23 foundation LMs over 20 core NLP tasks in finance. We open-source
our framework software along with all data and results.

</details>


### [5] [Entropy-Driven Pre-Tokenization for Byte-Pair Encoding](https://arxiv.org/abs/2506.15889)
*Yifan Hu,Frank Liang,Dachuan Zhao,Jonathan Geuter,Varshini Reddy,Craig W. Schmidt,Chris Tanner*

Main category: cs.CL

TL;DR: 论文提出两种基于熵的预分词策略，改进BPE在中文等未分词语言中的表现，显著提升了分词的精确度、召回率和F1分数。


<details>
  <summary>Details</summary>
Motivation: BPE在未分词语言（如中文）中因忽略语言边界而表现不佳，需改进其分词效果。

Method: 提出两种策略：1）利用点互信息和左右熵识别连贯字符片段；2）利用预训练GPT-2模型的预测熵检测边界不确定性。

Result: 在PKU数据集上测试，两种方法显著优于标准BPE，提升了分词的精确度、召回率和F1分数。

Conclusion: 熵引导的预分词不仅更符合语言学单元，还为低资源和多语言场景下的分词质量提升提供了方向。

Abstract: Byte-Pair Encoding (BPE) has become a widely adopted subword tokenization
method in modern language models due to its simplicity and strong empirical
performance across downstream tasks. However, applying BPE to unsegmented
languages such as Chinese presents significant challenges, as its
frequency-driven merge operation is agnostic to linguistic boundaries. To
address this, we propose two entropy-informed pre-tokenization strategies that
guide BPE segmentation using unsupervised information-theoretic cues. The first
approach uses pointwise mutual information and left/right entropy to identify
coherent character spans, while the second leverages predictive entropy derived
from a pretrained GPT-2 model to detect boundary uncertainty. We evaluate both
methods on a subset of the PKU dataset and demonstrate substantial improvements
in segmentation precision, recall, and F1 score compared to standard BPE. Our
results suggest that entropy-guided pre-tokenization not only enhances
alignment with gold-standard linguistic units but also offers a promising
direction for improving tokenization quality in low-resource and multilingual
settings.

</details>


### [6] [Language Models can perform Single-Utterance Self-Correction of Perturbed Reasoning](https://arxiv.org/abs/2506.15894)
*Sam Silver,Jimin Sun,Ivan Zhang,Sara Hooker,Eddie Kim*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在数学推理方面表现出色，但对问题描述和提示策略的微小变化仍显脆弱。研究发现，LLMs具有内在的自我纠正能力，能够处理推理中的错误。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在推理过程中的自我纠正能力，以了解其内在特性是否被低估。

Method: 通过实验测量模型对合成扰动的自我纠正能力，观察其在Chain of Thought（CoT）推理中的表现。

Result: 发现LLMs具有强大的单次内在自我纠正能力，包括隐式和显式纠正错误。

Conclusion: LLMs的内在自我纠正能力可能比文献中显示的更强，表明近期“推理”模型研究是对模型已有特性的放大。

Abstract: Large Language Models (LLMs) have demonstrated impressive mathematical
reasoning capabilities, yet their performance remains brittle to minor
variations in problem description and prompting strategy. Furthermore,
reasoning is vulnerable to sampling-induced errors which autoregressive models
must primarily address using self-correction via additionally-generated tokens.
To better understand self-correction capabilities of recent models, we conduct
experiments measuring models' ability to self-correct synthetic perturbations
introduced into their Chain of Thought (CoT) reasoning. We observe robust
single-utterance intrinsic self-correction behavior across a range of
open-weight models and datasets, ranging from subtle, implicit corrections to
explicit acknowledgments and corrections of errors. Our findings suggest that
LLMs, including those not finetuned for long CoT, may possess stronger
intrinsic self-correction capabilities than commonly shown in the literature.
The presence of this ability suggests that recent "reasoning" model work
involves amplification of traits already meaningfully present in models.

</details>


### [7] [From RAG to Agentic: Validating Islamic-Medicine Responses with LLM Agents](https://arxiv.org/abs/2506.15911)
*Mohammad Amaan Sayeed,Mohammed Talha Alam,Raza Imam,Shahab Saquib Sohail,Amir Hussain*

Main category: cs.CL

TL;DR: 论文提出了一种评估管道Tibbe-AG，用于验证基于伊斯兰医学文本的AI系统，结合检索和自我评估提高了回答的准确性和文化敏感性。


<details>
  <summary>Details</summary>
Motivation: 伊斯兰医学文本如《医典》和《先知医学》蕴含丰富的预防和整体疗法，但在现代AI系统中未被充分利用。现有语言模型基准过于狭窄，缺乏对文化背景的验证。

Method: 提出Tibbe-AG评估管道，结合30个精选问题、人类验证疗法，测试三种LLM（LLaMA-3、Mistral-7B、Qwen2-7B）在三种配置下的表现：直接生成、检索增强生成和科学自我批判过滤。

Result: 检索提高事实准确性13%，代理提示通过机制洞察和安全性考虑再提升10%。

Conclusion: 结合古典伊斯兰文本、检索和自我评估，可实现可靠且文化敏感的医学问答。

Abstract: Centuries-old Islamic medical texts like Avicenna's Canon of Medicine and the
Prophetic Tibb-e-Nabawi encode a wealth of preventive care, nutrition, and
holistic therapies, yet remain inaccessible to many and underutilized in modern
AI systems. Existing language-model benchmarks focus narrowly on factual recall
or user preference, leaving a gap in validating culturally grounded medical
guidance at scale. We propose a unified evaluation pipeline, Tibbe-AG, that
aligns 30 carefully curated Prophetic-medicine questions with human-verified
remedies and compares three LLMs (LLaMA-3, Mistral-7B, Qwen2-7B) under three
configurations: direct generation, retrieval-augmented generation, and a
scientific self-critique filter. Each answer is then assessed by a secondary
LLM serving as an agentic judge, yielding a single 3C3H quality score.
Retrieval improves factual accuracy by 13%, while the agentic prompt adds
another 10% improvement through deeper mechanistic insight and safety
considerations. Our results demonstrate that blending classical Islamic texts
with retrieval and self-evaluation enables reliable, culturally sensitive
medical question-answering.

</details>


### [8] [Reranking-based Generation for Unbiased Perspective Summarization](https://arxiv.org/abs/2506.15925)
*Narutatsu Ri,Nicholas Deas,Kathleen McKeown*

Main category: cs.CL

TL;DR: 论文提出了一种改进大语言模型（LLM）在政治观点摘要任务中生成无偏摘要的方法，通过识别可靠的评估指标并验证LLM方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有评估框架依赖传统指标，未验证其适用性，且改进摘要生成方法的研究尚不成熟。

Method: 构建基于人工标注的测试集验证指标可靠性，并研究LLM方法（如重排序和偏好调优）的有效性。

Result: 语言模型指标优于传统指标，重排序和偏好调优方法显著提升性能。

Conclusion: 研究为视角摘要的可靠评估和方法开发提供了贡献。

Abstract: Generating unbiased summaries in real-world settings such as political
perspective summarization remains a crucial application of Large Language
Models (LLMs). Yet, existing evaluation frameworks rely on traditional metrics
for measuring key attributes such as coverage and faithfulness without
verifying their applicability, and efforts to develop improved summarizers are
still nascent. We address these gaps by (1) identifying reliable metrics for
measuring perspective summary quality, and (2) investigating the efficacy of
LLM-based methods beyond zero-shot inference. Namely, we build a test set for
benchmarking metric reliability using human annotations and show that
traditional metrics underperform compared to language model-based metrics,
which prove to be strong evaluators. Using these metrics, we show that
reranking-based methods yield strong results, and preference tuning with
synthetically generated and reranking-labeled data further boosts performance.
Our findings aim to contribute to the reliable evaluation and development of
perspective summarization methods.

</details>


### [9] [A Vietnamese Dataset for Text Segmentation and Multiple Choices Reading Comprehension](https://arxiv.org/abs/2506.15978)
*Toan Nguyen Hai,Ha Nguyen Viet,Truong Quan Xuan,Duc Do Minh*

Main category: cs.CL

TL;DR: 论文介绍了VSMRC数据集，用于越南语文本分割和阅读理解任务，填补了越南语NLP资源的空白。实验显示mBERT在多语言任务中表现优于单语模型。


<details>
  <summary>Details</summary>
Motivation: 越南语作为全球第20大语言，缺乏高质量的NLP资源，尤其是在文本分割和阅读理解任务上。

Method: 数据集来自越南语维基百科，包含15,942个文本分割文档和16,347个人工质量保证的合成多选题对。

Result: mBERT在阅读理解测试集上准确率达88.01%，文本分割测试集F1得分为63.15%，表现优于单语模型。

Conclusion: 多语言模型在越南语NLP任务中表现优异，VSMRC数据集为其他资源匮乏语言提供了潜在应用价值。

Abstract: Vietnamese, the 20th most spoken language with over 102 million native
speakers, lacks robust resources for key natural language processing tasks such
as text segmentation and machine reading comprehension (MRC). To address this
gap, we present VSMRC, the Vietnamese Text Segmentation and Multiple-Choice
Reading Comprehension Dataset. Sourced from Vietnamese Wikipedia, our dataset
includes 15,942 documents for text segmentation and 16,347 synthetic
multiple-choice question-answer pairs generated with human quality assurance,
ensuring a reliable and diverse resource. Experiments show that mBERT
consistently outperforms monolingual models on both tasks, achieving an
accuracy of 88.01% on MRC test set and an F1 score of 63.15\% on text
segmentation test set. Our analysis reveals that multilingual models excel in
NLP tasks for Vietnamese, suggesting potential applications to other
under-resourced languages. VSMRC is available at HuggingFace

</details>


### [10] [REIS: A High-Performance and Energy-Efficient Retrieval System with In-Storage Processing](https://arxiv.org/abs/2506.16444)
*Kangqi Chen,Andreas Kosmas Kakolyris,Rakesh Nadig,Manos Frouzakis,Nika Mansouri Ghiasi,Yu Liang,Haiyu Mao,Jisung Park,Mohammad Sadrosadati,Onur Mutlu*

Main category: cs.CL

TL;DR: REIS是一种针对RAG优化的ISP系统，通过改进数据库布局、数据放置和ANNS引擎，显著提升了检索性能和能效。


<details>
  <summary>Details</summary>
Motivation: 解决RAG中检索阶段的瓶颈问题，特别是ANNS在大型数据库中的数据移动开销。

Method: 提出REIS系统，采用优化的数据库布局、ISP定制的数据放置技术和轻量级Flash Translation Layer，并利用存储系统内现有计算资源。

Result: 相比服务器级系统，REIS平均提升检索性能13倍，能效55倍。

Conclusion: REIS为RAG中的检索瓶颈提供了高效解决方案，具有显著性能和能效优势。

Abstract: Large Language Models (LLMs) face an inherent challenge: their knowledge is
confined to the data that they have been trained on. To overcome this issue,
Retrieval-Augmented Generation (RAG) complements the static training-derived
knowledge of LLMs with an external knowledge repository. RAG consists of three
stages: indexing, retrieval, and generation. The retrieval stage of RAG becomes
a significant bottleneck in inference pipelines. In this stage, a user query is
mapped to an embedding vector and an Approximate Nearest Neighbor Search (ANNS)
algorithm searches for similar vectors in the database to identify relevant
items. Due to the large database sizes, ANNS incurs significant data movement
overheads between the host and the storage system. To alleviate these
overheads, prior works propose In-Storage Processing (ISP) techniques that
accelerate ANNS by performing computations inside storage. However, existing
works that leverage ISP for ANNS (i) employ algorithms that are not tailored to
ISP systems, (ii) do not accelerate data retrieval operations for data selected
by ANNS, and (iii) introduce significant hardware modifications, limiting
performance and hindering their adoption. We propose REIS, the first ISP system
tailored for RAG that addresses these limitations with three key mechanisms.
First, REIS employs a database layout that links database embedding vectors to
their associated documents, enabling efficient retrieval. Second, it enables
efficient ANNS by introducing an ISP-tailored data placement technique that
distributes embeddings across the planes of the storage system and employs a
lightweight Flash Translation Layer. Third, REIS leverages an ANNS engine that
uses the existing computational resources inside the storage system. Compared
to a server-grade system, REIS improves the performance (energy efficiency) of
retrieval by an average of 13x (55x).

</details>


### [11] [Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion](https://arxiv.org/abs/2506.15981)
*Markus Frohmann,Gabriel Meseguer-Brocal,Markus Schedl,Elena V. Epure*

Main category: cs.CL

TL;DR: 论文提出了一种多模态、模块化的后期融合方法DE-detect，结合自动转录的歌词和音频中的语音特征，以更鲁棒地检测AI生成的音乐。


<details>
  <summary>Details</summary>
Motivation: AI音乐生成工具的快速发展对音乐行业带来挑战，现有检测方法（基于音频或歌词）存在局限性，需要更可靠的解决方案。

Method: 采用多模态、模块化的后期融合管道，结合自动转录的歌词和音频中的语音特征，直接从音频中提取歌词相关信息。

Result: DE-detect在实验中表现优于现有基于歌词的检测器，同时对音频扰动更具鲁棒性。

Conclusion: DE-detect为实际场景中检测AI生成音乐提供了有效且鲁棒的解决方案。

Abstract: The rapid advancement of AI-based music generation tools is revolutionizing
the music industry but also posing challenges to artists, copyright holders,
and providers alike. This necessitates reliable methods for detecting such
AI-generated content. However, existing detectors, relying on either audio or
lyrics, face key practical limitations: audio-based detectors fail to
generalize to new or unseen generators and are vulnerable to audio
perturbations; lyrics-based methods require cleanly formatted and accurate
lyrics, unavailable in practice. To overcome these limitations, we propose a
novel, practically grounded approach: a multimodal, modular late-fusion
pipeline that combines automatically transcribed sung lyrics and speech
features capturing lyrics-related information within the audio. By relying on
lyrical aspects directly from audio, our method enhances robustness, mitigates
susceptibility to low-level artifacts, and enables practical applicability.
Experiments show that our method, DE-detect, outperforms existing lyrics-based
detectors while also being more robust to audio perturbations. Thus, it offers
an effective, robust solution for detecting AI-generated music in real-world
scenarios. Our code is available at
https://github.com/deezer/robust-AI-lyrics-detection.

</details>


### [12] [From General to Targeted Rewards: Surpassing GPT-4 in Open-Ended Long-Context Generation](https://arxiv.org/abs/2506.16024)
*Zhihan Guo,Jiele Wu,Wenqian Cui,Yifei Zhang,Minda Hu,Yufei Wang,Irwin King*

Main category: cs.CL

TL;DR: 论文提出ProxyReward框架，通过自动生成数据集和针对性奖励信号，提升LLM在开放长文本生成任务中的性能，表现优于GPT-4-Turbo。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注长上下文理解，而开放长文本生成任务缺乏探索，且缺乏高质量参考数据。现有方法仅使用通用评估信号，限制了准确性。

Method: 提出ProxyReward框架，包括自动生成数据集和计算针对性奖励信号的方法，无需大量标注数据。

Result: 实验表明，ProxyReward在开放长文本生成任务中性能提升20%，优于GPT-4-Turbo和LLM-as-a-Judge方法。

Conclusion: ProxyReward为提升LLM处理复杂开放问题的能力提供了有效方法。

Abstract: Current research on long-form context in Large Language Models (LLMs)
primarily focuses on the understanding of long-contexts, the Open-ended Long
Text Generation (Open-LTG) remains insufficiently explored. Training a
long-context generation model requires curation of gold standard reference
data, which is typically nonexistent for informative Open-LTG tasks. However,
previous methods only utilize general assessments as reward signals, which
limits accuracy. To bridge this gap, we introduce ProxyReward, an innovative
reinforcement learning (RL) based framework, which includes a dataset and a
reward signal computation method. Firstly, ProxyReward Dataset generation is
accomplished through simple prompts that enables the model to create
automatically, obviating extensive labeled data or significant manual effort.
Secondly, ProxyReward Signal offers a targeted evaluation of information
comprehensiveness and accuracy for specific questions. The experimental results
indicate that our method ProxyReward surpasses even GPT-4-Turbo. It can
significantly enhance performance by 20% on the Open-LTG task when training
widely used open-source models, while also surpassing the LLM-as-a-Judge
approach. Our work presents effective methods to enhance the ability of LLMs to
address complex open-ended questions posed by human.

</details>


### [13] [EvoLM: In Search of Lost Language Model Training Dynamics](https://arxiv.org/abs/2506.16029)
*Zhenting Qi,Fan Nie,Alexandre Alahi,James Zou,Himabindu Lakkaraju,Yilun Du,Eric Xing,Sham Kakade,Hanlin Zhang*

Main category: cs.CL

TL;DR: EvoLM是一个模型套件，用于系统透明地分析语言模型在不同训练阶段的动态，包括预训练、持续预训练、监督微调和强化学习。通过训练100多个模型，揭示了预训练和后续训练的收益递减、持续预训练的重要性以及微调和强化学习的复杂权衡。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型训练分为多个阶段，下游开发者难以评估每个阶段设计选择的影响。EvoLM旨在提供透明分析工具。

Method: 训练超过100个1B和4B参数的模型，评估语言建模和问题解决能力，包括域内和域外泛化。

Result: 发现预训练和后续训练的收益递减、持续预训练的关键作用，以及微调和强化学习的复杂权衡。

Conclusion: EvoLM为语言模型训练提供了系统分析工具，并公开了所有模型、数据和训练流程以促进研究。

Abstract: Modern language model (LM) training has been divided into multiple stages,
making it difficult for downstream developers to evaluate the impact of design
choices made at each stage. We present EvoLM, a model suite that enables
systematic and transparent analysis of LMs' training dynamics across
pre-training, continued pre-training, supervised fine-tuning, and reinforcement
learning. By training over 100 LMs with 1B and 4B parameters from scratch, we
rigorously evaluate both upstream (language modeling) and downstream
(problem-solving) reasoning capabilities, including considerations of both
in-domain and out-of-domain generalization. Key insights highlight the
diminishing returns from excessive pre-training and post-training, the
importance and practices of mitigating forgetting during domain-specific
continued pre-training, the crucial role of continued pre-training in bridging
pre-training and post-training phases, and various intricate trade-offs when
configuring supervised fine-tuning and reinforcement learning. To facilitate
open research and reproducibility, we release all pre-trained and post-trained
models, training datasets for all stages, and our entire training and
evaluation pipeline.

</details>


### [14] [Enhancing Document-Level Question Answering via Multi-Hop Retrieval-Augmented Generation with LLaMA 3](https://arxiv.org/abs/2506.16037)
*Xinyue Huang,Ziqi Lin,Fang Sun,Wenchao Zhang,Kejian Tong,Yunbo Liu*

Main category: cs.CL

TL;DR: 提出了一种基于LLaMA 3的检索增强生成框架，用于复杂问答任务，通过多跳推理和上下文融合提升回答准确性。


<details>
  <summary>Details</summary>
Motivation: 解决复杂问答任务中多跳推理和长文档上下文理解的挑战。

Method: 结合密集检索模块、上下文融合和多跳推理机制，采用联合优化策略（检索似然与生成交叉熵）。

Result: 实验表明，该框架在检索增强和生成基线中表现更优，提供更精确的上下文相关回答。

Conclusion: 该框架在复杂问答任务中表现出色，验证了其有效性和鲁棒性。

Abstract: This paper presents a novel Retrieval-Augmented Generation (RAG) framework
tailored for complex question answering tasks, addressing challenges in
multi-hop reasoning and contextual understanding across lengthy documents.
Built upon LLaMA 3, the framework integrates a dense retrieval module with
advanced context fusion and multi-hop reasoning mechanisms, enabling more
accurate and coherent response generation. A joint optimization strategy
combining retrieval likelihood and generation cross-entropy improves the
model's robustness and adaptability. Experimental results show that the
proposed system outperforms existing retrieval-augmented and generative
baselines, confirming its effectiveness in delivering precise, contextually
grounded answers.

</details>


### [15] [DynScaling: Efficient Verifier-free Inference Scaling via Dynamic and Integrated Sampling](https://arxiv.org/abs/2506.16043)
*Fei Wang,Xingchen Wan,Ruoxi Sun,Jiefeng Chen,Sercan Ö. Arık*

Main category: cs.CL

TL;DR: DynScaling通过集成并行-顺序采样策略和动态预算分配框架，提升大语言模型性能，无需外部验证器。


<details>
  <summary>Details</summary>
Motivation: 推理时扩展虽能提升大语言模型性能，但依赖外部验证器或未优化实际计算限制，限制了其实际应用。

Method: 提出DynScaling，结合并行-顺序采样策略和基于多臂老虎机的动态预算分配框架，优化计算资源分配。

Result: 实验显示DynScaling在任务性能和计算成本上均优于现有无验证器推理扩展方法。

Conclusion: DynScaling有效解决了实际资源限制下的性能提升问题，无需依赖外部验证器。

Abstract: Inference-time scaling has proven effective in boosting large language model
(LLM) performance through increased test-time computation. Yet, its practical
application is often hindered by reliance on external verifiers or a lack of
optimization for realistic computational constraints. We propose DynScaling,
which addresses these limitations through two primary innovations: an
integrated parallel-sequential sampling strategy and a bandit-based dynamic
budget allocation framework. The integrated sampling strategy unifies parallel
and sequential sampling by constructing synthetic sequential reasoning chains
from initially independent parallel responses, promoting diverse and coherent
reasoning trajectories. The dynamic budget allocation framework formulates the
allocation of computational resources as a multi-armed bandit problem,
adaptively distributing the inference budget across queries based on the
uncertainty of previously sampled responses, thereby maximizing computational
efficiency. By combining these components, DynScaling effectively improves LLM
performance under practical resource constraints without the need for external
verifiers. Experimental results demonstrate that DynScaling consistently
surpasses existing verifier-free inference scaling baselines in both task
performance and computational cost.

</details>


### [16] [A Hybrid DeBERTa and Gated Broad Learning System for Cyberbullying Detection in English Text](https://arxiv.org/abs/2506.16052)
*Devesh Kumar*

Main category: cs.CL

TL;DR: 本文提出了一种结合Transformer模型和广义学习系统的混合架构，用于高效检测网络欺凌，并在多个数据集上取得了优于现有方法的表现。


<details>
  <summary>Details</summary>
Motivation: 网络欺凌对青少年影响巨大（约54.4%的青少年受影响），现有检测方法在上下文理解和模式识别方面存在不足。

Method: 采用改进的DeBERTa模型（结合Squeeze-and-Excitation模块和情感分析）与门控广义学习系统（GBLS）分类器结合的混合架构。

Result: 在四个英文数据集上表现优异：HateXplain（79.3%）、SOSNet（95.41%）、Mendeley-I（91.37%）和Mendeley-II（94.67%）。

Conclusion: 该框架不仅性能优越，还具备可解释性机制，未来改进方向包括检测隐含偏见和讽刺内容。

Abstract: The proliferation of online communication platforms has created unprecedented
opportunities for global connectivity while simultaneously enabling harmful
behaviors such as cyberbullying, which affects approximately 54.4\% of
teenagers according to recent research. This paper presents a hybrid
architecture that combines the contextual understanding capabilities of
transformer-based models with the pattern recognition strengths of broad
learning systems for effective cyberbullying detection. This approach
integrates a modified DeBERTa model augmented with Squeeze-and-Excitation
blocks and sentiment analysis capabilities with a Gated Broad Learning System
(GBLS) classifier, creating a synergistic framework that outperforms existing
approaches across multiple benchmark datasets. The proposed ModifiedDeBERTa +
GBLS model achieved good performance on four English datasets: 79.3\% accuracy
on HateXplain, 95.41\% accuracy on SOSNet, 91.37\% accuracy on Mendeley-I, and
94.67\% accuracy on Mendeley-II. Beyond performance gains, the framework
incorporates comprehensive explainability mechanisms including token-level
attribution analysis, LIME-based local interpretations, and confidence
calibration, addressing critical transparency requirements in automated content
moderation. Ablation studies confirm the meaningful contribution of each
architectural component, while failure case analysis reveals specific
challenges in detecting implicit bias and sarcastic content, providing valuable
insights for future improvements in cyberbullying detection systems.

</details>


### [17] [Knee-Deep in C-RASP: A Transformer Depth Hierarchy](https://arxiv.org/abs/2506.16055)
*Andy Yang,Michaël Cadilhac,David Chiang*

Main category: cs.CL

TL;DR: 论文通过理论证明和实证研究，探讨了更深层次的Transformer在表达能力上的优势，并验证了其预测能力。


<details>
  <summary>Details</summary>
Motivation: 研究动机是明确更深层次的Transformer模型在表达能力上的具体增益，并通过理论证明和实验验证这一关系。

Method: 方法包括：1) 研究固定精度Transformer与C-RASP编程语言的表达能力等价性；2) 证明更深层次的C-RASP程序表达能力更强；3) 通过时序逻辑与计数算子的研究支持理论。

Result: 结果表明，更深层次的Transformer在表达能力上优于浅层模型，且理论预测与无位置编码的Transformer在序列依赖任务上的表现一致。

Conclusion: 结论是更深层次的Transformer确实具有更强的表达能力，理论预测与实验结果相符。

Abstract: It has been observed that transformers with greater depth (that is, more
layers) have more capabilities, but can we establish formally which
capabilities are gained with greater depth? We answer this question with a
theoretical proof followed by an empirical study. First, we consider
transformers that round to fixed precision except inside attention. We show
that this subclass of transformers is expressively equivalent to the
programming language C-RASP and this equivalence preserves depth. Second, we
prove that deeper C-RASP programs are more expressive than shallower C-RASP
programs, implying that deeper transformers are more expressive than shallower
transformers (within the subclass mentioned above). These results are
established by studying a form of temporal logic with counting operators, which
was shown equivalent to C-RASP in previous work. Finally, we provide empirical
evidence that our theory predicts the depth required for transformers without
positional encodings to length-generalize on a family of sequential dependency
tasks.

</details>


### [18] [Self-Critique-Guided Curiosity Refinement: Enhancing Honesty and Helpfulness in Large Language Models via In-Context Learning](https://arxiv.org/abs/2506.16064)
*Duc Hieu Ho,Chenglin Fan*

Main category: cs.CL

TL;DR: 论文提出了一种自批判引导的好奇心优化提示策略，通过无需额外训练的方式提升大型语言模型的诚实性和帮助性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在多种自然语言任务中表现优异，但其输出的诚实性和帮助性仍存在挑战。

Method: 论文通过基准评估十种常用大型语言模型，并提出自批判引导的好奇心优化提示策略，包含自批判和优化两个轻量级步骤。

Result: 实验结果显示，该方法在HONESET数据集上显著提升了模型的H²分数（诚实性和帮助性），减少了低质量回答，增加了高质量回答。

Conclusion: 结构化自优化是一种可扩展且无需训练的策略，能有效提升大型语言模型输出的可信度。

Abstract: Large language models (LLMs) have demonstrated robust capabilities across
various natural language tasks. However, producing outputs that are
consistently honest and helpful remains an open challenge. To overcome this
challenge, this paper tackles the problem through two complementary directions.
It conducts a comprehensive benchmark evaluation of ten widely used large
language models, including both proprietary and open-weight models from OpenAI,
Meta, and Google. In parallel, it proposes a novel prompting strategy,
self-critique-guided curiosity refinement prompting. The key idea behind this
strategy is enabling models to self-critique and refine their responses without
additional training. The proposed method extends the curiosity-driven prompting
strategy by incorporating two lightweight in-context steps including
self-critique step and refinement step.
  The experiment results on the HONESET dataset evaluated using the framework
$\mathrm{H}^2$ (honesty and helpfulness), which was executed with GPT-4o as a
judge of honesty and helpfulness, show consistent improvements across all
models. The approach reduces the number of poor-quality responses, increases
high-quality responses, and achieves relative gains in $\mathrm{H}^2$ scores
ranging from 1.4% to 4.3% compared to curiosity-driven prompting across
evaluated models. These results highlight the effectiveness of structured
self-refinement as a scalable and training-free strategy to improve the
trustworthiness of LLMs outputs.

</details>


### [19] [Cyberbullying Detection in Hinglish Text Using MURIL and Explainable AI](https://arxiv.org/abs/2506.16066)
*Devesh Kumar*

Main category: cs.CL

TL;DR: 本文提出了一种基于MURIL架构的框架，用于检测Hinglish文本中的网络欺凌，解决了现有多语言模型的局限性，并在多个数据集上表现优于RoBERTa和IndicBERT。


<details>
  <summary>Details</summary>
Motivation: 随着数字通信平台的增长，网络欺凌事件增多，而现有的检测系统主要针对单语言文本，无法有效处理Hinglish等混合语言内容。

Method: 使用MURIL架构，结合选择性层冻结、分类头设计和专门预处理方法，提升检测性能。

Result: 在六个基准数据集上，MURIL框架的准确率显著高于现有模型，最高提升13.07个百分点。

Conclusion: 该框架通过归因分析和跨语言模式识别提供了解释性，同时指出了未来研究的方向，如文化理解和跨语言讽刺检测。

Abstract: The growth of digital communication platforms has led to increased
cyberbullying incidents worldwide, creating a need for automated detection
systems to protect users. The rise of code-mixed Hindi-English (Hinglish)
communication on digital platforms poses challenges for existing cyberbullying
detection systems, which were designed primarily for monolingual text. This
paper presents a framework for cyberbullying detection in Hinglish text using
the Multilingual Representations for Indian Languages (MURIL) architecture to
address limitations in current approaches. Evaluation across six benchmark
datasets -- Bohra \textit{et al.}, BullyExplain, BullySentemo, Kumar \textit{et
al.}, HASOC 2021, and Mendeley Indo-HateSpeech -- shows that the MURIL-based
approach outperforms existing multilingual models including RoBERTa and
IndicBERT, with improvements of 1.36 to 13.07 percentage points and accuracies
of 86.97\% on Bohra, 84.62\% on BullyExplain, 86.03\% on BullySentemo, 75.41\%
on Kumar datasets, 83.92\% on HASOC 2021, and 94.63\% on Mendeley dataset. The
framework includes explainability features through attribution analysis and
cross-linguistic pattern recognition. Ablation studies show that selective
layer freezing, appropriate classification head design, and specialized
preprocessing for code-mixed content improve detection performance, while
failure analysis identifies challenges including context-dependent
interpretation, cultural understanding, and cross-linguistic sarcasm detection,
providing directions for future research in multilingual cyberbullying
detection.

</details>


### [20] [FinCoT: Grounding Chain-of-Thought in Expert Financial Reasoning](https://arxiv.org/abs/2506.16123)
*Natapong Nitarach,Warit Sirichotedumrong,Panop Pitchayarthorn,Pittawat Taveekitworachai,Potsawee Manakul,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: FinCoT是一种结合领域专家知识的结构化思维链提示方法，显著提升金融NLP任务的性能并降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 研究金融NLP中不同提示方法的有效性，尤其是结构化思维链提示的潜力，并解决现有方法中缺乏领域专家知识的问题。

Method: 提出FinCoT方法，结合金融领域专家的结构化推理步骤，对比评估标准提示、非结构化思维链提示和结构化思维链提示。

Result: FinCoT将性能从63.2%提升至80.5%，同时减少生成的令牌数量，推理成本降低八倍。

Conclusion: 领域对齐的结构化提示不仅能提高性能，还能生成更可解释且符合专家推理的思维链。

Abstract: This paper presents FinCoT, a structured chain-of-thought (CoT) prompting
approach that incorporates insights from domain-specific expert financial
reasoning to guide the reasoning traces of large language models. We
investigate that there are three main prompting styles in FinNLP: (1) standard
prompting--zero-shot prompting; (2) unstructured CoT--CoT prompting without an
explicit reasoning structure, such as the use of tags; and (3) structured CoT
prompting--CoT prompting with explicit instructions or examples that define
structured reasoning steps. Previously, FinNLP has primarily focused on prompt
engineering with either standard or unstructured CoT prompting. However,
structured CoT prompting has received limited attention in prior work.
Furthermore, the design of reasoning structures in structured CoT prompting is
often based on heuristics from non-domain experts. In this study, we
investigate each prompting approach in FinNLP. We evaluate the three main
prompting styles and FinCoT on CFA-style questions spanning ten financial
domains. We observe that FinCoT improves performance from 63.2% to 80.5% and
Qwen-2.5-7B-Instruct from 69.7% to 74.2%, while reducing generated tokens
eight-fold compared to structured CoT prompting. Our findings show that
domain-aligned structured prompts not only improve performance and reduce
inference costs but also yield more interpretable and expert-aligned reasoning
traces.

</details>


### [21] [Under the Shadow of Babel: How Language Shapes Reasoning in LLMs](https://arxiv.org/abs/2506.16151)
*Chenxi Wang,Yixuan Zhang,Lang Gao,Zixiang Xu,Zirui Song,Yanbo Wang,Xiuying Chen*

Main category: cs.CL

TL;DR: 论文研究了语言结构如何影响大语言模型（LLMs）的因果推理能力，通过双语数据集BICAUSE验证了模型内部化语言习惯的现象。


<details>
  <summary>Details</summary>
Motivation: 探讨语言结构是否会影响LLMs的认知和推理模式，验证语言相对性假说在模型中的表现。

Method: 使用双语数据集BICAUSE（中英文对齐样本），分析模型在因果推理中的注意力分布和表现。

Result: 发现LLMs会内化语言特定的因果顺序偏好，并在非典型输入中表现下降；成功推理时，模型表征会跨语言趋同。

Conclusion: LLMs不仅模仿语言表面形式，还内化了语言塑造的推理偏见，首次通过模型内部结构分析验证了这一现象。

Abstract: Language is not only a tool for communication but also a medium for human
cognition and reasoning. If, as linguistic relativity suggests, the structure
of language shapes cognitive patterns, then large language models (LLMs)
trained on human language may also internalize the habitual logical structures
embedded in different languages. To examine this hypothesis, we introduce
BICAUSE, a structured bilingual dataset for causal reasoning, which includes
semantically aligned Chinese and English samples in both forward and reversed
causal forms. Our study reveals three key findings: (1) LLMs exhibit
typologically aligned attention patterns, focusing more on causes and
sentence-initial connectives in Chinese, while showing a more balanced
distribution in English. (2) Models internalize language-specific preferences
for causal word order and often rigidly apply them to atypical inputs, leading
to degraded performance, especially in Chinese. (3) When causal reasoning
succeeds, model representations converge toward semantically aligned
abstractions across languages, indicating a shared understanding beyond surface
form. Overall, these results suggest that LLMs not only mimic surface
linguistic forms but also internalize the reasoning biases shaped by language.
Rooted in cognitive linguistic theory, this phenomenon is for the first time
empirically verified through structural analysis of model internals.

</details>


### [22] [SGIC: A Self-Guided Iterative Calibration Framework for RAG](https://arxiv.org/abs/2506.16172)
*Guanhua Chen,Yutong Yao,Lidia S. Chao,Xuebo Liu,Derek F. Wong*

Main category: cs.CL

TL;DR: 本文提出了一种名为SGIC的自引导迭代校准框架，通过利用不确定性评分提升大语言模型（LLMs）的校准能力，显著提高了多轮校准的效果。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成（RAG）方法常忽视LLMs的校准能力，而本文旨在通过特定提示和不确定性评分优化这一能力。

Method: 提出SGIC框架，利用不确定性评分评估文档相关性和LLM响应置信度，并通过迭代重新评分和自校准训练集优化模型。

Result: SGIC框架显著提升了闭源和开源LLMs的性能。

Conclusion: 通过自引导迭代校准，LLMs在多轮校准中的表现得到显著提升。

Abstract: Recent research in retrieval-augmented generation (RAG) has concentrated on
retrieving useful information from candidate documents. However, numerous
methodologies frequently neglect the calibration capabilities of large language
models (LLMs), which capitalize on their robust in-context reasoning prowess.
This work illustrates that providing LLMs with specific cues substantially
improves their calibration efficacy, especially in multi-round calibrations. We
present a new SGIC: Self-Guided Iterative Calibration Framework that employs
uncertainty scores as a tool. Initially, this framework calculates uncertainty
scores to determine both the relevance of each document to the query and the
confidence level in the responses produced by the LLMs. Subsequently, it
reevaluates these scores iteratively, amalgamating them with prior responses to
refine calibration. Furthermore, we introduce an innovative approach for
constructing an iterative self-calibration training set, which optimizes LLMs
to efficiently harness uncertainty scores for capturing critical information
and enhancing response accuracy. Our proposed framework significantly improves
performance on both closed-source and open-weight LLMs.

</details>


### [23] [JETHICS: Japanese Ethics Understanding Evaluation Dataset](https://arxiv.org/abs/2506.16187)
*Masashi Takeshita,Rafal Rzepka*

Main category: cs.CL

TL;DR: JETHICS是一个用于评估AI模型伦理理解的日语数据集，包含78K样本，基于英语ETHICS数据集构建。实验显示，当前LLM在伦理理解上仍有较大改进空间。


<details>
  <summary>Details</summary>
Motivation: 构建一个日语伦理数据集，以评估AI模型在伦理理解上的表现，填补现有研究的空白。

Method: 采用英语ETHICS数据集的构建方法，包含四类伦理理论和一类常识道德。

Result: GPT-4o平均得分约0.7，表现最佳的日语LLM得分约0.5，显示当前模型仍有较大改进空间。

Conclusion: JETHICS为评估AI伦理理解提供了新工具，未来研究可进一步提升模型表现。

Abstract: In this work, we propose JETHICS, a Japanese dataset for evaluating ethics
understanding of AI models. JETHICS contains 78K examples and is built by
following the construction methods of the existing English ETHICS dataset. It
includes four categories based normative theories and concepts from ethics and
political philosophy; and one representing commonsense morality. Our evaluation
experiments on non-proprietary large language models (LLMs) and on GPT-4o
reveal that even GPT-4o achieves only an average score of about 0.7, while the
best-performing Japanese LLM attains around 0.5, indicating a relatively large
room for improvement in current LLMs.

</details>


### [24] [Web(er) of Hate: A Survey on How Hate Speech Is Typed](https://arxiv.org/abs/2506.16190)
*Luna Wang,Andrew Caines,Alice Hutchings*

Main category: cs.CL

TL;DR: 本文探讨了仇恨言论数据集构建中的方法论选择及其对可靠性的影响，提倡采用反思性方法以提高透明度。


<details>
  <summary>Details</summary>
Motivation: 研究仇恨言论数据集构建中的复杂设计决策，揭示其对数据集可靠性的影响。

Method: 通过分析多种数据集，结合马克斯·韦伯的理想类型概念，提出反思性方法。

Result: 揭示了数据集构建中的常见主题和实践，强调了透明度的重要性。

Conclusion: 呼吁研究者在数据集构建中承认自身价值判断，以提升方法论的严谨性。

Abstract: The curation of hate speech datasets involves complex design decisions that
balance competing priorities. This paper critically examines these
methodological choices in a diverse range of datasets, highlighting common
themes and practices, and their implications for dataset reliability. Drawing
on Max Weber's notion of ideal types, we argue for a reflexive approach in
dataset creation, urging researchers to acknowledge their own value judgments
during dataset construction, fostering transparency and methodological rigour.

</details>


### [25] [Comparative Analysis of Abstractive Summarization Models for Clinical Radiology Reports](https://arxiv.org/abs/2506.16247)
*Anindita Bhattacharya,Tohida Rehman,Debarshi Kumar Sanyal,Samiran Chattopadhyay*

Main category: cs.CL

TL;DR: 研究探讨了使用抽象摘要模型从放射学报告的详细发现部分生成简洁印象的方法，比较了多种预训练和开源大语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 放射学报告的印象部分需要简洁地总结关键诊断结论，而现有方法往往冗长，因此需要高效的自动化摘要解决方案。

Method: 使用MIMIC-CXR数据集，比较了T5-base、BART-base、PEGASUS-x-base、ChatGPT-4、LLaMA-3-8B和自定义Pointer Generator Network等模型的性能，并采用多种评估指标。

Result: 通过ROUGE-1、ROUGE-2、ROUGE-L、METEOR和BERTScore等指标评估，分析了各模型在医学文本摘要中的优缺点。

Conclusion: 研究结果为医疗专业人士提供了自动化摘要解决方案的有用信息，有助于提升医疗领域的效率。

Abstract: The findings section of a radiology report is often detailed and lengthy,
whereas the impression section is comparatively more compact and captures key
diagnostic conclusions. This research explores the use of advanced abstractive
summarization models to generate the concise impression from the findings
section of a radiology report. We have used the publicly available MIMIC-CXR
dataset. A comparative analysis is conducted on leading pre-trained and
open-source large language models, including T5-base, BART-base,
PEGASUS-x-base, ChatGPT-4, LLaMA-3-8B, and a custom Pointer Generator Network
with a coverage mechanism. To ensure a thorough assessment, multiple evaluation
metrics are employed, including ROUGE-1, ROUGE-2, ROUGE-L, METEOR, and
BERTScore. By analyzing the performance of these models, this study identifies
their respective strengths and limitations in the summarization of medical
text. The findings of this paper provide helpful information for medical
professionals who need automated summarization solutions in the healthcare
sector.

</details>


### [26] [End-to-End Speech Translation for Low-Resource Languages Using Weakly Labeled Data](https://arxiv.org/abs/2506.16251)
*Aishwarya Pothula,Bhavana Akkiraju,Srihari Bandarupalli,Charan D,Santosh Kesiraju,Anil Kumar Vuppala*

Main category: cs.CL

TL;DR: 本文探讨了利用弱标注数据构建低资源语言对的端到端语音到文本翻译（ST）系统的可行性，并通过实验验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 高标注质量数据的稀缺性对低资源语言的ST系统开发构成挑战，因此研究弱标注数据的利用价值。

Method: 利用双语文本挖掘和先进句子编码器构建ST数据集（Shrutilipi-anuvaad），并研究不同质量与数量的弱标注数据对模型性能的影响。

Result: 实验表明，弱标注数据构建的ST系统性能可与SONAR和SeamlessM4T等大规模多模态多语言基线相媲美。

Conclusion: 弱标注数据可用于构建低资源语言对的ST系统，为数据稀缺问题提供解决方案。

Abstract: The scarcity of high-quality annotated data presents a significant challenge
in developing effective end-to-end speech-to-text translation (ST) systems,
particularly for low-resource languages. This paper explores the hypothesis
that weakly labeled data can be used to build ST models for low-resource
language pairs. We constructed speech-to-text translation datasets with the
help of bitext mining using state-of-the-art sentence encoders. We mined the
multilingual Shrutilipi corpus to build Shrutilipi-anuvaad, a dataset
comprising ST data for language pairs Bengali-Hindi, Malayalam-Hindi,
Odia-Hindi, and Telugu-Hindi. We created multiple versions of training data
with varying degrees of quality and quantity to investigate the effect of
quality versus quantity of weakly labeled data on ST model performance. Results
demonstrate that ST systems can be built using weakly labeled data, with
performance comparable to massive multi-modal multilingual baselines such as
SONAR and SeamlessM4T.

</details>


### [27] [Advancing Automated Speaking Assessment Leveraging Multifaceted Relevance and Grammar Information](https://arxiv.org/abs/2506.16285)
*Hao-Chien Lu,Jhen-Ke Lin,Hong-Yun Lin,Chung-Chun Wang,Berlin Chen*

Main category: cs.CL

TL;DR: 本文提出了一种混合评分模型，通过多方面的相关性模块和细粒度语法错误特征，显著提升了自动口语评估系统的性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动口语评估系统在多方面评估中未能充分利用内容相关性，且语法分析较为肤浅，缺乏详细的错误类型。

Method: 引入多方面的相关性模块整合问题、图像内容、范例和口语回答，并使用高级语法错误校正（GEC）和详细标注提取细粒度语法错误特征。

Result: 实验表明，这些改进显著提升了内容相关性、语言使用和整体评估性能。

Conclusion: 通过更丰富、更细致的特征集，实现了更全面的口语评估。

Abstract: Current automated speaking assessment (ASA) systems for use in multi-aspect
evaluations often fail to make full use of content relevance, overlooking image
or exemplar cues, and employ superficial grammar analysis that lacks detailed
error types. This paper ameliorates these deficiencies by introducing two novel
enhancements to construct a hybrid scoring model. First, a multifaceted
relevance module integrates question and the associated image content,
exemplar, and spoken response of an L2 speaker for a comprehensive assessment
of content relevance. Second, fine-grained grammar error features are derived
using advanced grammar error correction (GEC) and detailed annotation to
identify specific error categories. Experiments and ablation studies
demonstrate that these components significantly improve the evaluation of
content relevance, language use, and overall ASA performance, highlighting the
benefits of using richer, more nuanced feature sets for holistic speaking
assessment.

</details>


### [28] [PL-Guard: Benchmarking Language Model Safety for Polish](https://arxiv.org/abs/2506.16322)
*Aleksandra Krasnodębska,Karolina Seweryn,Szymon Łukasik,Wojciech Kusa*

Main category: cs.CL

TL;DR: 论文提出了一个针对波兰语的语言模型安全分类基准数据集，并通过对抗性扰动样本测试模型鲁棒性。实验表明，基于HerBERT的分类器在对抗条件下表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型安全评估工具多偏向英语和高资源语言，全球多数语言未被充分研究，因此需要填补这一空白。

Method: 构建手动标注的波兰语基准数据集及对抗性扰动样本，评估不同架构和大小的语言模型和分类器，包括Llama-Guard-3-8B、HerBERT和PLLuM。

Result: 基于HerBERT的分类器在对抗条件下表现最优。

Conclusion: 研究填补了波兰语语言模型安全评估的空白，并验证了HerBERT在对抗条件下的优越性。

Abstract: Despite increasing efforts to ensure the safety of large language models
(LLMs), most existing safety assessments and moderation tools remain heavily
biased toward English and other high-resource languages, leaving majority of
global languages underexamined. To address this gap, we introduce a manually
annotated benchmark dataset for language model safety classification in Polish.
We also create adversarially perturbed variants of these samples designed to
challenge model robustness. We conduct a series of experiments to evaluate
LLM-based and classifier-based models of varying sizes and architectures.
Specifically, we fine-tune three models: Llama-Guard-3-8B, a HerBERT-based
classifier (a Polish BERT derivative), and PLLuM, a Polish-adapted Llama-8B
model. We train these models using different combinations of annotated data and
evaluate their performance, comparing it against publicly available guard
models. Results demonstrate that the HerBERT-based classifier achieves the
highest overall performance, particularly under adversarial conditions.

</details>


### [29] [Generalizability of Media Frames: Corpus creation and analysis across countries](https://arxiv.org/abs/2506.16337)
*Agnese Daffara,Sourabh Dattawad,Sebastian Padó,Tanise Ceron*

Main category: cs.CL

TL;DR: 研究探讨了MFC框架在巴西新闻中的适用性，发现其大部分框架仍适用，但需注意跨文化差异。


<details>
  <summary>Details</summary>
Motivation: 评估MFC框架在非美国文化背景（巴西）中的适用性，以验证其跨文化普适性。

Method: 通过FrameNews-PT数据集对巴西葡萄牙语新闻进行多轮标注，并评估MFC框架的适用性及模型表现。

Result: MFC的15个框架基本适用，但部分框架使用较少，需调整指南。

Conclusion: 跨文化框架使用需谨慎，需考虑文化差异和适应性。

Abstract: Frames capture aspects of an issue that are emphasized in a debate by
interlocutors and can help us understand how political language conveys
different perspectives and ultimately shapes people's opinions. The Media Frame
Corpus (MFC) is the most commonly used framework with categories and detailed
guidelines for operationalizing frames. It is, however, focused on a few
salient U.S. news issues, making it unclear how well these frames can capture
news issues in other cultural contexts. To explore this, we introduce
FrameNews-PT, a dataset of Brazilian Portuguese news articles covering
political and economic news and annotate it within the MFC framework. Through
several annotation rounds, we evaluate the extent to which MFC frames
generalize to the Brazilian debate issues. We further evaluate how fine-tuned
and zero-shot models perform on out-of-domain data. Results show that the 15
MFC frames remain broadly applicable with minor revisions of the guidelines.
However, some MFC frames are rarely used, and novel news issues are analyzed
using general 'fall-back' frames. We conclude that cross-cultural frame use
requires careful consideration.

</details>


### [30] [Analyzing the Influence of Knowledge Graph Information on Relation Extraction](https://arxiv.org/abs/2506.16343)
*Cedric Möller,Ricardo Usbeck*

Main category: cs.CL

TL;DR: 研究探讨了知识图谱信息对关系抽取模型性能的影响，发现其显著提升效果，尤其在训练样本不平衡时。


<details>
  <summary>Details</summary>
Motivation: 验证知识图谱中实体位置信息对关系抽取任务的重要性。

Method: 结合传统关系抽取方法与图感知的Neural Bellman-Ford网络，测试监督和零样本设置。

Result: 知识图谱信息显著提升模型性能，尤其在样本不平衡时表现突出。

Conclusion: 知识图谱信息是关系抽取任务的重要补充，能有效提升模型表现。

Abstract: We examine the impact of incorporating knowledge graph information on the
performance of relation extraction models across a range of datasets. Our
hypothesis is that the positions of entities within a knowledge graph provide
important insights for relation extraction tasks. We conduct experiments on
multiple datasets, each varying in the number of relations, training examples,
and underlying knowledge graphs. Our results demonstrate that integrating
knowledge graph information significantly enhances performance, especially when
dealing with an imbalance in the number of training examples for each relation.
We evaluate the contribution of knowledge graph-based features by combining
established relation extraction methods with graph-aware Neural Bellman-Ford
networks. These features are tested in both supervised and zero-shot settings,
demonstrating consistent performance improvements across various datasets.

</details>


### [31] [DISCIE -- Discriminative Closed Information Extraction](https://arxiv.org/abs/2506.16348)
*Cedric Möller,Ricardo Usbeck*

Main category: cs.CL

TL;DR: 提出了一种新的封闭信息抽取方法，通过结合类型和实体特定信息提升关系抽取准确性，尤其在长尾关系上表现优异，且效率更高。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型在大规模封闭信息抽取任务中表现不足，尤其是面对大量实体和关系时，需要更高效且准确的方法。

Method: 采用判别式方法，整合类型和实体特定信息，利用较小模型提升效率。

Result: 性能优于现有端到端生成模型，尤其在长尾关系和大规模任务中表现突出。

Conclusion: 该方法为信息抽取提供了更准确和高效的解决方案，具有广泛应用潜力。

Abstract: This paper introduces a novel method for closed information extraction. The
method employs a discriminative approach that incorporates type and
entity-specific information to improve relation extraction accuracy,
particularly benefiting long-tail relations. Notably, this method demonstrates
superior performance compared to state-of-the-art end-to-end generative models.
This is especially evident for the problem of large-scale closed information
extraction where we are confronted with millions of entities and hundreds of
relations. Furthermore, we emphasize the efficiency aspect by leveraging
smaller models. In particular, the integration of type-information proves
instrumental in achieving performance levels on par with or surpassing those of
a larger generative model. This advancement holds promise for more accurate and
efficient information extraction techniques.

</details>


### [32] [Can structural correspondences ground real world representational content in Large Language Models?](https://arxiv.org/abs/2506.16370)
*Iwan Williams*

Main category: cs.CL

TL;DR: 论文探讨了大型语言模型（LLMs）是否能表示现实世界内容，并提出了基于结构对应性的表示理论。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否能够表示现实世界内容，以及如何通过结构对应性理论解释这种表示能力。

Method: 采用结构对应性理论分析LLMs的表示能力，并探讨其在任务表现中的作用。

Result: 仅存在结构对应性不足以证明LLMs能表示现实世界内容，但若这些对应性在任务表现中发挥作用，则可能支持其表示能力。

Conclusion: LLMs的文本局限性可能阻碍其完成特定任务，但结构对应性理论为其表示能力提供了潜在解释。

Abstract: Large Language Models (LLMs) such as GPT-4 produce compelling responses to a
wide range of prompts. But their representational capacities are uncertain.
Many LLMs have no direct contact with extra-linguistic reality: their inputs,
outputs and training data consist solely of text, raising the questions (1) can
LLMs represent anything and (2) if so, what? In this paper, I explore what it
would take to answer these questions according to a structural-correspondence
based account of representation, and make an initial survey of this evidence. I
argue that the mere existence of structural correspondences between LLMs and
worldly entities is insufficient to ground representation of those entities.
However, if these structural correspondences play an appropriate role - they
are exploited in a way that explains successful task performance - then they
could ground real world contents. This requires overcoming a challenge: the
text-boundedness of LLMs appears, on the face of it, to prevent them engaging
in the right sorts of tasks.

</details>


### [33] [InstructTTSEval: Benchmarking Complex Natural-Language Instruction Following in Text-to-Speech Systems](https://arxiv.org/abs/2506.16381)
*Kexin Huang,Qian Tu,Liwei Fan,Chenchen Yang,Dong Zhang,Shimin Li,Zhaoye Fei,Qinyuan Cheng,Xipeng Qiu*

Main category: cs.CL

TL;DR: 论文提出InstructTTSEval基准，用于评估基于自然语言指令的TTS系统在复杂风格控制上的能力，并指出当前系统的不足。


<details>
  <summary>Details</summary>
Motivation: 传统TTS系统在控制副语言信息（如音色、情感、韵律）时灵活性不足，且缺乏高质量基准和评估指标。

Method: 引入InstructTTSEval基准，包含三个任务（声学参数指定、描述性风格指令、角色扮演），共6k测试用例，并使用Gemini作为自动评估工具。

Result: 评估显示现有指令驱动TTS系统在复杂指令执行上仍有较大改进空间。

Conclusion: InstructTTSEval有望推动更强大、灵活和准确的指令驱动TTS系统发展。

Abstract: In modern speech synthesis, paralinguistic information--such as a speaker's
vocal timbre, emotional state, and dynamic prosody--plays a critical role in
conveying nuance beyond mere semantics. Traditional Text-to-Speech (TTS)
systems rely on fixed style labels or inserting a speech prompt to control
these cues, which severely limits flexibility. Recent attempts seek to employ
natural-language instructions to modulate paralinguistic features,
substantially improving the generalization of instruction-driven TTS models.
Although many TTS systems now support customized synthesis via textual
description, their actual ability to interpret and execute complex instructions
remains largely unexplored. In addition, there is still a shortage of
high-quality benchmarks and automated evaluation metrics specifically designed
for instruction-based TTS, which hinders accurate assessment and iterative
optimization of these models. To address these limitations, we introduce
InstructTTSEval, a benchmark for measuring the capability of complex
natural-language style control. We introduce three tasks, namely
Acoustic-Parameter Specification, Descriptive-Style Directive, and Role-Play,
including English and Chinese subsets, each with 1k test cases (6k in total)
paired with reference audio. We leverage Gemini as an automatic judge to assess
their instruction-following abilities. Our evaluation of accessible
instruction-following TTS systems highlights substantial room for further
improvement. We anticipate that InstructTTSEval will drive progress toward more
powerful, flexible, and accurate instruction-following TTS.

</details>


### [34] [Large Language Models in Argument Mining: A Survey](https://arxiv.org/abs/2506.16383)
*Hao Li,Viktor Schlegel,Yizheng Sun,Riza Batista-Navarro,Goran Nenadic*

Main category: cs.CL

TL;DR: 本文综述了大型语言模型（LLMs）在论证挖掘（AM）领域的最新进展，包括理论基础、数据集、任务分类、技术方法和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 论证挖掘是自然语言处理的重要子领域，而LLMs的出现为其带来了革命性变化，本文旨在系统总结这些进展并为未来研究提供指导。

Method: 通过综述现有文献，整理数据集，提出任务分类，并分析LLMs在AM中的技术应用（如提示学习、思维链推理等）。

Result: 总结了LLMs在AM中的优势（如跨域适应性）和挑战（如长上下文推理、可解释性），并提出了未来研究方向。

Conclusion: LLMs为AM带来了巨大潜力，但仍需解决技术挑战，未来研究应关注长上下文推理、可解释性等问题。

Abstract: Argument Mining (AM), a critical subfield of Natural Language Processing
(NLP), focuses on extracting argumentative structures from text. The advent of
Large Language Models (LLMs) has profoundly transformed AM, enabling advanced
in-context learning, prompt-based generation, and robust cross-domain
adaptability. This survey systematically synthesizes recent advancements in
LLM-driven AM. We provide a concise review of foundational theories and
annotation frameworks, alongside a meticulously curated catalog of datasets. A
key contribution is our comprehensive taxonomy of AM subtasks, elucidating how
contemporary LLM techniques -- such as prompting, chain-of-thought reasoning,
and retrieval augmentation -- have reconfigured their execution. We further
detail current LLM architectures and methodologies, critically assess
evaluation practices, and delineate pivotal challenges including long-context
reasoning, interpretability, and annotation bottlenecks. Conclusively, we
highlight emerging trends and propose a forward-looking research agenda for
LLM-based computational argumentation, aiming to strategically guide
researchers in this rapidly evolving domain.

</details>


### [35] [HausaNLP at SemEval-2025 Task 11: Advancing Hausa Text-based Emotion Detection](https://arxiv.org/abs/2506.16388)
*Sani Abdullahi Sani,Salim Abubakar,Falalu Ibrahim Lawan,Abdulhamid Abubakar,Maryam Bala*

Main category: cs.CL

TL;DR: 本文提出了一种针对低资源非洲语言豪萨语的多标签情感检测方法，基于AfriBERTa模型进行微调，验证准确率达74.00%。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决豪萨语这种低资源语言的情感检测问题。

Method: 方法包括数据预处理、分词，并使用Hugging Face Trainer API对AfriBERTa模型进行微调。

Result: 系统在验证集上达到74.00%的准确率和73.50%的F1分数。

Conclusion: 结论表明基于Transformer的模型在低资源语言情感检测中表现有效。

Abstract: This paper presents our approach to multi-label emotion detection in Hausa, a
low-resource African language, as part of SemEval Track A. We fine-tuned
AfriBERTa, a transformer-based model pre-trained on African languages, to
classify Hausa text into six emotions: anger, disgust, fear, joy, sadness, and
surprise. Our methodology involved data preprocessing, tokenization, and model
fine-tuning using the Hugging Face Trainer API. The system achieved a
validation accuracy of 74.00%, with an F1-score of 73.50%, demonstrating the
effectiveness of transformer-based models for emotion detection in low-resource
languages.

</details>


### [36] [RiOT: Efficient Prompt Refinement with Residual Optimization Tree](https://arxiv.org/abs/2506.16389)
*Chenyi Zhou,Zhengyan Shi,Yuan Yao,Lei Liang,Huajun Chen,Qiang Zhang*

Main category: cs.CL

TL;DR: RiOT是一种新的自动提示优化框架，通过文本梯度和树结构解决现有方法的多样性和语义漂移问题。


<details>
  <summary>Details</summary>
Motivation: 现有自动提示优化方法缺乏多样性且易导致语义漂移，限制了探索创新方向。

Method: RiOT通过迭代优化提示，生成多样候选并使用困惑度选择最佳提示，同时引入文本残差连接以减少语义漂移。

Result: 在五个基准测试中，RiOT优于现有自动优化方法和手动提示。

Conclusion: RiOT通过多样性和语义保留机制，显著提升了提示优化的效果。

Abstract: Recent advancements in large language models (LLMs) have highlighted their
potential across a variety of tasks, but their performance still heavily relies
on the design of effective prompts. Existing methods for automatic prompt
optimization face two challenges: lack of diversity, limiting the exploration
of valuable and innovative directions and semantic drift, where optimizations
for one task can degrade performance in others. To address these issues, we
propose Residual Optimization Tree (RiOT), a novel framework for automatic
prompt optimization. RiOT iteratively refines prompts through text gradients,
generating multiple semantically diverse candidates at each step, and selects
the best prompt using perplexity. Additionally, RiOT incorporates the text
residual connection to mitigate semantic drift by selectively retaining
beneficial content across optimization iterations. A tree structure efficiently
manages the optimization process, ensuring scalability and flexibility.
Extensive experiments across five benchmarks, covering commonsense,
mathematical, logical, temporal, and semantic reasoning, demonstrate that RiOT
outperforms both previous prompt optimization methods and manual prompting.

</details>


### [37] [From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling](https://arxiv.org/abs/2506.16393)
*Yao Lu,Zhaiyuan Ji,Jiawei Du,Yu Shanqing,Qi Xuan,Tianyi Zhou*

Main category: cs.CL

TL;DR: 提出了一种多模型协作标注的新范式AutoAnnotator，解决了LLMs标注成本高和细粒度语义理解精度低的问题。


<details>
  <summary>Details</summary>
Motivation: LLMs在大规模标注中成本高，且在细粒度任务中精度低于SLMs，需改进。

Method: 设计了两层框架：上层元控制器选择SLMs并验证困难样本，下层任务专家通过多模型投票标注。利用困难样本进行强化学习，提升SLMs泛化能力。

Result: AutoAnnotator在零样本、单样本、CoT和多数投票设置中优于现有LLMs，成本降低74.15%，精度提升6.21%。

Conclusion: AutoAnnotator有效解决了LLMs标注的瓶颈问题，具有显著的成本和精度优势。

Abstract: Although the annotation paradigm based on Large Language Models (LLMs) has
made significant breakthroughs in recent years, its actual deployment still has
two core bottlenecks: first, the cost of calling commercial APIs in large-scale
annotation is very expensive; second, in scenarios that require fine-grained
semantic understanding, such as sentiment classification and toxicity
classification, the annotation accuracy of LLMs is even lower than that of
Small Language Models (SLMs) dedicated to this field. To address these
problems, we propose a new paradigm of multi-model cooperative annotation and
design a fully automatic annotation framework AutoAnnotator based on this.
Specifically, AutoAnnotator consists of two layers. The upper-level
meta-controller layer uses the generation and reasoning capabilities of LLMs to
select SLMs for annotation, automatically generate annotation code and verify
difficult samples; the lower-level task-specialist layer consists of multiple
SLMs that perform annotation through multi-model voting. In addition, we use
the difficult samples obtained by the secondary review of the meta-controller
layer as the reinforcement learning set and fine-tune the SLMs in stages
through a continual learning strategy, thereby improving the generalization of
SLMs. Extensive experiments show that AutoAnnotator outperforms existing
open-source/API LLMs in zero-shot, one-shot, CoT, and majority voting settings.
Notably, AutoAnnotator reduces the annotation cost by 74.15% compared to
directly annotating with GPT-3.5-turbo, while still improving the accuracy by
6.21%. Project page: https://github.com/Zhaiyuan-Ji/AutoAnnotator.

</details>


### [38] [OJBench: A Competition Level Code Benchmark For Large Language Models](https://arxiv.org/abs/2506.16395)
*Zhexu Wang,Yiping Liu,Yejie Wang,Wenyang He,Bofei Gao,Muxi Diao,Yanxu Chen,Kelin Fu,Flood Sung,Zhilin Yang,Tianyu Liu,Weiran Xu*

Main category: cs.CL

TL;DR: OJBench是一个新的代码推理基准测试，用于评估大型语言模型在竞争级编程问题上的能力，结果表明即使是先进模型也难以应对高难度问题。


<details>
  <summary>Details</summary>
Motivation: 现有代码基准测试无法全面评估大型语言模型的竞争级代码推理能力，因此需要更严格的测试工具。

Method: 引入OJBench，包含232个来自NOI和ICPC的编程竞赛问题，并对37种模型进行全面评估。

Result: 即使是先进模型（如o4-mini和Gemini-2.5-pro-exp）在竞争级问题上表现不佳，显示模型在高难度代码推理中的挑战。

Conclusion: 竞争级代码推理对模型仍具挑战性，需要进一步研究提升模型能力。

Abstract: Recent advancements in large language models (LLMs) have demonstrated
significant progress in math and code reasoning capabilities. However, existing
code benchmark are limited in their ability to evaluate the full spectrum of
these capabilities, particularly at the competitive level. To bridge this gap,
we introduce OJBench, a novel and challenging benchmark designed to assess the
competitive-level code reasoning abilities of LLMs. OJBench comprises 232
programming competition problems from NOI and ICPC, providing a more rigorous
test of models' reasoning skills. We conducted a comprehensive evaluation using
OJBench on 37 models, including both closed-source and open-source models,
reasoning-oriented and non-reasoning-oriented models. Our results indicate that
even state-of-the-art reasoning-oriented models, such as o4-mini and
Gemini-2.5-pro-exp, struggle with highly challenging competition-level
problems. This highlights the significant challenges that models face in
competitive-level code reasoning.

</details>


### [39] [NepaliGPT: A Generative Language Model for the Nepali Language](https://arxiv.org/abs/2506.16399)
*Shushanta Pudasaini,Aman Shakya,Siddhartha Shrestha,Sahil Bhatta,Sunil Thapa,Sushmita Palikhe*

Main category: cs.CL

TL;DR: 该研究填补了尼泊尔语生成语言模型的空白，提出了NepaliGPT，并引入了Devanagari语料库和首个尼泊尔语基准数据集。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏针对尼泊尔语的生成语言模型，导致下游任务如微调等无法开展，研究旨在填补这一空白。

Method: 研究收集了多来源的Devanagari语料库，并构建了包含4,296个问答对的基准数据集，开发了NepaliGPT模型。

Result: NepaliGPT在文本生成中表现优异：困惑度为26.32245，ROUGE-1得分为0.2604，因果一致性为85.41%，因果连贯性为81.25%。

Conclusion: NepaliGPT为尼泊尔语NLP领域提供了首个生成模型，为后续研究奠定了基础。

Abstract: After the release of ChatGPT, Large Language Models (LLMs) have gained huge
popularity in recent days and thousands of variants of LLMs have been released.
However, there is no generative language model for the Nepali language, due to
which other downstream tasks, including fine-tuning, have not been explored
yet. To fill this research gap in the Nepali NLP space, this research proposes
\textit{NepaliGPT}, a generative large language model tailored specifically for
the Nepali language. This research introduces an advanced corpus for the Nepali
language collected from several sources, called the Devanagari Corpus.
Likewise, the research introduces the first NepaliGPT benchmark dataset
comprised of 4,296 question-answer pairs in the Nepali language. The proposed
LLM NepaliGPT achieves the following metrics in text generation: Perplexity of
26.32245, ROUGE-1 score of 0.2604, causal coherence of 81.25\%, and causal
consistency of 85.41\%.

</details>


### [40] [When Does Divide and Conquer Work for Long Context LLM? A Noise Decomposition Framework](https://arxiv.org/abs/2506.16411)
*Zhen Xu,Shang Zhu,Jue Wang,Junlin Wang,Ben Athiwaratkun,Chi Wang,James Zou,Ce Zhang*

Main category: cs.CL

TL;DR: 论文研究了将大语言模型（LLMs）应用于长文本的挑战，提出了一个理论框架，将长上下文任务的失败模式分为三类，并通过实验验证了多代理分块方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在处理长文本时面临的挑战，尤其是跨块依赖、模型噪声和聚合噪声等问题。

Method: 提出理论框架分析长上下文任务的失败模式，并通过多代理分块方法（将长序列分成小块并聚合结果）进行实验验证。

Result: 实验证实了理论分析的正确性，并发现对于大型输入，配置分块处理的较弱模型可能优于单次处理的先进模型（如GPT4o）。

Conclusion: 通过精心设计的分块和聚合策略，为LLMs处理长上下文提供了一条直接且有效的路径。

Abstract: We investigate the challenge of applying Large Language Models (LLMs) to long
texts. We propose a theoretical framework that distinguishes the failure modes
of long context tasks into three categories: cross-chunk dependence (task
noise), confusion that grows with context size (model noise), and the imperfect
integration of partial results (aggregator noise). Under this view, we analyze
when it is effective to use multi-agent chunking, i.e., dividing a length
sequence into smaller chunks and aggregating the processed results of each
chunk. Our experiments on tasks such as retrieval, question answering, and
summarization confirm both the theoretical analysis and the conditions that
favor multi-agent chunking. By exploring superlinear model noise growth with
input length, we also explain why, for large inputs, a weaker model configured
with chunk-based processing can surpass a more advanced model like GPT4o
applied in a single shot. Overall, we present a principled understanding
framework and our results highlight a direct pathway to handling long contexts
in LLMs with carefully managed chunking and aggregator strategies.

</details>


### [41] [StoryWriter: A Multi-Agent Framework for Long Story Generation](https://arxiv.org/abs/2506.16445)
*Haotian Xia,Hao Peng,Yunjia Qi,Xiaozhi Wang,Bin Xu,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: StoryWriter是一个多代理框架，用于解决长故事生成的连贯性和复杂性挑战，通过大纲、规划和写作代理生成高质量长故事。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在长故事生成中面临连贯性和复杂性挑战，需要新的方法提升生成质量。

Method: StoryWriter包含三个模块：大纲代理生成事件大纲，规划代理细化事件并分章，写作代理动态压缩历史以确保连贯性。

Result: StoryWriter在故事质量和长度上显著优于基线模型，并生成了包含6000个高质量长故事的数据集。

Conclusion: StoryWriter及其训练模型在长故事生成中表现出先进性能，为相关领域提供了新工具和数据集。

Abstract: Long story generation remains a challenge for existing large language models
(LLMs), primarily due to two main factors: (1) discourse coherence, which
requires plot consistency, logical coherence, and completeness in the long-form
generation, and (2) narrative complexity, which requires an interwoven and
engaging narrative. To address these challenges, we propose StoryWriter, a
multi-agent story generation framework, which consists of three main modules:
(1) outline agent, which generates event-based outlines containing rich event
plots, character, and event-event relationships. (2) planning agent, which
further details events and plans which events should be written in each chapter
to maintain an interwoven and engaging story. (3) writing agent, which
dynamically compresses the story history based on the current event to generate
and reflect new plots, ensuring the coherence of the generated story. We
conduct both human and automated evaluation, and StoryWriter significantly
outperforms existing story generation baselines in both story quality and
length. Furthermore, we use StoryWriter to generate a dataset, which contains
about $6,000$ high-quality long stories, with an average length of $8,000$
words. We train the model Llama3.1-8B and GLM4-9B using supervised fine-tuning
on LongStory and develop StoryWriter_GLM and StoryWriter_GLM, which
demonstrates advanced performance in long story generation.

</details>


### [42] [Towards Generalizable Generic Harmful Speech Datasets for Implicit Hate Speech Detection](https://arxiv.org/abs/2506.16476)
*Saad Almohaimeed,Saleh Almohaimeed,Damla Turgut,Ladislau Bölöni*

Main category: cs.CL

TL;DR: 论文提出了一种检测隐式仇恨言论的方法，通过利用现有有害言论数据集，结合样本识别、重新标注和增强技术，显著提升了检测效果。


<details>
  <summary>Details</summary>
Motivation: 隐式仇恨言论对社会媒体平台构成挑战，现有研究多关注显式有害言论，缺乏对隐式仇恨的通用检测方法。

Method: 方法包括三个关键步骤：有影响力样本识别、重新标注和基于Llama-3 70B与GPT-4o的数据增强。

Result: 实验结果显示，该方法在隐式仇恨检测上比基线提升了12.9个F1分数点。

Conclusion: 该方法有效提升了隐式仇恨言论的检测能力，具有跨数据集的通用性。

Abstract: Implicit hate speech has recently emerged as a critical challenge for social
media platforms. While much of the research has traditionally focused on
harmful speech in general, the need for generalizable techniques to detect
veiled and subtle forms of hate has become increasingly pressing. Based on
lexicon analysis, we hypothesize that implicit hate speech is already present
in publicly available harmful speech datasets but may not have been explicitly
recognized or labeled by annotators. Additionally, crowdsourced datasets are
prone to mislabeling due to the complexity of the task and often influenced by
annotators' subjective interpretations. In this paper, we propose an approach
to address the detection of implicit hate speech and enhance generalizability
across diverse datasets by leveraging existing harmful speech datasets. Our
method comprises three key components: influential sample identification,
reannotation, and augmentation using Llama-3 70B and GPT-4o. Experimental
results demonstrate the effectiveness of our approach in improving implicit
hate detection, achieving a +12.9-point F1 score improvement compared to the
baseline.

</details>


### [43] [Relic: Enhancing Reward Model Generalization for Low-Resource Indic Languages with Few-Shot Examples](https://arxiv.org/abs/2506.16502)
*Soumya Suvra Ghosal,Vaibhav Singh,Akash Ghosh,Soumyabrata Pal,Subhadip Baidya,Sriparna Saha,Dinesh Manocha*

Main category: cs.CL

TL;DR: RELIC是一种新颖的上下文学习框架，用于低资源印度语言的奖励建模，通过从高资源语言中选择上下文示例，显著提升了奖励模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有开源多语言奖励模型主要基于高资源语言的偏好数据训练，导致对低资源印度语言的奖励信号不可靠，而收集这些语言的大规模高质量偏好数据成本高昂。

Method: RELIC通过训练一个检索器，利用成对排序目标从高资源语言中选择最能区分偏好和非偏好响应的上下文示例。

Result: 在多个偏好数据集上的实验表明，RELIC显著提升了低资源印度语言的奖励模型准确性，例如在Bodo语言上比零样本提示和现有最佳方法分别提升了12.81%和10.13%。

Conclusion: RELIC为解决低资源语言奖励建模问题提供了一种高效且实用的解决方案。

Abstract: Reward models are essential for aligning large language models (LLMs) with
human preferences. However, most open-source multilingual reward models are
primarily trained on preference datasets in high-resource languages, resulting
in unreliable reward signals for low-resource Indic languages. Collecting
large-scale, high-quality preference data for these languages is prohibitively
expensive, making preference-based training approaches impractical. To address
this challenge, we propose RELIC, a novel in-context learning framework for
reward modeling in low-resource Indic languages. RELIC trains a retriever with
a pairwise ranking objective to select in-context examples from auxiliary
high-resource languages that most effectively highlight the distinction between
preferred and less-preferred responses. Extensive experiments on three
preference datasets- PKU-SafeRLHF, WebGPT, and HH-RLHF-using state-of-the-art
open-source reward models demonstrate that RELIC significantly improves reward
model accuracy for low-resource Indic languages, consistently outperforming
existing example selection methods. For example, on Bodo-a low-resource Indic
language-using a LLaMA-3.2-3B reward model, RELIC achieves a 12.81% and 10.13%
improvement in accuracy over zero-shot prompting and state-of-the-art example
selection method, respectively.

</details>


### [44] [Automatic Speech Recognition Biases in Newcastle English: an Error Analysis](https://arxiv.org/abs/2506.16558)
*Dana Serditova,Kevin Tang,Jochen Steffens*

Main category: cs.CL

TL;DR: 研究探讨了自动语音识别（ASR）系统在区域方言（如纽卡斯尔英语）中的表现，发现其错误与方言特征直接相关，并呼吁增加训练数据的方言多样性。


<details>
  <summary>Details</summary>
Motivation: ASR系统因偏向主流语言而难以处理区域方言，区域偏见研究不足。

Method: 采用两阶段分析：手动错误分析和区域代词案例研究。

Result: ASR错误与方言特征直接相关，社会因素影响较小。

Conclusion: 需增加ASR训练数据的方言多样性，并利用社会语言学分析解决区域偏见。

Abstract: Automatic Speech Recognition (ASR) systems struggle with regional dialects
due to biased training which favours mainstream varieties. While previous
research has identified racial, age, and gender biases in ASR, regional bias
remains underexamined. This study investigates ASR performance on Newcastle
English, a well-documented regional dialect known to be challenging for ASR. A
two-stage analysis was conducted: first, a manual error analysis on a subsample
identified key phonological, lexical, and morphosyntactic errors behind ASR
misrecognitions; second, a case study focused on the systematic analysis of ASR
recognition of the regional pronouns ``yous'' and ``wor''. Results show that
ASR errors directly correlate with regional dialectal features, while social
factors play a lesser role in ASR mismatches. We advocate for greater dialectal
diversity in ASR training data and highlight the value of sociolinguistic
analysis in diagnosing and addressing regional biases.

</details>


### [45] [Weight Factorization and Centralization for Continual Learning in Speech Recognition](https://arxiv.org/abs/2506.16574)
*Enes Yavuz Ugan,Ngoc-Quan Pham,Alexander Waibel*

Main category: cs.CL

TL;DR: 提出了一种基于因子化和中心化的持续学习方法，通过低秩适配器防止灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 现代神经网络语音识别模型需要持续吸收新数据而无需重新训练整个系统，但在无排练、多语言和语言无关条件下容易导致灾难性遗忘。

Method: 受人类大脑通过醒睡循环学习和巩固知识的启发，提出两阶段方法：因子化阶段学习知识，中心化阶段通过低秩适配器合并知识。

Result: 在多种代码切换数据集上的实验表明，中心化阶段能有效防止灾难性遗忘。

Conclusion: 该方法通过低秩适配器积累知识，为持续学习提供了有效解决方案。

Abstract: Modern neural network based speech recognition models are required to
continually absorb new data without re-training the whole system, especially in
downstream applications using foundation models, having no access to the
original training data. Continually training the models in a rehearsal-free,
multilingual, and language agnostic condition, likely leads to catastrophic
forgetting, when a seemingly insignificant disruption to the weights can
destructively harm the quality of the models. Inspired by the ability of human
brains to learn and consolidate knowledge through the waking-sleeping cycle, we
propose a continual learning approach with two distinct phases: factorization
and centralization, learning and merging knowledge accordingly. Our experiments
on a sequence of varied code-switching datasets showed that the centralization
stage can effectively prevent catastrophic forgetting by accumulating the
knowledge in multiple scattering low-rank adapters.

</details>


### [46] [Streaming Non-Autoregressive Model for Accent Conversion and Pronunciation Improvement](https://arxiv.org/abs/2506.16580)
*Tuan-Nam Nguyen,Ngoc-Quan Pham,Seymanur Akti,Alexander Waibel*

Main category: cs.CL

TL;DR: 提出首个流式口音转换模型，将非母语语音转换为母语口音，同时保留说话者身份和韵律，并改进发音。


<details>
  <summary>Details</summary>
Motivation: 解决现有口音转换模型无法实时流式处理的问题，同时提升发音质量。

Method: 改进现有AC架构，采用Emformer编码器和优化推理机制，并集成TTS模型生成理想训练数据。

Result: 流式AC模型性能与顶级AC模型相当，且保持稳定延迟，成为首个支持流式处理的AC系统。

Conclusion: 该模型实现了流式口音转换，为实时应用提供了可能。

Abstract: We propose a first streaming accent conversion (AC) model that transforms
non-native speech into a native-like accent while preserving speaker identity,
prosody and improving pronunciation. Our approach enables stream processing by
modifying a previous AC architecture with an Emformer encoder and an optimized
inference mechanism. Additionally, we integrate a native text-to-speech (TTS)
model to generate ideal ground-truth data for efficient training. Our streaming
AC model achieves comparable performance to the top AC models while maintaining
stable latency, making it the first AC system capable of streaming.

</details>


### [47] [Measuring (a Sufficient) World Model in LLMs: A Variance Decomposition Framework](https://arxiv.org/abs/2506.16584)
*Nadav Kunievsky,James A. Evans*

Main category: cs.CL

TL;DR: 论文提出了一种评估大型语言模型（LLM）是否具备稳健世界模型的框架，通过分析模型输出的变异性来源，衡量其语义一致性。


<details>
  <summary>Details</summary>
Motivation: 评估LLM是否具备世界模型，以支持高风险应用中的可靠性。

Method: 提出新评估方法，将模型输出变异性分解为用户目的、用户表达和模型不稳定性三部分。

Result: 较大模型在用户目的变异性上表现更好，但优势有限且不统一。

Conclusion: 需超越准确性基准，采用语义诊断直接评估模型内部世界模型的结构和稳定性。

Abstract: Understanding whether large language models (LLMs) possess a world model-a
structured understanding of the world that supports generalization beyond
surface-level patterns-is central to assessing their reliability, especially in
high-stakes applications. We propose a formal framework for evaluating whether
an LLM exhibits a sufficiently robust world model, defined as producing
consistent outputs across semantically equivalent prompts while distinguishing
between prompts that express different intents. We introduce a new evaluation
approach to measure this that decomposes model response variability into three
components: variability due to user purpose, user articulation, and model
instability. An LLM with a strong world model should attribute most of the
variability in its responses to changes in foundational purpose rather than
superficial changes in articulation. This approach allows us to quantify how
much of a model's behavior is semantically grounded rather than driven by model
instability or alternative wording. We apply this framework to evaluate LLMs
across diverse domains. Our results show how larger models attribute a greater
share of output variability to changes in user purpose, indicating a more
robust world model. This improvement is not uniform, however: larger models do
not consistently outperform smaller ones across all domains, and their
advantage in robustness is often modest. These findings highlight the
importance of moving beyond accuracy-based benchmarks toward semantic
diagnostics that more directly assess the structure and stability of a model's
internal understanding of the world.

</details>


### [48] [A Scoping Review of Synthetic Data Generation for Biomedical Research and Applications](https://arxiv.org/abs/2506.16594)
*Hanshu Rao,Weisi Liu,Haohan Wang,I-Chan Huang,Zhe He,Xiaolei Huang*

Main category: cs.CL

TL;DR: 本文综述了2020-2025年间59项关于合成数据生成在生物医学领域应用的研究，重点分析了临床应用、方法学和评估趋势。


<details>
  <summary>Details</summary>
Motivation: 解决生物医学领域数据稀缺、隐私问题和数据质量挑战，利用大语言模型（LLMs）生成合成数据。

Method: 遵循PRISMA-ScR指南，系统分析了PubMed、ACM、Web of Science和Google Scholar中的59项研究。

Result: 研究发现合成数据生成主要应用于非结构化文本（78.0%）、表格数据（13.6%）和多模态数据（8.4%），方法包括提示（72.9%）、微调（22.0%）和专用模型（5.1%），评估方式多样。

Conclusion: 当前合成数据生成在生物医学领域的应用仍面临临床适应性、资源可及性和评估标准化等挑战。

Abstract: Synthetic data generation--mitigating data scarcity, privacy concerns, and
data quality challenges in biomedical fields--has been facilitated by rapid
advances of large language models (LLMs). This scoping review follows
PRISMA-ScR guidelines and synthesizes 59 studies, published between 2020 and
2025 and collected from PubMed, ACM, Web of Science, and Google Scholar. The
review systematically examines biomedical research and application trends in
synthetic data generation, emphasizing clinical applications, methodologies,
and evaluations. Our analysis identifies data modalities of unstructured texts
(78.0%), tabular data (13.6%), and multimodal sources (8.4%); generation
methods of prompting (72.9%), fine-tuning (22.0%) LLMs and specialized model
(5.1%); and heterogeneous evaluations of intrinsic metrics (27.1%),
human-in-the-loop assessments (55.9%), and LLM-based evaluations (13.6%). The
analysis addresses current limitations in what, where, and how health
professionals can leverage synthetic data generation for biomedical domains.
Our review also highlights challenges in adaption across clinical domains,
resource and model accessibility, and evaluation standardizations.

</details>


### [49] [Modeling Public Perceptions of Science in Media](https://arxiv.org/abs/2506.16622)
*Jiaxin Pei,Dustin Wright,Isabelle Augenstin,David Jurgens*

Main category: cs.CL

TL;DR: 本文提出了一种计算框架，用于建模公众对科学新闻的感知，并通过大规模数据集和NLP模型预测公众反应。研究发现，科学新闻的消费频率是感知的主要驱动因素，而感知评分与公众参与度直接相关。


<details>
  <summary>Details</summary>
Motivation: 科学传播中，公众对科学信息的感知和互动方式难以预测，影响了科学传播的效果。本文旨在通过建模公众感知，为科学传播提供新工具和见解。

Method: 开发了一个计算框架，建模公众对科学新闻的12个维度的感知，并创建了一个包含10,489个注释的大规模数据集。利用NLP模型预测感知评分，并通过Reddit实验验证感知与公众参与度的关系。

Result: 研究发现，科学新闻消费频率是感知的主要驱动因素，而感知评分显著影响公众参与度（如评论和点赞）。

Conclusion: 本研究强调了感知建模在科学传播中的重要性，为预测公众兴趣和参与度提供了新途径。

Abstract: Effectively engaging the public with science is vital for fostering trust and
understanding in our scientific community. Yet, with an ever-growing volume of
information, science communicators struggle to anticipate how audiences will
perceive and interact with scientific news. In this paper, we introduce a
computational framework that models public perception across twelve dimensions,
such as newsworthiness, importance, and surprisingness. Using this framework,
we create a large-scale science news perception dataset with 10,489 annotations
from 2,101 participants from diverse US and UK populations, providing valuable
insights into public responses to scientific information across domains. We
further develop NLP models that predict public perception scores with a strong
performance. Leveraging the dataset and model, we examine public perception of
science from two perspectives: (1) Perception as an outcome: What factors
affect the public perception of scientific information? (2) Perception as a
predictor: Can we use the estimated perceptions to predict public engagement
with science? We find that individuals' frequency of science news consumption
is the driver of perception, whereas demographic factors exert minimal
influence. More importantly, through a large-scale analysis and carefully
designed natural experiment on Reddit, we demonstrate that the estimated public
perception of scientific information has direct connections with the final
engagement pattern. Posts with more positive perception scores receive
significantly more comments and upvotes, which is consistent across different
scientific information and for the same science, but are framed differently.
Overall, this research underscores the importance of nuanced perception
modeling in science communication, offering new pathways to predict public
interest and engagement with scientific content.

</details>


### [50] [Initial Investigation of LLM-Assisted Development of Rule-Based Clinical NLP System](https://arxiv.org/abs/2506.16628)
*Jianlin Shi,Brian T. Bucher*

Main category: cs.CL

TL;DR: 论文提出了一种利用大语言模型（LLM）辅助开发基于规则的NLP系统的新方法，显著提高了效率与透明度。


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习和大型语言模型有进展，基于规则的NLP系统因其可解释性和操作效率仍在临床环境中使用，但其手动开发和维护成本高。

Method: 在规则系统开发阶段利用LLM，实验聚焦于从临床笔记中提取相关片段和关键词。

Result: 实验显示在提取临床相关片段（Deepseek: 0.98, Qwen: 0.99）和关键词（1.0）方面表现优异。

Conclusion: 该方法为NLP开发提供了新方向，比基于深度学习模型的解决方案更快、更经济且更透明。

Abstract: Despite advances in machine learning (ML) and large language models (LLMs),
rule-based natural language processing (NLP) systems remain active in clinical
settings due to their interpretability and operational efficiency. However,
their manual development and maintenance are labor-intensive, particularly in
tasks with large linguistic variability. To overcome these limitations, we
proposed a novel approach employing LLMs solely during the rule-based systems
development phase. We conducted the initial experiments focusing on the first
two steps of developing a rule-based NLP pipeline: find relevant snippets from
the clinical note; extract informative keywords from the snippets for the
rule-based named entity recognition (NER) component. Our experiments
demonstrated exceptional recall in identifying clinically relevant text
snippets (Deepseek: 0.98, Qwen: 0.99) and 1.0 in extracting key terms for NER.
This study sheds light on a promising new direction for NLP development,
enabling semi-automated or automated development of rule-based systems with
significantly faster, more cost-effective, and transparent execution compared
with deep learning model-based solutions.

</details>


### [51] [GeoGuess: Multimodal Reasoning based on Hierarchy of Visual Information in Street View](https://arxiv.org/abs/2506.16633)
*Fenghua Cheng,Jinxiang Wang,Sen Wang,Zi Huang,Xue Li*

Main category: cs.CL

TL;DR: 论文提出了一种名为GeoGuess的多模态推理任务，要求通过街景图像识别地理位置并解释，填补了现有任务在层次视觉线索推理上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有多模态推理任务缺乏对层次视觉线索（如局部细节和全局上下文）的推理能力，而GeoGuess任务旨在解决这一问题。

Method: 提出了SightSense方法，结合多模态和多层次推理，利用视觉信息和外部知识进行预测和解释。

Result: 实验表明，SightSense在GeoGuess任务中表现优异。

Conclusion: GeoGuess任务和SightSense方法为多模态推理提供了新的挑战和解决方案。

Abstract: Multimodal reasoning is a process of understanding, integrating and inferring
information across different data modalities. It has recently attracted surging
academic attention as a benchmark for Artificial Intelligence (AI). Although
there are various tasks for evaluating multimodal reasoning ability, they still
have limitations. Lack of reasoning on hierarchical visual clues at different
levels of granularity, e.g., local details and global context, is of little
discussion, despite its frequent involvement in real scenarios. To bridge the
gap, we introduce a novel and challenging task for multimodal reasoning, namely
GeoGuess. Given a street view image, the task is to identify its location and
provide a detailed explanation. A system that succeeds in GeoGuess should be
able to detect tiny visual clues, perceive the broader landscape, and associate
with vast geographic knowledge. Therefore, GeoGuess would require the ability
to reason between hierarchical visual information and geographic knowledge. In
this work, we establish a benchmark for GeoGuess by introducing a specially
curated dataset GeoExplain which consists of
panoramas-geocoordinates-explanation tuples. Additionally, we present a
multimodal and multilevel reasoning method, namely SightSense which can make
prediction and generate comprehensive explanation based on hierarchy of visual
information and external knowledge. Our analysis and experiments demonstrate
their outstanding performance in GeoGuess.

</details>


### [52] [Long-Context Generalization with Sparse Attention](https://arxiv.org/abs/2506.16640)
*Pavlo Vasylenko,Marcos Treviso,André F. T. Martins*

Main category: cs.CL

TL;DR: 论文提出使用稀疏注意力机制（如α-entmax）替代传统的softmax，以避免长序列中注意力分散的问题，并引入自适应可扩展的ASEntmax，结合位置编码，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统softmax在长序列任务中会导致注意力分散和表示崩溃，需要一种更精确的注意力机制来聚焦固定大小的模式。

Method: 提出ASEntmax，结合可学习的温度参数，使注意力分布能在稀疏和密集之间调节，并优化位置编码设计。

Result: ASEntmax结合位置编码后，在长上下文泛化任务中显著优于softmax和其他基线方法。

Conclusion: 稀疏注意力机制和优化的位置编码能有效提升模型在长序列任务中的表现。

Abstract: Transformer-based architectures traditionally employ softmax to compute
attention weights, which produces dense distributions over all tokens in a
sequence. While effective in many settings, this density has been shown to be
detrimental for tasks that demand precise focus on fixed-size patterns: as
sequence length increases, non-informative tokens accumulate attention
probability mass, leading to dispersion and representational collapse. We show
in this paper that sparse attention mechanisms using $\alpha$-entmax can avoid
these issues, due to their ability to assign exact zeros to irrelevant tokens.
Furthermore, we introduce Adaptive-Scalable Entmax (ASEntmax), which endows
$\alpha$-entmax with a learnable temperature parameter, allowing the attention
distribution to interpolate between sparse (pattern-focused) and dense
(softmax-like) regimes. Finally, we show that the ability to locate and
generalize fixed-size patterns can be further improved through a careful design
of position encodings, which impacts both dense and sparse attention methods.
By integrating ASEntmax into standard transformer layers alongside proper
positional encodings, we show that our models greatly outperform softmax,
scalable softmax, and fixed-temperature $\alpha$-entmax baselines on
long-context generalization.

</details>


### [53] [Arch-Router: Aligning LLM Routing with Human Preferences](https://arxiv.org/abs/2506.16655)
*Co Tran,Salman Paracha,Adil Hafeez,Shuguang Chen*

Main category: cs.CL

TL;DR: 本文提出了一种偏好对齐的路由框架Arch-Router，用于根据用户定义的领域或动作类型匹配查询，优化大语言模型（LLM）的路由决策。


<details>
  <summary>Details</summary>
Motivation: 现有LLM路由方法在性能评估和模型选择上存在局限性，无法充分捕捉人类偏好或支持灵活扩展。

Method: 提出Arch-Router，一个1.5B参数的紧凑模型，通过学习查询与领域-动作偏好的映射来指导路由决策，并支持无缝添加新模型。

Result: 在对话数据集上的实验表明，Arch-Router在匹配人类偏好方面达到了SOTA性能，优于顶级专有模型。

Conclusion: Arch-Router通过捕捉主观评价标准，使路由决策更透明灵活，且无需重新训练即可扩展模型池。

Abstract: With the rapid proliferation of large language models (LLMs) -- each
optimized for different strengths, style, or latency/cost profile -- routing
has become an essential technique to operationalize the use of different
models. However, existing LLM routing approaches are limited in two key ways:
they evaluate performance using benchmarks that often fail to capture human
preferences driven by subjective evaluation criteria, and they typically select
from a limited pool of models. In this work, we propose a preference-aligned
routing framework that guides model selection by matching queries to
user-defined domains (e.g., travel) or action types (e.g., image editing) --
offering a practical mechanism to encode preferences in routing decisions.
Specifically, we introduce \textbf{Arch-Router}, a compact 1.5B model that
learns to map queries to domain-action preferences for model routing decisions.
Our approach also supports seamlessly adding new models for routing without
requiring retraining or architectural modifications. Experiments on
conversational datasets demonstrate that our approach achieves state-of-the-art
(SOTA) results in matching queries with human preferences, outperforming top
proprietary models. Our approach captures subjective evaluation criteria and
makes routing decisions more transparent and flexible. Our model is available
at: \texttt{https://huggingface.co/katanemo/Arch-Router-1.5B}.

</details>


### [54] [Mechanisms vs. Outcomes: Probing for Syntax Fails to Explain Performance on Targeted Syntactic Evaluations](https://arxiv.org/abs/2506.16678)
*Ananth Agarwal,Jasper Jian,Christopher D. Manning,Shikhar Murty*

Main category: cs.CL

TL;DR: 研究发现，尽管大语言模型（LLMs）在语法处理上表现出色，但通过探测提取的语法特征无法预测其在具体语法任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs内部语法表示机制与下游语法任务表现之间的关系。

Method: 评估32个开源Transformer模型，比较探测提取的语法特征与下游语法任务表现。

Result: 探测提取的语法特征与下游语法任务表现无显著关联。

Conclusion: LLMs的潜在语法表示与可观察的语法行为之间存在明显脱节。

Abstract: Large Language Models (LLMs) exhibit a robust mastery of syntax when
processing and generating text. While this suggests internalized understanding
of hierarchical syntax and dependency relations, the precise mechanism by which
they represent syntactic structure is an open area within interpretability
research. Probing provides one way to identify the mechanism of syntax being
linearly encoded in activations, however, no comprehensive study has yet
established whether a model's probing accuracy reliably predicts its downstream
syntactic performance. Adopting a "mechanisms vs. outcomes" framework, we
evaluate 32 open-weight transformer models and find that syntactic features
extracted via probing fail to predict outcomes of targeted syntax evaluations
across English linguistic phenomena. Our results highlight a substantial
disconnect between latent syntactic representations found via probing and
observable syntactic behaviors in downstream tasks.

</details>


### [55] [LegiGPT: Party Politics and Transport Policy with Large Language Model](https://arxiv.org/abs/2506.16692)
*Hyunsoo Yun,Eun Hak Lee*

Main category: cs.CL

TL;DR: LegiGPT结合大型语言模型和可解释AI，分析韩国立法数据，揭示党派、赞助者特征和地理变量对交通政策制定的影响。


<details>
  <summary>Details</summary>
Motivation: 研究立法者政治意识形态对政策制定的影响，为理解立法动态提供工具。

Method: 使用LegiGPT框架，通过多阶段过滤和分类流程，结合GPT-4和XAI技术分析立法提案。

Result: 保守派和进步派赞助者数量、选区规模和选民人口是关键因素，两党通过不同方式推动两党立法。

Conclusion: LegiGPT为立法动态和政策发展提供了有价值的工具，对基础设施规划和治理有广泛意义。

Abstract: Given the significant influence of lawmakers' political ideologies on
legislative decision-making, understanding their impact on policymaking is
critically important. We introduce a novel framework, LegiGPT, which integrates
a large language model (LLM) with explainable artificial intelligence (XAI) to
analyze transportation-related legislative proposals. LegiGPT employs a
multi-stage filtering and classification pipeline using zero-shot prompting
with GPT-4. Using legislative data from South Korea's 21st National Assembly,
we identify key factors - including sponsor characteristics, political
affiliations, and geographic variables - that significantly influence
transportation policymaking. The LLM was used to classify
transportation-related bill proposals through a stepwise filtering process
based on keywords, phrases, and contextual relevance. XAI techniques were then
applied to examine relationships between party affiliation and associated
attributes. The results reveal that the number and proportion of conservative
and progressive sponsors, along with district size and electoral population,
are critical determinants shaping legislative outcomes. These findings suggest
that both parties contributed to bipartisan legislation through different forms
of engagement, such as initiating or supporting proposals. This integrated
approach provides a valuable tool for understanding legislative dynamics and
guiding future policy development, with broader implications for infrastructure
planning and governance.

</details>


### [56] [ReasonGRM: Enhancing Generative Reward Models through Large Reasoning Models](https://arxiv.org/abs/2506.16712)
*Bin Chen,Xinzge Gao,Chuanrui Hu,Penghang Yu,Hua Zhang,Bing-Kun Bao*

Main category: cs.CL

TL;DR: ReasonGRM是一个三阶段生成奖励建模框架，通过改进推理路径和减少幻觉，显著提升了生成奖励模型的性能。


<details>
  <summary>Details</summary>
Motivation: 生成奖励模型（GRMs）在捕捉人类偏好方面比标量奖励模型更灵活，但其推理能力不足导致推理路径不完整或过于推测性，从而产生幻觉或遗漏关键信息。

Method: ReasonGRM分为三个阶段：1）使用Zero-RL生成简洁、结果导向的推理路径；2）引入新评估指标$R^\star$，基于生成可能性评分推理路径；3）通过强化学习在挑战性示例上进一步优化模型。

Result: 在三个公共基准测试中，ReasonGRM表现优异，平均优于先前最佳GRMs 1.8%，并超越GPT-4o等专有模型达5.6%。

Conclusion: ReasonGRM证明了推理感知训练的有效性，并强调了高质量理性选择对可靠偏好建模的重要性。

Abstract: Generative Reward Models (GRMs) provide greater flexibility than scalar
reward models in capturing human preferences, but their effectiveness is
limited by poor reasoning capabilities. This often results in incomplete or
overly speculative reasoning paths, leading to hallucinations or missing key
information in complex tasks. We address this challenge with ReasonGRM, a
three-stage generative reward modeling framework. In the first stage, Zero-RL
is used to generate concise, outcome-directed reasoning paths that reduce the
likelihood of critical omissions. In the second stage, we introduce a novel
evaluation metric, $R^\star$, which scores reasoning paths based on their
generation likelihood. This favors paths that reach correct answers with
minimal exploration, helping to reduce hallucination-prone data during
training. In the final stage, the model is further refined through
reinforcement learning on challenging examples to enhance its preference
discrimination capabilities. Experiments on three public benchmarks show that
ReasonGRM achieves competitive or state-of-the-art performance, outperforming
previous best GRMs by 1.8\% on average and surpassing proprietary models such
as GPT-4o by up to 5.6\%. These results demonstrate the effectiveness of
reasoning-aware training and highlight the importance of high-quality rationale
selection for reliable preference modeling.

</details>


### [57] [The Role of Model Confidence on Bias Effects in Measured Uncertainties](https://arxiv.org/abs/2506.16724)
*Xinyi Liu,Weiguang Wang,Hangfeng He*

Main category: cs.CL

TL;DR: 论文研究了在大型语言模型（LLMs）中如何准确评估认知不确定性，并探讨了偏差对不确定性量化的影响。通过实验发现，减少提示引入的偏差可以改善GPT-4o的不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在开放任务中的广泛应用，准确评估认知不确定性（反映模型知识不足）对确保可靠结果至关重要。然而，由于存在多义性（aleatoric uncertainty），量化认知不确定性具有挑战性。

Method: 在视觉问答（VQA）任务上进行实验，分析提示偏差对GPT-4o和Qwen2-VL模型中认知和随机不确定性的影响。

Result: 研究发现，所有考虑的偏差在模型信心较低时对两种不确定性的影响更大。低信心还导致认知不确定性被低估（过度自信），但对随机不确定性的方向性变化无显著影响。

Conclusion: 这些发现深化了对偏差缓解在不确定性量化中作用的理解，并为开发更先进的技术提供了潜在指导。

Abstract: With the growing adoption of Large Language Models (LLMs) for open-ended
tasks, accurately assessing epistemic uncertainty, which reflects a model's
lack of knowledge, has become crucial to ensuring reliable outcomes. However,
quantifying epistemic uncertainty in such tasks is challenging due to the
presence of aleatoric uncertainty, which arises from multiple valid answers.
While bias can introduce noise into epistemic uncertainty estimation, it may
also reduce noise from aleatoric uncertainty. To investigate this trade-off, we
conduct experiments on Visual Question Answering (VQA) tasks and find that
mitigating prompt-introduced bias improves uncertainty quantification in
GPT-4o. Building on prior work showing that LLMs tend to copy input information
when model confidence is low, we further analyze how these prompt biases affect
measured epistemic and aleatoric uncertainty across varying bias-free
confidence levels with GPT-4o and Qwen2-VL. We find that all considered biases
induce greater changes in both uncertainties when bias-free model confidence is
lower. Moreover, lower bias-free model confidence leads to greater
underestimation of epistemic uncertainty (i.e. overconfidence) due to bias,
whereas it has no significant effect on the direction of changes in aleatoric
uncertainty estimation. These distinct effects deepen our understanding of bias
mitigation for uncertainty quantification and potentially inform the
development of more advanced techniques.

</details>


### [58] [LM-SPT: LM-Aligned Semantic Distillation for Speech Tokenization](https://arxiv.org/abs/2506.16738)
*Daejin Jo,Jeeyoung Yun,Byungseok Roh,Sungwoong Kim*

Main category: cs.CL

TL;DR: LM-SPT是一种新的语音标记化方法，通过间接数据驱动监督学习更语义化的离散单元，支持多种帧率，并在语音到文本和文本到语音任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有语音标记化方法生成的标记序列过长，且标准降帧技术可能破坏语义结构，因此需要一种更有效的方法来对齐语言模型。

Method: 提出LM-SPT，通过重构语音并最小化原始与重构波形的编码表示差异，间接学习语义对齐的离散单元，同时改进编码器和解码器架构。

Result: LM-SPT在重建保真度上优于基线，且基于其标记的语音语言模型在语音到文本和文本到语音任务中表现更优。

Conclusion: LM-SPT通过语义蒸馏和架构改进，显著提升了语音标记化的语义对齐和任务性能。

Abstract: With the rapid progress of speech language models (SLMs), discrete speech
tokens have emerged as a core interface between speech and text, enabling
unified modeling across modalities. Recent speech tokenization approaches aim
to isolate semantic information from low-level acoustics to better align with
language models. In particular, previous methods use SSL teachers such as
HuBERT to extract semantic representations, which are then distilled into a
semantic quantizer to suppress acoustic redundancy as well as capture
content-related latent structures. However, they still produce speech token
sequences significantly longer than their textual counterparts, creating
challenges for efficient speech-language modeling. Reducing the frame rate is a
natural solution, but standard techniques, such as rigid average pooling across
frames, can distort or dilute the semantic structure required for effective LM
alignment. To address this, we propose LM-SPT, a speech tokenization method
that introduces a novel semantic distillation. Instead of directly matching
teacher and student features via pooling, we reconstruct speech solely from
semantic tokens and minimize the discrepancy between the encoded
representations of the original and reconstructed waveforms, obtained from a
frozen automatic speech recognition (ASR) encoder. This indirect yet
data-driven supervision enables the tokenizer to learn discrete units that are
more semantically aligned with language models. LM-SPT further incorporates
architectural improvements to the encoder and decoder for speech tokenization,
and supports multiple frame rates, including 25Hz, 12.5Hz, and 6.25Hz.
Experimental results show that LM-SPT achieves superior reconstruction fidelity
compared to baselines, and that SLMs trained with LM-SPT tokens achieve
competitive performances on speech-to-text and consistently outperform
baselines on text-to-speech tasks.

</details>


### [59] [Language-Informed Synthesis of Rational Agent Models for Grounded Theory-of-Mind Reasoning On-The-Fly](https://arxiv.org/abs/2506.16755)
*Lance Ying,Ryan Truong,Katherine M. Collins,Cedegao E. Zhang,Megan Wei,Tyler Brooke-Wilson,Tan Zhi-Xuan,Lionel Wong,Joshua B. Tenenbaum*

Main category: cs.CL

TL;DR: LIRAS框架通过结合语言和视觉输入，构建特定情境的代理和环境表示，利用贝叶斯逆规划引擎进行社会推理，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界的社会推理需要多模态信息，语言在社交环境中尤为重要，尤其是在新情境中。

Method: 提出LIRAS框架，利用多模态语言模型解析语言和视觉输入为统一符号表示，并通过贝叶斯逆规划引擎生成概率判断。

Result: 在多个社会推理任务中，LIRAS表现优于现有模型，更接近人类判断。

Conclusion: LIRAS展示了语言和视觉结合在社会推理中的有效性，为多模态推理提供了新思路。

Abstract: Drawing real world social inferences usually requires taking into account
information from multiple modalities. Language is a particularly powerful
source of information in social settings, especially in novel situations where
language can provide both abstract information about the environment dynamics
and concrete specifics about an agent that cannot be easily visually observed.
In this paper, we propose Language-Informed Rational Agent Synthesis (LIRAS), a
framework for drawing context-specific social inferences that integrate
linguistic and visual inputs. LIRAS frames multimodal social reasoning as a
process of constructing structured but situation-specific agent and environment
representations - leveraging multimodal language models to parse language and
visual inputs into unified symbolic representations, over which a Bayesian
inverse planning engine can be run to produce granular probabilistic judgments.
On a range of existing and new social reasoning tasks derived from cognitive
science experiments, we find that our model (instantiated with a comparatively
lightweight VLM) outperforms ablations and state-of-the-art models in capturing
human judgments across all domains.

</details>


### [60] [SocialSim: Towards Socialized Simulation of Emotional Support Conversation](https://arxiv.org/abs/2506.16756)
*Zhuang Chen,Yaru Cao,Guanqun Bi,Jincenzi Wu,Jinfeng Zhou,Xiyao Xiao,Si Chen,Hongning Wang,Minlie Huang*

Main category: cs.CL

TL;DR: SocialSim框架通过整合社交互动中的社交披露和社交意识，模拟情感支持对话（ESC），并构建了高质量的合成ESC语料库SSConv。


<details>
  <summary>Details</summary>
Motivation: 由于众包大规模ESC语料库成本高，现有方法忽视了ESC中的社交动态，导致模拟效果不佳。

Method: 在寻求者端，通过构建全面的角色库促进社交披露；在支持者端，通过认知推理增强社交意识。

Result: 构建的SSConv语料库质量超越众包数据，训练出的聊天机器人在自动和人工评估中表现优异。

Conclusion: SocialSim为ESC合成提供了可扩展的方法，使情感关怀更易实现。

Abstract: Emotional support conversation (ESC) helps reduce people's psychological
stress and provide emotional value through interactive dialogues. Due to the
high cost of crowdsourcing a large ESC corpus, recent attempts use large
language models for dialogue augmentation. However, existing approaches largely
overlook the social dynamics inherent in ESC, leading to less effective
simulations. In this paper, we introduce SocialSim, a novel framework that
simulates ESC by integrating key aspects of social interactions: social
disclosure and social awareness. On the seeker side, we facilitate social
disclosure by constructing a comprehensive persona bank that captures diverse
and authentic help-seeking scenarios. On the supporter side, we enhance social
awareness by eliciting cognitive reasoning to generate logical and supportive
responses. Building upon SocialSim, we construct SSConv, a large-scale
synthetic ESC corpus of which quality can even surpass crowdsourced ESC data.
We further train a chatbot on SSConv and demonstrate its state-of-the-art
performance in both automatic and human evaluations. We believe SocialSim
offers a scalable way to synthesize ESC, making emotional care more accessible
and practical.

</details>


### [61] [Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models](https://arxiv.org/abs/2506.16760)
*Lei Jiang,Zixun Zhang,Zizhou Wang,Xiaobing Sun,Zhen Li,Liangli Zhen,Xiaohua Xu*

Main category: cs.CL

TL;DR: CAMO是一种新型的黑盒越狱攻击框架，通过将恶意提示分解为视觉和文本片段，利用多模态模型的跨模态推理能力绕过安全机制。


<details>
  <summary>Details</summary>
Motivation: 现有黑盒越狱方法易被检测且效率低，CAMO旨在提供更隐蔽和高效的攻击方式。

Method: CAMO将恶意提示分解为语义无害的视觉和文本片段，利用跨模态推理重构有害指令。

Result: CAMO在主流多模态模型上表现优异，具有强跨模型迁移性和低查询需求。

Conclusion: 当前安全机制存在显著漏洞，亟需更高级的安全解决方案。

Abstract: Large Vision-Language Models (LVLMs) demonstrate exceptional performance
across multimodal tasks, yet remain vulnerable to jailbreak attacks that bypass
built-in safety mechanisms to elicit restricted content generation. Existing
black-box jailbreak methods primarily rely on adversarial textual prompts or
image perturbations, yet these approaches are highly detectable by standard
content filtering systems and exhibit low query and computational efficiency.
In this work, we present Cross-modal Adversarial Multimodal Obfuscation (CAMO),
a novel black-box jailbreak attack framework that decomposes malicious prompts
into semantically benign visual and textual fragments. By leveraging LVLMs'
cross-modal reasoning abilities, CAMO covertly reconstructs harmful
instructions through multi-step reasoning, evading conventional detection
mechanisms. Our approach supports adjustable reasoning complexity and requires
significantly fewer queries than prior attacks, enabling both stealth and
efficiency. Comprehensive evaluations conducted on leading LVLMs validate
CAMO's effectiveness, showcasing robust performance and strong cross-model
transferability. These results underscore significant vulnerabilities in
current built-in safety mechanisms, emphasizing an urgent need for advanced,
alignment-aware security and safety solutions in vision-language systems.

</details>


### [62] [DistillNote: LLM-based clinical note summaries improve heart failure diagnosis](https://arxiv.org/abs/2506.16777)
*Heloisa Oss Boll,Antonio Oss Boll,Leticia Puttlitz Boll,Ameen Abu Hanna,Iacer Calixto*

Main category: cs.CL

TL;DR: Distillnote框架利用LLMs生成临床笔记摘要，通过三种技术（一步摘要、结构化摘要和蒸馏摘要）实现高效压缩和性能提升。蒸馏摘要压缩率达79%，AUPRC提升18.2%，临床评估显示一步摘要更受青睐。


<details>
  <summary>Details</summary>
Motivation: 减轻临床文档负担，利用LLMs生成高效且准确的临床笔记摘要。

Method: 采用一步摘要、结构化摘要和蒸馏摘要三种技术生成摘要，并通过预测心衰和临床评估验证其效果。

Result: 蒸馏摘要实现79%文本压缩和18.2% AUPRC提升，一步摘要在临床评估中表现更优。

Conclusion: Distillnote框架有效提升临床笔记摘要的效率和性能，一步摘要和蒸馏摘要各有优势，适用于不同场景。

Abstract: Large language models (LLMs) offer unprecedented opportunities to generate
concise summaries of patient information and alleviate the burden of clinical
documentation that overwhelms healthcare providers. We present Distillnote, a
framework for LLM-based clinical note summarization, and generate over 64,000
admission note summaries through three techniques: (1) One-step, direct
summarization, and a divide-and-conquer approach involving (2) Structured
summarization focused on independent clinical insights, and (3) Distilled
summarization that further condenses the Structured summaries. We test how
useful are the summaries by using them to predict heart failure compared to a
model trained on the original notes. Distilled summaries achieve 79% text
compression and up to 18.2% improvement in AUPRC compared to an LLM trained on
the full notes. We also evaluate the quality of the generated summaries in an
LLM-as-judge evaluation as well as through blinded pairwise comparisons with
clinicians. Evaluations indicate that one-step summaries are favoured by
clinicians according to relevance and clinical actionability, while distilled
summaries offer optimal efficiency (avg. 6.9x compression-to-performance ratio)
and significantly reduce hallucinations. We release our summaries on PhysioNet
to encourage future research.

</details>


### [63] [MIST: Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning](https://arxiv.org/abs/2506.16792)
*Muyang Zheng,Yuanzhi Yao,Changting Lin,Rui Wang,Meng Han*

Main category: cs.CL

TL;DR: MIST是一种通过迭代语义调整（Iterative Semantic Tuning）来破解黑盒大语言模型（LLMs）的有效方法，能够在保持语义意图的同时诱导有害内容。


<details>
  <summary>Details</summary>
Motivation: 尽管努力将大语言模型与社会和道德价值观对齐，但这些模型仍易受破解攻击的影响，尤其是在黑盒条件下破解更具挑战性。

Method: MIST采用两种关键策略：顺序同义词搜索和顺序确定优化，以平衡语义相似性和计算效率。

Result: 实验表明，MIST在攻击成功率和攻击可转移性上优于其他先进的白盒和黑盒破解方法，并验证了其计算效率的实用性。

Conclusion: MIST为破解黑盒大语言模型提供了一种高效且实用的解决方案。

Abstract: Despite efforts to align large language models (LLMs) with societal and moral
values, these models remain susceptible to jailbreak attacks--methods designed
to elicit harmful responses. Jailbreaking black-box LLMs is considered
challenging due to the discrete nature of token inputs, restricted access to
the target LLM, and limited query budget. To address the issues above, we
propose an effective method for jailbreaking black-box large language Models
via Iterative Semantic Tuning, named MIST. MIST enables attackers to
iteratively refine prompts that preserve the original semantic intent while
inducing harmful content. Specifically, to balance semantic similarity with
computational efficiency, MIST incorporates two key strategies: sequential
synonym search, and its advanced version--order-determining optimization.
Extensive experiments across two open-source models and four closed-source
models demonstrate that MIST achieves competitive attack success rates and
attack transferability compared with other state-of-the-art white-box and
black-box jailbreak methods. Additionally, we conduct experiments on
computational efficiency to validate the practical viability of MIST.

</details>


### [64] [From Data to Knowledge: Evaluating How Efficiently Language Models Learn Facts](https://arxiv.org/abs/2506.16912)
*Daniel Christoph,Max Ploner,Patrick Haller,Alan Akbik*

Main category: cs.CL

TL;DR: 研究分析了不同架构和大小的语言模型在相同预训练数据上的表现，发现模型在高频事实上的表现相似，但在低频事实上差异显著。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的信息呈现长尾分布，模型需要高效学习和记忆高频及低频事实，以提高样本效率。

Method: 通过标注训练语料中关系事实的频率，分析不同模型在不同频率事实上的表现。

Result: 大多数模型在高频事实上表现相似，但在低频事实上表现差异显著。

Conclusion: 研究揭示了模型架构、大小与事实学习效率之间的关系。

Abstract: Sample efficiency is a crucial property of language models with practical
implications for training efficiency. In real-world text, information follows a
long-tailed distribution. Yet, we expect models to learn and recall frequent
and infrequent facts. Sample-efficient models are better equipped to handle
this challenge of learning and retaining rare information without requiring
excessive exposure. This study analyzes multiple models of varying
architectures and sizes, all trained on the same pre-training data. By
annotating relational facts with their frequencies in the training corpus, we
examine how model performance varies with fact frequency. Our findings show
that most models perform similarly on high-frequency facts but differ notably
on low-frequency facts. This analysis provides new insights into the
relationship between model architecture, size, and factual learning efficiency.

</details>


### [65] [Language Bottleneck Models: A Framework for Interpretable Knowledge Tracing and Beyond](https://arxiv.org/abs/2506.16982)
*Antonin Berthon,Mihaela van der Schaar*

Main category: cs.CL

TL;DR: 论文提出了一种基于语言瓶颈模型（LBM）的知识追踪方法，通过生成可解释的自然语言摘要来提高预测准确性，同时减少数据需求。


<details>
  <summary>Details</summary>
Motivation: 传统知识追踪方法依赖不透明的潜在嵌入，缺乏可解释性；而基于LLM的方法可能产生不准确的预测或摘要。因此，需要一种既能保证准确性又具有可解释性的方法。

Method: 提出语言瓶颈模型（LBM），包括一个编码器LLM生成可解释的知识摘要，以及一个冻结的解码器LLM仅基于摘要重构和预测学生回答。通过自然语言瓶颈约束信息传递，确保摘要准确且可解释。

Result: 在合成算术基准和大规模Eedi数据集上，LBM的准确性媲美最先进的知识追踪和直接LLM方法，同时所需学生轨迹数据显著减少。

Conclusion: LBM通过语言瓶颈和策略优化，实现了高准确性和可解释性的知识追踪，为教育领域提供了一种高效且透明的解决方案。

Abstract: Accurately assessing student knowledge is critical for effective education,
yet traditional Knowledge Tracing (KT) methods rely on opaque latent
embeddings, limiting interpretability. Even LLM-based approaches generate
direct predictions or summaries that may hallucinate without any accuracy
guarantees. We recast KT as an inverse problem: learning the minimum
natural-language summary that makes past answers explainable and future answers
predictable. Our Language Bottleneck Model (LBM) consists of an encoder LLM
that writes an interpretable knowledge summary and a frozen decoder LLM that
must reconstruct and predict student responses using only that summary text. By
constraining all predictive information to pass through a short
natural-language bottleneck, LBMs ensure that the summary contains accurate
information while remaining human-interpretable. Experiments on synthetic
arithmetic benchmarks and the large-scale Eedi dataset show that LBMs rival the
accuracy of state-of-the-art KT and direct LLM methods while requiring
orders-of-magnitude fewer student trajectories. We demonstrate that training
the encoder with group-relative policy optimization, using downstream decoding
accuracy as a reward signal, effectively improves summary quality.

</details>


### [66] [TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs](https://arxiv.org/abs/2506.16990)
*Sahil Kale,Vijaykant Nadadur*

Main category: cs.CL

TL;DR: TeXpert是一个用于评估LLMs生成LaTeX代码能力的基准数据集，发现LLMs在复杂任务中表现不佳，开源模型与闭源模型竞争激烈，且格式和包错误常见。


<details>
  <summary>Details</summary>
Motivation: 现有基准缺乏对LLMs生成LaTeX代码能力的评估，而LaTeX在科学文档中的重要性促使开发Texpert填补这一空白。

Method: 通过Texpert数据集，包含多难度级别的自然语言提示，对开源和闭源LLMs进行LaTeX生成能力的深入分析。

Result: LLMs在标准基准表现优异，但在LaTeX生成中表现差，复杂度增加时准确性显著下降；开源模型如DeepSeek v3与闭源模型竞争激烈；格式和包错误普遍。

Conclusion: Texpert揭示了LLMs在LaTeX生成中的局限性，尤其是训练数据缺乏多样性，为未来改进提供了方向。

Abstract: LaTeX's precision and flexibility in typesetting have made it the gold
standard for the preparation of scientific documentation. Large Language Models
(LLMs) present a promising opportunity for researchers to produce
publication-ready material using LaTeX with natural language instructions, yet
current benchmarks completely lack evaluation of this ability. By introducing
TeXpert, our benchmark dataset with natural language prompts for generating
LaTeX code focused on components of scientific documents across multiple
difficulty levels, we conduct an in-depth analysis of LLM performance in this
regard and identify frequent error types. Our evaluation across open and
closed-source LLMs highlights multiple key findings: LLMs excelling on standard
benchmarks perform poorly in LaTeX generation with a significant accuracy
drop-off as the complexity of tasks increases; open-source models like DeepSeek
v3 and DeepSeek Coder strongly rival closed-source counterparts in LaTeX tasks;
and formatting and package errors are unexpectedly prevalent, suggesting a lack
of diverse LaTeX examples in the training datasets of most LLMs. Our dataset,
code, and model evaluations are available at
https://github.com/knowledge-verse-ai/TeXpert.

</details>


### [67] [PersonalAI: Towards digital twins in the graph form](https://arxiv.org/abs/2506.17001)
*Mikhail Menschikov,Dmitry Evseev,Ruslan Kostoev,Ilya Perepechkin,Ilnaz Salimov,Victoria Dochkina,Petr Anokhin,Evgeny Burnaev,Nikita Semenov*

Main category: cs.CL

TL;DR: 论文提出了一种利用知识图谱作为外部记忆的方法，以增强语言模型的个性化能力，并通过实验验证了其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）和检索增强生成技术取得了进展，但如何保留大量个人信息并生成个性化响应仍是一个挑战。

Method: 采用知识图谱作为外部记忆，扩展了AriGraph架构，首次引入包含标准边和两种超边的组合图。

Result: 在TriviaQA、HotpotQA和DiaASQ基准测试中表现良好，证明了方法的统一性和鲁棒性。

Conclusion: 提出的架构能够有效维护和利用时间依赖性，即使在对话中引入矛盾和时间参数的情况下仍保持稳健性能。

Abstract: The challenge of personalizing language models, specifically the ability to
account for a user's history during interactions, is of significant interest.
Despite recent advancements in large language models (LLMs) and Retrieval
Augmented Generation that have enhanced the factual base of LLMs, the task of
retaining extensive personal information and using it to generate personalized
responses remains pertinent. To address this, we propose utilizing external
memory in the form of knowledge graphs, which are constructed and updated by
the LLM itself. We have expanded upon ideas of AriGraph architecture and for
the first time introduced a combined graph featuring both standard edges and
two types of hyperedges. Experiments conducted on the TriviaQA, HotpotQA and
DiaASQ benchmarks indicates that this approach aids in making the process of
graph construction and knowledge extraction unified and robust. Furthermore, we
augmented the DiaASQ benchmark by incorporating parameters such as time into
dialogues and introducing contradictory statements made by the same speaker at
different times. Despite these modifications, the performance of the
question-answering system remained robust, demonstrating the proposed
architecture's ability to maintain and utilize temporal dependencies.

</details>


### [68] [LLM-Generated Feedback Supports Learning If Learners Choose to Use It](https://arxiv.org/abs/2506.17006)
*Danielle R. Thomas,Conrad Borchers,Shambhavi Bhushan,Erin Gatz,Shivang Gupta,Kenneth R. Koedinger*

Main category: cs.CL

TL;DR: 研究探讨了LLM生成反馈对学习的影响，发现其效果取决于学习者寻求支持的倾向，且在部分课程中表现出显著学习收益。


<details>
  <summary>Details</summary>
Motivation: 探索LLM生成反馈对学习的影响，并与现有反馈方法进行比较。

Method: 通过分析885名学习者的2,600多次课程完成情况，比较了接受LLM反馈、拒绝LLM反馈和无LLM反馈三组的学习效果，并使用倾向评分调整选择偏差。

Result: 两门课程中LLM反馈显示出显著学习收益（效应量0.28和0.33），且学习者普遍认为反馈有帮助，未显著增加完成时间。

Conclusion: LLM反馈是一种低成本、可扩展的学习改进方法，尤其适用于已有反馈系统的开放任务。

Abstract: Large language models (LLMs) are increasingly used to generate feedback, yet
their impact on learning remains underexplored, especially compared to existing
feedback methods. This study investigates how on-demand LLM-generated
explanatory feedback influences learning in seven scenario-based tutor training
lessons. Analyzing over 2,600 lesson completions from 885 tutor learners, we
compare posttest performance among learners across three groups: learners who
received feedback generated by gpt-3.5-turbo, those who declined it, and those
without access. All groups received non-LLM corrective feedback. To address
potential selection bias-where higher-performing learners may be more inclined
to use LLM feedback-we applied propensity scoring. Learners with a higher
predicted likelihood of engaging with LLM feedback scored significantly higher
at posttest than those with lower propensity. After adjusting for this effect,
two out of seven lessons showed statistically significant learning benefits
from LLM feedback with standardized effect sizes of 0.28 and 0.33. These
moderate effects suggest that the effectiveness of LLM feedback depends on the
learners' tendency to seek support. Importantly, LLM feedback did not
significantly increase completion time, and learners overwhelmingly rated it as
helpful. These findings highlight LLM feedback's potential as a low-cost and
scalable way to improve learning on open-ended tasks, particularly in existing
systems already providing feedback without LLMs. This work contributes open
datasets, LLM prompts, and rubrics to support reproducibility.

</details>


### [69] [Instituto de Telecomunicações at IWSLT 2025: Aligning Small-Scale Speech and Language Models for Speech-to-Text Learning](https://arxiv.org/abs/2506.17019)
*Giuseppe Attanasio,Sonal Sannigrahi,Ben Peters,André F. T. Martins*

Main category: cs.CL

TL;DR: 本文介绍了IT-IST团队在IWSLT 2025共享任务中关于指令跟随语音处理的提交，专注于短赛道（语音识别、翻译和口语问答），采用统一语音到文本模型，结合预训练编码器和文本解码器，并通过模态对齐和指令微调两阶段训练。


<details>
  <summary>Details</summary>
Motivation: 解决指令跟随语音处理任务，同时限制使用小规模语言模型（<2B）和高质量数据。

Method: 采用统一语音到文本模型，分两阶段训练：模态对齐和指令微调，使用小规模语言模型和高质量CC-BY数据及合成数据。

Result: 提交了短赛道（语音识别、翻译和口语问答）的结果。

Conclusion: 通过两阶段训练和小规模语言模型，实现了指令跟随语音处理任务的高效解决方案。

Abstract: This paper presents the IT-IST submission to the IWSLT 2025 Shared Task on
Instruction Following Speech Processing. We submit results for the Short Track,
i.e., speech recognition, translation, and spoken question answering. Our model
is a unified speech-to-text model that integrates a pre-trained continuous
speech encoder and text decoder through a first phase of modality alignment and
a second phase of instruction fine-tuning. Crucially, we focus on using
small-scale language model backbones (< 2B) and restrict to high-quality, CC-BY
data along with synthetic data generation to supplement existing resources.

</details>


### [70] [MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models](https://arxiv.org/abs/2506.17046)
*Xiaolong Wang,Zhaolu Kang,Wangyuxuan Zhai,Xinyue Lou,Yunghwei Lai,Ziyue Wang,Yawen Wang,Kaiyu Huang,Yile Wang,Peng Li,Yang Liu*

Main category: cs.CL

TL;DR: MUCAR是一个新的多模态基准测试，专注于评估多语言和跨模态场景下的歧义解决能力，揭示了当前模型与人类性能的差距。


<details>
  <summary>Details</summary>
Motivation: 现有多模态基准测试通常忽略语言和视觉歧义，未能充分利用模态间的互补性，因此需要新的评估工具。

Method: 提出MUCAR基准，包括多语言数据集和双歧义数据集，通过视觉和文本的相互消歧构造清晰解释。

Result: 对19种先进多模态模型的评估显示，它们在歧义解决上远未达到人类水平。

Conclusion: 未来研究需开发更复杂的跨模态歧义理解方法，推动多模态推理的边界。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated significant
advances across numerous vision-language tasks. Due to their strong image-text
alignment capability, MLLMs can effectively understand image-text pairs with
clear meanings. However, effectively resolving the inherent ambiguities in
natural language and visual contexts remains challenging. Existing multimodal
benchmarks typically overlook linguistic and visual ambiguities, relying mainly
on unimodal context for disambiguation and thus failing to exploit the mutual
clarification potential between modalities. To bridge this gap, we introduce
MUCAR, a novel and challenging benchmark designed explicitly for evaluating
multimodal ambiguity resolution across multilingual and cross-modal scenarios.
MUCAR includes: (1) a multilingual dataset where ambiguous textual expressions
are uniquely resolved by corresponding visual contexts, and (2) a
dual-ambiguity dataset that systematically pairs ambiguous images with
ambiguous textual contexts, with each combination carefully constructed to
yield a single, clear interpretation through mutual disambiguation. Extensive
evaluations involving 19 state-of-the-art multimodal models--encompassing both
open-source and proprietary architectures--reveal substantial gaps compared to
human-level performance, highlighting the need for future research into more
sophisticated cross-modal ambiguity comprehension methods, further pushing the
boundaries of multimodal reasoning.

</details>


### [71] [Simultaneous Translation with Offline Speech and LLM Models in CUNI Submission to IWSLT 2025](https://arxiv.org/abs/2506.17077)
*Dominik Macháček,Peter Polák*

Main category: cs.CL

TL;DR: 本文介绍了查尔斯大学在IWSLT 2025同步语音翻译任务中的提交方案，覆盖四种语言对，采用直接或级联方法，基于Whisper模型，结合AlignAtt策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决同步语音翻译任务中的性能问题，提升翻译质量和延迟表现。

Method: 使用Whisper模型和AlignAtt策略，结合提示注入领域术语和上下文适应，级联系统采用EuroLLM进行无界同步翻译。

Result: 相比基线，捷克语到英语提升2 BLEU分，英语到德语、中文和日语提升13-22 BLEU分。

Conclusion: 提出的方法显著提升了同步翻译性能，并引入新的语音识别延迟度量标准。

Abstract: This paper describes Charles University submission to the Simultaneous Speech
Translation Task of the IWSLT 2025. We cover all four language pairs with a
direct or cascade approach. The backbone of our systems is the offline Whisper
speech model, which we use for both translation and transcription in
simultaneous mode with the state-of-the-art simultaneous policy AlignAtt. We
further improve the performance by prompting to inject in-domain terminology,
and we accommodate context. Our cascaded systems further use EuroLLM for
unbounded simultaneous translation. Compared to the Organizers' baseline, our
systems improve by 2 BLEU points on Czech to English and 13-22 BLEU points on
English to German, Chinese and Japanese on the development sets. Additionally,
we also propose a new enhanced measure of speech recognition latency.

</details>


### [72] [Tower+: Bridging Generality and Translation Specialization in Multilingual LLMs](https://arxiv.org/abs/2506.17080)
*Ricardo Rei,Nuno M. Guerreiro,José Pombal,João Alves,Pedro Teixeirinha,Amin Farajian,André F. T. Martins*

Main category: cs.CL

TL;DR: Tower+模型通过多阶段训练方法，在翻译和多语言通用任务上实现高性能，同时保持通用能力。


<details>
  <summary>Details</summary>
Motivation: 解决微调预训练LLMs时牺牲通用能力的问题，提升模型在翻译和多语言通用任务中的实用性。

Method: 采用持续预训练、监督微调、偏好优化和强化学习，结合精心生成的数据，训练不同规模的模型（2B、9B、72B）。

Result: 小模型优于大型通用LLMs，大模型在高资源语言翻译和多语言任务中表现最佳。

Conclusion: Tower+证明在优化特定领域（如翻译）的同时，仍能匹敌前沿模型的通用能力。

Abstract: Fine-tuning pretrained LLMs has been shown to be an effective strategy for
reaching state-of-the-art performance on specific tasks like machine
translation. However, this process of adaptation often implies sacrificing
general-purpose capabilities, such as conversational reasoning and
instruction-following, hampering the utility of the system in real-world
applications that require a mixture of skills. In this paper, we introduce
Tower+, a suite of models designed to deliver strong performance across both
translation and multilingual general-purpose text capabilities. We achieve a
Pareto frontier between translation specialization and multilingual
general-purpose capabilities by introducing a novel training recipe that builds
on Tower (Alves et al., 2024), comprising continued pretraining, supervised
fine-tuning, preference optimization, and reinforcement learning with
verifiable rewards. At each stage of training, we carefully generate and curate
data to strengthen performance on translation as well as general-purpose tasks
involving code generation, mathematics problem solving, and general
instruction-following. We develop models at multiple scales: 2B, 9B, and 72B.
Our smaller models often outperform larger general-purpose open-weight and
proprietary LLMs (e.g., Llama 3.3 70B, GPT-4o). Our largest model delivers
best-in-class translation performance for high-resource languages and top
results in multilingual Arena Hard evaluations and in IF-MT, a benchmark we
introduce for evaluating both translation and instruction-following. Our
findings highlight that it is possible to rival frontier models in general
capabilities, while optimizing for specific business domains, such as
translation and localization.

</details>


### [73] [Chain-of-Thought Prompting Obscures Hallucination Cues in Large Language Models: An Empirical Evaluation](https://arxiv.org/abs/2506.17088)
*Jiahao Cheng,Tiancheng Su,Jia Yuan,Guoxiu He,Jiawei Liu,Xinqi Tao,Jingwen Xie,Huaxia Li*

Main category: cs.CL

TL;DR: 研究发现，CoT提示可以减少LLM的幻觉频率，但会模糊检测信号，影响检测方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 探索CoT提示对LLM幻觉检测的影响，填补研究空白。

Method: 通过实验评估CoT提示对幻觉检测的影响，分析幻觉分数分布、检测准确性和置信度的变化。

Result: CoT提示减少幻觉频率，但削弱检测信号，降低检测方法的有效性。

Conclusion: 研究揭示了推理使用中的权衡问题，需进一步优化检测方法。

Abstract: Large Language Models (LLMs) often exhibit \textit{hallucinations},
generating factually incorrect or semantically irrelevant content in response
to prompts. Chain-of-Thought (CoT) prompting can mitigate hallucinations by
encouraging step-by-step reasoning, but its impact on hallucination detection
remains underexplored. To bridge this gap, we conduct a systematic empirical
evaluation. We begin with a pilot experiment, revealing that CoT reasoning
significantly affects the LLM's internal states and token probability
distributions. Building on this, we evaluate the impact of various CoT
prompting methods on mainstream hallucination detection methods across both
instruction-tuned and reasoning-oriented LLMs. Specifically, we examine three
key dimensions: changes in hallucination score distributions, variations in
detection accuracy, and shifts in detection confidence. Our findings show that
while CoT prompting helps reduce hallucination frequency, it also tends to
obscure critical signals used for detection, impairing the effectiveness of
various detection methods. Our study highlights an overlooked trade-off in the
use of reasoning. Code is publicly available at:
https://anonymous.4open.science/r/cot-hallu-detect.

</details>


### [74] [Better Language Model Inversion by Compactly Representing Next-Token Distributions](https://arxiv.org/abs/2506.17090)
*Murtaza Nazir,Matthew Finlayson,John X. Morris,Xiang Ren,Swabha Swayamdipta*

Main category: cs.CL

TL;DR: 论文提出了一种新方法PILS，通过语言模型的多步生成概率恢复隐藏提示，显著提升了恢复率，并展示了在跨模型和任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型反转能力对安全和问责的影响，如从API保护的语言模型中泄露私有信息。

Method: 提出PILS方法，利用语言模型的多步生成概率的低维子空间特性，通过线性映射无损压缩概率分布，从而恢复隐藏提示。

Result: PILS方法在恢复隐藏提示上比现有方法提升2-3.5倍，恢复率从17%提升至60%，并在跨任务和模型上表现优异。

Conclusion: 研究表明，语言模型的下一词概率是反转攻击的脆弱点，PILS方法在安全和问责领域具有重要应用价值。

Abstract: Language model inversion seeks to recover hidden prompts using only language
model outputs. This capability has implications for security and accountability
in language model deployments, such as leaking private information from an
API-protected language model's system message. We propose a new method --
prompt inversion from logprob sequences (PILS) -- that recovers hidden prompts
by gleaning clues from the model's next-token probabilities over the course of
multiple generation steps. Our method is enabled by a key insight: The
vector-valued outputs of a language model occupy a low-dimensional subspace.
This enables us to losslessly compress the full next-token probability
distribution over multiple generation steps using a linear map, allowing more
output information to be used for inversion. Our approach yields massive gains
over previous state-of-the-art methods for recovering hidden prompts, achieving
2--3.5 times higher exact recovery rates across test sets, in one case
increasing the recovery rate from 17% to 60%. Our method also exhibits
surprisingly good generalization behavior; for instance, an inverter trained on
16 generations steps gets 5--27 points higher prompt recovery when we increase
the number of steps to 32 at test time. Furthermore, we demonstrate strong
performance of our method on the more challenging task of recovering hidden
system messages. We also analyze the role of verbatim repetition in prompt
recovery and propose a new method for cross-family model transfer for
logit-based inverters. Our findings show that next-token probabilities are a
considerably more vulnerable attack surface for inversion attacks than
previously known.

</details>


### [75] [Cache Me If You Can: How Many KVs Do You Need for Effective Long-Context LMs?](https://arxiv.org/abs/2506.17121)
*Adithya Bhaskar,Alexander Wettig,Tianyu Gao,Yihe Dong,Danqi Chen*

Main category: cs.CL

TL;DR: 论文提出了一种统一的度量标准*KV footprint*，用于评估语言模型在处理长上下文时的内存效率，揭示了现有KV缓存方法的局限性，并提出改进方法以降低内存占用。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型处理长上下文任务的增加，KV缓存的内存成本显著上升，现有方法存在高内存峰值和性能下降的问题，缺乏统一的比较标准。

Method: 提出*KV footprint*作为统一度量标准，评估方法在保持性能的同时的最小内存占用；改进*post-fill eviction*方法以支持预填充阶段的KV丢弃；提出PruLong方法优化注意力头的KV缓存需求。

Result: 改进后的方法显著降低了KV footprint，PruLong在保持性能的同时比现有方法减少了12%的内存占用。

Conclusion: 论文通过统一度量标准和方法改进，为长上下文推理的内存优化提供了清晰方向。

Abstract: Language models handle increasingly long contexts for tasks such as book
summarization, but this leads to growing memory costs for the key-value (KV)
cache. Many prior works have proposed ways of discarding KVs from memory, but
their approaches are tailored to favorable settings, obscuring caveats like
high peak memory and performance degradation, and a fair comparison between
methods is difficult. In this paper, we propose the *KV footprint* as a unified
metric, which accounts for both the amount of KV entries stored and their
lifespan in memory. We evaluate methods based on the smallest footprint they
attain while preserving performance in both long-context understanding and
generation, with context lengths of up to 128K tokens. This metric reveals the
high peak memory of prior KV eviction methods. One class of methods --
*post-fill eviction* -- has a high footprint due to being incompatible with
eviction during pre-filling. We adapt these methods to be able to evict KVs
during pre-filling, achieving substantially lower KV footprints. We then turn
to *recency eviction* methods, wherein we propose PruLong, an end-to-end
optimization method for learning which attention heads need to retain the full
KV cache and which do not. PruLong saves memory while preserving long-context
performance, achieving 12% smaller KV footprint than prior methods while
retaining performance in challenging recall tasks. Our paper clarifies the
complex tangle of long-context inference methods and paves the way for future
development to minimize the KV footprint.

</details>


### [76] [CLEAR-3K: Assessing Causal Explanatory Capabilities in Language Models](https://arxiv.org/abs/2506.17180)
*Naiming Liu,Richard Baraniuk,Shashank Sonkar*

Main category: cs.CL

TL;DR: CLEAR-3K是一个包含3000个断言-推理问题的数据集，用于评估语言模型是否能判断一个陈述是否因果解释另一个陈述。研究发现，语言模型常混淆语义相似性与因果关系，且模型性能随参数增加而变化，但最高性能仅为0.55。


<details>
  <summary>Details</summary>
Motivation: 评估语言模型是否能区分语义相关性和真实的因果解释关系，以提升其在需要准确因果推理的应用中的能力。

Method: 通过CLEAR-3K数据集测试21种先进语言模型（参数范围0.5B至72B），分析其对因果关系的判断能力。

Result: 语言模型常混淆语义相似性与因果关系，且随着参数增加，模型从过度怀疑转向过度接受因果关系，但性能最高仅0.55。

Conclusion: CLEAR-3K为开发和评估语言模型的真实因果推理能力提供了关键基准。

Abstract: We introduce CLEAR-3K, a dataset of 3,000 assertion-reasoning questions
designed to evaluate whether language models can determine if one statement
causally explains another. Each question present an assertion-reason pair and
challenge language models to distinguish between semantic relatedness and
genuine causal explanatory relationships. Through comprehensive evaluation of
21 state-of-the-art language models (ranging from 0.5B to 72B parameters), we
identify two fundamental findings. First, language models frequently confuse
semantic similarity with causality, relying on lexical and semantic overlap
instead of inferring actual causal explanatory relationships. Second, as
parameter size increases, models tend to shift from being overly skeptical
about causal relationships to being excessively permissive in accepting them.
Despite this shift, performance measured by the Matthews Correlation
Coefficient plateaus at just 0.55, even for the best-performing models.Hence,
CLEAR-3K provides a crucial benchmark for developing and evaluating genuine
causal reasoning in language models, which is an essential capability for
applications that require accurate assessment of causal relationships.

</details>


### [77] [Towards AI Search Paradigm](https://arxiv.org/abs/2506.17188)
*Yuchen Li,Hengyi Cai,Rui Kong,Xinran Chen,Jiamin Chen,Jun Yang,Haojie Zhang,Jiayi Li,Jiayi Wu,Yiqun Chen,Changle Qu,Keyi Kong,Wenwen Ye,Lixin Su,Xinyu Ma,Long Xia,Daiting Shi,Jiashu Zhao,Haoyi Xiong,Shuaiqiang Wang,Dawei Yin*

Main category: cs.CL

TL;DR: 本文提出了一种名为AI Search Paradigm的下一代搜索系统蓝图，通过四个LLM驱动的代理（Master、Planner、Executor和Writer）动态适应各种信息需求，从简单查询到复杂推理任务。


<details>
  <summary>Details</summary>
Motivation: 旨在开发能够模拟人类信息处理和决策的下一代搜索系统，以满足从简单到复杂的信息需求。

Method: 采用模块化架构，四个代理通过协调工作流评估查询复杂性、分解问题、执行任务和合成内容，并整合任务规划、工具使用、检索增强生成和高效推理等方法。

Result: 提出了一套系统的方法论，包括算法技术和基础设施优化，支持可信、自适应和可扩展的AI搜索系统开发。

Conclusion: 本文为构建下一代AI搜索系统提供了全面的指导和基础组件，推动了可信、自适应和可扩展搜索技术的发展。

Abstract: In this paper, we introduce the AI Search Paradigm, a comprehensive blueprint
for next-generation search systems capable of emulating human information
processing and decision-making. The paradigm employs a modular architecture of
four LLM-powered agents (Master, Planner, Executor and Writer) that dynamically
adapt to the full spectrum of information needs, from simple factual queries to
complex multi-stage reasoning tasks. These agents collaborate dynamically
through coordinated workflows to evaluate query complexity, decompose problems
into executable plans, and orchestrate tool usage, task execution, and content
synthesis. We systematically present key methodologies for realizing this
paradigm, including task planning and tool integration, execution strategies,
aligned and robust retrieval-augmented generation, and efficient LLM inference,
spanning both algorithmic techniques and infrastructure-level optimizations. By
providing an in-depth guide to these foundational components, this work aims to
inform the development of trustworthy, adaptive, and scalable AI search
systems.

</details>


### [78] [Fine-Tuning Lowers Safety and Disrupts Evaluation Consistency](https://arxiv.org/abs/2506.17209)
*Kathleen C. Fraser,Hillary Dawkins,Isar Nejadgholi,Svetlana Kiritchenko*

Main category: cs.CL

TL;DR: 研究发现微调通用大语言模型（LLM）会削弱其安全对齐功能，即使微调数据无害。安全评估结果受实验设置微小变化影响显著，需改进报告方式。


<details>
  <summary>Details</summary>
Motivation: 微调LLM已成为常见操作，但会意外移除模型的安全对齐功能，即使数据无害。这一问题可能被恶意利用，亟需可靠的安全评估方法。

Method: 研究安全评估对实验设置微小变化和LLM随机性的鲁棒性，通过实验观察评估结果的方差。

Result: 实验显示安全评估结果对微调设置的微小变化敏感，结果差异显著。

Conclusion: 研究结果对安全评估报告方式提出新要求，需确保结果可复现和可比性。

Abstract: Fine-tuning a general-purpose large language model (LLM) for a specific
domain or task has become a routine procedure for ordinary users. However,
fine-tuning is known to remove the safety alignment features of the model, even
when the fine-tuning data does not contain any harmful content. We consider
this to be a critical failure mode of LLMs due to the widespread uptake of
fine-tuning, combined with the benign nature of the "attack". Most
well-intentioned developers are likely unaware that they are deploying an LLM
with reduced safety. On the other hand, this known vulnerability can be easily
exploited by malicious actors intending to bypass safety guardrails. To make
any meaningful progress in mitigating this issue, we first need reliable and
reproducible safety evaluations. In this work, we investigate how robust a
safety benchmark is to trivial variations in the experimental procedure, and
the stochastic nature of LLMs. Our initial experiments expose surprising
variance in the results of the safety evaluation, even when seemingly
inconsequential changes are made to the fine-tuning setup. Our observations
have serious implications for how researchers in this field should report
results to enable meaningful comparisons in the future.

</details>


### [79] [LaMP-Cap: Personalized Figure Caption Generation With Multimodal Figure Profiles](https://arxiv.org/abs/2506.06561)
*Ho Yin 'Sam' Ng,Ting-Yao Hsu,Aashish Anantha Ramakrishnan,Branislav Kveton,Nedim Lipka,Franck Dernoncourt,Dongwon Lee,Tong Yu,Sungchul Kim,Ryan A. Rossi,Ting-Hao 'Kenneth' Huang*

Main category: cs.CL

TL;DR: LaMP-Cap数据集支持多模态个性化图表标题生成，实验证明多模态信息（如图像）比纯文本更能提升标题质量。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成的图表标题缺乏个性化，且多模态场景下的个性化技术研究不足。

Method: 提出LaMP-Cap数据集，结合多模态信息（图像、标题和相关段落）作为个性化输入，测试四种LLM模型。

Result: 使用多模态信息生成的标题更接近作者原版，图像比文本段落更有效。

Conclusion: 多模态个性化方法优于纯文本，LaMP-Cap为相关研究提供了新工具。

Abstract: Figure captions are crucial for helping readers understand and remember a
figure's key message. Many models have been developed to generate these
captions, helping authors compose better quality captions more easily. Yet,
authors almost always need to revise generic AI-generated captions to match
their writing style and the domain's style, highlighting the need for
personalization. Despite language models' personalization (LaMP) advances,
these technologies often focus on text-only settings and rarely address
scenarios where both inputs and profiles are multimodal. This paper introduces
LaMP-Cap, a dataset for personalized figure caption generation with multimodal
figure profiles. For each target figure, LaMP-Cap provides not only the needed
inputs, such as figure images, but also up to three other figures from the same
document--each with its image, caption, and figure-mentioning paragraphs--as a
profile to characterize the context. Experiments with four LLMs show that using
profile information consistently helps generate captions closer to the original
author-written ones. Ablation studies reveal that images in the profile are
more helpful than figure-mentioning paragraphs, highlighting the advantage of
using multimodal profiles over text-only ones.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [80] [A Strong View-Free Baseline Approach for Single-View Image Guided Point Cloud Completion](https://arxiv.org/abs/2506.15747)
*Fangzhou Lin,Zilin Dai,Rigved Sanku,Songlin Hou,Kazunori D Yamada,Haichong K. Zhang,Ziming Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种基于注意力机制的多分支编码器-解码器网络，用于单视角图像引导的点云补全任务，仅使用部分点云输入，无需图像引导。实验表明该方法优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 探讨单视角图像引导在点云补全任务中的必要性，并提出一种无需图像引导的强基线方法。

Method: 采用基于注意力的多分支编码器-解码器网络，通过层次化自融合机制（交叉注意力和自注意力层）整合多流信息。

Result: 在ShapeNet-ViPC数据集上的实验表明，该方法优于现有单视角图像引导方法。

Conclusion: 研究为多模态学习在点云补全任务中的发展提供了新见解。

Abstract: The single-view image guided point cloud completion (SVIPC) task aims to
reconstruct a complete point cloud from a partial input with the help of a
single-view image. While previous works have demonstrated the effectiveness of
this multimodal approach, the fundamental necessity of image guidance remains
largely unexamined. To explore this, we propose a strong baseline approach for
SVIPC based on an attention-based multi-branch encoder-decoder network that
only takes partial point clouds as input, view-free. Our hierarchical
self-fusion mechanism, driven by cross-attention and self-attention layers,
effectively integrates information across multiple streams, enriching feature
representations and strengthening the networks ability to capture geometric
structures. Extensive experiments and ablation studies on the ShapeNet-ViPC
dataset demonstrate that our view-free framework performs superiorly to
state-of-the-art SVIPC methods. We hope our findings provide new insights into
the development of multimodal learning in SVIPC. Our demo code will be
available at https://github.com/Zhang-VISLab.

</details>


### [81] [VLMInferSlow: Evaluating the Efficiency Robustness of Large Vision-Language Models as a Service](https://arxiv.org/abs/2506.15755)
*Xiasi Wang,Tianliang Yao,Simin Chen,Runqi Wang,Lei YE,Kuofeng Gao,Yi Huang,Yuan Yao*

Main category: cs.CV

TL;DR: 本文提出了一种名为VLMInferSlow的新方法，用于在现实黑盒设置中评估视觉语言模型（VLM）的效率鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注VLM的准确性，而效率问题未得到充分探索。许多实时应用对效率要求高，但现有评估方法假设不切实际，需要访问模型架构和参数，这在ML-as-a-service场景中不可行。

Method: VLMInferSlow结合了针对VLM推理的细粒度效率建模，并利用零阶优化搜索对抗样本。

Result: 实验表明，VLMInferSlow生成的对抗图像具有难以察觉的扰动，可将计算成本提高至128.47%。

Conclusion: 本研究旨在提高社区对VLM效率鲁棒性的关注。

Abstract: Vision-Language Models (VLMs) have demonstrated great potential in real-world
applications. While existing research primarily focuses on improving their
accuracy, the efficiency remains underexplored. Given the real-time demands of
many applications and the high inference overhead of VLMs, efficiency
robustness is a critical issue. However, previous studies evaluate efficiency
robustness under unrealistic assumptions, requiring access to the model
architecture and parameters -- an impractical scenario in ML-as-a-service
settings, where VLMs are deployed via inference APIs. To address this gap, we
propose VLMInferSlow, a novel approach for evaluating VLM efficiency robustness
in a realistic black-box setting. VLMInferSlow incorporates fine-grained
efficiency modeling tailored to VLM inference and leverages zero-order
optimization to search for adversarial examples. Experimental results show that
VLMInferSlow generates adversarial images with imperceptible perturbations,
increasing the computational cost by up to 128.47%. We hope this research
raises the community's awareness about the efficiency robustness of VLMs.

</details>


### [82] [Weakly-supervised VLM-guided Partial Contrastive Learning for Visual Language Navigation](https://arxiv.org/abs/2506.15757)
*Ruoyu Wang,Tong Yu,Junda Wu,Yao Liu,Julian McAuley,Lina Yao*

Main category: cs.CV

TL;DR: 论文提出了一种弱监督部分对比学习（WPCL）方法，用于提升视觉语言导航（VLN）任务中代理的动态视角对象识别能力，无需微调预训练视觉语言模型（VLM），同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有VLN方法依赖预训练骨干模型，但动态视角下表现不佳；预训练LLMs或VLMs未微调时性能有限；微调虽能提升效果但计算成本高。

Method: 提出WPCL方法，通过弱监督部分对比学习，将预训练VLM知识有效整合到感知过程中，无需微调VLM。

Result: 实验表明，WPCL在多个基准测试中优于基线方法，验证了其有效性、鲁棒性和泛化性。

Conclusion: WPCL方法解决了VLN中的动态视角和计算效率问题，为未来研究提供了新方向。

Abstract: Visual Language Navigation (VLN) is a fundamental task within the field of
Embodied AI, focusing on the ability of agents to navigate complex environments
based on natural language instructions. Despite the progress made by existing
methods, these methods often present some common challenges. First, they rely
on pre-trained backbone models for visual perception, which struggle with the
dynamic viewpoints in VLN scenarios. Second, the performance is limited when
using pre-trained LLMs or VLMs without fine-tuning, due to the absence of VLN
domain knowledge. Third, while fine-tuning LLMs and VLMs can improve results,
their computational costs are higher than those without fine-tuning. To address
these limitations, we propose Weakly-supervised Partial Contrastive Learning
(WPCL), a method that enhances an agent's ability to identify objects from
dynamic viewpoints in VLN scenarios by effectively integrating pre-trained VLM
knowledge into the perception process, without requiring VLM fine-tuning. Our
method enhances the agent's ability to interpret and respond to environmental
cues while ensuring computational efficiency. Experimental results have shown
that our method outperforms the baseline methods on multiple benchmarks, which
validate the effectiveness, robustness and generalizability of our method.

</details>


### [83] [Implicit 3D scene reconstruction using deep learning towards efficient collision understanding in autonomous driving](https://arxiv.org/abs/2506.15806)
*Akarshani Ramanayake,Nihal Kodikara*

Main category: cs.CV

TL;DR: 论文提出了一种基于学习的方法，利用LiDAR数据和深度神经网络构建静态符号距离函数（SDF）地图，以解决密集交通环境中3D场景重建的边界精度问题。


<details>
  <summary>Details</summary>
Motivation: 在密集城市交通环境中，现有技术难以精确导航，而3D场景重建的边界精度问题尚未完全解决。符号距离函数（SDF）因其高效存储特性成为潜在解决方案。

Method: 结合LiDAR数据和深度神经网络，开发了一种学习型的3D场景重建方法，生成静态SDF地图，以替代传统的多边形表示。

Result: 初步结果表明，该方法能显著提升碰撞检测性能，尤其在拥挤和动态环境中。

Conclusion: 该研究填补了现有文献中的空白，展示了SDF在3D障碍物形状重建中的潜力，尤其在边界细节方面表现优异。

Abstract: In crowded urban environments where traffic is dense, current technologies
struggle to oversee tight navigation, but surface-level understanding allows
autonomous vehicles to safely assess proximity to surrounding obstacles. 3D or
2D scene mapping of the surrounding objects is an essential task in addressing
the above problem. Despite its importance in dense vehicle traffic conditions,
3D scene reconstruction of object shapes with higher boundary level accuracy is
not yet entirely considered in current literature. The sign distance function
represents any shape through parameters that calculate the distance from any
point in space to the closest obstacle surface, making it more efficient in
terms of storage. In recent studies, researchers have started to formulate
problems with Implicit 3D reconstruction methods in the autonomous driving
domain, highlighting the possibility of using sign distance function to map
obstacles effectively. This research addresses this gap by developing a
learning-based 3D scene reconstruction methodology that leverages LiDAR data
and a deep neural network to build a the static Signed Distance Function (SDF)
maps. Unlike traditional polygonal representations, this approach has the
potential to map 3D obstacle shapes with more boundary-level details. Our
preliminary results demonstrate that this method would significantly enhance
collision detection performance, particularly in congested and dynamic
environments.

</details>


### [84] [ADAM-Dehaze: Adaptive Density-Aware Multi-Stage Dehazing for Improved Object Detection in Foggy Conditions](https://arxiv.org/abs/2506.15837)
*Fatmah AlHindaassi,Mohammed Talha Alam,Fakhri Karray*

Main category: cs.CV

TL;DR: ADAM-Dehaze是一种自适应、密度感知的去雾框架，通过动态路由和自适应损失优化图像恢复和目标检测，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 雾天严重影响自动驾驶和监控系统的视觉信息，需要一种能够适应不同雾密度的去雾方法。

Method: 使用HDEN网络分类雾密度，动态路由到三个CORUN分支，结合自适应损失平衡物理模型和感知保真度。

Result: 在Cityscapes和RTTS基准上，PSNR提升2.1 dB，FADE降低30%，目标检测mAP提升13点，推理时间减少20%。

Conclusion: ADAM-Dehaze证明了密度特定处理和与下游视觉任务无缝集成的重要性。

Abstract: Adverse weather conditions, particularly fog, pose a significant challenge to
autonomous vehicles, surveillance systems, and other safety-critical
applications by severely degrading visual information. We introduce
ADAM-Dehaze, an adaptive, density-aware dehazing framework that jointly
optimizes image restoration and object detection under varying fog intensities.
A lightweight Haze Density Estimation Network (HDEN) classifies each input as
light, medium, or heavy fog. Based on this score, the system dynamically routes
the image through one of three CORUN branches: Light, Medium, or Complex, each
tailored to its haze regime. A novel adaptive loss balances physical-model
coherence and perceptual fidelity, ensuring both accurate defogging and
preservation of fine details. On Cityscapes and the real-world RTTS benchmark,
ADAM-Dehaze improves PSNR by up to 2.1 dB, reduces FADE by 30 percent, and
increases object detection mAP by up to 13 points, while cutting inference time
by 20 percent. These results highlight the importance of intensity-specific
processing and seamless integration with downstream vision tasks. Code
available at: https://github.com/talha-alam/ADAM-Dehaze.

</details>


### [85] [EchoShot: Multi-Shot Portrait Video Generation](https://arxiv.org/abs/2506.15838)
*Jiahao Wang,Hualian Sheng,Sijia Cai,Weizhan Zhang,Caixia Yan,Yachuang Feng,Bing Deng,Jieping Ye*

Main category: cs.CV

TL;DR: EchoShot是一个基于视频扩散模型的多镜头肖像定制框架，通过创新的位置嵌入机制和高质量数据集PortraitGala，实现了身份一致性和内容可控性。


<details>
  <summary>Details</summary>
Motivation: 现实应用需要多镜头生成且保持身份一致性和内容可控性，而现有方法局限于单镜头生成。

Method: 提出shot-aware位置嵌入机制，在视频扩散变换器架构中建模镜头间变化；构建PortraitGala数据集支持训练；扩展支持参考图像生成和长视频合成。

Result: EchoShot在多镜头肖像视频生成中表现出优越的身份一致性和属性级可控性。

Conclusion: EchoShot是通用多镜头视频建模的基础范式，具有广泛应用潜力。

Abstract: Video diffusion models substantially boost the productivity of artistic
workflows with high-quality portrait video generative capacity. However,
prevailing pipelines are primarily constrained to single-shot creation, while
real-world applications urge for multiple shots with identity consistency and
flexible content controllability. In this work, we propose EchoShot, a native
and scalable multi-shot framework for portrait customization built upon a
foundation video diffusion model. To start with, we propose shot-aware position
embedding mechanisms within video diffusion transformer architecture to model
inter-shot variations and establish intricate correspondence between multi-shot
visual content and their textual descriptions. This simple yet effective design
enables direct training on multi-shot video data without introducing additional
computational overhead. To facilitate model training within multi-shot
scenario, we construct PortraitGala, a large-scale and high-fidelity
human-centric video dataset featuring cross-shot identity consistency and
fine-grained captions such as facial attributes, outfits, and dynamic motions.
To further enhance applicability, we extend EchoShot to perform reference
image-based personalized multi-shot generation and long video synthesis with
infinite shot counts. Extensive evaluations demonstrate that EchoShot achieves
superior identity consistency as well as attribute-level controllability in
multi-shot portrait video generation. Notably, the proposed framework
demonstrates potential as a foundational paradigm for general multi-shot video
modeling.

</details>


### [86] [Assessing the impact of Binarization for Writer Identification in Greek Papyrus](https://arxiv.org/abs/2506.15852)
*Dominic Akt,Marco Peer,Florian Kleber*

Main category: cs.CV

TL;DR: 该论文研究了希腊纸草文献的作者识别任务，重点探讨了图像二值化预处理对识别性能的影响，并比较了传统方法与深度学习方法的效果。


<details>
  <summary>Details</summary>
Motivation: 希腊纸草文献的背景通常不均匀、碎片化且变色，传统二值化方法难以处理，因此需要探索深度学习方法及其数据增强技术对二值化质量的影响。

Method: 比较了传统二值化方法与深度学习方法，并评估了数据增强技术和不同模型选择标准对二值化效果的影响。随后使用DIBCO 2019数据集和先进的作者识别方法评估二值化对识别性能的影响。

Result: 研究发现数据增强对深度学习方法有显著影响，且二值化效果与作者识别性能之间存在强相关性。

Conclusion: 论文强调了数据增强在二值化中的重要性，并表明二值化质量对希腊纸草文献的作者识别任务至关重要。

Abstract: This paper tackles the task of writer identification for Greek papyri. A
common preprocessing step in writer identification pipelines is image
binarization, which prevents the model from learning background features. This
is challenging in historical documents, in our case Greek papyri, as background
is often non-uniform, fragmented, and discolored with visible fiber structures.
We compare traditional binarization methods to state-of-the-art Deep Learning
(DL) models, evaluating the impact of binarization quality on subsequent writer
identification performance. DL models are trained with and without a custom
data augmentation technique, as well as different model selection criteria are
applied. The performance of these binarization methods, is then systematically
evaluated on the DIBCO 2019 dataset. The impact of binarization on writer
identification is subsequently evaluated using a state-of-the-art approach for
writer identification. The results of this analysis highlight the influence of
data augmentation for DL methods. Furthermore, findings indicate a strong
correlation between binarization effectiveness on papyri documents of DIBCO
2019 and downstream writer identification performance.

</details>


### [87] [Privacy-Preserving in Connected and Autonomous Vehicles Through Vision to Text Transformation](https://arxiv.org/abs/2506.15854)
*Abdolazim Rezaei,Mehdi Sookhak,Ahmad Patooghy*

Main category: cs.CV

TL;DR: 论文提出了一种基于反馈强化学习和视觉语言模型的新框架，用于保护AI摄像头捕获的隐私敏感数据，将图像转换为语义等效的文本描述。


<details>
  <summary>Details</summary>
Motivation: 传统隐私保护技术（如面部模糊）仍存在隐私泄露风险，无法完全防止个体追踪。

Method: 采用反馈强化学习和视觉语言模型，将图像转换为语义文本，并通过分层强化学习迭代优化文本生成。

Result: 相比现有方法，隐私保护和文本质量显著提升，独特词数增加约77%，细节密度提高约50%。

Conclusion: 该框架在保留场景信息的同时有效保护隐私，为CAV中的隐私问题提供了创新解决方案。

Abstract: Connected and Autonomous Vehicles (CAVs) rely on a range of devices that
often process privacy-sensitive data. Among these, roadside units play a
critical role particularly through the use of AI-equipped (AIE) cameras for
applications such as violation detection. However, the privacy risks associated
with captured imagery remain a major concern, as such data can be misused for
identity theft, profiling, or unauthorized commercial purposes. While
traditional techniques such as face blurring and obfuscation have been applied
to mitigate privacy risks, individual privacy remains at risk, as individuals
can still be tracked using other features such as their clothing. This paper
introduces a novel privacy-preserving framework that leverages feedback-based
reinforcement learning (RL) and vision-language models (VLMs) to protect
sensitive visual information captured by AIE cameras. The main idea is to
convert images into semantically equivalent textual descriptions, ensuring that
scene-relevant information is retained while visual privacy is preserved. A
hierarchical RL strategy is employed to iteratively refine the generated text,
enhancing both semantic accuracy and privacy. Evaluation results demonstrate
significant improvements in both privacy protection and textual quality, with
the Unique Word Count increasing by approximately 77\% and Detail Density by
around 50\% compared to existing approaches.

</details>


### [88] [Visual symbolic mechanisms: Emergent symbol processing in vision language models](https://arxiv.org/abs/2506.15871)
*Rim Assouel,Declan Campbell,Taylor Webb*

Main category: cs.CV

TL;DR: 研究发现视觉语言模型（VLMs）通过内容无关的空间索引机制解决特征绑定问题，并揭示了绑定错误的根源。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型（VLMs）是否采用类似语言模型的符号化机制解决特征绑定问题，以解释其在绑定任务中的持续失败。

Method: 识别VLMs中支持绑定的内容无关空间索引机制，并分析绑定错误与这些机制的关系。

Result: 发现VLMs通过符号化机制实现特征绑定，绑定错误源于这些机制的失效。

Conclusion: 研究揭示了VLMs中符号化处理的机制，为解决其绑定失败问题提供了潜在方向。

Abstract: To accurately process a visual scene, observers must bind features together
to represent individual objects. This capacity is necessary, for instance, to
distinguish an image containing a red square and a blue circle from an image
containing a blue square and a red circle. Recent work has found that language
models solve this 'binding problem' via a set of symbol-like,
content-independent indices, but it is unclear whether similar mechanisms are
employed by vision language models (VLMs). This question is especially
relevant, given the persistent failures of VLMs on tasks that require binding.
Here, we identify a set of emergent symbolic mechanisms that support binding in
VLMs via a content-independent, spatial indexing scheme. Moreover, we find that
binding errors can be traced directly to failures in these mechanisms. Taken
together, these results shed light on the mechanisms that support symbol-like
processing in VLMs, and suggest possible avenues for addressing the persistent
binding failures exhibited by these models.

</details>


### [89] [Pediatric Pancreas Segmentation from MRI Scans with Deep Learning](https://arxiv.org/abs/2506.15908)
*Elif Keles,Merve Yazol,Gorkem Durak,Ziliang Hong,Halil Ertugrul Aktas,Zheyuan Zhang,Linkai Peng,Onkar Susladkar,Necati Guzelyel,Oznur Leman Boyunaga,Cemal Yazici,Mark Lowe,Aliye Uc,Ulas Bagci*

Main category: cs.CV

TL;DR: PanSegNet是一种用于儿童胰腺MRI分割的深度学习算法，在健康儿童和胰腺炎患者中表现出专家级性能。


<details>
  <summary>Details</summary>
Motivation: 评估和验证PanSegNet在儿童急性胰腺炎、慢性胰腺炎及健康对照中的胰腺MRI分割效果。

Method: 回顾性收集84例MRI扫描，由放射科医生手动分割胰腺，PanSegNet生成的分割结果通过DSC和HD95评估，并计算观察者一致性。

Result: PanSegNet在健康儿童中DSC为88%，胰腺炎患者中为80-81%，观察者一致性高（kappa 0.81-0.88）。

Conclusion: PanSegNet是首个经过验证的胰腺MRI分割深度学习工具，性能可靠，数据集和算法已开源，推动无辐射儿科胰腺影像研究。

Abstract: Objective: Our study aimed to evaluate and validate PanSegNet, a deep
learning (DL) algorithm for pediatric pancreas segmentation on MRI in children
with acute pancreatitis (AP), chronic pancreatitis (CP), and healthy controls.
Methods: With IRB approval, we retrospectively collected 84 MRI scans (1.5T/3T
Siemens Aera/Verio) from children aged 2-19 years at Gazi University
(2015-2024). The dataset includes healthy children as well as patients
diagnosed with AP or CP based on clinical criteria. Pediatric and general
radiologists manually segmented the pancreas, then confirmed by a senior
pediatric radiologist. PanSegNet-generated segmentations were assessed using
Dice Similarity Coefficient (DSC) and 95th percentile Hausdorff distance
(HD95). Cohen's kappa measured observer agreement. Results: Pancreas MRI T2W
scans were obtained from 42 children with AP/CP (mean age: 11.73 +/- 3.9 years)
and 42 healthy children (mean age: 11.19 +/- 4.88 years). PanSegNet achieved
DSC scores of 88% (controls), 81% (AP), and 80% (CP), with HD95 values of 3.98
mm (controls), 9.85 mm (AP), and 15.67 mm (CP). Inter-observer kappa was 0.86
(controls), 0.82 (pancreatitis), and intra-observer agreement reached 0.88 and
0.81. Strong agreement was observed between automated and manual volumes (R^2 =
0.85 in controls, 0.77 in diseased), demonstrating clinical reliability.
Conclusion: PanSegNet represents the first validated deep learning solution for
pancreatic MRI segmentation, achieving expert-level performance across healthy
and diseased states. This tool, algorithm, along with our annotated dataset,
are freely available on GitHub and OSF, advancing accessible, radiation-free
pediatric pancreatic imaging and fostering collaborative research in this
underserved domain.

</details>


### [90] [MoiréXNet: Adaptive Multi-Scale Demoiréing with Linear Attention Test-Time Training and Truncated Flow Matching Prior](https://arxiv.org/abs/2506.15929)
*Liangyan Li,Yimo Ning,Kevin Le,Wei Dong,Yunzhe Li,Jun Chen,Xiaohong Liu*

Main category: cs.CV

TL;DR: 本文提出了一种结合MAP估计与深度学习的图像和视频去摩尔纹框架，解决了非线性退化问题，并通过混合方法提升了恢复效果。


<details>
  <summary>Details</summary>
Motivation: 传统监督学习方法在去摩尔纹任务中表现不佳，要么无法完全去除摩尔纹，要么导致结果过于平滑。生成模型虽在线性退化中表现良好，但在非线性任务中易引入伪影。

Method: 提出了一种混合MAP框架，包含两部分：1）增强的监督学习模型，利用线性注意力模块学习非线性映射；2）截断流匹配先验（TFMP），通过对齐干净图像分布优化输出。

Result: 该方法结合了线性注意力的计算效率和生成模型的优化能力，显著提升了图像恢复性能。

Conclusion: 该框架有效解决了非线性退化问题，为图像和视频去摩尔纹提供了一种高效且高质量的解决方案。

Abstract: This paper introduces a novel framework for image and video demoir\'eing by
integrating Maximum A Posteriori (MAP) estimation with advanced deep learning
techniques. Demoir\'eing addresses inherently nonlinear degradation processes,
which pose significant challenges for existing methods.
  Traditional supervised learning approaches either fail to remove moir\'e
patterns completely or produce overly smooth results. This stems from
constrained model capacity and scarce training data, which inadequately
represent the clean image distribution and hinder accurate reconstruction of
ground-truth images. While generative models excel in image restoration for
linear degradations, they struggle with nonlinear cases such as demoir\'eing
and often introduce artifacts.
  To address these limitations, we propose a hybrid MAP-based framework that
integrates two complementary components. The first is a supervised learning
model enhanced with efficient linear attention Test-Time Training (TTT)
modules, which directly learn nonlinear mappings for RAW-to-sRGB demoir\'eing.
The second is a Truncated Flow Matching Prior (TFMP) that further refines the
outputs by aligning them with the clean image distribution, effectively
restoring high-frequency details and suppressing artifacts. These two
components combine the computational efficiency of linear attention with the
refinement abilities of generative models, resulting in improved restoration
performance.

</details>


### [91] [Beyond Audio and Pose: A General-Purpose Framework for Video Synchronization](https://arxiv.org/abs/2506.15937)
*Yosub Shin,Igor Molybog*

Main category: cs.CV

TL;DR: VideoSync是一个独立于特定特征提取方法的视频同步框架，适用于多种内容类型，并通过新数据集和严格评估框架展示了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频同步方法依赖音频或特定视觉事件，适用性受限；现有基准缺乏通用性和可重复性。

Method: 提出VideoSync框架，不依赖特定特征提取方法，使用CNN模型预测同步偏移。

Result: VideoSync在公平实验条件下优于现有方法，包括SeSyn-Net，并纠正了其预处理偏差。

Conclusion: VideoSync提升了视频同步的通用性和鲁棒性，适用于更广泛的现实应用。

Abstract: Video synchronization-aligning multiple video streams capturing the same
event from different angles-is crucial for applications such as reality TV show
production, sports analysis, surveillance, and autonomous systems. Prior work
has heavily relied on audio cues or specific visual events, limiting
applicability in diverse settings where such signals may be unreliable or
absent. Additionally, existing benchmarks for video synchronization lack
generality and reproducibility, restricting progress in the field. In this
work, we introduce VideoSync, a video synchronization framework that operates
independently of specific feature extraction methods, such as human pose
estimation, enabling broader applicability across different content types. We
evaluate our system on newly composed datasets covering single-human,
multi-human, and non-human scenarios, providing both the methodology and code
for dataset creation to establish reproducible benchmarks. Our analysis reveals
biases in prior SOTA work, particularly in SeSyn-Net's preprocessing pipeline,
leading to inflated performance claims. We correct these biases and propose a
more rigorous evaluation framework, demonstrating that VideoSync outperforms
existing approaches, including SeSyn-Net, under fair experimental conditions.
Additionally, we explore various synchronization offset prediction methods,
identifying a convolutional neural network (CNN)-based model as the most
effective. Our findings advance video synchronization beyond domain-specific
constraints, making it more generalizable and robust for real-world
applications.

</details>


### [92] [Polyline Path Masked Attention for Vision Transformer](https://arxiv.org/abs/2506.15940)
*Zhongchen Zhao,Chaodong Xiao,Hui Lin,Qi Xie,Lei Zhang,Deyu Meng*

Main category: cs.CV

TL;DR: 本文提出了一种名为PPMA的方法，结合了ViTs的自注意力机制和Mamba2的结构化掩码，通过改进的2D折线路径扫描策略增强空间邻接建模，并在多项任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习框架中，全局依赖建模和空间位置建模是核心问题。ViTs和Mamba2分别在计算机视觉和自然语言处理中表现出色，但各有局限性。本文旨在结合两者的优势。

Method: 改进Mamba2的结构化掩码，提出2D折线路径扫描策略，生成折线路径掩码，并将其嵌入ViTs的自注意力机制中，以显式建模空间邻接关系。

Result: 在图像分类、目标检测和分割等任务中，PPMA模型表现优于现有方法。例如，在ADE20K语义分割任务中，PPMA-T/S/B模型的mIoU分别达到48.7%/51.1%/52.3%。

Conclusion: PPMA成功结合了ViTs和Mamba2的优势，通过改进的折线路径掩码显式建模空间邻接关系，在多项任务中取得了显著提升。

Abstract: Global dependency modeling and spatial position modeling are two core issues
of the foundational architecture design in current deep learning frameworks.
Recently, Vision Transformers (ViTs) have achieved remarkable success in
computer vision, leveraging the powerful global dependency modeling capability
of the self-attention mechanism. Furthermore, Mamba2 has demonstrated its
significant potential in natural language processing tasks by explicitly
modeling the spatial adjacency prior through the structured mask. In this
paper, we propose Polyline Path Masked Attention (PPMA) that integrates the
self-attention mechanism of ViTs with an enhanced structured mask of Mamba2,
harnessing the complementary strengths of both architectures. Specifically, we
first ameliorate the traditional structured mask of Mamba2 by introducing a 2D
polyline path scanning strategy and derive its corresponding structured mask,
polyline path mask, which better preserves the adjacency relationships among
image tokens. Notably, we conduct a thorough theoretical analysis on the
structural characteristics of the proposed polyline path mask and design an
efficient algorithm for the computation of the polyline path mask. Next, we
embed the polyline path mask into the self-attention mechanism of ViTs,
enabling explicit modeling of spatial adjacency prior. Extensive experiments on
standard benchmarks, including image classification, object detection, and
segmentation, demonstrate that our model outperforms previous state-of-the-art
approaches based on both state-space models and Transformers. For example, our
proposed PPMA-T/S/B models achieve 48.7%/51.1%/52.3% mIoU on the ADE20K
semantic segmentation task, surpassing RMT-T/S/B by 0.7%/1.3%/0.3%,
respectively. Code is available at https://github.com/zhongchenzhao/PPMA.

</details>


### [93] [Heterogeneous-Modal Unsupervised Domain Adaptation via Latent Space Bridging](https://arxiv.org/abs/2506.15971)
*Jiawen Yang,Shuhao Chen,Yucong Duan,Ke Tang,Yu Zhang*

Main category: cs.CV

TL;DR: 提出了一种新的异构模态无监督域适应（HMUDA）方法，通过桥接域实现不同模态间的知识迁移，并设计了Latent Space Bridging（LSB）框架，在语义分割任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决源域和目标域属于完全不同模态时，传统无监督域适应方法效果不佳的问题。

Method: 提出HMUDA设置，利用桥接域；设计LSB框架，采用双分支架构，结合特征一致性损失和域对齐损失。

Result: 在六个基准数据集上验证，LSB达到最先进性能。

Conclusion: HMUDA和LSB为不同模态间的无监督域适应提供了有效解决方案。

Abstract: Unsupervised domain adaptation (UDA) methods effectively bridge domain gaps
but become struggled when the source and target domains belong to entirely
distinct modalities. To address this limitation, we propose a novel setting
called Heterogeneous-Modal Unsupervised Domain Adaptation (HMUDA), which
enables knowledge transfer between completely different modalities by
leveraging a bridge domain containing unlabeled samples from both modalities.
To learn under the HMUDA setting, we propose Latent Space Bridging (LSB), a
specialized framework designed for the semantic segmentation task.
Specifically, LSB utilizes a dual-branch architecture, incorporating a feature
consistency loss to align representations across modalities and a domain
alignment loss to reduce discrepancies between class centroids across domains.
Extensive experiments conducted on six benchmark datasets demonstrate that LSB
achieves state-of-the-art performance.

</details>


### [94] [LBMamba: Locally Bi-directional Mamba](https://arxiv.org/abs/2506.15976)
*Jingwei Zhang,Xi Han,Hong Qin,Mahdi S. Hosseini,Dimitris Samaras*

Main category: cs.CV

TL;DR: LBMamba是一种局部双向状态空间模型，通过嵌入轻量级局部反向扫描来消除额外计算负担，LBVim是其扩展版本，在多个视觉任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: Mamba的单向性限制了其全局感知能力，传统双向扫描方法增加了计算负担，因此需要一种高效的双向扫描方案。

Method: 提出LBMamba，在正向选择性扫描中嵌入局部反向扫描，并构建LBVim作为视觉骨干网络，交替扫描方向以恢复全局感知。

Result: LBVim在ImageNet-1K、ADE20K和COCO等数据集上表现优于基线，病理图像分类任务中也有显著提升。

Conclusion: LBMamba和LBVim在保持高效的同时提升了性能，为视觉任务提供了一种新的解决方案。

Abstract: Mamba, a State Space Model (SSM) that accelerates training by recasting
recurrence as a parallel selective scan, has recently emerged as a
linearly-scaling, efficient alternative to self-attention. Because of its
unidirectional nature, each state in Mamba only has information of its previous
states and is blind to states after. Current Mamba-based computer-vision
methods typically overcome this limitation by augmenting Mamba's global forward
scan with a global backward scan, forming a bi-directional scan that restores a
full receptive field. However, this operation doubles the computational load,
eroding much of the efficiency advantage that originally Mamba have. To
eliminate this extra scans, we introduce LBMamba, a locally bi-directional SSM
block that embeds a lightweight locally backward scan inside the forward
selective scan and executes it entirely in per-thread registers. Building on
LBMamba, we present LBVim, a scalable vision backbone that alternates scan
directions every two layers to recover a global receptive field without extra
backward sweeps. We validate the versatility of our approach on both natural
images and whole slide images (WSIs). We show that our LBVim constantly offers
a superior performance-throughput trade-off. That is under the same throughput,
LBVim achieves 0.8% to 1.6% higher top-1 accuracy on the ImageNet-1K
classification dataset, 0.6% to 2.7% higher mIoU on the ADE20K semantic
segmentation dataset, 0.9% higher APb and 1.1% higher APm on the COCO detection
dataset. We also integrate LBMamba into the SOTA pathology multiple instance
learning (MIL) approach, MambaMIL, which uses single directional scan.
Experiments on 3 public WSI classification datasets for show that our method
achieves a relative improvement of up to 3.06% better AUC, 3.39% better F1,
1.67% better accuracy.

</details>


### [95] [Towards Classifying Histopathological Microscope Images as Time Series Data](https://arxiv.org/abs/2506.15977)
*Sungrae Hong,Hyeongmin Park,Youngsin Ko,Sol Lee,Bryan Wong,Mun Yong Yi*

Main category: cs.CV

TL;DR: 本文提出了一种将显微镜图像作为时间序列数据分类的新方法，解决了手动采集和弱标签带来的挑战，通过动态时间规整和注意力池化提升性能。


<details>
  <summary>Details</summary>
Motivation: 显微镜病理图像是癌症诊断的前线数据，但深度学习社区对其关注不足。本文旨在填补这一空白，提升其分类性能。

Method: 利用动态时间规整（DTW）处理变长图像序列，结合注意力池化预测类别。

Result: 实验表明，该方法优于多种基线，并通过消融研究验证了各组件的作用。

Conclusion: 该方法不仅将显微镜图像纳入深度学习分析，还将其性能提升至可靠水平。

Abstract: As the frontline data for cancer diagnosis, microscopic pathology images are
fundamental for providing patients with rapid and accurate treatment. However,
despite their practical value, the deep learning community has largely
overlooked their usage. This paper proposes a novel approach to classifying
microscopy images as time series data, addressing the unique challenges posed
by their manual acquisition and weakly labeled nature. The proposed method fits
image sequences of varying lengths to a fixed-length target by leveraging
Dynamic Time-series Warping (DTW). Attention-based pooling is employed to
predict the class of the case simultaneously. We demonstrate the effectiveness
of our approach by comparing performance with various baselines and showcasing
the benefits of using various inference strategies in achieving stable and
reliable results. Ablation studies further validate the contribution of each
component. Our approach contributes to medical image analysis by not only
embracing microscopic images but also lifting them to a trustworthy level of
performance.

</details>


### [96] [Advanced Sign Language Video Generation with Compressed and Quantized Multi-Condition Tokenization](https://arxiv.org/abs/2506.15980)
*Cong Wang,Zexuan Deng,Zhiwei Jiang,Fei Shen,Yafeng Yin,Shiwei Gan,Zifeng Cheng,Shiping Ge,Qing Gu*

Main category: cs.CV

TL;DR: SignViP是一种新的手语视频生成框架，通过多粒度条件提升生成质量，采用离散化表示和扩散模型实现高效生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖单一粗糙条件（如骨架序列），限制了生成视频的自然性和表现力。

Method: SignViP包含三个核心组件：1）联合训练的视频扩散模型和多条件编码器；2）FSQ自动编码器压缩嵌入为离散标记；3）多条件标记翻译器将文本转换为离散标记。

Result: 实验表明SignViP在视频质量、时间一致性和语义保真度上达到最优性能。

Conclusion: SignViP通过多粒度条件和离散化表示显著提升了手语视频生成的质量和表现力。

Abstract: Sign Language Video Generation (SLVG) seeks to generate identity-preserving
sign language videos from spoken language texts. Existing methods primarily
rely on the single coarse condition (\eg, skeleton sequences) as the
intermediary to bridge the translation model and the video generation model,
which limits both the naturalness and expressiveness of the generated videos.
To overcome these limitations, we propose SignViP, a novel SLVG framework that
incorporates multiple fine-grained conditions for improved generation fidelity.
Rather than directly translating error-prone high-dimensional conditions,
SignViP adopts a discrete tokenization paradigm to integrate and represent
fine-grained conditions (\ie, fine-grained poses and 3D hands). SignViP
contains three core components. (1) Sign Video Diffusion Model is jointly
trained with a multi-condition encoder to learn continuous embeddings that
encapsulate fine-grained motion and appearance. (2) Finite Scalar Quantization
(FSQ) Autoencoder is further trained to compress and quantize these embeddings
into discrete tokens for compact representation of the conditions. (3)
Multi-Condition Token Translator is trained to translate spoken language text
to discrete multi-condition tokens. During inference, Multi-Condition Token
Translator first translates the spoken language text into discrete
multi-condition tokens. These tokens are then decoded to continuous embeddings
by FSQ Autoencoder, which are subsequently injected into Sign Video Diffusion
Model to guide video generation. Experimental results show that SignViP
achieves state-of-the-art performance across metrics, including video quality,
temporal coherence, and semantic fidelity. The code is available at
https://github.com/umnooob/signvip/.

</details>


### [97] [Adversarial Attacks and Detection in Visual Place Recognition for Safer Robot Navigation](https://arxiv.org/abs/2506.15988)
*Connor Malone,Owen Claxton,Iman Shames,Michael Milford*

Main category: cs.CV

TL;DR: 论文分析了视觉地点识别（VPR）系统对抗性攻击的脆弱性，提出了一种结合对抗攻击检测器（AAD）和主动导航决策的系统框架，实验表明AAD能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: VPR系统在面对对抗性攻击时缺乏防御能力，可能导致机器人导航灾难性后果，因此需要研究攻击影响及防御方法。

Method: 分析了四种常见对抗性攻击和四种VPR特有攻击，提出结合AAD的系统框架，并通过实验验证其性能提升。

Result: 实验显示AAD能显著降低定位误差（如沿轨误差减少50%），并探讨了FGSM攻击在VPR中的效果。

Conclusion: 研究强调了AAD在真实系统中的必要性，为系统设计提供了量化要求。

Abstract: Stand-alone Visual Place Recognition (VPR) systems have little defence
against a well-designed adversarial attack, which can lead to disastrous
consequences when deployed for robot navigation. This paper extensively
analyzes the effect of four adversarial attacks common in other perception
tasks and four novel VPR-specific attacks on VPR localization performance. We
then propose how to close the loop between VPR, an Adversarial Attack Detector
(AAD), and active navigation decisions by demonstrating the performance benefit
of simulated AADs in a novel experiment paradigm -- which we detail for the
robotics community to use as a system framework. In the proposed experiment
paradigm, we see the addition of AADs across a range of detection accuracies
can improve performance over baseline; demonstrating a significant improvement
-- such as a ~50% reduction in the mean along-track localization error -- can
be achieved with True Positive and False Positive detection rates of only 75%
and up to 25% respectively. We examine a variety of metrics including:
Along-Track Error, Percentage of Time Attacked, Percentage of Time in an
`Unsafe' State, and Longest Continuous Time Under Attack. Expanding further on
these results, we provide the first investigation into the efficacy of the Fast
Gradient Sign Method (FGSM) adversarial attack for VPR. The analysis in this
work highlights the need for AADs in real-world systems for trustworthy
navigation, and informs quantitative requirements for system design.

</details>


### [98] [DIGMAPPER: A Modular System for Automated Geologic Map Digitization](https://arxiv.org/abs/2506.16006)
*Weiwei Duan,Michael P. Gerlek,Steven N. Minton,Craig A. Knoblock,Fandel Lin,Theresa Chen,Leeje Jang,Sofia Kirsanova,Zekun Li,Yijun Lin,Yao-Yi Chiang*

Main category: cs.CV

TL;DR: DIGMAPPER是一个模块化、可扩展的系统，用于自动化地质地图的数字化，通过深度学习模型和创新的技术（如上下文学习和合成数据生成）提高效率。


<details>
  <summary>Details</summary>
Motivation: 地质地图中的地理空间信息对可再生能源、电动汽车和国家安全至关重要，但数字化过程耗时耗力。

Method: 系统采用Docker化、工作流编排的架构，整合深度学习模型进行地图布局分析、特征提取和地理配准，并利用上下文学习、合成数据生成和Transformer模型解决数据不足和视觉复杂性。

Result: 在DARPA-USGS数据集上的评估显示，系统在多类特征提取和地理配准方面表现优异。

Conclusion: DIGMAPPER显著加速了地理空间数据集的生成，支持国家关键矿物评估和更广泛的地球科学应用。

Abstract: Historical geologic maps contain rich geospatial information, such as rock
units, faults, folds, and bedding planes, that is critical for assessing
mineral resources essential to renewable energy, electric vehicles, and
national security. However, digitizing maps remains a labor-intensive and
time-consuming task. We present DIGMAPPER, a modular, scalable system developed
in collaboration with the United States Geological Survey (USGS) to automate
the digitization of geologic maps. DIGMAPPER features a fully dockerized,
workflow-orchestrated architecture that integrates state-of-the-art deep
learning models for map layout analysis, feature extraction, and
georeferencing. To overcome challenges such as limited training data and
complex visual content, our system employs innovative techniques, including
in-context learning with large language models, synthetic data generation, and
transformer-based models. Evaluations on over 100 annotated maps from the
DARPA-USGS dataset demonstrate high accuracy across polygon, line, and point
feature extraction, and reliable georeferencing performance. Deployed at USGS,
DIGMAPPER significantly accelerates the creation of analysis-ready geospatial
datasets, supporting national-scale critical mineral assessments and broader
geoscientific applications.

</details>


### [99] [EndoMUST: Monocular Depth Estimation for Robotic Endoscopy via End-to-end Multi-step Self-supervised Training](https://arxiv.org/abs/2506.16017)
*Liangjing Shao,Linxin Bai,Chenkang Du,Xinrong Chen*

Main category: cs.CV

TL;DR: 提出一种多步微调框架，用于内窥镜场景中的自监督深度估计，解决了光照变化和稀疏纹理问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 内窥镜场景中光照变化和纹理稀疏导致深度估计困难，现有方法在多模块训练策略上仍有不足。

Method: 采用三步训练策略：光流注册、多尺度图像分解和多变换对齐，每步仅训练相关网络以减少干扰。

Result: 在SCARED和Hamlyn数据集上实现最低误差（降低4%~10%），达到SOTA性能。

Conclusion: 多步微调框架有效提升内窥镜深度估计性能，代码已开源。

Abstract: Monocular depth estimation and ego-motion estimation are significant tasks
for scene perception and navigation in stable, accurate and efficient
robot-assisted endoscopy. To tackle lighting variations and sparse textures in
endoscopic scenes, multiple techniques including optical flow, appearance flow
and intrinsic image decomposition have been introduced into the existing
methods. However, the effective training strategy for multiple modules are
still critical to deal with both illumination issues and information
interference for self-supervised depth estimation in endoscopy. Therefore, a
novel framework with multistep efficient finetuning is proposed in this work.
In each epoch of end-to-end training, the process is divided into three steps,
including optical flow registration, multiscale image decomposition and
multiple transformation alignments. At each step, only the related networks are
trained without interference of irrelevant information. Based on
parameter-efficient finetuning on the foundation model, the proposed method
achieves state-of-the-art performance on self-supervised depth estimation on
SCARED dataset and zero-shot depth estimation on Hamlyn dataset, with
4\%$\sim$10\% lower error. The evaluation code of this work has been published
on https://github.com/BaymaxShao/EndoMUST.

</details>


### [100] [PAROAttention: Pattern-Aware ReOrdering for Efficient Sparse and Quantized Attention in Visual Generation Models](https://arxiv.org/abs/2506.16054)
*Tianchen Zhao,Ke Hong,Xinhao Yang,Xuefeng Xiao,Huixia Li,Feng Ling,Ruiqi Xie,Siqi Chen,Hongyu Zhu,Yichong Zhang,Yu Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为PARO的技术，通过重新组织注意力模式来降低视觉生成中的计算和内存成本，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 视觉生成中注意力机制的二次复杂度导致高计算和内存成本，尤其是在高分辨率图像或多帧视频生成中。现有稀疏化和量化技术面临低密度和低比特宽度的挑战。

Method: 设计了一种Pattern-Aware token ReOrdering (PARO)技术，将多样化的注意力模式统一为硬件友好的块状模式，简化并增强了稀疏化和量化。

Result: PAROAttention在视频和图像生成中实现了无损指标，与全精度基线结果几乎相同，同时显著降低了密度（20%-30%）和比特宽度（INT8/INT4），端到端延迟加速1.9x至2.7x。

Conclusion: 通过重新组织注意力模式，PARO技术有效解决了视觉生成中的计算和内存效率问题，为高分辨率图像和多帧视频生成提供了高效解决方案。

Abstract: In visual generation, the quadratic complexity of attention mechanisms
results in high memory and computational costs, especially for longer token
sequences required in high-resolution image or multi-frame video generation. To
address this, prior research has explored techniques such as sparsification and
quantization. However, these techniques face significant challenges under low
density and reduced bitwidths. Through systematic analysis, we identify that
the core difficulty stems from the dispersed and irregular characteristics of
visual attention patterns. Therefore, instead of introducing specialized
sparsification and quantization design to accommodate such patterns, we propose
an alternative strategy: *reorganizing* the attention pattern to alleviate the
challenges. Inspired by the local aggregation nature of visual feature
extraction, we design a novel **Pattern-Aware token ReOrdering (PARO)**
technique, which unifies the diverse attention patterns into a
hardware-friendly block-wise pattern. This unification substantially simplifies
and enhances both sparsification and quantization. We evaluate the
performance-efficiency trade-offs of various design choices and finalize a
methodology tailored for the unified pattern. Our approach, **PAROAttention**,
achieves video and image generation with lossless metrics, and nearly identical
results from full-precision (FP) baselines, while operating at notably lower
density (~20%-30%) and bitwidth (**INT8/INT4**), achieving a **1.9x** to
**2.7x** end-to-end latency speedup.

</details>


### [101] [Stepping Out of Similar Semantic Space for Open-Vocabulary Segmentation](https://arxiv.org/abs/2506.16058)
*Yong Liu,SongLi Wu,Sule Bai,Jiahao Wang,Yitong Wang,Yansong Tang*

Main category: cs.CV

TL;DR: 论文提出新基准OpenBench，评估开放词汇分割模型的真实能力，并开发OVSNet方法提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试集无法充分评估开放词汇分割模型的泛化能力，因其语义空间与训练集相似。

Method: 提出OpenBench基准，设计OVSNet方法，通过异构特征融合和训练空间扩展提升性能。

Result: OVSNet在现有数据集和OpenBench上均取得最优结果。

Conclusion: OpenBench和OVSNet有效提升了开放词汇分割的评估和性能。

Abstract: Open-vocabulary segmentation aims to achieve segmentation of arbitrary
categories given unlimited text inputs as guidance. To achieve this, recent
works have focused on developing various technical routes to exploit the
potential of large-scale pre-trained vision-language models and have made
significant progress on existing benchmarks. However, we find that existing
test sets are limited in measuring the models' comprehension of
``open-vocabulary" concepts, as their semantic space closely resembles the
training space, even with many overlapping categories. To this end, we present
a new benchmark named OpenBench that differs significantly from the training
semantics. It is designed to better assess the model's ability to understand
and segment a wide range of real-world concepts. When testing existing methods
on OpenBench, we find that their performance diverges from the conclusions
drawn on existing test sets. In addition, we propose a method named OVSNet to
improve the segmentation performance for diverse and open scenarios. Through
elaborate fusion of heterogeneous features and cost-free expansion of the
training space, OVSNet achieves state-of-the-art results on both existing
datasets and our proposed OpenBench. Corresponding analysis demonstrate the
soundness and effectiveness of our proposed benchmark and method.

</details>


### [102] [STAR-Pose: Efficient Low-Resolution Video Human Pose Estimation via Spatial-Temporal Adaptive Super-Resolution](https://arxiv.org/abs/2506.16061)
*Yucheng Jin,Jinyan Chen,Ziyue He,Baojun Han,Furan An*

Main category: cs.CV

TL;DR: STAR-Pose是一种针对低分辨率视频中人体姿态估计的空间-时间自适应超分辨率框架，通过新型Transformer和自适应融合模块提升性能，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 低分辨率视频中的人体姿态估计具有挑战性，传统方法依赖高质量输入或计算密集型处理，限制了在资源受限环境中的应用。

Method: 提出STAR-Pose框架，结合空间-时间Transformer（带LeakyReLU修改的线性注意力）和自适应融合模块，设计姿态感知复合损失以实现任务导向的超分辨率。

Result: 在多个主流视频HPE数据集上，STAR-Pose在极低分辨率（64x48）条件下mAP提升5.2%，推理速度比级联方法快2.8x至4.4x。

Conclusion: STAR-Pose通过高效的空间-时间建模和任务导向优化，显著提升了低分辨率视频中人体姿态估计的性能和效率。

Abstract: Human pose estimation in low-resolution videos presents a fundamental
challenge in computer vision. Conventional methods either assume high-quality
inputs or employ computationally expensive cascaded processing, which limits
their deployment in resource-constrained environments. We propose STAR-Pose, a
spatial-temporal adaptive super-resolution framework specifically designed for
video-based human pose estimation. Our method features a novel spatial-temporal
Transformer with LeakyReLU-modified linear attention, which efficiently
captures long-range temporal dependencies. Moreover, it is complemented by an
adaptive fusion module that integrates parallel CNN branch for local texture
enhancement. We also design a pose-aware compound loss to achieve task-oriented
super-resolution. This loss guides the network to reconstruct structural
features that are most beneficial for keypoint localization, rather than
optimizing purely for visual quality. Extensive experiments on several
mainstream video HPE datasets demonstrate that STAR-Pose outperforms existing
approaches. It achieves up to 5.2% mAP improvement under extremely
low-resolution (64x48) conditions while delivering 2.8x to 4.4x faster
inference than cascaded approaches.

</details>


### [103] [TD3Net: A Temporal Densely Connected Multi-Dilated Convolutional Network for Lipreading](https://arxiv.org/abs/2506.16073)
*Byung Hoon Lee,Wooseok Shin,Sung Won Han*

Main category: cs.CV

TL;DR: 论文提出了一种名为TD3Net的新方法，通过结合密集跳跃连接和多扩张时间卷积，解决了传统TCN在唇读任务中因盲点导致的信息丢失问题。


<details>
  <summary>Details</summary>
Motivation: 传统TCN在唇读任务中存在盲点，导致对连续唇部运动的信息丢失，限制了性能。

Method: 提出TD3Net，结合密集跳跃连接和多扩张时间卷积，覆盖更广且无盲点的感受野。

Result: 在LRW和LRW-1000数据集上，TD3Net性能与现有方法相当，但参数和计算量更少。

Conclusion: TD3Net有效利用了多样化的时间特征，保持了时间连续性，在唇读系统中具有显著优势。

Abstract: The word-level lipreading approach typically employs a two-stage framework
with separate frontend and backend architectures to model dynamic lip
movements. Each component has been extensively studied, and in the backend
architecture, temporal convolutional networks (TCNs) have been widely adopted
in state-of-the-art methods. Recently, dense skip connections have been
introduced in TCNs to mitigate the limited density of the receptive field,
thereby improving the modeling of complex temporal representations. However,
their performance remains constrained owing to potential information loss
regarding the continuous nature of lip movements, caused by blind spots in the
receptive field. To address this limitation, we propose TD3Net, a temporal
densely connected multi-dilated convolutional network that combines dense skip
connections and multi-dilated temporal convolutions as the backend
architecture. TD3Net covers a wide and dense receptive field without blind
spots by applying different dilation factors to skip-connected features.
Experimental results on a word-level lipreading task using two large publicly
available datasets, Lip Reading in the Wild (LRW) and LRW-1000, indicate that
the proposed method achieves performance comparable to state-of-the-art
methods. It achieved higher accuracy with fewer parameters and lower
floating-point operations compared to existing TCN-based backend architectures.
Moreover, visualization results suggest that our approach effectively utilizes
diverse temporal features while preserving temporal continuity, presenting
notable advantages in lipreading systems. The code is available at our GitHub
repository:
https://github.com/Leebh-kor/TD3Net-A-Temporal-Densely-Connected-Multi-dilated-Convolutional-Network-for-Lipreading

</details>


### [104] [PR-DETR: Injecting Position and Relation Prior for Dense Video Captioning](https://arxiv.org/abs/2506.16082)
*Yizhe Li,Sanping Zhou,Zheng Qin,Le Wang*

Main category: cs.CV

TL;DR: PR-DETR是一种新颖的密集视频描述框架，通过注入显式的位置和关系先验来改进事件定位和描述生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法基于检测变换器隐式学习事件位置和语义，需要大量训练数据且性能受限。

Method: 生成位置锚定查询作为位置先验，设计事件关系编码器作为关系先验，改进定位和描述质量。

Result: 在ActivityNet Captions和YouCook2数据集上表现出竞争力。

Conclusion: PR-DETR通过显式先验显著提升了密集视频描述的性能。

Abstract: Dense video captioning is a challenging task that aims to localize and
caption multiple events in an untrimmed video. Recent studies mainly follow the
transformer-based architecture to jointly perform the two sub-tasks, i.e.,
event localization and caption generation, in an end-to-end manner. Based on
the general philosophy of detection transformer, these methods implicitly learn
the event locations and event semantics, which requires a large amount of
training data and limits the model's performance in practice. In this paper, we
propose a novel dense video captioning framework, named PR-DETR, which injects
the explicit position and relation prior into the detection transformer to
improve the localization accuracy and caption quality, simultaneously. On the
one hand, we first generate a set of position-anchored queries to provide the
scene-specific position and semantic information about potential events as
position prior, which serves as the initial event search regions to eliminate
the implausible event proposals. On the other hand, we further design an event
relation encoder to explicitly calculate the relationship between event
boundaries as relation prior to guide the event interaction to improve the
semantic coherence of the captions. Extensive ablation studies are conducted to
verify the effectiveness of the position and relation prior. Experimental
results also show the competitive performance of our method on ActivityNet
Captions and YouCook2 datasets.

</details>


### [105] [AutoV: Learning to Retrieve Visual Prompt for Large Vision-Language Models](https://arxiv.org/abs/2506.16112)
*Yuan Zhang,Chun-Kai Fan,Tao Huang,Ming Lu,Sicheng Yu,Junwen Pan,Kuan Cheng,Qi She,Shanghang Zhang*

Main category: cs.CV

TL;DR: AutoV是一种自动选择最优视觉提示的方法，通过训练基于文本查询和输入图像的模型，提升大型视觉语言模型（LVLMs）的性能。


<details>
  <summary>Details</summary>
Motivation: 当前手动设计视觉提示的方法效率低且效果不佳，因此需要一种自动化的解决方案。

Method: AutoV通过自动数据收集和标注流程，评估多种视觉提示并训练模型选择最优提示。

Result: 实验显示AutoV显著提升了多种LVLMs的性能，例如LLaVA-OV和Qwen2.5-VL。

Conclusion: AutoV是一种高效的视觉提示方法，具有广泛的应用潜力。

Abstract: Inspired by text prompts in large language models (LLMs), visual prompts have
been explored to enhance the reasoning capabilities of large vision-language
models (LVLMs). Current methods design heuristic visual prompts, such as
overlaying a text-query-guided attention heatmap on the original input image.
However, designing effective prompts manually is challenging and
time-consuming, and it often fails to explore the benefits of different visual
prompts, leading to sub-optimal performance. To this end, we propose
\textbf{AutoV} that learns to automatically select the optimal visual prompt
from various candidates based on given textual queries and the input image. To
train AutoV, we developed an automatic data collection and labeling pipeline
that evaluates various visual prompts with a pre-trained LVLM. We input a set
of visual prompts into the LVLM and rank them according to the prediction
losses generated by the model. Using the ranking as a supervision signal, we
train AutoV to automatically choose the optimal visual prompt from various
visual prompts for LVLMs. Experimental results indicate that AutoV enhances the
performance of various LVLMs across multiple popular image understanding tasks.
For instance, LLaVA-OV with AutoV achieves $\textbf{1.7}\%$ accuracy gain on
LLaVA$^{\text{Wild}}$, and AutoV boosts Qwen2.5-VL by $\textbf{1.9}\%$ on MMMU,
highlighting its potential as an optimal visual prompting method for LVLMs.

</details>


### [106] [FastInit: Fast Noise Initialization for Temporally Consistent Video Generation](https://arxiv.org/abs/2506.16119)
*Chengyu Bai,Yuming Li,Zhongyu Zhao,Jintao Chen,Peidong Jia,Qi She,Ming Lu,Shanghang Zhang*

Main category: cs.CV

TL;DR: FastInit提出了一种快速噪声初始化方法，通过单次前向传播生成高质量视频噪声，显著提升视频生成效率和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如FreeInit）通过迭代优化噪声提高时间一致性，但计算成本高。FastInit旨在解决这一问题。

Method: FastInit训练一个视频噪声预测网络（VNPNet），通过单次前向传播生成优化后的噪声，无需迭代。

Result: 实验表明，FastInit显著提升生成视频的质量和时间一致性，同时大幅降低计算成本。

Conclusion: FastInit为视频生成提供了一种高效且实用的解决方案，可直接应用于推理阶段。

Abstract: Video generation has made significant strides with the development of
diffusion models; however, achieving high temporal consistency remains a
challenging task. Recently, FreeInit identified a training-inference gap and
introduced a method to iteratively refine the initial noise during inference.
However, iterative refinement significantly increases the computational cost
associated with video generation. In this paper, we introduce FastInit, a fast
noise initialization method that eliminates the need for iterative refinement.
FastInit learns a Video Noise Prediction Network (VNPNet) that takes random
noise and a text prompt as input, generating refined noise in a single forward
pass. Therefore, FastInit greatly enhances the efficiency of video generation
while achieving high temporal consistency across frames. To train the VNPNet,
we create a large-scale dataset consisting of pairs of text prompts, random
noise, and refined noise. Extensive experiments with various text-to-video
models show that our method consistently improves the quality and temporal
consistency of the generated videos. FastInit not only provides a substantial
improvement in video generation but also offers a practical solution that can
be applied directly during inference. The code and dataset will be released.

</details>


### [107] [Neurosymbolic Object-Centric Learning with Distant Supervision](https://arxiv.org/abs/2506.16129)
*Stefano Colamonaco,David Debot,Giuseppe Marra*

Main category: cs.CV

TL;DR: 论文提出了一种直接从原始非结构化感知数据中学习对象中心表示的方法，仅需远程监督，并通过神经符号模型DeepObjectLog实现。


<details>
  <summary>Details</summary>
Motivation: 现有系统依赖对象级监督或预定义的对象分解，限制了模型的泛化能力。

Method: 结合感知模块（提取对象表示）和基于概率逻辑编程的符号推理层，通过概率逻辑推理引入新的学习信号。

Result: 在未见过的对象组合、任务和对象数量等泛化场景中，模型表现优于神经和神经符号基线。

Conclusion: DeepObjectLog通过神经符号整合，显著提升了对象中心表示的学习和泛化能力。

Abstract: Relational learning enables models to generalize across structured domains by
reasoning over objects and their interactions. While recent advances in
neurosymbolic reasoning and object-centric learning bring us closer to this
goal, existing systems rely either on object-level supervision or on a
predefined decomposition of the input into objects. In this work, we propose a
neurosymbolic formulation for learning object-centric representations directly
from raw unstructured perceptual data and using only distant supervision. We
instantiate this approach in DeepObjectLog, a neurosymbolic model that
integrates a perceptual module, which extracts relevant object representations,
with a symbolic reasoning layer based on probabilistic logic programming. By
enabling sound probabilistic logical inference, the symbolic component
introduces a novel learning signal that further guides the discovery of
meaningful objects in the input. We evaluate our model across a diverse range
of generalization settings, including unseen object compositions, unseen tasks,
and unseen number of objects. Experimental results show that our method
outperforms neural and neurosymbolic baselines across the tested settings.

</details>


### [108] [GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal Reasoning](https://arxiv.org/abs/2506.16141)
*Yi Chen,Yuying Ge,Rui Wang,Yixiao Ge,Junhao Cheng,Ying Shan,Xihui Liu*

Main category: cs.CV

TL;DR: 本文提出了GRPO-CARE，一种一致性感知的强化学习框架，用于提升多模态大语言模型（MLLMs）的答案正确性和推理连贯性，并在SEED-Bench-R1基准上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法如GRPO在MLLMs中缺乏严格的评估，且仅关注最终答案的正确性，导致推理步骤与答案之间逻辑一致性不足。

Method: 提出GRPO-CARE框架，采用双层奖励机制（基础奖励和自适应一致性奖励）替代KL惩罚，优化推理连贯性。

Result: GRPO-CARE在SEED-Bench-R1上表现优于标准GRPO，性能提升6.7%，一致性提高24.5%，并展示了强迁移能力。

Conclusion: GRPO-CARE为MLLMs提供了一种可推广的后训练框架，推动了更可解释和鲁棒的模型发展。

Abstract: Recent reinforcement learning approaches, such as outcome-supervised GRPO,
have advanced Chain-of-Thought reasoning in large language models (LLMs), yet
their adaptation to multimodal LLMs (MLLMs) is unexplored. To address the lack
of rigorous evaluation for MLLM post-training methods, we introduce
SEED-Bench-R1, a benchmark with complex real-world videos requiring balanced
perception and reasoning. It offers a large training set and evaluates
generalization across three escalating challenges: in-distribution,
cross-environment, and cross-environment-task scenarios. Using SEED-Bench-R1,
we find that standard GRPO, while improving answer accuracy, often reduces
logical coherence between reasoning steps and answers, with only a 57.9%
consistency rate. This stems from reward signals focusing solely on final
answers, encouraging shortcuts, and strict KL penalties limiting exploration.To
address this, we propose GRPO-CARE, a consistency-aware RL framework optimizing
both answer correctness and reasoning coherence without explicit supervision.
GRPO-CARE introduces a two-tiered reward: (1) a base reward for answer
correctness, and (2) an adaptive consistency bonus, computed by comparing the
model's reasoning-to-answer likelihood (via a slowly-evolving reference model)
against group peers.This dual mechanism amplifies rewards for reasoning paths
that are both correct and logically consistent. Replacing KL penalties with
this adaptive bonus, GRPO-CARE outperforms standard GRPO on SEED-Bench-R1,
achieving a 6.7% performance gain on the hardest evaluation level and a 24.5%
improvement in consistency. It also shows strong transferability, improving
model performance across diverse video understanding benchmarks. Our work
contributes a systematically designed benchmark and a generalizable
post-training framework, advancing the development of more interpretable and
robust MLLMs.

</details>


### [109] [MBA: Multimodal Bidirectional Attack for Referring Expression Segmentation Models](https://arxiv.org/abs/2506.16157)
*Xingbai Chen,Tingchao Fu,Renyang Liu,Wei Zhou,Chao Yi*

Main category: cs.CV

TL;DR: 本文提出了一种针对Referring Expression Segmentation（RES）模型的多模态双向对抗攻击策略，通过联合优化图像和文本模态，增强了对抗样本的跨文本迁移能力。


<details>
  <summary>Details</summary>
Motivation: 尽管RES模型在基于自然语言描述的图像分割任务中表现出色，但其对抗鲁棒性尚未得到充分研究。现有对抗攻击方法在RES模型上表现不佳，且实际应用中用户会使用多样化的文本输入，需要对抗样本具有跨文本迁移能力。

Method: 提出Multimodal Bidirectional Attack方法，通过可学习的代理文本嵌入扰动和视觉对齐优化，联合优化图像和文本模态，生成对抗样本。

Result: 实验表明，该方法在多个RES模型和基准数据集上优于现有方法，显著提升了对抗样本的跨文本迁移能力。

Conclusion: 该方法有效解决了RES模型的多模态对抗攻击问题，为提升其鲁棒性提供了新思路。

Abstract: Referring Expression Segmentation (RES) enables precise object segmentation
in images based on natural language descriptions, offering high flexibility and
broad applicability in real-world vision tasks. Despite its impressive
performance, the robustness of RES models against adversarial examples remains
largely unexplored. While prior adversarial attack methods have explored
adversarial robustness on conventional segmentation models, they perform poorly
when directly applied to RES, failing to expose vulnerabilities in its
multimodal structure. Moreover, in practical open-world scenarios, users
typically issue multiple, diverse referring expressions to interact with the
same image, highlighting the need for adversarial examples that generalize
across varied textual inputs. To address these multimodal challenges, we
propose a novel adversarial attack strategy termed \textbf{Multimodal
Bidirectional Attack}, tailored for RES models. Our method introduces learnable
proxy textual embedding perturbation and jointly performs visual-aligned
optimization on the image modality and textual-adversarial optimization on the
textual modality during attack generation. This dual optimization framework
encourages adversarial images to actively adapt to more challenging text
embedding during optimization, thereby enhancing their cross-text
transferability, which refers to the ability of adversarial examples to remain
effective under a variety of unseen or semantically diverse textual inputs.
Extensive experiments conducted on multiple RES models and benchmark datasets
demonstrate the superior effectiveness of our method compared to existing
methods.

</details>


### [110] [Co-Speech Gesture and Facial Expression Generation for Non-Photorealistic 3D Characters](https://arxiv.org/abs/2506.16159)
*Taisei Omine,Naoyuki Kawabata,Fuminori Homma*

Main category: cs.CV

TL;DR: 本研究提出了一种为非写实角色（如动漫角色）设计情感表达的方法，利用漫画中的表情数据和对话特定的语义手势，显著优于现有研究。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注写实化虚拟角色，忽略了非写实角色的情感表达需求，尤其是动漫风格的夸张表情。

Method: 从漫画中提取表情数据，并结合对话特定的语义手势，设计情感表达方法。

Result: 用户研究表明，该方法在多个方面显著优于现有研究。

Conclusion: 该方法为非写实角色的情感表达提供了有效解决方案，具有实际应用潜力。

Abstract: With the advancement of conversational AI, research on bodily expressions,
including gestures and facial expressions, has also progressed. However, many
existing studies focus on photorealistic avatars, making them unsuitable for
non-photorealistic characters, such as those found in anime. This study
proposes methods for expressing emotions, including exaggerated expressions
unique to non-photorealistic characters, by utilizing expression data extracted
from comics and dialogue-specific semantic gestures. A user study demonstrated
significant improvements across multiple aspects when compared to existing
research.

</details>


### [111] [Align the GAP: Prior-based Unified Multi-Task Remote Physiological Measurement Framework For Domain Generalization and Personalization](https://arxiv.org/abs/2506.16160)
*Jiyao Wang,Xiao Yang,Hao Lu,Dengbo He,Kaishun Wu*

Main category: cs.CV

TL;DR: 提出了一种统一框架GAP，结合多源语义域泛化（MSSDG）和测试时个性化适应（TTPA），通过先验知识提升远程生理测量的泛化性和个性化能力。


<details>
  <summary>Details</summary>
Motivation: 解决多任务远程生理测量中的部分标记和环境噪声问题，同时探索泛化与个性化之间的融合。

Method: 将面部视频信息分解为不变语义、个体偏差和噪声，利用先验知识设计多模块框架，实现MSSDG和TTPA的统一。

Result: 在六个公开数据集和新引入的真实驾驶数据集上验证了框架的有效性。

Conclusion: GAP框架能够以最小调整同时解决MSSDG和TTPA问题，代码和新数据集将公开。

Abstract: Multi-source synsemantic domain generalization (MSSDG) for multi-task remote
physiological measurement seeks to enhance the generalizability of these
metrics and attracts increasing attention. However, challenges like partial
labeling and environmental noise may disrupt task-specific accuracy. Meanwhile,
given that real-time adaptation is necessary for personalized products, the
test-time personalized adaptation (TTPA) after MSSDG is also worth exploring,
while the gap between previous generalization and personalization methods is
significant and hard to fuse. Thus, we proposed a unified framework for
MSSD\textbf{G} and TTP\textbf{A} employing \textbf{P}riors (\textbf{GAP}) in
biometrics and remote photoplethysmography (rPPG). We first disentangled
information from face videos into invariant semantics, individual bias, and
noise. Then, multiple modules incorporating priors and our observations were
applied in different stages and for different facial information. Then, based
on the different principles of achieving generalization and personalization,
our framework could simultaneously address MSSDG and TTPA under multi-task
remote physiological estimation with minimal adjustments. We expanded the MSSDG
benchmark to the TTPA protocol on six publicly available datasets and
introduced a new real-world driving dataset with complete labeling. Extensive
experiments that validated our approach, and the codes along with the new
dataset will be released.

</details>


### [112] [Integrating Generative Adversarial Networks and Convolutional Neural Networks for Enhanced Traffic Accidents Detection and Analysis](https://arxiv.org/abs/2506.16186)
*Zhenghao Xi,Xiang Liu,Yaqi Liu,Yitong Cai,Yangyu Zheng*

Main category: cs.CV

TL;DR: 论文提出了一种基于深度学习的交通事故检测框架，结合GANs生成数据和CNN训练模型，实现了高精度的实时事故检测。


<details>
  <summary>Details</summary>
Motivation: 全球交通事故数量上升，亟需智能、高效的自动化事故检测系统以提升交通安全。

Method: 使用GANs合成数据，CNN、FTCNN和VIT模型进行训练，视频帧来自YouTube，经过预处理后用于模型训练。

Result: FTCNN和VIT模型分别达到94%和95%的准确率，CNN模型为88%，验证了框架的高效性。

Conclusion: 该框架适用于实时交通监控和智能城市系统，为未来智能监控系统奠定了基础。

Abstract: Accident detection using Closed Circuit Television (CCTV) footage is one of
the most imperative features for enhancing transport safety and efficient
traffic control. To this end, this research addresses the issues of supervised
monitoring and data deficiency in accident detection systems by adapting
excellent deep learning technologies. The motivation arises from rising
statistics in the number of car accidents worldwide; this calls for innovation
and the establishment of a smart, efficient and automated way of identifying
accidents and calling for help to save lives. Addressing the problem of the
scarcity of data, the presented framework joins Generative Adversarial Networks
(GANs) for synthesizing data and Convolutional Neural Networks (CNN) for model
training. Video frames for accidents and non-accidents are collected from
YouTube videos, and we perform resizing, image enhancement and image
normalisation pixel range adjustments. Three models are used: CNN, Fine-tuned
Convolutional Neural Network (FTCNN) and Vision Transformer (VIT) worked best
for detecting accidents from CCTV, obtaining an accuracy rate of 94% and 95%,
while the CNN model obtained 88%. Such results show that the proposed framework
suits traffic safety applications due to its high real-time accident detection
capabilities and broad-scale applicability. This work lays the foundation for
intelligent surveillance systems in the future for real-time traffic
monitoring, smart city framework, and integration of intelligent surveillance
systems into emergency management systems.

</details>


### [113] [VideoGAN-based Trajectory Proposal for Automated Vehicles](https://arxiv.org/abs/2506.16209)
*Annajoyce Mariani,Kira Maag,Hanno Gottschalk*

Main category: cs.CV

TL;DR: 使用生成对抗网络（GAN）从鸟瞰视角视频生成交通场景的轨迹，以解决传统方法难以捕捉复杂多模态分布的问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如模型驱动、规则基础或经典学习方法）难以有效捕捉未来轨迹的复杂多模态分布，因此探索GAN是否能生成统计准确的轨迹。

Method: 提出一种流程，利用低分辨率鸟瞰占用网格视频训练视频生成模型，并通过单帧目标检测和帧间目标匹配提取轨迹数据。

Result: 在100 GPU小时内完成训练，推理时间低于20毫秒，生成的轨迹在空间和动态参数分布上与真实数据对齐。

Conclusion: GAN能够高效生成物理真实的轨迹，适用于自动驾驶场景。

Abstract: Being able to generate realistic trajectory options is at the core of
increasing the degree of automation of road vehicles. While model-driven,
rule-based, and classical learning-based methods are widely used to tackle
these tasks at present, they can struggle to effectively capture the complex,
multimodal distributions of future trajectories. In this paper we investigate
whether a generative adversarial network (GAN) trained on videos of bird's-eye
view (BEV) traffic scenarios can generate statistically accurate trajectories
that correctly capture spatial relationships between the agents. To this end,
we propose a pipeline that uses low-resolution BEV occupancy grid videos as
training data for a video generative model. From the generated videos of
traffic scenarios we extract abstract trajectory data using single-frame object
detection and frame-to-frame object matching. We particularly choose a GAN
architecture for the fast training and inference times with respect to
diffusion models. We obtain our best results within 100 GPU hours of training,
with inference times under 20\,ms. We demonstrate the physical realism of the
proposed trajectories in terms of distribution alignment of spatial and dynamic
parameters with respect to the ground truth videos from the Waymo Open Motion
Dataset.

</details>


### [114] [FOCoOp: Enhancing Out-of-Distribution Robustness in Federated Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2506.16218)
*Xinting Liao,Weiming Liu,Jiaming Qian,Pengyang Zhou,Jiahe Xu,Wenjie Wang,Chaochao Chen,Xiaolin Zheng,Tat-Seng Chua*

Main category: cs.CV

TL;DR: FOCoOp框架通过全局、局部和OOD提示优化联邦提示学习，提升分布外数据的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦提示学习方法在性能与鲁棒性之间存在权衡，尤其在分布外数据上表现不佳，限制了实际应用。

Method: 提出FOCoOp框架，利用全局、局部和OOD提示，通过双层分布鲁棒优化和半不平衡最优传输校准提示。

Result: 实验表明FOCoOp能有效捕捉分布式异构数据并增强对OOD变化的鲁棒性。

Conclusion: FOCoOp填补了联邦提示学习在OOD鲁棒性上的空白，适用于实际场景。

Abstract: Federated prompt learning (FPL) for vision-language models is a powerful
approach to collaboratively adapt models across distributed clients while
preserving data privacy. However, existing FPL approaches suffer from a
trade-off between performance and robustness, particularly in
out-of-distribution (OOD) shifts, limiting their reliability in real-world
scenarios. The inherent in-distribution (ID) data heterogeneity among different
clients makes it more challenging to maintain this trade-off. To fill this gap,
we introduce a Federated OOD-aware Context Optimization (FOCoOp) framework,
which captures diverse distributions among clients using ID global prompts,
local prompts, and OOD prompts. Specifically, FOCoOp leverages three sets of
prompts to create both class-level and distribution-level separations, which
adapt to OOD shifts through bi-level distributionally robust optimization.
Additionally, FOCoOp improves the discrimination consistency among clients,
i.e., calibrating global prompts, seemingly OOD prompts, and OOD prompts by
semi-unbalanced optimal transport. The extensive experiments on real-world
datasets demonstrate that FOCoOp effectively captures decentralized
heterogeneous distributions and enhances robustness of different OOD shifts.
The project is available at GitHub.

</details>


### [115] [R3eVision: A Survey on Robust Rendering, Restoration, and Enhancement for 3D Low-Level Vision](https://arxiv.org/abs/2506.16262)
*Weeyoung Kwon,Jeahun Sung,Minkyu Jeon,Chanho Eom,Jihyong Oh*

Main category: cs.CV

TL;DR: 该论文综述了3D低层视觉（3D LLV）领域，探讨了如何在退化条件下实现高保真3D重建，并提出了相关挑战和方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经渲染方法（如NeRF和3DGS）通常假设输入为干净的高分辨率多视图，但在实际场景中常面临噪声、模糊、低分辨率等问题，限制了其鲁棒性。

Method: 论文通过形式化退化感知渲染问题，分类整合低层视觉任务（如超分辨率、去模糊等）到神经渲染框架中的方法。

Result: 综述了代表性方法、数据集和评估协议，展示了如何在退化条件下实现高保真3D重建。

Conclusion: 3D LLV是现实环境中鲁棒3D内容生成和场景重建的重要方向，尤其在自动驾驶、AR/VR和机器人等领域具有广泛应用。

Abstract: Neural rendering methods such as Neural Radiance Fields (NeRF) and 3D
Gaussian Splatting (3DGS) have achieved significant progress in photorealistic
3D scene reconstruction and novel view synthesis. However, most existing models
assume clean and high-resolution (HR) multi-view inputs, which limits their
robustness under real-world degradations such as noise, blur, low-resolution
(LR), and weather-induced artifacts. To address these limitations, the emerging
field of 3D Low-Level Vision (3D LLV) extends classical 2D Low-Level Vision
tasks including super-resolution (SR), deblurring, weather degradation removal,
restoration, and enhancement into the 3D spatial domain. This survey, referred
to as R\textsuperscript{3}eVision, provides a comprehensive overview of robust
rendering, restoration, and enhancement for 3D LLV by formalizing the
degradation-aware rendering problem and identifying key challenges related to
spatio-temporal consistency and ill-posed optimization. Recent methods that
integrate LLV into neural rendering frameworks are categorized to illustrate
how they enable high-fidelity 3D reconstruction under adverse conditions.
Application domains such as autonomous driving, AR/VR, and robotics are also
discussed, where reliable 3D perception from degraded inputs is critical. By
reviewing representative methods, datasets, and evaluation protocols, this work
positions 3D LLV as a fundamental direction for robust 3D content generation
and scene-level reconstruction in real-world environments.

</details>


### [116] [Dense 3D Displacement Estimation for Landslide Monitoring via Fusion of TLS Point Clouds and Embedded RGB Images](https://arxiv.org/abs/2506.16265)
*Zhaoyi Wang,Jemil Avers Butt,Shengyu Huang,Tomislav Medic,Andreas Wieser*

Main category: cs.CV

TL;DR: 提出了一种基于3D点云和RGB图像的分层分区方法，用于估计密集3D位移矢量场，提高了滑坡监测的覆盖率和精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常仅依赖几何或辐射信息，导致稀疏或非3D位移估计，无法满足滑坡监测需求。

Method: 采用分层分区粗到细的方法，融合3D点云和配准RGB图像，通过几何一致性检查和刚性变换估计匹配。

Result: 在两个真实滑坡数据集上，方法实现了高空间覆盖率（79%和97%）和高精度（位移偏差0.15m和0.25m）。

Conclusion: 该方法在空间覆盖率和精度上优于现有技术，适用于TLS滑坡监测，并可扩展至其他点云和监测任务。

Abstract: Landslide monitoring is essential for understanding geohazards and mitigating
associated risks. However, existing point cloud-based methods typically rely on
either geometric or radiometric information and often yield sparse or non-3D
displacement estimates. In this paper, we propose a hierarchical
partition-based coarse-to-fine approach that fuses 3D point clouds and
co-registered RGB images to estimate dense 3D displacement vector fields. We
construct patch-level matches using both 3D geometry and 2D image features.
These matches are refined via geometric consistency checks, followed by rigid
transformation estimation per match. Experimental results on two real-world
landslide datasets demonstrate that our method produces 3D displacement
estimates with high spatial coverage (79% and 97%) and high accuracy.
Deviations in displacement magnitude with respect to external measurements
(total station or GNSS observations) are 0.15 m and 0.25 m on the two datasets,
respectively, and only 0.07 m and 0.20 m compared to manually derived
references. These values are below the average scan resolutions (0.08 m and
0.30 m). Our method outperforms the state-of-the-art method F2S3 in spatial
coverage while maintaining comparable accuracy. Our approach offers a practical
and adaptable solution for TLS-based landslide monitoring and is extensible to
other types of point clouds and monitoring tasks. Our example data and source
code are publicly available at https://github.com/zhaoyiww/fusion4landslide.

</details>


### [117] [Fine-grained Image Retrieval via Dual-Vision Adaptation](https://arxiv.org/abs/2506.16273)
*Xin Jiang,Meiqi Cao,Hao Tang,Fei Shen,Zechao Li*

Main category: cs.CV

TL;DR: 本文提出了一种双视觉适应（DVA）方法，用于细粒度图像检索（FGIR），通过样本和特征的协同适应，解决了现有方法容易过拟合和泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有FGIR方法容易过拟合训练数据，且忽视大规模预训练知识，导致泛化能力下降。

Method: 提出DVA方法，包括对象感知适应（修改输入样本）和上下文适应（引入少量参数调整特征），并通过知识蒸馏机制平衡检索效率和性能。

Result: 实验表明，DVA在三个分布内和三个分布外细粒度数据集上表现优异，且参数较少。

Conclusion: DVA通过协同适应和知识蒸馏，有效提升了FGIR的性能和泛化能力。

Abstract: Fine-Grained Image Retrieval~(FGIR) faces challenges in learning
discriminative visual representations to retrieve images with similar
fine-grained features. Current leading FGIR solutions typically follow two
regimes: enforce pairwise similarity constraints in the semantic embedding
space, or incorporate a localization sub-network to fine-tune the entire model.
However, such two regimes tend to overfit the training data while forgetting
the knowledge gained from large-scale pre-training, thus reducing their
generalization ability. In this paper, we propose a Dual-Vision Adaptation
(DVA) approach for FGIR, which guides the frozen pre-trained model to perform
FGIR through collaborative sample and feature adaptation. Specifically, we
design Object-Perceptual Adaptation, which modifies input samples to help the
pre-trained model perceive critical objects and elements within objects that
are helpful for category prediction. Meanwhile, we propose In-Context
Adaptation, which introduces a small set of parameters for feature adaptation
without modifying the pre-trained parameters. This makes the FGIR task using
these adjusted features closer to the task solved during the pre-training.
Additionally, to balance retrieval efficiency and performance, we propose
Discrimination Perception Transfer to transfer the discriminative knowledge in
the object-perceptual adaptation to the image encoder using the knowledge
distillation mechanism. Extensive experiments show that DVA has fewer learnable
parameters and performs well on three in-distribution and three
out-of-distribution fine-grained datasets.

</details>


### [118] [SycnMapV2: Robust and Adaptive Unsupervised Segmentation](https://arxiv.org/abs/2506.16297)
*Heng Zhang,Zikang Wan,Danilo Vasconcellos Vargas*

Main category: cs.CV

TL;DR: SyncMapV2是一种无监督分割算法，具有卓越的鲁棒性，无需训练或监督，性能远超现有方法。


<details>
  <summary>Details</summary>
Motivation: 人类视觉在无显式训练下仍能稳健分割视觉线索，而现有AI算法在噪声增加时性能下降明显。SyncMapV2旨在解决这一问题。

Method: 基于自组织动力学方程和随机网络概念，无需鲁棒训练或监督，支持在线自适应输入。

Result: 在数字损坏下，mIoU仅下降0.01%，远优于现有方法（23.8%）。在噪声、天气和模糊等场景中表现同样出色。

Conclusion: SyncMapV2首次实现无监督、在线自适应的鲁棒分割，为未来智能系统提供了新方向。

Abstract: Human vision excels at segmenting visual cues without the need for explicit
training, and it remains remarkably robust even as noise severity increases. In
contrast, existing AI algorithms struggle to maintain accuracy under similar
conditions. Here, we present SyncMapV2, the first to solve unsupervised
segmentation with state-of-the-art robustness. SyncMapV2 exhibits a minimal
drop in mIoU, only 0.01%, under digital corruption, compared to a 23.8% drop
observed in SOTA methods.This superior performance extends across various types
of corruption: noise (7.3% vs. 37.7%), weather (7.5% vs. 33.8%), and blur (7.0%
vs. 29.5%). Notably, SyncMapV2 accomplishes this without any robust training,
supervision, or loss functions. It is based on a learning paradigm that uses
self-organizing dynamical equations combined with concepts from random
networks. Moreover,unlike conventional methods that require re-initialization
for each new input, SyncMapV2 adapts online, mimicking the continuous
adaptability of human vision. Thus, we go beyond the accurate and robust
results, and present the first algorithm that can do all the above online,
adapting to input rather than re-initializing. In adaptability tests, SyncMapV2
demonstrates near-zero performance degradation, which motivates and fosters a
new generation of robust and adaptive intelligence in the near future.

</details>


### [119] [Learning Multi-scale Spatial-frequency Features for Image Denoising](https://arxiv.org/abs/2506.16307)
*Xu Zhao,Chen Zhao,Xiantao Hu,Hongliang Zhang,Ying Tai,Jian Yang*

Main category: cs.CV

TL;DR: 提出了一种新型多尺度自适应双域网络（MADNet）用于图像去噪，通过图像金字塔输入和自适应空间频率学习单元（ASFU）提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖固定单输入单输出Unet架构，忽视多尺度表示及高低频噪声特性差异。

Method: 使用图像金字塔输入，设计ASFU单元分离高低频信息，并在跳跃连接中引入全局特征融合块。

Result: 在合成和真实噪声图像数据集上验证了MADNet优于现有去噪方法。

Conclusion: MADNet通过多尺度自适应双域设计显著提升了图像去噪效果。

Abstract: Recent advancements in multi-scale architectures have demonstrated
exceptional performance in image denoising tasks. However, existing
architectures mainly depends on a fixed single-input single-output Unet
architecture, ignoring the multi-scale representations of pixel level. In
addition, previous methods treat the frequency domain uniformly, ignoring the
different characteristics of high-frequency and low-frequency noise. In this
paper, we propose a novel multi-scale adaptive dual-domain network (MADNet) for
image denoising. We use image pyramid inputs to restore noise-free results from
low-resolution images. In order to realize the interaction of high-frequency
and low-frequency information, we design an adaptive spatial-frequency learning
unit (ASFU), where a learnable mask is used to separate the information into
high-frequency and low-frequency components. In the skip connections, we design
a global feature fusion block to enhance the features at different scales.
Extensive experiments on both synthetic and real noisy image datasets verify
the effectiveness of MADNet compared with current state-of-the-art denoising
approaches.

</details>


### [120] [Segment Anything for Satellite Imagery: A Strong Baseline and a Regional Dataset for Automatic Field Delineation](https://arxiv.org/abs/2506.16318)
*Carmelo Scribano,Elena Govi,Paolo bertellini,Simone Parisi,Giorgia Franchini,Marko Bertogna*

Main category: cs.CV

TL;DR: 本文提出了一种基于Segment Anything Model（SAM）的农田边界自动提取方法，通过微调策略适应任务需求，并补充了区域数据集ERAS，验证了方法的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 农田边界的高精度测绘对农业高效运营至关重要，传统地面调查成本高昂，而基于计算机视觉的自动提取方法可以解决这一问题。

Method: 采用Segment Anything Model（SAM）构建农田边界提取流程，提出微调策略，并补充区域数据集ERAS以扩展数据覆盖范围。

Result: 实验验证了方法的准确性和泛化能力，提供了农田边界自动提取的稳健基线，并公开了ERAS数据集。

Conclusion: 该方法为农田边界自动提取提供了高效解决方案，补充的数据集ERAS进一步支持了相关研究。

Abstract: Accurate mapping of agricultural field boundaries is essential for the
efficient operation of agriculture. Automatic extraction from high-resolution
satellite imagery, supported by computer vision techniques, can avoid costly
ground surveys. In this paper, we present a pipeline for field delineation
based on the Segment Anything Model (SAM), introducing a fine-tuning strategy
to adapt SAM to this task. In addition to using published datasets, we describe
a method for acquiring a complementary regional dataset that covers areas
beyond current sources. Extensive experiments assess segmentation accuracy and
evaluate the generalization capabilities. Our approach provides a robust
baseline for automated field delineation. The new regional dataset, known as
ERAS, is now publicly available.

</details>


### [121] [RealDriveSim: A Realistic Multi-Modal Multi-Task Synthetic Dataset for Autonomous Driving](https://arxiv.org/abs/2506.16319)
*Arpit Jadon,Haoran Wang,Phillip Thomas,Michael Stanley,S. Nathaniel Cibik,Rachel Laurat,Omar Maher,Lukas Hoyer,Ozan Unal,Dengxin Dai*

Main category: cs.CV

TL;DR: RealDriveSim是一个多模态合成数据集，用于自动驾驶，支持2D计算机视觉和LiDAR应用，提供64类精细标注，显著降低成本并提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着感知模型的发展，大规模数据集需求增加，但数据标注成本高昂，合成数据集成为低成本解决方案。现有合成数据集在范围、真实性和通用性上有限。

Method: 提出RealDriveSim，一个真实感多模态合成数据集，支持2D和LiDAR应用，提供64类精细标注。

Result: 在多种应用和领域中评估，表现优于现有合成基准，达到最先进水平。

Conclusion: RealDriveSim为自动驾驶研究提供了低成本、高质量的合成数据集，填补了现有空白。

Abstract: As perception models continue to develop, the need for large-scale datasets
increases. However, data annotation remains far too expensive to effectively
scale and meet the demand. Synthetic datasets provide a solution to boost model
performance with substantially reduced costs. However, current synthetic
datasets remain limited in their scope, realism, and are designed for specific
tasks and applications. In this work, we present RealDriveSim, a realistic
multi-modal synthetic dataset for autonomous driving that not only supports
popular 2D computer vision applications but also their LiDAR counterparts,
providing fine-grained annotations for up to 64 classes. We extensively
evaluate our dataset for a wide range of applications and domains,
demonstrating state-of-the-art results compared to existing synthetic
benchmarks. The dataset is publicly available at
https://realdrivesim.github.io/.

</details>


### [122] [Reliable Few-shot Learning under Dual Noises](https://arxiv.org/abs/2506.16330)
*Ji Zhang,Jingkuan Song,Lianli Gao,Nicu Sebe,Heng Tao Shen*

Main category: cs.CV

TL;DR: DETA++提出了一种用于可靠少样本学习的方法，通过去噪任务适应和噪声鲁棒性设计，解决了支持样本和查询样本中的分布内外噪声问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在开放世界中可能因支持样本和查询样本中的分布内外噪声而失效，尤其是在少样本情况下，噪声影响会被放大。

Method: DETA++使用对比相关性聚合模块计算支持样本权重，提出干净原型损失和噪声熵最大化损失，并利用内存库存储干净区域，设计局部最近质心分类器进行噪声鲁棒预测。

Result: 实验证明DETA++在噪声环境下具有有效性和灵活性。

Conclusion: DETA++通过去噪和噪声鲁棒性设计，显著提升了少样本学习在噪声环境中的性能。

Abstract: Recent advances in model pre-training give rise to task adaptation-based
few-shot learning (FSL), where the goal is to adapt a pre-trained task-agnostic
model for capturing task-specific knowledge with a few-labeled support samples
of the target task.Nevertheless, existing approaches may still fail in the open
world due to the inevitable in-distribution (ID) and out-of-distribution (OOD)
noise from both support and query samples of the target task. With limited
support samples available, i) the adverse effect of the dual noises can be
severely amplified during task adaptation, and ii) the adapted model can
produce unreliable predictions on query samples in the presence of the dual
noises. In this work, we propose DEnoised Task Adaptation (DETA++) for reliable
FSL. DETA++ uses a Contrastive Relevance Aggregation (CoRA) module to calculate
image and region weights for support samples, based on which a clean prototype
loss and a noise entropy maximization loss are proposed to achieve noise-robust
task adaptation. Additionally,DETA++ employs a memory bank to store and refine
clean regions for each inner-task class, based on which a Local Nearest
Centroid Classifier (LocalNCC) is devised to yield noise-robust predictions on
query samples. Moreover, DETA++ utilizes an Intra-class Region Swapping
(IntraSwap) strategy to rectify ID class prototypes during task adaptation,
enhancing the model's robustness to the dual noises. Extensive experiments
demonstrate the effectiveness and flexibility of DETA++.

</details>


### [123] [Transparency Techniques for Neural Networks trained on Writer Identification and Writer Verification](https://arxiv.org/abs/2506.16331)
*Viktoria Pundy,Marco Peer,Florian Kleber*

Main category: cs.CV

TL;DR: 论文研究了神经网络在笔迹识别和验证中的透明度技术，比较了两种显著性图方法，发现像素级显著性图更适合支持法医专家。


<details>
  <summary>Details</summary>
Motivation: 提高神经网络在笔迹识别和验证中的透明度和可靠性，支持法医专家分析手写文本的相似性。

Method: 应用两种透明度技术：像素级显著性图和点特异性显著性图，并通过删除和插入评分指标进行评估。

Result: 像素级显著性图优于点特异性显著性图，适合支持法医专家。

Conclusion: 像素级显著性图在笔迹识别和验证中更具实用性，为法医专家提供了有效支持。

Abstract: Neural Networks are the state of the art for many tasks in the computer
vision domain, including Writer Identification (WI) and Writer Verification
(WV). The transparency of these "black box" systems is important for
improvements of performance and reliability. For this work, two transparency
techniques are applied to neural networks trained on WI and WV for the first
time in this domain. The first technique provides pixel-level saliency maps,
while the point-specific saliency maps of the second technique provide
information on similarities between two images. The transparency techniques are
evaluated using deletion and insertion score metrics. The goal is to support
forensic experts with information on similarities in handwritten text and to
explore the characteristics selected by a neural network for the identification
process. For the qualitative evaluation, the highlights of the maps are
compared to the areas forensic experts consider during the identification
process. The evaluation results show that the pixel-wise saliency maps
outperform the point-specific saliency maps and are suitable for the support of
forensic experts.

</details>


### [124] [MambaHash: Visual State Space Deep Hashing Model for Large-Scale Image Retrieval](https://arxiv.org/abs/2506.16353)
*Chao He,Hongxi Wei*

Main category: cs.CV

TL;DR: MambaHash是一种基于视觉状态空间的哈希模型，用于大规模图像检索，通过分组Mamba操作和通道交互注意力模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 探索Mamba在大规模图像检索任务中的适用性，并提出高效解决方案。

Method: 采用分阶段架构，引入分组Mamba操作建模局部和全局信息，设计通道交互注意力模块和自适应特征增强模块。

Result: 在CIFAR-10、NUS-WIDE和IMAGENET数据集上表现优于现有深度哈希方法。

Conclusion: MambaHash在大规模图像检索中具有高效性和优越性能。

Abstract: Deep image hashing aims to enable effective large-scale image retrieval by
mapping the input images into simple binary hash codes through deep neural
networks. More recently, Vision Mamba with linear time complexity has attracted
extensive attention from researchers by achieving outstanding performance on
various computer tasks. Nevertheless, the suitability of Mamba for large-scale
image retrieval tasks still needs to be explored. Towards this end, we propose
a visual state space hashing model, called MambaHash. Concretely, we propose a
backbone network with stage-wise architecture, in which grouped Mamba operation
is introduced to model local and global information by utilizing Mamba to
perform multi-directional scanning along different groups of the channel.
Subsequently, the proposed channel interaction attention module is used to
enhance information communication across channels. Finally, we meticulously
design an adaptive feature enhancement module to increase feature diversity and
enhance the visual representation capability of the model. We have conducted
comprehensive experiments on three widely used datasets: CIFAR-10, NUS-WIDE and
IMAGENET. The experimental results demonstrate that compared with the
state-of-the-art deep hashing methods, our proposed MambaHash has well
efficiency and superior performance to effectively accomplish large-scale image
retrieval tasks. Source code is available
https://github.com/shuaichaochao/MambaHash.git

</details>


### [125] [Prompt-based Dynamic Token Pruning to Guide Transformer Attention in Efficient Segmentation](https://arxiv.org/abs/2506.16369)
*Pallabi Dutta,Anubhab Maity,Sushmita Mitra*

Main category: cs.CV

TL;DR: 提出了一种基于自适应提示的剪枝方法，减少ViTs在医学图像分割中处理的无关token数量，提高计算效率和准确性。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers（ViTs）在处理大量token时计算需求高，限制了其在医学图像分析中的实际应用。

Method: 采用自适应提示引导的剪枝策略，通过提示空间先验对token进行相关性排序，低相关性token被降权，仅保留相关token进行后续处理。

Result: 实验显示减少了35-55%的token，降低了计算成本，同时保持了分割精度。

Conclusion: 该方法在资源受限环境中实现了高效的医学图像处理，有助于实时诊断。

Abstract: The high computational demands of Vision Transformers (ViTs), in processing a
huge number of tokens, often constrain their practical application in analyzing
medical images. This research proposes an adaptive prompt-guided pruning method
to selectively reduce the processing of irrelevant tokens in the segmentation
pipeline. The prompt-based spatial prior helps to rank the tokens according to
their relevance. Tokens with low-relevance scores are down-weighted, ensuring
that only the relevant ones are propagated for processing across subsequent
stages. This data-driven pruning strategy facilitates end-to-end training,
maintains gradient flow, and improves segmentation accuracy by focusing
computational resources on essential regions. The proposed framework is
integrated with several state-of-the-art models to facilitate the elimination
of irrelevant tokens; thereby, enhancing computational efficiency while
preserving segmentation accuracy. The experimental results show a reduction of
$\sim$ 35-55\% tokens; thus reducing the computational costs relative to the
baselines. Cost-effective medical image processing, using our framework,
facilitates real-time diagnosis by expanding its applicability in
resource-constrained environments.

</details>


### [126] [AGC-Drive: A Large-Scale Dataset for Real-World Aerial-Ground Collaboration in Driving Scenarios](https://arxiv.org/abs/2506.16371)
*Yunhao Hou,Bochao Zou,Min Zhang,Ran Chen,Shangdong Yang,Yanmei Zhang,Junbao Zhuo,Siheng Chen,Jiansheng Chen,Huimin Ma*

Main category: cs.CV

TL;DR: AGC-Drive是一个首个大规模真实世界数据集，用于空中-地面协同3D感知，填补了无人机视角在协作感知中的空白。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注车辆间或车辆与基础设施的协作，而无人机提供的动态俯视视角能有效缓解遮挡问题，但缺乏高质量数据集支持。

Method: 通过两辆装备多摄像头和LiDAR的车辆及一架无人机收集数据，覆盖14种驾驶场景，包含120K LiDAR帧和440K图像。

Result: 数据集包含400个场景，13类物体的3D标注，并提供了两种协作感知任务的基准。

Conclusion: AGC-Drive为空中-地面协作感知研究提供了重要资源，并发布了开源工具包。

Abstract: By sharing information across multiple agents, collaborative perception helps
autonomous vehicles mitigate occlusions and improve overall perception
accuracy. While most previous work focus on vehicle-to-vehicle and
vehicle-to-infrastructure collaboration, with limited attention to aerial
perspectives provided by UAVs, which uniquely offer dynamic, top-down views to
alleviate occlusions and monitor large-scale interactive environments. A major
reason for this is the lack of high-quality datasets for aerial-ground
collaborative scenarios. To bridge this gap, we present AGC-Drive, the first
large-scale real-world dataset for Aerial-Ground Cooperative 3D perception. The
data collection platform consists of two vehicles, each equipped with five
cameras and one LiDAR sensor, and one UAV carrying a forward-facing camera and
a LiDAR sensor, enabling comprehensive multi-view and multi-agent perception.
Consisting of approximately 120K LiDAR frames and 440K images, the dataset
covers 14 diverse real-world driving scenarios, including urban roundabouts,
highway tunnels, and on/off ramps. Notably, 19.5% of the data comprises dynamic
interaction events, including vehicle cut-ins, cut-outs, and frequent lane
changes. AGC-Drive contains 400 scenes, each with approximately 100 frames and
fully annotated 3D bounding boxes covering 13 object categories. We provide
benchmarks for two 3D perception tasks: vehicle-to-vehicle collaborative
perception and vehicle-to-UAV collaborative perception. Additionally, we
release an open-source toolkit, including spatiotemporal alignment verification
tools, multi-agent visualization systems, and collaborative annotation
utilities. The dataset and code are available at
https://github.com/PercepX/AGC-Drive.

</details>


### [127] [CLIP-MG: Guiding Semantic Attention with Skeletal Pose Features and RGB Data for Micro-Gesture Recognition on the iMiGUE Dataset](https://arxiv.org/abs/2506.16385)
*Santosh Patapati,Trisanth Srinivasan,Amith Adiraju*

Main category: cs.CV

TL;DR: 本文提出了一种基于CLIP的微手势识别模型CLIP-MG，通过结合姿态信息和多模态融合机制，在iMiGUE数据集上取得了61.82%的Top-1准确率。


<details>
  <summary>Details</summary>
Motivation: 微手势识别因手势细微且幅度低而具有挑战性，本文旨在改进现有方法。

Method: 采用Pose-Guided Semantics-Aware CLIP架构，结合姿态引导的语义查询生成和多模态融合机制。

Result: 模型在iMiGUE数据集上的Top-1准确率为61.82%。

Conclusion: CLIP-MG展示了潜力，但微手势识别仍具挑战性，需进一步改进。

Abstract: Micro-gesture recognition is a challenging task in affective computing due to
the subtle, involuntary nature of the gestures and their low movement
amplitude. In this paper, we introduce a Pose-Guided Semantics-Aware CLIP-based
architecture, or CLIP for Micro-Gesture recognition (CLIP-MG), a modified CLIP
model tailored for micro-gesture classification on the iMiGUE dataset. CLIP-MG
integrates human pose (skeleton) information into the CLIP-based recognition
pipeline through pose-guided semantic query generation and a gated multi-modal
fusion mechanism. The proposed model achieves a Top-1 accuracy of 61.82%. These
results demonstrate both the potential of our approach and the remaining
difficulty in fully adapting vision-language models like CLIP for micro-gesture
recognition.

</details>


### [128] [HyperPath: Knowledge-Guided Hyperbolic Semantic Hierarchy Modeling for WSI Analysis](https://arxiv.org/abs/2506.16398)
*Peixiang Huang,Yanyan Huang,Weiqin Zhao,Junjun He,Lequan Yu*

Main category: cs.CV

TL;DR: HyperPath利用双曲空间建模WSI的语义层次结构，结合视觉和文本特征，通过几何感知方法提升WSI分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖欧几里得嵌入，难以充分捕捉WSI的语义层次结构。

Method: 结合病理视觉语言基础模型提取的视觉和文本特征，设计角度模态对齐损失和语义层次一致性损失，利用双曲空间中的测地距离进行分类。

Result: 实验表明，HyperPath在多个任务上优于现有方法。

Conclusion: 双曲嵌入在WSI分析中具有潜力。

Abstract: Pathology is essential for cancer diagnosis, with multiple instance learning
(MIL) widely used for whole slide image (WSI) analysis. WSIs exhibit a natural
hierarchy -- patches, regions, and slides -- with distinct semantic
associations. While some methods attempt to leverage this hierarchy for
improved representation, they predominantly rely on Euclidean embeddings, which
struggle to fully capture semantic hierarchies. To address this limitation, we
propose HyperPath, a novel method that integrates knowledge from textual
descriptions to guide the modeling of semantic hierarchies of WSIs in
hyperbolic space, thereby enhancing WSI classification. Our approach adapts
both visual and textual features extracted by pathology vision-language
foundation models to the hyperbolic space. We design an Angular Modality
Alignment Loss to ensure robust cross-modal alignment, while a Semantic
Hierarchy Consistency Loss further refines feature hierarchies through
entailment and contradiction relationships and thus enhance semantic coherence.
The classification is performed with geodesic distance, which measures the
similarity between entities in the hyperbolic semantic hierarchy. This
eliminates the need for linear classifiers and enables a geometry-aware
approach to WSI analysis. Extensive experiments show that our method achieves
superior performance across tasks compared to existing methods, highlighting
the potential of hyperbolic embeddings for WSI analysis.

</details>


### [129] [Robustness Evaluation of OCR-based Visual Document Understanding under Multi-Modal Adversarial Attacks](https://arxiv.org/abs/2506.16407)
*Dong Nguyen Tien,Dung D. Le*

Main category: cs.CV

TL;DR: 本文提出了首个统一框架，用于生成和评估基于OCR的视觉文档理解（VDU）模型的多模态对抗攻击，研究了六种梯度布局攻击场景，并验证了攻击效果。


<details>
  <summary>Details</summary>
Motivation: 尽管VDU系统在信息提取方面表现优异，但其在真实对抗扰动下的鲁棒性尚未充分探索。

Method: 方法包括六种梯度布局攻击场景，涵盖OCR边界框、像素和文本的操纵，同时限制布局扰动预算以保持合理性。

Result: 实验结果表明，行级攻击和复合扰动（边界框+像素+文本）对性能影响最大，PGD边界框扰动优于随机基线。

Conclusion: 研究验证了布局预算、文本修改和对抗可迁移性的影响，为VDU模型的鲁棒性提供了新见解。

Abstract: Visual Document Understanding (VDU) systems have achieved strong performance
in information extraction by integrating textual, layout, and visual signals.
However, their robustness under realistic adversarial perturbations remains
insufficiently explored. We introduce the first unified framework for
generating and evaluating multi-modal adversarial attacks on OCR-based VDU
models. Our method covers six gradient-based layout attack scenarios,
incorporating manipulations of OCR bounding boxes, pixels, and texts across
both word and line granularities, with constraints on layout perturbation
budget (e.g., IoU >= 0.6) to preserve plausibility.
  Experimental results across four datasets (FUNSD, CORD, SROIE, DocVQA) and
six model families demonstrate that line-level attacks and compound
perturbations (BBox + Pixel + Text) yield the most severe performance
degradation. Projected Gradient Descent (PGD)-based BBox perturbations
outperform random-shift baselines in all investigated models. Ablation studies
further validate the impact of layout budget, text modification, and
adversarial transferability.

</details>


### [130] [Efficient Transformations in Deep Learning Convolutional Neural Networks](https://arxiv.org/abs/2506.16418)
*Berk Yilmaz,Daniel Fidel Harvey,Prajit Dhuri*

Main category: cs.CV

TL;DR: 研究探讨了在ResNet50 CNN模型中集成FFT、WHT和DCT信号处理变换对图像分类的影响，发现WHT显著降低能耗并提高准确性。


<details>
  <summary>Details</summary>
Motivation: 评估信号处理变换在CNN模型中对计算效率、能耗和分类准确性的权衡。

Method: 在ResNet50中集成FFT、WHT和DCT，使用CIFAR-100数据集进行实验。

Result: WHT显著降低能耗（从25,606 kJ降至39 kJ）并提高准确性（从66%提升至79%）。

Conclusion: WHT是一种高效且有效的方法，适用于能耗受限的CNN应用。

Abstract: This study investigates the integration of signal processing transformations
-- Fast Fourier Transform (FFT), Walsh-Hadamard Transform (WHT), and Discrete
Cosine Transform (DCT) -- within the ResNet50 convolutional neural network
(CNN) model for image classification. The primary objective is to assess the
trade-offs between computational efficiency, energy consumption, and
classification accuracy during training and inference. Using the CIFAR-100
dataset (100 classes, 60,000 images), experiments demonstrated that
incorporating WHT significantly reduced energy consumption while improving
accuracy. Specifically, a baseline ResNet50 model achieved a testing accuracy
of 66%, consuming an average of 25,606 kJ per model. In contrast, a modified
ResNet50 incorporating WHT in the early convolutional layers achieved 74%
accuracy, and an enhanced version with WHT applied to both early and late
layers achieved 79% accuracy, with an average energy consumption of only 39 kJ
per model. These results demonstrate the potential of WHT as a highly efficient
and effective approach for energy-constrained CNN applications.

</details>


### [131] [Structured Semantic 3D Reconstruction (S23DR) Challenge 2025 -- Winning solution](https://arxiv.org/abs/2506.16421)
*Jan Skvrna,Lukas Neumann*

Main category: cs.CV

TL;DR: 本文介绍了S23DR Challenge 2025的获胜解决方案，通过3D深度学习从稀疏点云和语义分割预测房屋3D屋顶线框。


<details>
  <summary>Details</summary>
Motivation: 解决从稀疏点云和语义分割中预测房屋3D屋顶线框的挑战。

Method: 直接在3D空间中操作，首先通过Gestalt分割从COLMAP点云识别顶点候选，然后使用两个PointNet-like模型：一个用于通过分析局部立方块来细化和分类候选顶点，另一个用于通过处理连接顶点对的圆柱区域来预测边缘。

Result: 在私有排行榜上以0.43的混合结构分数（HSS）获胜。

Conclusion: 两阶段的3D深度学习方法在预测3D屋顶线框任务中表现出色。

Abstract: This paper presents the winning solution for the S23DR Challenge 2025, which
involves predicting a house's 3D roof wireframe from a sparse point cloud and
semantic segmentations. Our method operates directly in 3D, first identifying
vertex candidates from the COLMAP point cloud using Gestalt segmentations. We
then employ two PointNet-like models: one to refine and classify these
candidates by analyzing local cubic patches, and a second to predict edges by
processing the cylindrical regions connecting vertex pairs. This two-stage, 3D
deep learning approach achieved a winning Hybrid Structure Score (HSS) of 0.43
on the private leaderboard.

</details>


### [132] [How Far Can Off-the-Shelf Multimodal Large Language Models Go in Online Episodic Memory Question Answering?](https://arxiv.org/abs/2506.16450)
*Giuseppe Lando,Rosario Forte,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 研究探讨现成多模态大语言模型（MLLMs）能否无需额外训练处理在线情景记忆视频问答（OEM-VQA）。通过将视频流转换为轻量文本记忆，仅需几千字节每分钟，结合LLM推理模块，在QAEgo4D-Closed基准上达到56.0%准确率，存储效率比现有系统高10^4/10^5倍。


<details>
  <summary>Details</summary>
Motivation: 探索现成MLLMs在OEM-VQA任务中的潜力，避免额外训练成本，同时实现高效存储。

Method: 将流式视频通过MLLM描述模块转换为轻量文本记忆，再通过LLM推理模块回答选择题。

Result: 在QAEgo4D-Closed基准上达到56.0%准确率，存储效率显著提升。

Conclusion: 现成MLLMs在OEM-VQA任务中表现优异，存储效率极高，未来研究可进一步优化组件设计。

Abstract: We investigate whether off-the-shelf Multimodal Large Language Models (MLLMs)
can tackle Online Episodic-Memory Video Question Answering (OEM-VQA) without
additional training. Our pipeline converts a streaming egocentric video into a
lightweight textual memory, only a few kilobytes per minute, via an MLLM
descriptor module, and answers multiple-choice questions by querying this
memory with an LLM reasoner module. On the QAEgo4D-Closed benchmark, our best
configuration attains 56.0% accuracy with 3.6 kB per minute storage, matching
the performance of dedicated state-of-the-art systems while being 10**4/10**5
times more memory-efficient. Extensive ablations provides insights into the
role of each component and design choice, and highlight directions of
improvement for future research.

</details>


### [133] [Spotting tell-tale visual artifacts in face swapping videos: strengths and pitfalls of CNN detectors](https://arxiv.org/abs/2506.16497)
*Riccardo Ziglio,Cecilia Pasquini,Silvio Ranise*

Main category: cs.CV

TL;DR: 论文研究了视频流中人脸交换操纵的检测方法，重点分析了CNN模型在不同数据集上的表现。


<details>
  <summary>Details</summary>
Motivation: 由于自动化和实时工具的进步，视频流中的人脸交换操纵威胁日益增加，需要有效的检测方法。

Method: 通过基准测试CNN模型在两个数据集（包括一个新收集的数据集）上的表现，分析其对不同采集源和交换算法的泛化能力。

Result: CNN架构在相同数据源下表现优异，但在跨数据集时难以鲁棒地捕捉遮挡相关的视觉线索。

Conclusion: 需要开发专门的检测策略以应对遮挡引入的视觉伪影。

Abstract: Face swapping manipulations in video streams represents an increasing threat
in remote video communications, due to advances
  in automated and real-time tools. Recent literature proposes to characterize
and exploit visual artifacts introduced in video frames
  by swapping algorithms when dealing with challenging physical scenes, such as
face occlusions. This paper investigates the
  effectiveness of this approach by benchmarking CNN-based data-driven models
on two data corpora (including a newly collected
  one) and analyzing generalization capabilities with respect to different
acquisition sources and swapping algorithms. The results
  confirm excellent performance of general-purpose CNN architectures when
operating within the same data source, but a significant
  difficulty in robustly characterizing occlusion-based visual cues across
datasets. This highlights the need for specialized detection
  strategies to deal with such artifacts.

</details>


### [134] [Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details](https://arxiv.org/abs/2506.16504)
*Zeqiang Lai,Yunfei Zhao,Haolin Liu,Zibo Zhao,Qingxiang Lin,Huiwen Shi,Xianghui Yang,Mingxin Yang,Shuhui Yang,Yifei Feng,Sheng Zhang,Xin Huang,Di Luo,Fan Yang,Fang Yang,Lifu Wang,Sicong Liu,Yixuan Tang,Yulin Cai,Zebin He,Tian Liu,Yuhong Liu,Jie Jiang,Linus,Jingwei Huang,Chunchao Guo*

Main category: cs.CV

TL;DR: Hunyuan3D 2.5是一套强大的3D扩散模型，用于生成高保真和细节丰富的3D资产。它在形状和纹理生成方面均有显著提升，通过新的形状基础模型LATTICE和基于物理的渲染（PBR）技术实现。


<details>
  <summary>Details</summary>
Motivation: 旨在提升3D资产的生成质量，缩小生成与手工制作3D形状之间的差距。

Method: 采用两阶段流程，引入LATTICE模型（10B参数）优化形状生成，并升级纹理生成技术为基于物理的渲染（PBR）。

Result: 在形状和端到端纹理生成方面显著优于先前方法。

Conclusion: Hunyuan3D 2.5在3D资产生成领域取得了重要进展，为高质量3D内容生成提供了新工具。

Abstract: In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion
models aimed at generating high-fidelity and detailed textured 3D assets.
Hunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D
2.0, while demonstrating substantial advancements in both shape and texture
generation. In terms of shape generation, we introduce a new shape foundation
model -- LATTICE, which is trained with scaled high-quality datasets,
model-size, and compute. Our largest model reaches 10B parameters and generates
sharp and detailed 3D shape with precise image-3D following while keeping mesh
surface clean and smooth, significantly closing the gap between generated and
handcrafted 3D shapes. In terms of texture generation, it is upgraded with
phyiscal-based rendering (PBR) via a novel multi-view architecture extended
from Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D
2.5 significantly outperforms previous methods in both shape and end-to-end
texture generation.

</details>


### [135] [How Hard Is Snow? A Paired Domain Adaptation Dataset for Clear and Snowy Weather: CADC+](https://arxiv.org/abs/2506.16531)
*Mei Qi Tang,Sean Sedwards,Chengjie Huang,Krzysztof Czarnecki*

Main category: cs.CV

TL;DR: CADC+是首个针对冬季自动驾驶的配对天气域适应数据集，通过匹配相同道路和时间的雪天与晴天数据，减少领域偏移，并初步评估了雪对3D目标检测性能的影响。


<details>
  <summary>Details</summary>
Motivation: 当前数据集在雪天和晴天的标注数据不足或依赖合成数据，导致评估不准确。CADC+旨在解决这一问题。

Method: 扩展CADC数据集，配对雪天与晴天序列，最小化非雪相关领域偏移。

Result: 雪引入了随机和认知不确定性，既作为噪声也作为独立数据域。

Conclusion: CADC+为研究雪对3D目标检测的影响提供了可靠数据，并揭示了雪的复杂影响。

Abstract: The impact of snowfall on 3D object detection performance remains
underexplored. Conducting such an evaluation requires a dataset with sufficient
labelled data from both weather conditions, ideally captured in the same
driving environment. Current driving datasets with LiDAR point clouds either do
not provide enough labelled data in both snowy and clear weather conditions, or
rely on de-snowing methods to generate synthetic clear weather. Synthetic data
often lacks realism and introduces an additional domain shift that confounds
accurate evaluations. To address these challenges, we present CADC+, the first
paired weather domain adaptation dataset for autonomous driving in winter
conditions. CADC+ extends the Canadian Adverse Driving Conditions dataset
(CADC) using clear weather data that was recorded on the same roads and in the
same period as CADC. To create CADC+, we pair each CADC sequence with a clear
weather sequence that matches the snowy sequence as closely as possible. CADC+
thus minimizes the domain shift resulting from factors unrelated to the
presence of snow. We also present some preliminary results using CADC+ to
evaluate the effect of snow on 3D object detection performance. We observe that
snow introduces a combination of aleatoric and epistemic uncertainties, acting
as both noise and a distinct data domain.

</details>


### [136] [From Semantic To Instance: A Semi-Self-Supervised Learning Approach](https://arxiv.org/abs/2506.16563)
*Keyhan Najafian,Farhad Maleki,Lingling Jin,Ian Stavness*

Main category: cs.CV

TL;DR: 提出了一种半自监督学习方法GLMask，用于实例分割，减少对大量标注数据的依赖，在农业和通用数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决农业图像中密集、遮挡对象的实例分割问题，减少标注需求。

Method: 设计GLMask图像-掩码表示，关注形状、纹理和模式，生成语义分割并转为实例分割。

Result: 在小麦头实例分割上达到98.5% mAP@50，在COCO数据集上提升12.6%。

Conclusion: 该方法适用于农业及其他类似数据特征的领域，性能显著优于传统方法。

Abstract: Instance segmentation is essential for applications such as automated
monitoring of plant health, growth, and yield. However, extensive effort is
required to create large-scale datasets with pixel-level annotations of each
object instance for developing instance segmentation models that restrict the
use of deep learning in these areas. This challenge is more significant in
images with densely packed, self-occluded objects, which are common in
agriculture. To address this challenge, we propose a semi-self-supervised
learning approach that requires minimal manual annotation to develop a
high-performing instance segmentation model. We design GLMask, an image-mask
representation for the model to focus on shape, texture, and pattern while
minimizing its dependence on color features. We develop a pipeline to generate
semantic segmentation and then transform it into instance-level segmentation.
The proposed approach substantially outperforms the conventional instance
segmentation models, establishing a state-of-the-art wheat head instance
segmentation model with mAP@50 of 98.5%. Additionally, we assessed the proposed
methodology on the general-purpose Microsoft COCO dataset, achieving a
significant performance improvement of over 12.6% mAP@50. This highlights that
the utility of our proposed approach extends beyond precision agriculture and
applies to other domains, specifically those with similar data characteristics.

</details>


### [137] [SafeTriage: Facial Video De-identification for Privacy-Preserving Stroke Triage](https://arxiv.org/abs/2506.16578)
*Tongan Cai,Haomiao Ni,Wenchao Ma,Yuan Xue,Qian Ma,Rachel Leicht,Kelvin Wong,John Volpi,Stephen T. C. Wong,James Z. Wang,Sharon X. Huang*

Main category: cs.CV

TL;DR: SafeTriage是一种新方法，通过去识别化患者面部视频保留关键运动特征，解决AI模型依赖真实患者数据的伦理和隐私问题。


<details>
  <summary>Details</summary>
Motivation: 在急诊环境中，AI模型依赖真实患者数据训练会引发伦理和隐私问题，尤其是跨机构训练时。

Method: SafeTriage利用预训练的视频运动转移模型，将真实患者面部的运动特征映射到合成身份上，并通过条件生成模型调整输入空间以确保准确运动转移。

Result: 评估表明，SafeTriage生成的合成视频能有效保留中风相关面部模式，同时提供强大的隐私保护。

Conclusion: SafeTriage为神经疾病数据共享和AI驱动的临床分析提供了安全且伦理的基础。

Abstract: Effective stroke triage in emergency settings often relies on clinicians'
ability to identify subtle abnormalities in facial muscle coordination. While
recent AI models have shown promise in detecting such patterns from patient
facial videos, their reliance on real patient data raises significant ethical
and privacy challenges -- especially when training robust and generalizable
models across institutions. To address these concerns, we propose SafeTriage, a
novel method designed to de-identify patient facial videos while preserving
essential motion cues crucial for stroke diagnosis. SafeTriage leverages a
pretrained video motion transfer (VMT) model to map the motion characteristics
of real patient faces onto synthetic identities. This approach retains
diagnostically relevant facial dynamics without revealing the patients'
identities. To mitigate the distribution shift between normal population
pre-training videos and patient population test videos, we introduce a
conditional generative model for visual prompt tuning, which adapts the input
space of the VMT model to ensure accurate motion transfer without needing to
fine-tune the VMT model backbone. Comprehensive evaluation, including
quantitative metrics and clinical expert assessments, demonstrates that
SafeTriage-produced synthetic videos effectively preserve stroke-relevant
facial patterns, enabling reliable AI-based triage. Our evaluations also show
that SafeTriage provides robust privacy protection while maintaining diagnostic
accuracy, offering a secure and ethically sound foundation for data sharing and
AI-driven clinical analysis in neurological disorders.

</details>


### [138] [Spatially-Aware Evaluation of Segmentation Uncertainty](https://arxiv.org/abs/2506.16589)
*Tal Zeevi,Eléonore V. Lieffrig,Lawrence H. Staib,John A. Onofrey*

Main category: cs.CV

TL;DR: 本文提出三种考虑空间结构和边界信息的不确定性评估指标，用于医学图像分割，验证结果显示其能更好地区分有意义和虚假的不确定性模式。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性评估指标忽略空间上下文和解剖结构，导致无法区分不同模式（如分散或边界对齐的不确定性）。

Method: 提出三种结合结构和边界信息的空间感知指标，并在前列腺分区分割挑战数据上进行验证。

Result: 新指标与临床重要因素更一致，并能更好区分有意义和虚假的不确定性模式。

Conclusion: 空间感知指标能更有效地评估医学图像分割中的不确定性。

Abstract: Uncertainty maps highlight unreliable regions in segmentation predictions.
However, most uncertainty evaluation metrics treat voxels independently,
ignoring spatial context and anatomical structure. As a result, they may assign
identical scores to qualitatively distinct patterns (e.g., scattered vs.
boundary-aligned uncertainty). We propose three spatially aware metrics that
incorporate structural and boundary information and conduct a thorough
validation on medical imaging data from the prostate zonal segmentation
challenge within the Medical Segmentation Decathlon. Our results demonstrate
improved alignment with clinically important factors and better discrimination
between meaningful and spurious uncertainty patterns.

</details>


### [139] [MetaQAP -- A Meta-Learning Approach for Quality-Aware Pretraining in Image Quality Assessment](https://arxiv.org/abs/2506.16601)
*Muhammad Azeem Aslam,Muhammad Hamza,Nisar Ahmed,Gulshan Saleem,Zhu Shuangtong,Hu Hongfei,Xu Wei,Saba Aslam,Wang Jun*

Main category: cs.CV

TL;DR: MetaQAP是一种新型无参考图像质量评估模型，通过质量感知预训练和元学习解决IQA挑战，在多个基准数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决图像质量评估中主观感知和复杂失真的挑战，提升无参考IQA模型的性能。

Method: 结合质量感知预训练CNN、质量感知损失函数和元学习集成模型。

Result: 在LiveCD、KonIQ-10K和BIQ2021数据集上取得PLCC和SROCC高分，跨数据集评估显示良好泛化性。

Conclusion: MetaQAP为无参考IQA提供了稳健且可推广的框架，推动了该领域的进步。

Abstract: Image Quality Assessment (IQA) is a critical task in a wide range of
applications but remains challenging due to the subjective nature of human
perception and the complexity of real-world image distortions. This study
proposes MetaQAP, a novel no-reference IQA model designed to address these
challenges by leveraging quality-aware pre-training and meta-learning. The
model performs three key contributions: pre-training Convolutional Neural
Networks (CNNs) on a quality-aware dataset, implementing a quality-aware loss
function to optimize predictions, and integrating a meta-learner to form an
ensemble model that effectively combines predictions from multiple base models.
Experimental evaluations were conducted on three benchmark datasets: LiveCD,
KonIQ-10K, and BIQ2021. The proposed MetaQAP model achieved exceptional
performance with Pearson Linear Correlation Coefficient (PLCC) and Spearman
Rank Order Correlation Coefficient (SROCC) scores of 0.9885/0.9812 on LiveCD,
0.9702/0.9658 on KonIQ-10K, and 0.884/0.8765 on BIQ2021, outperforming existing
IQA methods. Cross-dataset evaluations further demonstrated the
generalizability of the model, with PLCC and SROCC scores ranging from 0.6721
to 0.8023 and 0.6515 to 0.7805, respectively, across diverse datasets. The
ablation study confirmed the significance of each model component, revealing
substantial performance degradation when critical elements such as the
meta-learner or quality-aware loss function were omitted. MetaQAP not only
addresses the complexities of authentic distortions but also establishes a
robust and generalizable framework for practical IQA applications. By advancing
the state-of-the-art in no-reference IQA, this research provides valuable
insights and methodologies for future improvements and extensions in the field.

</details>


### [140] [Leveraging CNN and IoT for Effective E-Waste Management](https://arxiv.org/abs/2506.16647)
*Ajesh Thangaraj Nadar,Gabriel Nixon Raj,Soham Chandane,Sushant Bhat*

Main category: cs.CV

TL;DR: 本文提出了一种结合物联网和轻量级CNN分类的系统，用于电子废物的智能识别和分类，以提高回收效率。


<details>
  <summary>Details</summary>
Motivation: 现代电子设备的激增导致电子废物（e-waste）问题日益严重，不当处理和回收不足对环境与健康构成威胁。

Method: 通过集成摄像头系统和数字称重设备，利用轻量级CNN分类管道，基于视觉和重量属性自动分类电子废物。

Result: 系统能实时检测电路板、传感器和电线等电子废物组件，优化智能回收流程并提升处理效率。

Conclusion: 该IoT和CNN结合的系统为电子废物管理提供了高效解决方案，有助于改善回收流程。

Abstract: The increasing proliferation of electronic devices in the modern era has led
to a significant surge in electronic waste (e-waste). Improper disposal and
insufficient recycling of e-waste pose serious environmental and health risks.
This paper proposes an IoT-enabled system combined with a lightweight CNN-based
classification pipeline to enhance the identification, categorization, and
routing of e-waste materials. By integrating a camera system and a digital
weighing scale, the framework automates the classification of electronic items
based on visual and weight-based attributes. The system demonstrates how
real-time detection of e-waste components such as circuit boards, sensors, and
wires can facilitate smart recycling workflows and improve overall waste
processing efficiency.

</details>


### [141] [A Comparative Analysis of Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) as Dimensionality Reduction Techniques](https://arxiv.org/abs/2506.16663)
*Michael Gyimadu,Gregory Bell*

Main category: cs.CV

TL;DR: 本文对PCA和SVD两种线性降维技术进行了纯理论比较，分析了它们的可解释性、数值稳定性和适用性，并提出了选择指南。


<details>
  <summary>Details</summary>
Motivation: 高维图像数据通常需要降维处理，PCA和SVD是常用方法，但缺乏系统的理论比较。

Method: 从基本原理推导PCA和SVD算法，评估其特性，并结合文献提出选择建议。

Result: 总结了PCA和SVD的优缺点，提供了无需实验的选择指南。

Conclusion: 指出了当前研究的局限性和未来实验工作的方向。

Abstract: High-dimensional image data often require dimensionality reduction before
further analysis. This paper provides a purely analytical comparison of two
linear techniques-Principal Component Analysis (PCA) and Singular Value
Decomposition (SVD). After the derivation of each algorithm from first
principles, we assess their interpretability, numerical stability, and
suitability for differing matrix shapes. building on classical and recent
numerical literature, We synthesize rule-of-thumb guidelines for choosing one
out of the two algorithms without empirical benchmarking, building on classical
and recent numerical literature. Limitations and directions for future
experimental work are outlined at the end.

</details>


### [142] [Extracting Multimodal Learngene in CLIP: Unveiling the Multimodal Generalizable Knowledge](https://arxiv.org/abs/2506.16673)
*Ruiming Chen,Junming Yang,Shiyu Xia,Xu Yang,Jing Wang,Xin Geng*

Main category: cs.CV

TL;DR: MM-LG是一种新型框架，通过提取CLIP的多模态通用知识，显著提升下游任务性能，同时减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 解决现有Learngene方法无法处理多模态通用知识的问题，并降低CLIP预训练的计算成本。

Method: 使用多模态和单模态块加权提取通用知识，初始化不同规模和模态的模型。

Result: 在多个数据集上性能提升（如Oxford-IIIT PET +3.1%），参数存储减少75%，预训练成本降低2.8倍。

Conclusion: MM-LG高效且性能优越，适合多下游任务部署。

Abstract: CLIP (Contrastive Language-Image Pre-training) has attracted widespread
attention for its multimodal generalizable knowledge, which is significant for
downstream tasks. However, the computational overhead of a large number of
parameters and large-scale pre-training poses challenges of pre-training a
different scale of CLIP. Learngene extracts the generalizable components termed
as learngene from an ancestry model and initializes diverse descendant models
with it. Previous Learngene paradigms fail to handle the generalizable
knowledge in multimodal scenarios. In this paper, we put forward the idea of
utilizing a multimodal block to extract the multimodal generalizable knowledge,
which inspires us to propose MM-LG (Multimodal Learngene), a novel framework
designed to extract and leverage generalizable components from CLIP.
Specifically, we first establish multimodal and unimodal blocks to extract the
multimodal and unimodal generalizable knowledge in a weighted-sum manner.
Subsequently, we employ these components to numerically initialize descendant
models of varying scales and modalities. Extensive experiments demonstrate
MM-LG's effectiveness, which achieves performance gains over existing learngene
approaches (e.g.,+3.1% on Oxford-IIIT PET and +4.13% on Flickr30k) and
comparable or superior results to the pre-training and fine-tuning paradigm
(e.g.,+1.9% on Oxford-IIIT PET and +3.65% on Flickr30k). Notably, MM-LG
requires only around 25% of the parameter storage while reducing around 2.8
times pre-training costs for diverse model scales compared to the pre-training
and fine-tuning paradigm, making it particularly suitable for efficient
deployment across diverse downstream tasks.

</details>


### [143] [How to Train your Text-to-Image Model: Evaluating Design Choices for Synthetic Training Captions](https://arxiv.org/abs/2506.16679)
*Manuel Brack,Sudeep Katakol,Felix Friedrich,Patrick Schramowski,Hareesh Ravi,Kristian Kersting,Ajinkya Kale*

Main category: cs.CV

TL;DR: 研究探讨了合成字幕策略对文本到图像模型性能的影响，发现高质量字幕提升文本对齐但可能牺牲美学和多样性，而随机长度字幕则能平衡美学与对齐。


<details>
  <summary>Details</summary>
Motivation: 现有研究未深入探讨合成字幕设计对模型性能的影响，本研究填补了这一空白。

Method: 系统研究不同合成字幕策略对文本到图像模型性能的影响。

Result: 高质量字幕提升文本对齐但可能影响美学和多样性；随机长度字幕平衡美学与对齐；不同字幕分布导致输出偏差。

Conclusion: 字幕设计对模型性能至关重要，研究为文本到图像生成提供了更有效的训练数据策略。

Abstract: Training data is at the core of any successful text-to-image models. The
quality and descriptiveness of image text are crucial to a model's performance.
Given the noisiness and inconsistency in web-scraped datasets, recent works
shifted towards synthetic training captions. While this setup is generally
believed to produce more capable models, current literature does not provide
any insights into its design choices. This study closes this gap by
systematically investigating how different synthetic captioning strategies
impact the downstream performance of text-to-image models. Our experiments
demonstrate that dense, high-quality captions enhance text alignment but may
introduce trade-offs in output aesthetics and diversity. Conversely, captions
of randomized lengths yield balanced improvements across aesthetics and
alignment without compromising sample diversity. We also demonstrate that
varying caption distributions introduce significant shifts in the output bias
of a trained model. Our findings underscore the importance of caption design in
achieving optimal model performance and provide practical insights for more
effective training data strategies in text-to-image generation.

</details>


### [144] [DepthVanish: Optimizing Adversarial Interval Structures for Stereo-Depth-Invisible Patches](https://arxiv.org/abs/2506.16690)
*Yun Xing,Yue Cao,Nhat Chung,Jie Zhang,Ivor Tsang,Ming-Ming Cheng,Yang Liu,Lei Ma,Qing Guo*

Main category: cs.CV

TL;DR: 研究发现条纹结构能显著提升对抗性贴片攻击立体深度估计的效果，并开发了一种新型攻击方法，成功应用于实际场景。


<details>
  <summary>Details</summary>
Motivation: 揭示立体深度估计系统的潜在漏洞，提升其在物理世界中的攻击实用性。

Method: 通过引入条纹结构优化对抗性贴片，联合优化结构和纹理元素。

Result: 生成的贴片能有效攻击先进立体深度估计方法和商用RGB-D相机。

Conclusion: 条纹结构显著提升攻击效果，具有实际安全评估价值。

Abstract: Stereo Depth estimation is a critical task in autonomous driving and
robotics, where inaccuracies (such as misidentifying nearby objects as distant)
can lead to dangerous situations. Adversarial attacks against stereo depth
estimation can help reveal vulnerabilities before deployment. Previous work has
shown that repeating optimized textures can effectively mislead stereo depth
estimation in digital settings. However, our research reveals that these
naively repeated texture structures perform poorly in physical-world
implementations, i.e., when deployed as patches, limiting their practical
utility for testing stereo depth estimation systems. In this work, for the
first time, we discover that introducing regular intervals between repeated
textures, creating a striped structure, significantly enhances the patch attack
effectiveness. Through extensive experimentation, we analyze how variations of
this novel structure influence the performance. Based on these insights, we
develop a novel stereo depth attack that jointly optimizes both the striped
structure and texture elements. Our generated adversarial patches can be
inserted into any scenes and successfully attack state-of-the-art stereo depth
estimation methods, i.e., RAFT-Stereo and STTR. Most critically, our patch can
also attack commercial RGB-D cameras (Intel RealSense) in real-world
conditions, demonstrating their practical relevance for security assessment of
stereo systems.

</details>


### [145] [LaVi: Efficient Large Vision-Language Models via Internal Feature Modulation](https://arxiv.org/abs/2506.16691)
*Tongtian Yue,Longteng Guo,Yepeng Tang,Zijia Zhao,Xinxin Zhu,Hua Huang,Jing Liu*

Main category: cs.CV

TL;DR: LaVi提出了一种新型的大视觉语言模型（LVLM），通过内部特征调制实现高效视觉语言融合，显著提升了计算效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大视觉语言模型在视觉语言融合上存在效率低下的问题，限制了其扩展性和实用性。

Method: LaVi采用轻量级自适应变换，通过视觉条件化的增量调制层归一化的仿射参数，避免了长上下文扩展。

Result: 在15个图像和视频基准测试中，LaVi实现了最先进的多模态性能，计算成本大幅降低（FLOPs减少94.0%，推理速度提升3.1倍，内存使用减半）。

Conclusion: LaVi是一种可扩展且实用的实时多模态推理解决方案。

Abstract: Despite the impressive advancements of Large Vision-Language Models (LVLMs),
existing approaches suffer from a fundamental bottleneck: inefficient
visual-language integration. Current methods either disrupt the model's
inherent structure or introduce severe long-context computational burden,
severely limiting scalability and efficiency. In this paper, we rethink
multimodal integration and present LaVi, a novel LVLM that enables seamless and
efficient vision-language fusion through internal feature modulation within the
Large Language Models (LLMs). Unlike dominant LVLMs that rely on visual token
concatenation, LaVi bypasses long-context expansion by introducing a
lightweight and adaptive transformation, which incorporates visual context by
injecting token-wise vision-conditioned deltas into the affine parameters of
layer normalization. This mechanism directly modulates linguistic hidden states
based on visual input, ensuring precise vision-language alignment while
preserving the LLM's linguistic priors and drastically reducing computational
costs. Extensive evaluations across 15 image and video benchmarks demonstrate
that LaVi not only achieves state-of-the-art multimodal performance but also
dramatically enhances efficiency. Compared to LLaVA-OV-7B, LaVi reduces FLOPs
by 94.0%, improves inference speed by 3.1 times, and cuts memory usage in half
- establishing LaVi as a scalable and practical solution for real-time
multimodal reasoning. The code and models will be released soon.

</details>


### [146] [Language-driven Description Generation and Common Sense Reasoning for Video Action Recognition](https://arxiv.org/abs/2506.16701)
*Xiaodan Hu,Chuhang Zou,Suchen Wang,Jaechul Kim,Narendra Ahuja*

Main category: cs.CV

TL;DR: 论文提出了一种结合语言驱动常识先验的框架，用于识别单目视角下被遮挡的视频动作序列，包含视频上下文总结、描述生成和多模态活动识别模块。


<details>
  <summary>Details</summary>
Motivation: 现有视频动作识别方法未充分利用语言模型中的常识先验（如场景上下文），这些先验对人类理解物体、人-物交互和活动至关重要。

Method: 1. 视频上下文总结模块生成候选对象、活动及其交互；2. 描述生成模块通过辅助提示和常识推理描述场景并推断后续活动；3. 多模态活动识别头结合视觉和文本线索识别动作。

Result: 在Action Genome和Charades数据集上验证了方法的有效性。

Conclusion: 通过引入语言驱动的常识先验，显著提升了复杂遮挡场景下的视频动作识别性能。

Abstract: Recent video action recognition methods have shown excellent performance by
adapting large-scale pre-trained language-image models to the video domain.
However, language models contain rich common sense priors - the scene contexts
that humans use to constitute an understanding of objects, human-object
interactions, and activities - that have not been fully exploited. In this
paper, we introduce a framework incorporating language-driven common sense
priors to identify cluttered video action sequences from monocular views that
are often heavily occluded. We propose: (1) A video context summary component
that generates candidate objects, activities, and the interactions between
objects and activities; (2) A description generation module that describes the
current scene given the context and infers subsequent activities, through
auxiliary prompts and common sense reasoning; (3) A multi-modal activity
recognition head that combines visual and textual cues to recognize video
actions. We demonstrate the effectiveness of our approach on the challenging
Action Genome and Charades datasets.

</details>


### [147] [Few-Shot Generalized Category Discovery With Retrieval-Guided Decision Boundary Enhancement](https://arxiv.org/abs/2506.16728)
*Yunhan Ren,Feng Luo,Siyu Huang*

Main category: cs.CV

TL;DR: 本文提出了Few-shot Generalized Category Discovery (FSGCD)任务，旨在在已知信息稀缺的条件下提升GCD任务的性能。通过决策边界增强框架和基于亲和力的检索，该方法在六个公共GCD基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有GCD模型在有限标注样本和少量已知类别下的性能尚未充分探索，因此提出FSGCD任务以解决这一问题。

Method: 提出决策边界增强框架，包括决策边界预训练模块和两阶段检索引导的决策边界优化策略，利用亲和力检索伪标注样本优化边界。

Result: 在六个公共GCD基准测试中，该方法优于现有方法。

Conclusion: 该方法在已知信息稀缺的条件下显著提升了GCD任务的性能，具有实际应用价值。

Abstract: While existing Generalized Category Discovery (GCD) models have achieved
significant success, their performance with limited labeled samples and a small
number of known categories remains largely unexplored. In this work, we
introduce the task of Few-shot Generalized Category Discovery (FSGCD), aiming
to achieve competitive performance in GCD tasks under conditions of known
information scarcity. To tackle this challenge, we propose a decision boundary
enhancement framework with affinity-based retrieval. Our framework is designed
to learn the decision boundaries of known categories and transfer these
boundaries to unknown categories. First, we use a decision boundary
pre-training module to mitigate the overfitting of pre-trained information on
known category boundaries and improve the learning of these decision boundaries
using labeled samples. Second, we implement a two-stage retrieval-guided
decision boundary optimization strategy. Specifically, this strategy further
enhances the severely limited known boundaries by using affinity-retrieved
pseudo-labeled samples. Then, these refined boundaries are applied to unknown
clusters via guidance from affinity-based feature retrieval. Experimental
results demonstrate that our proposed method outperforms existing methods on
six public GCD benchmarks under the FSGCD setting. The codes are available at:
https://github.com/Ryh1218/FSGCD

</details>


### [148] [TeSG: Textual Semantic Guidance for Infrared and Visible Image Fusion](https://arxiv.org/abs/2506.16730)
*Mingrui Zhu,Xiru Chen,Xin Wei,Nannan Wang,Xinbo Gao*

Main category: cs.CV

TL;DR: 论文提出了一种基于文本语义引导的红外与可见光图像融合方法（TeSG），通过多层次语义信息优化融合过程，提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有文本引导的红外与可见光图像融合方法对文本语义信息的利用不足，需要更有效的整合方式。

Method: TeSG包含语义信息生成器（SIG）、掩码引导交叉注意力模块（MGCA）和文本驱动注意力融合模块（TDAF），分别生成语义信息、初步融合和细化融合。

Result: 实验表明，TeSG在下游任务（如检测和分割）中表现优于现有方法。

Conclusion: TeSG通过多层次文本语义引导，显著提升了红外与可见光图像融合的效果和实用性。

Abstract: Infrared and visible image fusion (IVF) aims to combine complementary
information from both image modalities, producing more informative and
comprehensive outputs. Recently, text-guided IVF has shown great potential due
to its flexibility and versatility. However, the effective integration and
utilization of textual semantic information remains insufficiently studied. To
tackle these challenges, we introduce textual semantics at two levels: the mask
semantic level and the text semantic level, both derived from textual
descriptions extracted by large Vision-Language Models (VLMs). Building on
this, we propose Textual Semantic Guidance for infrared and visible image
fusion, termed TeSG, which guides the image synthesis process in a way that is
optimized for downstream tasks such as detection and segmentation.
Specifically, TeSG consists of three core components: a Semantic Information
Generator (SIG), a Mask-Guided Cross-Attention (MGCA) module, and a Text-Driven
Attentional Fusion (TDAF) module. The SIG generates mask and text semantics
based on textual descriptions. The MGCA module performs initial attention-based
fusion of visual features from both infrared and visible images, guided by mask
semantics. Finally, the TDAF module refines the fusion process with gated
attention driven by text semantics. Extensive experiments demonstrate the
competitiveness of our approach, particularly in terms of performance on
downstream tasks, compared to existing state-of-the-art methods.

</details>


### [149] [3DeepRep: 3D Deep Low-rank Tensor Representation for Hyperspectral Image Inpainting](https://arxiv.org/abs/2506.16735)
*Yunshan Li,Wenwu Gong,Qianqian Wang,Chao Wang,Lili Yang*

Main category: cs.CV

TL;DR: 提出了一种新的3方向深度低秩张量表示模型（3DeepRep），通过在所有三个HSI张量模式上执行深度非线性变换，显著提升了高光谱图像修复性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常仅限制变换在光谱模式上，忽略了其他张量模式的低秩特性，限制了修复效果。

Method: 提出3DeepRep模型，通过三方向TNN正则化，最小化每个方向潜在空间中模式-i正面切片的核范数，并通过可学习聚合模块融合结果。

Result: 在真实HSI数据集上的实验表明，该方法在定性和定量上均优于现有技术。

Conclusion: 3DeepRep模型通过多方向深度变换和低秩约束，显著提升了高光谱图像修复的性能。

Abstract: Recent approaches based on transform-based tensor nuclear norm (TNN) have
demonstrated notable effectiveness in hyperspectral image (HSI) inpainting by
leveraging low-rank structures in latent representations. Recent developments
incorporate deep transforms to improve low-rank tensor representation; however,
existing approaches typically restrict the transform to the spectral mode,
neglecting low-rank properties along other tensor modes. In this paper, we
propose a novel 3-directional deep low-rank tensor representation (3DeepRep)
model, which performs deep nonlinear transforms along all three modes of the
HSI tensor. To enforce low-rankness, the model minimizes the nuclear norms of
mode-i frontal slices in the corresponding latent space for each direction
(i=1,2,3), forming a 3-directional TNN regularization. The outputs from the
three directional branches are subsequently fused via a learnable aggregation
module to produce the final result. An efficient gradient-based optimization
algorithm is developed to solve the model in a self-supervised manner.
Extensive experiments on real-world HSI datasets demonstrate that the proposed
method achieves superior inpainting performance compared to existing
state-of-the-art techniques, both qualitatively and quantitatively.

</details>


### [150] [Cross-modal Offset-guided Dynamic Alignment and Fusion for Weakly Aligned UAV Object Detection](https://arxiv.org/abs/2506.16737)
*Liu Zongzhen,Luo Hui,Wang Zhixing,Wei Yuxing,Zuo Haorui,Zhang Jianlin*

Main category: cs.CV

TL;DR: 论文提出了一种名为CoDAF的统一框架，通过联合解决弱对齐无人机目标检测中的语义不一致和模态冲突问题，提高了检测的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 无人机目标检测在环境监测和城市安全中至关重要，但多模态检测中因运动和非同步成像导致的空间错位问题限制了现有方法的有效性。

Method: CoDAF框架包含两个模块：OSA模块通过估计空间偏移和使用可变形卷积对齐特征；DAFM模块通过门控和双注意力机制自适应融合模态特征。

Result: 在DroneVehicle数据集上，CoDAF实现了78.6%的mAP。

Conclusion: CoDAF通过统一设计解决了弱对齐问题，显著提升了无人机目标检测的性能。

Abstract: Unmanned aerial vehicle (UAV) object detection plays a vital role in
applications such as environmental monitoring and urban security. To improve
robustness, recent studies have explored multimodal detection by fusing visible
(RGB) and infrared (IR) imagery. However, due to UAV platform motion and
asynchronous imaging, spatial misalignment frequently occurs between
modalities, leading to weak alignment. This introduces two major challenges:
semantic inconsistency at corresponding spatial locations and modality conflict
during feature fusion. Existing methods often address these issues in
isolation, limiting their effectiveness. In this paper, we propose Cross-modal
Offset-guided Dynamic Alignment and Fusion (CoDAF), a unified framework that
jointly tackles both challenges in weakly aligned UAV-based object detection.
CoDAF comprises two novel modules: the Offset-guided Semantic Alignment (OSA),
which estimates attention-based spatial offsets and uses deformable convolution
guided by a shared semantic space to align features more precisely; and the
Dynamic Attention-guided Fusion Module (DAFM), which adaptively balances
modality contributions through gating and refines fused features via
spatial-channel dual attention. By integrating alignment and fusion in a
unified design, CoDAF enables robust UAV object detection. Experiments on
standard benchmarks validate the effectiveness of our approach, with CoDAF
achieving a mAP of 78.6% on the DroneVehicle dataset.

</details>


### [151] [Uncertainty-Aware Variational Information Pursuit for Interpretable Medical Image Analysis](https://arxiv.org/abs/2506.16742)
*Md Nahiduzzaman,Ruwan Tennakoon,Steven Korevaar,Zongyuan Ge,Alireza Bab-Hadiashar*

Main category: cs.CV

TL;DR: 论文提出了一种不确定性感知的V-IP框架（UAV-IP），在医疗影像中提升AI决策的准确性和可解释性，同时量化不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有V-IP方法忽略了查询-答案生成中的实例级不确定性，影响了AI决策的可靠性和临床实用性。

Method: 引入UAV-IP框架，将不确定性量化融入V-IP过程，评估其在四个医疗影像数据集上的表现。

Result: UAV-IP在AUC上平均提升3.2%，生成更简洁的解释（减少20%），且不损失信息量。

Conclusion: 不确定性感知推理对可解释性设计模型在医疗决策中的稳健性和可靠性至关重要。

Abstract: In medical imaging, AI decision-support systems must balance accuracy and
interpretability to build user trust and support effective clinical
decision-making. Recently, Variational Information Pursuit (V-IP) and its
variants have emerged as interpretable-by-design modeling techniques, aiming to
explain AI decisions in terms of human-understandable, clinically relevant
concepts. However, existing V-IP methods overlook instance-level uncertainties
in query-answer generation, which can arise from model limitations (epistemic
uncertainty) or variability in expert responses (aleatoric uncertainty).
  This paper introduces Uncertainty-Aware V-IP (UAV-IP), a novel framework that
integrates uncertainty quantification into the V-IP process. We evaluate UAV-IP
across four medical imaging datasets, PH2, Derm7pt, BrEaST, and SkinCon,
demonstrating an average AUC improvement of approximately 3.2% while generating
20% more concise explanations compared to baseline V-IP, without sacrificing
informativeness. These findings highlight the importance of uncertainty-aware
reasoning in interpretable by design models for robust and reliable medical
decision-making.

</details>


### [152] [Noise-Informed Diffusion-Generated Image Detection with Anomaly Attention](https://arxiv.org/abs/2506.16743)
*Weinan Guan,Wei Wang,Bo Peng,Ziwen He,Jing Dong,Haonan Cheng*

Main category: cs.CV

TL;DR: 论文提出了一种基于噪声感知自注意力模块（NASA）的检测方法，用于识别扩散模型生成的图像，特别针对训练中未见的模型。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型生成图像质量的提升，信息安全隐患增加，现有检测方法难以泛化到未见过的扩散模型。

Method: 利用扩散模型生成图像的噪声模式相似性，设计了NASA模块，结合Swin Transformer构建NASA-Swin架构，并采用跨模态融合嵌入和通道掩码策略。

Result: 实验表明，该方法在检测未见过的扩散模型生成图像时表现优异，达到SOTA性能。

Conclusion: NASA-Swin通过噪声模式分析和跨模态学习，显著提升了检测泛化能力，为信息防伪提供了有效工具。

Abstract: With the rapid development of image generation technologies, especially the
advancement of Diffusion Models, the quality of synthesized images has
significantly improved, raising concerns among researchers about information
security. To mitigate the malicious abuse of diffusion models,
diffusion-generated image detection has proven to be an effective
countermeasure.However, a key challenge for forgery detection is generalising
to diffusion models not seen during training. In this paper, we address this
problem by focusing on image noise. We observe that images from different
diffusion models share similar noise patterns, distinct from genuine images.
Building upon this insight, we introduce a novel Noise-Aware Self-Attention
(NASA) module that focuses on noise regions to capture anomalous patterns. To
implement a SOTA detection model, we incorporate NASA into Swin Transformer,
forming an novel detection architecture NASA-Swin. Additionally, we employ a
cross-modality fusion embedding to combine RGB and noise images, along with a
channel mask strategy to enhance feature learning from both modalities.
Extensive experiments demonstrate the effectiveness of our approach in
enhancing detection capabilities for diffusion-generated images. When
encountering unseen generation methods, our approach achieves the
state-of-the-art performance.Our code is available at
https://github.com/WeinanGuan/NASA-Swin.

</details>


### [153] [Class Agnostic Instance-level Descriptor for Visual Instance Search](https://arxiv.org/abs/2506.16745)
*Qi-Ying Sun,Wan-Lei Zhao,Yi-Bo Miao,Chong-Wah Ngo*

Main category: cs.CV

TL;DR: 本文提出了一种基于自监督ViT的分层特征子集检测方法，用于解决视觉实例搜索中的实例级特征表示问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 视觉实例搜索因缺乏有效的实例级特征表示而具有挑战性，传统监督或弱监督方法对未知类别表现不佳。

Method: 利用自监督ViT输出的特征集，通过分层方式检测紧凑特征子集，生成多语义尺度的实例区域层次结构。

Result: 在三个实例搜索基准测试中，该方法显著优于现有技术，对已知和未知类别均有效。

Conclusion: 分层分解方法有效解决了对象嵌入和遮挡问题，为图像中的潜在实例提供了全面的表示。

Abstract: Despite the great success of the deep features in content-based image
retrieval, the visual instance search remains challenging due to the lack of
effective instance level feature representation. Supervised or weakly
supervised object detection methods are not among the options due to their poor
performance on the unknown object categories. In this paper, based on the
feature set output from self-supervised ViT, the instance level region
discovery is modeled as detecting the compact feature subsets in a hierarchical
fashion. The hierarchical decomposition results in a hierarchy of feature
subsets. The non-leaf nodes and leaf nodes on the hierarchy correspond to the
various instance regions in an image of different semantic scales. The
hierarchical decomposition well addresses the problem of object embedding and
occlusions, which are widely observed in the real scenarios. The features
derived from the nodes on the hierarchy make up a comprehensive representation
for the latent instances in the image. Our instance-level descriptor remains
effective on both the known and unknown object categories. Empirical studies on
three instance search benchmarks show that it outperforms state-of-the-art
methods considerably.

</details>


### [154] [Infrared and Visible Image Fusion Based on Implicit Neural Representations](https://arxiv.org/abs/2506.16773)
*Shuchen Sun,Ligen Shi,Chang Liu,Lina Wu,Jun Qiu*

Main category: cs.CV

TL;DR: 本文提出了一种基于隐式神经表示（INR）的红外与可见光图像融合方法INRFuse，通过神经网络参数化连续函数，突破传统依赖离散像素或显式特征的局限，实现多模态信息的自适应融合。


<details>
  <summary>Details</summary>
Motivation: 红外与可见光图像融合旨在结合两种模态的优势，生成信息丰富且满足视觉或计算需求的图像。传统方法依赖离散像素或显式特征，限制了融合效果。

Method: 利用归一化空间坐标作为输入，通过多层感知机自适应融合两种模态的特征，设计多损失函数联合优化融合图像与原图像的相似性。

Result: 实验结果表明，INRFuse在主观视觉质量和客观评价指标上均优于现有方法，融合图像结构清晰、细节自然、信息丰富，且无需训练数据集。

Conclusion: INRFuse通过INR的分辨率无关特性，实现了不同分辨率图像的直接融合及超分辨率重建，为多模态图像融合提供了新思路。

Abstract: Infrared and visible light image fusion aims to combine the strengths of both
modalities to generate images that are rich in information and fulfill visual
or computational requirements. This paper proposes an image fusion method based
on Implicit Neural Representations (INR), referred to as INRFuse. This method
parameterizes a continuous function through a neural network to implicitly
represent the multimodal information of the image, breaking through the
traditional reliance on discrete pixels or explicit features. The normalized
spatial coordinates of the infrared and visible light images serve as inputs,
and multi-layer perceptrons is utilized to adaptively fuse the features of both
modalities, resulting in the output of the fused image. By designing multiple
loss functions, the method jointly optimizes the similarity between the fused
image and the original images, effectively preserving the thermal radiation
information of the infrared image while maintaining the texture details of the
visible light image. Furthermore, the resolution-independent characteristic of
INR allows for the direct fusion of images with varying resolutions and
achieves super-resolution reconstruction through high-density coordinate
queries. Experimental results indicate that INRFuse outperforms existing
methods in both subjective visual quality and objective evaluation metrics,
producing fused images with clear structures, natural details, and rich
information without the necessity for a training dataset.

</details>


### [155] [PQCAD-DM: Progressive Quantization and Calibration-Assisted Distillation for Extremely Efficient Diffusion Model](https://arxiv.org/abs/2506.16776)
*Beomseok Ko,Hyeryung Jang*

Main category: cs.CV

TL;DR: PQCAD-DM是一种结合渐进量化（PQ）和校准辅助蒸馏（CAD）的混合压缩框架，旨在解决扩散模型的计算和资源消耗问题，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成中表现出色，但依赖迭代马尔可夫链过程导致计算和资源密集，且误差累积限制了压缩技术的效果。

Method: PQ采用两阶段量化，通过动量机制自适应调整位宽，减少低精度下的权重扰动；CAD利用全精度校准数据集在蒸馏过程中提升学生模型的性能。

Result: PQCAD-DM在计算效率和生成质量之间取得平衡，推理时间减半，同时保持竞争力。

Conclusion: PQCAD-DM在多种数据集上验证了其优越的生成能力和效率，优于固定位宽量化方法。

Abstract: Diffusion models excel in image generation but are computational and
resource-intensive due to their reliance on iterative Markov chain processes,
leading to error accumulation and limiting the effectiveness of naive
compression techniques. In this paper, we propose PQCAD-DM, a novel hybrid
compression framework combining Progressive Quantization (PQ) and
Calibration-Assisted Distillation (CAD) to address these challenges. PQ employs
a two-stage quantization with adaptive bit-width transitions guided by a
momentum-based mechanism, reducing excessive weight perturbations in
low-precision. CAD leverages full-precision calibration datasets during
distillation, enabling the student to match full-precision performance even
with a quantized teacher. As a result, PQCAD-DM achieves a balance between
computational efficiency and generative quality, halving inference time while
maintaining competitive performance. Extensive experiments validate PQCAD-DM's
superior generative capabilities and efficiency across diverse datasets,
outperforming fixed-bit quantization methods.

</details>


### [156] [TextBraTS: Text-Guided Volumetric Brain Tumor Segmentation with Innovative Dataset Development and Fusion Module Exploration](https://arxiv.org/abs/2506.16784)
*Xiaoyu Shi,Rahul Kumar Jain,Yinhao Li,Ruibo Hou,Jingliang Cheng,Jie Bai,Guohua Zhao,Lanfen Lin,Rui Xu,Yen-wei Chen*

Main category: cs.CV

TL;DR: 论文介绍了首个公开的多模态数据集TextBraTS，结合MRI和文本注释，并提出了一种新的文本引导医学图像分割方法，显著提高了脑肿瘤分割的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有脑肿瘤分析领域缺乏结合影像和文本注释的综合数据集，限制了多模态方法的研究。

Method: 提出TextBraTS数据集，并设计了一种基于序列交叉注意力的文本引导体积医学图像分割框架。

Result: 实验表明，该方法显著提高了脑肿瘤分割的准确性，并提供了多模态融合的有效见解。

Conclusion: TextBraTS数据集和提出的方法为多模态脑肿瘤分析提供了重要资源和技术支持。

Abstract: Deep learning has demonstrated remarkable success in medical image
segmentation and computer-aided diagnosis. In particular, numerous advanced
methods have achieved state-of-the-art performance in brain tumor segmentation
from MRI scans. While recent studies in other medical imaging domains have
revealed that integrating textual reports with visual data can enhance
segmentation accuracy, the field of brain tumor analysis lacks a comprehensive
dataset that combines radiological images with corresponding textual
annotations. This limitation has hindered the exploration of multimodal
approaches that leverage both imaging and textual data.
  To bridge this critical gap, we introduce the TextBraTS dataset, the first
publicly available volume-level multimodal dataset that contains paired MRI
volumes and rich textual annotations, derived from the widely adopted BraTS2020
benchmark. Building upon this novel dataset, we propose a novel baseline
framework and sequential cross-attention method for text-guided volumetric
medical image segmentation. Through extensive experiments with various
text-image fusion strategies and templated text formulations, our approach
demonstrates significant improvements in brain tumor segmentation accuracy,
offering valuable insights into effective multimodal integration techniques.
  Our dataset, implementation code, and pre-trained models are publicly
available at https://github.com/Jupitern52/TextBraTS.

</details>


### [157] [RealSR-R1: Reinforcement Learning for Real-World Image Super-Resolution with Vision-Language Chain-of-Thought](https://arxiv.org/abs/2506.16796)
*Junbo Qiao,Miaomiao Cai,Wei Li,Yutong Liu,Xudong Huang,Gaoqi He,Jiao Xie,Jie Hu,Xinghao Chen,Shaohui Lin*

Main category: cs.CV

TL;DR: RealSR-R1提出了一种结合视觉与语言推理的VLCoT框架，通过模拟人类处理退化图像的过程，提升图像超分辨率任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在理解退化图像内容时表现不佳，导致重建结果低保真且不自然。

Method: 提出VLCoT框架，结合Chain of Thought思想，并引入Group Relative Policy Optimization（GRPO）和四种奖励函数。

Result: 实验证明RealSR-R1能生成更真实的细节，尤其在语义丰富或严重退化的场景中表现优异。

Conclusion: VLCoT-GRPO框架有效提升了图像超分辨率的性能，特别是在复杂场景下的表现。

Abstract: Real-World Image Super-Resolution is one of the most challenging task in
image restoration. However, existing methods struggle with an accurate
understanding of degraded image content, leading to reconstructed results that
are both low-fidelity and unnatural. We present RealSR-R1 in this work, which
empowers the RealSR models with understanding and reasoning capabilities.
Inspired by the success of Chain of Thought (CoT) in large language models
(LLMs), we simulate the human process of handling degraded images and propose
the VLCoT framework, which integrates vision and language reasoning. The
framework aims to precisely restore image details by progressively generating
more comprehensive text and higher-resolution images. To overcome the challenge
of traditional supervised learning CoT failing to generalize to real-world
scenarios, we introduce, for the first time, Group Relative Policy Optimization
(GRPO) into the Real-World Image Super-Resolution task. We propose VLCoT-GRPO
as a solution, which designs four reward functions: (1) Format reward, used to
standardize the CoT process; (2) Degradation reward, to incentivize accurate
degradation estimation; (3) Understanding reward, to ensure the accuracy of the
generated content; and (4) Generation reward, where we propose using a visual
expert model to evaluate the quality of generated images, encouraging the model
to generate more realistic images. Extensive experiments demonstrate that our
proposed RealSR-R1 can generate realistic details and accurately understand
image content, particularly in semantically rich scenes or images with severe
degradation.

</details>


### [158] [Seeing What Matters: Generalizable AI-generated Video Detection with Forensic-Oriented Augmentation](https://arxiv.org/abs/2506.16802)
*Riccardo Corvi,Davide Cozzolino,Ekta Prashnani,Shalini De Mello,Koki Nagano,Luisa Verdoliva*

Main category: cs.CV

TL;DR: 提出了一种基于小波分解的数据增强策略，通过引导检测器关注生成视频的低级伪影而非高级语义缺陷，显著提升了AI生成视频检测器的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频伪造检测器泛化能力差，难以适应真实场景。研究旨在通过关注生成架构引入的低级伪影而非模型特定的高级缺陷，提升检测器的实用性。

Method: 研究不同生成架构，识别共享的判别特征；提出基于小波分解的数据增强策略，替换特定频带以引导模型利用更相关的取证线索。

Result: 在仅使用单一生成模型数据训练的情况下，检测器对多种其他模型生成的视频表现出显著改进的准确性，优于现有技术。

Conclusion: 该方法通过简单且高效的方式提升了检测器的泛化能力，适用于多种最新生成模型，如NOVA和FLUX。

Abstract: Synthetic video generation is progressing very rapidly. The latest models can
produce very realistic high-resolution videos that are virtually
indistinguishable from real ones. Although several video forensic detectors
have been recently proposed, they often exhibit poor generalization, which
limits their applicability in a real-world scenario. Our key insight to
overcome this issue is to guide the detector towards seeing what really
matters. In fact, a well-designed forensic classifier should focus on
identifying intrinsic low-level artifacts introduced by a generative
architecture rather than relying on high-level semantic flaws that characterize
a specific model. In this work, first, we study different generative
architectures, searching and identifying discriminative features that are
unbiased, robust to impairments, and shared across models. Then, we introduce a
novel forensic-oriented data augmentation strategy based on the wavelet
decomposition and replace specific frequency-related bands to drive the model
to exploit more relevant forensic cues. Our novel training paradigm improves
the generalizability of AI-generated video detectors, without the need for
complex algorithms and large datasets that include multiple synthetic
generators. To evaluate our approach, we train the detector using data from a
single generative model and test it against videos produced by a wide range of
other models. Despite its simplicity, our method achieves a significant
accuracy improvement over state-of-the-art detectors and obtains excellent
results even on very recent generative models, such as NOVA and FLUX. Code and
data will be made publicly available.

</details>


### [159] [Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes](https://arxiv.org/abs/2506.16805)
*Chao Chen,Nobel Dang,Juexiao Zhang,Wenkai Sun,Pengfei Zheng,Xuhang He,Yimeng Ye,Taarun Srinivas,Chen Feng*

Main category: cs.CV

TL;DR: 论文提出了Co-VisiON基准，用于评估稀疏图像集中的共视性推理能力，发现现有视觉模型在此任务上表现不佳，尤其是与人类相比。作者提出了一种新方法Covis，缩小了与专有视觉语言模型的差距。


<details>
  <summary>Details</summary>
Motivation: 研究人类在复杂场景中识别共视性的能力，并评估当前视觉模型是否达到人类水平。

Method: 引入Co-VisiON基准，测试稀疏图像集的共视性推理；提出多视图基线方法Covis。

Result: 专有视觉语言模型表现最佳，但所有模型均远低于人类水平；Covis在纯视觉模型中表现最优。

Conclusion: 共视性推理需要高层次的空间理解，未来需开发更强大的视觉模型以应对稀疏环境。

Abstract: Humans exhibit a remarkable ability to recognize co-visibility-the
overlapping regions visible in multiple images-even when these images are
sparsely distributed across a complex scene. This capability is foundational in
3D vision and robotic perception. Despite significant progress in vision
learning, it remains unclear whether current vision models have reached
human-level proficiency in co-visibility analysis. In this work, we introduce
the Co-Visibility reasONing (Co-VisiON) benchmark, designed to directly
evaluate co-visibility reasoning on sparse image sets across over 1000 indoor
scenarios. Our experiments reveal that while co-visibility is typically treated
as a low-level feature matching task, it poses a significant challenge for
existing vision models under sparse conditions. Notably, a proprietary
vision-language model outperforms all purely vision-based approaches, with all
models lagging substantially behind human performance. This gap underscores the
need for more than basic pairwise vision processing-it calls for a
comprehensive spatial understanding through high-level reasoning across
multiple views. Inspired by human visual cognition, we propose a novel
multi-view baseline, Covis, which achieves top performance among pure vision
models and narrows the gap to the proprietary VLM. We hope our benchmark and
findings will spur further advancements in developing vision models capable of
robust, high-level reasoning in challenging, sparse environments. Our dataset
and source code can be found at: https://ai4ce.github.io/CoVISION

</details>


### [160] [FOCUS: Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation](https://arxiv.org/abs/2506.16806)
*Fan Yang,Yousong Zhu,Xin Li,Yufei Zhan,Hongyin Zhao,Shurong Zheng,Yaowei Wang,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: FOCUS是一个统一的大型视觉语言模型，通过端到端框架整合分割感知和可控对象生成，显著提升多模态任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法将视觉理解和生成任务分离，依赖多个独立模型，导致效率低下。FOCUS旨在统一这些任务，提升性能。

Method: 采用双分支视觉编码器捕获全局和局部信息，结合MoVQGAN视觉标记器和多阶段训练策略，优化分割与生成。

Result: 在多项任务中表现优异，包括多模态理解、参考分割和可控图像生成。

Conclusion: FOCUS通过统一框架有效整合视觉感知与生成能力，为多模态任务提供高效解决方案。

Abstract: Recent Large Vision Language Models (LVLMs) demonstrate promising
capabilities in unifying visual understanding and generative modeling, enabling
both accurate content understanding and flexible editing. However, current
approaches treat "what to see" and "how to edit" separately: they either
perform isolated object segmentation or utilize segmentation masks merely as
conditional prompts for local edit generation tasks, often relying on multiple
disjointed models. To bridge these gaps, we introduce FOCUS, a unified LVLM
that integrates segmentation-aware perception and controllable object-centric
generation within an end-to-end framework. FOCUS employs a dual-branch visual
encoder to simultaneously capture global semantic context and fine-grained
spatial details. In addition, we leverage a MoVQGAN-based visual tokenizer to
produce discrete visual tokens that enhance generation quality. To enable
accurate and controllable image editing, we propose a progressive multi-stage
training pipeline, where segmentation masks are jointly optimized and used as
spatial condition prompts to guide the diffusion decoder. This strategy aligns
visual encoding, segmentation, and generation modules, effectively bridging
segmentation-aware perception with fine-grained visual synthesis. Extensive
experiments across three core tasks, including multimodal understanding,
referring segmentation accuracy, and controllable image generation, demonstrate
that FOCUS achieves strong performance by jointly optimizing visual perception
and generative capabilities.

</details>


### [161] [Loupe: A Generalizable and Adaptive Framework for Image Forgery Detection](https://arxiv.org/abs/2506.16819)
*Yuchu Jiang,Jiaming Chu,Jian Zhao,Xin Zhang,Xu Yang,Lei Jin,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: Loupe是一个轻量级框架，用于联合深度伪造检测和定位，通过整合补丁感知分类器和分割模块，实现了全局分类和细粒度掩码预测，并在测试时引入伪标签引导机制提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 生成模型的普及引发了视觉内容伪造的严重问题，现有方法在泛化性或架构复杂性上存在局限。

Method: Loupe整合补丁感知分类器和条件查询的分割模块，引入伪标签引导的测试时适应机制。

Result: 在DDL数据集上表现优异，IJCAI 2025挑战赛中总分0.846，排名第一。

Conclusion: Loupe通过补丁级融合和条件查询设计，显著提升了分类和定位的准确性。

Abstract: The proliferation of generative models has raised serious concerns about
visual content forgery. Existing deepfake detection methods primarily target
either image-level classification or pixel-wise localization. While some
achieve high accuracy, they often suffer from limited generalization across
manipulation types or rely on complex architectures. In this paper, we propose
Loupe, a lightweight yet effective framework for joint deepfake detection and
localization. Loupe integrates a patch-aware classifier and a segmentation
module with conditional queries, allowing simultaneous global authenticity
classification and fine-grained mask prediction. To enhance robustness against
distribution shifts of test set, Loupe introduces a pseudo-label-guided
test-time adaptation mechanism by leveraging patch-level predictions to
supervise the segmentation head. Extensive experiments on the DDL dataset
demonstrate that Loupe achieves state-of-the-art performance, securing the
first place in the IJCAI 2025 Deepfake Detection and Localization Challenge
with an overall score of 0.846. Our results validate the effectiveness of the
proposed patch-level fusion and conditional query design in improving both
classification accuracy and spatial localization under diverse forgery
patterns. The code is available at https://github.com/Kamichanw/Loupe.

</details>


### [162] [Self-supervised Feature Extraction for Enhanced Ball Detection on Soccer Robots](https://arxiv.org/abs/2506.16821)
*Can Lin,Daniele Affinita,Marco E. P. Zimmatore,Daniele Nardi,Domenico D. Bloisi,Vincenzo Suriani*

Main category: cs.CV

TL;DR: 提出一种自监督学习框架，用于提升足球机器人球体检测性能，减少对人工标注的依赖。


<details>
  <summary>Details</summary>
Motivation: 传统监督方法需要大量人工标注，成本高且耗时，因此提出自监督学习框架以解决这一问题。

Method: 利用预训练模型生成伪标签，通过自监督任务（如着色、边缘检测和三元组损失）学习鲁棒特征，并结合MAML策略快速适应新场景。

Result: 实验表明，该方法在准确性、F1分数和IoU上优于基线模型，且收敛更快。

Conclusion: 自监督学习框架能有效提升球体检测性能，减少对人工标注的依赖，适用于动态环境。

Abstract: Robust and accurate ball detection is a critical component for autonomous
humanoid soccer robots, particularly in dynamic and challenging environments
such as RoboCup outdoor fields. However, traditional supervised approaches
require extensive manual annotation, which is costly and time-intensive. To
overcome this problem, we present a self-supervised learning framework for
domain-adaptive feature extraction to enhance ball detection performance. The
proposed approach leverages a general-purpose pretrained model to generate
pseudo-labels, which are then used in a suite of self-supervised pretext tasks
-- including colorization, edge detection, and triplet loss -- to learn robust
visual features without relying on manual annotations. Additionally, a
model-agnostic meta-learning (MAML) strategy is incorporated to ensure rapid
adaptation to new deployment scenarios with minimal supervision. A new dataset
comprising 10,000 labeled images from outdoor RoboCup SPL matches is
introduced, used to validate the method, and made available to the community.
Experimental results demonstrate that the proposed pipeline outperforms
baseline models in terms of accuracy, F1 score, and IoU, while also exhibiting
faster convergence.

</details>


### [163] [AnyTraverse: An off-road traversability framework with VLM and human operator in the loop](https://arxiv.org/abs/2506.16826)
*Sattwik Sahu,Agamdeep Singh,Karthik Nambiar,Srikanth Saripalli,P. B. Sujit*

Main category: cs.CV

TL;DR: AnyTraverse是一个结合自然语言提示和人工辅助的框架，用于分割不同机器人车辆的可导航区域，减少主动监督需求并适应多变环境。


<details>
  <summary>Details</summary>
Motivation: 当前框架在非结构化环境中表现不佳，且无法适应不同类型的机器人。AnyTraverse旨在解决这些问题。

Method: 结合自然语言提示和人工辅助，仅在遇到未知场景时调用操作员，采用零样本学习方法。

Result: 在多个数据集和机器人平台上验证，性能优于GA-NAV和Off-seg，提供车辆无关的解决方案。

Conclusion: AnyTraverse在自动化与人工监督之间取得平衡，适用于多变户外场景。

Abstract: Off-road traversability segmentation enables autonomous navigation with
applications in search-and-rescue, military operations, wildlife exploration,
and agriculture. Current frameworks struggle due to significant variations in
unstructured environments and uncertain scene changes, and are not adaptive to
be used for different robot types. We present AnyTraverse, a framework
combining natural language-based prompts with human-operator assistance to
determine navigable regions for diverse robotic vehicles. The system segments
scenes for a given set of prompts and calls the operator only when encountering
previously unexplored scenery or unknown class not part of the prompt in its
region-of-interest, thus reducing active supervision load while adapting to
varying outdoor scenes. Our zero-shot learning approach eliminates the need for
extensive data collection or retraining. Our experimental validation includes
testing on RELLIS-3D, Freiburg Forest, and RUGD datasets and demonstrate
real-world deployment on multiple robot platforms. The results show that
AnyTraverse performs better than GA-NAV and Off-seg while offering a
vehicle-agnostic approach to off-road traversability that balances automation
with targeted human supervision.

</details>


### [164] [Camera Calibration via Circular Patterns: A Comprehensive Framework with Measurement Uncertainty and Unbiased Projection Model](https://arxiv.org/abs/2506.16842)
*Chaehyeon Song,Dongjae Lee,Jongwoo Lim,Ayoung Kim*

Main category: cs.CV

TL;DR: 论文提出了一种无偏的圆形标靶投影模型，解决了现有模型在镜头畸变下的偏差问题，并通过引入不确定性提高了标定的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有圆形标靶的投影模型在镜头畸变下存在偏差，导致标定性能不佳，需要改进以提高精度和鲁棒性。

Method: 提出无偏的圆形标靶投影模型，引入不确定性，并通过马尔可夫随机场建模边界点，利用格林定理传播形状分布到质心不确定性。

Result: 新框架显著提高了标定精度和鲁棒性，优于传统的棋盘格标定方法。

Conclusion: 该方法为相机标定提供了更准确和鲁棒的解决方案，并提供了基于评估指标的标定指南。

Abstract: Camera calibration using planar targets has been widely favored, and two
types of control points have been mainly considered as measurements: the
corners of the checkerboard and the centroid of circles. Since a centroid is
derived from numerous pixels, the circular pattern provides more precise
measurements than the checkerboard. However, the existing projection model of
circle centroids is biased under lens distortion, resulting in low performance.
To surmount this limitation, we propose an unbiased projection model of the
circular pattern and demonstrate its superior accuracy compared to the
checkerboard. Complementing this, we introduce uncertainty into circular
patterns to enhance calibration robustness and completeness. Defining centroid
uncertainty improves the performance of calibration components, including
pattern detection, optimization, and evaluation metrics. We also provide
guidelines for performing good camera calibration based on the evaluation
metric. The core concept of this approach is to model the boundary points of a
two-dimensional shape as a Markov random field, considering its connectivity.
The shape distribution is propagated to the centroid uncertainty through an
appropriate shape representation based on the Green theorem. Consequently, the
resulting framework achieves marked gains in calibration accuracy and
robustness. The complete source code and demonstration video are available at
https://github.com/chaehyeonsong/discocal.

</details>


### [165] [Controllable and Expressive One-Shot Video Head Swapping](https://arxiv.org/abs/2506.16852)
*Chaonan Ji,Jinwei Qi,Peng Zhang,Bang Zhang,Liefeng Bo*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的多条件可控视频头部替换框架，能够将静态图像中的头部无缝移植到动态视频中，并支持调整头部表情和动作。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注局部面部替换，忽略了整体头部形态，且无法在替换后修改表情。本文旨在解决这些问题。

Method: 采用统一的潜在扩散范式，包括身份保留上下文融合和表情感知地标重定向与编辑模块。

Result: 实验结果表明，该方法在背景无缝融合和表情传递方面表现优异。

Conclusion: 该方法在保留源肖像身份的同时，实现了高质量的表情传递和背景融合。

Abstract: In this paper, we propose a novel diffusion-based multi-condition
controllable framework for video head swapping, which seamlessly transplant a
human head from a static image into a dynamic video, while preserving the
original body and background of target video, and further allowing to tweak
head expressions and movements during swapping as needed. Existing
face-swapping methods mainly focus on localized facial replacement neglecting
holistic head morphology, while head-swapping approaches struggling with
hairstyle diversity and complex backgrounds, and none of these methods allow
users to modify the transplanted head expressions after swapping. To tackle
these challenges, our method incorporates several innovative strategies through
a unified latent diffusion paradigm. 1) Identity-preserving context fusion: We
propose a shape-agnostic mask strategy to explicitly disentangle foreground
head identity features from background/body contexts, combining hair
enhancement strategy to achieve robust holistic head identity preservation
across diverse hair types and complex backgrounds. 2) Expression-aware landmark
retargeting and editing: We propose a disentangled 3DMM-driven retargeting
module that decouples identity, expression, and head poses, minimizing the
impact of original expressions in input images and supporting expression
editing. While a scale-aware retargeting strategy is further employed to
minimize cross-identity expression distortion for higher transfer precision.
Experimental results demonstrate that our method excels in seamless background
integration while preserving the identity of the source portrait, as well as
showcasing superior expression transfer capabilities applicable to both real
and virtual characters.

</details>


### [166] [ParkFormer: A Transformer-Based Parking Policy with Goal Embedding and Pedestrian-Aware Control](https://arxiv.org/abs/2506.16856)
*Jun Fu,Bin Tian,Haonan Chen,Shi Meng,Tingting Yao*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的端到端自主泊车框架，通过学习专家演示实现高精度控制，在模拟环境中验证了其高效性和安全性。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的泊车系统在复杂环境中适应性差，而人类驾驶员能直观泊车，因此提出一种学习人类驾驶行为的智能框架。

Method: 采用Transformer网络，输入包括环视摄像头图像、目标点表示、车辆运动和行人轨迹，输出离散控制序列。引入交叉注意力模块和GRU行人预测器。

Result: 在CARLA模拟器中测试，成功率达96.57%，平均位置误差0.21米，方向误差0.41度。

Conclusion: 该方法在复杂泊车场景中表现优异，关键模块如行人预测和目标点注意力融合效果显著。

Abstract: Autonomous parking plays a vital role in intelligent vehicle systems,
particularly in constrained urban environments where high-precision control is
required. While traditional rule-based parking systems struggle with
environmental uncertainties and lack adaptability in crowded or dynamic scenes,
human drivers demonstrate the ability to park intuitively without explicit
modeling. Inspired by this observation, we propose a Transformer-based
end-to-end framework for autonomous parking that learns from expert
demonstrations. The network takes as input surround-view camera images,
goal-point representations, ego vehicle motion, and pedestrian trajectories. It
outputs discrete control sequences including throttle, braking, steering, and
gear selection. A novel cross-attention module integrates BEV features with
target points, and a GRU-based pedestrian predictor enhances safety by modeling
dynamic obstacles. We validate our method on the CARLA 0.9.14 simulator in both
vertical and parallel parking scenarios. Experiments show our model achieves a
high success rate of 96.57\%, with average positional and orientation errors of
0.21 meters and 0.41 degrees, respectively. The ablation studies further
demonstrate the effectiveness of key modules such as pedestrian prediction and
goal-point attention fusion. The code and dataset will be released at:
https://github.com/little-snail-f/ParkFormer.

</details>


### [167] [With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You](https://arxiv.org/abs/2506.16895)
*Fabian Gröger,Shuo Wen,Huyen Le,Maria Brbić*

Main category: cs.CV

TL;DR: 本文提出了一种在有限配对数据下构建多模态模型的方法，通过对齐预训练的单模态基础模型，仅需少量样本即可实现高质量对齐。


<details>
  <summary>Details</summary>
Motivation: 现有多模态模型依赖大量配对数据，但在许多领域获取成本高昂或不可行，因此探索在有限数据下构建高效模型的方法。

Method: 引入STRUCTURE正则化技术，保持单模态编码器潜在空间的邻域几何结构，并优化对齐层选择，选择跨模态表示相似性最高的层进行对齐。

Result: 在24个零样本图像分类和检索基准测试中，平均相对提升51.6%（分类）和91.8%（检索）。

Conclusion: 该方法为资源受限领域的多模态学习提供了高效且广泛适用的框架。

Abstract: Multimodal models have demonstrated powerful capabilities in complex tasks
requiring multimodal alignment including zero-shot classification and
cross-modal retrieval. However, existing models typically rely on millions of
paired multimodal samples, which are prohibitively expensive or infeasible to
obtain in many domains. In this work, we explore the feasibility of building
multimodal models with limited amount of paired data by aligning pretrained
unimodal foundation models. We show that high-quality alignment is possible
with as few as tens of thousands of paired samples$\unicode{x2013}$less than
$1\%$ of the data typically used in the field. To achieve this, we introduce
STRUCTURE, an effective regularization technique that preserves the
neighborhood geometry of the latent space of unimodal encoders. Additionally,
we show that aligning last layers is often suboptimal and demonstrate the
benefits of aligning the layers with the highest representational similarity
across modalities. These two components can be readily incorporated into
existing alignment methods, yielding substantial gains across 24 zero-shot
image classification and retrieval benchmarks, with average relative
improvement of $51.6\%$ in classification and $91.8\%$ in retrieval tasks. Our
results highlight the effectiveness and broad applicability of our framework
for limited-sample multimodal learning and offer a promising path forward for
resource-constrained domains.

</details>


### [168] [LunarLoc: Segment-Based Global Localization on the Moon](https://arxiv.org/abs/2506.16940)
*Annika Thomas,Robaire Galliath,Aleksander Garbuz,Luke Anger,Cormac O'Neill,Trevor Johst,Dami Thomas,George Lordos,Jonathan P. How*

Main category: cs.CV

TL;DR: 论文提出了一种名为LunarLoc的全球定位方法，用于解决月球表面自主操作中的定位问题，通过实例分割提取地标并构建图结构，实现高精度定位。


<details>
  <summary>Details</summary>
Motivation: 由于月球缺乏GPS等导航基础设施，传统视觉惯性里程计（VIO）在长距离任务中会积累误差，因此需要一种无漂移的全球定位方法支持自主任务。

Method: LunarLoc利用实例分割从立体图像中提取地标（如巨石），构建图结构，并通过图论数据关联与参考地图对齐，实现定位。

Result: 实验表明，LunarLoc在多会话全球定位中达到亚厘米级精度，显著优于现有技术。

Conclusion: LunarLoc为月球全球定位提供了一种高效解决方案，并公开了数据集以促进进一步研究。

Abstract: Global localization is necessary for autonomous operations on the lunar
surface where traditional Earth-based navigation infrastructure, such as GPS,
is unavailable. As NASA advances toward sustained lunar presence under the
Artemis program, autonomous operations will be an essential component of tasks
such as robotic exploration and infrastructure deployment. Tasks such as
excavation and transport of regolith require precise pose estimation, but
proposed approaches such as visual-inertial odometry (VIO) accumulate odometry
drift over long traverses. Precise pose estimation is particularly important
for upcoming missions such as the ISRU Pilot Excavator (IPEx) that rely on
autonomous agents to operate over extended timescales and varied terrain. To
help overcome odometry drift over long traverses, we propose LunarLoc, an
approach to global localization that leverages instance segmentation for
zero-shot extraction of boulder landmarks from onboard stereo imagery. Segment
detections are used to construct a graph-based representation of the terrain,
which is then aligned with a reference map of the environment captured during a
previous session using graph-theoretic data association. This method enables
accurate and drift-free global localization in visually ambiguous settings.
LunarLoc achieves sub-cm level accuracy in multi-session global localization
experiments, significantly outperforming the state of the art in lunar global
localization. To encourage the development of further methods for global
localization on the Moon, we release our datasets publicly with a playback
module: https://github.com/mit-acl/lunarloc-data.

</details>


### [169] [LAION-C: An Out-of-Distribution Benchmark for Web-Scale Vision Models](https://arxiv.org/abs/2506.16950)
*Fanfei Li,Thomas Klein,Wieland Brendel,Robert Geirhos,Roland S. Zimmermann*

Main category: cs.CV

TL;DR: 论文提出了LAION-C作为ImageNet-C的替代基准，专门设计用于评估现代大规模网络数据集下的OOD鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基准（如ImageNet-C）的失真类型已不再适用于评估现代网络规模数据集下的OOD鲁棒性，因为模型可能已在训练中接触过这些失真。

Method: 设计了六种新型失真类型（LAION-C），确保其对于网络规模数据集（如LAION）仍为OOD。

Result: LAION-C对当代模型（如Gemini和GPT-4o）构成显著挑战，且最佳模型的OOD泛化能力已接近或超越人类。

Conclusion: LAION-C为评估现代模型的OOD鲁棒性提供了更有效的基准，并揭示了模型在OOD泛化上的范式转变。

Abstract: Out-of-distribution (OOD) robustness is a desired property of computer vision
models. Improving model robustness requires high-quality signals from
robustness benchmarks to quantify progress. While various benchmark datasets
such as ImageNet-C were proposed in the ImageNet era, most ImageNet-C
corruption types are no longer OOD relative to today's large, web-scraped
datasets, which already contain common corruptions such as blur or JPEG
compression artifacts. Consequently, these benchmarks are no longer well-suited
for evaluating OOD robustness in the era of web-scale datasets. Indeed, recent
models show saturating scores on ImageNet-era OOD benchmarks, indicating that
it is unclear whether models trained on web-scale datasets truly become better
at OOD generalization or whether they have simply been exposed to the test
distortions during training. To address this, we introduce LAION-C as a
benchmark alternative for ImageNet-C. LAION-C consists of six novel distortion
types specifically designed to be OOD, even for web-scale datasets such as
LAION. In a comprehensive evaluation of state-of-the-art models, we find that
the LAION-C dataset poses significant challenges to contemporary models,
including MLLMs such as Gemini and GPT-4o. We additionally conducted a
psychophysical experiment to evaluate the difficulty of our corruptions for
human observers, enabling a comparison of models to lab-quality human
robustness data. We observe a paradigm shift in OOD generalization: from humans
outperforming models, to the best models now matching or outperforming the best
human observers.

</details>


### [170] [Visual-Instructed Degradation Diffusion for All-in-One Image Restoration](https://arxiv.org/abs/2506.16960)
*Wenyang Luo,Haina Qin,Zewen Chen,Libin Wang,Dandan Zheng,Yuming Li,Yufan Liu,Bing Li,Weiming Hu*

Main category: cs.CV

TL;DR: Defusion提出了一种基于视觉指令引导降解扩散的全能图像修复框架，能够处理多种或未知的退化类型，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像修复方法通常需要针对每种退化类型设计特定模型，限制了其在混合或未知退化场景中的泛化能力。

Method: Defusion通过构建明确的视觉指令来指导扩散模型，这些指令基于标准化视觉元素的退化特征，与图像语义无关。

Result: 实验表明，Defusion在多样化的图像修复任务中表现优于现有方法，包括复杂和真实世界的退化情况。

Conclusion: Defusion通过视觉指令引导的扩散模型，实现了更稳定和泛化的图像修复能力。

Abstract: Image restoration tasks like deblurring, denoising, and dehazing usually need
distinct models for each degradation type, restricting their generalization in
real-world scenarios with mixed or unknown degradations. In this work, we
propose \textbf{Defusion}, a novel all-in-one image restoration framework that
utilizes visual instruction-guided degradation diffusion. Unlike existing
methods that rely on task-specific models or ambiguous text-based priors,
Defusion constructs explicit \textbf{visual instructions} that align with the
visual degradation patterns. These instructions are grounded by applying
degradations to standardized visual elements, capturing intrinsic degradation
features while agnostic to image semantics. Defusion then uses these visual
instructions to guide a diffusion-based model that operates directly in the
degradation space, where it reconstructs high-quality images by denoising the
degradation effects with enhanced stability and generalizability. Comprehensive
experiments demonstrate that Defusion outperforms state-of-the-art methods
across diverse image restoration tasks, including complex and real-world
degradations.

</details>


### [171] [Reversing Flow for Image Restoration](https://arxiv.org/abs/2506.16961)
*Haina Qin,Wenyang Luo,Libin Wang,Dandan Zheng,Jingdong Chen,Ming Yang,Bing Li,Weiming Hu*

Main category: cs.CV

TL;DR: ResFlow是一种新的图像恢复框架，通过确定性路径建模退化过程，显著提升了性能和速度。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型将退化过程视为随机变换，导致效率低下和复杂性增加。

Method: ResFlow使用连续归一化流建模退化过程，引入辅助过程消除HQ预测的不确定性，并采用熵保持流路径匹配速度场。

Result: ResFlow在少于4个采样步骤内完成任务，并在多个基准测试中取得最优结果。

Conclusion: ResFlow为图像恢复提供了高效实用的解决方案。

Abstract: Image restoration aims to recover high-quality (HQ) images from degraded
low-quality (LQ) ones by reversing the effects of degradation. Existing
generative models for image restoration, including diffusion and score-based
models, often treat the degradation process as a stochastic transformation,
which introduces inefficiency and complexity. In this work, we propose ResFlow,
a novel image restoration framework that models the degradation process as a
deterministic path using continuous normalizing flows. ResFlow augments the
degradation process with an auxiliary process that disambiguates the
uncertainty in HQ prediction to enable reversible modeling of the degradation
process. ResFlow adopts entropy-preserving flow paths and learns the augmented
degradation flow by matching the velocity field. ResFlow significantly improves
the performance and speed of image restoration, completing the task in fewer
than four sampling steps. Extensive experiments demonstrate that ResFlow
achieves state-of-the-art results across various image restoration benchmarks,
offering a practical and efficient solution for real-world applications.

</details>


### [172] [Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs](https://arxiv.org/abs/2506.16962)
*Haoran Sun,Yankai Jiang,Wenjie Lou,Yujie Zhang,Wenjie Li,Lilong Wang,Mianxin Liu,Lei Liu,Xiaosong Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为MICS的新方法，用于生成高质量的医学推理路径数据，并构建了一个多任务医学推理数据集MMRP和一个新的医学MLLM模型Chiron-o1，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有的医学多模态大语言模型（MLLMs）在推理能力上存在不足，缺乏全面的框架来搜索和评估有效的推理路径，尤其是在关键诊断任务中。

Method: 提出MICS方法，通过导师-实习生协作搜索生成严格的医学推理路径数据，并利用MICS-Score评估路径质量。构建了MMRP数据集和Chiron-o1模型。

Result: 实验表明，基于MICS生成的CoT数据训练的Chiron-o1在医学视觉问答和推理任务中达到了最先进的性能。

Conclusion: MICS方法有效提升了医学MLLMs的推理能力，Chiron-o1模型在多个基准测试中表现优异。

Abstract: Multimodal large language models (MLLMs) have begun to demonstrate robust
reasoning capabilities on general tasks, yet their application in the medical
domain remains in its early stages. Constructing chain-of-thought (CoT)
training data is essential for bolstering the reasoning abilities of medical
MLLMs. However, existing approaches exhibit a deficiency in offering a
comprehensive framework for searching and evaluating effective reasoning paths
towards critical diagnosis. To address this challenge, we propose Mentor-Intern
Collaborative Search (MICS), a novel reasoning-path searching scheme to
generate rigorous and effective medical CoT data. MICS first leverages mentor
models to initialize the reasoning, one step at a time, then prompts each
intern model to continue the thinking along those initiated paths, and finally
selects the optimal reasoning path according to the overall reasoning
performance of multiple intern models. The reasoning performance is determined
by an MICS-Score, which assesses the quality of generated reasoning paths.
Eventually, we construct MMRP, a multi-task medical reasoning dataset with
ranked difficulty, and Chiron-o1, a new medical MLLM devised via a curriculum
learning strategy, with robust visual question-answering and generalizable
reasoning capabilities. Extensive experiments demonstrate that Chiron-o1,
trained on our CoT dataset constructed using MICS, achieves state-of-the-art
performance across a list of medical visual question answering and reasoning
benchmarks. Codes are available at GitHub - manglu097/Chiron-o1: Enhancing
Step-by-Step and Verifiable Medical Reasoning in MLLMs

</details>


### [173] [ForestFormer3D: A Unified Framework for End-to-End Segmentation of Forest LiDAR 3D Point Clouds](https://arxiv.org/abs/2506.16991)
*Binbin Xiang,Maciej Wielgosz,Stefano Puliti,Kamil Král,Martin Krůček,Azim Missarov,Rasmus Astrup*

Main category: cs.CV

TL;DR: ForestFormer3D是一个端到端的框架，用于森林LiDAR点云的个体树和语义分割，通过新组件实现了高性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前方法难以应对自然森林环境的复杂性和多样性，因此需要一种更精确的分割方法。

Method: 结合ISA引导的查询点选择、基于分数的块合并策略和一对多关联机制。

Result: 在FOR-instanceV2数据集上达到最先进的个体树分割性能，并在未见过的测试集上表现良好。

Conclusion: ForestFormer3D具有跨森林条件和传感器模态的鲁棒性，数据集和代码将公开。

Abstract: The segmentation of forest LiDAR 3D point clouds, including both individual
tree and semantic segmentation, is fundamental for advancing forest management
and ecological research. However, current approaches often struggle with the
complexity and variability of natural forest environments. We present
ForestFormer3D, a new unified and end-to-end framework designed for precise
individual tree and semantic segmentation. ForestFormer3D incorporates
ISA-guided query point selection, a score-based block merging strategy during
inference, and a one-to-many association mechanism for effective training. By
combining these new components, our model achieves state-of-the-art performance
for individual tree segmentation on the newly introduced FOR-instanceV2
dataset, which spans diverse forest types and regions. Additionally,
ForestFormer3D generalizes well to unseen test sets (Wytham woods and LAUTx),
showcasing its robustness across different forest conditions and sensor
modalities. The FOR-instanceV2 dataset and the ForestFormer3D code will be
released soon.

</details>


### [174] [Prmpt2Adpt: Prompt-Based Zero-Shot Domain Adaptation for Resource-Constrained Environments](https://arxiv.org/abs/2506.16994)
*Yasir Ali Farrukh,Syed Wali,Irfan Khan,Nathaniel D. Bastian*

Main category: cs.CV

TL;DR: Prmpt2Adpt是一个轻量级、高效的零样本域适应框架，通过提示驱动的特征对齐实现快速适应，适用于资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 解决现有提示驱动的无监督域适应方法依赖大型模型和完整源域数据的问题，提升在资源受限环境（如无人机）中的适用性。

Method: 基于教师-学生范式，使用蒸馏和微调的CLIP模型作为教师模型，通过提示驱动的实例归一化（PIN）对齐特征，生成高质量伪标签指导学生模型适应。

Result: 在MDS-A数据集上表现优异，适应速度快7倍，推理速度快5倍，且仅需少量源图像。

Conclusion: Prmpt2Adpt是一种实用且可扩展的解决方案，适用于低资源领域的实时适应。

Abstract: Unsupervised Domain Adaptation (UDA) is a critical challenge in real-world
vision systems, especially in resource-constrained environments like drones,
where memory and computation are limited. Existing prompt-driven UDA methods
typically rely on large vision-language models and require full access to
source-domain data during adaptation, limiting their applicability. In this
work, we propose Prmpt2Adpt, a lightweight and efficient zero-shot domain
adaptation framework built around a teacher-student paradigm guided by
prompt-based feature alignment. At the core of our method is a distilled and
fine-tuned CLIP model, used as the frozen backbone of a Faster R-CNN teacher. A
small set of low-level source features is aligned to the target domain
semantics-specified only through a natural language prompt-via Prompt-driven
Instance Normalization (PIN). These semantically steered features are used to
briefly fine-tune the detection head of the teacher model. The adapted teacher
then generates high-quality pseudo-labels, which guide the on-the-fly
adaptation of a compact student model. Experiments on the MDS-A dataset
demonstrate that Prmpt2Adpt achieves competitive detection performance compared
to state-of-the-art methods, while delivering up to 7x faster adaptation and 5x
faster inference speed using few source images-making it a practical and
scalable solution for real-time adaptation in low-resource domains.

</details>


### [175] [A Synthetic Benchmark for Collaborative 3D Semantic Occupancy Prediction in V2X Autonomous Driving](https://arxiv.org/abs/2506.17004)
*Hanlin Wu,Pengfei Lin,Ehsan Javanmardi,Naren Bao,Bo Qian,Hao Si,Manabu Tsukada*

Main category: cs.CV

TL;DR: 论文提出了一种通过协作感知增强3D语义占用预测的方法，填补了缺乏专用数据集的空白，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 单车的感知能力受限于遮挡、传感器范围和视角狭窄，协作感知可以交换互补信息，提升预测的完整性和准确性。

Method: 通过CARLA重放现有协作感知数据集，生成高分辨率语义体素标注；建立不同预测范围的基准；开发基于空间对齐和注意力聚合的基线模型。

Result: 基线模型在扩展预测范围时，性能优于单车模型，且增益随范围扩大而增加。

Conclusion: 协作感知能显著提升3D语义占用预测的性能，尤其在更大空间范围内效果更明显。

Abstract: 3D semantic occupancy prediction is an emerging perception paradigm in
autonomous driving, providing a voxel-level representation of both geometric
details and semantic categories. However, the perception capability of a single
vehicle is inherently constrained by occlusion, restricted sensor range, and
narrow viewpoints. To address these limitations, collaborative perception
enables the exchange of complementary information, thereby enhancing the
completeness and accuracy. In the absence of a dedicated dataset for
collaborative 3D semantic occupancy prediction, we augment an existing
collaborative perception dataset by replaying it in CARLA with a
high-resolution semantic voxel sensor to provide dense and comprehensive
occupancy annotations. In addition, we establish benchmarks with varying
prediction ranges designed to systematically assess the impact of spatial
extent on collaborative prediction. We further develop a baseline model that
performs inter-agent feature fusion via spatial alignment and attention
aggregation. Experimental results demonstrate that our baseline model
consistently outperforms single-agent models, with increasing gains observed as
the prediction range expands.

</details>


### [176] [Unsupervised Image Super-Resolution Reconstruction Based on Real-World Degradation Patterns](https://arxiv.org/abs/2506.17027)
*Yiyang Tie,Hong Zhu,Yunyun Luo,Jing Shi*

Main category: cs.CV

TL;DR: 提出TripleGAN框架，通过两个GAN组件分别处理模糊特性和其他退化模式，第三个GAN用于重建真实低分辨率图像，显著提升超分辨率重建性能。


<details>
  <summary>Details</summary>
Motivation: 真实世界超分辨率重建依赖反映真实退化模式的数据集，但目前仅依赖真实低分辨率图像提取和建模退化模式仍具挑战性。

Method: 提出TripleGAN框架，包含FirstGAN（缩小模糊特性域差距）、SecondGAN（学习目标域模糊特性和其他退化模式）和ThirdGAN（重建真实低分辨率图像）。

Result: 在RealSR和DRealSR数据集上，该方法在定量指标上表现优越，重建结果清晰且无过平滑伪影。

Conclusion: TripleGAN能有效学习真实退化模式并合成对齐数据集，显著提升超分辨率重建性能。

Abstract: The training of real-world super-resolution reconstruction models heavily
relies on datasets that reflect real-world degradation patterns. Extracting and
modeling degradation patterns for super-resolution reconstruction using only
real-world low-resolution (LR) images remains a challenging task. When
synthesizing datasets to simulate real-world degradation, relying solely on
degradation extraction methods fails to capture both blur and diverse noise
characteristics across varying LR distributions, as well as more implicit
degradations such as color gamut shifts. Conversely, domain translation alone
cannot accurately approximate real-world blur characteristics due to the
significant degradation domain gap between synthetic and real data. To address
these challenges, we propose a novel TripleGAN framework comprising two
strategically designed components: The FirstGAN primarily focuses on narrowing
the domain gap in blur characteristics, while the SecondGAN performs
domain-specific translation to approximate target-domain blur properties and
learn additional degradation patterns. The ThirdGAN is trained on pseudo-real
data generated by the FirstGAN and SecondGAN to reconstruct real-world LR
images. Extensive experiments on the RealSR and DRealSR datasets demonstrate
that our method exhibits clear advantages in quantitative metrics while
maintaining sharp reconstructions without over-smoothing artifacts. The
proposed framework effectively learns real-world degradation patterns from LR
observations and synthesizes aligned datasets with corresponding degradation
characteristics, thereby enabling the trained network to achieve superior
performance in reconstructing high-quality SR images from real-world LR inputs.

</details>


### [177] [Stretching Beyond the Obvious: A Gradient-Free Framework to Unveil the Hidden Landscape of Visual Invariance](https://arxiv.org/abs/2506.17040)
*Lorenzo Tausani,Paolo Muratore,Morgan B. Talbot,Giacomo Amerio,Gabriel Kreiman,Davide Zoccolan*

Main category: cs.CV

TL;DR: 论文提出了一种名为Stretch-and-Squeeze (SnS)的无偏、模型无关且无需梯度的框架，用于系统表征视觉单元的不变性景观及其对对抗性扰动的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 理解高级视觉单元编码的特征组合对于揭示图像如何转化为支持识别的表征至关重要。现有方法通常只能推断单元最兴奋的图像，无法揭示其不变性变换的多样性。

Method: SnS将变换建模为双目标优化问题，通过寻找既能最大化改变参考刺激表征又能保持单元激活的图像扰动来探究不变性，同时通过最小化改变刺激但抑制单元激活的扰动来探究对抗敏感性。

Result: 在卷积神经网络(CNN)中，SnS发现的图像变化在像素空间上比仿射变换更远离参考图像，同时更强烈地保留了目标单元的响应。不同表征优化选择导致的不变图像差异显著。

Conclusion: SnS揭示了视觉单元的不变性景观，并表明鲁棒网络的生成图像对人类更具可识别性，支持鲁棒CNN作为视觉系统模型的更高保真度。

Abstract: Uncovering which features' combinations high-level visual units encode is
critical to understand how images are transformed into representations that
support recognition. While existing feature visualization approaches typically
infer a unit's most exciting images, this is insufficient to reveal the
manifold of transformations under which responses remain invariant, which is
key to generalization in vision. Here we introduce Stretch-and-Squeeze (SnS),
an unbiased, model-agnostic, and gradient-free framework to systematically
characterize a unit's invariance landscape and its vulnerability to adversarial
perturbations in both biological and artificial visual systems. SnS frames
these transformations as bi-objective optimization problems. To probe
invariance, SnS seeks image perturbations that maximally alter the
representation of a reference stimulus in a given processing stage while
preserving unit activation. To probe adversarial sensitivity, SnS seeks
perturbations that minimally alter the stimulus while suppressing unit
activation. Applied to convolutional neural networks (CNNs), SnS revealed image
variations that were further from a reference image in pixel-space than those
produced by affine transformations, while more strongly preserving the target
unit's response. The discovered invariant images differed dramatically
depending on the choice of image representation used for optimization:
pixel-level changes primarily affected luminance and contrast, while stretching
mid- and late-layer CNN representations altered texture and pose respectively.
Notably, the invariant images from robust networks were more recognizable by
human subjects than those from standard networks, supporting the higher
fidelity of robust CNNs as models of the visual system.

</details>


### [178] [Relaxed syntax modeling in Transformers for future-proof license plate recognition](https://arxiv.org/abs/2506.17051)
*Florent Meyer,Laurent Guichard,Denis Coquenet,Guillaume Gravier,Yann Soullard,Bertrand Coüasnon*

Main category: cs.CV

TL;DR: 论文提出了一种名为SaLT的语法无关Transformer模型，用于解决现有Transformer在车牌识别中对过去语法过度依赖的问题，显著提升了未来车牌识别的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的车牌识别系统在面对语法变化的新车牌时性能下降明显，无法满足实际生产环境的需求。

Method: 通过分析Transformer编码器-解码器中位置和上下文信息的流动，识别了过度依赖过去语法的原因，并设计了架构上的改进（SaLT模型）。

Result: 实验表明，SaLT在现有和未来车牌上均表现优异，几乎保持了性能稳定性。

Conclusion: SaLT通过语法无关建模显著提升了车牌识别的鲁棒性，适用于动态变化的实际场景。

Abstract: Effective license plate recognition systems are required to be resilient to
constant change, as new license plates are released into traffic daily. While
Transformer-based networks excel in their recognition at first sight, we
observe significant performance drop over time which proves them unsuitable for
tense production environments. Indeed, such systems obtain state-of-the-art
results on plates whose syntax is seen during training. Yet, we show they
perform similarly to random guessing on future plates where legible characters
are wrongly recognized due to a shift in their syntax. After highlighting the
flows of positional and contextual information in Transformer encoder-decoders,
we identify several causes for their over-reliance on past syntax. Following,
we devise architectural cut-offs and replacements which we integrate into SaLT,
an attempt at a Syntax-Less Transformer for syntax-agnostic modeling of license
plate representations. Experiments on both real and synthetic datasets show
that our approach reaches top accuracy on past syntax and most importantly
nearly maintains performance on future license plates. We further demonstrate
the robustness of our architecture enhancements by way of various ablations.

</details>


### [179] [Assembler: Scalable 3D Part Assembly via Anchor Point Diffusion](https://arxiv.org/abs/2506.17074)
*Wang Zhao,Yan-Pei Cao,Jiale Xu,Yuejiang Dong,Ying Shan*

Main category: cs.CV

TL;DR: Assembler是一个可扩展且通用的3D部件组装框架，通过输入部件网格和参考图像重建完整对象。它采用生成式方法和扩散模型处理多样性对象，并引入基于稀疏锚点云的形状表示，实现了在复杂真实对象上的高质量组装。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在多样性对象（如不同部件数量、几何形状和结构）上的局限性，以及确定性姿态预测和类别特定训练的不足。

Method: 1. 将部件组装视为生成问题，使用扩散模型采样合理配置；2. 引入基于稀疏锚点云的形状表示；3. 构建大规模数据集（320K+部件-对象组装）。

Result: 在PartNet上达到最先进性能，首次实现复杂真实对象的高质量组装。

Conclusion: Assembler为交互式和组合式设计提供了潜力，进一步开发了基于图像的部件感知3D建模系统。

Abstract: We present Assembler, a scalable and generalizable framework for 3D part
assembly that reconstructs complete objects from input part meshes and a
reference image. Unlike prior approaches that mostly rely on deterministic part
pose prediction and category-specific training, Assembler is designed to handle
diverse, in-the-wild objects with varying part counts, geometries, and
structures. It addresses the core challenges of scaling to general 3D part
assembly through innovations in task formulation, representation, and data.
First, Assembler casts part assembly as a generative problem and employs
diffusion models to sample plausible configurations, effectively capturing
ambiguities arising from symmetry, repeated parts, and multiple valid
assemblies. Second, we introduce a novel shape-centric representation based on
sparse anchor point clouds, enabling scalable generation in Euclidean space
rather than SE(3) pose prediction. Third, we construct a large-scale dataset of
over 320K diverse part-object assemblies using a synthesis and filtering
pipeline built on existing 3D shape repositories. Assembler achieves
state-of-the-art performance on PartNet and is the first to demonstrate
high-quality assembly for complex, real-world objects. Based on Assembler, we
further introduce an interesting part-aware 3D modeling system that generates
high-resolution, editable objects from images, demonstrating potential for
interactive and compositional design. Project page:
https://assembler3d.github.io

</details>


### [180] [Acquiring and Accumulating Knowledge from Diverse Datasets for Multi-label Driving Scene Classification](https://arxiv.org/abs/2506.17101)
*Ke Li,Chenyu Zhang,Yuxin Ding,Xianbiao Hu,Ruwen Qin*

Main category: cs.CV

TL;DR: 论文提出了一种结合知识获取与积累（KAA）和基于一致性的主动学习（CAL）的新系统，用于解决驾驶场景识别的多标签分类问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 驾驶场景识别对自动驾驶车辆理解复杂环境至关重要，但多标签分类面临数据集标注不平衡和任务学习平衡的挑战。

Method: 通过KAA从单标签数据集获取知识，再通过CAL解决知识分布差异问题。

Result: 在DSI数据集上性能提升56.1%，KAA和CAL分别贡献31.3%和24.8%，并在公共数据集上表现优于SOTA模型。

Conclusion: KAA-CAL系统有效解决了多标签分类问题，显著提升了驾驶场景识别的性能。

Abstract: Driving scene identification, which assigns multiple non-exclusive class
labels to a scene, provides the contextual awareness necessary for enhancing
autonomous vehicles' ability to understand, reason about, and interact with the
complex driving environment. As a multi-label classification problem, it is
better tackled via multitasking learning. However, directly training a
multi-label classification model for driving scene identification through
multitask learning presents two main challenges: acquiring a balanced,
comprehensively annotated multi-label dataset and balancing learning across
different tasks. This paper introduces a novel learning system that synergizes
knowledge acquisition and accumulation (KAA) with consistency-based active
learning (CAL) to address those challenges. KAA acquires and accumulates
knowledge about scene identification from various single-label datasets via
monotask learning. Subsequently, CAL effectively resolves the knowledge gap
caused by the discrepancy between the marginal distributions of individual
attributes and their joint distribution. An ablation study on our Driving Scene
Identification (DSI) dataset demonstrates a 56.1% performance increase over the
baseline model pretrained on ImageNet. Of this, KAA accounts for 31.3% of the
gain, and CAL contributes 24.8%. Moreover, KAA-CAL stands out as the best
performer when compared to state-of-the-art (SOTA) multi-label models on two
public datasets, BDD100K and HSD, achieving this while using 85% less data. The
DSI dataset and the implementation code for KAA-CAL are available at
https://github.com/KELISBU/KAA-CAL .

</details>


### [181] [MEXA: Towards General Multimodal Reasoning with Dynamic Multi-Expert Aggregation](https://arxiv.org/abs/2506.17113)
*Shoubin Yu,Yue Zhang,Ziyang Wang,Jaehong Yoon,Mohit Bansal*

Main category: cs.CV

TL;DR: MEXA是一个无需训练的框架，通过动态选择和聚合专家模型实现多模态推理，适用于多样化任务和领域。


<details>
  <summary>Details</summary>
Motivation: 解决多模态推理中因输入模态多样性和任务复杂性带来的统一框架构建难题。

Method: MEXA动态选择专家模型，生成可解释的文本推理输出，并通过大型推理模型（LRM）聚合结果。

Result: 在多种多模态基准测试中表现优于基线，验证了其有效性和广泛适用性。

Conclusion: MEXA通过专家驱动的选择和聚合，实现了灵活、透明的多模态推理，无需额外训练。

Abstract: Combining pre-trained expert models offers substantial potential for scalable
multimodal reasoning, but building a unified framework remains challenging due
to the increasing diversity of input modalities and task complexity. For
instance, medical diagnosis requires precise reasoning over structured clinical
tables, while financial forecasting depends on interpreting plot-based data to
make informed predictions. To tackle this challenge, we introduce MEXA, a
training-free framework that performs modality- and task-aware aggregation of
multiple expert models to enable effective multimodal reasoning across diverse
and distinct domains. MEXA dynamically selects expert models based on the input
modality and the task-specific reasoning demands (i.e., skills). Each expert
model, specialized in a modality task pair, generates interpretable textual
reasoning outputs. MEXA then aggregates and reasons over these outputs using a
Large Reasoning Model (LRM) to produce the final answer. This modular design
allows flexible and transparent multimodal reasoning across diverse domains
without additional training overhead. We extensively evaluate our approach on
diverse multimodal benchmarks, including Video Reasoning, Audio Reasoning, 3D
Understanding, and Medical QA. MEXA consistently delivers performance
improvements over strong multimodal baselines, highlighting the effectiveness
and broad applicability of our expert-driven selection and aggregation in
diverse multimodal reasoning tasks.

</details>


### [182] [RGBTrack: Fast, Robust Depth-Free 6D Pose Estimation and Tracking](https://arxiv.org/abs/2506.17119)
*Teng Guo,Jingjin Yu*

Main category: cs.CV

TL;DR: RGBTrack是一个仅基于RGB数据的实时6D姿态估计与跟踪框架，无需深度输入，通过结合二进制搜索策略和渲染-比较机制，实现了高效深度推断和姿态假设生成。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖深度输入，限制了动态和精确物体姿态跟踪的应用范围。RGBTrack旨在通过仅使用RGB数据，提供一种更灵活且实用的解决方案。

Method: 基于FoundationPose架构，结合二进制搜索和渲染-比较机制生成姿态假设，并集成2D目标跟踪（XMem）、卡尔曼滤波和状态机以应对动态场景。

Result: 在基准数据集上的评估表明，RGBTrack在精度和实时性能上具有竞争力，适用于机器人、增强现实和计算机视觉领域。

Conclusion: RGBTrack是一种无需深度输入的实用解决方案，具有广泛的应用潜力。

Abstract: We introduce a robust framework, RGBTrack, for real-time 6D pose estimation
and tracking that operates solely on RGB data, thereby eliminating the need for
depth input for such dynamic and precise object pose tracking tasks. Building
on the FoundationPose architecture, we devise a novel binary search strategy
combined with a render-and-compare mechanism to efficiently infer depth and
generate robust pose hypotheses from true-scale CAD models. To maintain stable
tracking in dynamic scenarios, including rapid movements and occlusions,
RGBTrack integrates state-of-the-art 2D object tracking (XMem) with a Kalman
filter and a state machine for proactive object pose recovery. In addition,
RGBTrack's scale recovery module dynamically adapts CAD models of unknown scale
using an initial depth estimate, enabling seamless integration with modern
generative reconstruction techniques. Extensive evaluations on benchmark
datasets demonstrate that RGBTrack's novel depth-free approach achieves
competitive accuracy and real-time performance, making it a promising practical
solution candidate for application areas including robotics, augmented reality,
and computer vision.
  The source code for our implementation will be made publicly available at
https://github.com/GreatenAnoymous/RGBTrack.git.

</details>


### [183] [Dynamic Watermark Generation for Digital Images using Perimeter Gated SPAD Imager PUFs](https://arxiv.org/abs/2506.17134)
*Md Sakibur Sajal,Marc Dandin*

Main category: cs.CV

TL;DR: 提出了一种基于pgSPAD成像器的数字水印技术，利用制造差异（DSNU）生成动态水印，实现来源识别和篡改检测。


<details>
  <summary>Details</summary>
Motivation: 尽管CMOS和APS传感器的数字水印已有研究，但SPAD成像器尚未被探索。本研究填补了这一空白。

Method: 利用三个64x64 pgSPAD芯片的DSNU，通过标准CMOS工艺制造，分析公开数据库中的测试图像生成水印。

Result: 提出的动态水印技术能够实现来源识别和篡改检测，并具有可控的灵敏度-鲁棒性权衡。

Conclusion: pgSPAD成像器在数字水印领域具有潜力，动态水印技术为安全应用提供了新思路。

Abstract: Digital image watermarks as a security feature can be derived from the
imager's physically unclonable functions (PUFs) by utilizing the manufacturing
variations, i.e., the dark signal non-uniformity (DSNU). While a few
demonstrations focused on the CMOS image sensors (CIS) and active pixel sensors
(APS), single photon avalanche diode (SPAD) imagers have never been
investigated for this purpose. In this work, we have proposed a novel
watermarking technique using perimeter gated SPAD (pgSPAD) imagers. We utilized
the DSNU of three 64 x 64 pgSPAD imager chips, fabricated in a 0.35 {\mu}m
standard CMOS process and analyzed the simulated watermarks for standard test
images from publicly available database. Our observation shows that both source
identification and tamper detection can be achieved using the proposed
source-scene-specific dynamic watermarks with a controllable
sensitivity-robustness trade-off.

</details>


### [184] [Semi-Supervised Multi-Modal Medical Image Segmentation for Complex Situations](https://arxiv.org/abs/2506.17136)
*Dongdong Meng,Sheng Li,Hao Wu,Guoping Wang,Xueqing Yan*

Main category: cs.CV

TL;DR: 提出了一种新的半监督多模态医学图像分割方法，通过多阶段融合和对比互学习提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决半监督条件下多模态融合方法难以有效利用未标记数据的问题。

Method: 采用多阶段多模态融合与增强策略，结合对比互学习约束预测一致性。

Result: 在两个多模态数据集上表现出优越性能和鲁棒性。

Conclusion: 该方法在复杂场景下具有解决医学图像分割任务的潜力。

Abstract: Semi-supervised learning addresses the issue of limited annotations in
medical images effectively, but its performance is often inadequate for complex
backgrounds and challenging tasks. Multi-modal fusion methods can significantly
improve the accuracy of medical image segmentation by providing complementary
information. However, they face challenges in achieving significant
improvements under semi-supervised conditions due to the challenge of
effectively leveraging unlabeled data. There is a significant need to create an
effective and reliable multi-modal learning strategy for leveraging unlabeled
data in semi-supervised segmentation. To address these issues, we propose a
novel semi-supervised multi-modal medical image segmentation approach, which
leverages complementary multi-modal information to enhance performance with
limited labeled data. Our approach employs a multi-stage multi-modal fusion and
enhancement strategy to fully utilize complementary multi-modal information,
while reducing feature discrepancies and enhancing feature sharing and
alignment. Furthermore, we effectively introduce contrastive mutual learning to
constrain prediction consistency across modalities, thereby facilitating the
robustness of segmentation results in semi-supervised tasks. Experimental
results on two multi-modal datasets demonstrate the superior performance and
robustness of the proposed framework, establishing its valuable potential for
solving medical image segmentation tasks in complex scenarios.

</details>


### [185] [On the Theory of Conditional Feature Alignment for Unsupervised Domain-Adaptive Counting](https://arxiv.org/abs/2506.17137)
*Zhuonan Liang,Dongnan Liu,Jianan Fan,Yaxuan Song,Qiang Qu,Yu Yao,Peng Fu,Weidong Cai*

Main category: cs.CV

TL;DR: 论文提出了一种条件特征对齐的理论框架，用于解决目标计数模型在跨域部署时的密度变化问题。通过条件对齐分布，证明了其能比无条件对齐更有效地降低联合误差，并在实验中验证了方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 目标计数模型在跨域部署时因密度变化而性能下降，传统域适应方法无法解决这一问题。

Method: 提出条件特征对齐框架，通过划分域为子集并测量条件差异，推导出联合误差边界，设计了一种保留任务相关信息的无监督域适应策略。

Result: 在多个密度分布不同的计数数据集上，该方法优于现有无监督域适应方法。

Conclusion: 条件特征对齐能有效提升跨域计数的泛化能力，理论和实验均验证了其优越性。

Abstract: Object counting models suffer when deployed across domains with differing
density variety, since density shifts are inherently task-relevant and violate
standard domain adaptation assumptions. To address this, we propose a
theoretical framework of conditional feature alignment. We first formalize the
notion of conditional divergence by partitioning each domain into subsets
(e.g., object vs. background) and measuring divergences per condition. We then
derive a joint error bound showing that, under discrete label spaces treated as
condition sets, aligning distributions conditionally leads to tighter bounds on
the combined source-target decision error than unconditional alignment. These
insights motivate a general conditional adaptation principle: by preserving
task-relevant variations while filtering out nuisance shifts, one can achieve
superior cross-domain generalization for counting. We provide both defining
conditional divergence then proving its benefit in lowering joint error and a
practical adaptation strategy that preserves task-relevant information in
unsupervised domain-adaptive counting. We demonstrate the effectiveness of our
approach through extensive experiments on multiple counting datasets with
varying density distributions. The results show that our method outperforms
existing unsupervised domain adaptation methods, empirically validating the
theoretical insights on conditional feature alignment.

</details>


### [186] [Do We Need Large VLMs for Spotting Soccer Actions?](https://arxiv.org/abs/2506.17144)
*Ritabrata Chakraborty,Rajatsubhra Chakraborty,Avijit Dasgupta,Sandeep Chaurasia*

Main category: cs.CV

TL;DR: 论文提出了一种基于文本的轻量级方法，利用大型语言模型（LLMs）替代传统的视频处理方法，通过专家评论来检测足球比赛中的关键动作。


<details>
  <summary>Details</summary>
Motivation: 传统视频处理方法计算量大且复杂，而专家评论提供了丰富的细粒度描述和上下文信息，足以可靠地识别比赛中的关键动作。

Method: 使用SoccerNet Echoes数据集中的时间戳评论，通过三个专门评估结果、兴奋度和战术的LLMs系统，滑动窗口分析评论以识别动作（如进球、红黄牌和换人）。

Result: 实验表明，这种基于语言的方法能有效检测比赛关键事件，为动作识别提供了一种无需训练的轻量级替代方案。

Conclusion: 语言为中心的方法在动作识别中表现优异，为传统视频方法提供了轻量级且无需训练的替代方案。

Abstract: Traditional video-based tasks like soccer action spotting rely heavily on
visual inputs, often requiring complex and computationally expensive models to
process dense video data. In this work, we propose a shift from this
video-centric approach to a text-based task, making it lightweight and scalable
by utilizing Large Language Models (LLMs) instead of Vision-Language Models
(VLMs). We posit that expert commentary, which provides rich, fine-grained
descriptions and contextual cues such as excitement and tactical insights,
contains enough information to reliably spot key actions in a match. To
demonstrate this, we use the SoccerNet Echoes dataset, which provides
timestamped commentary, and employ a system of three LLMs acting as judges
specializing in outcome, excitement, and tactics. Each LLM evaluates sliding
windows of commentary to identify actions like goals, cards, and substitutions,
generating accurate timestamps for these events. Our experiments show that this
language-centric approach performs effectively in detecting critical match
events, providing a lightweight and training-free alternative to traditional
video-based methods for action spotting.

</details>


### [187] [Co-Seg++: Mutual Prompt-Guided Collaborative Learning for Versatile Medical Segmentation](https://arxiv.org/abs/2506.17159)
*Qing Xu,Yuxiang Luo,Wenting Duan,Zhen Chen*

Main category: cs.CV

TL;DR: Co-Seg++框架通过联合语义和实例分割任务，提升医学图像分割性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常独立处理分割任务，忽视了任务间的相互依赖性，导致分割性能不佳。

Method: 提出Co-Seg++框架，包括STP-Encoder捕获空间和时间关系，MTC-Decoder通过跨任务指导增强一致性。

Result: 在多种数据集上，Co-Seg++在语义、实例和全景分割任务中表现优于现有方法。

Conclusion: Co-Seg++通过任务间协同显著提升医学图像分割效果，具有广泛应用潜力。

Abstract: Medical image analysis is critical yet challenged by the need of jointly
segmenting organs or tissues, and numerous instances for anatomical structures
and tumor microenvironment analysis. Existing studies typically formulated
different segmentation tasks in isolation, which overlooks the fundamental
interdependencies between these tasks, leading to suboptimal segmentation
performance and insufficient medical image understanding. To address this
issue, we propose a Co-Seg++ framework for versatile medical segmentation.
Specifically, we introduce a novel co-segmentation paradigm, allowing semantic
and instance segmentation tasks to mutually enhance each other. We first devise
a spatio-temporal prompt encoder (STP-Encoder) to capture long-range spatial
and temporal relationships between segmentation regions and image embeddings as
prior spatial constraints. Moreover, we devise a multi-task collaborative
decoder (MTC-Decoder) that leverages cross-guidance to strengthen the
contextual consistency of both tasks, jointly computing semantic and instance
segmentation masks. Extensive experiments on diverse CT and histopathology
datasets demonstrate that the proposed Co-Seg++ outperforms state-of-the-arts
in the semantic, instance, and panoptic segmentation of dental anatomical
structures, histopathology tissues, and nuclei instances. The source code is
available at https://github.com/xq141839/Co-Seg-Plus.

</details>


### [188] [YASMOT: Yet another stereo image multi-object tracker](https://arxiv.org/abs/2506.17186)
*Ketil Malde*

Main category: cs.CV

TL;DR: Yasmot是一个轻量级、灵活的对象跟踪器，用于处理图像时间序列中的对象跟踪问题，支持单目或立体相机配置，并能整合多个检测器的结果。


<details>
  <summary>Details</summary>
Motivation: 在图像时间序列中，跟踪对象并保持其身份有助于提高检测性能，并为下游任务（如行为分类和丰度估计）提供支持。

Method: Yasmot处理流行对象检测器的输出，支持单目或立体相机配置，并能生成多个检测器的共识检测结果。

Result: Yasmot实现了轻量级且灵活的对象跟踪功能。

Conclusion: Yasmot为图像时间序列中的对象跟踪提供了一种高效且灵活的解决方案。

Abstract: There now exists many popular object detectors based on deep learning that
can analyze images and extract locations and class labels for occurrences of
objects. For image time series (i.e., video or sequences of stills), tracking
objects over time and preserving object identity can help to improve object
detection performance, and is necessary for many downstream tasks, including
classifying and predicting behaviors, and estimating total abundances. Here we
present yasmot, a lightweight and flexible object tracker that can process the
output from popular object detectors and track objects over time from either
monoscopic or stereoscopic camera configurations. In addition, it includes
functionality to generate consensus detections from ensembles of object
detectors.

</details>


### [189] [Facial Landmark Visualization and Emotion Recognition Through Neural Networks](https://arxiv.org/abs/2506.17191)
*Israel Juárez-Jiménez,Tiffany Guadalupe Martínez Paredes,Jesús García-Ramírez,Eric Ramos Aguilar*

Main category: cs.CV

TL;DR: 提出了一种面部标志箱线图可视化技术，用于识别面部数据集中的异常值，并比较了两种面部标志特征。结果表明神经网络优于随机森林分类器。


<details>
  <summary>Details</summary>
Motivation: 面部图像情感识别是人机交互中的重要任务，但现有研究缺乏对数据集的深入分析，且面部标志的可视化提取有意义信息具有挑战性。

Method: 提出面部标志箱线图可视化技术，比较两种面部标志特征：绝对位置和从中性表情到情绪峰值的位移。

Result: 神经网络在性能上优于随机森林分类器。

Conclusion: 面部标志箱线图有助于数据集分析，神经网络在情感识别任务中表现更优。

Abstract: Emotion recognition from facial images is a crucial task in human-computer
interaction, enabling machines to learn human emotions through facial
expressions. Previous studies have shown that facial images can be used to
train deep learning models; however, most of these studies do not include a
through dataset analysis. Visualizing facial landmarks can be challenging when
extracting meaningful dataset insights; to address this issue, we propose
facial landmark box plots, a visualization technique designed to identify
outliers in facial datasets. Additionally, we compare two sets of facial
landmark features: (i) the landmarks' absolute positions and (ii) their
displacements from a neutral expression to the peak of an emotional expression.
Our results indicate that a neural network achieves better performance than a
random forest classifier.

</details>


### [190] [Hunyuan-GameCraft: High-dynamic Interactive Game Video Generation with Hybrid History Condition](https://arxiv.org/abs/2506.17201)
*Jiaqi Li,Junshu Tang,Zhiyong Xu,Longhuang Wu,Yuan Zhou,Shuai Shao,Tianbao Yu,Zhiguo Cao,Qinglin Lu*

Main category: cs.CV

TL;DR: Hunyuan-GameCraft是一个用于游戏环境中高动态交互视频生成的新框架，通过统一输入表示、混合历史条件训练和模型蒸馏，解决了现有方法在动态性、通用性和效率上的限制。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散和可控视频生成的方法在动态性、通用性、长期一致性和效率方面存在不足，限制了多样化游戏视频的生成能力。

Method: 提出Hunyuan-GameCraft框架，统一键盘和鼠标输入为共享相机表示空间，采用混合历史条件训练策略，并通过模型蒸馏提升推理效率。

Result: 在包含100多款AAA游戏的百万级数据集上训练，实验表明Hunyuan-GameCraft在真实感和可玩性上显著优于现有模型。

Conclusion: Hunyuan-GameCraft通过改进输入控制、训练策略和效率优化，显著提升了交互游戏视频生成的性能。

Abstract: Recent advances in diffusion-based and controllable video generation have
enabled high-quality and temporally coherent video synthesis, laying the
groundwork for immersive interactive gaming experiences. However, current
methods face limitations in dynamics, generality, long-term consistency, and
efficiency, which limit the ability to create various gameplay videos. To
address these gaps, we introduce Hunyuan-GameCraft, a novel framework for
high-dynamic interactive video generation in game environments. To achieve
fine-grained action control, we unify standard keyboard and mouse inputs into a
shared camera representation space, facilitating smooth interpolation between
various camera and movement operations. Then we propose a hybrid
history-conditioned training strategy that extends video sequences
autoregressively while preserving game scene information. Additionally, to
enhance inference efficiency and playability, we achieve model distillation to
reduce computational overhead while maintaining consistency across long
temporal sequences, making it suitable for real-time deployment in complex
interactive environments. The model is trained on a large-scale dataset
comprising over one million gameplay recordings across over 100 AAA games,
ensuring broad coverage and diversity, then fine-tuned on a carefully annotated
synthetic dataset to enhance precision and control. The curated game scene data
significantly improves the visual fidelity, realism and action controllability.
Extensive experiments demonstrate that Hunyuan-GameCraft significantly
outperforms existing models, advancing the realism and playability of
interactive game video generation.

</details>


### [191] [UniFork: Exploring Modality Alignment for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2506.17202)
*Teng Li,Quanfeng Lu,Lirui Zhao,Hao Li,Xizhou Zhu,Yu Qiao,Jun Zhang,Wenqi Shao*

Main category: cs.CV

TL;DR: UniFork提出了一种Y形架构，通过共享浅层和任务特定的深层分支，解决了图像理解与生成任务中模态对齐的冲突，性能优于传统共享架构。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型在图像理解与生成任务中存在模态对齐冲突，导致性能折衷。

Method: 分析任务特定模型和统一模型的模态对齐行为，提出UniFork架构，共享浅层并采用任务特定深层分支。

Result: UniFork性能优于传统共享架构，与任务特定模型相当或更好。

Conclusion: UniFork有效平衡了共享学习与任务专业化，为统一模型设计提供了新思路。

Abstract: Unified image understanding and generation has emerged as a promising
paradigm in multimodal artificial intelligence. Despite recent progress, the
optimal architectural design for such unified models remains an open challenge.
In this work, we start by analyzing the modality alignment behaviors of
task-specific expert models for understanding and generation, as well as
current unified models. Our analysis reveals a crucial observation:
understanding tasks benefit from a progressively increasing modality alignment
across network depth, which helps build up semantic information for better
comprehension; In contrast, generation tasks follow a different trend: modality
alignment increases in the early layers but decreases in the deep layers to
recover spatial details. These divergent alignment patterns create a
fundamental conflict in fully shared Transformer backbones, where a uniform
representational flow often leads to performance compromises across two tasks.
Motivated by this finding, we introduce UniFork, a novel Y-shaped architecture
that shares the shallow layers for cross-task representation learning, while
employing task-specific branches in deeper layers to avoid task interference.
This design effectively balances shared learning and task specialization.
Through extensive ablation experiments, we demonstrate that Unifork
consistently outperforms conventional fully shared Transformer architectures,
and achieves performance on par with or better than task-specific models.

</details>


### [192] [Part$^{2}$GS: Part-aware Modeling of Articulated Objects using 3D Gaussian Splatting](https://arxiv.org/abs/2506.17212)
*Tianjiao Yu,Vedant Shah,Muntasir Wahed,Ying Shen,Kiet A. Nguyen,Ismini Lourentzou*

Main category: cs.CV

TL;DR: Part$^{2}$GS是一个用于建模多部件物体高保真几何和物理一致运动的框架，通过部件感知的3D高斯表示和物理约束实现。


<details>
  <summary>Details</summary>
Motivation: 现实世界中关节物体普遍存在，但其结构和运动的建模仍具挑战性。

Method: 采用部件感知的3D高斯表示，结合物理约束（如接触强制、速度一致性和矢量场对齐）和排斥点场防止部件碰撞。

Result: 在合成和真实数据集上，Part$^{2}$GS在可移动部件的Chamfer距离上比现有方法提升高达10倍。

Conclusion: Part$^{2}$GS通过高保真几何和物理一致运动建模，显著提升了关节物体的重建性能。

Abstract: Articulated objects are common in the real world, yet modeling their
structure and motion remains a challenging task for 3D reconstruction methods.
In this work, we introduce Part$^{2}$GS, a novel framework for modeling
articulated digital twins of multi-part objects with high-fidelity geometry and
physically consistent articulation. Part$^{2}$GS leverages a part-aware 3D
Gaussian representation that encodes articulated components with learnable
attributes, enabling structured, disentangled transformations that preserve
high-fidelity geometry. To ensure physically consistent motion, we propose a
motion-aware canonical representation guided by physics-based constraints,
including contact enforcement, velocity consistency, and vector-field
alignment. Furthermore, we introduce a field of repel points to prevent part
collisions and maintain stable articulation paths, significantly improving
motion coherence over baselines. Extensive evaluations on both synthetic and
real-world datasets show that Part$^{2}$GS consistently outperforms
state-of-the-art methods by up to 10$\times$ in Chamfer Distance for movable
parts.

</details>


### [193] [Long-term Traffic Simulation with Interleaved Autoregressive Motion and Scenario Generation](https://arxiv.org/abs/2506.17213)
*Xiuyu Yang,Shuhan Tan,Philipp Krähenbühl*

Main category: cs.CV

TL;DR: InfGen是一种统一的下一代预测模型，通过交替进行闭环运动模拟和场景生成，实现稳定的长期交通模拟。


<details>
  <summary>Details</summary>
Motivation: 现有模型和基准主要关注场景中初始代理的闭环运动模拟，难以支持长期模拟，因为代理会随车辆进入新区域而动态变化。

Method: InfGen采用统一的下一代预测模型，交替进行闭环运动模拟和场景生成，自动切换模式以支持长期模拟。

Result: InfGen在短期（9秒）交通模拟中达到最先进水平，在长期（30秒）模拟中显著优于其他方法。

Conclusion: InfGen通过创新的模式切换机制，解决了长期交通模拟的挑战，为自动驾驶系统的部署提供了更真实的模拟环境。

Abstract: An ideal traffic simulator replicates the realistic long-term point-to-point
trip that a self-driving system experiences during deployment. Prior models and
benchmarks focus on closed-loop motion simulation for initial agents in a
scene. This is problematic for long-term simulation. Agents enter and exit the
scene as the ego vehicle enters new regions. We propose InfGen, a unified
next-token prediction model that performs interleaved closed-loop motion
simulation and scene generation. InfGen automatically switches between
closed-loop motion simulation and scene generation mode. It enables stable
long-term rollout simulation. InfGen performs at the state-of-the-art in
short-term (9s) traffic simulation, and significantly outperforms all other
methods in long-term (30s) simulation. The code and model of InfGen will be
released at https://orangesodahub.github.io/InfGen

</details>


### [194] [Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual Tokens](https://arxiv.org/abs/2506.17218)
*Zeyuan Yang,Xueyang Yu,Delin Chen,Maohao Shen,Chuang Gan*

Main category: cs.CV

TL;DR: Mirage框架通过隐式视觉标记增强视觉语言模型（VLM）的解码能力，避免显式图像生成，从而提升多模态推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLM因仅依赖文本解码而限制了视觉推理能力，显式图像生成又损害推理能力，因此探索通过隐式视觉标记实现多模态推理。

Method: 提出Mirage框架，通过隐式视觉标记和文本交替解码，监督训练分为蒸馏阶段和强化学习阶段。

Result: 实验表明Mirage在多模态推理任务中表现优于显式图像生成方法。

Conclusion: Mirage证明了隐式视觉标记可有效增强VLM的多模态推理能力，无需显式图像生成。

Abstract: Vision-language models (VLMs) excel at multimodal understanding, yet their
text-only decoding forces them to verbalize visual reasoning, limiting
performance on tasks that demand visual imagination. Recent attempts train VLMs
to render explicit images, but the heavy image-generation pre-training often
hinders the reasoning ability. Inspired by the way humans reason with mental
imagery-the internal construction and manipulation of visual cues-we
investigate whether VLMs can reason through interleaved multimodal trajectories
without producing explicit images. To this end, we present a Machine Mental
Imagery framework, dubbed as Mirage, which augments VLM decoding with latent
visual tokens alongside ordinary text. Concretely, whenever the model chooses
to ``think visually'', it recasts its hidden states as next tokens, thereby
continuing a multimodal trajectory without generating pixel-level images. Begin
by supervising the latent tokens through distillation from ground-truth image
embeddings, we then switch to text-only supervision to make the latent
trajectory align tightly with the task objective. A subsequent reinforcement
learning stage further enhances the multimodal reasoning capability.
Experiments on diverse benchmarks demonstrate that Mirage unlocks stronger
multimodal reasoning without explicit image generation.

</details>


### [195] [Emergent Temporal Correspondences from Video Diffusion Transformers](https://arxiv.org/abs/2506.17220)
*Jisu Nam,Soowon Son,Dahyun Chung,Jiyoung Kim,Siyoon Jin,Junhwa Hur,Seungryong Kim*

Main category: cs.CV

TL;DR: DiffTrack是一个定量分析框架，用于研究视频扩散模型（DiTs）如何建立和表示帧间时间对应关系。通过伪真实跟踪注释数据集和新评估指标，揭示了特定层在时间匹配中的关键作用，并展示了其在零样本点跟踪和运动增强视频生成中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究视频扩散模型（DiTs）内部如何建立和表示帧间时间对应关系，填补现有研究的空白。

Method: 构建带伪真实跟踪注释的视频数据集，提出评估指标，系统分析DiTs的3D注意力机制中各组件（如表示、层和时间步）对时间对应关系的贡献。

Result: 发现特定层的查询-键相似性在时间匹配中起关键作用，且匹配在去噪过程中逐渐显著。DiffTrack在零样本点跟踪中表现优异，并可用于运动增强视频生成。

Conclusion: DiffTrack为理解视频DiTs的时间机制提供了关键见解，并为未来研究和应用奠定了基础。

Abstract: Recent advancements in video diffusion models based on Diffusion Transformers
(DiTs) have achieved remarkable success in generating temporally coherent
videos. Yet, a fundamental question persists: how do these models internally
establish and represent temporal correspondences across frames? We introduce
DiffTrack, the first quantitative analysis framework designed to answer this
question. DiffTrack constructs a dataset of prompt-generated video with pseudo
ground-truth tracking annotations and proposes novel evaluation metrics to
systematically analyze how each component within the full 3D attention
mechanism of DiTs (e.g., representations, layers, and timesteps) contributes to
establishing temporal correspondences. Our analysis reveals that query-key
similarities in specific, but not all, layers play a critical role in temporal
matching, and that this matching becomes increasingly prominent during the
denoising process. We demonstrate practical applications of DiffTrack in
zero-shot point tracking, where it achieves state-of-the-art performance
compared to existing vision foundation and self-supervised video models.
Further, we extend our findings to motion-enhanced video generation with a
novel guidance method that improves temporal consistency of generated videos
without additional training. We believe our work offers crucial insights into
the inner workings of video DiTs and establishes a foundation for further
research and applications leveraging their temporal understanding.

</details>


### [196] [VLN-R1: Vision-Language Navigation via Reinforcement Fine-Tuning](https://arxiv.org/abs/2506.17221)
*Zhangyang Qi,Zhixiong Zhang,Yizhou Yu,Jiaqi Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: VLN-R1是一个端到端框架，利用大型视觉语言模型（LVLM）将第一视角视频流直接转换为连续导航动作，采用GRPO训练方法，并在VLN-CE基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前基于语言模型的导航系统受限于离散拓扑图，无法实现连续路径规划，因此需要一种更灵活的方法。

Method: VLN-R1采用两阶段训练：监督微调（SFT）对齐专家演示的动作序列文本预测，强化微调（RFT）结合时间衰减奖励（TDR）机制优化多步动作。

Result: VLN-R1在VLN-CE基准测试中表现优异，验证了LVLMs在具身导航中的潜力。

Conclusion: VLN-R1展示了LVLMs通过数据高效、奖励驱动的后训练增强任务特定推理的能力。

Abstract: Vision-Language Navigation (VLN) is a core challenge in embodied AI,
requiring agents to navigate real-world environments using natural language
instructions. Current language model-based navigation systems operate on
discrete topological graphs, limiting path planning to predefined node
connections. We propose VLN-R1, an end-to-end framework that leverages Large
Vision-Language Models (LVLM) to directly translate egocentric video streams
into continuous navigation actions, adopting GRPO-based training inspired by
DeepSeek-R1. To enable effective training, we first construct the VLN-Ego
dataset using a 3D simulator, Habitat, and propose Long-Short Memory Sampling
to balance historical and current observations. While large language models can
supervise complete textual instructions, they lack fine-grained action-level
control. Our framework employs a two-stage training approach: a) Supervised
fine-tuning (SFT) to align the model's action sequence text predictions with
expert demonstrations, followed by b) Reinforcement fine-tuning (RFT) enhanced
with a Time-Decayed Reward (TDR) mechanism that strategically weights
multi-step future actions. Experimental results show VLN-R1 achieves strong
performance on VLN-CE benchmark. VLN-R1 proves LVLMs can drive embodied
navigation and enhance task-specific reasoning through data-efficient,
reward-driven post-training.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [197] [TrainVerify: Equivalence-Based Verification for Distributed LLM Training](https://arxiv.org/abs/2506.15961)
*Yunchi Lu,Youshan Miao,Cheng Tan,Peng Huang,Yi Zhu,Xian Zhang,Fan Yang*

Main category: cs.DC

TL;DR: TrainVerify是一个用于验证大规模语言模型（LLM）分布式训练的系统，确保其数学等效性，避免因错误浪费计算资源。


<details>
  <summary>Details</summary>
Motivation: 大规模LLM训练成本高昂且缺乏验证，容易导致错误和资源浪费。

Method: TrainVerify通过形状缩减技术和分阶段并行验证算法，降低验证复杂度，同时保持正确性。

Result: 成功验证了Llama3（405B）和DeepSeek-V3（671B）等前沿LLM的训练计划。

Conclusion: TrainVerify为大规模分布式训练提供了高效且可靠的验证解决方案。

Abstract: Training large language models (LLMs) at scale requires parallel execution
across thousands of devices, incurring enormous computational costs. Yet, these
costly distributed trainings are rarely verified, leaving them prone to silent
errors and potentially wasting millions of GPU hours. We introduce TrainVerify,
a system for verifiable distributed training of LLMs. Given a deep learning
model's logical specification as the ground truth, TrainVerify formally
verifies that a distributed parallel execution plan is mathematically
equivalent to it. Direct verification is notoriously difficult due to the sheer
scale of LLMs which often involves billions of variables and highly intricate
computation graphs. Therefore, TrainVerify introduces shape-reduction
techniques and a stage-wise parallel verification algorithm that significantly
reduces complexity while preserving formal correctness. TrainVerify scales to
frontier LLMs, including the successful verification of the Llama3 (405B) and
DeepSeek-V3 (671B) training plans.

</details>


### [198] [NetSenseML: Network-Adaptive Compression for Efficient Distributed Machine Learning](https://arxiv.org/abs/2506.16235)
*Yisu Wang,Xinjiao Li,Ruilong Wu,Huangxun Chen,Dirk Kutscher*

Main category: cs.DC

TL;DR: NetSenseML是一种新型网络自适应分布式深度学习框架，通过动态调整梯度压缩策略来平衡网络负载和模型精度，显著提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 大规模分布式机器学习训练对网络基础设施需求高，容易导致拥塞和性能下降，现有梯度压缩技术常牺牲模型精度。

Method: NetSenseML实时监测网络状况，动态调整量化、剪枝和压缩策略，仅在网络拥塞影响收敛速度时应用压缩。

Result: 实验表明，NetSenseML在带宽受限条件下，训练吞吐量提升1.55至9.84倍。

Conclusion: NetSenseML通过自适应数据缩减策略，有效平衡网络负载和模型精度，显著提升训练效率。

Abstract: Training large-scale distributed machine learning models imposes considerable
demands on network infrastructure, often resulting in sudden traffic spikes
that lead to congestion, increased latency, and reduced throughput, which would
ultimately affect convergence times and overall training performance. While
gradient compression techniques are commonly employed to alleviate network
load, they frequently compromise model accuracy due to the loss of gradient
information.
  This paper introduces NetSenseML, a novel network adaptive distributed deep
learning framework that dynamically adjusts quantization, pruning, and
compression strategies in response to real-time network conditions. By actively
monitoring network conditions, NetSenseML applies gradient compression only
when network congestion negatively impacts convergence speed, thus effectively
balancing data payload reduction and model accuracy preservation.
  Our approach ensures efficient resource usage by adapting reduction
techniques based on current network conditions, leading to shorter convergence
times and improved training efficiency. We present the design of the NetSenseML
adaptive data reduction function and experimental evaluations show that
NetSenseML can improve training throughput by a factor of 1.55 to 9.84 times
compared to state-of-the-art compression-enabled systems for representative DDL
training jobs in bandwidth-constrained conditions.

</details>


### [199] [A Study of Synchronization Methods for Concurrent Size](https://arxiv.org/abs/2506.16350)
*Hen Kas-Sharir,Gal Sela,Erez Petrank*

Main category: cs.DC

TL;DR: 本文研究了并发环境下数据结构中`size`方法的同步技术，比较了握手、乐观和基于锁的方法，发现不同场景需要不同方法，低争用下乐观和锁方法最优，高争用下握手和无等待方法更有效。


<details>
  <summary>Details</summary>
Motivation: 在并发环境中，实现线性化并发`size`方法会显著增加数据结构的操作开销，即使未调用`size`方法。本文旨在探索同步方法以优化性能。

Method: 研究了三种同步技术：握手（常用于并发垃圾回收）、乐观方法和基于锁的方法，并与现有`size`方法进行对比评估。

Result: 选择合适的同步方法可显著减少开销，但无通用最优方法。低争用下乐观和锁方法表现最佳，高争用下握手和无等待方法更有效。

Conclusion: 不同并发场景需采用不同同步方法，研究结果与并发计算的普遍趋势一致。

Abstract: The size of collections, maps, and data structures in general, constitutes a
fundamental property. An implementation of the size method is required in most
programming environments. Nevertheless, in a concurrent environment,
integrating a linearizable concurrent size introduces a noticeable overhead on
all operations of the data structure, even when the size method is not invoked
during the execution. In this work we present a study of synchronization
methods in an attempt to improve the performance of the data structure. In
particular, we study a handshake technique that is commonly used with
concurrent garbage collection, an optimistic technique, and a lock-based
technique. Evaluation against the state-of-the-art size methodology
demonstrates that the overhead can be significantly reduced by selecting the
appropriate synchronization approach, but there is no one-size-fits-all method.
Different scenarios call for different synchronization methods, as rigorously
shown in this study. Nevertheless, our findings align with general trends in
concurrent computing. In scenarios characterized by low contention, optimistic
and lock-based approaches work best, whereas under high contention, the most
effective solutions are the handshake approach and the wait-free approach.

</details>


### [200] [Parallel Point-to-Point Shortest Paths and Batch Queries](https://arxiv.org/abs/2506.16488)
*Xiaojun Dong,Andy Li,Yan Gu,Yihan Sun*

Main category: cs.DC

TL;DR: Orionet提出了一种高效的并行点对点最短路径（PPSP）查询方法，结合双向搜索（BiDS）和其他启发式算法，并扩展到批量查询。实验表明其性能显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 解决现有单源最短路径（SSSP）框架在并行PPSP查询中的效率问题，并扩展到批量查询的实际应用场景。

Method: 结合双向搜索、A*搜索和双向A*，设计并行PPSP算法，并扩展为批量查询框架。

Result: 双向搜索比GraphIt快2.9倍，比MBQ快6.8倍；双向A*比GraphIt和MBQ分别快4.4倍和6.2倍。

Conclusion: Orionet在单次和批量PPSP查询中均表现出高效性，为实际应用提供了有力支持。

Abstract: We propose Orionet, efficient parallel implementations of Point-to-Point
Shortest Paths (PPSP) queries using bidirectional search (BiDS) and other
heuristics, with an additional focus on batch PPSP queries. We present a
framework for parallel PPSP built on existing single-source shortest paths
(SSSP) frameworks by incorporating pruning conditions. As a result, we develop
efficient parallel PPSP algorithms based on early termination, bidirectional
search, A$^*$ search, and bidirectional A$^*$ all with simple and efficient
implementations.
  We extend our idea to batch PPSP queries, which are widely used in real-world
scenarios. We first design a simple and flexible abstraction to represent the
batch so PPSP can leverage the shared information of the batch. Orionet
formalizes the batch as a query graph represented by edges between queried
sources and targets. In this way, we directly extended our PPSP framework to
batched queries in a simple and efficient way.
  We evaluate Orionet on both single and batch PPSP queries using various graph
types and distance percentiles of queried pairs, and compare it against two
baselines, GraphIt and MBQ. Both of them support parallel single PPSP and A$^*$
using unidirectional search. On 14 graphs we tested, on average, our
bidirectional search is 2.9$\times$ faster than GraphIt, and 6.8$\times$ faster
than MBQ. Our bidirectional A$^*$ is 4.4$\times$ and 6.2$\times$ faster than
the A$^*$ in GraphIt and MBQ, respectively. For batched PPSP queries, we also
provide in-depth experimental evaluation, and show that Orionet provides strong
performance compared to the plain solutions.

</details>


### [201] [Enabling Blockchain Interoperability Through Network Discovery Services](https://arxiv.org/abs/2506.16611)
*Khalid Hassan,Amirreza Sokhankhosh,Sara Rouhani*

Main category: cs.DC

TL;DR: 本文提出了一种去中心化的区块链网络发现架构，解决了现有解决方案中网络初始发现未被解决的问题，并展示了其高扩展性和低延迟性能。


<details>
  <summary>Details</summary>
Motivation: 随着区块链网络的快速发展，现有解决方案通常假设网络已相互感知，但初始发现仍未被解决，亟需一种去中心化的发现机制。

Method: 提出了一种去中心化的区块链网络发现架构，引入激励机制鼓励节点参与维护发现网络，并使用Substrate框架实现和评估。

Result: 在测试网络配置下，架构能处理13万并发请求，中位响应时间为5.5毫秒，展示了高扩展性和低延迟。

Conclusion: 该去中心化发现架构具有实际可行性，能够满足未来区块链网络的需求。

Abstract: Web3 technologies have experienced unprecedented growth in the last decade,
achieving widespread adoption. As various blockchain networks continue to
evolve, we are on the cusp of a paradigm shift in which they could provide
services traditionally offered by the Internet, but in a decentralized manner,
marking the emergence of the Internet of Blockchains. While significant
progress has been achieved in enabling interoperability between blockchain
networks, existing solutions often assume that networks are already mutually
aware. This reveals a critical gap: the initial discovery of blockchain
networks remains largely unaddressed. This paper proposes a decentralized
architecture for blockchain network discovery that operates independently of
any centralized authority. We also introduce a mechanism for discovering assets
and services within a blockchain from external networks. Given the
decentralized nature of the proposed discovery architecture, we design an
incentive mechanism to encourage nodes to actively participate in maintaining
the discovery network. The proposed architecture implemented and evaluated,
using the Substrate framework, demonstrates its resilience and scalability,
effectively handling up to 130,000 concurrent requests under the tested network
configurations, with a median response time of 5.5 milliseconds, demonstrating
the ability to scale its processing capacity further by increasing its network
size.

</details>


### [202] [JANUS: Resilient and Adaptive Data Transmission for Enabling Timely and Efficient Cross-Facility Scientific Workflows](https://arxiv.org/abs/2506.17084)
*Vladislav Esaulov,Jieyang Chen,Norbert Podhorszki,Fred Suter,Scott Klasky,Anu G Bourgeois,Lipeng Wan*

Main category: cs.DC

TL;DR: JANUS是一种用于跨设施科学工作流的弹性自适应数据传输方法，结合UDP、纠删码和有损压缩，显著提升了传输效率。


<details>
  <summary>Details</summary>
Motivation: 现代科学项目中跨设施工作流的数据传输面临带宽压力、TCP重传和纠删码开销等问题，需要更高效的解决方案。

Method: JANUS采用UDP协议，集成纠删码和有损压缩，动态调整参数以适应实时网络条件，并通过优化模型确定最佳配置。

Result: 实验表明，JANUS在保持数据保真度的同时，显著提高了数据传输效率。

Conclusion: JANUS为跨设施科学工作流提供了一种高效、灵活的数据传输方案。

Abstract: In modern science, the growing complexity of large-scale projects has
increased reliance on cross-facility workflows, where institutions share
resources and expertise to accelerate discovery. These workflows often involve
transferring massive data over wide-area networks. While high-speed networks
like ESnet and data transfer services like Globus have improved data mobility,
challenges remain. Large data volumes can strain bandwidth, TCP suffers from
retransmissions due to packet loss, and traditional fault-tolerance methods
like erasure coding introduce significant overhead.
  This paper presents JANUS, a resilient and adaptive data transmission
approach for cross-facility scientific workflows. JANUS uses UDP, integrates
erasure coding for fault tolerance, and applies error-bounded lossy compression
to reduce overhead. This design enables users to balance transmission time and
accuracy based on specific needs. JANUS also adapts coding parameters to
real-time network conditions and uses optimization models to determine ideal
configurations. Experiments show that JANUS significantly improves data
transfer efficiency while preserving fidelity.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [203] [DeepRTL2: A Versatile Model for RTL-Related Tasks](https://arxiv.org/abs/2506.15697)
*Yi Liu,Hongji Zhang,Yunhao Zhou,Zhengyuan Shi,Changran Xu,Qiang Xu*

Main category: cs.AR

TL;DR: DeepRTL2是一个多功能大型语言模型家族，首次统一了RTL相关的生成和嵌入任务，填补了EDA领域的空白，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs在EDA中的生成任务，而忽略了同样关键的嵌入任务（如代码搜索、功能等价性检查等），这些任务对硬件设计流程至关重要。

Method: 提出了DeepRTL2，一个同时处理生成和嵌入任务的模型家族，覆盖EDA中的多样化需求。

Result: 实验表明，DeepRTL2在所有评估任务中均达到最先进的性能。

Conclusion: DeepRTL2为EDA领域提供了首个全面解决方案，显著推动了硬件设计流程的加速和优化。

Abstract: The integration of large language models (LLMs) into electronic design
automation (EDA) has significantly advanced the field, offering transformative
benefits, particularly in register transfer level (RTL) code generation and
understanding. While previous studies have demonstrated the efficacy of
fine-tuning LLMs for these generation-based tasks, embedding-based tasks, which
are equally critical to EDA workflows, have been largely overlooked. These
tasks, including natural language code search, RTL code functionality
equivalence checking, and performance prediction, are essential for
accelerating and optimizing the hardware design process. To address this gap,
we present DeepRTL2, a family of versatile LLMs that unifies both generation-
and embedding-based tasks related to RTL. By simultaneously tackling a broad
range of tasks, DeepRTL2 represents the first model to provide a comprehensive
solution to the diverse challenges in EDA. Through extensive experiments, we
show that DeepRTL2 achieves state-of-the-art performance across all evaluated
tasks.

</details>


### [204] [Profile-Guided Temporal Prefetching](https://arxiv.org/abs/2506.15985)
*Mengming Li,Qijun Zhang,Yichuan Gao,Wenji Fang,Yao Lu,Yongqing Ren,Zhiyao Xie*

Main category: cs.AR

TL;DR: Prophet是一种硬件-软件协同设计的框架，通过配置文件引导的方法优化元数据存储管理，显著提升不规则内存访问模式的性能。


<details>
  <summary>Details</summary>
Motivation: 现有预取方案难以高效利用有限的片上存储，而软件间接访问预取对时间预取的优化效果不佳。

Method: Prophet使用计数器而非跟踪文件分析程序，注入提示以指导元数据存储管理，并动态调整这些提示以适应不同输入。

Result: Prophet比现有最佳时间预取器Triangel性能提升14.23%，在复杂时间模式中表现优异。

Conclusion: Prophet为高频执行工作负载提供高效解决方案，同时保持低频工作负载的原始运行时方案，性能优越且开销可忽略。

Abstract: Temporal prefetching shows promise for handling irregular memory access
patterns, which are common in data-dependent and pointer-based data structures.
Recent studies introduced on-chip metadata storage to reduce the memory traffic
caused by accessing metadata from off-chip DRAM. However, existing prefetching
schemes struggle to efficiently utilize the limited on-chip storage. An
alternative solution, software indirect access prefetching, remains ineffective
for optimizing temporal prefetching.
  In this work, we propose Prophet--a hardware-software co-designed framework
that leverages profile-guided methods to optimize metadata storage management.
Prophet profiles programs using counters instead of traces, injects hints into
programs to guide metadata storage management, and dynamically tunes these
hints to enable the optimized binary to adapt to different program inputs.
Prophet is designed to coexist with existing hardware temporal prefetchers,
delivering efficient, high-performance solutions for frequently executed
workloads while preserving the original runtime scheme for less frequently
executed workloads. Prophet outperforms the state-of-the-art temporal
prefetcher, Triangel, by 14.23%, effectively addressing complex temporal
patterns where prior profile-guided solutions fall short (only achieving 0.1%
performance gain). Prophet delivers superior performance across all evaluated
workload inputs, introducing negligible profiling, analysis, and instruction
overhead.

</details>


### [205] [HetGPU: The pursuit of making binary compatibility towards GPUs](https://arxiv.org/abs/2506.15993)
*Yiwei Yang,Yusheng Zheng,Tong Yu,Andi Quinn*

Main category: cs.AR

TL;DR: hetGPU系统通过编译器、运行时和抽象层，实现单一GPU二进制在多种硬件上的执行，解决了异构GPU的兼容性问题。


<details>
  <summary>Details</summary>
Motivation: 异构GPU基础设施因指令集、执行模型和驱动栈的差异导致二进制兼容性问题，限制了跨厂商GPU的使用。

Method: hetGPU编译器生成架构无关的GPU中间表示（IR），运行时动态翻译为目标GPU原生代码，并提供统一的线程、内存和同步抽象。

Result: 初步评估显示，hetGPU编译的未修改GPU二进制可在不同GPU间迁移，开销极小。

Conclusion: hetGPU为跨厂商GPU计算提供了可行方案。

Abstract: Heterogeneous GPU infrastructures present a binary compatibility challenge:
code compiled for one vendor's GPU will not run on another due to divergent
instruction sets, execution models, and driver stacks . We propose hetGPU, a
new system comprising a compiler, runtime, and abstraction layer that together
enable a single GPU binary to execute on NVIDIA, AMD, Intel, and Tenstorrent
hardware. The hetGPU compiler emits an architecture-agnostic GPU intermediate
representation (IR) and inserts metadata for managing execution state. The
hetGPU runtime then dynamically translates this IR to the target GPU's native
code and provides a uniform abstraction of threads, memory, and
synchronization. Our design tackles key challenges: differing SIMT vs. MIMD
execution (warps on NVIDIA/AMD vs. many-core RISC-V on Tenstorrent), varied
instruction sets, scheduling and memory model discrepancies, and the need for
state serialization for live migration. We detail the hetGPU architecture,
including the IR transformation pipeline, a state capture/reload mechanism for
live GPU migration, and an abstraction layer that bridges warp-centric and
core-centric designs. Preliminary evaluation demonstrates that unmodified GPU
binaries compiled with hetGPU can be migrated across disparate GPUs with
minimal overhead, opening the door to vendor-agnostic GPU computing.

</details>


### [206] [SparseDPD: A Sparse Neural Network-based Digital Predistortion FPGA Accelerator for RF Power Amplifier Linearization](https://arxiv.org/abs/2506.16591)
*Manno Versluis,Yizhuo Wu,Chang Gao*

Main category: cs.AR

TL;DR: SparseDPD是一种基于FPGA的加速器，采用稀疏相位归一化时延神经网络（PNTDNN），通过非结构化剪枝优化计算负载，保持精度，显著提升无线系统中数字预失真（DPD）的实时性能。


<details>
  <summary>Details</summary>
Motivation: 传统多项式模型在数字预失真（DPD）中性能有限，神经网络（NN）方法虽优但计算复杂度高，难以实际部署。本文旨在解决这一问题。

Method: 提出SparseDPD，一种基于FPGA的加速器，采用稀疏相位归一化时延神经网络（PNTDNN），并通过非结构化剪枝优化计算效率。

Result: 在Xilinx Zynq-7Z010 FPGA上实现，运行频率170 MHz，性能优异（ACPR: -59.4 dBc, EVM: -54.0 dBc, NMSE: -48.2 dB），动态功耗仅241 mW，参数64个，稀疏度74%。

Conclusion: SparseDPD证明了FPGA加速的可行性，使基于神经网络的DPD在实时无线通信中更实用高效。

Abstract: Digital predistortion (DPD) is crucial for linearizing radio frequency (RF)
power amplifiers (PAs), improving signal integrity and efficiency in wireless
systems. Neural network (NN)-based DPD methods surpass traditional polynomial
models but face computational challenges limiting their practical deployment.
This paper introduces SparseDPD, an FPGA accelerator employing a spatially
sparse phase-normalized time-delay neural network (PNTDNN), optimized through
unstructured pruning to reduce computational load without accuracy loss.
Implemented on a Xilinx Zynq-7Z010 FPGA, SparseDPD operates at 170 MHz,
achieving exceptional linearization performance (ACPR: -59.4 dBc, EVM: -54.0
dBc, NMSE: -48.2 dB) with only 241 mW dynamic power, using 64 parameters with
74% sparsity. This work demonstrates FPGA-based acceleration, making NN-based
DPD practical and efficient for real-time wireless communication applications.
Code is publicly available at https://github.com/MannoVersluis/SparseDPD.

</details>


### [207] [Lookup Table-based Multiplication-free All-digital DNN Accelerator Featuring Self-Synchronous Pipeline Accumulation](https://arxiv.org/abs/2506.16800)
*Hiroto Tagata,Takashi Sato,Hiromitsu Awano*

Main category: cs.AR

TL;DR: 本文提出了一种基于MADDNESS的全数字加速器，通过自同步流水线累加器实现高效能、低功耗且不受PVT影响的运算。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNNs）的大规模矩阵运算导致高功耗，现有模拟计算电路在面积效率和计算精度上存在挑战。

Method: 采用全数字加速器设计，结合自同步流水线累加器，替代传统矩阵乘法运算。

Result: 在22nm工艺下，能效提升2.5倍（174 TOPS/W），面积效率提升5倍（2.01 TOPS/mm2）。

Conclusion: 该方法显著提升了能效和面积效率，为DNNs的节能计算提供了新思路。

Abstract: Deep neural networks (DNNs) have been widely applied in our society, yet
reducing power consumption due to large-scale matrix computations remains a
critical challenge. MADDNESS is a known approach to improving energy efficiency
by substituting matrix multiplication with table lookup operations. Previous
research has employed large analog computing circuits to convert inputs into
LUT addresses, which presents challenges to area efficiency and computational
accuracy. This paper proposes a novel MADDNESS-based all-digital accelerator
featuring a self-synchronous pipeline accumulator, resulting in a compact,
energy-efficient, and PVT-invariant computation. Post-layout simulation using a
commercial 22nm process showed that 2.5 times higher energy efficiency (174
TOPS/W) and 5 times higher area efficiency (2.01 TOPS/mm2) can be achieved
compared to the conventional accelerator.

</details>


### [208] [RCNet: $ΔΣ$ IADCs as Recurrent AutoEncoders](https://arxiv.org/abs/2506.16903)
*Arnaud Verdant,William Guicquero,Jérôme Chossat*

Main category: cs.AR

TL;DR: 本文提出了一种用于Delta-Sigma ADC的深度学习模型（RCNet），通过RNN描述调制器和滤波器，结合硬件设计约束优化SNR与面积。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用深度学习模型优化Delta-Sigma ADC的设计，特别是在硬件约束下实现高性能。

Method: 使用RNN描述调制器和滤波器，结合高端优化器和自定义损失函数，量化权重、信号饱和等硬件约束。

Result: 在DC转换中，RCNet成功在特定硬件复杂度下优化SNR（>13bit）与面积（<14pF），且最优架构不依赖高阶调制器。

Conclusion: RCNet为Delta-Sigma ADC设计提供了新的自由度，展示了在硬件约束下优化性能的潜力。

Abstract: This paper proposes a deep learning model (RCNet) for Delta-Sigma
($\Delta\Sigma$) ADCs. Recurrent Neural Networks (RNNs) allow to describe both
modulators and filters. This analogy is applied to Incremental ADCs (IADC).
High-end optimizers combined with full-custom losses are used to define
additional hardware design constraints: quantized weights, signal saturation,
temporal noise injection, devices area. Focusing on DC conversion, our early
results demonstrate that $SNR$ defined as an Effective Number Of Bits (ENOB)
can be optimized under a certain hardware mapping complexity. The proposed
RCNet succeeded to provide design tradeoffs in terms of $SNR$ ($>$13bit) versus
area constraints ($<$14pF total capacitor) at a given $OSR$ (80 samples).
Interestingly, it appears that the best RCNet architectures do not necessarily
rely on high-order modulators, leveraging additional topology exploration
degrees of freedom.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [209] [A System Level Compiler for Massively-Parallel, Spatial, Dataflow Architectures](https://arxiv.org/abs/2506.15875)
*Dirk Van Essendelft,Patrick Wingo,Terry Jordan,Ryan Smith,Wissam Saidi*

Main category: cs.PL

TL;DR: MACH是一种新型编译器，专为大规模并行、空间数据流架构设计，同时支持传统统一内存设备。它通过虚拟机和领域特定语言简化了编译过程。


<details>
  <summary>Details</summary>
Motivation: 解决为空间架构编译代码的复杂性，同时支持多种架构和灵活的数据映射。

Method: 使用虚拟机概念、领域特定语言，并将高级语言编译为符合虚拟机概念的机器特定代码。

Result: 展示了针对NumPy密集张量的示例，并成功将代码编译到Wafer Scale Engine。

Conclusion: MACH为空间架构编译提供了灵活且高效的解决方案，支持多种硬件目标。

Abstract: We have developed a novel compiler called the Multiple-Architecture Compiler
for Advanced Computing Hardware (MACH) designed specifically for
massively-parallel, spatial, dataflow architectures like the Wafer Scale
Engine. Additionally, MACH can execute code on traditional unified-memory
devices. MACH addresses the complexities in compiling for spatial architectures
through a conceptual Virtual Machine, a flexible domain-specific language, and
a compiler that can lower high-level languages to machine-specific code in
compliance with the Virtual Machine concept. While MACH is designed to be
operable on several architectures and provide the flexibility for several
standard and user-defined data mappings, we introduce the concept with dense
tensor examples from NumPy and show lowering to the Wafer Scale Engine by
targeting Cerebras' hardware specific languages.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [210] [Incentivizing High-quality Participation From Federated Learning Agents](https://arxiv.org/abs/2506.16731)
*Jinlong Pang,Jiaheng Wei,Yifan Hua,Chen Qian,Yang Liu*

Main category: cs.AI

TL;DR: 该论文提出了一种激励感知的联邦学习框架，解决自利代理参与不足和数据异构性问题，通过Wasserstein距离和博弈论方法优化模型收敛。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习研究假设代理自愿无私参与，但实际中自利代理可能退出或提供低质量贡献，且数据异构性导致聚合模型效果不佳。

Method: 引入Wasserstein距离量化数据异构性，改进收敛上界；利用同伴预测机制设计评分函数；提出两阶段Stackelberg博弈模型验证均衡存在性。

Result: 在真实数据集上的实验验证了所提机制的有效性。

Conclusion: 该框架通过激励设计和数据异构性处理，显著提升了联邦学习的参与积极性和模型性能。

Abstract: Federated learning (FL) provides a promising paradigm for facilitating
collaboration between multiple clients that jointly learn a global model
without directly sharing their local data. However, existing research suffers
from two caveats: 1) From the perspective of agents, voluntary and unselfish
participation is often assumed. But self-interested agents may opt out of the
system or provide low-quality contributions without proper incentives; 2) From
the mechanism designer's perspective, the aggregated models can be
unsatisfactory as the existing game-theoretical federated learning approach for
data collection ignores the potential heterogeneous effort caused by
contributed data. To alleviate above challenges, we propose an incentive-aware
framework for agent participation that considers data heterogeneity to
accelerate the convergence process. Specifically, we first introduce the notion
of Wasserstein distance to explicitly illustrate the heterogeneous effort and
reformulate the existing upper bound of convergence. To induce truthful
reporting from agents, we analyze and measure the generalization error gap of
any two agents by leveraging the peer prediction mechanism to develop score
functions. We further present a two-stage Stackelberg game model that
formalizes the process and examines the existence of equilibrium. Extensive
experiments on real-world datasets demonstrate the effectiveness of our
proposed mechanism.

</details>


### [211] [OAgents: An Empirical Study of Building Effective Agents](https://arxiv.org/abs/2506.15741)
*He Zhu,Tianrui Qin,King Zhu,Heyuan Huang,Yeyi Guan,Jinxiang Xia,Yi Yao,Hanhao Li,Ningning Wang,Pai Liu,Tianhao Peng,Xin Gui,Xiaowan Li,Yuhui Liu,Yuchen Eleanor Jiang,Jun Wang,Changwang Zhang,Xiangru Tang,Ge Zhang,Jian Yang,Minghao Liu,Xitong Gao,Wangchunshu Zhou,Jiaheng Liu*

Main category: cs.AI

TL;DR: 该论文指出当前Agentic AI研究缺乏标准化和科学严谨性，通过系统性实证研究提出更稳健的评估协议，并开源了高性能的OAgents框架。


<details>
  <summary>Details</summary>
Motivation: 当前Agentic AI研究缺乏标准化和科学严谨性，导致方法间难以公平比较，设计选择对效果的影响不明确。

Method: 在GAIA基准和BrowseComp上进行系统性实证研究，分析关键组件设计选择的影响，并提出新的评估协议。

Result: 研究发现缺乏标准评估协议导致先前工作不可复现，且随机运行间差异显著；提出更稳健的评估协议并开源OAgents框架。

Conclusion: OAgents框架通过模块化设计提升了Agentic AI研究的标准化和性能，为未来研究提供了基础。

Abstract: Recently, Agentic AI has become an increasingly popular research field.
However, we argue that current agent research practices lack standardization
and scientific rigor, making it hard to conduct fair comparisons among methods.
As a result, it is still unclear how different design choices in agent
frameworks affect effectiveness, and measuring their progress remains
challenging. In this work, we conduct a systematic empirical study on GAIA
benchmark and BrowseComp to examine the impact of popular design choices in key
agent components in a fair and rigorous manner. We find that the lack of a
standard evaluation protocol makes previous works, even open-sourced ones,
non-reproducible, with significant variance between random runs. Therefore, we
introduce a more robust evaluation protocol to stabilize comparisons. Our study
reveals which components and designs are crucial for effective agents, while
others are redundant, despite seeming logical. Based on our findings, we build
and open-source OAgents, a new foundation agent framework that achieves
state-of-the-art performance among open-source projects. OAgents offers a
modular design for various agent components, promoting future research in
Agentic AI.

</details>


### [212] [SLR: An Automated Synthesis Framework for Scalable Logical Reasoning](https://arxiv.org/abs/2506.15787)
*Lukas Helff,Ahmad Omar,Felix Friedrich,Wolfgang Stammer,Antonia Wüst,Tim Woydt,Rupert Mitchell,Patrick Schramowski,Kristian Kersting*

Main category: cs.AI

TL;DR: SLR是一个端到端框架，用于通过可扩展的逻辑推理系统评估和训练大型语言模型（LLMs）。它自动化生成推理任务，并创建SLR-Bench基准测试，结果显示当前LLMs在逻辑推理上仍有不足，但通过SLR调优可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在逻辑推理任务上表现不佳，且缺乏系统化的评估和训练方法。SLR旨在提供一个自动化、可扩展的框架来解决这些问题。

Method: SLR通过自动化合成推理任务，包括潜在规则、验证程序和指令提示。基于此创建SLR-Bench，涵盖20个难度递增的课程级别。

Result: 评估显示当代LLMs在逻辑推理上表现有限，但通过SLR调优（如Llama-3-8B）可将准确率翻倍，达到与更高计算成本模型相当的水平。

Conclusion: SLR为LLMs的推理能力提供了自动化、可扩展的评估和训练环境，无需人工标注，且能显著提升模型性能。

Abstract: We introduce SLR, an end-to-end framework for systematic evaluation and
training of Large Language Models (LLMs) via Scalable Logical Reasoning. Given
a user's task specification, SLR enables scalable, automated synthesis of
inductive reasoning tasks with precisely controlled difficulty. For each task,
SLR synthesizes (i) a latent ground-truth rule, (ii) an executable validation
program used by a symbolic judge to deterministically verify model outputs, and
(iii) an instruction prompt for the reasoning task. Using SLR, we create
SLR-Bench, a benchmark comprising over 19k prompts spanning 20 curriculum
levels that progressively increase in relational, arithmetic, and recursive
complexity. Large-scale evaluation reveals that contemporary LLMs readily
produce syntactically valid rules, yet often fail at correct logical inference.
Recent reasoning LLMs do somewhat better, but incur substantial increases in
test-time compute, sometimes exceeding 15k completion tokens. Finally,
logic-tuning via SLR doubles Llama-3-8B accuracy on SLR-Bench, achieving parity
with Gemini-Flash-Thinking at a fraction of computational cost. SLR is fully
automated, requires no human annotation, ensures dataset novelty, and offers a
scalable environment for probing and advancing LLMs' reasoning capabilities.

</details>


### [213] [Exploring Big Five Personality and AI Capability Effects in LLM-Simulated Negotiation Dialogues](https://arxiv.org/abs/2506.15928)
*Myke C. Cohen,Zhe Su,Hsien-Te Kao,Daniel Nguyen,Spencer Lynch,Maarten Sap,Svitlana Volkova*

Main category: cs.AI

TL;DR: 论文提出了一个评估框架，用于关键任务谈判中的AI代理系统，通过实验研究了人格特质和AI特性对谈判结果的影响。


<details>
  <summary>Details</summary>
Motivation: 解决AI代理在多样人类操作者和利益相关者中适应性的需求，特别是在高风险的跨团队协调和军民互动中。

Method: 使用Sotopia模拟平台，通过两个实验系统评估人格特质和AI特性对LLM模拟社交谈判的影响。实验1采用因果发现方法分析人格特质对价格谈判的影响；实验2评估人类-AI工作谈判中透明度和适应性等AI特性的作用。

Result: 实验1发现亲和性和外向性显著影响谈判结果；实验2表明AI代理的可信度对任务有效性至关重要。

Conclusion: 研究为AI代理的可靠性评估提供了可重复的方法，并强调了社交动态在复杂任务中的重要性。

Abstract: This paper presents an evaluation framework for agentic AI systems in
mission-critical negotiation contexts, addressing the need for AI agents that
can adapt to diverse human operators and stakeholders. Using Sotopia as a
simulation testbed, we present two experiments that systematically evaluated
how personality traits and AI agent characteristics influence LLM-simulated
social negotiation outcomes--a capability essential for a variety of
applications involving cross-team coordination and civil-military interactions.
Experiment 1 employs causal discovery methods to measure how personality traits
impact price bargaining negotiations, through which we found that Agreeableness
and Extraversion significantly affect believability, goal achievement, and
knowledge acquisition outcomes. Sociocognitive lexical measures extracted from
team communications detected fine-grained differences in agents' empathic
communication, moral foundations, and opinion patterns, providing actionable
insights for agentic AI systems that must operate reliably in high-stakes
operational scenarios. Experiment 2 evaluates human-AI job negotiations by
manipulating both simulated human personality and AI system characteristics,
specifically transparency, competence, adaptability, demonstrating how AI agent
trustworthiness impact mission effectiveness. These findings establish a
repeatable evaluation methodology for experimenting with AI agent reliability
across diverse operator personalities and human-agent team dynamics, directly
supporting operational requirements for reliable AI systems. Our work advances
the evaluation of agentic AI workflows by moving beyond standard performance
metrics to incorporate social dynamics essential for mission success in complex
operations.

</details>


### [214] [Bayesian Epistemology with Weighted Authority: A Formal Architecture for Truth-Promoting Autonomous Scientific Reasoning](https://arxiv.org/abs/2506.16015)
*Craig S. Wright*

Main category: cs.AI

TL;DR: BEWA是一种基于贝叶斯推理的动态信念架构，通过结构化科学主张、作者可信度建模和加密锚定，提升机器推理系统的真实性和可审计性。


<details>
  <summary>Details</summary>
Motivation: 科学文献的指数增长超出了人类和AI系统的处理能力，需要一种新的架构来动态、概率化地评估科学主张。

Method: BEWA采用贝叶斯推理、复制评分、引用权重和时间衰减机制，构建了一个基于图的科学主张传播网络。

Result: BEWA实现了动态科学领域的理性信念收敛、真实性提升和可审计性。

Conclusion: BEWA为机器推理系统提供了可验证的认知网络基础，支持科学领域的动态推理和完整性维护。

Abstract: The exponential expansion of scientific literature has surpassed the
epistemic processing capabilities of both human experts and current artificial
intelligence systems. This paper introduces Bayesian Epistemology with Weighted
Authority (BEWA), a formally structured architecture that operationalises
belief as a dynamic, probabilistically coherent function over structured
scientific claims. Each claim is contextualised, author-attributed, and
evaluated through a system of replication scores, citation weighting, and
temporal decay. Belief updates are performed via evidence-conditioned Bayesian
inference, contradiction processing, and epistemic decay mechanisms. The
architecture supports graph-based claim propagation, authorial credibility
modelling, cryptographic anchoring, and zero-knowledge audit verification. By
formalising scientific reasoning into a computationally verifiable epistemic
network, BEWA advances the foundation for machine reasoning systems that
promote truth utility, rational belief convergence, and audit-resilient
integrity across dynamic scientific domains.

</details>


### [215] [IS-Bench: Evaluating Interactive Safety of VLM-Driven Embodied Agents in Daily Household Tasks](https://arxiv.org/abs/2506.16402)
*Xiaoya Lu,Zeren Chen,Xuhao Hu,Yijin Zhou,Weichen Zhang,Dongrui Liu,Lu Sheng,Jing Shao*

Main category: cs.AI

TL;DR: 论文提出IS-Bench，首个多模态交互安全基准，用于评估VLM驱动智能体在动态环境中的安全能力。


<details>
  <summary>Details</summary>
Motivation: 现有静态评估方法无法捕捉动态风险，阻碍了智能体在真实家庭任务中的安全部署。

Method: 提出交互安全评估框架，设计包含161个场景的IS-Bench，支持过程导向评估。

Result: 实验显示当前VLM智能体缺乏交互安全意识，安全感知的Chain-of-Thought虽能提升性能，但可能影响任务完成。

Conclusion: IS-Bench为开发更安全的AI系统奠定了基础，揭示了现有技术的局限性。

Abstract: Flawed planning from VLM-driven embodied agents poses significant safety
hazards, hindering their deployment in real-world household tasks. However,
existing static, non-interactive evaluation paradigms fail to adequately assess
risks within these interactive environments, since they cannot simulate dynamic
risks that emerge from an agent's actions and rely on unreliable post-hoc
evaluations that ignore unsafe intermediate steps. To bridge this critical gap,
we propose evaluating an agent's interactive safety: its ability to perceive
emergent risks and execute mitigation steps in the correct procedural order. We
thus present IS-Bench, the first multi-modal benchmark designed for interactive
safety, featuring 161 challenging scenarios with 388 unique safety risks
instantiated in a high-fidelity simulator. Crucially, it facilitates a novel
process-oriented evaluation that verifies whether risk mitigation actions are
performed before/after specific risk-prone steps. Extensive experiments on
leading VLMs, including the GPT-4o and Gemini-2.5 series, reveal that current
agents lack interactive safety awareness, and that while safety-aware
Chain-of-Thought can improve performance, it often compromises task completion.
By highlighting these critical limitations, IS-Bench provides a foundation for
developing safer and more reliable embodied AI systems.

</details>


### [216] [Advancing Harmful Content Detection in Organizational Research: Integrating Large Language Models with Elo Rating System](https://arxiv.org/abs/2506.16575)
*Mustafa Akben,Aaron Satko*

Main category: cs.AI

TL;DR: 本文提出了一种基于Elo评级的改进方法，显著提升了大语言模型（LLM）在有害内容分析中的表现，尤其在微侵犯和仇恨言论检测方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: LLM的内置审核系统在分析有害内容时可能导致结果失真或过于保守，影响研究有效性，尤其是在组织冲突（如微侵犯或仇恨言论）分析中。

Method: 采用Elo评级方法改进LLM的有害内容分析性能，并在微侵犯检测和仇恨言论两个数据集上进行验证。

Result: 该方法在准确性、精确度和F1分数等关键指标上优于传统LLM提示技术和常规机器学习模型，具有更高的可靠性和可扩展性。

Conclusion: 该方法为组织应用（如职场骚扰检测和有毒沟通评估）提供了更有效和可扩展的解决方案，有助于创建更安全、包容的工作环境。

Abstract: Large language models (LLMs) offer promising opportunities for organizational
research. However, their built-in moderation systems can create problems when
researchers try to analyze harmful content, often refusing to follow certain
instructions or producing overly cautious responses that undermine validity of
the results. This is particularly problematic when analyzing organizational
conflicts such as microaggressions or hate speech. This paper introduces an Elo
rating-based method that significantly improves LLM performance for harmful
content analysis In two datasets, one focused on microaggression detection and
the other on hate speech, we find that our method outperforms traditional LLM
prompting techniques and conventional machine learning models on key measures
such as accuracy, precision, and F1 scores. Advantages include better
reliability when analyzing harmful content, fewer false positives, and greater
scalability for large-scale datasets. This approach supports organizational
applications, including detecting workplace harassment, assessing toxic
communication, and fostering safer and more inclusive work environments.

</details>


### [217] [Are Bias Evaluation Methods Biased ?](https://arxiv.org/abs/2506.17111)
*Lina Berrayana,Sean Rooney,Luis Garcés-Erice,Ioana Giurgiu*

Main category: cs.AI

TL;DR: 论文探讨了大型语言模型安全性评估基准的稳健性，发现不同方法会导致模型排名差异，并提出了使用建议。


<details>
  <summary>Details</summary>
Motivation: 评估基准是可信AI社区的核心活动，但不同方法可能导致不一致的模型排名，需研究其稳健性。

Method: 通过不同方法对代表性模型进行偏见排名，比较整体排名的相似性。

Result: 广泛使用的偏见评估方法导致模型排名显著不同。

Conclusion: 建议社区在使用评估基准时注意方法差异，以确保结果一致性。

Abstract: The creation of benchmarks to evaluate the safety of Large Language Models is
one of the key activities within the trusted AI community. These benchmarks
allow models to be compared for different aspects of safety such as toxicity,
bias, harmful behavior etc. Independent benchmarks adopt different approaches
with distinct data sets and evaluation methods. We investigate how robust such
benchmarks are by using different approaches to rank a set of representative
models for bias and compare how similar are the overall rankings. We show that
different but widely used bias evaluations methods result in disparate model
rankings. We conclude with recommendations for the community in the usage of
such benchmarks.

</details>


### [218] [The Safety Reminder: A Soft Prompt to Reactivate Delayed Safety Awareness in Vision-Language Models](https://arxiv.org/abs/2506.15734)
*Peiyuan Tang,Haojie Xin,Xiaodong Zhang,Jun Sun,Qin Xia,Zijiang Yang*

Main category: cs.AI

TL;DR: 该论文提出了一种名为“安全提醒”的软提示调优方法，通过优化可学习的提示标记来增强视觉语言模型（VLM）的安全性，防止生成有害内容。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型（VLM）在代码生成和聊天机器人等实际应用中的能力增强，其安全性问题日益突出。VLM因其多模态特性面临独特的安全漏洞，可能导致生成有害内容。

Method: 通过系统分析VLM在攻击下的行为，发现“延迟安全意识”现象，并提出“安全提醒”方法，即在文本生成过程中定期注入优化的提示标记以增强安全意识。

Result: 在三个安全基准和一个对抗攻击测试中，该方法显著降低了攻击成功率，同时保持了模型在正常任务中的性能。

Conclusion: “安全提醒”是一种实用的解决方案，可有效提升VLM在现实应用中的安全性。

Abstract: As Vision-Language Models (VLMs) demonstrate increasing capabilities across
real-world applications such as code generation and chatbot assistance,
ensuring their safety has become paramount. Unlike traditional Large Language
Models (LLMs), VLMs face unique vulnerabilities due to their multimodal nature,
allowing adversaries to modify visual or textual inputs to bypass safety
guardrails and trigger the generation of harmful content. Through systematic
analysis of VLM behavior under attack, we identify a novel phenomenon termed
``delayed safety awareness''. Specifically, we observe that safety-aligned VLMs
may initially be compromised to produce harmful content, but eventually
recognize the associated risks and attempt to self-correct. This pattern
suggests that VLMs retain their underlying safety awareness but experience a
temporal delay in their activation. Building on this insight, we hypothesize
that VLMs' safety awareness can be proactively reactivated through carefully
designed prompts. To this end, we introduce ``The Safety Reminder'', a soft
prompt tuning approach that optimizes learnable prompt tokens, which are
periodically injected during the text generation process to enhance safety
awareness, effectively preventing harmful content generation. Additionally, our
safety reminder only activates when harmful content is detected, leaving normal
conversations unaffected and preserving the model's performance on benign
tasks. Through comprehensive evaluation across three established safety
benchmarks and one adversarial attacks, we demonstrate that our approach
significantly reduces attack success rates while maintaining model utility,
offering a practical solution for deploying safer VLMs in real-world
applications.

</details>


### [219] [AI's Blind Spots: Geographic Knowledge and Diversity Deficit in Generated Urban Scenario](https://arxiv.org/abs/2506.16898)
*Ciro Beneduce,Massimiliano Luca,Bruno Lepri*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Image generation models are revolutionizing many domains, and urban analysis
and design is no exception. While such models are widely adopted, there is a
limited literature exploring their geographic knowledge, along with the biases
they embed. In this work, we generated 150 synthetic images for each state in
the USA and related capitals using FLUX 1 and Stable Diffusion 3.5, two
state-of-the-art models for image generation. We embed each image using DINO-v2
ViT-S/14 and the Fr\'echet Inception Distances to measure the similarity
between the generated images. We found that while these models have implicitly
learned aspects of USA geography, if we prompt the models to generate an image
for "United States" instead of specific cities or states, the models exhibit a
strong representative bias toward metropolis-like areas, excluding rural states
and smaller cities. {\color{black} In addition, we found that models
systematically exhibit some entity-disambiguation issues with European-sounding
names like Frankfort or Devon.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [220] [From Prompts to Constructs: A Dual-Validity Framework for LLM Research in Psychology](https://arxiv.org/abs/2506.16697)
*Zhicheng Lin*

Main category: cs.CY

TL;DR: 论文探讨了在心理学研究中应用大语言模型（LLMs）时可能产生的测量假象问题，提出了一个双效度框架，强调需要结合可靠的测量原则和因果推断标准来建立稳健的AI心理学科学。


<details>
  <summary>Details</summary>
Motivation: 心理学研究中广泛使用LLMs作为工具或模型，但直接应用人类测量工具可能导致矛盾结果，甚至产生虚假现象，因此需要更严谨的验证方法。

Method: 提出了一个双效度框架，根据科学目标的不同（如分类文本或模拟焦虑），要求不同程度的证据支持，并强调需要开发计算模拟的心理构念。

Result: 当前实践往往未能满足这些要求，常将统计模式匹配误认为心理现象的证据。

Conclusion: 未来需要建立清晰、可扩展的证据标准，避免不加批判地应用人类测量工具，以推动AI心理学的发展。

Abstract: Large language models (LLMs) are rapidly being adopted across psychology,
serving as research tools, experimental subjects, human simulators, and
computational models of cognition. However, the application of human
measurement tools to these systems can produce contradictory results, raising
concerns that many findings are measurement phantoms--statistical artifacts
rather than genuine psychological phenomena. In this Perspective, we argue that
building a robust science of AI psychology requires integrating two of our
field's foundational pillars: the principles of reliable measurement and the
standards for sound causal inference. We present a dual-validity framework to
guide this integration, which clarifies how the evidence needed to support a
claim scales with its scientific ambition. Using an LLM to classify text may
require only basic accuracy checks, whereas claiming it can simulate anxiety
demands a far more rigorous validation process. Current practice systematically
fails to meet these requirements, often treating statistical pattern matching
as evidence of psychological phenomena. The same model output--endorsing "I am
anxious"--requires different validation strategies depending on whether
researchers claim to measure, characterize, simulate, or model psychological
constructs. Moving forward requires developing computational analogues of
psychological constructs and establishing clear, scalable standards of evidence
rather than the uncritical application of human measurement tools.

</details>


### [221] [Large Language Models as Psychological Simulators: A Methodological Guide](https://arxiv.org/abs/2506.16702)
*Zhicheng Lin*

Main category: cs.CY

TL;DR: 本文提供了一个框架，指导如何将大型语言模型（LLMs）用作心理学模拟器，涵盖角色模拟和认知建模两大应用，并讨论了验证方法、伦理问题及模型局限性。


<details>
  <summary>Details</summary>
Motivation: 缺乏关于如何将LLMs应用于心理学和行为研究的方法论指导，本文旨在填补这一空白。

Method: 提出两种主要应用：1）模拟角色和人物以探索多样化情境；2）作为计算模型研究认知过程。包括验证方法、因果干预技术和模型行为与人类认知的关联策略。

Result: 整合了LLMs性能的实证证据（如系统性偏见、文化局限性和提示敏感性），帮助研究者应对挑战并利用LLMs的独特能力。

Conclusion: 强调透明度和对模型能力与限制的清晰认识，为心理学研究中LLMs的应用提供了实用框架。

Abstract: Large language models (LLMs) offer emerging opportunities for psychological
and behavioral research, but methodological guidance is lacking. This article
provides a framework for using LLMs as psychological simulators across two
primary applications: simulating roles and personas to explore diverse
contexts, and serving as computational models to investigate cognitive
processes. For simulation, we present methods for developing psychologically
grounded personas that move beyond demographic categories, with strategies for
validation against human data and use cases ranging from studying inaccessible
populations to prototyping research instruments. For cognitive modeling, we
synthesize emerging approaches for probing internal representations,
methodological advances in causal interventions, and strategies for relating
model behavior to human cognition. We address overarching challenges including
prompt sensitivity, temporal limitations from training data cutoffs, and
ethical considerations that extend beyond traditional human subjects review.
Throughout, we emphasize the need for transparency about model capabilities and
constraints. Together, this framework integrates emerging empirical evidence
about LLM performance--including systematic biases, cultural limitations, and
prompt brittleness--to help researchers wrangle these challenges and leverage
the unique capabilities of LLMs in psychological research.

</details>


### [222] [TrajSceneLLM: A Multimodal Perspective on Semantic GPS Trajectory Analysis](https://arxiv.org/abs/2506.16401)
*Chunhou Ji,Qiumeng Li*

Main category: cs.CY

TL;DR: TrajSceneLLM通过结合地图图像和LLM生成的文本描述，提升GPS轨迹的语义理解，显著提高了旅行模式识别的性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以提取GPS轨迹的深层语义表示和整合地图上下文信息，需要一种更有效的方法。

Method: 提出TrajSceneLLM框架，融合地图图像和LLM生成的文本描述，生成多模态嵌入，并通过MLP分类器验证。

Result: 实验表明，该方法在旅行模式识别任务中性能显著提升，减少了对手工特征的依赖。

Conclusion: TrajSceneLLM在捕捉时空依赖性和语义增强方面具有潜力，适用于地理空间人工智能的多样化应用。

Abstract: GPS trajectory data reveals valuable patterns of human mobility and urban
dynamics, supporting a variety of spatial applications. However, traditional
methods often struggle to extract deep semantic representations and incorporate
contextual map information. We propose TrajSceneLLM, a multimodal perspective
for enhancing semantic understanding of GPS trajectories. The framework
integrates visualized map images (encoding spatial context) and textual
descriptions generated through LLM reasoning (capturing temporal sequences and
movement dynamics). Separate embeddings are generated for each modality and
then concatenated to produce trajectory scene embeddings with rich semantic
content which are further paired with a simple MLP classifier. We validate the
proposed framework on Travel Mode Identification (TMI), a critical task for
analyzing travel choices and understanding mobility behavior. Our experiments
show that these embeddings achieve significant performance improvement,
highlighting the advantage of our LLM-driven method in capturing deep
spatio-temporal dependencies and reducing reliance on handcrafted features.
This semantic enhancement promises significant potential for diverse downstream
applications and future research in geospatial artificial intelligence. The
source code and dataset are publicly available at:
https://github.com/februarysea/TrajSceneLLM.

</details>


<div id='astro-ph.EP'></div>

# astro-ph.EP [[Back]](#toc)

### [223] [Exoplanet Classification through Vision Transformers with Temporal Image Analysis](https://arxiv.org/abs/2506.16597)
*Anupma Choudhary,Sohith Bandari,B. S. Kushvah,C. Swastik*

Main category: astro-ph.EP

TL;DR: 论文提出了一种利用Gramian Angular Fields和Recurrence Plots转换开普勒任务光曲线数据，并通过Vision Transformer模型高效分类系外行星的方法，结果显示RPs优于GAFs，模型表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统系外行星分类方法耗费资源且效率低，需借助机器学习提升分类效率。

Method: 将开普勒任务的光曲线数据转换为GAFs和RPs，输入Vision Transformer模型，并通过5折交叉验证评估性能。

Result: ViT模型在RPs上表现更佳，召回率89.46%，精确率85.09%。

Conclusion: 研究强调了优化模型架构的重要性，以提升自动化、性能和泛化能力。

Abstract: The classification of exoplanets has been a longstanding challenge in
astronomy, requiring significant computational and observational resources.
Traditional methods demand substantial effort, time, and cost, highlighting the
need for advanced machine learning techniques to enhance classification
efficiency. In this study, we propose a methodology that transforms raw light
curve data from NASA's Kepler mission into Gramian Angular Fields (GAFs) and
Recurrence Plots (RPs) using the Gramian Angular Difference Field and
recurrence plot techniques. These transformed images serve as inputs to the
Vision Transformer (ViT) model, leveraging its ability to capture intricate
temporal dependencies. We assess the performance of the model through recall,
precision, and F1 score metrics, using a 5-fold cross-validation approach to
obtain a robust estimate of the model's performance and reduce evaluation bias.
Our comparative analysis reveals that RPs outperform GAFs, with the ViT model
achieving an 89.46$\%$ recall and an 85.09$\%$ precision rate, demonstrating
its significant capability in accurately identifying exoplanetary transits.
Despite using under-sampling techniques to address class imbalance, dataset
size reduction remains a limitation. This study underscores the importance of
further research into optimizing model architectures to enhance automation,
performance, and generalization of the model.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [224] [PRISM-Loc: a Lightweight Long-range LiDAR Localization in Urban Environments with Topological Maps](https://arxiv.org/abs/2506.15849)
*Kirill Muravyev,Vasily Yuryev,Oleg Bulichev,Dmitry Yudin,Konstantin Yakovlev*

Main category: cs.RO

TL;DR: PRISM-Loc是一种基于拓扑地图的定位方法，适用于大范围环境中的实时定位，结合全局地点识别和局部位姿估计，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在长距离导航中，基于密集全局激光雷达地图的实时定位可能困难且内存消耗大，因此提出利用拓扑地图的解决方案。

Method: 采用双重定位流程，包括全局地点识别和局部位姿估计，后者基于2D特征和点优化的激光雷达扫描匹配算法。

Result: 在3公里路线的ITLP-Campus数据集上测试，PRISM-Loc在质量和计算效率上均优于现有方法。

Conclusion: PRISM-Loc是一种高效且性能优越的拓扑地图定位方法，适用于大规模环境中的实时导航。

Abstract: Localization in the environment is one of the crucial tasks of navigation of
a mobile robot or a self-driving vehicle. For long-range routes, performing
localization within a dense global lidar map in real time may be difficult, and
the creation of such a map may require much memory. To this end, leveraging
topological maps may be useful. In this work, we propose PRISM-Loc -- a
topological map-based approach for localization in large environments. The
proposed approach leverages a twofold localization pipeline, which consists of
global place recognition and estimation of the local pose inside the found
location. For local pose estimation, we introduce an original lidar scan
matching algorithm, which is based on 2D features and point-based optimization.
We evaluate the proposed method on the ITLP-Campus dataset on a 3 km route, and
compare it against the state-of-the-art metric map-based and place
recognition-based competitors. The results of the experiments show that the
proposed method outperforms its competitors both quality-wise and
computationally-wise.

</details>


### [225] [Semantic and Feature Guided Uncertainty Quantification of Visual Localization for Autonomous Vehicles](https://arxiv.org/abs/2506.15851)
*Qiyuan Wu,Mark Campbell*

Main category: cs.RO

TL;DR: 本文提出了一种用于自动驾驶视觉定位的轻量级传感器误差模型，通过学习图像特征和语义信息预测二维误差分布，实现上下文相关的测量不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 传感器测量与深度学习网络的不确定性量化对机器人系统（如自动驾驶汽车）至关重要，尤其是在安全关键应用中。

Method: 采用轻量级传感器误差模型，将图像特征和语义信息映射到二维误差分布，隐式捕获未标注的关键因素（如城市与高速公路、动态与静态场景、冬季与夏季）。

Result: 在Ithaca365数据集上验证了方法的准确性，结果显示在恶劣天气和光照条件下，测量误差不符合高斯分布，而高斯混合模型预测效果更佳。

Conclusion: 该方法能有效量化传感器和网络的不确定性，为自动驾驶视觉定位提供了更可靠的误差预测。

Abstract: The uncertainty quantification of sensor measurements coupled with deep
learning networks is crucial for many robotics systems, especially for
safety-critical applications such as self-driving cars. This paper develops an
uncertainty quantification approach in the context of visual localization for
autonomous driving, where locations are selected based on images. Key to our
approach is to learn the measurement uncertainty using light-weight sensor
error model, which maps both image feature and semantic information to
2-dimensional error distribution. Our approach enables uncertainty estimation
conditioned on the specific context of the matched image pair, implicitly
capturing other critical, unannotated factors (e.g., city vs highway, dynamic
vs static scenes, winter vs summer) in a latent manner. We demonstrate the
accuracy of our uncertainty prediction framework using the Ithaca365 dataset,
which includes variations in lighting and weather (sunny, night, snowy). Both
the uncertainty quantification of the sensor+network is evaluated, along with
Bayesian localization filters using unique sensor gating method. Results show
that the measurement error does not follow a Gaussian distribution with poor
weather and lighting conditions, and is better predicted by our Gaussian
Mixture model.

</details>


### [226] [Noise Fusion-based Distillation Learning for Anomaly Detection in Complex Industrial Environments](https://arxiv.org/abs/2506.16050)
*Jiawen Yu,Jieji Ren,Yang Chang,Qiaojun Yu,Xuan Tong,Boyang Wang,Yan Song,You Li,Xinji Mai,Wenqiang Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于异构教师网络（HetNet）的新方法，用于复杂工业环境中的异常检测与定位，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂、非结构化的工业环境中难以准确检测工件缺陷，因此需要一种更鲁棒的方法。

Method: 采用异构教师网络（HetNet）、自适应局部-全局特征融合模块和局部多元高斯噪声生成模块。

Result: HetNet在MSC-AD基准上性能提升约10%，并在其他数据集上达到最优结果，验证了其鲁棒性。

Conclusion: HetNet能有效集成到生产线中，实现实时、鲁棒的异常检测。

Abstract: Anomaly detection and localization in automated industrial manufacturing can
significantly enhance production efficiency and product quality. Existing
methods are capable of detecting surface defects in pre-defined or controlled
imaging environments. However, accurately detecting workpiece defects in
complex and unstructured industrial environments with varying views, poses and
illumination remains challenging. We propose a novel anomaly detection and
localization method specifically designed to handle inputs with perturbative
patterns. Our approach introduces a new framework based on a collaborative
distillation heterogeneous teacher network (HetNet), an adaptive local-global
feature fusion module, and a local multivariate Gaussian noise generation
module. HetNet can learn to model the complex feature distribution of normal
patterns using limited information about local disruptive changes. We conducted
extensive experiments on mainstream benchmarks. HetNet demonstrates superior
performance with approximately 10% improvement across all evaluation metrics on
MSC-AD under industrial conditions, while achieving state-of-the-art results on
other datasets, validating its resilience to environmental fluctuations and its
capability to enhance the reliability of industrial anomaly detection systems
across diverse scenarios. Tests in real-world environments further confirm that
HetNet can be effectively integrated into production lines to achieve robust
and real-time anomaly detection. Codes, images and videos are published on the
project website at: https://zihuatanejoyu.github.io/HetNet/

</details>


### [227] [FlowRAM: Grounding Flow Matching Policy with Region-Aware Mamba Framework for Robotic Manipulation](https://arxiv.org/abs/2506.16201)
*Sen Wang,Le Wang,Sanping Zhou,Jingyi Tian,Jiayi Li,Haowen Sun,Wei Tang*

Main category: cs.RO

TL;DR: FlowRAM提出了一种基于生成模型的高效机器人操作框架，通过动态半径调度和多模态信息整合，显著提升了高精度任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散的策略学习方法在推理时计算效率低，且未充分利用生成模型在3D环境中的信息探索潜力。

Method: FlowRAM结合动态半径调度、状态空间模型和条件流匹配，实现高效多模态信息处理和确定性动作学习。

Result: 在RLBench基准测试中，FlowRAM平均成功率提升12.0%，推理速度显著加快（少于4步）。

Conclusion: FlowRAM在高精度机器人操作任务中表现出色，为实际应用提供了高效解决方案。

Abstract: Robotic manipulation in high-precision tasks is essential for numerous
industrial and real-world applications where accuracy and speed are required.
Yet current diffusion-based policy learning methods generally suffer from low
computational efficiency due to the iterative denoising process during
inference. Moreover, these methods do not fully explore the potential of
generative models for enhancing information exploration in 3D environments. In
response, we propose FlowRAM, a novel framework that leverages generative
models to achieve region-aware perception, enabling efficient multimodal
information processing. Specifically, we devise a Dynamic Radius Schedule,
which allows adaptive perception, facilitating transitions from global scene
comprehension to fine-grained geometric details. Furthermore, we integrate
state space models to integrate multimodal information, while preserving linear
computational complexity. In addition, we employ conditional flow matching to
learn action poses by regressing deterministic vector fields, simplifying the
learning process while maintaining performance. We verify the effectiveness of
the FlowRAM in the RLBench, an established manipulation benchmark, and achieve
state-of-the-art performance. The results demonstrate that FlowRAM achieves a
remarkable improvement, particularly in high-precision tasks, where it
outperforms previous methods by 12.0% in average success rate. Additionally,
FlowRAM is able to generate physically plausible actions for a variety of
real-world tasks in less than 4 time steps, significantly increasing inference
speed.

</details>


### [228] [Reimagination with Test-time Observation Interventions: Distractor-Robust World Model Predictions for Visual Model Predictive Control](https://arxiv.org/abs/2506.16565)
*Yuxin Chen,Jianglan Wei,Chenfeng Xu,Boyi Li,Masayoshi Tomizuka,Andrea Bajcsy,Ran Tian*

Main category: cs.RO

TL;DR: 论文提出ReOI方法，通过检测并移除视觉干扰物，提升世界模型在开放环境中的预测可靠性。


<details>
  <summary>Details</summary>
Motivation: 世界模型在遇到训练中未见的视觉干扰物时表现脆弱，影响动作预测和规划。

Method: 提出ReOI方法，检测并修改观测以移除干扰物，重新预测未来状态并恢复干扰物。

Result: ReOI显著提升任务成功率，在新型干扰物下表现优于未干预方法。

Conclusion: ReOI是一种简单有效的测试时策略，增强世界模型在开放环境中的鲁棒性。

Abstract: World models enable robots to "imagine" future observations given current
observations and planned actions, and have been increasingly adopted as
generalized dynamics models to facilitate robot learning. Despite their
promise, these models remain brittle when encountering novel visual distractors
such as objects and background elements rarely seen during training.
Specifically, novel distractors can corrupt action outcome predictions, causing
downstream failures when robots rely on the world model imaginations for
planning or action verification. In this work, we propose Reimagination with
Observation Intervention (ReOI), a simple yet effective test-time strategy that
enables world models to predict more reliable action outcomes in open-world
scenarios where novel and unanticipated visual distractors are inevitable.
Given the current robot observation, ReOI first detects visual distractors by
identifying which elements of the scene degrade in physically implausible ways
during world model prediction. Then, it modifies the current observation to
remove these distractors and bring the observation closer to the training
distribution. Finally, ReOI "reimagines" future outcomes with the modified
observation and reintroduces the distractors post-hoc to preserve visual
consistency for downstream planning and verification. We validate our approach
on a suite of robotic manipulation tasks in the context of action verification,
where the verifier needs to select desired action plans based on predictions
from a world model. Our results show that ReOI is robust to both
in-distribution and out-of-distribution visual distractors. Notably, it
improves task success rates by up to 3x in the presence of novel distractors,
significantly outperforming action verification that relies on world model
predictions without imagination interventions.

</details>


### [229] [CodeDiffuser: Attention-Enhanced Diffusion Policy via VLM-Generated Code for Instruction Ambiguity](https://arxiv.org/abs/2506.16652)
*Guang Yin,Yitong Li,Yixuan Wang,Dale McConachie,Paarth Shah,Kunimatsu Hashimoto,Huan Zhang,Katherine Liu,Yunzhu Li*

Main category: cs.RO

TL;DR: 论文提出了一种新型机器人操作框架，通过结合视觉语言模型和任务特定代码生成，解决自然语言指令的模糊性问题。


<details>
  <summary>Details</summary>
Motivation: 自然语言指令在机器人操作任务中常存在模糊性，现有端到端模型因缺乏模块化和可解释性导致性能不佳。

Method: 采用视觉语言模型（VLM）解析指令并生成可执行的任务特定代码，结合感知模块生成3D注意力图以消除指令模糊性。

Result: 实验表明，该方法在语言模糊性、接触丰富操作和多对象交互任务中表现优异。

Conclusion: 该框架通过模块化和可解释性设计，显著提升了机器人操作任务的适应性和性能。

Abstract: Natural language instructions for robotic manipulation tasks often exhibit
ambiguity and vagueness. For instance, the instruction "Hang a mug on the mug
tree" may involve multiple valid actions if there are several mugs and branches
to choose from. Existing language-conditioned policies typically rely on
end-to-end models that jointly handle high-level semantic understanding and
low-level action generation, which can result in suboptimal performance due to
their lack of modularity and interpretability. To address these challenges, we
introduce a novel robotic manipulation framework that can accomplish tasks
specified by potentially ambiguous natural language. This framework employs a
Vision-Language Model (VLM) to interpret abstract concepts in natural language
instructions and generates task-specific code - an interpretable and executable
intermediate representation. The generated code interfaces with the perception
module to produce 3D attention maps that highlight task-relevant regions by
integrating spatial and semantic information, effectively resolving ambiguities
in instructions. Through extensive experiments, we identify key limitations of
current imitation learning methods, such as poor adaptation to language and
environmental variations. We show that our approach excels across challenging
manipulation tasks involving language ambiguity, contact-rich manipulation, and
multi-object interactions.

</details>


### [230] [Monocular One-Shot Metric-Depth Alignment for RGB-Based Robot Grasping](https://arxiv.org/abs/2506.17110)
*Teng Guo,Baichuan Huang,Jingjin Yu*

Main category: cs.RO

TL;DR: MOMA提出了一种单目RGB图像度量深度恢复框架，通过一次适应实现准确深度估计，适用于透明物体，并在实际机器人任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有6D姿态估计方法依赖昂贵深度传感器且无法处理透明物体的问题，同时改进单目深度估计模型的度量深度恢复能力。

Method: 提出MOMA框架，通过相机校准中的尺度-旋转-平移对齐，结合稀疏真实深度点，实现单次适应下的度量深度恢复。

Result: MOMA在透明物体上表现优异，并在实际机器人抓取和分拣任务中取得高成功率。

Conclusion: MOMA通过单次适应实现高效度量深度恢复，具有强泛化能力，适用于多种机器人任务。

Abstract: Accurate 6D object pose estimation is a prerequisite for successfully
completing robotic prehensile and non-prehensile manipulation tasks. At
present, 6D pose estimation for robotic manipulation generally relies on depth
sensors based on, e.g., structured light, time-of-flight, and stereo-vision,
which can be expensive, produce noisy output (as compared with RGB cameras),
and fail to handle transparent objects. On the other hand, state-of-the-art
monocular depth estimation models (MDEMs) provide only affine-invariant depths
up to an unknown scale and shift. Metric MDEMs achieve some successful
zero-shot results on public datasets, but fail to generalize. We propose a
novel framework, Monocular One-shot Metric-depth Alignment (MOMA), to recover
metric depth from a single RGB image, through a one-shot adaptation building on
MDEM techniques. MOMA performs scale-rotation-shift alignments during camera
calibration, guided by sparse ground-truth depth points, enabling accurate
depth estimation without additional data collection or model retraining on the
testing setup. MOMA supports fine-tuning the MDEM on transparent objects,
demonstrating strong generalization capabilities. Real-world experiments on
tabletop 2-finger grasping and suction-based bin-picking applications show MOMA
achieves high success rates in diverse tasks, confirming its effectiveness.

</details>


### [231] [Dex1B: Learning with 1B Demonstrations for Dexterous Manipulation](https://arxiv.org/abs/2506.17198)
*Jianglong Ye,Keyi Wang,Chengjing Yuan,Ruihan Yang,Yiquan Li,Jiyue Zhu,Yuzhe Qin,Xueyan Zou,Xiaolong Wang*

Main category: cs.RO

TL;DR: 论文介绍了Dex1B，一个通过生成模型创建的大规模、多样化和高质量的手部操作演示数据集，包含10亿个演示，用于抓取和关节任务。


<details>
  <summary>Details</summary>
Motivation: 解决大规模手部操作演示生成的挑战，提出生成模型作为高效创建多样且物理可行演示的方法。

Method: 提出一种结合几何约束以提升可行性和附加条件以增强多样性的生成模型，用于构建Dex1B数据集。

Result: 在仿真基准测试中显著优于现有方法，并通过真实机器人实验验证了其有效性和鲁棒性。

Conclusion: Dex1B数据集及其生成模型为手部操作任务提供了高效、多样且高质量的演示资源。

Abstract: Generating large-scale demonstrations for dexterous hand manipulation remains
challenging, and several approaches have been proposed in recent years to
address this. Among them, generative models have emerged as a promising
paradigm, enabling the efficient creation of diverse and physically plausible
demonstrations. In this paper, we introduce Dex1B, a large-scale, diverse, and
high-quality demonstration dataset produced with generative models. The dataset
contains one billion demonstrations for two fundamental tasks: grasping and
articulation. To construct it, we propose a generative model that integrates
geometric constraints to improve feasibility and applies additional conditions
to enhance diversity. We validate the model on both established and newly
introduced simulation benchmarks, where it significantly outperforms prior
state-of-the-art methods. Furthermore, we demonstrate its effectiveness and
robustness through real-world robot experiments. Our project page is at
https://jianglongye.com/dex1b

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [232] [cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree](https://arxiv.org/abs/2506.15655)
*Yilin Zhang,Xinran Zhao,Zora Zhiruo Wang,Chenyang Yang,Jiayi Wei,Tongshuang Wu*

Main category: cs.SE

TL;DR: 论文提出了一种基于抽象语法树（AST）的代码分块方法（\ourwork），以解决现有基于行的分块方法破坏语义结构的问题，显著提升了代码生成任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于行的分块方法在代码检索增强生成（RAG）中常破坏语义结构（如拆分函数或合并无关代码），影响生成质量。

Method: 通过递归分解大型AST节点并合并兄弟节点，生成语义连贯且自包含的代码块。

Result: 在多种代码生成任务中表现优异，如RepoEval检索的Recall@5提升4.3点，SWE-bench生成的Pass@1提升2.67点。

Conclusion: 结构感知的分块方法对提升检索增强的代码智能至关重要。

Abstract: Retrieval-Augmented Generation (RAG) has become essential for large-scale
code generation, grounding predictions in external code corpora to improve
actuality. However, a critical yet underexplored aspect of RAG pipelines is
chunking -- the process of dividing documents into retrievable units. Existing
line-based chunking heuristics often break semantic structures, splitting
functions or merging unrelated code, which can degrade generation quality. We
propose chunking via Abstract Syntax Trees (\ourwork), a structure-aware method
that recursively breaks large AST nodes into smaller chunks and merges sibling
nodes while respecting size limits. This approach generates self-contained,
semantically coherent units across programming languages and tasks, improving
performance on diverse code generation tasks, e.g., boosting Recall@5 by 4.3
points on RepoEval retrieval and Pass@1 by 2.67 points on SWE-bench generation.
Our work highlights the importance of structure-aware chunking for scaling
retrieval-enhanced code intelligence.

</details>


### [233] [Dissecting the SWE-Bench Leaderboards: Profiling Submitters and Architectures of LLM- and Agent-Based Repair Systems](https://arxiv.org/abs/2506.17208)
*Matias Martinez,Xavier Franch*

Main category: cs.SE

TL;DR: 本文对SWE-Bench Lite和Verified排行榜上的提交进行了首次全面研究，分析了67种独特方法，揭示了专有LLM（如Claude 3.5/3.7）的主导地位、代理与非代理设计的共存以及贡献者多样性。


<details>
  <summary>Details</summary>
Motivation: 由于SWE-Bench提交过程缺乏详细文档，许多解决方案的设计和来源不明确，因此需要系统研究以揭示当前APR领域的趋势和技术特点。

Method: 研究分析了SWE-Bench Lite（68项）和Verified（79项）排行榜的所有提交，从提交者类型、产品可用性、LLM使用和系统架构等维度进行考察。

Result: 研究发现专有LLM（如Claude 3.5/3.7）占主导地位，代理与非代理设计并存，贡献者包括个人开发者到大型科技公司。

Conclusion: 该研究为APR领域提供了重要洞见，揭示了技术趋势和多样化设计，强调了透明文档的必要性。

Abstract: The rapid progress in Automated Program Repair (APR) has been driven by
advances in AI, particularly large language models (LLMs) and agent-based
systems. SWE-Bench is a recent benchmark designed to evaluate LLM-based repair
systems using real issues and pull requests mined from 12 popular open-source
Python repositories. Its public leaderboards, SWE-Bench Lite and SWE-Bench
Verified, have become central platforms for tracking progress and comparing
solutions. However, because the submission process does not require detailed
documentation, the architectural design and origin of many solutions remain
unclear. In this paper, we present the first comprehensive study of all
submissions to the SWE-Bench Lite (68 entries) and Verified (79 entries)
leaderboards, analyzing 67 unique approaches across dimensions such as
submitter type, product availability, LLM usage, and system architecture. Our
findings reveal the dominance of proprietary LLMs (especially Claude 3.5/3.7),
the presence of both agentic and non-agentic designs, and a contributor base
spanning from individual developers to large tech companies.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [234] [Autonomous Trajectory Optimization for UAVs in Disaster Zone Using Henry Gas Optimization Scheme](https://arxiv.org/abs/2506.15910)
*Zakria Qadir,Muhammad Bilal,Guoqiang Liu,Xiaolong Xu*

Main category: eess.SY

TL;DR: 论文提出了一种基于亨利气体优化（HGO）算法的集群优化方案（COS），用于无人机（UAV）在复杂环境中的最优轨迹规划，显著降低了运输成本和计算时间。


<details>
  <summary>Details</summary>
Motivation: 在灾害多发环境中，无人机在救援服务和互联网连接中扮演重要角色，但复杂环境下的最优轨迹选择是关键挑战。

Method: 采用HGO算法设计COS数学模型，并与PSO、GWO、CSA和BMO等现有算法进行比较。

Result: HGO算法在四种不同场景中均优于现有算法，尤其在开放环境中，运输成本降低39.3%，计算时间减少16.8%。

Conclusion: HGO算法适用于智能城市中无人机的自主轨迹优化。

Abstract: The unmanned aerial vehicles (UAVs) in a disaster-prone environment plays
important role in assisting the rescue services and providing the internet
connectivity with the outside world. However, in such a complex environment the
selection of optimum trajectory of UAVs is of utmost importance. UAV trajectory
optimization deals with finding the shortest path in the minimal possible time.
In this paper, a cluster optimization scheme (COS) is proposed using the Henry
gas optimization (HGO) metaheuristic algorithm to identify the shortest path
having minimal transportation cost and algorithm complexity. The mathematical
model is designed for COS using the HGO algorithm and compared with the
state-of-the-art metaheuristic algorithms such as particle swarm optimization
(PSO), grey wolf optimization (GWO), cuckoo search algorithm (CSA) and
barnacles mating optimizer (BMO). In order to prove the robustness of the
proposed model, four different scenarios are evaluated that includes ambient
environment, constrict environment, tangled environment, and complex
environment. In all the aforementioned scenarios, the HGO algorithm outperforms
the existing algorithms. Particularly, in the ambient environment, the HGO
algorithm achieves a 39.3% reduction in transportation cost and a 16.8%
reduction in computational time as compared to the PSO algorithm. Hence, the
HGO algorithm can be used for autonomous trajectory optimization of UAVs in
smart cities.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [235] [MoR: Better Handling Diverse Queries with a Mixture of Sparse, Dense, and Human Retrievers](https://arxiv.org/abs/2506.15862)
*Jushaan Singh Kalra,Xinran Zhao,To Eun Kim,Fengyu Cai,Fernando Diaz,Tongshuang Wu*

Main category: cs.IR

TL;DR: 论文提出了一种动态选择和集成多种检索器的方法（mixture of retrievers），通过零样本加权组合，显著提升了检索增强生成（RAG）的效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常固定使用单一检索器，无法适应多样化的信息需求，因此需要一种动态选择和集成多种检索器的方案。

Method: 提出了一种零样本加权组合的混合检索器框架，结合了BM25和密集检索器的优势。

Result: 实验表明，该方法在仅0.8B参数下，平均性能优于单一检索器和更大的7B模型，分别提升10.8%和3.9%。

Conclusion: 混合检索器框架不仅高效，还能整合非专家人类信息源，实现协作性能提升58.9%。

Abstract: Retrieval-augmented Generation (RAG) is powerful, but its effectiveness
hinges on which retrievers we use and how. Different retrievers offer distinct,
often complementary signals: BM25 captures lexical matches; dense retrievers,
semantic similarity. Yet in practice, we typically fix a single retriever based
on heuristics, which fails to generalize across diverse information needs. Can
we dynamically select and integrate multiple retrievers for each individual
query, without the need for manual selection? In our work, we validate this
intuition with quantitative analysis and introduce mixture of retrievers: a
zero-shot, weighted combination of heterogeneous retrievers. Extensive
experiments show that such mixtures are effective and efficient: Despite
totaling just 0.8B parameters, this mixture outperforms every individual
retriever and even larger 7B models by +10.8% and +3.9% on average,
respectively. Further analysis also shows that this mixture framework can help
incorporate specialized non-oracle human information sources as retrievers to
achieve good collaboration, with a 58.9% relative performance improvement over
simulated humans alone.

</details>


### [236] [Revela: Dense Retriever Learning via Language Modeling](https://arxiv.org/abs/2506.16552)
*Fengyu Cai,Tong Chen,Xinran Zhao,Sihao Chen,Hongming Zhang,Sherry Tongshuang Wu,Iryna Gurevych,Heinz Koeppl*

Main category: cs.IR

TL;DR: Revela是一个通过语言建模实现自监督检索器学习的统一框架，利用局部和跨文档上下文优化检索器，显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 在专业领域中，标注查询-文档对的成本高昂，因此需要自监督学习方法来训练密集检索器。

Method: Revela通过语言建模目标建模文档间的语义依赖，利用批内注意力机制和检索器计算的相似性分数优化检索器。

Result: 在BEIR和CoIR基准测试中，Revela在NDCG@10上分别提升了5.2%和5.6%，且性能随模型规模增加而提升。

Conclusion: Revela展示了自监督检索器学习的有效性和可扩展性，为专业领域检索提供了新思路。

Abstract: Dense retrievers play a vital role in accessing external and specialized
knowledge to augment language models (LMs). Training dense retrievers typically
requires annotated query-document pairs, which are costly and hard to obtain in
specialized domains such as code-motivating growing interest in self-supervised
retriever learning. Since LMs are trained to capture token-level dependencies
through a self-supervised learning objective (i.e., next-token prediction), we
can analogously cast retrieval as learning dependencies among chunks of tokens.
This analogy naturally leads to the question: How can we adapt self-supervised
learning objectives in the spirit of language modeling to train retrievers?
  To answer this question, we introduce Revela, a unified and scalable training
framework for self-supervised retriever learning via language modeling. Revela
models semantic dependencies among documents by conditioning next-token
prediction on both local and cross-document context through an in-batch
attention mechanism. This attention is weighted by retriever-computed
similarity scores, enabling the retriever to be optimized as part of language
modeling. We evaluate Revela on both general-domain (BEIR) and domain-specific
(CoIR) benchmarks across various retriever backbones. At a comparable parameter
scale, Revela outperforms the previous best method with absolute improvements
of 5.2 % (18.3 % relative) and 5.6 % (14.4 % relative) on NDCG@10,
respectively, underscoring its effectiveness. Performance increases with model
size, highlighting both the scalability of our approach and its promise for
self-supervised retriever learning.

</details>


<div id='cs.PF'></div>

# cs.PF [[Back]](#toc)

### [237] [How to Increase Energy Efficiency with a Single Linux Command](https://arxiv.org/abs/2506.16046)
*Alborz Jelvani,Richard P Martin,Santosh Nagarakatte*

Main category: cs.PF

TL;DR: 通过简单的功率限制（power capping）可以显著提升能效，比传统节能配置提高25%，且性能损失小。


<details>
  <summary>Details</summary>
Motivation: 现有动态电源管理设置无法实现最佳能效，需探索更简单有效的方法。

Method: 利用现有功率限制机制，通过单条Linux命令实现，无需修改现有电源管理策略。

Result: 功率限制能效提升25%，性能损失小，且易于实施。

Conclusion: 建议程序员和管理员优先使用功率限制而非复杂算法，以平衡能效与性能。

Abstract: Processors with dynamic power management provide a variety of settings to
control energy efficiency. However, tuning these settings does not achieve
optimal energy savings. We highlight how existing power capping mechanisms can
address these limitations without requiring any changes to current power
governors. We validate this approach using system measurements across a
month-long data acquisition campaign from SPEC CPU 2017 benchmarks on a
server-class system equipped with dual Intel Xeon Scalable processors. Our
results indicate that setting a simple power cap can improve energy efficiency
by up to 25% over traditional energy-saving system configurations with little
performance loss, as most default settings focus on thermal regulation and
performance rather than compute efficiency. Power capping is very accessible
compared to other approaches, as it can be implemented with a single Linux
command. Our results point to programmers and administrators using power caps
as a primary mechanism to maintain significant energy efficiency while
retaining acceptable performance, as opposed to deploying complex DVFS
algorithms.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [238] [PNCS:Power-Norm Cosine Similarity for Diverse Client Selection in Federated Learning](https://arxiv.org/abs/2506.15923)
*Liangyan Li,Yangyi Liu,Yimo Ning,Stefano Rini,Jun Chen*

Main category: cs.LG

TL;DR: 本文提出了一种基于Power-Norm Cosine Similarity（PNCS）的联邦学习框架，通过捕捉高阶梯度矩解决非独立同分布数据问题，提升收敛速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习方法未充分考虑客户端间的梯度相关性，尤其在数据异构场景下表现不佳。

Method: 提出PNCS框架，结合选择历史队列算法，优化客户端选择以提升模型聚合效果。

Result: 在VGG16模型上的实验表明，该方法在多种数据分区下均优于现有技术。

Conclusion: PNCS框架有效解决了数据异构问题，提升了联邦学习的性能。

Abstract: Federated Learning (FL) has emerged as a powerful paradigm for leveraging
diverse datasets from multiple sources while preserving data privacy by
avoiding centralized storage. However, many existing approaches fail to account
for the intricate gradient correlations between remote clients, a limitation
that becomes especially problematic in data heterogeneity scenarios. In this
work, we propose a novel FL framework utilizing Power-Norm Cosine Similarity
(PNCS) to improve client selection for model aggregation. By capturing
higher-order gradient moments, PNCS addresses non-IID data challenges,
enhancing convergence speed and accuracy. Additionally, we introduce a simple
algorithm ensuring diverse client selection through a selection history queue.
Experiments with a VGG16 model across varied data partitions demonstrate
consistent improvements over state-of-the-art methods.

</details>


### [239] [BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models](https://arxiv.org/abs/2506.15689)
*Liulu He,Shenli Zhen,Karwei Sun,Yijiang Liu,Yufei Zhao,Chongkang Tan,Huanrui Yang,Yuan Du,Li Du*

Main category: cs.LG

TL;DR: 论文提出了一种名为BASE-Q的新方法，通过结合偏置校正和非对称缩放，有效减少旋转量化中的舍入和裁剪误差，同时支持分块优化，降低内存消耗。


<details>
  <summary>Details</summary>
Motivation: 当前旋转量化方法存在两个问题：一是旋转未能对齐通道均值，导致量化边界变宽和舍入误差增加；二是旋转使激活分布更接近高斯分布，增加了裁剪误差的能量损失。

Method: 引入BASE-Q方法，结合偏置校正和非对称缩放，并支持分块优化，避免全模型反向传播的高内存需求。

Result: 实验表明，BASE-Q在多种大语言模型和基准测试中表现优异，将精度差距缩小了50.5%、42.9%和29.2%（相比QuaRot、SpinQuant和OSTQuant）。

Conclusion: BASE-Q是一种简单而有效的方法，显著提升了旋转量化的性能，同时降低了内存开销。

Abstract: Rotations have become essential to state-of-the-art quantization pipelines
for large language models (LLMs) by effectively smoothing outliers in weights
and activations. However, further optimizing the rotation parameters offers
only limited performance gains and introduces significant training overhead:
due to rotation parameter sharing, full-model must be loaded simultaneously to
enable backpropagation, resulting in substantial memory consumption and limited
practical utility. In this work, we identify two fundamental limitations of
current rotational quantization methods: (i) rotation fails to align channel
means, resulting in wider quantization bounds and increased rounding errors;
and (ii) rotation makes the activation distribution more Gaussian-like,
increasing energy loss caused by clipping errors. To address these issues, we
introduce \textbf{BASE-Q}, a simple yet powerful approach that combines bias
correction and asymmetric scaling to effectively reduce rounding and clipping
errors. Furthermore, BASE-Q enables blockwise optimization, eliminating the
need for memory-intensive full-model backpropagation. Extensive experiments on
various LLMs and benchmarks demonstrate the effectiveness of BASE-Q, narrowing
the accuracy gap to full-precision models by 50.5\%, 42.9\%, and 29.2\%
compared to QuaRot, SpinQuant, and OSTQuant, respectively. The code will be
released soon.

</details>


### [240] [Learn from the Past: Fast Sparse Indexing for Large Language Model Decoding](https://arxiv.org/abs/2506.15704)
*Feiyu Yao,Qian Wang*

Main category: cs.LG

TL;DR: LFPS是一种通过利用历史注意力模式动态构建稀疏索引候选的加速方法，显著减少了长上下文LLM推理中的解码开销。


<details>
  <summary>Details</summary>
Motivation: 随着LLM支持更长的上下文，KV缓存的存储需求急剧增加，成为GPU内存和PCIe带宽的瓶颈。稀疏注意力机制虽能缓解此问题，但其索引检索成本高。

Method: LFPS通过捕捉解码器注意力的垂直和斜线模式，动态构建稀疏索引候选，并结合位置扩展策略预测Top-k索引。

Result: 在LongBench-RULER基准测试中，LFPS比全注意力快22.8倍，比精确Top-k检索快9.6倍，同时保持生成准确性。

Conclusion: LFPS为长上下文LLM推理提供了一种高效且实用的解码优化方案。

Abstract: As large language models (LLMs) continue to support increasingly longer
contexts, the memory demand for key-value (KV) caches during decoding grows
rapidly, becoming a critical bottleneck in both GPU memory capacity and PCIe
bandwidth. Sparse attention mechanisms alleviate this issue by computing
attention weights only for selected key-value pairs. However, their indexing
computation typically requires traversing all key vectors, resulting in
significant computational and data transfer overhead. To reduce the cost of
index retrieval, existing methods often treat each decoding step as an
independent process, failing to exploit the temporal correlations embedded in
historical decoding information. To this end, we propose LFPS(Learn From the
Past for Sparse Indexing), an acceleration method that dynamically constructs
sparse indexing candidates based on historical attention patterns. LFPS
captures two prevalent trends in decoder attention -vertical patterns
(attending to fixed positions) and slash patterns (attending to relative
positions) -and incorporates a positional expansion strategy to effectively
predict the Top-k indices for the current step. We validate LFPS on challenging
long-context benchmarks such as LongBench-RULER, using Llama-3.1-8B-Instruct as
the base model. Experimental results show that LFPS achieves up to 22.8$\times$
speedup over full attention and 9.6$\times$ speedup over exact Top-k retrieval
on an RTX 4090 GPU and a single CPU core of a Xeon Gold 6430, respectively,
while preserving generation accuracy. These results demonstrate that LFPS
offers a practical and efficient solution for decoding optimization in
long-context LLM inference.

</details>


### [241] [Adaptive Two Sided Laplace Transforms: A Learnable, Interpretable, and Scalable Replacement for Self-Attention](https://arxiv.org/abs/2506.15714)
*Andrew Kiruluta*

Main category: cs.LG

TL;DR: 提出了一种可学习的双短时拉普拉斯变换（STLT）机制，替代传统自注意力机制，实现动态调整令牌相关性和频率响应，适用于超长序列建模。


<details>
  <summary>Details</summary>
Motivation: 传统自注意力机制在长序列建模中存在计算瓶颈，需要一种更高效且可扩展的替代方案。

Method: 引入可训练参数的STLT机制，支持动态调整衰减率、振荡频率和窗口带宽，结合快速递归卷积和FFT计算，实现高效复杂度。

Result: 在语言建模、机器翻译和长文档问答任务中表现优异，支持超过100k令牌的上下文长度。

Conclusion: STLT机制兼具可解释性、可扩展性和鲁棒性，为超长序列建模提供了新途径。

Abstract: We propose an innovative, learnable two-sided short-time Laplace transform
(STLT) mechanism to supplant the traditional self attention in
transformer-based LLMs. Our STLT introduces trainable parameters for each
Laplace node, enabling end-to-end learning of decay rates , oscillatory
frequencies, and window bandwidth T. This flexibility allows the model to
dynamically adapt token relevance half lives and frequency responses during
training. By selecting S learnable nodes and leveraging fast recursive
convolution, we achieve an effective complexity of in time and memory. We
further incorporate an efficient FFT-based computation of the relevance matrix
and an adaptive node allocation mechanism to dynamically adjust the number of
active Laplace nodes. Empirical results on language modeling (WikiText\-103,
Project Gutenberg), machine translation (WMT'14 En\-De), and long document
question answering (NarrativeQA) demonstrate that our learnable STLT achieves
perplexities and scores on par with or better than existing efficient
transformers while naturally extending to context lengths exceeding 100k tokens
or more limited only by available hardware. Ablation studies confirm the
importance of learnable parameters and adaptive node allocation. The proposed
approach combines interpretability, through explicit decay and frequency
parameters, with scalability and robustness, offering a pathway towards
ultra-long-sequence language modeling without the computational bottleneck of
self-attention.

</details>


### [242] [daDPO: Distribution-Aware DPO for Distilling Conversational Abilities](https://arxiv.org/abs/2506.15717)
*Zhengze Zhang,Shiqi Wang,Yiqun Shen,Simin Guo,Dahua Lin,Xiaoliang Wang,Nguyen Cam-Tu,Fei Tan*

Main category: cs.LG

TL;DR: 论文提出了一种名为daDPO（Distribution-Aware DPO）的方法，通过结合偏好优化和基于分布的蒸馏，提升小规模语言模型的对话能力。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在资源受限环境中因模型规模减小而对话能力下降，现有方法仅关注教师模型的响应而忽略其输出分布。

Method: 提出daDPO方法，统一偏好优化和基于分布的蒸馏，通过理论分析和实证验证其有效性。

Result: daDPO在修剪模型和小规模LLM上表现优于现有方法，例如修剪后的Vicuna1.5-7B性能接近教师模型，Qwen2.5-1.5B甚至偶尔超越其7B教师模型。

Conclusion: daDPO是一种有效的方法，能够显著提升小规模语言模型的对话能力，填补了现有方法的不足。

Abstract: Large language models (LLMs) have demonstrated exceptional performance across
various applications, but their conversational abilities decline sharply as
model size decreases, presenting a barrier to their deployment in
resource-constrained environments. Knowledge distillation with Direct
Preference Optimization (dDPO) has emerged as a promising approach to enhancing
the conversational abilities of smaller models using a larger teacher model.
However, current methods primarily focus on 'black-box' KD, which only uses the
teacher's responses, overlooking the output distribution offered by the
teacher. This paper addresses this gap by introducing daDPO (Distribution-Aware
DPO), a unified method for preference optimization and distribution-based
distillation. We provide rigorous theoretical analysis and empirical
validation, showing that daDPO outperforms existing methods in restoring
performance for pruned models and enhancing smaller LLM models. Notably, in
in-domain evaluation, our method enables a 20% pruned Vicuna1.5-7B to achieve
near-teacher performance (-7.3% preference rate compared to that of dDPO's
-31%), and allows Qwen2.5-1.5B to occasionally outperform its 7B teacher model
(14.0% win rate).

</details>


### [243] [MadaKV: Adaptive Modality-Perception KV Cache Eviction for Efficient Multimodal Long-Context Inference](https://arxiv.org/abs/2506.15724)
*Kunxi Li,Zhonghua Jiang,Zhouzhou Shen,Zhaode Wang,Chengfei Lv,Shengyu Zhang,Fan Wu,Fei Wu*

Main category: cs.LG

TL;DR: MadaKV是一种模态自适应的KV缓存淘汰策略，旨在提升多模态大语言模型在长上下文推理中的效率。


<details>
  <summary>Details</summary>
Motivation: 多模态场景中，注意力头对不同模态的偏好差异显著，传统单模态KV缓存淘汰方法无法捕捉模态特定信息，导致性能不佳。

Method: MadaKV通过模态偏好适应和分层压缩补偿，动态感知注意力头中的模态信息并自适应保留关键令牌。

Result: 实验表明，MadaKV显著减少了KV缓存内存占用和解码延迟（提升1.3至1.5倍），同时在多模态长上下文任务中保持高准确率。

Conclusion: MadaKV在多模态场景中优于现有KV缓存淘汰方法，验证了其有效性。

Abstract: This paper introduces MadaKV, a modality-adaptive key-value (KV) cache
eviction strategy designed to enhance the efficiency of multimodal large
language models (MLLMs) in long-context inference. In multimodal scenarios,
attention heads exhibit varying preferences for different modalities, resulting
in significant disparities in modality importance across attention heads.
Traditional KV cache eviction methods, which are tailored for unimodal
settings, fail to capture modality-specific information, thereby yielding
suboptimal performance. MadaKV addresses these challenges through two key
components: modality preference adaptation and hierarchical compression
compensation. By dynamically sensing modality information within attention
heads and adaptively retaining critical tokens, MadaKV achieves substantial
reductions in KV cache memory footprint and model inference decoding latency
(1.3 to 1.5 times improvement) while maintaining high accuracy across various
multimodal long-context tasks. Extensive experiments on representative MLLMs
and the MileBench benchmark demonstrate the effectiveness of MadaKV compared to
existing KV cache eviction methods.

</details>


### [244] [Fractional Reasoning via Latent Steering Vectors Improves Inference Time Compute](https://arxiv.org/abs/2506.15882)
*Sheng Liu,Tianlang Chen,Pan Lu,Haotian Ye,Yizheng Chen,Lei Xing,James Zou*

Main category: cs.LG

TL;DR: Fractional Reasoning是一种无需训练、模型无关的框架，通过动态调整推理强度提升LLM性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如Best-of-N、多数投票等）对不同问题采用统一推理深度，忽略了问题复杂性差异。

Method: 提取潜在推理向量并通过可调缩放因子动态控制推理强度，支持广度（如Best-of-N）和深度（如自反思）策略。

Result: 在GSM8K、MATH500和GPQA等任务中，Fractional Reasoning显著提升了性能。

Conclusion: Fractional Reasoning为LLM提供了更灵活的推理控制，适用于多样化任务。

Abstract: Test-time compute has emerged as a powerful paradigm for improving the
performance of large language models (LLMs), where generating multiple outputs
or refining individual chains can significantly boost answer accuracy. However,
existing methods like Best-of-N, majority voting, and self-reflection typically
apply reasoning in a uniform way across inputs, overlooking the fact that
different problems may require different levels of reasoning depth. In this
work, we propose Fractional Reasoning, a training-free and model-agnostic
framework that enables continuous control over reasoning intensity at inference
time, going beyond the limitations of fixed instructional prompts. Our method
operates by extracting the latent steering vector associated with deeper
reasoning and reapplying it with a tunable scaling factor, allowing the model
to tailor its reasoning process to the complexity of each input. This supports
two key modes of test-time scaling: (1) improving output quality in
breadth-based strategies (e.g., Best-of-N, majority voting), and (2) enhancing
the correctness of individual reasoning chains in depth-based strategies (e.g.,
self-reflection). Experiments on GSM8K, MATH500, and GPQA demonstrate that
Fractional Reasoning consistently improves performance across diverse reasoning
tasks and models.

</details>


### [245] [Early Attentive Sparsification Accelerates Neural Speech Transcription](https://arxiv.org/abs/2506.15912)
*Zifei Xu,Sayeh Sharify,Hesham Mostafa,Tristan Webb,Wanzin Yazar,Xin Wang*

Main category: cs.LG

TL;DR: 通过时间域信号稀疏化加速神经语音转录，利用Transformer音频编码器的自注意力机制可解释性，在Whisper模型上进行架构搜索，最佳方案在早期编码阶段稀疏化隐藏状态至40-60%，实现1.6倍运行时加速且准确率下降小于1%。


<details>
  <summary>Details</summary>
Motivation: 语音音频信号高度可压缩，利用Transformer的自注意力机制可解释性，加速神经语音转录。

Method: 在Whisper模型上进行架构搜索，探索稀疏化阶段（特定编码层）和压缩比（稀疏度）的联合空间。

Result: 最佳方案在早期编码阶段稀疏化隐藏状态至40-60%，实现1.6倍运行时加速，准确率下降小于1%。

Conclusion: 时间域信号稀疏化在早期编码阶段可显著加速神经语音转录，且对准确率影响较小。

Abstract: Transformer-based neural speech processing has achieved state-of-the-art
performance. Since speech audio signals are known to be highly compressible,
here we seek to accelerate neural speech transcription by time-domain signal
sparsification early in the neural encoding stage, taking advantage of the
interpretability of the self-attention mechanism in transformer audio encoders.
With the Whisper family of models, we perform a systematic architecture search
over the joint space of sparsification stage (a certain encoder layer) and
compression ratio (sparsity). We found that the best resulting solutions under
1% accuracy degradation choose to sparsify the hidden state to 40-60% sparsity
at an early encoding stage, and thereby achieve up to 1.6x runtime acceleration
in English speech transcription tasks on Nvidia GPUs without any fine-tuning.

</details>


### [246] [Probing the Robustness of Large Language Models Safety to Latent Perturbations](https://arxiv.org/abs/2506.16078)
*Tianle Gu,Kexin Huang,Zongqi Wang,Yixu Wang,Jie Li,Yuanqi Yao,Yang Yao,Yujiu Yang,Yan Teng,Yingchun Wang*

Main category: cs.LG

TL;DR: 论文探讨了现有安全对齐方法的浅层性，提出了一种探测方法（ASA）和改进策略（LAPT）以增强对齐鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有安全对齐方法仅关注表面拒绝行为，未充分改变内部表征，导致轻微潜在偏移仍可能触发不安全响应。

Method: 引入探测方法（ASA）量化潜在空间敏感性，并提出LAPT策略在训练中注入受控扰动。

Result: 实验表明LAPT能增强对齐鲁棒性且不影响模型通用能力。

Conclusion: 当前对齐范式存在根本缺陷，需转向表征级训练策略。

Abstract: Safety alignment is a key requirement for building reliable Artificial
General Intelligence. Despite significant advances in safety alignment, we
observe that minor latent shifts can still trigger unsafe responses in aligned
models. We argue that this stems from the shallow nature of existing alignment
methods, which focus on surface-level refusal behaviors without sufficiently
altering internal representations. Consequently, small shifts in hidden
activations can re-trigger harmful behaviors embedded in the latent space. To
explore the robustness of safety alignment to latent perturbations, we
introduce a probing method that measures the Negative Log-Likelihood of the
original response generated by the model. This probe quantifies local
sensitivity in the latent space, serving as a diagnostic tool for identifying
vulnerable directions. Based on this signal, we construct effective jailbreak
trajectories, giving rise to the Activation Steering Attack (ASA). More
importantly, these insights offer a principled foundation for improving
alignment robustness. To this end, we introduce Layer-wise Adversarial Patch
Training~(LAPT), a fine-tuning strategy that inject controlled perturbations
into hidden representations during training. Experimental results highlight
that LAPT strengthen alignment robustness without compromising general
capabilities. Our findings reveal fundamental flaws in current alignment
paradigms and call for representation-level training strategies that move
beyond surface-level behavior supervision. Codes and results are available at
https://github.com/Carol-gutianle/LatentSafety.

</details>


### [247] [Latent Concept Disentanglement in Transformer-based Language Models](https://arxiv.org/abs/2506.16975)
*Guan Zhe Hong,Bhavya Vasudeva,Vatsal Sharan,Cyrus Rashtchian,Prabhakar Raghavan,Rina Panigrahy*

Main category: cs.LG

TL;DR: 研究探讨了大型语言模型（LLM）在上下文学习（ICL）中是否能够捕捉潜在概念，并揭示了模型如何解耦和使用这些概念。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM在ICL中是否真正理解潜在概念，而非仅通过捷径解决问题。

Method: 通过2跳推理任务和连续潜在概念任务，分析模型如何解耦和使用潜在概念。

Result: 模型成功识别离散潜在概念并逐步组合；在连续潜在概念任务中，表示空间的低维子空间几何与潜在参数化一致。

Conclusion: 研究深化了对ICL和Transformer表示的理解，证明了模型中存在解耦潜在概念的局部结构。

Abstract: When large language models (LLMs) use in-context learning (ICL) to solve a
new task, they seem to grasp not only the goal of the task but also core,
latent concepts in the demonstration examples. This begs the question of
whether transformers represent latent structures as part of their computation
or whether they take shortcuts to solve the problem. Prior mechanistic work on
ICL does not address this question because it does not sufficiently examine the
relationship between the learned representation and the latent concept, and the
considered problem settings often involve only single-step reasoning. In this
work, we examine how transformers disentangle and use latent concepts. We show
that in 2-hop reasoning tasks with a latent, discrete concept, the model
successfully identifies the latent concept and does step-by-step concept
composition. In tasks parameterized by a continuous latent concept, we find
low-dimensional subspaces in the representation space where the geometry mimics
the underlying parameterization. Together, these results refine our
understanding of ICL and the representation of transformers, and they provide
evidence for highly localized structures in the model that disentangle latent
concepts in ICL tasks.

</details>


### [248] [From Concepts to Components: Concept-Agnostic Attention Module Discovery in Transformers](https://arxiv.org/abs/2506.17052)
*Jingtong Su,Julia Kempe,Karen Ullrich*

Main category: cs.LG

TL;DR: 论文提出了一种名为SAMD的方法，用于将任意复杂的概念映射到Transformer模型的特定注意力头上，并通过SAMI策略调整这些模块的效果。实验表明，该方法在语言和视觉任务中均有效。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在语言和视觉任务中表现出色，但对其内部机制的解释仍不足。现有研究多关注简单概念，忽略了注意力机制的影响。本文旨在填补这一空白。

Method: 提出SAMD方法，将概念表示为向量，计算其与注意力头的余弦相似度，选择TopK头构建概念关联模块。进一步提出SAMI策略，通过调整标量参数控制模块效果。

Result: 实验证明模块位置在LLM训练前后稳定，SAMI能显著提升或抑制模型性能（如安全性和推理能力）。

Conclusion: SAMD和SAMI为Transformer模型的解释和控制提供了通用且有效的方法。

Abstract: Transformers have achieved state-of-the-art performance across language and
vision tasks. This success drives the imperative to interpret their internal
mechanisms with the dual goals of enhancing performance and improving
behavioral control. Attribution methods help advance interpretability by
assigning model outputs associated with a target concept to specific model
components. Current attribution research primarily studies multi-layer
perceptron neurons and addresses relatively simple concepts such as factual
associations (e.g., Paris is located in France). This focus tends to overlook
the impact of the attention mechanism and lacks a unified approach for
analyzing more complex concepts. To fill these gaps, we introduce Scalable
Attention Module Discovery (SAMD), a concept-agnostic method for mapping
arbitrary, complex concepts to specific attention heads of general transformer
models. We accomplish this by representing each concept as a vector,
calculating its cosine similarity with each attention head, and selecting the
TopK-scoring heads to construct the concept-associated attention module. We
then propose Scalar Attention Module Intervention (SAMI), a simple strategy to
diminish or amplify the effects of a concept by adjusting the attention module
using only a single scalar parameter. Empirically, we demonstrate SAMD on
concepts of varying complexity, and visualize the locations of their
corresponding modules. Our results demonstrate that module locations remain
stable before and after LLM post-training, and confirm prior work on the
mechanics of LLM multilingualism. Through SAMI, we facilitate jailbreaking on
HarmBench (+72.7%) by diminishing "safety" and improve performance on the GSM8K
benchmark (+1.6%) by amplifying "reasoning". Lastly, we highlight the
domain-agnostic nature of our approach by suppressing the image classification
accuracy of vision transformers on ImageNet.

</details>


### [249] [Global Context-aware Representation Learning for Spatially Resolved Transcriptomics](https://arxiv.org/abs/2506.15698)
*Yunhak Oh,Junseok Lee,Yeongmin Kim,Sangwoo Seo,Namkyeong Lee,Chanyoung Park*

Main category: cs.LG

TL;DR: 论文提出了一种名为Spotscape的新框架，通过引入Similarity Telescope模块和相似性缩放策略，解决了现有图方法在空间转录组学中难以捕捉全局关系和边界区域的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的图方法在空间转录组学中过度依赖相邻点，导致边界区域的点表示不准确，无法有效捕捉全局关系。

Method: 提出Spotscape框架，包含Similarity Telescope模块和相似性缩放策略，用于捕捉全局关系并优化多切片整合。

Result: 实验表明，Spotscape在单切片和多切片场景的下游任务中表现优异。

Conclusion: Spotscape通过改进全局关系捕捉和边界处理，显著提升了空间转录组学分析的性能。

Abstract: Spatially Resolved Transcriptomics (SRT) is a cutting-edge technique that
captures the spatial context of cells within tissues, enabling the study of
complex biological networks. Recent graph-based methods leverage both gene
expression and spatial information to identify relevant spatial domains.
However, these approaches fall short in obtaining meaningful spot
representations, especially for spots near spatial domain boundaries, as they
heavily emphasize adjacent spots that have minimal feature differences from an
anchor node. To address this, we propose Spotscape, a novel framework that
introduces the Similarity Telescope module to capture global relationships
between multiple spots. Additionally, we propose a similarity scaling strategy
to regulate the distances between intra- and inter-slice spots, facilitating
effective multi-slice integration. Extensive experiments demonstrate the
superiority of Spotscape in various downstream tasks, including single-slice
and multi-slice scenarios. Our code is available at the following link: https:
//github.com/yunhak0/Spotscape.

</details>


### [250] [Shadow defense against gradient inversion attack in federated learning](https://arxiv.org/abs/2506.15711)
*Le Jiang,Liyan Ma,Guang Yang*

Main category: cs.LG

TL;DR: 本文提出了一种针对联邦学习中梯度反转攻击的防御框架，通过影子模型和针对性噪声注入，显著提升了隐私保护效果，同时最小化对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在隐私保护分布式训练中具有潜力，但梯度反转攻击可能导致隐私泄露，现有防御方法缺乏针对性，影响模型性能或保护不足。

Method: 利用影子模型识别敏感区域，并进行针对性噪声注入，实现更精准的隐私保护。

Result: 在ChestXRay和EyePACS数据集上，PSNR和SSIM指标显著优于无防御情况，且模型性能损失小于1%。

Conclusion: 该框架在多种医学图像上验证了其泛化能力，为联邦学习提供了高效的隐私保护方案。

Abstract: Federated learning (FL) has emerged as a transformative framework for
privacy-preserving distributed training, allowing clients to collaboratively
train a global model without sharing their local data. This is especially
crucial in sensitive fields like healthcare, where protecting patient data is
paramount. However, privacy leakage remains a critical challenge, as the
communication of model updates can be exploited by potential adversaries.
Gradient inversion attacks (GIAs), for instance, allow adversaries to
approximate the gradients used for training and reconstruct training images,
thus stealing patient privacy. Existing defense mechanisms obscure gradients,
yet lack a nuanced understanding of which gradients or types of image
information are most vulnerable to such attacks. These indiscriminate
calibrated perturbations result in either excessive privacy protection
degrading model accuracy, or insufficient one failing to safeguard sensitive
information. Therefore, we introduce a framework that addresses these
challenges by leveraging a shadow model with interpretability for identifying
sensitive areas. This enables a more targeted and sample-specific noise
injection. Specially, our defensive strategy achieves discrepancies of 3.73 in
PSNR and 0.2 in SSIM compared to the circumstance without defense on the
ChestXRay dataset, and 2.78 in PSNR and 0.166 in the EyePACS dataset. Moreover,
it minimizes adverse effects on model performance, with less than 1\% F1
reduction compared to SOTA methods. Our extensive experiments, conducted across
diverse types of medical images, validate the generalization of the proposed
framework. The stable defense improvements for FedAvg are consistently over
1.5\% times in LPIPS and SSIM. It also offers a universal defense against
various GIA types, especially for these sensitive areas in images.

</details>


### [251] [Tripartite Weight-Space Ensemble for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2506.15720)
*Juntae Lee,Munawar Hayat,Sungrack Yun*

Main category: cs.LG

TL;DR: 本文提出了一种新的少样本类增量学习（FSCIL）方法，通过权重空间三重集成（Tri-WE）和增强数据知识蒸馏，解决了灾难性遗忘和过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 现有FSCIL方法固定特征提取器限制了模型对新类的适应性，导致灾难性遗忘和过拟合。

Method: 提出Tri-WE方法，在权重空间中插值基础模型、前一个模型和当前模型，并引入增强数据知识蒸馏正则化损失。

Result: 在miniImageNet、CUB200和CIFAR100数据集上取得了最先进的结果。

Conclusion: Tri-WE和增强数据知识蒸馏有效提升了FSCIL性能，解决了固定特征提取器的限制。

Abstract: Few-shot class incremental learning (FSCIL) enables the continual learning of
new concepts with only a few training examples. In FSCIL, the model undergoes
substantial updates, making it prone to forgetting previous concepts and
overfitting to the limited new examples. Most recent trend is typically to
disentangle the learning of the representation from the classification head of
the model. A well-generalized feature extractor on the base classes (many
examples and many classes) is learned, and then fixed during incremental
learning. Arguing that the fixed feature extractor restricts the model's
adaptability to new classes, we introduce a novel FSCIL method to effectively
address catastrophic forgetting and overfitting issues. Our method enables to
seamlessly update the entire model with a few examples. We mainly propose a
tripartite weight-space ensemble (Tri-WE). Tri-WE interpolates the base,
immediately previous, and current models in weight-space, especially for the
classification heads of the models. Then, it collaboratively maintains
knowledge from the base and previous models. In addition, we recognize the
challenges of distilling generalized representations from the previous model
from scarce data. Hence, we suggest a regularization loss term using amplified
data knowledge distillation. Simply intermixing the few-shot data, we can
produce richer data enabling the distillation of critical knowledge from the
previous model. Consequently, we attain state-of-the-art results on the
miniImageNet, CUB200, and CIFAR100 datasets.

</details>


### [252] [Watermarking Autoregressive Image Generation](https://arxiv.org/abs/2506.16349)
*Nikola Jovanović,Ismail Labiad,Tomáš Souček,Martin Vechev,Pierre Fernandez*

Main category: cs.LG

TL;DR: 本文提出了一种在自回归图像生成模型的输出中嵌入水印的方法，解决了重新标记图像令牌时水印丢失的问题，并通过实验验证了其可靠性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型的普及，追踪其输出来源的需求日益增长，但目前尚无针对自回归图像生成模型的令牌级水印方法。

Method: 通过调整语言模型水印技术，引入自定义的标记器-解标记器微调程序和改进的水印同步层，以应对重新标记导致的令牌序列变化。

Result: 实验表明，该方法能够实现可靠且鲁棒的水印检测，并提供理论支持的p值。

Conclusion: 该方法为自回归图像生成模型的水印嵌入提供了首个可行的解决方案，具有实际应用潜力。

Abstract: Watermarking the outputs of generative models has emerged as a promising
approach for tracking their provenance. Despite significant interest in
autoregressive image generation models and their potential for misuse, no prior
work has attempted to watermark their outputs at the token level. In this work,
we present the first such approach by adapting language model watermarking
techniques to this setting. We identify a key challenge: the lack of reverse
cycle-consistency (RCC), wherein re-tokenizing generated image tokens
significantly alters the token sequence, effectively erasing the watermark. To
address this and to make our method robust to common image transformations,
neural compression, and removal attacks, we introduce (i) a custom
tokenizer-detokenizer finetuning procedure that improves RCC, and (ii) a
complementary watermark synchronization layer. As our experiments demonstrate,
our approach enables reliable and robust watermark detection with theoretically
grounded p-values.

</details>


### [253] [Subspace-Boosted Model Merging](https://arxiv.org/abs/2506.16506)
*Ronald Skorobogat,Karsten Roth,Mariana-Iuliana Georgescu,Zeynep Akata*

Main category: cs.LG

TL;DR: 论文提出Subspace Boosting方法，通过维持任务向量空间的秩来缓解模型合并中的秩崩溃问题，显著提升合并效果。


<details>
  <summary>Details</summary>
Motivation: 随着合并的专家模型数量增加，合并效果逐渐减弱，论文从任务算术角度分析并提出解决方案。

Method: 引入Subspace Boosting方法，基于奇异值分解的任务向量空间维持秩，并采用高阶广义奇异值分解量化任务相似性。

Result: 在视觉基准测试中，Subspace Boosting将合并效果提升超过10%，支持多达20个专家模型的合并。

Conclusion: Subspace Boosting有效解决了模型合并中的秩崩溃问题，同时提供了任务相似性的新解释视角。

Abstract: Model merging enables the combination of multiple specialized expert models
into a single model capable of performing multiple tasks. However, the benefits
of merging an increasing amount of specialized experts generally lead to
diminishing returns and reduced overall performance gains. In this work, we
offer an explanation and analysis from a task arithmetic perspective; revealing
that as the merging process (across numerous existing merging methods)
continues for more and more experts, the associated task vector space
experiences rank collapse. To mitigate this issue, we introduce Subspace
Boosting, which operates on the singular value decomposed task vector space and
maintains task vector ranks. Subspace Boosting raises merging efficacy for up
to 20 expert models by large margins of more than 10% when evaluated on vision
benchmarks. Moreover, we propose employing Higher-Order Generalized Singular
Value Decomposition to further quantify task similarity, offering a new
interpretable perspective on model merging.

</details>


### [254] [From Lab to Factory: Pitfalls and Guidelines for Self-/Unsupervised Defect Detection on Low-Quality Industrial Images](https://arxiv.org/abs/2506.16890)
*Sebastian Hönel,Jonas Nordqvist*

Main category: cs.LG

TL;DR: 论文探讨了在工业大规模生产中，利用机器学习替代人工检测质量问题的可行性，重点解决了低质量数据和实际场景中的鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 传统的人工检测成本高且易出错，机器学习有望替代，但现有方法在低质量数据和实际场景中表现不佳，需要改进。

Method: 评估了两种最先进的模型，用于识别和改进生产数据中的质量问题，无需新数据，并提出了一种更适用于实际场景的经验风险估计框架。

Result: 研究为从业者提供了识别模型或数据问题的指导，并揭示了基于似然方法的常见缺陷。

Conclusion: 论文提出了改进实际工业场景中质量检测的框架，强调了鲁棒性和经验风险估计的重要性。

Abstract: The detection and localization of quality-related problems in industrially
mass-produced products has historically relied on manual inspection, which is
costly and error-prone. Machine learning has the potential to replace manual
handling. As such, the desire is to facilitate an unsupervised (or
self-supervised) approach, as it is often impossible to specify all conceivable
defects ahead of time. A plethora of prior works have demonstrated the aptitude
of common reconstruction-, embedding-, and synthesis-based methods in
laboratory settings. However, in practice, we observe that most methods do not
handle low data quality well or exude low robustness in unfavorable, but
typical real-world settings. For practitioners it may be very difficult to
identify the actual underlying problem when such methods underperform. Worse,
often-reported metrics (e.g., AUROC) are rarely suitable in practice and may
give misleading results. In our setting, we attempt to identify subtle
anomalies on the surface of blasted forged metal parts, using rather
low-quality RGB imagery only, which is a common industrial setting. We
specifically evaluate two types of state-of-the-art models that allow us to
identify and improve quality issues in production data, without having to
obtain new data. Our contribution is to provide guardrails for practitioners
that allow them to identify problems related to, e.g., (lack of) robustness or
invariance, in either the chosen model or the data reliably in similar
scenarios. Furthermore, we exemplify common pitfalls in and shortcomings of
likelihood-based approaches and outline a framework for proper empirical risk
estimation that is more suitable for real-world scenarios.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [255] [Comparison of substructured non-overlapping domain decomposition and overlapping additive Schwarz methods for large-scale Helmholtz problems with multiple sources](https://arxiv.org/abs/2506.16875)
*Boris Martin,Pierre Jolivet,Christophe Geuzaine*

Main category: math.NA

TL;DR: 比较非重叠子结构域分解方法（DDM）和优化限制加性Schwarz（ORAS）预处理器在解决大规模Helmholtz问题中的性能，发现适当调优的非重叠方法能显著优于重叠方法。


<details>
  <summary>Details</summary>
Motivation: 解决大规模Helmholtz问题在高阶有限元离散化下的计算困难，尤其是在3D中直接分解系统矩阵成本高且迭代方法收敛困难。

Method: 比较非重叠子结构域分解方法和ORAS预处理器在解决多源Helmholtz问题中的性能。

Result: 在现实地球物理测试案例中，适当调优的非重叠方法能显著减少收敛差距，优于重叠方法。

Conclusion: 非重叠子结构域分解方法在解决大规模Helmholtz问题时具有显著优势。

Abstract: Solving large-scale Helmholtz problems discretized with high-order finite
elements is notoriously difficult, especially in 3D where direct factorization
of the system matrix is very expensive and memory demanding, and robust
convergence of iterative methods is difficult to obtain. Domain decomposition
methods (DDM) constitute one of the most promising strategy so far, by
combining direct and iterative approaches: using direct solvers on overlapping
or non-overlapping subdomains, as a preconditioner for a Krylov subspace method
on the original Helmholtz system or as an iterative solver on a substructured
problem involving field values or Lagrange multipliers on the interfaces
between the subdomains. In this work we compare the computational performance
of non-overlapping substructured DDM and Optimized Restricted Additive Schwarz
(ORAS) preconditioners for solving large-scale Helmholtz problems with multiple
sources, as is encountered, e.g., in frequency-domain Full Waveform Inversion.
We show on a realistic geophysical test-case that, when appropriately tuned,
the non-overlapping methods can reduce the convergence gap sufficiently to
significantly outperform the overlapping methods.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [256] [InfiniPot-V: Memory-Constrained KV Cache Compression for Streaming Video Understanding](https://arxiv.org/abs/2506.15745)
*Minsoo Kim,Kyuhong Shim,Jungwook Choi,Simyung Chang*

Main category: eess.IV

TL;DR: InfiniPot-V是一种无需训练、与查询无关的框架，用于解决多模态大语言模型（MLLMs）在处理流式视频时KV缓存内存线性增长的问题，通过轻量级压缩技术实现固定内存上限。


<details>
  <summary>Details</summary>
Motivation: 解决MLLMs在处理长视频时KV缓存内存线性增长的问题，使其适用于内存有限的设备（如手机、AR眼镜和边缘机器人）。

Method: 采用Temporal-axis Redundancy (TaR)指标去除时间冗余令牌，并通过Value-Norm (VaN)排名保留语义重要令牌。

Result: 在四个开源MLLMs和六个视频基准测试中，InfiniPot-V将GPU峰值内存降低高达94%，保持实时生成，并匹配或超越全缓存准确性。

Conclusion: InfiniPot-V通过消除KV缓存瓶颈，无需重新训练或查询知识，为设备端流式视频助手提供了可行解决方案。

Abstract: Modern multimodal large language models (MLLMs) can reason over hour-long
video, yet their key-value (KV) cache grows linearly with time--quickly
exceeding the fixed memory of phones, AR glasses, and edge robots. Prior
compression schemes either assume the whole video and user query are available
offline or must first build the full cache, so memory still scales with stream
length. InfiniPot-V is the first training-free, query-agnostic framework that
enforces a hard, length-independent memory cap for streaming video
understanding. During video encoding it monitors the cache and, once a user-set
threshold is reached, runs a lightweight compression pass that (i) removes
temporally redundant tokens via Temporal-axis Redundancy (TaR) metric and (ii)
keeps semantically significant tokens via Value-Norm (VaN) ranking. Across four
open-source MLLMs and four long-video and two streaming-video benchmarks,
InfiniPot-V cuts peak GPU memory by up to 94%, sustains real-time generation,
and matches or surpasses full-cache accuracy--even in multi-turn dialogues. By
dissolving the KV cache bottleneck without retraining or query knowledge,
InfiniPot-V closes the gap for on-device streaming video assistants.

</details>


### [257] [Pixel-wise Modulated Dice Loss for Medical Image Segmentation](https://arxiv.org/abs/2506.15744)
*Seyed Mohsen Hosseini*

Main category: eess.IV

TL;DR: 论文提出了一种改进的Dice损失函数（PM Dice损失），通过像素级调制项同时解决类别不平衡和难度不平衡问题，在医学分割任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 医学分割任务中存在类别不平衡和难度不平衡问题，传统方法（如交叉熵损失或改进的Dice损失）计算成本高且效果有限。

Method: 提出了一种简单的Dice损失改进方法（PM Dice损失），通过像素级调制项，利用Dice损失处理类别不平衡的优势，同时解决难度不平衡问题。

Result: 在三种常用医学分割任务上的实验表明，PM Dice损失优于其他针对难度不平衡问题设计的方法。

Conclusion: PM Dice损失是一种计算成本低且有效的方法，能够同时解决类别不平衡和难度不平衡问题。

Abstract: Class imbalance and the difficulty imbalance are the two types of data
imbalance that affect the performance of neural networks in medical
segmentation tasks. In class imbalance the loss is dominated by the majority
classes and in difficulty imbalance the loss is dominated by easy to classify
pixels. This leads to an ineffective training. Dice loss, which is based on a
geometrical metric, is very effective in addressing the class imbalance
compared to the cross entropy (CE) loss, which is adopted directly from
classification tasks. To address the difficulty imbalance, the common approach
is employing a re-weighted CE loss or a modified Dice loss to focus the
training on difficult to classify areas. The existing modification methods are
computationally costly and with limited success. In this study we propose a
simple modification to the Dice loss with minimal computational cost. With a
pixel level modulating term, we take advantage of the effectiveness of Dice
loss in handling the class imbalance to also handle the difficulty imbalance.
Results on three commonly used medical segmentation tasks show that the
proposed Pixel-wise Modulated Dice loss (PM Dice loss) outperforms other
methods, which are designed to tackle the difficulty imbalance problem.

</details>


### [258] [Diffusion-based Counterfactual Augmentation: Towards Robust and Interpretable Knee Osteoarthritis Grading](https://arxiv.org/abs/2506.15748)
*Zhe Wang,Yuhua Ru,Aladine Chetouani,Tina Shiang,Fang Chen,Fabian Bauer,Liping Zhang,Didier Hans,Rachid Jennane,William Ewing Palmer,Mohamed Jarraya,Yung Hsin Chen*

Main category: eess.IV

TL;DR: 论文提出了一种基于扩散模型的反事实增强框架（DCA），通过生成针对性反事实样本提升模型鲁棒性和可解释性，显著提高了膝关节骨关节炎（KOA）自动分级的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决膝关节骨关节炎（KOA）自动分级中观察者间差异大和深度学习模型在关键决策边界附近鲁棒性不足的问题。

Method: 使用扩散模型和随机微分方程（SDE）生成反事实样本，结合自校正学习策略优化分类器。

Result: 在OAI和MOST数据集上显著提升了分类准确性，且生成的潜在空间拓扑与KOA临床进展知识一致。

Conclusion: DCA框架将模型不确定性转化为鲁棒训练信号，为开发更准确、可信的自动诊断系统提供了新途径。

Abstract: Automated grading of Knee Osteoarthritis (KOA) from radiographs is challenged
by significant inter-observer variability and the limited robustness of deep
learning models, particularly near critical decision boundaries. To address
these limitations, this paper proposes a novel framework, Diffusion-based
Counterfactual Augmentation (DCA), which enhances model robustness and
interpretability by generating targeted counterfactual examples. The method
navigates the latent space of a diffusion model using a Stochastic Differential
Equation (SDE), governed by balancing a classifier-informed boundary drive with
a manifold constraint. The resulting counterfactuals are then used within a
self-corrective learning strategy to improve the classifier by focusing on its
specific areas of uncertainty. Extensive experiments on the public
Osteoarthritis Initiative (OAI) and Multicenter Osteoarthritis Study (MOST)
datasets demonstrate that this approach significantly improves classification
accuracy across multiple model architectures. Furthermore, the method provides
interpretability by visualizing minimal pathological changes and revealing that
the learned latent space topology aligns with clinical knowledge of KOA
progression. The DCA framework effectively converts model uncertainty into a
robust training signal, offering a promising pathway to developing more
accurate and trustworthy automated diagnostic systems. Our code is available at
https://github.com/ZWang78/DCA.

</details>


### [259] [MoNetV2: Enhanced Motion Network for Freehand 3D Ultrasound Reconstruction](https://arxiv.org/abs/2506.15835)
*Mingyuan Luo,Xin Yang,Zhongnuo Yan,Yan Cao,Yuanji Zhang,Xindi Hu,Jin Wang,Haoxuan Ding,Wei Han,Litao Sun,Dong Ni*

Main category: eess.IV

TL;DR: MoNetV2通过融合图像和运动信息、多级一致性约束及多模态自监督策略，显著提升了自由手3D超声重建的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 自由手3D超声重建在复杂运动轨迹下存在累积漂移和精度不足的问题，需改进。

Method: 提出MoNetV2，包括传感器辅助的时空多分支结构、在线多级一致性约束及多模态自监督策略。

Result: 在三个大型数据集上，MoNetV2在重建质量和泛化性能上优于现有方法。

Conclusion: MoNetV2通过多信息融合和一致性约束，有效解决了自由手3D超声重建的挑战。

Abstract: Three-dimensional (3D) ultrasound (US) aims to provide sonographers with the
spatial relationships of anatomical structures, playing a crucial role in
clinical diagnosis. Recently, deep-learning-based freehand 3D US has made
significant advancements. It reconstructs volumes by estimating transformations
between images without external tracking. However, image-only reconstruction
poses difficulties in reducing cumulative drift and further improving
reconstruction accuracy, particularly in scenarios involving complex motion
trajectories. In this context, we propose an enhanced motion network (MoNetV2)
to enhance the accuracy and generalizability of reconstruction under diverse
scanning velocities and tactics. First, we propose a sensor-based temporal and
multi-branch structure that fuses image and motion information from a velocity
perspective to improve image-only reconstruction accuracy. Second, we devise an
online multi-level consistency constraint that exploits the inherent
consistency of scans to handle various scanning velocities and tactics. This
constraint exploits both scan-level velocity consistency, path-level appearance
consistency, and patch-level motion consistency to supervise inter-frame
transformation estimation. Third, we distill an online multi-modal
self-supervised strategy that leverages the correlation between network
estimation and motion information to further reduce cumulative errors.
Extensive experiments clearly demonstrate that MoNetV2 surpasses existing
methods in both reconstruction quality and generalizability performance across
three large datasets.

</details>


### [260] [Cross-Modality Learning for Predicting IHC Biomarkers from H&E-Stained Whole-Slide Images](https://arxiv.org/abs/2506.15853)
*Amit Das,Naofumi Tomita,Kyle J. Syme,Weijie Ma,Paige O'Connor,Kristin N. Corbett,Bing Ren,Xiaoying Liu,Saeed Hassanpour*

Main category: eess.IV

TL;DR: HistoStainAlign是一种深度学习框架，直接从H&E全切片图像预测IHC染色模式，无需标注或组织配准，提高了诊断效率。


<details>
  <summary>Details</summary>
Motivation: IHC染色成本高、耗时长且资源密集，限制了其广泛应用。本研究旨在通过计算模型预测IHC染色模式，减少对实际IHC染色的依赖。

Method: 提出HistoStainAlign框架，通过对比训练策略整合H&E和IHC的嵌入特征，学习形态学和分子特征的联合表示。

Result: 在胃肠道和肺组织WSIs上评估，对P53、PD-L1和Ki-67三种IHC染色，加权F1分数分别为0.735、0.830和0.723。

Conclusion: HistoStainAlign展示了作为预筛查工具的潜力，可优化IHC染色的工作流程，提高效率。

Abstract: Hematoxylin and Eosin (H&E) staining is a cornerstone of pathological
analysis, offering reliable visualization of cellular morphology and tissue
architecture for cancer diagnosis, subtyping, and grading. Immunohistochemistry
(IHC) staining provides molecular insights by detecting specific proteins
within tissues, enhancing diagnostic accuracy, and improving treatment
planning. However, IHC staining is costly, time-consuming, and
resource-intensive, requiring specialized expertise. To address these
limitations, this study proposes HistoStainAlign, a novel deep learning
framework that predicts IHC staining patterns directly from H&E whole-slide
images (WSIs) by learning joint representations of morphological and molecular
features. The framework integrates paired H&E and IHC embeddings through a
contrastive training strategy, capturing complementary features across staining
modalities without patch-level annotations or tissue registration. The model
was evaluated on gastrointestinal and lung tissue WSIs with three commonly used
IHC stains: P53, PD-L1, and Ki-67. HistoStainAlign achieved weighted F1 scores
of 0.735 [95% Confidence Interval (CI): 0.670-0.799], 0.830 [95% CI:
0.772-0.886], and 0.723 [95% CI: 0.607-0.836], respectively for these three IHC
stains. Embedding analyses demonstrated the robustness of the contrastive
alignment in capturing meaningful cross-stain relationships. Comparisons with a
baseline model further highlight the advantage of incorporating contrastive
learning for improved stain pattern prediction. This study demonstrates the
potential of computational approaches to serve as a pre-screening tool, helping
prioritize cases for IHC staining and improving workflow efficiency.

</details>


### [261] [Fast Training-free Perceptual Image Compression](https://arxiv.org/abs/2506.16102)
*Ziran Zhu,Tongda Xu,Minye Huang,Dailan He,Xingtong Ge,Xinjie Zhang,Ling Li,Yan Wang*

Main category: eess.IV

TL;DR: 提出一种无需训练的算法，显著提升现有图像编解码器的感知质量，并优化解码时间。


<details>
  <summary>Details</summary>
Motivation: 现有无需训练的感知图像编解码器依赖扩散反转或样本通信，解码时间过长（1分钟以上）。本文旨在解决这一问题。

Method: 提出一种无需训练的算法，支持不同解码时间预算（0.1秒、0.1-10秒、≥10秒）下的最优感知质量实现。

Result: 将解码时间从1分钟缩短至0.1-10秒，感知质量相当；适用于非可微分编解码器（如VTM）；提升现有感知编解码器（如MS-ILLM）。

Conclusion: 该方法在快速解码下显著提升感知质量，FID优于现有条件生成模型编解码器（如HiFiC和MS-ILLM）。

Abstract: Training-free perceptual image codec adopt pre-trained unconditional
generative model during decoding to avoid training new conditional generative
model. However, they heavily rely on diffusion inversion or sample
communication, which take 1 min to intractable amount of time to decode a
single image. In this paper, we propose a training-free algorithm that improves
the perceptual quality of any existing codec with theoretical guarantee. We
further propose different implementations for optimal perceptual quality when
decoding time budget is $\approx 0.1$s, $0.1-10$s and $\ge 10$s. Our approach:
1). improves the decoding time of training-free codec from 1 min to $0.1-10$s
with comparable perceptual quality. 2). can be applied to non-differentiable
codec such as VTM. 3). can be used to improve previous perceptual codecs, such
as MS-ILLM. 4). can easily achieve perception-distortion trade-off.
Empirically, we show that our approach successfully improves the perceptual
quality of ELIC, VTM and MS-ILLM with fast decoding. Our approach achieves
comparable FID to previous training-free codec with significantly less decoding
time. And our approach still outperforms previous conditional generative model
based codecs such as HiFiC and MS-ILLM in terms of FID. The source code is
provided in the supplementary material.

</details>


### [262] [Enhanced Dermatology Image Quality Assessment via Cross-Domain Training](https://arxiv.org/abs/2506.16116)
*Ignacio Hernández Montilla,Alfonso Medela,Paola Pasquali,Andy Aguilar,Taig Mac Carthy,Gerardo Fernández,Antonio Martorell,Enrique Onieva*

Main category: eess.IV

TL;DR: 论文提出了一种跨域训练的图像质量评估（IQA）方法，结合皮肤病学和非皮肤病学数据集，解决了皮肤病学中图像质量评估数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 远程皮肤病学中图像质量差是一个未解决的问题，影响了远程咨询的有效性。现有研究未能充分利用非皮肤病学IQA的最新进展。

Method: 通过创建新的皮肤病学IQA数据库（Legit.Health-DIQA-Artificial），并结合非皮肤病学IQA数据集，进行跨域训练。

Result: 跨域训练在多个领域表现最优，克服了皮肤病学IQA数据规模小的限制，提升了图像质量管理的效果。

Conclusion: 跨域训练方法显著改善了远程皮肤病学中的图像质量管理，为未来研究提供了新方向。

Abstract: Teledermatology has become a widely accepted communication method in daily
clinical practice, enabling remote care while showing strong agreement with
in-person visits. Poor image quality remains an unsolved problem in
teledermatology and is a major concern to practitioners, as bad-quality images
reduce the usefulness of the remote consultation process. However, research on
Image Quality Assessment (IQA) in dermatology is sparse, and does not leverage
the latest advances in non-dermatology IQA, such as using larger image
databases with ratings from large groups of human observers. In this work, we
propose cross-domain training of IQA models, combining dermatology and
non-dermatology IQA datasets. For this purpose, we created a novel dermatology
IQA database, Legit.Health-DIQA-Artificial, using dermatology images from
several sources and having them annotated by a group of human observers. We
demonstrate that cross-domain training yields optimal performance across
domains and overcomes one of the biggest limitations in dermatology IQA, which
is the small scale of data, and leads to models trained on a larger pool of
image distortions, resulting in a better management of image quality in the
teledermatology process.

</details>


### [263] [From Coarse to Continuous: Progressive Refinement Implicit Neural Representation for Motion-Robust Anisotropic MRI Reconstruction](https://arxiv.org/abs/2506.16210)
*Zhenxuan Zhang,Lipei Zhang,Yanqi Cheng,Zi Wang,Fanwen Wang,Haosen Zhang,Yue Yang,Yinzhe Wu,Jiahao Huang,Angelica I Aviles-Rivero,Zhifan Gao,Guang Yang,Peter J. Lally*

Main category: eess.IV

TL;DR: PR-INR框架通过渐进式隐式神经表示，统一了运动校正、结构细化和体积合成，显著提升了运动鲁棒MRI的重建质量。


<details>
  <summary>Details</summary>
Motivation: 在运动鲁棒MRI中，切片到体积重建面临局部细节丢失、全局结构混叠和体积各向异性等挑战，需要一种统一的方法来解决这些问题。

Method: PR-INR框架包括运动感知扩散模块（粗重建）、隐式细节恢复模块（局部修正）和体素连续感知表示模块（高频细节恢复）。

Result: 在多种运动条件、欠采样率和切片分辨率下，PR-INR在定量重建指标和视觉质量上均优于现有方法，并展示了跨领域的泛化能力。

Conclusion: PR-INR为运动鲁棒MRI提供了一种高效且通用的解决方案，显著提升了重建精度和鲁棒性。

Abstract: In motion-robust magnetic resonance imaging (MRI), slice-to-volume
reconstruction is critical for recovering anatomically consistent 3D brain
volumes from 2D slices, especially under accelerated acquisitions or patient
motion. However, this task remains challenging due to hierarchical structural
disruptions. It includes local detail loss from k-space undersampling, global
structural aliasing caused by motion, and volumetric anisotropy. Therefore, we
propose a progressive refinement implicit neural representation (PR-INR)
framework. Our PR-INR unifies motion correction, structural refinement, and
volumetric synthesis within a geometry-aware coordinate space. Specifically, a
motion-aware diffusion module is first employed to generate coarse volumetric
reconstructions that suppress motion artifacts and preserve global anatomical
structures. Then, we introduce an implicit detail restoration module that
performs residual refinement by aligning spatial coordinates with visual
features. It corrects local structures and enhances boundary precision.
Further, a voxel continuous-aware representation module represents the image as
a continuous function over 3D coordinates. It enables accurate inter-slice
completion and high-frequency detail recovery. We evaluate PR-INR on five
public MRI datasets under various motion conditions (3% and 5% displacement),
undersampling rates (4x and 8x) and slice resolutions (scale = 5). Experimental
results demonstrate that PR-INR outperforms state-of-the-art methods in both
quantitative reconstruction metrics and visual quality. It further shows
generalization and robustness across diverse unseen domains.

</details>


### [264] [CF-Seg: Counterfactuals meet Segmentation](https://arxiv.org/abs/2506.16213)
*Raghav Mehta,Fabio De Sousa Ribeiro,Tian Xia,Melanie Roschewitz,Ainkaran Santhirasekaram,Dominic C. Marshall,Ben Glocker*

Main category: eess.IV

TL;DR: 通过生成反事实图像模拟无疾病状态下的解剖结构，提升医学图像分割准确性。


<details>
  <summary>Details</summary>
Motivation: 疾病会改变健康组织的表现，增加分割难度，可能导致误诊。

Method: 生成反事实图像模拟无疾病状态，不改变原始结构，用于分割。

Result: 在两个真实临床胸部X光数据集上，反事实图像显著提升解剖分割效果。

Conclusion: 反事实图像有助于改善解剖分割，支持临床决策。

Abstract: Segmenting anatomical structures in medical images plays an important role in
the quantitative assessment of various diseases. However, accurate segmentation
becomes significantly more challenging in the presence of disease. Disease
patterns can alter the appearance of surrounding healthy tissues, introduce
ambiguous boundaries, or even obscure critical anatomical structures. As such,
segmentation models trained on real-world datasets may struggle to provide good
anatomical segmentation, leading to potential misdiagnosis. In this paper, we
generate counterfactual (CF) images to simulate how the same anatomy would
appear in the absence of disease without altering the underlying structure. We
then use these CF images to segment structures of interest, without requiring
any changes to the underlying segmentation model. Our experiments on two
real-world clinical chest X-ray datasets show that the use of counterfactual
images improves anatomical segmentation, thereby aiding downstream clinical
decision-making.

</details>


### [265] [AGE-US: automated gestational age estimation based on fetal ultrasound images](https://arxiv.org/abs/2506.16256)
*César Díaz-Parga,Marta Nuñez-Garcia,Maria J. Carreira,Gabriel Bernardino,Nicolás Vila-Blanco*

Main category: eess.IV

TL;DR: 提出了一种基于深度学习的自动计算孕龄方法，通过新颖的分割架构和距离图解决数据限制问题，性能接近现有最佳模型，适用于资源有限环境。


<details>
  <summary>Details</summary>
Motivation: 传统孕龄估计方法（如末次月经）在某些情况下难以获取，而超声方法依赖人工测量，存在变异性。需要更可靠且自动化的方法。

Method: 采用可解释的深度学习模型，结合新颖的分割架构和距离图，克服数据集限制和分割掩码稀缺问题。

Result: 模型性能接近现有最佳模型，复杂度更低，尤其适合资源有限环境。距离图特别适用于股骨端点估计。

Conclusion: 该方法为孕龄估计提供了可靠且高效的自动化解决方案，尤其适用于资源有限和标注数据稀缺的场景。

Abstract: Being born small carries significant health risks, including increased
neonatal mortality and a higher likelihood of future cardiac diseases. Accurate
estimation of gestational age is critical for monitoring fetal growth, but
traditional methods, such as estimation based on the last menstrual period, are
in some situations difficult to obtain. While ultrasound-based approaches offer
greater reliability, they rely on manual measurements that introduce
variability. This study presents an interpretable deep learning-based method
for automated gestational age calculation, leveraging a novel segmentation
architecture and distance maps to overcome dataset limitations and the scarcity
of segmentation masks. Our approach achieves performance comparable to
state-of-the-art models while reducing complexity, making it particularly
suitable for resource-constrained settings and with limited annotated data.
Furthermore, our results demonstrate that the use of distance maps is
particularly suitable for estimating femur endpoints.

</details>


### [266] [VesselSDF: Distance Field Priors for Vascular Network Reconstruction](https://arxiv.org/abs/2506.16556)
*Salvatore Esposito,Daniel Rebain,Arno Onken,Changjian Li,Oisin Mac Aodha*

Main category: eess.IV

TL;DR: VesselSDF提出了一种基于符号距离场（SDF）的新方法，用于从稀疏CT扫描切片中准确分割血管网络，解决了现有深度学习方法在结构连续性和几何保真度上的不足。


<details>
  <summary>Details</summary>
Motivation: 稀疏CT扫描切片中血管网络的准确分割是一个挑战，尤其是血管的细长分支特性以及成像平面间的稀疏性。现有基于二值体素分类的深度学习方法难以保证结构的连续性和几何保真度。

Method: VesselSDF将血管分割问题重新定义为连续的SDF回归问题，通过自适应高斯正则化器消除SDF的常见伪影，同时保持血管表面的精确几何形状。

Result: 实验结果表明，VesselSDF显著优于现有方法，能够更好地保留血管的几何形状和连通性。

Conclusion: VesselSDF为临床环境中的血管分析提供了更可靠的解决方案。

Abstract: Accurate segmentation of vascular networks from sparse CT scan slices remains
a significant challenge in medical imaging, particularly due to the thin,
branching nature of vessels and the inherent sparsity between imaging planes.
Existing deep learning approaches, based on binary voxel classification, often
struggle with structural continuity and geometric fidelity. To address this
challenge, we present VesselSDF, a novel framework that leverages signed
distance fields (SDFs) for robust vessel reconstruction. Our method
reformulates vessel segmentation as a continuous SDF regression problem, where
each point in the volume is represented by its signed distance to the nearest
vessel surface. This continuous representation inherently captures the smooth,
tubular geometry of blood vessels and their branching patterns. We obtain
accurate vessel reconstructions while eliminating common SDF artifacts such as
floating segments, thanks to our adaptive Gaussian regularizer which ensures
smoothness in regions far from vessel surfaces while producing precise geometry
near the surface boundaries. Our experimental results demonstrate that
VesselSDF significantly outperforms existing methods and preserves vessel
geometry and connectivity, enabling more reliable vascular analysis in clinical
settings.

</details>


### [267] [DiffO: Single-step Diffusion for Image Compression at Ultra-Low Bitrates](https://arxiv.org/abs/2506.16572)
*Chanung Park,Joo Chan Lee,Jong Hwan Ko*

Main category: eess.IV

TL;DR: DiffO是一种单步扩散模型，用于图像压缩，通过VQ残差训练和速率自适应噪声调制，在极低比特率下实现高质量和快速解码。


<details>
  <summary>Details</summary>
Motivation: 现有图像压缩方法在极低比特率下质量下降严重，且基于扩散的模型解码延迟高。

Method: 结合VQ残差训练（捕获全局几何和高频细节）和速率自适应噪声调制（动态调整去噪强度）。

Result: DiffO在压缩性能和解码速度上优于现有方法，解码速度提升约50倍。

Conclusion: DiffO显著提升了生成编解码器的实用性，适用于极低比特率场景。

Abstract: Although image compression is fundamental to visual data processing and has
inspired numerous standard and learned codecs, these methods still suffer
severe quality degradation at extremely low bits per pixel. While recent
diffusion based models provided enhanced generative performance at low
bitrates, they still yields limited perceptual quality and prohibitive decoding
latency due to multiple denoising steps. In this paper, we propose the first
single step diffusion model for image compression (DiffO) that delivers high
perceptual quality and fast decoding at ultra low bitrates. DiffO achieves
these goals by coupling two key innovations: (i) VQ Residual training, which
factorizes a structural base code and a learned residual in latent space,
capturing both global geometry and high frequency details; and (ii) rate
adaptive noise modulation, which tunes denoising strength on the fly to match
the desired bitrate. Extensive experiments show that DiffO surpasses state of
the art compression performance while improving decoding speed by about 50x
compared to prior diffusion-based methods, greatly improving the practicality
of generative codecs. The code will be available at
https://github.com/Freemasti/DiffO.

</details>


### [268] [Hybrid Attention Network for Accurate Breast Tumor Segmentation in Ultrasound Images](https://arxiv.org/abs/2506.16592)
*Muhammad Azeem Aslam,Asim Naveed,Nisar Ahmed*

Main category: eess.IV

TL;DR: 提出了一种基于混合注意力的网络用于乳腺超声图像中的肿瘤分割，结合了预训练的DenseNet121和多分支注意力增强解码器，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 乳腺超声图像中的肿瘤分割面临噪声、病变尺度变化和模糊边界等挑战，需要更精确的自动化方法。

Method: 采用预训练的DenseNet121作为编码器，结合多分支注意力增强解码器，引入全局空间注意力、位置编码和缩放点积注意力，并嵌入空间特征增强块优化特征。使用混合损失函数（BCE和Jaccard损失）优化分割结果。

Result: 在公开数据集上的实验表明，该方法优于现有方法，提高了分割准确性和鲁棒性。

Conclusion: 该方法在乳腺超声图像分割中表现出色，有望辅助放射科医生实现早期和准确的乳腺癌诊断。

Abstract: Breast ultrasound imaging is a valuable tool for early breast cancer
detection, but automated tumor segmentation is challenging due to inherent
noise, variations in scale of lesions, and fuzzy boundaries. To address these
challenges, we propose a novel hybrid attention-based network for lesion
segmentation. Our proposed architecture integrates a pre-trained DenseNet121 in
the encoder part for robust feature extraction with a multi-branch
attention-enhanced decoder tailored for breast ultrasound images. The
bottleneck incorporates Global Spatial Attention (GSA), Position Encoding (PE),
and Scaled Dot-Product Attention (SDPA) to learn global context, spatial
relationships, and relative positional features. The Spatial Feature
Enhancement Block (SFEB) is embedded at skip connections to refine and enhance
spatial features, enabling the network to focus more effectively on tumor
regions. A hybrid loss function combining Binary Cross-Entropy (BCE) and
Jaccard Index loss optimizes both pixel-level accuracy and region-level overlap
metrics, enhancing robustness to class imbalance and irregular tumor shapes.
Experiments on public datasets demonstrate that our method outperforms existing
approaches, highlighting its potential to assist radiologists in early and
accurate breast cancer diagnosis.

</details>


### [269] [Overfitting in Histopathology Model Training: The Need for Customized Architectures](https://arxiv.org/abs/2506.16631)
*Saghir Alfasly,Ghazal Alabtah,H. R. Tizhoosh*

Main category: eess.IV

TL;DR: 研究表明，在组织病理学图像分析中直接采用自然图像分析的大规模模型会导致过拟合和性能不佳，需定制专用架构。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在组织病理学图像分析中的过拟合问题，并探索模型容量与性能的关系。

Method: 通过实验比较不同模型架构（如ResNet和ViT），并验证简单、领域专用架构的有效性。

Result: 增加模型容量不一定提升性能，而定制架构在有限数据集上表现更优且减少过拟合。

Conclusion: 组织病理学图像分析需设计专用架构，而非依赖通用模型。

Abstract: This study investigates the critical problem of overfitting in deep learning
models applied to histopathology image analysis. We show that simply adopting
and fine-tuning large-scale models designed for natural image analysis often
leads to suboptimal performance and significant overfitting when applied to
histopathology tasks. Through extensive experiments with various model
architectures, including ResNet variants and Vision Transformers (ViT), we show
that increasing model capacity does not necessarily improve performance on
histopathology datasets. Our findings emphasize the need for customized
architectures specifically designed for histopathology image analysis,
particularly when working with limited datasets. Using Oesophageal
Adenocarcinomas public dataset, we demonstrate that simpler, domain-specific
architectures can achieve comparable or better performance while minimizing
overfitting.

</details>


### [270] [A Prior-Guided Joint Diffusion Model in Projection Domain for PET Tracer Conversion](https://arxiv.org/abs/2506.16733)
*Fang Chen,Weifeng Zhang,Xingyu Ai,BingXuan Li,An Li,Qiegen Liu*

Main category: eess.IV

TL;DR: 该研究提出了一种先验引导的联合扩散模型（PJDM），用于在投影域中将18F-FDG PET图像转换为18F-DOPA PET图像，以提高图像质量和合成效果。


<details>
  <summary>Details</summary>
Motivation: 18F-DOPA在神经内分泌肿瘤和神经系统疾病中具有更高的特异性，但其合成复杂且临床应用受限。通过直接在投影域建模，可以减少图像重建过程中的误差累积。

Method: 研究采用先验引导的联合扩散模型（PJDM），包括粗估计模型和先验细化模型。通过高阶混合采样器生成初始合成图像，并利用学习到的先验进行迭代细化。

Result: 实验结果表明，PJDM显著提高了投影域图像的质量和合成效果。

Conclusion: PJDM为18F-FDG到18F-DOPA的图像转换提供了一种有效方法，尤其在投影域建模中表现出优势。

Abstract: Positron emission tomography (PET) is widely used to assess metabolic
activity, but its application is limited by the availability of radiotracers.
18F-labeled fluorodeoxyglucose (18F-FDG) is the most commonly used tracer but
shows limited effectiveness for certain tumors. In contrast,
6-18F-fluoro-3,4-dihydroxy-L-phenylalanine (18F-DOPA) offers higher specificity
for neuroendocrine tumors and neurological disorders. However, its complex
synthesis and limitations in transportation and clinical use hinder widespread
adoption. During PET imaging, the sinogram represents a form of raw data
acquired by the scanner. Therefore, modeling in projection domain enables more
direct utilization of the original information, potentially reducing the
accumulation of errors introduced during the image reconstruction process.
Inspired by these factors, this study proposes a prior-guided joint diffusion
model (PJDM) for transforming 18F-FDG PET images into 18F-DOPA PET images in
projection domain. Specifically, a coarse estimation model and a prior
refinement model are trained independently. During inference, an initial
synthetic 18F-DOPA PET sinogram is generated using a higher-order hybrid
sampler. This sinogram is then degraded and serves as an additional condition
to guide the iterative refinement process using learned prior. Experimental
results demonstrated that PJDM effectively improved both sinogram quality and
synthetic outcomes. The code is available at: https://github.com/yqx7150/PJDM.

</details>


### [271] [Temperature calibration of surface emissivities with an improved thermal image enhancement network](https://arxiv.org/abs/2506.16803)
*Ning Chu,Siya Zheng,Shanqing Zhang,Li Li,Caifang Cai,Ali Mohammad-Djafari,Feng Zhao,Yuanbo Song*

Main category: eess.IV

TL;DR: 提出了一种物理引导的神经框架，通过对称跳跃CNN和发射率感知注意力模块，联合优化温度校正和图像增强，解决了红外热成像中材料发射率变化导致的温度准确性问题。


<details>
  <summary>Details</summary>
Motivation: 红外热成像因材料发射率变化导致温度准确性不足，现有方法常忽略辐射校准和图像退化的联合优化。

Method: 采用对称跳跃CNN架构和发射率感知注意力模块，通过双约束损失函数（均值-方差对齐和KL散度直方图匹配）动态融合热辐射特征与空间背景。

Result: 在工业鼓风机系统验证中，模型有效抑制发射率伪影并恢复结构细节，实现多种工业条件下的准确校准。

Conclusion: 该方法通过动态融合热辐射特征与空间背景，显著提升了红外热成像的温度准确性和图像质量。

Abstract: Infrared thermography faces persistent challenges in temperature accuracy due
to material emissivity variations, where existing methods often neglect the
joint optimization of radiometric calibration and image degradation. This study
introduces a physically guided neural framework that unifies temperature
correction and image enhancement through a symmetric skip-CNN architecture and
an emissivity-aware attention module. The pre-processing stage segments the
ROIs of the image and and initially corrected the firing rate. A novel
dual-constrained loss function strengthens the statistical consistency between
the target and reference regions through mean-variance alignment and histogram
matching based on Kullback-Leibler dispersion. The method works by dynamically
fusing thermal radiation features and spatial context, and the model suppresses
emissivity artifacts while recovering structural details. After validating the
industrial blower system under different conditions, the improved network
realizes the dynamic fusion of thermal radiation characteristics and spatial
background, with accurate calibration results in various industrial conditions.

</details>


### [272] [PET Tracer Separation Using Conditional Diffusion Transformer with Multi-latent Space Learning](https://arxiv.org/abs/2506.16934)
*Bin Huang,Feihong Xu,Xinchong Shi,Shan Huang,Binxuan Li,Fei Li,Qiegen Liu*

Main category: eess.IV

TL;DR: 提出了一种多潜在空间引导的纹理条件扩散变换模型（MS-CDT），用于PET成像中的示踪剂分离，首次结合纹理条件和多潜在空间技术。


<details>
  <summary>Details</summary>
Motivation: 多示踪剂PET成像能提供更全面的生理和病理信息，但由于不同示踪剂产生的光子对能量相同，信号难以区分。

Method: 整合扩散和变换器架构，引入纹理掩码作为条件输入，利用多潜在空间先验捕捉多层次特征表示。

Result: 在脑部和胸部3D PET数据集上，MS-CDT在图像质量和临床信息保留方面表现优异。

Conclusion: MS-CDT通过纹理条件和多潜在空间技术，实现了更准确和鲁棒的示踪剂分离。

Abstract: In clinical practice, single-radiotracer positron emission tomography (PET)
is commonly used for imaging. Although multi-tracer PET imaging can provide
supplementary information of radiotracers that are sensitive to physiological
function changes, enabling a more comprehensive characterization of
physiological and pathological states, the gamma-photon pairs generated by
positron annihilation reactions of different tracers in PET imaging have the
same energy, making it difficult to distinguish the tracer signals. In this
study, a multi-latent space guided texture conditional diffusion transformer
model (MS-CDT) is proposed for PET tracer separation. To the best of our
knowledge, this is the first attempt to use texture condition and multi-latent
space for tracer separation in PET imaging. The proposed model integrates
diffusion and transformer architectures into a unified optimization framework,
with the novel addition of texture masks as conditional inputs to enhance image
details. By leveraging multi-latent space prior derived from different tracers,
the model captures multi-level feature representations, aiming to balance
computational efficiency and detail preservation. The texture masks, serving as
conditional guidance, help the model focus on salient structural patterns,
thereby improving the extraction and utilization of fine-grained image
textures. When combined with the diffusion transformer backbone, this
conditioning mechanism contributes to more accurate and robust tracer
separation. To evaluate its effectiveness, the proposed MS-CDT is compared with
several advanced methods on two types of 3D PET datasets: brain and chest
scans. Experimental results indicate that MS-CDT achieved competitive
performance in terms of image quality and preservation of clinically relevant
information. Code is available at: https://github.com/yqx7150/MS-CDT.

</details>


### [273] [Robust Training with Data Augmentation for Medical Imaging Classification](https://arxiv.org/abs/2506.17133)
*Josué Martínez-Martínez,Olivia Brown,Mostafa Karami,Sheida Nabavi*

Main category: eess.IV

TL;DR: 提出了一种名为RTDA的鲁棒训练算法，用于提升医学图像分类模型对抗攻击和分布偏移的鲁棒性，并在多种成像技术中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在医学影像诊断中应用广泛，但易受对抗攻击和分布偏移影响，导致诊断可靠性下降。

Method: 提出RTDA算法，结合数据增强和鲁棒训练，与六种基线方法在三种医学影像技术上进行对比。

Result: RTDA在对抗攻击和分布偏移下表现出更强的鲁棒性，同时保持高准确率。

Conclusion: RTDA是一种有效的医学图像分类鲁棒性提升方法。

Abstract: Deep neural networks are increasingly being used to detect and diagnose
medical conditions using medical imaging. Despite their utility, these models
are highly vulnerable to adversarial attacks and distribution shifts, which can
affect diagnostic reliability and undermine trust among healthcare
professionals. In this study, we propose a robust training algorithm with data
augmentation (RTDA) to mitigate these vulnerabilities in medical image
classification. We benchmark classifier robustness against adversarial
perturbations and natural variations of RTDA and six competing baseline
techniques, including adversarial training and data augmentation approaches in
isolation and combination, using experimental data sets with three different
imaging technologies (mammograms, X-rays, and ultrasound). We demonstrate that
RTDA achieves superior robustness against adversarial attacks and improved
generalization performance in the presence of distribution shift in each image
classification task while maintaining high clean accuracy.

</details>


### [274] [MeDi: Metadata-Guided Diffusion Models for Mitigating Biases in Tumor Classification](https://arxiv.org/abs/2506.17140)
*David Jacob Drexlin,Jonas Dippel,Julius Hense,Niklas Prenißl,Grégoire Montavon,Frederick Klauschen,Klaus-Robert Müller*

Main category: eess.IV

TL;DR: 提出了一种名为MeDi的元数据引导生成扩散模型框架，用于增强代表性不足的亚群数据，以减少深度学习模型在临床实践中的偏见。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在组织学预测任务中表现优异，但在临床实践中因对染色、扫描仪、医院和人口统计等条件缺乏鲁棒性而受限，导致模型偏向于过代表亚群，产生偏见预测。

Method: 提出MeDi框架，通过元数据引导生成扩散模型，针对性地增强代表性不足的亚群数据，生成高质量合成数据以平衡训练数据。

Result: 实验表明，MeDi能生成高质量的组织病理学图像，提升生成图像的整体保真度，并在亚群偏移的数据集上改善下游分类器的性能。

Conclusion: MeDi是减少数据偏见的生成模型概念验证，为临床实践中的模型鲁棒性提供了新思路。

Abstract: Deep learning models have made significant advances in histological
prediction tasks in recent years. However, for adaptation in clinical practice,
their lack of robustness to varying conditions such as staining, scanner,
hospital, and demographics is still a limiting factor: if trained on
overrepresented subpopulations, models regularly struggle with less frequent
patterns, leading to shortcut learning and biased predictions. Large-scale
foundation models have not fully eliminated this issue. Therefore, we propose a
novel approach explicitly modeling such metadata into a Metadata-guided
generative Diffusion model framework (MeDi). MeDi allows for a targeted
augmentation of underrepresented subpopulations with synthetic data, which
balances limited training data and mitigates biases in downstream models. We
experimentally show that MeDi generates high-quality histopathology images for
unseen subpopulations in TCGA, boosts the overall fidelity of the generated
images, and enables improvements in performance for downstream classifiers on
datasets with subpopulation shifts. Our work is a proof-of-concept towards
better mitigating data biases with generative models.

</details>


### [275] [Proportional Sensitivity in Generative Adversarial Network (GAN)-Augmented Brain Tumor Classification Using Convolutional Neural Network](https://arxiv.org/abs/2506.17165)
*Mahin Montasir Afif,Abdullah Al Noman,K. M. Tahsin Kabir,Md. Mortuza Ahmmed,Md. Mostafizur Rahman,Mufti Mahmud,Md. Ashraful Babu*

Main category: eess.IV

TL;DR: 研究探讨了GAN生成的脑肿瘤MRI图像与真实图像不同比例混合对CNN分类性能的影响，发现少量GAN数据能显著提升模型性能，但过多会降低效果。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像数据稀缺问题，探索GAN生成数据在增强数据集中的作用。

Method: 使用DCGAN生成合成图像，与真实图像按不同比例混合训练CNN，并在真实测试集上评估性能。

Result: 少量GAN数据（如100张）显著提升模型性能（准确率95.2%），但过多会降低效果。

Conclusion: GAN生成数据可有效扩充有限数据集，但需控制比例以避免泛化能力下降。

Abstract: Generative Adversarial Networks (GAN) have shown potential in expanding
limited medical imaging datasets. This study explores how different ratios of
GAN-generated and real brain tumor MRI images impact the performance of a CNN
in classifying healthy vs. tumorous scans. A DCGAN was used to create synthetic
images which were mixed with real ones at various ratios to train a custom CNN.
The CNN was then evaluated on a separate real-world test set. Our results
indicate that the model maintains high sensitivity and precision in tumor
classification, even when trained predominantly on synthetic data. When only a
small portion of GAN data was added, such as 900 real images and 100 GAN
images, the model achieved excellent performance, with test accuracy reaching
95.2%, and precision, recall, and F1-score all exceeding 95%. However, as the
proportion of GAN images increased further, performance gradually declined.
This study suggests that while GANs are useful for augmenting limited datasets
especially when real data is scarce, too much synthetic data can introduce
artifacts that affect the model's ability to generalize to real world cases.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [276] [Microcanonical simulated annealing: Massively parallel Monte Carlo simulations with sporadic random-number generation](https://arxiv.org/abs/2506.16240)
*M. Bernaschi,L. A. Fernandez,I. González-Adalid Pemartín,E. Marinari,V. Martin-Mayor,G. Parisi,F. Ricci-Tersenghi,J. J. Ruiz-Lorenzo,D. Yllanes*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种通用微正则模拟退火（mic.SA）方法，显著减少蒙特卡洛模拟中对随机数的依赖，适用于大规模并行计算，并在三维伊辛自旋玻璃模型中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 蒙特卡洛模拟在复杂系统研究中广泛应用，但其对随机数的高需求成为计算瓶颈，尤其是在高性能硬件上。

Method: 开发了mic.SA算法，减少随机数生成的计算负担，并通过GPU与Janus II超级计算机的标准模拟结果对比验证。

Result: 在可达到热平衡的情况下，mic.SA与标准模拟结果一致；非平衡动力学通过简单时间重标定即可匹配标准模拟。

Conclusion: mic.SA方法有效解决了随机数依赖问题，适用于大规模并行计算，为复杂系统模拟提供了高效工具。

Abstract: Numerical simulations of models and theories that describe complex
experimental systems $\unicode{x2014}$in fields like high-energy and
condensed-matter physics$\unicode{x2014}$ are becoming increasingly important.
Examples include lattice gauge theories, which can describe, among others,
quantum chromodynamics (the Standard Model description of strong interactions
between elementary particles), and spin-glass systems. Beyond fundamental
research, these computational methods also find practical applications, among
many others, in optimization, finance, and complex biological problems.
However, Monte Carlo simulations, an important subcategory of these methods,
are plagued by a major drawback: they are extremely greedy for (pseudo) random
numbers. The total fraction of computer time dedicated to random-number
generation increases as the hardware grows more sophisticated, and can get
prohibitive for special-purpose computing platforms. We propose here a
general-purpose microcanonical simulated annealing (mic.SA) formalism that
dramatically reduces such a burden. The algorithm is fully adapted to a
massively parallel computation, as we show in the particularly demanding
benchmark of the three-dimensional Ising spin glass. We carry out very
stringent numerical tests of the new algorithm by comparing our results,
obtained on GPUs, with high-precision standard (i.e., random-number-greedy)
simulations performed on the Janus II custom-built supercomputer. In those
cases where thermal equilibrium is reachable (i.e., in the paramagnetic phase),
both simulations reach compatible values. More significantly, barring
short-time corrections, a simple time rescaling suffices to map the mic.SA
off-equilibrium dynamics onto the results obtained with standard simulations.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [277] [Unpacking Generative AI in Education: Computational Modeling of Teacher and Student Perspectives in Social Media Discourse](https://arxiv.org/abs/2506.16412)
*Paulina DeVito,Akhil Vallala,Sean Mcmahon,Yaroslav Hinda,Benjamin Thaw,Hanqi Zhuang,Hari Kalva*

Main category: cs.SI

TL;DR: 该研究分析了社交媒体数据，探讨了学生和教育工作者对生成式AI（GAI）在教育中的看法，提出了一个基于LLM的模块化框架，并在情感分析、主题建模和作者分类任务中表现优于传统NLP模型。


<details>
  <summary>Details</summary>
Motivation: 随着GAI在教育中的快速普及，了解学生和教育工作者的观点至关重要，以指导政策制定和技术整合。

Method: 研究使用Reddit数据（1,199篇帖子和13,959条评论），应用情感分析、主题建模和作者分类，并提出了基于GPT-4o的模块化框架。

Result: GPT-4o框架在所有任务中表现优异（如情感分析准确率达90.6%），揭示了12个潜在主题，学生和教师对GAI的看法存在显著差异。

Conclusion: 研究表明需要更清晰的政策、透明的GAI整合实践以及对教育者和学生的支持机制，同时展示了LLM框架在分析在线社区话语中的潜力。

Abstract: Generative AI (GAI) technologies are quickly reshaping the educational
landscape. As adoption accelerates, understanding how students and educators
perceive these tools is essential. This study presents one of the most
comprehensive analyses to date of stakeholder discourse dynamics on GAI in
education using social media data. Our dataset includes 1,199 Reddit posts and
13,959 corresponding top-level comments. We apply sentiment analysis, topic
modeling, and author classification. To support this, we propose and validate a
modular framework that leverages prompt-based large language models (LLMs) for
analysis of online social discourse, and we evaluate this framework against
classical natural language processing (NLP) models. Our GPT-4o pipeline
consistently outperforms prior approaches across all tasks. For example, it
achieved 90.6% accuracy in sentiment analysis against gold-standard human
annotations. Topic extraction uncovered 12 latent topics in the public
discourse with varying sentiment and author distributions. Teachers and
students convey optimism about GAI's potential for personalized learning and
productivity in higher education. However, key differences emerged: students
often voice distress over false accusations of cheating by AI detectors, while
teachers generally express concern about job security, academic integrity, and
institutional pressures to adopt GAI tools. These contrasting perspectives
highlight the tension between innovation and oversight in GAI-enabled learning
environments. Our findings suggest a need for clearer institutional policies,
more transparent GAI integration practices, and support mechanisms for both
educators and students. More broadly, this study demonstrates the potential of
LLM-based frameworks for modeling stakeholder discourse within online
communities.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [278] [GratNet: A Photorealistic Neural Shader for Diffractive Surfaces](https://arxiv.org/abs/2506.15815)
*Narayan Kandel,Daljit Singh J. S. Dhillon*

Main category: cs.GR

TL;DR: 本文提出了一种基于多层感知机（MLP）的数据驱动方法，用于高效且高精度地渲染衍射表面，显著减少了数据依赖性和内存占用。


<details>
  <summary>Details</summary>
Motivation: 当前的结构着色模型依赖密集的预处理数据，缺乏对隐式神经表示的全面研究。本文旨在解决这一问题。

Method: 采用MLP方法，从数据压缩角度设计训练和建模方法，避免过拟合并具有鲁棒的重采样行为。

Result: 通过PSNR、SSIM和FLIP评估，方法能高质量重建真实数据，内存占用减少两个数量级。

Conclusion: 该方法在保持主观质量的同时，显著提升了性能，适用于衍射表面的高效渲染。

Abstract: Structural coloration is commonly modeled using wave optics for reliable and
photorealistic rendering of natural, quasi-periodic and complex nanostructures.
Such models often rely on dense, preliminary or preprocessed data to accurately
capture the nuanced variations in diffractive surface reflectances. This heavy
data dependency warrants implicit neural representation which has not been
addressed comprehensively in the current literature. In this paper, we present
a multi-layer perceptron (MLP) based method for data-driven rendering of
diffractive surfaces with high accuracy and efficiency. We primarily approach
this problem from a data compression perspective to devise a nuanced training
and modeling method which is attuned to the domain and range characteristics of
diffractive reflectance datasets. Importantly, our approach avoids over-fitting
and has robust resampling behavior. Using Peak-Signal-to-Noise (PSNR),
Structural Similarity Index Measure (SSIM) and a flipping difference evaluator
(FLIP) as evaluation metrics, we demonstrate the high-quality reconstruction of
the ground-truth. In comparison to a recent state-of-the-art offline,
wave-optical, forward modeling approach, our method reproduces subjectively
similar results with significant performance gains. We reduce the memory
footprint of the raw datasets by two orders of magnitude in general. Lastly, we
depict the working of our method with actual surface renderings.

</details>


### [279] [VEIGAR: View-consistent Explicit Inpainting and Geometry Alignment for 3D object Removal](https://arxiv.org/abs/2506.15821)
*Pham Khai Nguyen Do,Bao Nguyen Tran,Nam Nguyen,Duc Dung Nguyen*

Main category: cs.GR

TL;DR: VEIGAR是一种高效的新视角合成框架，无需初始3D重建阶段，通过轻量级基础模型和尺度不变深度损失监督策略，显著提升了重建质量和跨视角一致性，同时大幅减少训练时间。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖初始3D重建阶段，计算开销大且重建质量不佳，因此需要一种更高效且性能优越的解决方案。

Method: VEIGAR采用轻量级基础模型在像素空间显式对齐先验，并引入尺度不变深度损失监督策略，避免传统单目深度正则化中的尺度调整操作。

Result: VEIGAR在重建质量和跨视角一致性上达到新标杆，训练时间减少三倍。

Conclusion: VEIGAR在效率和效果上取得了显著平衡，为NVS和3D生成任务提供了更优的解决方案。

Abstract: Recent advances in Novel View Synthesis (NVS) and 3D generation have
significantly improved editing tasks, with a primary emphasis on maintaining
cross-view consistency throughout the generative process. Contemporary methods
typically address this challenge using a dual-strategy framework: performing
consistent 2D inpainting across all views guided by embedded priors either
explicitly in pixel space or implicitly in latent space; and conducting 3D
reconstruction with additional consistency guidance. Previous strategies, in
particular, often require an initial 3D reconstruction phase to establish
geometric structure, introducing considerable computational overhead. Even with
the added cost, the resulting reconstruction quality often remains suboptimal.
In this paper, we present VEIGAR, a computationally efficient framework that
outperforms existing methods without relying on an initial reconstruction
phase. VEIGAR leverages a lightweight foundation model to reliably align priors
explicitly in the pixel space. In addition, we introduce a novel supervision
strategy based on scale-invariant depth loss, which removes the need for
traditional scale-and-shift operations in monocular depth regularization.
Through extensive experimentation, VEIGAR establishes a new state-of-the-art
benchmark in reconstruction quality and cross-view consistency, while achieving
a threefold reduction in training time compared to the fastest existing method,
highlighting its superior balance of efficiency and effectiveness.

</details>


### [280] [FlatCAD: Fast Curvature Regularization of Neural SDFs for CAD Models](https://arxiv.org/abs/2506.16627)
*Haotian Yin,Aleksander Plocharski,Michal Jan Wlodarczyk,Mikolaj Kida,Przemyslaw Musialski*

Main category: cs.GR

TL;DR: 提出了一种新的曲率代理方法，用于神经符号距离场（SDF）的几何学习，避免了计算完整Hessian矩阵的高成本。


<details>
  <summary>Details</summary>
Motivation: 高斯曲率惩罚需要完整的Hessian评估和二阶自动微分，这在内存和运行时成本高昂。

Method: 提出了两种曲率代理实现：(i) 有限差分代理，用四个前向SDF评估和一个一阶梯度替换Hessian条目；(ii) 自动微分代理，通过一个Hessian-向量积计算混合导数，避免显式组装完整Hessian矩阵。

Result: 在ABC基准测试中，代理方法在重建保真度上达到或超过基于Hessian的基线，同时将GPU内存使用和运行时间减少一半。

Conclusion: 该方法为工程级形状重建提供了一种实用且可扩展的曲率感知SDF学习路径。

Abstract: Neural signed-distance fields (SDFs) have become a versatile backbone for
geometric learning, yet enforcing developable, CAD-style behavior still hinges
on Gaussian curvature penalties that require full Hessian evaluation and
second-order automatic differentiation, both of which are costly in memory and
runtime. We present a curvature proxy that regularizes only the mixed
second-order term (Weingarten term), allowing the two principal curvatures to
adapt freely to data while suppressing unwanted warp. Two complementary
instantiations realize this idea: (i) a finite-difference proxy that replaces
each Hessian entry with four forward SDF evaluations and a single first-order
gradient, and (ii) an autodiff proxy that computes the same mixed derivative
via one Hessian-vector product, sidestepping explicit full Hessian assembly and
remaining faster in practice. Both variants converge to the exact mixed second
derivative, thus preserving the intended geometric bias without incurring full
second-order graphs. On the ABC benchmarks, the proxies match or exceed the
reconstruction fidelity of Hessian-based baselines while reducing GPU memory
use and wall-clock time by a factor of two. Because the method is drop-in and
framework-agnostic, it opens a practical path toward scalable, curvature-aware
SDF learning for engineering-grade shape reconstruction.

</details>


### [281] [Beyond Blur: A Fluid Perspective on Generative Diffusion Models](https://arxiv.org/abs/2506.16827)
*Grzegorz Gruszczynski,Michal Jan Wlodarczyk,Jakub J Meixner,Przemyslaw Musialski*

Main category: cs.GR

TL;DR: 提出了一种基于PDE的图像生成新方法，结合了流体动力学和深度学习，通过可逆的PDE过程生成高质量图像。


<details>
  <summary>Details</summary>
Motivation: 现有PDE方法在图像生成中存在局限性，希望通过结合流体动力学理论（如Peclet和Fourier数）和深度学习，提出更通用的框架。

Method: 使用GPU加速的Lattice Boltzmann求解器实现PDE数值模拟，结合随机速度场模拟湍流，并通过神经网络学习逆PDE过程。

Result: 该方法能生成多样且高质量的图像，同时保持色彩一致性，并证明了其通用性（涵盖现有PDE方法）。

Conclusion: 该工作为基于PDE的图像生成提供了新视角，结合了流体动力学和深度学习，展示了物理启发的图像生成潜力。

Abstract: We propose a novel PDE-driven corruption process for generative image
synthesis based on advection-diffusion processes which generalizes existing
PDE-based approaches. Our forward pass formulates image corruption via a
physically motivated PDE that couples directional advection with isotropic
diffusion and Gaussian noise, controlled by dimensionless numbers (Peclet,
Fourier). We implement this PDE numerically through a GPU-accelerated custom
Lattice Boltzmann solver for fast evaluation. To induce realistic turbulence,
we generate stochastic velocity fields that introduce coherent motion and
capture multi-scale mixing. In the generative process, a neural network learns
to reverse the advection-diffusion operator thus constituting a novel
generative model. We discuss how previous methods emerge as specific cases of
our operator, demonstrating that our framework generalizes prior PDE-based
corruption techniques. We illustrate how advection improves the diversity and
quality of the generated images while keeping the overall color palette
unaffected. This work bridges fluid dynamics, dimensionless PDE theory, and
deep generative modeling, offering a fresh perspective on physically informed
image corruption processes for diffusion-based synthesis.

</details>


### [282] [DreamCube: 3D Panorama Generation via Multi-plane Synchronization](https://arxiv.org/abs/2506.17206)
*Yukun Huang,Yanning Zhou,Jianan Wang,Kaiyi Huang,Xihui Liu*

Main category: cs.GR

TL;DR: DreamCube通过多平面同步技术扩展2D基础模型能力，实现高质量3D全景生成。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法因3D全景与2D单视图不兼容导致的局限性。

Method: 采用多平面同步技术，设计DreamCube多平面RGB-D扩散模型。

Result: 在全景图像生成、深度估计和3D场景生成中表现优异。

Conclusion: DreamCube有效利用2D基础模型先验，实现多样化外观和准确几何的3D全景生成。

Abstract: 3D panorama synthesis is a promising yet challenging task that demands
high-quality and diverse visual appearance and geometry of the generated
omnidirectional content. Existing methods leverage rich image priors from
pre-trained 2D foundation models to circumvent the scarcity of 3D panoramic
data, but the incompatibility between 3D panoramas and 2D single views limits
their effectiveness. In this work, we demonstrate that by applying multi-plane
synchronization to the operators from 2D foundation models, their capabilities
can be seamlessly extended to the omnidirectional domain. Based on this design,
we further introduce DreamCube, a multi-plane RGB-D diffusion model for 3D
panorama generation, which maximizes the reuse of 2D foundation model priors to
achieve diverse appearances and accurate geometry while maintaining multi-view
consistency. Extensive experiments demonstrate the effectiveness of our
approach in panoramic image generation, panoramic depth estimation, and 3D
scene generation.

</details>


<div id='cs.CG'></div>

# cs.CG [[Back]](#toc)

### [283] [Wavelet-based Global Orientation and Surface Reconstruction for Point Clouds](https://arxiv.org/abs/2506.16299)
*Yueji Ma,Yanzun Meng,Dong Xiao,Zuoqiang Shi,Bin Wang*

Main category: cs.CG

TL;DR: 提出了一种基于小波的方法，用于处理无定向点云的重建问题，通过改进核函数和构建无散度函数场，显著提升了稀疏点云的重建效果和速度。


<details>
  <summary>Details</summary>
Motivation: 传统小波重建方法仅适用于定向点云，而现有改进方法在稀疏点云上表现不佳，因此需要一种更高效、稳定的解决方案。

Method: 利用小波的紧支撑性和正交性，通过改进核函数平滑表面不连续性，并构建无散度函数场作为额外约束，加速计算。

Result: 实验表明，该方法在稀疏点云的定向和重建任务中达到最优性能，且在CPU上高效运行。

Conclusion: 该方法显著提升了无定向稀疏点云的重建效果和计算效率，具有实际应用价值。

Abstract: Unoriented surface reconstruction is an important task in computer graphics
and has extensive applications. Based on the compact support of wavelet and
orthogonality properties, classic wavelet surface reconstruction achieves good
and fast reconstruction. However, this method can only handle oriented points.
Despite some improved attempts for unoriented points, such as iWSR, these
methods perform poorly on sparse point clouds. To address these shortcomings,
we propose a wavelet-based method to represent the mollified indicator function
and complete both the orientation and surface reconstruction tasks. We use the
modifying kernel function to smoothen out discontinuities on the surface,
aligning with the continuity of the wavelet basis function. During the
calculation of coefficient, we fully utilize the properties of the
convolutional kernel function to shift the modifying computation onto wavelet
basis to accelerate. In addition, we propose a novel method for constructing
the divergence-free function field and using them to construct the additional
homogeneous constraints to improve the effectiveness and stability. Extensive
experiments demonstrate that our method achieves state-of-the-art performance
in both orientation and reconstruction for sparse models. We align the matrix
construction with the compact support property of wavelet basis functions to
further accelerate our method, resulting in efficient performance on CPU. Our
source codes will be released on GitHub.

</details>


<div id='q-bio.QM'></div>

# q-bio.QM [[Back]](#toc)

### [284] [Smartphone-integrated RPA-CRISPR-Cas12a Detection System with Microneedle Sampling for Point-of-Care Diagnosis of Potato Late Blight in Early Stage](https://arxiv.org/abs/2506.15728)
*Jiangnan Zhao,Hanbo Xu,Cifu Xu,Wenlong Yin,Laixin Luo,Gang Liu,Yan Wang*

Main category: q-bio.QM

TL;DR: 该研究开发了一种便携式RPA-CRISPR诊断系统，结合智能手机用于马铃薯晚疫病的早期检测，具有高灵敏度和特异性，适用于田间即时诊断。


<details>
  <summary>Details</summary>
Motivation: 传统植物病害检测方法（如PCR和LAMP）依赖昂贵且笨重的实验室设备，操作复杂，无法满足田间即时诊断需求。

Method: 采用PVA微针贴片快速提取植物叶片样本，建立RPA-CRISPR-Cas12a等温检测系统，结合智能手机进行荧光图像采集与分析。

Result: 系统对P. infestans的检测限为2 pg/uL，灵敏度与实验室设备相当，接种后第3天和第4天的检测率分别达到80%和100%。

Conclusion: 该系统突破了传统方法的设备限制，为田间植物病害的早期检测和控制提供了可行方案。

Abstract: Potato late blight, caused by the oomycete pathogen Phytophthora infestans,
is one of the most devastating diseases affecting potato crops in the history.
Although conventional detection methods of plant diseases such as PCR and LAMP
are highly sensitive and specific, they rely on bulky and expensive laboratory
equipment and involve complex operations, making them impracticable for
point-of care diagnosis in the field. Here in this study, we report a portable
RPA-CRISPR based diagnosis system for plant disease, integrating smartphone for
acquisition and analysis of fluorescent images. A polyvinyl alcohol (PVA)
microneedle patch was employed for sample extraction on the plant leaves within
one minute, the DNA extraction efficiency achieved 56 ug/mg, which is
approximately 3 times to the traditional CTAB methods (18 ug/mg). The system of
RPA-CRISPR-Cas12a isothermal assay was established to specifically target P.
infestans with no cross-reactivity observed against closely-related species (P.
sojae, P. capsici). The system demonstrated a detection limit of 2 pg/uL for P.
infestans genomic DNA, offering sensitivity comparable to that of benchtop
laboratory equipment. The system demonstrates the early-stage diagnosis
capability by achieving a approximately 80% and 100% detection rate on the
third and fourth day post-inoculation respectively, before visible symptoms
observed on the leaves. The smartphone-based "sample-to-result" system
decouples the limitations of traditional methods that rely heavily on
specialized equipment, offering a promising way for early-stage plant disease
detection and control in the field.

</details>


<div id='physics.ins-det'></div>

# physics.ins-det [[Back]](#toc)

### [285] [Bias Variation Compensation in Perimeter-Gated SPAD TRNGs](https://arxiv.org/abs/2506.15888)
*Md Sakibur Sajal,Hunter Guthrie,Marc Dandin*

Main category: physics.ins-det

TL;DR: 论文提出了一种基于64x64阵列的pgSPADs的随机数生成器，通过BV补偿技术解决了偏置变化问题，并在室温下实现了低偏置和高随机性。


<details>
  <summary>Details</summary>
Motivation: 传统硬件友好的去偏算法无法适应宽范围的偏置变化（BV），因此需要一种新的熵源和补偿技术。

Method: 使用64x64阵列的pgSPADs作为熵源，通过调节栅极电压补偿BV，并结合Von Neumann算法去偏。

Result: 在室温下实现了小于1%的BV，并通过了NIST的16项统计测试。

Conclusion: 该方法有效解决了BV问题，生成了高质量的随机二进制字符串。

Abstract: Random number generators that utilize arrays of entropy source elements
suffer from bias variation (BV). Despite the availability of efficient
debiasing algorithms, optimized implementations of hardware friendly options
depend on the bit bias in the raw bit streams and cannot accommodate a wide BV.
In this work, we present a 64 x 64 array of perimeter gated single photon
avalanche diodes (pgSPADs), fabricated in a 0.35 {\mu}m standard CMOS
technology, as a source of entropy to generate random binary strings with a BV
compensation technique. By applying proper gate voltages based on the devices'
native dark count rates, we demonstrate less than 1% BV for a raw-bit
generation rate of 2 kHz/pixel at room temperature. The raw bits were debiased
using the classical iterative Von Neumann's algorithm and the debiased bits
were found to pass all of the 16 tests from NIST's Statistical Test Suite.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [286] [DT-UFC: Universal Large Model Feature Coding via Peaky-to-Balanced Distribution Transformation](https://arxiv.org/abs/2506.16495)
*Changsheng Gao,Zijie Liu,Li Li,Dong Liu,Xiaoyan Sun,Weisi Lin*

Main category: cs.MM

TL;DR: 本文首次系统研究了通用特征编码在大模型中的应用，提出了一种非均匀、数据驱动的分布变换方法，显著提升了压缩效率和跨模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于不同大模型提取的特征分布差异大且不兼容，现有方法难以实现通用特征编码，本文旨在解决这一挑战。

Method: 提出了一种学习的峰值到平衡分布变换方法，将不同模型的特征分布对齐到一个共同的平衡目标空间。

Result: 在LLaMA3、DINOv2和SD3等多个模型和任务上的实验表明，该方法在压缩效率和跨模型泛化方面优于任务特定基线。

Conclusion: 本文的方法为通用特征编码提供了有效解决方案，未来研究将开源代码。

Abstract: Like image coding in visual data transmission, feature coding is essential
for the distributed deployment of large models by significantly reducing
transmission and storage overhead. However, prior studies have mostly targeted
task- or model-specific scenarios, leaving the challenge of universal feature
coding across diverse large models largely unaddressed. In this paper, we
present the first systematic study on universal feature coding for large
models. The key challenge lies in the inherently diverse and distributionally
incompatible nature of features extracted from different models. For example,
features from DINOv2 exhibit highly peaky, concentrated distributions, while
those from Stable Diffusion 3 (SD3) are more dispersed and uniform. This
distributional heterogeneity severely hampers both compression efficiency and
cross-model generalization. To address this, we propose a learned
peaky-to-balanced distribution transformation, which reshapes highly skewed
feature distributions into a common, balanced target space. This transformation
is non-uniform, data-driven, and plug-and-play, enabling effective alignment of
heterogeneous distributions without modifying downstream codecs. With this
alignment, a universal codec trained on the balanced target distribution can
effectively generalize to features from different models and tasks. We validate
our approach on three representative large models-LLaMA3, DINOv2, and
SD3-across multiple tasks and modalities. Extensive experiments show that our
method achieves notable improvements in both compression efficiency and
cross-model generalization over task-specific baselines. All source code will
be released for future research.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [287] [Sudoku: Decomposing DRAM Address Mapping into Component Functions](https://arxiv.org/abs/2506.15918)
*Minbok Wi,Seungmin Baek,Seonyong Park,Mattan Erez,Jung Ho Ahn*

Main category: cs.CR

TL;DR: 论文提出了一种基于时序的新方法，通过利用DRAM刷新间隔和连续访问延迟来推断地址映射的组件级功能，并开发了首个软件工具Sudoku，能够自动分解完整的DRAM地址映射。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法有效分解DRAM地址映射，限制了对其行为的理解及精确攻击（如RowHammer）的实现。

Method: 利用DRAM刷新间隔和连续访问延迟的时序技术，开发了软件工具Sudoku，自动分解地址映射为通道、rank、bank组、bank等功能，并识别行和列位。

Result: 成功验证了Sudoku在最新Intel和AMD处理器上的有效性，能够准确分解地址映射。

Conclusion: Sudoku为理解和利用DRAM地址映射提供了高效工具，填补了现有方法的不足。

Abstract: Decomposing DRAM address mappings into component-level functions is critical
for understanding memory behavior and enabling precise RowHammer attacks, yet
existing reverse-engineering methods fall short. We introduce novel
timing-based techniques leveraging DRAM refresh intervals and consecutive
access latencies to infer component-specific functions. Based on this, we
present Sudoku, the first software-based tool to automatically decompose full
DRAM address mappings into channel, rank, bank group, and bank functions while
identifying row and column bits. We validate Sudoku's effectiveness,
successfully decomposing mappings on recent Intel and AMD processors.

</details>


### [288] [Multi-use LLM Watermarking and the False Detection Problem](https://arxiv.org/abs/2506.15975)
*Zihao Fu,Chris Russell*

Main category: cs.CR

TL;DR: 论文提出双水印技术，同时嵌入检测和用户识别水印，显著减少误检并保持高检测精度。


<details>
  <summary>Details</summary>
Motivation: 解决现有数字水印技术中因同时用于检测和用户识别而导致的误检问题。

Method: 通过理论分析提出双水印技术，联合编码检测和识别水印。

Result: 实验验证了理论分析，双水印技术有效减少误检并保持高检测精度。

Conclusion: 双水印技术是解决数字水印误检问题的有效方法。

Abstract: Digital watermarking is a promising solution for mitigating some of the risks
arising from the misuse of automatically generated text. These approaches
either embed non-specific watermarks to allow for the detection of any text
generated by a particular sampler, or embed specific keys that allow the
identification of the LLM user. However, simultaneously using the same
embedding for both detection and user identification leads to a false detection
problem, whereby, as user capacity grows, unwatermarked text is increasingly
likely to be falsely detected as watermarked. Through theoretical analysis, we
identify the underlying causes of this phenomenon. Building on these insights,
we propose Dual Watermarking which jointly encodes detection and identification
watermarks into generated text, significantly reducing false positives while
maintaining high detection accuracy. Our experimental results validate our
theoretical findings and demonstrate the effectiveness of our approach.

</details>


### [289] [Probe before You Talk: Towards Black-box Defense against Backdoor Unalignment for Large Language Models](https://arxiv.org/abs/2506.16447)
*Biao Yi,Tiansheng Huang,Sishuo Chen,Tong Li,Zheli Liu,Zhixuan Chu,Yiming Li*

Main category: cs.CR

TL;DR: 论文提出BEAT方法，通过检测触发样本来防御LLMs中的后门攻击，解决了样本依赖性目标问题。


<details>
  <summary>Details</summary>
Motivation: 后门攻击对LLMs的安全对齐构成威胁，尤其是在黑盒LLMaaS环境中，攻击目标具有样本依赖性。

Method: BEAT通过测量输入与探针拼接前后输出分布的失真程度，识别触发样本。

Result: 实验验证了BEAT在多种后门攻击和LLMs（包括GPT-3.5-turbo）中的有效性和高效性。

Conclusion: BEAT不仅能防御后门攻击，还能有效应对越狱攻击，因其可视为“自然后门”。

Abstract: Backdoor unalignment attacks against Large Language Models (LLMs) enable the
stealthy compromise of safety alignment using a hidden trigger while evading
normal safety auditing. These attacks pose significant threats to the
applications of LLMs in the real-world Large Language Model as a Service
(LLMaaS) setting, where the deployed model is a fully black-box system that can
only interact through text. Furthermore, the sample-dependent nature of the
attack target exacerbates the threat. Instead of outputting a fixed label, the
backdoored LLM follows the semantics of any malicious command with the hidden
trigger, significantly expanding the target space. In this paper, we introduce
BEAT, a black-box defense that detects triggered samples during inference to
deactivate the backdoor. It is motivated by an intriguing observation (dubbed
the probe concatenate effect), where concatenated triggered samples
significantly reduce the refusal rate of the backdoored LLM towards a malicious
probe, while non-triggered samples have little effect. Specifically, BEAT
identifies whether an input is triggered by measuring the degree of distortion
in the output distribution of the probe before and after concatenation with the
input. Our method addresses the challenges of sample-dependent targets from an
opposite perspective. It captures the impact of the trigger on the refusal
signal (which is sample-independent) instead of sample-specific successful
attack behaviors. It overcomes black-box access limitations by using multiple
sampling to approximate the output distribution. Extensive experiments are
conducted on various backdoor attacks and LLMs (including the closed-source
GPT-3.5-turbo), verifying the effectiveness and efficiency of our defense.
Besides, we also preliminarily verify that BEAT can effectively defend against
popular jailbreak attacks, as they can be regarded as 'natural backdoors'.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [290] [Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU](https://arxiv.org/abs/2506.08911)
*Petar Jakuš,Hrvoje Džapo*

Main category: cs.HC

TL;DR: 本文介绍了一种在NXP MCXN947微控制器上实现的关键词检测系统，利用集成的NPU实现实时语音交互，通过MFCC特征提取和CNN分类器结合量化感知训练优化模型。


<details>
  <summary>Details</summary>
Motivation: 研究旨在在资源受限的设备上实现高效的实时语音交互，解决传统方法在嵌入式平台上性能不足的问题。

Method: 采用MFCC特征提取和CNN分类器，结合量化感知训练优化模型大小和性能。

Result: 实验结果显示，利用NPU相比仅用CPU实现了59倍的推理速度提升，模型大小为30.58 KB，准确率达97.06%。

Conclusion: 证明了在嵌入式平台上实现高效、低功耗语音接口的可行性。

Abstract: This paper presents a keyword spotting (KWS) system implemented on the NXP
MCXN947 microcontroller with an integrated Neural Processing Unit (NPU),
enabling real-time voice interaction on resource-constrained devices. The
system combines MFCC feature extraction with a CNN classifier, optimized using
Quantization Aware Training to reduce model size with minimal accuracy drop.
Experimental results demonstrate a 59x speedup in inference time when
leveraging the NPU compared to CPU-only execution, achieving 97.06% accuracy
with a model size of 30.58 KB, demonstrating the feasibility of efficient,
low-power voice interfaces on embedded platforms.

</details>


### [291] [Do We Talk to Robots Like Therapists, and Do They Respond Accordingly? Language Alignment in AI Emotional Support](https://arxiv.org/abs/2506.16473)
*Sophie Chiang,Guy Laban,Hatice Gunes*

Main category: cs.HC

TL;DR: 研究比较了机器人（QTrobot）与人类治疗师在情感支持对话中的相似性，发现90.88%的机器人对话主题可映射到人类治疗数据集，且语义上高度重叠。


<details>
  <summary>Details</summary>
Motivation: 探讨机器人情感支持对话与传统人类治疗对话的相似性，以评估其在心理健康干预中的潜力。

Method: 分析两个数据集（人类治疗对话与机器人对话），使用句子嵌入和K-means聚类评估主题对齐，并通过Transformer、Word2Vec和BERT嵌入比较语义。

Result: 机器人对话主题与人类治疗对话高度重叠，语义分析显示两者在主题和回应上相似。

Conclusion: 机器人支持对话与传统治疗对话有显著相似性，表明其在心理健康干预中的潜在应用价值。

Abstract: As conversational agents increasingly engage in emotionally supportive
dialogue, it is important to understand how closely their interactions resemble
those in traditional therapy settings. This study investigates whether the
concerns shared with a robot align with those shared in human-to-human (H2H)
therapy sessions, and whether robot responses semantically mirror those of
human therapists. We analyzed two datasets: one of interactions between users
and professional therapists (Hugging Face's NLP Mental Health Conversations),
and another involving supportive conversations with a social robot (QTrobot
from LuxAI) powered by a large language model (LLM, GPT-3.5). Using sentence
embeddings and K-means clustering, we assessed cross-agent thematic alignment
by applying a distance-based cluster-fitting method that evaluates whether
responses from one agent type map to clusters derived from the other, and
validated it using Euclidean distances. Results showed that 90.88% of robot
conversation disclosures could be mapped to clusters from the human therapy
dataset, suggesting shared topical structure. For matched clusters, we compared
the subjects as well as therapist and robot responses using Transformer,
Word2Vec, and BERT embeddings, revealing strong semantic overlap in subjects'
disclosures in both datasets, as well as in the responses given to similar
human disclosure themes across agent types (robot vs. human therapist). These
findings highlight both the parallels and boundaries of robot-led support
conversations and their potential for augmenting mental health interventions.

</details>
