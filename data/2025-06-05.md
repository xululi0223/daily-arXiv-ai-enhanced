<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 220]
- [cs.CV](#cs.CV) [Total: 232]
- [cs.DC](#cs.DC) [Total: 9]
- [eess.IV](#eess.IV) [Total: 42]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 2]
- [cs.HC](#cs.HC) [Total: 3]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.IR](#cs.IR) [Total: 2]
- [cs.AI](#cs.AI) [Total: 8]
- [cs.NI](#cs.NI) [Total: 1]
- [cs.LG](#cs.LG) [Total: 31]
- [physics.med-ph](#physics.med-ph) [Total: 4]
- [cs.MM](#cs.MM) [Total: 2]
- [cs.RO](#cs.RO) [Total: 4]
- [cs.GR](#cs.GR) [Total: 6]
- [eess.AS](#eess.AS) [Total: 4]
- [cs.SE](#cs.SE) [Total: 4]
- [eess.SY](#eess.SY) [Total: 2]
- [cs.DL](#cs.DL) [Total: 4]
- [physics.optics](#physics.optics) [Total: 2]
- [cs.DS](#cs.DS) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Evaluating Large Language Models for Zero-Shot Disease Labeling in CT Radiology Reports Across Organ Systems](https://arxiv.org/abs/2506.03259)
*Michael E. Garcia-Alcoser,Mobina GhojoghNejad,Fakrul Islam Tushar,David Kim,Kyle J. Lafata,Geoffrey D. Rubin,Joseph Y. Lo*

Main category: cs.CL

TL;DR: 该研究评估了轻量级开源大语言模型（LLMs）在自动化标注CT放射报告疾病方面的效果，发现其优于基于规则的方法，并能通过零样本提示泛化到不同器官系统。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在自动化标注CT报告疾病方面的有效性，并与传统规则方法（RBA）进行比较，以探索更灵活的临床解决方案。

Method: 回顾性分析了40,833份CT报告，测试了三种轻量级开源LLMs（零样本提示），并使用Cohen's Kappa和F1分数评估性能。

Result: Gemma-3 27B和Llama-3.1 8B表现最佳，分别在手动标注集和CT-RATE数据集上取得最高分，而RBA得分最低。

Conclusion: 轻量级LLMs在CT报告标注中优于规则方法，但二元标签无法完全捕捉报告的复杂性，LLMs提供了更灵活的临床解决方案。

Abstract: Purpose: This study aims to evaluate the effectiveness of large language
models (LLMs) in automating disease annotation of CT radiology reports. We
compare a rule-based algorithm (RBA), RadBERT, and three lightweight
open-weight LLMs for multi-disease labeling of chest, abdomen, and pelvis (CAP)
CT reports.
  Materials and Methods: This retrospective study analyzed 40,833 CT reports
from 29,540 patients, with 1,789 CAP reports manually annotated across three
organ systems. External validation was conducted using the CT-RATE dataset.
Three open-weight LLMs were tested with zero-shot prompting. Performance was
evaluated using Cohen's Kappa and micro/macro-averaged F1 scores.
  Results: In 12,197 Duke CAP reports from 8,854 patients, Llama-3.1 8B and
Gemma-3 27B showed the highest agreement ($\kappa$ median: 0.87). On the
manually annotated set, Gemma-3 27B achieved the top macro-F1 (0.82), followed
by Llama-3.1 8B (0.79), while the RBA scored lowest (0.64). On the CT-RATE
dataset (lungs/pleura only), Llama-3.1 8B performed best (0.91), with Gemma-3
27B close behind (0.89). Performance differences were mainly due to differing
labeling practices, especially for lung atelectasis.
  Conclusion: Lightweight LLMs outperform rule-based methods for CT report
annotation and generalize across organ systems with zero-shot prompting.
However, binary labels alone cannot capture the full nuance of report language.
LLMs can provide a flexible, efficient solution aligned with clinical judgment
and user needs.

</details>


### [2] [A conclusive remark on linguistic theorizing and language modeling](https://arxiv.org/abs/2506.03268)
*Cristiano Chesi*

Main category: cs.CL

TL;DR: 对目标论文的回复总结


<details>
  <summary>Details</summary>
Motivation: 总结和回应意大利语言学杂志中对目标论文的反馈

Method: 分析收到的回复内容

Result: 对回复内容进行综合评述

Conclusion: 提供对目标论文的进一步思考或建议

Abstract: This is the final remark on the replies received to my target paper in the
Italian Journal of Linguistics

</details>


### [3] [FailureSensorIQ: A Multi-Choice QA Dataset for Understanding Sensor Relationships and Failure Modes](https://arxiv.org/abs/2506.03278)
*Christodoulos Constantinides,Dhaval Patel,Shuxin Lin,Claudio Guerrero,Sunil Dagajirao Patil,Jayant Kalagnanam*

Main category: cs.CL

TL;DR: FailureSensorIQ是一个多选问答基准系统，用于评估大型语言模型在工业4.0复杂场景中的推理能力，通过多种分析方法揭示模型的局限性，并提供实际案例和开源工具。


<details>
  <summary>Details</summary>
Motivation: 传统QA基准无法全面评估LLMs在工业领域中的复杂推理能力，因此开发了专注于故障模式、传感器数据及其关系的系统。

Method: 采用扰动-不确定性-复杂性分析、专家评估、知识缺口分析等方法，评估了包括GPT-4在内的多个LLMs。

Result: 尽管部分闭源模型表现接近专家水平，但整体性能易受干扰和知识缺口影响。

Conclusion: FailureSensorIQ为工业领域提供了新的评估工具和特征选择方法，揭示了LLMs在复杂场景中的局限性。

Abstract: We introduce FailureSensorIQ, a novel Multi-Choice Question-Answering (MCQA)
benchmarking system designed to assess the ability of Large Language Models
(LLMs) to reason and understand complex, domain-specific scenarios in Industry
4.0. Unlike traditional QA benchmarks, our system focuses on multiple aspects
of reasoning through failure modes, sensor data, and the relationships between
them across various industrial assets. Through this work, we envision a
paradigm shift where modeling decisions are not only data-driven using
statistical tools like correlation analysis and significance tests, but also
domain-driven by specialized LLMs which can reason about the key contributors
and useful patterns that can be captured with feature engineering. We evaluate
the Industrial knowledge of over a dozen LLMs-including GPT-4, Llama, and
Mistral-on FailureSensorIQ from different lens using
Perturbation-Uncertainty-Complexity analysis, Expert Evaluation study,
Asset-Specific Knowledge Gap analysis, ReAct agent using external
knowledge-bases. Even though closed-source models with strong reasoning
capabilities approach expert-level performance, the comprehensive benchmark
reveals a significant drop in performance that is fragile to perturbations,
distractions, and inherent knowledge gaps in the models. We also provide a
real-world case study of how LLMs can drive the modeling decisions on 3
different failure prediction datasets related to various assets. We release:
(a) expert-curated MCQA for various industrial assets, (b) FailureSensorIQ
benchmark and Hugging Face leaderboard based on MCQA built from non-textual
data found in ISO documents, and (c) LLMFeatureSelector, an LLM-based feature
selection scikit-learn pipeline. The software is available at
https://github.com/IBM/FailureSensorIQ.

</details>


### [4] [HyperSteer: Activation Steering at Scale with Hypernetworks](https://arxiv.org/abs/2506.03292)
*Jiuding Sun,Sidharth Baskaran,Zhengxuan Wu,Michael Sklar,Christopher Potts,Atticus Geiger*

Main category: cs.CL

TL;DR: HyperSteer是一种基于超网络的架构，通过自然语言提示生成控制向量，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法中，无监督字典学习方法缺乏对单个向量效果的保证，而有监督方法需要大量数据和训练。HyperSteer旨在结合两者的优势。

Method: 使用超网络架构，根据自然语言提示和语言模型内部状态生成控制向量。

Result: HyperSteer在数千个提示下性能优于现有方法，甚至在未见过的提示上也表现良好。

Conclusion: HyperSteer在控制文本生成方面表现出色，性能接近基于提示的方法。

Abstract: Steering language models (LMs) by modifying internal activations is a popular
approach for controlling text generation. Unsupervised dictionary learning
methods, e.g., sparse autoencoders, can be scaled to produce many steering
vectors, but lack guarantees on the individual efficacy of each vector and
control over the coverage of relevant steering tasks. In contrast, supervised
methods for constructing steering vectors are targeted and effective, but
require more data collection and training for each additional steering vector
produced. In this work, we introduce HyperSteer, a family of hypernetwork-based
architectures which are trained end-to-end to generate steering vectors
conditioned on the natural language steering prompts and the internals of the
steered LM. In our evaluations, we show that scaling HyperSteer with thousands
of steering prompts exceeds the performance of state-of-the-art activation
steering methods, even on steering prompts never seen during training.
Moreover, HyperSteer performs on par with steering-via-prompting.

</details>


### [5] [Unleashing the Reasoning Potential of Pre-trained LLMs by Critique Fine-Tuning on One Problem](https://arxiv.org/abs/2506.03295)
*Yubo Wang,Ping Nie,Kai Zou,Lijun Wu,Wenhu Chen*

Main category: cs.CL

TL;DR: 通过Critique Fine-Tuning (CFT)方法，仅需单个问题和少量计算资源，即可显著提升大型语言模型（LLM）的推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习（RL）能提升LLM的推理能力，但其成本高且不稳定。因此，需要一种更高效的方法来释放LLM的推理潜力。

Method: CFT方法通过收集模型对单个问题的多样化解答，并利用教师模型提供详细批评，构建批评数据，对LLM进行微调。

Result: 实验显示，仅需5 GPU小时的训练，Qwen-Math-7B-CFT在数学和逻辑推理任务上分别提升15%和16%，效果媲美或超越RL，且计算资源减少20倍。

Conclusion: CFT是一种简单、通用且计算高效的方法，能够有效释放现代LLM的推理潜力。

Abstract: We have witnessed that strong LLMs like Qwen-Math, MiMo, and Phi-4 possess
immense reasoning potential inherited from the pre-training stage. With
reinforcement learning (RL), these models can improve dramatically on reasoning
tasks. Recent studies have shown that even RL on a single problem can unleash
these models' reasoning capabilities. However, RL is not only expensive but
also unstable. Even one-shot RL requires hundreds of GPU hours. This raises a
critical question: Is there a more efficient way to unleash the reasoning
potential of these powerful base LLMs? In this work, we demonstrate that
Critique Fine-Tuning (CFT) on only one problem can effectively unleash the
reasoning potential of LLMs. Our method constructs critique data by collecting
diverse model-generated solutions to a single problem and using teacher LLMs to
provide detailed critiques. We fine-tune Qwen and Llama family models, ranging
from 1.5B to 14B parameters, on the CFT data and observe significant
performance gains across diverse reasoning tasks. For example, with just 5 GPU
hours of training, Qwen-Math-7B-CFT show an average improvement of 15% on six
math benchmarks and 16% on three logic reasoning benchmarks. These results are
comparable to or even surpass the results from RL with 20x less compute.
Ablation studies reveal the robustness of one-shot CFT across different prompt
problems. These results highlight one-shot CFT as a simple, general, and
compute-efficient approach to unleashing the reasoning capabilities of modern
LLMs.

</details>


### [6] [From Instructions to ODRL Usage Policies: An Ontology Guided Approach](https://arxiv.org/abs/2506.03301)
*Daham M. Mustafa,Abhishek Nadgeri,Diego Collarana,Benedikt T. Arnold,Christoph Quix,Christoph Lange,Stefan Decker*

Main category: cs.CL

TL;DR: 利用GPT-4等大语言模型，从自然语言指令自动生成W3C ODRL使用策略，通过ODRL本体及其文档优化提示，生成知识图谱，准确率达91.95%。


<details>
  <summary>Details</summary>
Motivation: 研究假设认为，经过整理的现有本体文档能更好地指导策略生成，特别是在数据空间等分布式基础设施中。

Method: 使用ODRL本体及其文档作为提示核心，提出多种启发式方法，适配ODRL本体以指导端到端知识图谱构建。

Result: 在文化领域的12个不同复杂度用例中，知识图谱生成准确率高达91.95%。

Conclusion: 该方法在自动生成ODRL策略方面表现优异，适用于分布式数据交换场景。

Abstract: This study presents an approach that uses large language models such as GPT-4
to generate usage policies in the W3C Open Digital Rights Language ODRL
automatically from natural language instructions. Our approach uses the ODRL
ontology and its documentation as a central part of the prompt. Our research
hypothesis is that a curated version of existing ontology documentation will
better guide policy generation. We present various heuristics for adapting the
ODRL ontology and its documentation to guide an end-to-end KG construction
process. We evaluate our approach in the context of dataspaces, i.e.,
distributed infrastructures for trustworthy data exchange between multiple
participating organizations for the cultural domain. We created a benchmark
consisting of 12 use cases of varying complexity. Our evaluation shows
excellent results with up to 91.95% accuracy in the resulting knowledge graph.

</details>


### [7] [Hopscotch: Discovering and Skipping Redundancies in Language Models](https://arxiv.org/abs/2506.03303)
*Mustafa Eyceoz,Nikhil Shivakumar Nayak,Hao Wang,Ligong Han,Akash Srivastava*

Main category: cs.CL

TL;DR: Hopscotch是一种通过跳过贡献最小的注意力块并调整剩余层输出以保持性能的方法，适用于现代因果语言模型。


<details>
  <summary>Details</summary>
Motivation: 现代因果语言模型通过堆叠多个注意力块提升性能，但并非所有块对每个任务都必要。Hopscotch旨在高效识别并跳过冗余块，同时保持输出质量。

Method: Hopscotch联合优化跳过哪些块及如何缩放剩余层的输出，通过轻量级可训练缩放参数缓解因跳过块引起的隐藏状态分布偏移。

Result: 在Llama-3.1-8B和Qwen2.5-7B上，跳过四个注意力块后性能下降不到2%。

Conclusion: Hopscotch无需修改模型权重或预训练数据，兼容现有压缩技术，是一种简单有效的方法。

Abstract: Modern causal language models stack many attention blocks to improve
performance, but not all blocks are necessary for every task. We propose
Hopscotch, a simple yet effective method that identifies and skips attention
blocks with least contributions to a task and adapts to preserve output
quality. Hopscotch jointly optimizes which blocks to skip and how to scale the
outputs of the remaining layers. By introducing lightweight, trainable scaling
parameters to attention and MLP blocks, it mitigates distribution shifts in
hidden states caused by removing attention blocks. Hopscotch does not modify
model weights or require access to pretraining or instruction-tuning data, and
is compatible with existing model compression techniques. When applied to
$\texttt{Llama-3.1-8B}$ and $\texttt{Qwen2.5-7B}$, Hopscotch achieves less than
a 2% drop in performance even after skipping four attention blocks.

</details>


### [8] [The Reader is the Metric: How Textual Features and Reader Profiles Explain Conflicting Evaluations of AI Creative Writing](https://arxiv.org/abs/2506.03310)
*Guillermo Marco,Julio Gonzalo,Víctor Fresno*

Main category: cs.CL

TL;DR: 研究发现，AI与人类创作的文学文本评价差异源于读者偏好不同，而非文本本身质量。通过分析读者偏好，揭示了两种读者类型及其对文本特征的重视程度。


<details>
  <summary>Details</summary>
Motivation: 探讨AI与人类文学文本评价差异的原因，提出读者偏好是关键因素。

Method: 使用五个公共数据集，提取17种文本特征，建模读者偏好，分析偏好空间。

Result: 读者分为两类：注重表面特征的非专家和注重整体特征的专家。文本质量评价取决于特征与读者偏好的匹配。

Conclusion: 建议在创意文本生成领域采用考虑读者偏好的评价框架。

Abstract: Recent studies comparing AI-generated and human-authored literary texts have
produced conflicting results: some suggest AI already surpasses human quality,
while others argue it still falls short. We start from the hypothesis that such
divergences can be largely explained by genuine differences in how readers
interpret and value literature, rather than by an intrinsic quality of the
texts evaluated. Using five public datasets (1,471 stories, 101 annotators
including critics, students, and lay readers), we (i) extract 17 reference-less
textual features (e.g., coherence, emotional variance, average sentence
length...); (ii) model individual reader preferences, deriving feature
importance vectors that reflect their textual priorities; and (iii) analyze
these vectors in a shared "preference space". Reader vectors cluster into two
profiles: 'surface-focused readers' (mainly non-experts), who prioritize
readability and textual richness; and 'holistic readers' (mainly experts), who
value thematic development, rhetorical variety, and sentiment dynamics. Our
results quantitatively explain how measurements of literary quality are a
function of how text features align with each reader's preferences. These
findings advocate for reader-sensitive evaluation frameworks in the field of
creative text generation.

</details>


### [9] [Cross-Platform Violence Detection on Social Media: A Dataset and Analysis](https://arxiv.org/abs/2506.03312)
*Celia Chen,Scotty Beland,Ingo Burghardt,Jill Byczek,William J. Conway,Eric Cotugno,Sadaf Davre,Megan Fletcher,Rajesh Kumar Gnanasekaran,Kristin Hamilton,Marilyn Harbert,Jordan Heustis,Tanaya Jha,Emily Klein,Hayden Kramer,Alex Leitch,Jessica Perkins,Casi Sherman,Celia Sterrn,Logan Stevens,Rebecca Zarrella,Jennifer Golbeck*

Main category: cs.CL

TL;DR: 论文介绍了一个跨平台的暴力威胁数据集，并通过机器学习分析验证了其有效性，结果表明数据集在不同平台和编码标准下仍能实现高分类准确率。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的暴力威胁问题严重，高质量数据有助于研究和检测恶意内容。

Method: 引入了一个包含30,000条手动编码帖子的跨平台数据集，并通过机器学习分析评估其信号。

Result: 在不同平台和编码标准下，数据集仍能实现高分类准确率。

Conclusion: 研究结果对内容分类策略和理解跨平台暴力内容具有重要意义。

Abstract: Violent threats remain a significant problem across social media platforms.
Useful, high-quality data facilitates research into the understanding and
detection of malicious content, including violence. In this paper, we introduce
a cross-platform dataset of 30,000 posts hand-coded for violent threats and
sub-types of violence, including political and sexual violence. To evaluate the
signal present in this dataset, we perform a machine learning analysis with an
existing dataset of violent comments from YouTube. We find that, despite
originating from different platforms and using different coding criteria, we
achieve high classification accuracy both by training on one dataset and
testing on the other, and in a merged dataset condition. These results have
implications for content-classification strategies and for understanding
violent content across social media.

</details>


### [10] [Ask a Local: Detecting Hallucinations With Specialized Model Divergence](https://arxiv.org/abs/2506.03357)
*Aldan Creo,Héctor Cerezo-Costas,Pedro Alonso-Doval,Maximiliano Hormazábal-Lagos*

Main category: cs.CL

TL;DR: 论文提出了一种名为'Ask a Local'的新方法，通过利用专业模型对领域特定不准确信息的惊讶度来检测大语言模型中的幻觉现象。该方法在多语言环境中表现良好，无需额外训练或外部数据支持。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）生成的幻觉信息（即看似合理但事实错误的内容）是AI领域的一大挑战。为解决这一问题，作者提出了一种无需依赖外部数据或训练的多语言检测方法。

Method: 通过计算语言专业模型的困惑度分布差异，识别潜在的幻觉片段。该方法适用于多语言环境，无需额外调整或训练，且选择了计算效率高的模型。

Result: 在涵盖14种语言的人工标注问答数据集上，该方法表现一致，IoU分数约为0.3，Spearman相关性值相当。意大利语和加泰罗尼亚语表现尤为突出，IoU分数分别为0.42和0.38。

Conclusion: 'Ask a Local'方法在多语言幻觉检测中表现出色，无需语言特定调整，且具有可扩展性。作者公开了代码和架构以促进进一步研究。

Abstract: Hallucinations in large language models (LLMs) - instances where models
generate plausible but factually incorrect information - present a significant
challenge for AI.
  We introduce "Ask a Local", a novel hallucination detection method exploiting
the intuition that specialized models exhibit greater surprise when
encountering domain-specific inaccuracies. Our approach computes divergence
between perplexity distributions of language-specialized models to identify
potentially hallucinated spans. Our method is particularly well-suited for a
multilingual context, as it naturally scales to multiple languages without the
need for adaptation, relying on external data sources, or performing training.
Moreover, we select computationally efficient models, providing a scalable
solution that can be applied to a wide range of languages and domains.
  Our results on a human-annotated question-answer dataset spanning 14
languages demonstrate consistent performance across languages, with
Intersection-over-Union (IoU) scores around 0.3 and comparable Spearman
correlation values. Our model shows particularly strong performance on Italian
and Catalan, with IoU scores of 0.42 and 0.38, respectively, while maintaining
cross-lingual effectiveness without language-specific adaptations. We release
our code and architecture to facilitate further research in multilingual
hallucination detection.

</details>


### [11] [A Multimodal, Multilingual, and Multidimensional Pipeline for Fine-grained Crowdsourcing Earthquake Damage Evaluation](https://arxiv.org/abs/2506.03360)
*Zihui Ma,Lingyao Li,Juan Li,Wenyue Hua,Jingxiao Liu,Qingyuan Feng,Yuki Miura*

Main category: cs.CL

TL;DR: 该研究提出了一种多模态、多语言、多维度的3M管道，利用多模态大语言模型（MLLMs）评估灾害影响，结果显示MLLMs能有效整合图像-文本信号并与地震数据强相关。


<details>
  <summary>Details</summary>
Motivation: 快速、细粒度的灾害损害评估对应急响应至关重要，但传统方法受限于地面传感器和官方报告的延迟，而社交媒体提供了丰富的实时人类观察数据。

Method: 研究提出3M管道，评估了三种基础模型在两次大地震事件中的表现，采用宏观和微观分析。

Result: MLLMs能有效整合图像-文本信号，与地震数据强相关，但性能受语言、震中距离和输入模态影响。

Conclusion: MLLMs在灾害评估中具有潜力，为未来实时危机应用提供了基础。

Abstract: Rapid, fine-grained disaster damage assessment is essential for effective
emergency response, yet remains challenging due to limited ground sensors and
delays in official reporting. Social media provides a rich, real-time source of
human-centric observations, but its multimodal and unstructured nature presents
challenges for traditional analytical methods. In this study, we propose a
structured Multimodal, Multilingual, and Multidimensional (3M) pipeline that
leverages multimodal large language models (MLLMs) to assess disaster impacts.
We evaluate three foundation models across two major earthquake events using
both macro- and micro-level analyses. Results show that MLLMs effectively
integrate image-text signals and demonstrate a strong correlation with
ground-truth seismic data. However, performance varies with language,
epicentral distance, and input modality. This work highlights the potential of
MLLMs for disaster assessment and provides a foundation for future research in
applying MLLMs to real-time crisis contexts. The code and data are released at:
https://github.com/missa7481/EMNLP25_earthquake

</details>


### [12] [Trajectory Prediction Meets Large Language Models: A Survey](https://arxiv.org/abs/2506.03408)
*Yi Xu,Ruining Yang,Yitian Zhang,Yizhou Wang,Jianglin Lu,Mingyuan Zhang,Lili Su,Yun Fu*

Main category: cs.CL

TL;DR: 本文综述了将大语言模型（LLMs）应用于轨迹预测的最新研究，总结了五种主要方向，并分析了代表性方法、设计选择和开放挑战。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，研究者对其在轨迹预测中的应用产生了兴趣，希望通过其语义和推理能力提升自主系统的轨迹预测能力。

Method: 通过分类和综述，将相关研究分为五个方向：基于语言建模范式的轨迹预测、直接使用预训练语言模型的轨迹预测、语言引导的场景理解、语言驱动的数据生成以及基于语言的推理与可解释性。

Result: 总结了每种方向的代表性方法、核心设计选择和未解决的问题，为自然语言处理与轨迹预测的结合提供了统一视角。

Conclusion: 语言模型为轨迹预测带来了新的可能性，但仍面临挑战，未来研究需进一步探索其潜力。

Abstract: Recent advances in large language models (LLMs) have sparked growing interest
in integrating language-driven techniques into trajectory prediction. By
leveraging their semantic and reasoning capabilities, LLMs are reshaping how
autonomous systems perceive, model, and predict trajectories. This survey
provides a comprehensive overview of this emerging field, categorizing recent
work into five directions: (1) Trajectory prediction via language modeling
paradigms, (2) Direct trajectory prediction with pretrained language models,
(3) Language-guided scene understanding for trajectory prediction, (4)
Language-driven data generation for trajectory prediction, (5) Language-based
reasoning and interpretability for trajectory prediction. For each, we analyze
representative methods, highlight core design choices, and identify open
challenges. This survey bridges natural language processing and trajectory
prediction, offering a unified perspective on how language can enrich
trajectory prediction.

</details>


### [13] [DistRAG: Towards Distance-Based Spatial Reasoning in LLMs](https://arxiv.org/abs/2506.03424)
*Nicole R Schneider,Nandini Ramachandran,Kent O'Sullivan,Hanan Samet*

Main category: cs.CL

TL;DR: DistRAG是一种新方法，通过检索空间信息增强大语言模型（LLM）的空间推理能力，特别是距离问题。


<details>
  <summary>Details</summary>
Motivation: LLM在空间推理（如距离计算）方面能力有限，无法满足实际任务需求（如POI推荐、行程规划）。

Method: 将城市间的地理距离编码为图结构，并检索与问题相关的子图作为上下文。

Result: DistRAG使LLM能够回答原本无法解决的距离推理问题。

Conclusion: DistRAG为LLM提供了一种补充其语言知识的初步‘世界模型’，扩展了其应用范围。

Abstract: Many real world tasks where Large Language Models (LLMs) can be used require
spatial reasoning, like Point of Interest (POI) recommendation and itinerary
planning. However, on their own LLMs lack reliable spatial reasoning
capabilities, especially about distances. To address this problem, we develop a
novel approach, DistRAG, that enables an LLM to retrieve relevant spatial
information not explicitly learned during training. Our method encodes the
geodesic distances between cities and towns in a graph and retrieves a context
subgraph relevant to the question. Using this technique, our method enables an
LLM to answer distance-based reasoning questions that it otherwise cannot
answer. Given the vast array of possible places an LLM could be asked about,
DistRAG offers a flexible first step towards providing a rudimentary `world
model' to complement the linguistic knowledge held in LLMs.

</details>


### [14] [Time Course MechInterp: Analyzing the Evolution of Components and Knowledge in Large Language Models](https://arxiv.org/abs/2506.03434)
*Ahmad Dawar Hakimi,Ali Modarressi,Philipp Wicke,Hinrich Schütze*

Main category: cs.CL

TL;DR: 研究分析了OLMo-7B模型中事实知识表示的演变，发现模型组件从通用逐渐转向特定角色，注意力头变化最大，FFNs更稳定，任务复杂性影响知识获取。


<details>
  <summary>Details</summary>
Motivation: 理解大语言模型（LLMs）如何获取和存储事实知识，以提高其可解释性和可靠性。

Method: 通过跟踪OLMo-7B模型的注意力头和FFNs在预训练中的角色变化，将其分为四类角色并分析其稳定性与转变。

Result: 模型组件从通用转向特定角色，注意力头变化最大，FFNs更稳定；基于位置的关系比基于名称的关系更早收敛。

Conclusion: 研究揭示了LLMs中知识形成的机制，为模型优化提供了新视角。

Abstract: Understanding how large language models (LLMs) acquire and store factual
knowledge is crucial for enhancing their interpretability and reliability. In
this work, we analyze the evolution of factual knowledge representation in the
OLMo-7B model by tracking the roles of its attention heads and feed forward
networks (FFNs) over the course of pre-training. We classify these components
into four roles: general, entity, relation-answer, and fact-answer specific,
and examine their stability and transitions. Our results show that LLMs
initially depend on broad, general-purpose components, which later specialize
as training progresses. Once the model reliably predicts answers, some
components are repurposed, suggesting an adaptive learning process. Notably,
attention heads display the highest turnover. We also present evidence that
FFNs remain more stable throughout training. Furthermore, our probing
experiments reveal that location-based relations converge to high accuracy
earlier in training than name-based relations, highlighting how task complexity
shapes acquisition dynamics. These insights offer a mechanistic view of
knowledge formation in LLMs.

</details>


### [15] [Culture Matters in Toxic Language Detection in Persian](https://arxiv.org/abs/2506.03458)
*Zahra Bokaei,Walid Magdy,Bonnie Webber*

Main category: cs.CL

TL;DR: 本文比较了波斯语中检测有毒语言的不同方法，包括微调、数据增强、零样本和少样本学习以及跨语言迁移学习，并探讨了文化背景对迁移学习效果的影响。


<details>
  <summary>Details</summary>
Motivation: 有毒语言检测对创建更安全的在线环境和限制有害内容传播至关重要，而波斯语中的相关研究较少。

Method: 比较了多种方法，如微调、数据增强、零样本和少样本学习、跨语言迁移学习，并分析了文化背景对迁移学习的影响。

Result: 研究表明，与波斯语文化相似的语言在迁移学习中表现更好，而文化差异较大的语言改进较小。

Conclusion: 文化背景对有毒语言检测的迁移学习效果有显著影响，相似文化的语言表现更优。

Abstract: Toxic language detection is crucial for creating safer online environments
and limiting the spread of harmful content. While toxic language detection has
been under-explored in Persian, the current work compares different methods for
this task, including fine-tuning, data enrichment, zero-shot and few-shot
learning, and cross-lingual transfer learning. What is especially compelling is
the impact of cultural context on transfer learning for this task: We show that
the language of a country with cultural similarities to Persian yields better
results in transfer learning. Conversely, the improvement is lower when the
language comes from a culturally distinct country. Warning: This paper contains
examples of toxic language that may disturb some readers. These examples are
included for the purpose of research on toxic detection.

</details>


### [16] [Delta-KNN: Improving Demonstration Selection in In-Context Learning for Alzheimer's Disease Detection](https://arxiv.org/abs/2506.03476)
*Chuyuan Li,Raymond Li,Thalia S. Field,Giuseppe Carenini*

Main category: cs.CL

TL;DR: Delta-KNN方法通过动态选择示例提升LLMs在AD诊断中的性能，优于传统ICL方法。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）的早期干预需要分析语言异常，LLMs作为健康助手具有潜力，但传统ICL方法效果不佳。

Method: 提出Delta-KNN策略，结合delta评分和KNN检索器动态选择最优示例。

Result: 在三个开源LLMs上，Delta-KNN表现优于现有ICL基线，Llama-3.1模型达到新SOTA。

Conclusion: Delta-KNN显著提升AD诊断性能，为LLMs在医疗领域的应用提供新思路。

Abstract: Alzheimer's Disease (AD) is a progressive neurodegenerative disorder that
leads to dementia, and early intervention can greatly benefit from analyzing
linguistic abnormalities. In this work, we explore the potential of Large
Language Models (LLMs) as health assistants for AD diagnosis from
patient-generated text using in-context learning (ICL), where tasks are defined
through a few input-output examples. Empirical results reveal that conventional
ICL methods, such as similarity-based selection, perform poorly for AD
diagnosis, likely due to the inherent complexity of this task. To address this,
we introduce Delta-KNN, a novel demonstration selection strategy that enhances
ICL performance. Our method leverages a delta score to assess the relative
gains of each training example, coupled with a KNN-based retriever that
dynamically selects optimal "representatives" for a given input. Experiments on
two AD detection datasets across three open-source LLMs demonstrate that
Delta-KNN consistently outperforms existing ICL baselines. Notably, when using
the Llama-3.1 model, our approach achieves new state-of-the-art results,
surpassing even supervised classifiers.

</details>


### [17] [APT: Improving Specialist LLM Performance with Weakness Case Acquisition and Iterative Preference Training](https://arxiv.org/abs/2506.03483)
*Jun Rao,Zepeng Lin,Xuebo Liu,Xiaopeng Ke,Lian Lian,Dong Jin,Shengjun Cheng,Jun Yu,Min Zhang*

Main category: cs.CL

TL;DR: APT方法通过自生成弱点数据（错误案例和类似案例）进行迭代偏好训练，提升领域性能，同时保持模型的通用能力。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在领域微调中通用能力下降的问题，平衡领域性能与通用性。

Method: APT方法利用自生成的弱点数据（错误案例和类似案例）进行针对性训练，仅关注错误样本，减少对通用知识的干扰。

Result: 实验证明APT在LLama-2和Mistral-V0.3上保持通用能力，并在下游任务中表现优于现有方法。

Conclusion: APT是一种有效策略，可在不牺牲通用性的情况下提升领域性能。

Abstract: Large Language Models (LLMs) often require domain-specific fine-tuning to
address targeted tasks, which risks degrading their general capabilities.
Maintaining a balance between domain-specific enhancements and general model
utility is a key challenge. This paper proposes a novel approach named APT
(Weakness Case Acquisition and Iterative Preference Training) to enhance
domain-specific performance with self-generated dis-preferred weakness data
(bad cases and similar cases). APT uniquely focuses on training the model using
only those samples where errors occur, alongside a small, similar set of
samples retrieved for this purpose. This targeted training minimizes
interference with the model's existing knowledge base, effectively retaining
generic capabilities. Experimental results on the LLama-2 and Mistral-V0.3
models across various benchmarks demonstrate that APT ensures no reduction in
generic capacity and achieves superior performance on downstream tasks compared
to various existing methods. This validates our method as an effective strategy
for enhancing domain-specific capabilities without sacrificing the model's
broader applicability.

</details>


### [18] [Explainable AI: XAI-Guided Context-Aware Data Augmentation](https://arxiv.org/abs/2506.03484)
*Melkamu Abay Mersha,Mesay Gemeda Yigezu,Atnafu Lambebo Tonja,Hassan Shakil,Samer Iskander,Olga Kolesnikova,Jugal Kalita*

Main category: cs.CL

TL;DR: 本文提出了一种基于可解释AI（XAI）的上下文感知数据增强框架（XAI-Guided Context-Aware Data Augmentation），通过选择性保留任务相关特征并迭代优化增强数据，显著提升了低资源语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 标记数据稀缺是开发稳健且通用AI模型的主要挑战，尤其是低资源语言。传统数据增强方法存在噪声、语义漂移和过拟合等问题。

Method: 提出XAI引导的上下文感知数据增强框架，利用XAI技术修改非关键特征并保留任务相关特征，结合迭代反馈循环优化增强数据。

Result: 在Amharic数据集上，XAI-SR-BT和XAI-PR-BT分别将仇恨言论和情感分析任务的模型准确率提高了6.6%和8.1%，优于基线和其他增强方法。

Conclusion: 该研究为数据增强提供了更可控、可解释且上下文感知的解决方案，为利用XAI技术增强AI模型训练提供了新范式。

Abstract: Explainable AI (XAI) has emerged as a powerful tool for improving the
performance of AI models, going beyond providing model transparency and
interpretability. The scarcity of labeled data remains a fundamental challenge
in developing robust and generalizable AI models, particularly for low-resource
languages. Conventional data augmentation techniques introduce noise, cause
semantic drift, disrupt contextual coherence, lack control, and lead to
overfitting. To address these challenges, we propose XAI-Guided Context-Aware
Data Augmentation. This novel framework leverages XAI techniques to modify less
critical features while selectively preserving most task-relevant features. Our
approach integrates an iterative feedback loop, which refines augmented data
over multiple augmentation cycles based on explainability-driven insights and
the model performance gain. Our experimental results demonstrate that XAI-SR-BT
and XAI-PR-BT improve the accuracy of models on hate speech and sentiment
analysis tasks by 6.6% and 8.1%, respectively, compared to the baseline, using
the Amharic dataset with the XLM-R model. XAI-SR-BT and XAI-PR-BT outperform
existing augmentation techniques by 4.8% and 5%, respectively, on the same
dataset and model. Overall, XAI-SR-BT and XAI-PR-BT consistently outperform
both baseline and conventional augmentation techniques across all tasks and
models. This study provides a more controlled, interpretable, and context-aware
solution to data augmentation, addressing critical limitations of existing
augmentation techniques and offering a new paradigm shift for leveraging XAI
techniques to enhance AI model training.

</details>


### [19] [EpiCoDe: Boosting Model Performance Beyond Training with Extrapolation and Contrastive Decoding](https://arxiv.org/abs/2506.03489)
*Mingxu Tao,Jie Hu,Mingchuan Yang,Yunhuai Liu,Dongyan Zhao,Yansong Feng*

Main category: cs.CL

TL;DR: EpiCoDe是一种新方法，通过模型外推和对比解码提升数据稀缺场景下的LLM性能，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 高成本标注数据限制了LLM在下游任务中的能力，需解决数据稀缺问题。

Method: 结合模型外推和对比解码，通过比较外推模型与原模型的logit分数减少预测错误。

Result: 在四个LLM上的三个任务中，EpiCoDe显著优于现有方法。

Conclusion: EpiCoDe有效提升数据稀缺场景下的性能，并提供了理论框架解释其机制。

Abstract: The remarkable performance of Large language models (LLMs) relies heavily on
the availability of abundant high-quality training data. However, the high cost
of acquiring annotated data often prevents models from obtaining capabilities
to tackle downstream tasks. In this paper, we introduce a novel method, EpiCoDe
that boosts model performance in data-scarcity scenarios without extra
training. We first employ model extrapolation to enhance a finetuned model with
its inferior version, and then adopt contrastive decoding to further reduce
predicted errors, by comparing the logit scores given by the extrapolated and
the vanilla finetuned model. Experiments across three tasks over four different
LLMs show that EpiCoDe consistently outperforms existing methods with
significant and robust improvement. We also propose a new theoretical framework
to reveal the mechanism behind contrastive decoding in data-scarcity scenarios,
which further helps us better understand the effectiveness of EpiCoDe.

</details>


### [20] [Beyond Memorization: A Rigorous Evaluation Framework for Medical Knowledge Editing](https://arxiv.org/abs/2506.03490)
*Shigeng Chen,Linhao Luo,Zhangchi Qiu,Yanan Cao,Carl Yang,Shirui Pan*

Main category: cs.CL

TL;DR: 论文提出了MedEditBench框架，用于评估知识编辑（KE）方法在医学领域的有效性，并发现现有方法仅能实现浅层记忆。作者提出SGR-Edit方法，通过模型自生成推理改进效果。


<details>
  <summary>Details</summary>
Motivation: 医学知识编辑（KE）在复杂医学领域的适用性尚未充分研究，需要解决知识内化和泛化问题。

Method: 提出MedEditBench框架，包括新的医学知识编辑基准和三种编辑范式，并开发SGR-Edit方法，利用模型自生成推理作为编辑目标。

Result: 现有KE方法仅能实现浅层记忆，SGR-Edit显著优于现有方法，并提供了医学知识定位和连续编辑影响的深入见解。

Conclusion: SGR-Edit为医学知识编辑提供了更优解决方案，并为实际应用提供了指导。

Abstract: Recently, knowledge editing (KE) has emerged as a promising approach to
update specific facts in Large Language Models (LLMs) without the need for full
retraining. Despite the effectiveness in general-domain benchmarks, their
applicability to complex medical domain remains largely unexplored. Medical
knowledge editing is particularly challenging, as it requires LLMs to
internalize the knowledge and generalize to unseen scenarios for effective and
interpretable decision-making. In this work, we propose a novel framework
called MedEditBench to rigorously evaluate the effectiveness of existing KE
methods in the medical domain. In MedEditBench, we introduce a new medical
knowledge editing benchmark as well as three different knowledge editing
paradigms, which are designed to assess the impact of different knowledge
sources for editing. Our findings indicate that current KE methods result in
only superficial memorization of the injected information, failing to
generalize to new scenarios. To overcome this limitation, we present
Self-Generated Rationale Editing (SGR-Edit), which utilizes model-derived
rationales as the target knowledge for editing, thereby uncovering the
underlying reasoning process and demonstrating significant improvements over
existing KE approaches. Additionally, we offer deeper insights into medical
knowledge editing, including the localization of medical knowledge in LLMs and
the impact of sequential editing on evolving knowledge. This could provide
practical guidance for implementing KE methods in real-world medical
applications.

</details>


### [21] [Measuring Human Involvement in AI-Generated Text: A Case Study on Academic Writing](https://arxiv.org/abs/2506.03501)
*Yuchen Guo,Zhicheng Dou,Huy H. Nguyen,Ching-Chun Chang,Saku Sugawara,Isao Echizen*

Main category: cs.CL

TL;DR: 论文提出了一种基于BERTScore和RoBERTa的方法，用于检测文本生成中的人类参与程度，解决了传统二元分类方法的不足。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的普及，人类与机器的协作变得复杂，传统二元分类方法无法准确检测人类参与程度。

Method: 使用BERTScore度量人类参与，并训练多任务RoBERTa回归器进行标记分类。

Result: 在模拟学术场景的连续数据集上，该方法表现优异（F1分数0.9423，回归均方误差0.004）。

Conclusion: 该方法能有效检测人类参与程度，并具有一定的跨模型泛化能力。

Abstract: Content creation has dramatically progressed with the rapid advancement of
large language models like ChatGPT and Claude. While this progress has greatly
enhanced various aspects of life and work, it has also negatively affected
certain areas of society. A recent survey revealed that nearly 30% of college
students use generative AI to help write academic papers and reports. Most
countermeasures treat the detection of AI-generated text as a binary
classification task and thus lack robustness. This approach overlooks human
involvement in the generation of content even though human-machine
collaboration is becoming mainstream. Besides generating entire texts, people
may use machines to complete or revise texts. Such human involvement varies
case by case, which makes binary classification a less than satisfactory
approach. We refer to this situation as participation detection obfuscation. We
propose using BERTScore as a metric to measure human involvement in the
generation process and a multi-task RoBERTa-based regressor trained on a token
classification task to address this problem. To evaluate the effectiveness of
this approach, we simulated academic-based scenarios and created a continuous
dataset reflecting various levels of human involvement. All of the existing
detectors we examined failed to detect the level of human involvement on this
dataset. Our method, however, succeeded (F1 score of 0.9423 and a regressor
mean squared error of 0.004). Moreover, it demonstrated some generalizability
across generative models. Our code is available at
https://github.com/gyc-nii/CAS-CS-and-dual-head-detector

</details>


### [22] [Accurate Sublayer Pruning for Large Language Models by Exploiting Latency and Tunability Information](https://arxiv.org/abs/2506.03510)
*Seungcheol Park,Sojin Lee,Jongjin Kim,Jinsik Lee,Hyunjik Jo,U Kang*

Main category: cs.CL

TL;DR: SPRINT是一种通过考虑延迟减少和子层可调性来精确剪枝大语言模型子层的方法，显著提升推理速度同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型推理速度慢，现有子层剪枝方法因忽略子层特性导致准确性不足。

Method: SPRINT结合延迟减少和子层可调性信息，迭代剪枝冗余子层并快速调整剩余子层参数。

Result: 实验显示SPRINT在零样本常识推理基准上准确率比现有方法高23.88%。

Conclusion: SPRINT实现了最佳的准确性与加速权衡，适用于大语言模型的高效推理。

Abstract: How can we accelerate large language models(LLMs) without sacrificing
accuracy? The slow inference speed of LLMs hinders us to benefit from their
remarkable performance in diverse applications. This is mainly because numerous
sublayers are stacked together in LLMs. Sublayer pruning compresses and
expedites LLMs via removing unnecessary sublayers. However, existing sublayer
pruning algorithms are limited in accuracy since they naively select sublayers
to prune, overlooking the different characteristics of each sublayer. In this
paper, we propose SPRINT (Sublayer PRuning wIth LateNcy and Tunability
Information), an accurate sublayer pruning method for LLMs. SPRINT accurately
selects a target sublayer to prune by considering 1) the amount of latency
reduction after pruning and 2) the tunability of sublayers. SPRINT iteratively
prunes redundant sublayers and swiftly tunes the parameters of remaining
sublayers. Experiments show that SPRINT achieves the best accuracy-speedup
trade-off, exhibiting up to 23.88%p higher accuracy on zero-shot commonsense
reasoning benchmarks compared to existing pruning algorithms.

</details>


### [23] [An Efficient Task-Oriented Dialogue Policy: Evolutionary Reinforcement Learning Injected by Elite Individuals](https://arxiv.org/abs/2506.03519)
*Yangyang Zhao,Ben Niu,Libo Qin,Shihan Wang*

Main category: cs.CL

TL;DR: 论文提出了一种结合进化算法（EA）和深度强化学习（DRL）的方法，通过精英个体注入机制（EII）优化任务导向对话系统的探索与利用平衡。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在任务导向对话系统中难以平衡探索与利用，导致局部最优或收敛性差。进化算法能有效探索解空间，但直接结合面临语言灵活性和进化时间长的问题。

Method: 结合EA的全局搜索能力和DRL的局部优化，提出EII机制，自适应引入精英个体提升搜索效率。

Result: 在四个数据集上验证，显著提升探索与利用的平衡和性能，EII机制有效减少探索时间。

Conclusion: 该方法成功实现了EA与DRL的高效结合，优化了任务导向对话策略。

Abstract: Deep Reinforcement Learning (DRL) is widely used in task-oriented dialogue
systems to optimize dialogue policy, but it struggles to balance exploration
and exploitation due to the high dimensionality of state and action spaces.
This challenge often results in local optima or poor convergence. Evolutionary
Algorithms (EAs) have been proven to effectively explore the solution space of
neural networks by maintaining population diversity. Inspired by this, we
innovatively combine the global search capabilities of EA with the local
optimization of DRL to achieve a balance between exploration and exploitation.
Nevertheless, the inherent flexibility of natural language in dialogue tasks
complicates this direct integration, leading to prolonged evolutionary times.
Thus, we further propose an elite individual injection mechanism to enhance
EA's search efficiency by adaptively introducing best-performing individuals
into the population. Experiments across four datasets show that our approach
significantly improves the balance between exploration and exploitation,
boosting performance. Moreover, the effectiveness of the EII mechanism in
reducing exploration time has been demonstrated, achieving an efficient
integration of EA and DRL on task-oriented dialogue policy tasks.

</details>


### [24] [TokAlign: Efficient Vocabulary Adaptation via Token Alignment](https://arxiv.org/abs/2506.03523)
*Chong Li,Jiajun Zhang,Chengqing Zong*

Main category: cs.CL

TL;DR: TokAlign是一种高效的方法，通过从词共现角度替换LLM的词汇表，并在模型间传递词级知识，显著提升了多语言文本压缩率和词汇初始化效果。


<details>
  <summary>Details</summary>
Motivation: 在新领域或语言中，分词器的低效会拖慢LLM的训练和生成，词汇不匹配也阻碍了模型间的深度知识迁移。

Method: TokAlign通过学习词ID的一对一映射矩阵，将源词汇表对齐到目标词汇表，并逐步微调模型参数（如嵌入向量）。

Result: TokAlign将困惑度从3.4e²降至1.2e²，仅需5k步即可恢复原始模型性能，词级蒸馏比句子级蒸馏提升4.4%。

Conclusion: TokAlign在统一LLM词汇表后，显著提升了模型性能和知识迁移效率。

Abstract: Tokenization serves as a foundational step for Large Language Models (LLMs)
to process text. In new domains or languages, the inefficiency of the tokenizer
will slow down the training and generation of LLM. The mismatch in vocabulary
also hinders deep knowledge transfer between LLMs like token-level
distillation. To mitigate this gap, we propose an efficient method named
TokAlign to replace the vocabulary of LLM from the token co-occurrences view,
and further transfer the token-level knowledge between models. It first aligns
the source vocabulary to the target one by learning a one-to-one mapping matrix
for token IDs. Model parameters, including embeddings, are rearranged and
progressively fine-tuned for the new vocabulary. Our method significantly
improves multilingual text compression rates and vocabulary initialization for
LLMs, decreasing the perplexity from 3.4$\text{e}^2$ of strong baseline methods
to 1.2$\text{e}^2$ after initialization. Experimental results on models across
multiple parameter scales demonstrate the effectiveness and generalization of
TokAlign, which costs as few as 5k steps to restore the performance of the
vanilla model. After unifying vocabularies between LLMs, token-level
distillation can remarkably boost (+4.4% than sentence-level distillation) the
base model, costing only 235M tokens.

</details>


### [25] [Seed-Coder: Let the Code Model Curate Data for Itself](https://arxiv.org/abs/2506.03524)
*Yuyu Zhang,Jing Su,Yifan Sun,Chenguang Xi,Xia Xiao,Shen Zheng,Anxiang Zhang,Kaibo Liu,Daoguang Zan,Tao Sun,Jinhua Zhu,Shulin Xin,Dong Huang,Yetao Bai,Lixin Dong,Chao Li,Jianchong Chen,Hanzhi Zhou,Yifan Huang,Guanghan Ning,Xierui Song,Jiaze Chen,Siyao Liu,Kai Shen,Liang Xiang,Yonghui Wu*

Main category: cs.CL

TL;DR: Seed-Coder是一个开源LLM系列，通过模型中心的数据管道减少人工参与，提升代码预训练数据的质量和扩展性。


<details>
  <summary>Details</summary>
Motivation: 当前开源LLM依赖人工生成代码预训练数据，存在扩展性差、主观偏见和维护成本高的问题。

Method: 采用模型中心的数据管道，利用LLM评分和过滤代码数据；通过监督微调、偏好优化和LongCoT强化学习训练推理模型。

Result: Seed-Coder在相似规模的开源模型中表现最佳，甚至超越部分更大模型，在代码生成、完成、编辑、推理和软件工程任务中表现卓越。

Conclusion: Seed-Coder通过减少人工干预，提升了代码预训练数据的质量和模型性能，为开源LLM提供了高效解决方案。

Abstract: Code data in large language model (LLM) pretraining is recognized crucial not
only for code-related tasks but also for enhancing general intelligence of
LLMs. Current open-source LLMs often heavily rely on human effort to produce
their code pretraining data, such as employing hand-crafted filtering rules
tailored to individual programming languages, or using human-annotated data to
train quality filters. However, these approaches are inherently limited in
scalability, prone to subjective biases, and costly to extend and maintain
across diverse programming languages. To address these challenges, we introduce
Seed-Coder, a series of open-source LLMs comprising base, instruct and
reasoning models of 8B size, minimizing human involvement in data construction.
Our code pretraining data is produced by a model-centric data pipeline, which
predominantly leverages LLMs for scoring and filtering code data. The instruct
model is further trained via supervised fine-tuning and preference
optimization, and the reasoning model leverages Long-Chain-of-Thought (LongCoT)
reinforcement learning to improve multi-step code reasoning. Seed-Coder
achieves state-of-the-art results among open-source models of similar size and
even surpasses some much larger models, demonstrating superior performance in
code generation, code completion, code editing, code reasoning, and software
engineering tasks.

</details>


### [26] [Go-Browse: Training Web Agents with Structured Exploration](https://arxiv.org/abs/2506.03533)
*Apurva Gandhi,Graham Neubig*

Main category: cs.CL

TL;DR: Go-Browse是一种通过结构化探索网络环境自动收集多样化且真实网络代理数据的方法，显著提升了数字代理对环境理解的能力。


<details>
  <summary>Details</summary>
Motivation: 数字代理缺乏对环境理解的能力，例如在网络浏览中容易迷失方向。

Method: 将数据收集建模为图搜索问题，实现信息在探索过程中的复用。

Result: 在WebArena基准测试中，收集了10K成功任务轨迹和40K交互步骤，微调后的7B参数语言模型成功率达到21.7%，优于GPT-4o mini和当前最先进的小模型。

Conclusion: Go-Browse方法有效提升了网络代理的任务解决能力，为小模型性能提供了新的基准。

Abstract: One of the fundamental problems in digital agents is their lack of
understanding of their environment. For instance, a web browsing agent may get
lost in unfamiliar websites, uncertain what pages must be visited to achieve
its goals. To address this, we propose Go-Browse, a method for automatically
collecting diverse and realistic web agent data at scale through structured
exploration of web environments. Go-Browse achieves efficient exploration by
framing data collection as a graph search, enabling reuse of information across
exploration episodes. We instantiate our method on the WebArena benchmark,
collecting a dataset of 10K successful task-solving trajectories and 40K
interaction steps across 100 URLs. Fine-tuning a 7B parameter language model on
this dataset achieves a success rate of 21.7% on the WebArena benchmark,
beating GPT-4o mini by 2.4% and exceeding current state-of-the-art results for
sub-10B parameter models by 2.9%.

</details>


### [27] [Debate, Reflect, and Distill: Multi-Agent Feedback with Tree-Structured Preference Optimization for Efficient Language Model Enhancement](https://arxiv.org/abs/2506.03541)
*Xiaofeng Zhou,Heyan Huang,Lizi Liao*

Main category: cs.CL

TL;DR: 论文提出了一种新颖的“辩论与反思”（D&R）框架，通过小模型与强教师模型的多轮辩论生成反馈，并结合树状直接偏好优化（T-DPO）方法，显著提升了小模型的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在知识密集和复杂推理任务中表现优异，但其高计算需求限制了广泛应用。现有的蒸馏方法（如静态知识蒸馏或强化学习）难以实现持续的性能提升。

Method: 提出D&R框架，通过小模型与教师模型的多轮辩论生成反馈，并设计T-DPO方法，将辩论日志组织为层次化结构以优化训练。

Result: 实验表明，该方法显著提升了小模型的准确性、鲁棒性和泛化能力，远超传统基线方法。

Conclusion: D&R框架与T-DPO方法的结合为高效训练小模型提供了新思路，具有广泛的应用潜力。

Abstract: Large Language Models (LLMs) continue to set new standards in
knowledge-intensive and complex reasoning tasks, yet their high computational
demands limit widespread adoption. While distilling large models into smaller
ones offers a sustainable solution, current techniques--such as static
knowledge distillation, resource-intensive reinforcement learning from human
feedback, or limited self-reflection--struggle to yield substantial and lasting
performance gains. In this paper, we present a novel Debate and Reflect (D&R)
framework that orchestrates multi-turn debates between smaller models and
stronger teacher models, eliciting actionable feedback (e.g., error analysis,
corrective strategies) to guide student models. Further, we introduce
Tree-structured Direct Preference Optimization (T-DPO) to efficiently leverage
these debate logs, organizing interactions into a hierarchical format for
effective training. Empirical evaluations across diverse NLP benchmarks
demonstrate that our approach significantly improves smaller-model accuracy,
robustness, and generalization, outperforming conventional baselines by a large
margin.

</details>


### [28] [BPO: Revisiting Preference Modeling in Direct Preference Optimization](https://arxiv.org/abs/2506.03557)
*Lin Sun,Chuang Liu,Peng Liu,Bingyang Li,Weijia Lu,Ning Wu*

Main category: cs.CL

TL;DR: BPO提出了一种新框架，通过平衡奖励边际和间隙适配器动态优化选择与拒绝响应，解决了DPO中的DCR问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: DPO方法在优化LLM与人类偏好对齐时，忽视了绝对奖励幅度，导致选择响应概率下降和分布外响应风险增加，即DCR问题。

Method: BPO框架包含平衡奖励边际和间隙适配器，动态平衡选择与拒绝响应的优化，无需额外约束损失函数。

Result: 在数学推理任务中，BPO显著优于DPO及其变体，准确率提升高达11.7%，且仅需单行代码修改。

Conclusion: BPO有效解决了DPO的DCR问题，性能显著提升，实现简单且兼容现有框架。

Abstract: Direct Preference Optimization (DPO) have emerged as a popular method for
aligning Large Language Models (LLMs) with human preferences. While DPO
effectively preserves the relative ordering between chosen and rejected
responses through pairwise ranking losses, it often neglects absolute reward
magnitudes. This oversight can decrease the likelihood of chosen responses and
increase the risk of generating out-of-distribution responses, leading to poor
performance. We term this issue Degraded Chosen Responses (DCR).To address this
issue, we propose Balanced Preference Optimization (BPO), a novel framework
that dynamically balances the optimization of chosen and rejected responses
through two key components: balanced reward margin and gap adaptor. Unlike
previous methods, BPO can fundamentally resolve DPO's DCR issue, without
introducing additional constraints to the loss function. Experimental results
on multiple mathematical reasoning tasks show that BPO significantly
outperforms DPO, improving accuracy by +10.1% with Llama-3.1-8B-Instruct (18.8%
to 28.9%) and +11.7% with Qwen2.5-Math-7B (35.0% to 46.7%). It also surpasses
DPO variants by +3.6% over IPO (43.1%), +5.0% over SLiC (41.7%), and +3.1% over
Cal-DPO (43.6%) on the same model. Remarkably, our algorithm requires only a
single line of code modification, making it simple to implement and fully
compatible with existing DPO-based frameworks.

</details>


### [29] [ConsistentChat: Building Skeleton-Guided Consistent Dialogues for Large Language Models from Scratch](https://arxiv.org/abs/2506.03558)
*Jiawei Chen,Xinyan Guan,Qianhao Yuan,Guozhao Mo,Weixiang Zhou,Yaojie Lu,Hongyu Lin,Ben He,Le Sun,Xianpei Han*

Main category: cs.CL

TL;DR: 论文提出了一种基于骨架引导的多轮对话生成框架，通过明确建模人类对话意图来解决现有单轮指令数据合成方法在多轮对话中缺乏连贯性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有指令数据合成方法主要关注单轮指令，忽视了多轮对话的连贯性，导致上下文漂移和任务完成率下降。

Method: 框架分为两个阶段：意图建模（捕获对话全局结构）和骨架生成（构建与意图对齐的用户查询序列）。

Result: 基于此构建的ConsistentChat数据集显著提升了模型在多轮对话中的连贯性和任务成功率。

Conclusion: 该方法在多轮对话生成中表现出色，显著优于现有单轮和多轮指令数据集训练的模型。

Abstract: Current instruction data synthesis methods primarily focus on single-turn
instructions and often neglect cross-turn coherence, resulting in context drift
and reduced task completion rates in extended conversations. To address this
limitation, we propose Skeleton-Guided Multi-Turn Dialogue Generation, a
framework that constrains multi-turn instruction synthesis by explicitly
modeling human conversational intent. It operates in two stages: (1) Intent
Modeling, which captures the global structure of human dialogues by assigning
each conversation to one of nine well-defined intent trajectories, ensuring a
coherent and goal-oriented information flow; and (2) Skeleton Generation, which
constructs a structurally grounded sequence of user queries aligned with the
modeled intent, thereby serving as a scaffold that constrains and guides the
downstream instruction synthesis process. Based on this process, we construct
ConsistentChat, a multi-turn instruction dataset with approximately 15,000
multi-turn conversations and 224,392 utterances. Experiments on the Light,
Topdial, and MT-Eval benchmarks show that models fine-tuned on ConsistentChat
achieve a 20-30% improvement in chat consistency and up to a 15% increase in
task success rate, significantly outperforming models trained on existing
single-turn and multi-turn instruction datasets.

</details>


### [30] [POSS: Position Specialist Generates Better Draft for Speculative Decoding](https://arxiv.org/abs/2506.03566)
*Langlin Huang,Chengsong Huang,Jixuan Leng,Di Huang,Jiaxin Huang*

Main category: cs.CL

TL;DR: 提出了一种名为Position Specialists (PosS)的方法，通过多个位置专用的草稿层来提高大型语言模型推理中的令牌接受率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在草稿模型生成的后期位置令牌预测质量下降，原因是特征误差累积。

Method: 使用多个位置专用的草稿层（PosS），每个层专注于处理特定位置的令牌预测。

Result: 在Llama-3-8B-Instruct和Llama-2-13B-chat模型上，PosS显著提高了平均接受长度和加速比。

Conclusion: PosS通过专注于特定位置的令牌预测，有效解决了草稿模型后期位置预测质量下降的问题。

Abstract: Speculative decoding accelerates Large Language Model (LLM) inference by
using a small draft model to predict multiple tokens, and a large target model
to verify these tokens in parallel. Recent studies leverage the hidden state of
the target model to enhance draft model prediction accuracy. However, existing
methods suffer from the degrading quality of draft token predictions at later
positions, due to error accumulation in draft model generated features. In this
paper, we propose Position Specialists (PosS), which consist of multiple
position-specialized draft layers to generate tokens at assigned position(s).
Position specialists greatly improve token acceptance rate at later positions
per drafting round, as each specialist only needs to focus on handling a
certain level of draft model feature deviation. Experiment results on
Llama-3-8B-Instruct and Llama-2-13B-chat across six datasets demonstrate that
PosS effectively improves over baselines on average acceptance length and
speed-up ratio. Our codebase is available at https://github.com/shrango/PosS.

</details>


### [31] [MiMo-VL Technical Report](https://arxiv.org/abs/2506.03569)
*Xiaomi LLM-Core Team,:,Zihao Yue,Zhenru Lin,Yifan Song,Weikun Wang,Shuhuai Ren,Shuhao Gu,Shicheng Li,Peidian Li,Liang Zhao,Lei Li,Kainan Bao,Hao Tian,Hailin Zhang,Gang Wang,Dawei Zhu,Cici,Chenhong He,Bowen Ye,Bowen Shen,Zihan Zhang,Zihan Jiang,Zhixian Zheng,Zhichao Song,Zhenbo Luo,Yue Yu,Yudong Wang,Yuanyuan Tian,Yu Tu,Yihan Yan,Yi Huang,Xu Wang,Xinzhe Xu,Xingchen Song,Xing Zhang,Xing Yong,Xin Zhang,Xiangwei Deng,Wenyu Yang,Wenhan Ma,Weiwei Lv,Weiji Zhuang,Wei Liu,Sirui Deng,Shuo Liu,Shimao Chen,Shihua Yu,Shaohui Liu,Shande Wang,Rui Ma,Qiantong Wang,Peng Wang,Nuo Chen,Menghang Zhu,Kangyang Zhou,Kang Zhou,Kai Fang,Jun Shi,Jinhao Dong,Jiebao Xiao,Jiaming Xu,Huaqiu Liu,Hongshen Xu,Heng Qu,Haochen Zhao,Hanglong Lv,Guoan Wang,Duo Zhang,Dong Zhang,Di Zhang,Chong Ma,Chang Liu,Can Cai,Bingquan Xia*

Main category: cs.CL

TL;DR: 开源MiMo-VL-7B-SFT和MiMo-VL-7B-RL两个视觉语言模型，性能领先，在多项任务中超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 提升视觉理解和多模态推理能力，推动领域发展。

Method: 结合四阶段预训练（2.4万亿token）与混合策略强化学习（MORL），整合多样化奖励信号。

Result: MiMo-VL-7B-RL在40项任务中35项超越Qwen2.5-VL-7B，OlympiadBench得分59.4，OSWorld-G得分56.1。

Conclusion: 高质量推理数据与混合强化学习对性能提升至关重要，开源模型和评估套件促进领域发展。

Abstract: We open-source MiMo-VL-7B-SFT and MiMo-VL-7B-RL, two powerful vision-language
models delivering state-of-the-art performance in both general visual
understanding and multimodal reasoning. MiMo-VL-7B-RL outperforms Qwen2.5-VL-7B
on 35 out of 40 evaluated tasks, and scores 59.4 on OlympiadBench, surpassing
models with up to 78B parameters. For GUI grounding applications, it sets a new
standard with 56.1 on OSWorld-G, even outperforming specialized models such as
UI-TARS. Our training combines four-stage pre-training (2.4 trillion tokens)
with Mixed On-policy Reinforcement Learning (MORL) integrating diverse reward
signals. We identify the importance of incorporating high-quality reasoning
data with long Chain-of-Thought into pre-training stages, and the benefits of
mixed RL despite challenges in simultaneous multi-domain optimization. We also
contribute a comprehensive evaluation suite covering 50+ tasks to promote
reproducibility and advance the field. The model checkpoints and full
evaluation suite are available at https://github.com/XiaomiMiMo/MiMo-VL.

</details>


### [32] [FreePRM: Training Process Reward Models Without Ground Truth Process Labels](https://arxiv.org/abs/2506.03570)
*Lin Sun,Chuang Liu,Xiaofeng Ma,Tao Yang,Weijia Lu,Ning Wu*

Main category: cs.CL

TL;DR: FreePRM是一种弱监督框架，无需真实步骤级标签即可训练过程奖励模型（PRM），通过伪标签和缓冲概率减少噪声影响，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统PRM训练依赖昂贵且难以大规模获取的步骤级标签，FreePRM旨在解决这一问题。

Method: FreePRM基于最终结果的正确性生成伪步骤级标签，并利用缓冲概率消除噪声。

Result: 在ProcessBench上平均F1得分为53.0%，优于多个开源PRM模型。

Conclusion: FreePRM为PRM训练提供了新范式，显著降低对昂贵标签的依赖，同时保持高性能。

Abstract: Recent advancements in Large Language Models (LLMs) have demonstrated that
Process Reward Models (PRMs) play a crucial role in enhancing model
performance. However, training PRMs typically requires step-level labels,
either manually annotated or automatically generated, which can be costly and
difficult to obtain at scale. To address this challenge, we introduce FreePRM,
a weakly supervised framework for training PRMs without access to ground-truth
step-level labels. FreePRM first generates pseudo step-level labels based on
the correctness of final outcome, and then employs Buffer Probability to
eliminate impact of noise inherent in pseudo labeling. Experimental results
show that FreePRM achieves an average F1 score of 53.0% on ProcessBench,
outperforming fully supervised PRM trained on Math-Shepherd by +24.1%. Compared
to other open-source PRMs, FreePRM outperforms upon RLHFlow-PRM-Mistral-8B
(28.4%) by +24.6%, EurusPRM (31.3%) by +21.7%, and Skywork-PRM-7B (42.1%) by
+10.9%. This work introduces a new paradigm in PRM training, significantly
reducing reliance on costly step-level annotations while maintaining strong
performance.

</details>


### [33] [Exchange of Perspective Prompting Enhances Reasoning in Large Language Models](https://arxiv.org/abs/2506.03573)
*Lin Sun,Can Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种名为Exchange-of-Perspective (EoP)的新框架，通过交换不同问题定义的视角来提升大语言模型（LLMs）在自然语言处理任务中的表现。实验表明，EoP显著提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在自然语言处理任务中表现优异，但其性能受限于对问题的固有理解。EoP旨在通过交换不同问题定义的视角，打破模型的固定思维模式。

Method: 提出EoP框架，通过交换不同问题定义的视角来增强模型对问题的理解。在8个基准测试上进行了广泛实验。

Result: 实验结果显示，EoP显著提升了模型性能。例如，使用GPT-3.5-Turbo和EoP在AQuA上的准确率提高了3.6%，而GPT-4驱动的EoP在Math和OlympiadBench Maths上的准确率分别提升了7.7%和3.5%。

Conclusion: EoP框架通过交换视角有效提升了大语言模型在多种任务中的性能，为解决模型固有理解限制提供了新思路。

Abstract: Large language models (LLMs) have made significant advancements in addressing
diverse natural language processing (NLP) tasks. However, their performance is
often limited by inherent comprehension of problems. To address this
limitation, we propose Exchange-of-Perspective (EoP), a novel framework
designed to exchange perspectives across different definitions of problem, so
that it can break the fixed mindset from any particular formulation of the
question. We conducted extensive and comprehensive experiments on 8 benchmarks.
The results show that EoP can significantly improve performance. For instance,
compared to the non-commutative baseline PHP, with GPT-3.5-Turbo and EoP, we
observe a 3.6% improvement on AQuA (60.6% to 64.2%), while GPT-4-powered EoP
demonstrates a 7.7% overall accuracy enhancement on Math (53.9% to 61.6%) and a
3.5% improvement on OlympiadBench Maths (43.5% to 47.0%) when using
Qwen-2.5-72b.

</details>


### [34] [KG-BiLM: Knowledge Graph Embedding via Bidirectional Language Models](https://arxiv.org/abs/2506.03576)
*Zirui Chen,Xin Wang,Zhao Li,Wenbin Guo,Dongxiao He*

Main category: cs.CL

TL;DR: KG-BiLM是一个双向语言模型框架，结合知识图谱的结构信息和生成式变换器的语义表达能力，通过双向知识注意力、知识掩码预测和对比图语义聚合三个关键组件，实现了知识图谱与语言模型的统一。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只关注知识图谱的结构或文本语义，缺乏一个能同时捕捉全局图谱连通性、细致语言上下文和判别性推理语义的统一框架。

Method: KG-BiLM通过双向知识注意力、知识掩码预测和对比图语义聚合三个组件，融合知识图谱的结构信息和语言模型的语义表达能力。

Result: 在标准基准测试中，KG-BiLM在链接预测任务上表现优于基线模型，尤其是在具有复杂多跳关系的大规模图谱上。

Conclusion: KG-BiLM有效地统一了结构信息和文本语义，验证了其在知识图谱与语言模型融合中的有效性。

Abstract: Recent advances in knowledge representation learning (KRL) highlight the
urgent necessity to unify symbolic knowledge graphs (KGs) with language models
(LMs) for richer semantic understanding. However, existing approaches typically
prioritize either graph structure or textual semantics, leaving a gap: a
unified framework that simultaneously captures global KG connectivity, nuanced
linguistic context, and discriminative reasoning semantics. To bridge this gap,
we introduce KG-BiLM, a bidirectional LM framework that fuses structural cues
from KGs with the semantic expressiveness of generative transformers. KG-BiLM
incorporates three key components: (i) Bidirectional Knowledge Attention, which
removes the causal mask to enable full interaction among all tokens and
entities; (ii) Knowledge-Masked Prediction, which encourages the model to
leverage both local semantic contexts and global graph connectivity; and (iii)
Contrastive Graph Semantic Aggregation, which preserves KG structure via
contrastive alignment of sampled sub-graph representations. Extensive
experiments on standard benchmarks demonstrate that KG-BiLM outperforms strong
baselines in link prediction, especially on large-scale graphs with complex
multi-hop relations - validating its effectiveness in unifying structural
information and textual semantics.

</details>


### [35] [Automatically Suggesting Diverse Example Sentences for L2 Japanese Learners Using Pre-Trained Language Models](https://arxiv.org/abs/2506.03580)
*Enrico Benedetti,Akiko Aizawa,Florian Boudin*

Main category: cs.CL

TL;DR: 该研究探讨了使用预训练语言模型（PLMs）为日语学习者生成多样化且符合其水平的例句，发现检索方法优于生成方法，但PLMs在提升语言学习适应性方面具有潜力。


<details>
  <summary>Details</summary>
Motivation: 为语言学习者提供多样化且符合其水平的例句是促进有效语言学习的关键。

Method: 研究采用PLMs作为检索系统中的质量评分组件和直接生成例句的工具（零样本学习），并通过多维度（难度、多样性、自然度）评估例句质量。

Result: 研究发现参与者对句子质量的评分存在分歧（难度除外），检索方法在所有评估者中更受欢迎，生成方法得分较低。

Conclusion: 尽管生成方法得分较低，但PLMs在提升句子推荐系统的适应性方面具有潜力，有助于改善语言学习体验。

Abstract: Providing example sentences that are diverse and aligned with learners'
proficiency levels is essential for fostering effective language acquisition.
This study examines the use of Pre-trained Language Models (PLMs) to produce
example sentences targeting L2 Japanese learners. We utilize PLMs in two ways:
as quality scoring components in a retrieval system that draws from a newly
curated corpus of Japanese sentences, and as direct sentence generators using
zero-shot learning. We evaluate the quality of sentences by considering
multiple aspects such as difficulty, diversity, and naturalness, with a panel
of raters consisting of learners of Japanese, native speakers -- and GPT-4. Our
findings suggest that there is inherent disagreement among participants on the
ratings of sentence qualities, except for difficulty. Despite that, the
retrieval approach was preferred by all evaluators, especially for beginner and
advanced target proficiency, while the generative approaches received lower
scores on average. Even so, our experiments highlight the potential for using
PLMs to enhance the adaptability of sentence suggestion systems and therefore
improve the language learning journey.

</details>


### [36] [From Understanding to Generation: An Efficient Shortcut for Evaluating Language Models](https://arxiv.org/abs/2506.03592)
*Viktor Hangya,Fabian Küch,Darina Gold*

Main category: cs.CL

TL;DR: 该研究提出将生成式任务（NLG）转化为更便宜的理解式任务（NLU），以减少LLM训练中的评估计算负担，并验证了两种任务格式间的强相关性。


<details>
  <summary>Details</summary>
Motivation: 在LLM训练中，生成式任务（如推理和代码生成）的评估耗时且计算密集，而理解式任务更高效。研究旨在通过任务转化降低评估成本。

Method: 将生成式任务重新设计为理解式任务，测试8种不同规模的LM在4种能力（数学推理、代码生成、事实知识和阅读理解）上的相关性。

Result: 结果显示两种任务格式间存在强相关性，评估时间平均减少35倍以上。

Conclusion: 通过任务转化可实现高效评估，支持在训练中低成本监控关键能力。

Abstract: Iterative evaluation of LLMs during training is essential to ensure expected
capability development, but can be time- and compute-intensive. While NLU
tasks, where the model selects from fixed answer choices, are cheap to
evaluate, essential capabilities like reasoning and code generation rely on the
more time-consuming NLG (token-by-token generation) format. In this work, our
aim is to decrease the computational burden of NLG benchmarks in order to
enable monitoring crucial LLM capabilities during model training. We
reformulate generative tasks into computationally cheaper NLU alternatives. We
test the performance correlation between the original and reformulated tasks
using 8 LMs of various sizes and 4 capabilities: mathematical reasoning, code
generation, factual knowledge and reading comprehension. Our results show a
strong correlation between task formats, supporting capability assessment via
cheaper alternatives and achieving over 35x average reduction in evaluation
time. We plan to publish our benchmark adaptions.

</details>


### [37] [Is linguistically-motivated data augmentation worth it?](https://arxiv.org/abs/2506.03593)
*Ray Groshan,Michael Ginn,Alexis Palmer*

Main category: cs.CL

TL;DR: 本文对语言数据增强的两种策略（语言无关和语言相关）进行了系统比较，发现语言相关策略在某些条件下优于语言无关策略。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决数据稀缺问题，并比较不同数据增强策略的效果，尤其是语言相关策略是否值得额外投入。

Method: 对两种低资源语言（Uspanteko和Arapaho）进行了多种数据增强策略及其组合的实验，评估了机器翻译和词间注释任务的效果。

Result: 语言相关策略在生成数据与训练数据分布相似时表现更好。

Conclusion: 语言相关数据增强策略在某些情况下优于语言无关策略，但需确保生成数据与训练数据分布一致。

Abstract: Data augmentation, a widely-employed technique for addressing data scarcity,
involves generating synthetic data examples which are then used to augment
available training data. Researchers have seen surprising success from simple
methods, such as random perturbations from natural examples, where models seem
to benefit even from data with nonsense words, or data that doesn't conform to
the rules of the language. A second line of research produces synthetic data
that does in fact follow all linguistic constraints; these methods require some
linguistic expertise and are generally more challenging to implement. No
previous work has done a systematic, empirical comparison of both
linguistically-naive and linguistically-motivated data augmentation strategies,
leaving uncertainty about whether the additional time and effort of
linguistically-motivated data augmentation work in fact yields better
downstream performance.
  In this work, we conduct a careful and comprehensive comparison of
augmentation strategies (both linguistically-naive and
linguistically-motivated) for two low-resource languages with different
morphological properties, Uspanteko and Arapaho. We evaluate the effectiveness
of many different strategies and their combinations across two important
sequence-to-sequence tasks for low-resource languages: machine translation and
interlinear glossing. We find that linguistically-motivated strategies can have
benefits over naive approaches, but only when the new examples they produce are
not significantly unlike the training data distribution.

</details>


### [38] [Auto prompt sql: a resource-efficient architecture for text-to-sql translation in constrained environments](https://arxiv.org/abs/2506.03598)
*Zetong Tang,Qian Ma,Di Wu*

Main category: cs.CL

TL;DR: AP-SQL是一种新颖的架构，旨在在资源受限环境中高效完成Text-to-SQL任务，通过分解任务和优化提示工程，结合小开源模型和大闭源模型的优势。


<details>
  <summary>Details</summary>
Motivation: 在资源受限环境中使用高性能Text-to-SQL方法存在挑战，因为现有方法依赖资源密集型开源模型。

Method: AP-SQL将任务分解为模式过滤、基于上下文示例的检索增强Text-to-SQL生成，以及提示驱动的模式链接和SQL生成，并利用CoT和GoT模板优化提示工程。

Result: 在Spider基准测试中，AP-SQL表现出色，验证了其有效性。

Conclusion: AP-SQL通过任务分解和提示工程优化，成功解决了资源受限环境下的Text-to-SQL挑战。

Abstract: Using the best Text-to-SQL methods in resource-constrained environments is
challenging due to their reliance on resource-intensive open-source models.
This paper introduces Auto Prompt SQL(AP-SQL), a novel architecture designed to
bridge the gap between resource-efficient small open-source models and the
powerful capabilities of large closed-source models for Text-to-SQL
translation. Our method decomposes the task into schema filtering,
retrieval-augmented text-to-SQL generation based on in-context examples, and
prompt-driven schema linking and SQL generation. To improve schema selection
accuracy, we fine-tune large language models. Crucially, we also explore the
impact of prompt engineering throughout the process, leveraging
Chain-of-Thought(CoT) and Graph-of-Thought(GoT) templates to significantly
enhance the model's reasoning for accurate SQL generation. Comprehensive
evaluations on the Spider benchmarks demonstrate the effectiveness of AP-SQL.

</details>


### [39] [Learning to Insert [PAUSE] Tokens for Better Reasoning](https://arxiv.org/abs/2506.03616)
*Eunki Kim,Sangryul Kim,James Thorne*

Main category: cs.CL

TL;DR: 论文提出了一种动态插入标记训练（DIT）方法，通过在模型置信度最低的位置插入[PAUSE]标记，显著提升了模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 为了增强大型语言模型的推理能力，研究探索了在训练过程中插入特殊标记的策略。

Method: DIT方法根据标记的对数似然识别序列中模型置信度最低的位置，并插入[PAUSE]标记以提升后续标记的预测能力。

Result: 实验表明，DIT在多个数据集和模型上优于传统微调和之前的标记插入方法，最高提升4.7%的准确率。

Conclusion: DIT是一种基于模型的动态方法，为推理研究提供了新的方向。

Abstract: To enhance reasoning capabilities, previous works have explored incorporating
special-purpose tokens into the training process. These strategies strengthen
the learning mechanism of transformer-based large language models (LLMs).
Building on prior research, in which inserting dummy tokens consecutively just
before reasoning steps can enhance effectiveness, we introduce a novel approach
termed Dynamic Inserting Tokens Training (DIT). Our method identifies positions
within sequences where model confidence is lowest according to token
log-likelihood. Strategically inserting [PAUSE] tokens on these positions
bolsters the model's predictive capabilities for subsequent tokens.
Experimental results across diverse datasets and models, from the 2.7B model to
the 8B model, demonstrate that DIT consistently outperforms traditional
fine-tuning and previous token insertion methods. With this simple yet
effective method, we achieve accuracy gains of up to 4.7%p on GSM8K, 3.23%p on
AQUA-RAT, and pass@1 improvements of up to 3.4%p on MBPP datasets. Our work
shows a model-based, dynamic approach rather than a heuristic one, thereby
broadening the scope of research in reasoning.

</details>


### [40] [Do Large Language Models Know Folktales? A Case Study of Yokai in Japanese Folktales](https://arxiv.org/abs/2506.03619)
*Ayuto Tsutsumi,Yuu Jinnai*

Main category: cs.CL

TL;DR: 论文提出YokaiEval基准数据集，评估LLMs对日本妖怪文化的理解，发现以日语资源训练的模型表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs文化知识局限于英语社区的问题，评估其对日本妖怪文化的理解。

Method: 构建YokaiEval数据集（809道选择题），评估31个日语和多语言LLMs的表现。

Result: 基于日语资源训练的模型（尤其是Llama-3）表现优于英语中心模型。

Conclusion: YokaiEval为评估LLMs文化意识提供有效工具，日语资源训练对提升文化理解至关重要。

Abstract: Although Large Language Models (LLMs) have demonstrated strong language
understanding and generation abilities across various languages, their cultural
knowledge is often limited to English-speaking communities, which can
marginalize the cultures of non-English communities. To address the problem,
evaluation of the cultural awareness of the LLMs and the methods to develop
culturally aware LLMs have been investigated. In this study, we focus on
evaluating knowledge of folktales, a key medium for conveying and circulating
culture. In particular, we focus on Japanese folktales, specifically on
knowledge of Yokai. Yokai are supernatural creatures originating from Japanese
folktales that continue to be popular motifs in art and entertainment today.
Yokai have long served as a medium for cultural expression, making them an
ideal subject for assessing the cultural awareness of LLMs. We introduce
YokaiEval, a benchmark dataset consisting of 809 multiple-choice questions
(each with four options) designed to probe knowledge about yokai. We evaluate
the performance of 31 Japanese and multilingual LLMs on this dataset. The
results show that models trained with Japanese language resources achieve
higher accuracy than English-centric models, with those that underwent
continued pretraining in Japanese, particularly those based on Llama-3,
performing especially well. The code and dataset are available at
https://github.com/CyberAgentA ILab/YokaiEval.

</details>


### [41] [Robustness of Prompting: Enhancing Robustness of Large Language Models Against Prompting Attacks](https://arxiv.org/abs/2506.03627)
*Lin Mu,Guowei Chu,Li Ni,Lei Sang,Zhize Wu,Peiquan Jin,Yiwen Zhang*

Main category: cs.CL

TL;DR: RoP是一种新型提示策略，旨在提升大语言模型（LLMs）对输入扰动的鲁棒性，通过错误纠正和引导两阶段显著改善模型性能。


<details>
  <summary>Details</summary>
Motivation: LLMs对输入扰动（如拼写错误或字符顺序错误）高度敏感，现有提示技术未能有效解决这一问题。

Method: RoP分为错误纠正和引导两阶段：首先生成对抗性示例以纠正输入错误，随后基于纠正后的输入生成最优引导提示。

Result: 实验表明，RoP显著提升了LLMs在对抗性扰动下的鲁棒性，同时保持模型准确性。

Conclusion: RoP是一种实用且有效的方法，适用于提升LLMs在现实应用中的鲁棒性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across
various tasks by effectively utilizing a prompting strategy. However, they are
highly sensitive to input perturbations, such as typographical errors or slight
character order errors, which can substantially degrade their performance.
Despite advances in prompting techniques, developing a prompting strategy that
explicitly mitigates the negative impact of such perturbations remains an open
challenge. To bridge this gap, we propose Robustness of Prompting (RoP), a
novel prompting strategy specifically designed to enhance the robustness of
LLMs. RoP consists of two stages: Error Correction and Guidance. In the Error
Correction stage, RoP applies diverse perturbation methods to generate
adversarial examples, which are then used to construct prompts that
automatically correct input errors. In the Guidance stage, RoP generates an
optimal guidance prompting based on the corrected input, steering the model
toward more robust and accurate inferences. Through comprehensive experiments
spanning arithmetic, commonsense, and logical reasoning tasks, we demonstrate
that RoP significantly improves LLMs' robustness against adversarial
perturbations. Notably, it maintains model accuracy with only minimal
degradation compared to clean input scenarios, thereby establishing RoP as a
practical and effective approach for enhancing LLM robustness in real-world
applications.

</details>


### [42] [RewardAnything: Generalizable Principle-Following Reward Models](https://arxiv.org/abs/2506.03637)
*Zhuohao Yu,Jiali Zeng,Weizheng Gu,Yidong Wang,Jindong Wang,Fandong Meng,Jie Zhou,Yue Zhang,Shikun Zhang,Wei Ye*

Main category: cs.CL

TL;DR: 论文提出了一种通用、遵循原则的奖励模型（RewardAnything），通过自然语言动态指定奖励原则，解决了传统奖励模型在多样任务中适应性差的问题。


<details>
  <summary>Details</summary>
Motivation: 传统奖励模型依赖固定偏好数据集，导致适应性差且资源消耗大，无法满足多样化的实际需求。

Method: 提出RewardAnything模型，通过自然语言动态指定奖励原则，并开发RABench基准测试其泛化能力。

Result: RewardAnything在传统基准和RABench上均表现优异，无需重新训练即可适应新原则。

Conclusion: RewardAnything为奖励模型提供了一种灵活、高效的解决方案，可无缝集成到现有RLHF方法中。

Abstract: Reward Models, essential for guiding Large Language Model optimization, are
typically trained on fixed preference datasets, resulting in rigid alignment to
single, implicit preference distributions. This prevents adaptation to diverse
real-world needs-from conciseness in one task to detailed explanations in
another. The standard practice of collecting task-specific preference data and
retraining reward models is resource-intensive, often producing biased rewards,
and limits practical application. We introduce generalizable,
principle-following reward models. We propose that RMs should understand and
adhere to dynamically provided natural language specifications of reward
principles, similar to instruction-following in LLMs. To measure this
capability, we develop RABench, a comprehensive benchmark for RMs focusing on
generalization across diverse principles. Evaluations on RABench reveal poor
generalization of current RMs. As a solution, we present RewardAnything, a
novel RM designed and trained to explicitly follow natural language principles.
We achieve SotA performance with RewardAnything in traditional RM benchmark
simply by specifying a well-defined principle, and results on RABench show we
excel in adapting to novel principles without retraining. Furthermore,
RewardAnything integrates seamlessly with existing RLHF methods and we show by
a case study on how to automatically and efficiently align LLMs with only
natural language principles.

</details>


### [43] [Trustworthy Medical Question Answering: An Evaluation-Centric Survey](https://arxiv.org/abs/2506.03659)
*Yinuo Wang,Robert E. Mercer,Frank Rudzicz,Sudipta Singha Roy,Pengjie Ren,Zhumin Chen,Xindi Wang*

Main category: cs.CL

TL;DR: 本文综述了医疗问答系统中信任度的六个关键维度（事实性、鲁棒性、公平性、安全性、可解释性和校准性），并分析了现有LLM系统的评估方法、改进技术和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 医疗问答系统的信任度对患者安全和临床决策至关重要，但现有LLM系统在复杂医疗场景中面临多维度挑战。

Method: 系统综述了六个信任度维度的评估方法、主要基准和改进技术（如检索增强、对抗微调等）。

Result: 总结了现有评估方法的局限性，并提出了改进方向。

Conclusion: 未来研究需关注专家评估、多维指标整合和实际部署，以提升LLM医疗问答系统的安全性和可靠性。

Abstract: Trustworthiness in healthcare question-answering (QA) systems is important
for ensuring patient safety, clinical effectiveness, and user confidence. As
large language models (LLMs) become increasingly integrated into medical
settings, the reliability of their responses directly influences clinical
decision-making and patient outcomes. However, achieving comprehensive
trustworthiness in medical QA poses significant challenges due to the inherent
complexity of healthcare data, the critical nature of clinical scenarios, and
the multifaceted dimensions of trustworthy AI. In this survey, we
systematically examine six key dimensions of trustworthiness in medical QA,
i.e., Factuality, Robustness, Fairness, Safety, Explainability, and
Calibration. We review how each dimension is evaluated in existing LLM-based
medical QA systems. We compile and compare major benchmarks designed to assess
these dimensions and analyze evaluation-guided techniques that drive model
improvements, such as retrieval-augmented grounding, adversarial fine-tuning,
and safety alignment. Finally, we identify open challenges-such as scalable
expert evaluation, integrated multi-dimensional metrics, and real-world
deployment studies-and propose future research directions to advance the safe,
reliable, and transparent deployment of LLM-powered medical QA.

</details>


### [44] [ROSA: Addressing text understanding challenges in photographs via ROtated SAmpling](https://arxiv.org/abs/2506.03665)
*Hernán Maina,Guido Ivetta,Mateo Lione Stuto,Julian Martin Eisenschlos,Jorge Sánchez,Luciana Benotti*

Main category: cs.CL

TL;DR: ROSA解码策略提升视觉问答系统在文本方向错误图像中的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉障碍人士拍摄的文本图像常因方向问题导致VQA系统表现不佳，现有基准未充分覆盖此类挑战。

Method: 提出ROSA解码策略，针对文本方向错误的图像优化VQA性能。

Result: ROSA在最佳模型中比Greedy解码提升11.7个百分点。

Conclusion: ROSA有效解决了视觉障碍人士拍摄文本图像的方向问题，提升了VQA系统的实用性。

Abstract: Visually impaired people could benefit from Visual Question Answering (VQA)
systems to interpret text in their surroundings. However, current models often
struggle with recognizing text in the photos taken by this population. Through
in-depth interviews with visually impaired individuals, we identified common
framing conventions that frequently result in misaligned text. Existing VQA
benchmarks primarily feature well-oriented text captured by sighted users,
under-representing these challenges. To address this gap, we introduce ROtated
SAmpling (ROSA), a decoding strategy that enhances VQA performance in text-rich
images with incorrectly oriented text. ROSA outperforms Greedy decoding by 11.7
absolute points in the best-performing model.

</details>


### [45] [Efficient Data Selection for Domain Adaptation of ASR Using Pseudo-Labels and Multi-Stage Filtering](https://arxiv.org/abs/2506.03681)
*Pradeep Rangappa,Andres Carofilis,Jeena Prakash,Shashi Kumar,Sergio Burdisso,Srikanth Madikeri,Esau Villatoro-Tello,Bidisha Sharma,Petr Motlicek,Kadri Hacioglu,Shankar Venkatesan,Saurabh Vyas,Andreas Stolcke*

Main category: cs.CL

TL;DR: 论文提出了一种通过筛选伪标签来优化ASR模型微调的方法，结合多种策略（如WER预测、NER和CER分析），在少量高质量数据上实现与大训练集相似的性能。


<details>
  <summary>Details</summary>
Motivation: 针对小组织在有限标注数据和计算资源下微调预训练ASR模型的挑战，研究如何通过数据选择提升适应性。

Method: 提出一种鲁棒的数据选择流程，结合Whisper和Zipformer生成的伪标签，通过WER预测、NER和CER分析筛选高质量训练片段。

Result: 在7500小时伪标注数据上微调达到12.3% WER，而筛选后的100小时数据（1.4%）性能相近；在Fisher English上也观察到类似趋势。

Conclusion: 该方法显著减少了所需数据量，同时保持了ASR模型的性能，为资源有限的场景提供了实用解决方案。

Abstract: Fine-tuning pretrained ASR models for specific domains is challenging for
small organizations with limited labeled data and computational resources.
Here, we explore different data selection pipelines and propose a robust
approach that improves ASR adaptation by filtering pseudo-labels generated
using Whisper (encoder-decoder) and Zipformer (transducer) models. Our approach
integrates multiple selection strategies -- including word error rate (WER)
prediction, named entity recognition (NER), and character error rate (CER)
analysis -- to extract high-quality training segments. We evaluate our method
on Whisper and Zipformer using a 7500-hour baseline, comparing it to a
CER-based approach relying on hypotheses from three ASR systems. Fine-tuning on
7500 hours of pseudo-labeled call center data achieves 12.3% WER, while our
filtering reduces the dataset to 100 hours (1.4%) with similar performance; a
similar trend is observed on Fisher English.

</details>


### [46] [Robust Preference Optimization via Dynamic Target Margins](https://arxiv.org/abs/2506.03690)
*Jie Sun,Junkang Wu,Jiancan Wu,Zhibo Zhu,Xingyu Lu,Jun Zhou,Lintao Ma,Xiang Wang*

Main category: cs.CL

TL;DR: 论文提出了一种动态目标边际偏好优化算法（γ-PO），通过调整成对奖励边际来提升大语言模型（LLM）的对齐效果，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型的对齐对安全性和可靠性至关重要，但现有方法（如DPO）对数据质量敏感，噪声会影响效果。

Method: 提出γ-PO，通过实例特定的边际校准，优先处理高置信度对并抑制模糊对的噪声，兼容现有DPO变体。

Result: 在AlpacaEval2和Arena-Hard等基准测试中，γ-PO平均提升4.4%，且对训练效率影响极小。

Conclusion: γ-PO是一种高效、兼容性强的插件式方法，显著提升了LLM对齐性能。

Abstract: The alignment of Large Language Models (LLMs) is crucial for ensuring their
safety and reliability in practical applications. Direct Preference
Optimization (DPO) has emerged as an efficient method that directly optimizes
models using preference pairs, significantly reducing resource demands.
However, the effectiveness of DPO heavily depends on the data quality, which is
frequently compromised by noise. In this work, we propose $\gamma$-PO, a
dynamic target margin preference optimization algorithm that adjust reward
margins at the pairwise level. By introducing instance-specific margin
calibration, $\gamma$-PO strategically prioritizes high-confidence pairs (those
demonstrating higher reward margins) while suppressing potential noise from
ambiguous pairs. Moreover, $\gamma$-PO is a plug-and-play method, compatible
with variants of DPO that rely on reward margin between preference pairs.
Across benchmarks such as AlpacaEval2 and Arena-Hard, $\gamma$-PO achieves an
average 4.4\% improvement over other baselines, setting new benchmarks for
state-of-the-art performance. Additionally, $\gamma$-PO requires minimal code
changes and has a negligible impact on training efficiency, making it a robust
solution for enhancing LLMs alignment. Our codes are available at
\href{https://github.com/sunjie279/gammaPO}{https://github.com/sunjie279/gammaPO}.

</details>


### [47] [AdaDecode: Accelerating LLM Decoding with Adaptive Layer Parallelism](https://arxiv.org/abs/2506.03700)
*Zhepei Wei,Wei-Lin Chen,Xinyu Zhu,Yu Meng*

Main category: cs.CL

TL;DR: AdaDecode是一种无需辅助模型或修改原始模型参数即可加速大语言模型解码的方法，通过自适应在中间层生成高置信度令牌，并行计算剩余层，实现1.73倍的解码加速，同时保证输出一致性。


<details>
  <summary>Details</summary>
Motivation: 现有解码方法（如推测解码和层跳过）存在辅助模型依赖或输出不一致问题，限制了硬件并行处理能力的充分利用。

Method: AdaDecode利用中间层生成高置信度令牌，并行计算剩余层，并通过验证步骤确保输出与标准自回归解码一致。

Result: 实验表明，AdaDecode在多种生成任务中实现最高1.73倍的解码加速，且输出与标准解码完全一致。

Conclusion: AdaDecode通过自适应中间层解码和并行计算，显著提升解码效率，同时保持输出质量。

Abstract: Large language models (LLMs) are increasingly used for long-content
generation (e.g., long Chain-of-Thought reasoning) where decoding efficiency
becomes a critical bottleneck: Autoregressive decoding is inherently limited by
its sequential token generation process, where each token must be generated
before the next can be processed. This sequential dependency restricts the
ability to fully leverage modern hardware's parallel processing capabilities.
Existing methods like speculative decoding and layer skipping offer potential
speedups but have notable drawbacks: speculative decoding relies on an
auxiliary "drafter" model, which can be challenging to acquire and increases
memory overhead, while layer skipping may introduce discrepancies in the
outputs due to the missing key-value cache at skipped layers. In this work, we
propose AdaDecode, which accelerates LLM decoding without requiring auxiliary
models or changes to the original model parameters, while ensuring output
consistency. AdaDecode leverages the insight that many tokens can accurately be
generated at intermediate layers, as further layers often do not significantly
alter predictions once the model reaches a certain confidence. By adaptively
generating tokens at intermediate layers when confidence is high, AdaDecode
enables the next token's computation to begin immediately. The remaining layer
computations for early-predicted tokens are deferred and executed in parallel
with subsequent tokens when needed, maximizing hardware utilization and
reducing decoding latency. A final verification step ensures that early
predictions match the results of standard autoregressive decoding, preserving
output parity. Experiments across diverse generation tasks shows that AdaDecode
consistently achieves superior decoding throughput with up to 1.73x speedup,
while guaranteeing output parity with standard autoregressive decoding.

</details>


### [48] [ScoreRAG: A Retrieval-Augmented Generation Framework with Consistency-Relevance Scoring and Structured Summarization for News Generation](https://arxiv.org/abs/2506.03704)
*Pei-Yun Lin,Yen-lung Tsai*

Main category: cs.CL

TL;DR: ScoreRAG通过多阶段框架提升新闻生成质量，结合检索增强生成、一致性评估和结构化摘要，显著提高准确性、连贯性和专业性。


<details>
  <summary>Details</summary>
Motivation: 当前新闻生成方法存在幻觉、事实不一致和缺乏领域专业知识的问题，ScoreRAG旨在解决这些挑战。

Method: 结合检索增强生成、一致性评估和结构化摘要，通过检索、评分、筛选和生成多阶段框架优化新闻生成。

Result: ScoreRAG显著提高了生成新闻的准确性、连贯性、信息量和专业性。

Conclusion: ScoreRAG为自动化新闻生成提供了一种高效、稳定的解决方案，代码和演示已开源。

Abstract: This research introduces ScoreRAG, an approach to enhance the quality of
automated news generation. Despite advancements in Natural Language Processing
and large language models, current news generation methods often struggle with
hallucinations, factual inconsistencies, and lack of domain-specific expertise
when producing news articles. ScoreRAG addresses these challenges through a
multi-stage framework combining retrieval-augmented generation, consistency
relevance evaluation, and structured summarization. The system first retrieves
relevant news documents from a vector database, maps them to complete news
items, and assigns consistency relevance scores based on large language model
evaluations. These documents are then reranked according to relevance, with
low-quality items filtered out. The framework proceeds to generate graded
summaries based on relevance scores, which guide the large language model in
producing complete news articles following professional journalistic standards.
Through this methodical approach, ScoreRAG aims to significantly improve the
accuracy, coherence, informativeness, and professionalism of generated news
articles while maintaining stability and consistency throughout the generation
process. The code and demo are available at:
https://github.com/peiyun2260/ScoreRAG.

</details>


### [49] [MFLA: Monotonic Finite Look-ahead Attention for Streaming Speech Recognition](https://arxiv.org/abs/2506.03722)
*Yinfeng Xia,Huiyan Li,Chenyang Le,Manhong Wang,Yutao Sun,Xingyang Ma,Yanmin Qian*

Main category: cs.CL

TL;DR: 本文提出了一种基于Whisper的流式语音识别框架，通过前缀到前缀训练和连续积分-触发机制，实现了低延迟与高质量的平衡。


<details>
  <summary>Details</summary>
Motivation: 尽管大型预训练语音模型（如Whisper）在降低训练成本方面表现出色，但其在流式系统中的集成仍具挑战性。

Method: 采用前缀到前缀训练框架，结合连续积分-触发机制和单调有限前瞻注意力机制，并使用wait-k解码策略。

Result: 实验证明该方法在延迟与质量之间实现了可控的权衡。

Conclusion: 该框架适用于多种流式应用，为流式语音识别提供了有效解决方案。

Abstract: Applying large pre-trained speech models like Whisper has shown promise in
reducing training costs for various speech tasks. However, integrating these
models into streaming systems remains a challenge. This paper presents a novel
prefix-to-prefix training framework for streaming recognition by fine-tuning
the Whisper. We introduce the Continuous Integrate-and-Fire mechanism to
establish a quasi-monotonic alignment between continuous speech sequences and
discrete text tokens. Additionally, we design Monotonic Finite Look-ahead
Attention, allowing each token to attend to infinite left-context and finite
right-context from the speech sequences. We also employ the wait-k decoding
strategy to simplify the decoding process while ensuring consistency between
training and testing. Our theoretical analysis and experiments demonstrate that
this approach achieves a controllable trade-off between latency and quality,
making it suitable for various streaming applications.

</details>


### [50] [Verbalized Confidence Triggers Self-Verification: Emergent Behavior Without Explicit Reasoning Supervision](https://arxiv.org/abs/2506.03723)
*Chaeyun Jang,Moonseok Choi,Yegon Kim,Hyungi Lee,Juho Lee*

Main category: cs.CL

TL;DR: 该论文研究了大型语言模型（LLMs）在链式推理（CoT）中的不确定性校准问题，发现仅通过标量置信度标签的监督微调即可引发模型的自我验证行为，无需显式推理监督或强化学习奖励。


<details>
  <summary>Details</summary>
Motivation: 确保LLMs在链式推理中的置信度校准对安全部署至关重要，但此前研究主要集中在分类器或短文本生成上，CoT推理的校准尚待探索。

Method: 通过监督微调训练模型生成置信度分数，并提出一种基于校准不确定性的简单重思考方法，在测试时进行性能优化。

Result: 在GSM8K、MATH-500和ARC-Challenge等任务上的实验表明，置信度感知微调提高了校准性和准确性，同时增强了模型推理路径与置信度的一致性。

Conclusion: 仅通过标量置信度标签的微调即可实现LLMs的自我验证行为，且提出的重思考方法进一步提升了性能，为LLMs的安全部署提供了新思路。

Abstract: Uncertainty calibration is essential for the safe deployment of large
language models (LLMs), particularly when users rely on verbalized confidence
estimates. While prior work has focused on classifiers or short-form
generation, confidence calibration for chain-of-thought (CoT) reasoning remains
largely unexplored. Surprisingly, we find that supervised fine-tuning with
scalar confidence labels alone suffices to elicit self-verification behavior of
language models, without any explicit reasoning supervision or reinforcement
learning-based rewards. Despite being trained only to produce a verbalized
confidence score without any self-verifying examples, the model learns to
generate longer and self-checking responses for low-confidence queries while
providing more concise answers for high-confidence ones. We further propose a
simple rethinking method that boosts performance via test-time scaling based on
calibrated uncertainty. Experiments on GSM8K and held-out reasoning tasks such
as MATH-500 and ARC-Challenge show that our confidence-aware fine-tuning
improves both calibration and accuracy, while also enhancing interpretability
by aligning the model's reasoning path with its confidence.

</details>


### [51] [Generating Pedagogically Meaningful Visuals for Math Word Problems: A New Benchmark and Analysis of Text-to-Image Models](https://arxiv.org/abs/2506.03735)
*Junling Wang,Anna Rutkiewicz,April Yi Wang,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: Math2Visual是一个自动生成数学应用题教学视觉内容的框架，通过预定义的视觉语言和教师访谈设计空间，生成符合教学需求的视觉内容。


<details>
  <summary>Details</summary>
Motivation: 数学应用题的教学视觉内容生成过程繁琐且缺乏自动化工具支持，Math2Visual旨在解决这一问题。

Method: 利用预定义的视觉语言和教师访谈设计空间，构建了1903个标注视觉数据集，并评估和微调了文本到图像模型。

Result: Math2Visual提升了教育视觉内容的生成质量，为自动化生成教学视觉内容设立了新基准。

Conclusion: 该研究为多模态教育内容生成提供了新方法，并揭示了数学关系误表达和视觉元素缺失等关键挑战。

Abstract: Visuals are valuable tools for teaching math word problems (MWPs), helping
young learners interpret textual descriptions into mathematical expressions
before solving them. However, creating such visuals is labor-intensive and
there is a lack of automated methods to support this process. In this paper, we
present Math2Visual, an automatic framework for generating pedagogically
meaningful visuals from MWP text descriptions. Math2Visual leverages a
pre-defined visual language and a design space grounded in interviews with math
teachers, to illustrate the core mathematical relationships in MWPs. Using
Math2Visual, we construct an annotated dataset of 1,903 visuals and evaluate
Text-to-Image (TTI) models for their ability to generate visuals that align
with our design. We further fine-tune several TTI models with our dataset,
demonstrating improvements in educational visual generation. Our work
establishes a new benchmark for automated generation of pedagogically
meaningful visuals and offers insights into key challenges in producing
multimodal educational content, such as the misrepresentation of mathematical
relationships and the omission of essential visual elements.

</details>


### [52] [Act-as-Pet: Benchmarking the Abilities of Large Language Models as E-Pets in Social Network Services](https://arxiv.org/abs/2506.03761)
*Hongcheng Guo,Zheyong Xie,Shaosheng Cao,Boyang Wang,Weiting Liu,Zheyu Ye,Zhoujun Li,Zuozhu Liu*

Main category: cs.CL

TL;DR: Pet-Bench是一个专门用于评估大型语言模型（LLMs）在虚拟宠物陪伴领域的基准测试，涵盖自我互动和人类互动维度，强调自我进化和行为发展。


<details>
  <summary>Details</summary>
Motivation: 随着对LLMs在情感丰富互动中应用的兴趣增长，虚拟宠物陪伴成为一个未被充分探索的领域，现有方法缺乏系统性评估。

Method: 提出Pet-Bench基准测试，包含智能调度、基于记忆的对话和心理对话等任务，共7,500多个互动实例。

Result: 评估28个LLMs，发现性能差异显著，与模型规模和能力相关，需专门优化。

Conclusion: Pet-Bench为宠物相关LLM能力评估和情感沉浸式互动提供了基础资源。

Abstract: As interest in using Large Language Models (LLMs) for interactive and
emotionally rich experiences grows, virtual pet companionship emerges as a
novel yet underexplored application. Existing approaches focus on basic pet
role-playing interactions without systematically benchmarking LLMs for
comprehensive companionship. In this paper, we introduce Pet-Bench, a dedicated
benchmark that evaluates LLMs across both self-interaction and
human-interaction dimensions. Unlike prior work, Pet-Bench emphasizes
self-evolution and developmental behaviors alongside interactive engagement,
offering a more realistic reflection of pet companionship. It features diverse
tasks such as intelligent scheduling, memory-based dialogues, and psychological
conversations, with over 7,500 interaction instances designed to simulate
complex pet behaviors. Evaluation of 28 LLMs reveals significant performance
variations linked to model size and inherent capabilities, underscoring the
need for specialized optimization in this domain. Pet-Bench serves as a
foundational resource for benchmarking pet-related LLM abilities and advancing
emotionally immersive human-pet interactions.

</details>


### [53] [AhaKV: Adaptive Holistic Attention-Driven KV Cache Eviction for Efficient Inference of Large Language Models](https://arxiv.org/abs/2506.03762)
*Yifeng Gu,Zicong Jiang,Jianxiu Jin,Kailing Guo,Ziyang Zhang,Xiangmin Xu*

Main category: cs.CL

TL;DR: 论文提出AhaKV方法，通过自适应调整softmax规模解决KV缓存中的注意力偏差问题，提升全局上下文信息利用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的KV缓存在推理中消耗大量内存，现有方法依赖累积注意力分数作为淘汰标准，但该分数存在偏差，导致模型无法充分利用全局上下文信息。

Method: 提出AhaKV方法，通过自适应调整softmax规模，并结合值向量信息，减少注意力分数的偏差。

Result: 实验表明，AhaKV在固定缓存预算下有效减少偏差，保留全局关键令牌，并在多个基准任务中取得最优结果。

Conclusion: AhaKV解决了KV缓存中的注意力偏差问题，提升了模型对全局上下文信息的利用能力。

Abstract: Large Language Models (LLMs) have significantly advanced the field of
Artificial Intelligence. However, their deployment is resource-intensive, not
only due to the large number of model parameters but also because the
(Key-Value) KV cache consumes a lot of memory during inference. While several
works propose reducing the KV cache by evicting the unnecessary tokens, these
approaches rely on accumulated attention score as eviction score to quantify
the importance of the token. We identify the accumulated attention score is
biased and it decreases with the position of the tokens in the mathematical
expectation. As a result, the retained tokens concentrate on the initial
positions, limiting model's access to global contextual information. To address
this issue, we propose Adaptive holistic attention KV (AhaKV), it addresses the
bias of the accumulated attention score by adaptively tuning the scale of
softmax according the expectation of information entropy of attention scores.
To make use of the holistic attention information in self-attention mechanism,
AhaKV utilize the information of value vectors, which is overlooked in previous
works, to refine the adaptive score. We show theoretically that our method is
well suited for bias reduction. We deployed AhaKV on different models with a
fixed cache budget. Experiments show that AhaKV successfully mitigates bias and
retains crucial tokens across global context and achieve state-of-the-art
results against other related work on several benchmark tasks.

</details>


### [54] [ClozeMath: Improving Mathematical Reasoning in Language Models by Learning to Fill Equations](https://arxiv.org/abs/2506.03763)
*Quang Hieu Pham,Thuy Duong Nguyen,Tung Pham,Anh Tuan Luu,Dat Quoc Nguyen*

Main category: cs.CL

TL;DR: 论文提出了一种名为ClozeMath的新方法，通过填空任务（类似于人类学习中的完形填空）来微调大语言模型（LLMs），以提升数学推理能力。实验表明，ClozeMath在性能和鲁棒性上优于基线方法Masked Thought。


<details>
  <summary>Details</summary>
Motivation: 传统的大语言模型训练方法（如下一个词预测）可能无法完全模拟人类学习思维的方式。受人类数学推理泛化能力的启发，作者希望通过填空任务更好地捕捉数学推理过程。

Method: 提出ClozeMath方法，通过预测给定解中的掩码方程（类似完形填空）来微调LLMs。实验使用了GSM8K、MATH和GSM-Symbolic数据集，并采用了Beam Search和Chain-of-Thought解码算法。

Result: ClozeMath在性能和鲁棒性上超越了基线方法Masked Thought。消融实验分析了不同架构和实现选择的影响。

Conclusion: ClozeMath是一种有效的数学推理微调方法，优于传统方法，并通过实验验证了其优越性。

Abstract: The capabilities of large language models (LLMs) have been enhanced by
training on data that reflects human thought processes, such as the
Chain-of-Thought format. However, evidence suggests that the conventional
scheme of next-word prediction may not fully capture how humans learn to think.
Inspired by how humans generalize mathematical reasoning, we propose a new
approach named ClozeMath to fine-tune LLMs for mathematical reasoning. Our
ClozeMath involves a text-infilling task that predicts masked equations from a
given solution, analogous to cloze exercises used in human learning.
Experiments on GSM8K, MATH, and GSM-Symbolic show that ClozeMath surpasses the
strong baseline Masked Thought in performance and robustness, with two
test-time scaling decoding algorithms, Beam Search and Chain-of-Thought
decoding. Additionally, we conduct an ablation study to analyze the effects of
various architectural and implementation choices on our approach.

</details>


### [55] [Unifying Uniform and Binary-coding Quantization for Accurate Compression of Large Language Models](https://arxiv.org/abs/2506.03781)
*Seungcheol Park,Jeongin Bae,Beomseok Kwon,Minjun Kim,Byeongwook Kim,Se Jung Kwon,U Kang,Dongsoo Lee*

Main category: cs.CL

TL;DR: UniQuanF是一种统一量化方法，结合了BCQ的表达能力和UQ的优化能力，显著提升了大型语言模型的量化精度。


<details>
  <summary>Details</summary>
Motivation: 现有量化方法（如BCQ和UQ）各有优势但无法兼顾，需要一种能同时利用两者优势的方法。

Method: 提出UniQuanF，结合UQ的灵活映射和BCQ的非均匀量化级别，并通过统一初始化、局部和周期性映射技术优化参数。

Result: 实验显示UniQuanF在GSM8K基准上比现有方法准确率提升4.60%。

Conclusion: UniQuanF在不增加部署成本的情况下，显著提升了量化模型的准确性。

Abstract: How can we quantize large language models while preserving accuracy?
Quantization is essential for deploying large language models (LLMs)
efficiently. Binary-coding quantization (BCQ) and uniform quantization (UQ) are
promising quantization schemes that have strong expressiveness and
optimizability, respectively. However, neither scheme leverages both
advantages. In this paper, we propose UniQuanF (Unified Quantization with
Flexible Mapping), an accurate quantization method for LLMs. UniQuanF harnesses
both strong expressiveness and optimizability by unifying the flexible mapping
technique in UQ and non-uniform quantization levels of BCQ. We propose unified
initialization, and local and periodic mapping techniques to optimize the
parameters in UniQuanF precisely. After optimization, our unification theorem
removes computational and memory overhead, allowing us to utilize the superior
accuracy of UniQuanF without extra deployment costs induced by the unification.
Experimental results demonstrate that UniQuanF outperforms existing UQ and BCQ
methods, achieving up to 4.60% higher accuracy on GSM8K benchmark.

</details>


### [56] [Knockout LLM Assessment: Using Large Language Models for Evaluations through Iterative Pairwise Comparisons](https://arxiv.org/abs/2506.03785)
*Isik Baran Sandan,Tu Anh Dinh,Jan Niehues*

Main category: cs.CL

TL;DR: 提出了一种名为“淘汰赛评估”的LLM评估方法，通过迭代成对比较提升评分准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估方法多依赖单次评估，缺乏全局排名视角。

Method: 采用淘汰赛系统进行迭代成对比较。

Result: 在两项任务中，评分准确性提升，与专家评估的Pearson相关性平均提高0.07。

Conclusion: 淘汰赛评估使LLM评分更接近人类评分。

Abstract: Large Language Models (LLMs) have shown to be effective evaluators across
various domains such as machine translations or the scientific domain. Current
LLM-as-a-Judge approaches rely mostly on individual assessments or a single
round of pairwise assessments, preventing the judge LLM from developing a
global ranking perspective. To address this, we present Knockout Assessment, an
LLM-asa Judge method using a knockout tournament system with iterative pairwise
comparisons. Experiments across three LLMs on two datasets show that knockout
assessment improves scoring accuracy, increasing Pearson correlation with
expert evaluations by 0.07 on average for university-level exam scoring and
machine translation evaluations, aligning LLM assessments more closely with
human scoring.

</details>


### [57] [Mark My Words: A Robust Multilingual Model for Punctuation in Text and Speech Transcripts](https://arxiv.org/abs/2506.03793)
*Sidharth Pulipaka,Sparsh Jain,Ashwin Sankar,Raj Dabre*

Main category: cs.CL

TL;DR: Cadence是一个基于预训练语言模型的标点恢复模型，支持多种语言，尤其在处理自发语音转录时表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前模型在处理自发语音转录中的标点恢复时表现不佳，影响下游任务质量。

Method: 利用预训练大型语言模型开发Cadence，支持多种语言和标点类型。

Result: Cadence在性能上超越现有技术，支持22种印度语言和英语，并分析了模型在不同标点类型和语言家族中的表现。

Conclusion: 预训练语言模型在多语言标点恢复中有效，Cadence对低资源NLP任务具有实用价值。

Abstract: Punctuation plays a vital role in structuring meaning, yet current models
often struggle to restore it accurately in transcripts of spontaneous speech,
especially in the presence of disfluencies such as false starts and
backtracking. These limitations hinder the performance of downstream tasks like
translation, text to speech, summarization, etc. where sentence boundaries are
critical for preserving quality. In this work, we introduce Cadence, a
generalist punctuation restoration model adapted from a pretrained large
language model. Cadence is designed to handle both clean written text and
highly spontaneous spoken transcripts. It surpasses the previous state of the
art in performance while expanding support from 14 to all 22 Indian languages
and English. We conduct a comprehensive analysis of model behavior across
punctuation types and language families, identifying persistent challenges
under domain shift and with rare punctuation marks. Our findings demonstrate
the efficacy of utilizing pretrained language models for multilingual
punctuation restoration and highlight Cadence practical value for low resource
NLP pipelines at scale.

</details>


### [58] [Automatic Correction of Writing Anomalies in Hausa Texts](https://arxiv.org/abs/2506.03820)
*Ahmad Mustapha Wali,Sergiu Nisioi*

Main category: cs.CL

TL;DR: 本文提出了一种基于Transformer模型的自动校正豪萨语文本异常的方法，通过合成噪声生成大规模平行数据集，并优化多语言模型，显著提升了文本校正效果。


<details>
  <summary>Details</summary>
Motivation: 豪萨语文本常因字符替换和间距错误等问题影响NLP应用，亟需自动化校正方法。

Method: 通过合成噪声创建45万对噪声-干净句子数据集，并微调多语言模型（如M2M100、AfriTEVA等）进行校正。

Result: 实验显示F1、BLEU、METEOR分数显著提升，CER和WER降低。

Conclusion: 研究提供了方法论、公开数据集和高效模型，推动了豪萨语NLP发展，并为其他低资源语言提供了借鉴。

Abstract: Hausa texts are often characterized by writing anomalies such as incorrect
character substitutions and spacing errors, which sometimes hinder natural
language processing (NLP) applications. This paper presents an approach to
automatically correct the anomalies by finetuning transformer-based models.
Using a corpus gathered from several public sources, we created a large-scale
parallel dataset of over 450,000 noisy-clean Hausa sentence pairs by
introducing synthetically generated noise, fine-tuned to mimic realistic
writing errors. Moreover, we adapted several multilingual and African
language-focused models, including M2M100, AfriTEVA, mBART, and Opus-MT
variants for this correction task using SentencePiece tokenization. Our
experimental results demonstrate significant increases in F1, BLEU and METEOR
scores, as well as reductions in Character Error Rate (CER) and Word Error Rate
(WER). This research provides a robust methodology, a publicly available
dataset, and effective models to improve Hausa text quality, thereby advancing
NLP capabilities for the language and offering transferable insights for other
low-resource languages.

</details>


### [59] [CRAWLDoc: A Dataset for Robust Ranking of Bibliographic Documents](https://arxiv.org/abs/2506.03822)
*Fabian Karl,Ansgar Scherp*

Main category: cs.CL

TL;DR: CRAWLDoc是一种新的上下文排名方法，用于从网页中提取和排序链接文档，以提高出版物元数据提取的准确性。


<details>
  <summary>Details</summary>
Motivation: 由于网页布局和数据格式的多样性，出版物数据库在元数据提取方面面临挑战，需要一种能够独立于布局的方法。

Method: CRAWLDoc通过URL（如DOI）获取网页及其链接资源（如PDF、ORCID等），并将这些资源、锚文本和URL嵌入统一表示中。

Result: 在600篇计算机科学出版物的手动标注数据集上，CRAWLDoc展示了跨出版商和数据格式的稳健排名能力。

Conclusion: CRAWLDoc为从多样化布局和格式的网页文档中提取元数据提供了基础，其代码和数据集已开源。

Abstract: Publication databases rely on accurate metadata extraction from diverse web
sources, yet variations in web layouts and data formats present challenges for
metadata providers. This paper introduces CRAWLDoc, a new method for contextual
ranking of linked web documents. Starting with a publication's URL, such as a
digital object identifier, CRAWLDoc retrieves the landing page and all linked
web resources, including PDFs, ORCID profiles, and supplementary materials. It
embeds these resources, along with anchor texts and the URLs, into a unified
representation. For evaluating CRAWLDoc, we have created a new, manually
labeled dataset of 600 publications from six top publishers in computer
science. Our method CRAWLDoc demonstrates a robust and layout-independent
ranking of relevant documents across publishers and data formats. It lays the
foundation for improved metadata extraction from web documents with various
layouts and formats. Our source code and dataset can be accessed at
https://github.com/FKarl/CRAWLDoc.

</details>


### [60] [Multi-objective Aligned Bidword Generation Model for E-commerce Search Advertising](https://arxiv.org/abs/2506.03827)
*Zhenhui Liu,Chunyuan Yuan,Ming Pang,Zheng Fang,Li Yuan,Xue Jiang,Changping Peng,Zhangang Lin,Zheng Luo,Jingping Shao*

Main category: cs.CL

TL;DR: 提出了一种多目标对齐的竞价词生成模型（MoBGM），通过判别器、生成器和偏好对齐模块优化查询改写，提升广告召回效果和平台收益。


<details>
  <summary>Details</summary>
Motivation: 解决现有查询改写方法无法同时优化查询相关性、真实性和广告收益的问题。

Method: 设计了一个包含判别器、生成器和偏好对齐模块的模型，通过多目标对齐生成竞价词。

Result: 离线与在线实验表明，该算法显著优于现有方法，并带来巨大商业价值。

Conclusion: MoBGM在提升广告召回效果和平台收益方面具有可行性和鲁棒性。

Abstract: Retrieval systems primarily address the challenge of matching user queries
with the most relevant advertisements, playing a crucial role in e-commerce
search advertising. The diversity of user needs and expressions often produces
massive long-tail queries that cannot be matched with merchant bidwords or
product titles, which results in some advertisements not being recalled,
ultimately harming user experience and search efficiency. Existing query
rewriting research focuses on various methods such as query log mining,
query-bidword vector matching, or generation-based rewriting. However, these
methods often fail to simultaneously optimize the relevance and authenticity of
the user's original query and rewrite and maximize the revenue potential of
recalled ads.
  In this paper, we propose a Multi-objective aligned Bidword Generation Model
(MoBGM), which is composed of a discriminator, generator, and preference
alignment module, to address these challenges. To simultaneously improve the
relevance and authenticity of the query and rewrite and maximize the platform
revenue, we design a discriminator to optimize these key objectives. Using the
feedback signal of the discriminator, we train a multi-objective aligned
bidword generator that aims to maximize the combined effect of the three
objectives. Extensive offline and online experiments show that our proposed
algorithm significantly outperforms the state of the art. After deployment, the
algorithm has created huge commercial value for the platform, further verifying
its feasibility and robustness.

</details>


### [61] [Brain-tuned Speech Models Better Reflect Speech Processing Stages in the Brain](https://arxiv.org/abs/2506.03832)
*Omer Moussa,Mariya Toneva*

Main category: cs.CL

TL;DR: 脑调优的自监督语音模型在语义理解上优于预训练模型，并展现出更接近人脑的层次化处理。


<details>
  <summary>Details</summary>
Motivation: 研究脑调优模型是否能更好地反映人脑在语音处理中的中间阶段。

Method: 通过脑调优（使用人脑记录微调模型）改进语音模型，并进行层次化分析。

Result: 脑调优模型的后期层显著改善了与语义语言区域的对应性，层次化处理更清晰。

Conclusion: 脑调优模型不仅性能更优，且层次化处理更接近人脑，是研究人类语音处理的更好模型。

Abstract: Pretrained self-supervised speech models excel in speech tasks but do not
reflect the hierarchy of human speech processing, as they encode rich semantics
in middle layers and poor semantics in late layers. Recent work showed that
brain-tuning (fine-tuning models using human brain recordings) improves speech
models' semantic understanding. Here, we examine how well brain-tuned models
further reflect the brain's intermediate stages of speech processing. We find
that late layers of brain-tuned models substantially improve over pretrained
models in their alignment with semantic language regions. Further layer-wise
probing reveals that early layers remain dedicated to low-level acoustic
features, while late layers become the best at complex high-level tasks. These
findings show that brain-tuned models not only perform better but also exhibit
a well-defined hierarchical processing going from acoustic to semantic
representations, making them better model organisms for human speech
processing.

</details>


### [62] [PulseReddit: A Novel Reddit Dataset for Benchmarking MAS in High-Frequency Cryptocurrency Trading](https://arxiv.org/abs/2506.03861)
*Qiuhan Han,Qian Wang,Atsushi Yoshikawa,Masayuki Yamamura*

Main category: cs.CL

TL;DR: 论文介绍了PulseReddit数据集，结合Reddit讨论与高频加密货币市场数据，通过多智能体系统（MAS）研究社交情绪对交易表现的影响，结果显示优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 高频交易（HFT）需要快速决策，而社交媒体如Reddit提供了未充分探索的信息。研究旨在探索社交情绪对高频交易的影响。

Method: 使用基于大语言模型（LLM）的多智能体系统（MAS）分析PulseReddit数据集，研究社交情绪与交易表现的关系。

Result: 实验表明，结合PulseReddit数据的MAS在牛市表现更优，且适应性强。研究还揭示了不同LLM的性能-效率权衡。

Conclusion: PulseReddit为HFT研究奠定了基础，展示了社交媒体整合的实际价值，并为模型选择提供了重要参考。

Abstract: High-Frequency Trading (HFT) is pivotal in cryptocurrency markets, demanding
rapid decision-making. Social media platforms like Reddit offer valuable, yet
underexplored, information for such high-frequency, short-term trading. This
paper introduces \textbf{PulseReddit}, a novel dataset that is the first to
align large-scale Reddit discussion data with high-frequency cryptocurrency
market statistics for short-term trading analysis. We conduct an extensive
empirical study using Large Language Model (LLM)-based Multi-Agent Systems
(MAS) to investigate the impact of social sentiment from PulseReddit on trading
performance. Our experiments conclude that MAS augmented with PulseReddit data
achieve superior trading outcomes compared to traditional baselines,
particularly in bull markets, and demonstrate robust adaptability across
different market regimes. Furthermore, our research provides conclusive
insights into the performance-efficiency trade-offs of different LLMs,
detailing significant considerations for practical model selection in HFT
applications. PulseReddit and our findings establish a foundation for advanced
MAS research in HFT, demonstrating the tangible benefits of integrating social
media.

</details>


### [63] [EuroGEST: Investigating gender stereotypes in multilingual language models](https://arxiv.org/abs/2506.03867)
*Jacqueline Rowe,Mateusz Klimaszewski,Liane Guillou,Shannon Vallor,Alexandra Birch*

Main category: cs.CL

TL;DR: EuroGEST是一个多语言数据集，用于评估大型语言模型（LLMs）在29种欧洲语言中的性别刻板印象。研究发现，所有模型中最强的性别刻板印象是女性被认为‘美丽’、‘有同理心’和‘整洁’，而男性则被视为‘领导者’、‘强壮’和‘专业’。


<details>
  <summary>Details</summary>
Motivation: 现有性别偏见基准主要集中于英语，缺乏多语言评估。EuroGEST旨在填补这一空白，提供跨语言的性别刻板印象测量工具。

Method: 基于专家定义的16种性别刻板印象，通过翻译工具、质量评估指标和形态学启发式方法扩展数据集，并进行人工评估验证。

Result: 研究发现，所有模型和语言中最强的性别刻板印象一致；更大的模型性别刻板印象更强，指令微调并未显著减少偏见。

Conclusion: 研究强调需要更多多语言的公平性研究，并提供了可扩展的方法和资源来评估跨语言的性别偏见。

Abstract: Large language models increasingly support multiple languages, yet most
benchmarks for gender bias remain English-centric. We introduce EuroGEST, a
dataset designed to measure gender-stereotypical reasoning in LLMs across
English and 29 European languages. EuroGEST builds on an existing
expert-informed benchmark covering 16 gender stereotypes, expanded in this work
using translation tools, quality estimation metrics, and morphological
heuristics. Human evaluations confirm that our data generation method results
in high accuracy of both translations and gender labels across languages. We
use EuroGEST to evaluate 24 multilingual language models from six model
families, demonstrating that the strongest stereotypes in all models across all
languages are that women are \textit{beautiful,} \textit{empathetic} and
\textit{neat} and men are \textit{leaders}, \textit{strong, tough} and
\textit{professional}. We also show that larger models encode gendered
stereotypes more strongly and that instruction finetuning does not consistently
reduce gendered stereotypes. Our work highlights the need for more multilingual
studies of fairness in LLMs and offers scalable methods and resources to audit
gender bias across languages.

</details>


### [64] [RadialRouter: Structured Representation for Efficient and Robust Large Language Models Routing](https://arxiv.org/abs/2506.03880)
*Ruihan Jin,Pengpeng Shao,Zhengqi Wen,Jinyang Wu,Mingkuan Feng,Shuai Zhang,Jianhua Tao*

Main category: cs.CL

TL;DR: RadialRouter是一种新型LLM路由框架，通过RadialFormer结构优化查询与LLM的关系，显著提升路由性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM路由方法因未能充分探索查询与LLM特性之间的内在联系而效果有限。

Method: 采用轻量级Transformer架构RadialFormer，结合KL散度和查询对比损失优化路由选择。

Result: 在RouterBench上，RadialRouter在Balance和Cost First场景中分别优于现有方法9.2%和5.8%。

Conclusion: RadialRouter具有适应不同性能-成本权衡和动态LLM池的潜力，展现了实际应用价值。

Abstract: The rapid advancements in large language models (LLMs) have led to the
emergence of routing techniques, which aim to efficiently select the optimal
LLM from diverse candidates to tackle specific tasks, optimizing performance
while reducing costs. Current LLM routing methods are limited in effectiveness
due to insufficient exploration of the intrinsic connection between user
queries and the characteristics of LLMs. To address this issue, in this paper,
we present RadialRouter, a novel framework for LLM routing which employs a
lightweight Transformer-based backbone with a radial structure named
RadialFormer to articulate the query-LLMs relationship. The optimal LLM
selection is performed based on the final states of RadialFormer. The pipeline
is further refined by an objective function that combines Kullback-Leibler
divergence with the query-query contrastive loss to enhance robustness.
Experimental results on RouterBench show that RadialRouter significantly
outperforms existing routing methods by 9.2\% and 5.8\% in the Balance and Cost
First scenarios, respectively. Additionally, its adaptability toward different
performance-cost trade-offs and the dynamic LLM pool demonstrates practical
application potential.

</details>


### [65] [Kinship in Speech: Leveraging Linguistic Relatedness for Zero-Shot TTS in Indian Languages](https://arxiv.org/abs/2506.03884)
*Utkarsh Pathak,Chandra Sai Krishna Gunda,Anusha Prakash,Keshav Agarwal,Hema A. Murthy*

Main category: cs.CL

TL;DR: 该论文提出了一种零样本合成方法，用于解决印度多种语言缺乏数字资源的问题，通过共享音素表示和调整文本解析规则，实现了对多语言的快速适应。


<details>
  <summary>Details</summary>
Motivation: 印度有1369种语言，其中大多数缺乏数字资源，传统的TTS系统需要高质量数据和准确转录，难以覆盖这些语言。因此，研究旨在为零资源语言提供语音合成解决方案。

Method: 通过增强共享音素表示和调整文本解析规则，使其适应目标语言的音位规则，从而减少合成器开销并实现快速适应。

Result: 成功为梵语、马拉地语、卡纳拉孔卡尼语、迈蒂利语和库鲁克语生成了清晰自然的语音，验证了方法的有效性。

Conclusion: 该方法能够扩展语音技术对资源匮乏语言的覆盖，具有广泛的应用潜力。

Abstract: Text-to-speech (TTS) systems typically require high-quality studio data and
accurate transcriptions for training. India has 1369 languages, with 22
official using 13 scripts. Training a TTS system for all these languages, most
of which have no digital resources, seems a Herculean task. Our work focuses on
zero-shot synthesis, particularly for languages whose scripts and phonotactics
come from different families. The novelty of our work is in the augmentation of
a shared phone representation and modifying the text parsing rules to match the
phonotactics of the target language, thus reducing the synthesiser overhead and
enabling rapid adaptation. Intelligible and natural speech was generated for
Sanskrit, Maharashtrian and Canara Konkani, Maithili and Kurukh by leveraging
linguistic connections across languages with suitable synthesisers. Evaluations
confirm the effectiveness of this approach, highlighting its potential to
expand speech technology access for under-represented languages.

</details>


### [66] [Pre$^3$: Enabling Deterministic Pushdown Automata for Faster Structured LLM Generation](https://arxiv.org/abs/2506.03887)
*Junyi Chen,Shihao Bai,Zaijun Wang,Siyu Wu,Chuheng Du,Hailong Yang,Ruihao Gong,Shengzhong Liu,Fan Wu,Guihai Chen*

Main category: cs.CL

TL;DR: Pre$^3$通过预计算前缀条件边和将LR(1)转移图转换为DPDA，显著提升了LLM在结构化生成中的效率，减少了运行时开销。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理LR(1)文法时存在运行时执行开销高的问题，尤其是在大规模推理批次下效率低下。

Method: Pre$^3$通过预计算前缀条件边和将LR(1)转移图转换为确定性下推自动机（DPDA），实现了并行转移处理和最小化运行时路径探索。

Result: 实验表明，Pre$^3$将每个输出令牌的时间（TPOT）减少了40%，吞吐量提升了36%。

Conclusion: Pre$^3$是一种高效且可无缝集成到LLM推理框架中的方法，显著提升了结构化生成的效率。

Abstract: Extensive LLM applications demand efficient structured generations,
particularly for LR(1) grammars, to produce outputs in specified formats (e.g.,
JSON). Existing methods primarily parse LR(1) grammars into a pushdown
automaton (PDA), leading to runtime execution overhead for context-dependent
token processing, especially inefficient under large inference batches. To
address these issues, we propose Pre$^3$ that exploits deterministic pushdown
automata (DPDA) to optimize the constrained LLM decoding efficiency. First, by
precomputing prefix-conditioned edges during the preprocessing, Pre$^3$ enables
ahead-of-time edge analysis and thus makes parallel transition processing
possible. Second, by leveraging the prefix-conditioned edges, Pre$^3$
introduces a novel approach that transforms LR(1) transition graphs into DPDA,
eliminating the need for runtime path exploration and achieving edge
transitions with minimal overhead. Pre$^3$ can be seamlessly integrated into
standard LLM inference frameworks, reducing time per output token (TPOT) by up
to 40% and increasing throughput by up to 36% in our experiments. Our code is
available at https://github.com/ModelTC/lightllm.

</details>


### [67] [Magic Mushroom: A Customizable Benchmark for Fine-grained Analysis of Retrieval Noise Erosion in RAG Systems](https://arxiv.org/abs/2506.03901)
*Yuxin Zhang,Yan Wang,Yongrui Chen,Shenyu Zhang,Xinbang Dai,Sheng Bi,Guilin Qi*

Main category: cs.CL

TL;DR: 论文介绍了Magic Mushroom基准，用于模拟真实世界中的检索噪声，评估RAG系统的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法模拟真实世界中的复杂噪声分布，限制了RAG系统的可靠评估。

Method: 定义了四类检索噪声，并开发了Magic Mushroom基准，包含单跳和多跳问答对。

Result: 实验表明，生成器和去噪策略对噪声分布极为敏感，仍有改进空间。

Conclusion: Magic Mushroom是评估和提升RAG系统噪声鲁棒性的有效工具。

Abstract: Retrieval-Augmented Generation (RAG) systems enhance Large Language Models
(LLMs) by incorporating external retrieved information, mitigating issues such
as hallucination and outdated knowledge.
  However, RAG systems are highly sensitive to retrieval noise prevalent in
real-world scenarios.
  Existing benchmarks fail to emulate the complex and heterogeneous noise
distributions encountered in real-world retrieval environments, undermining
reliable robustness assessment.
  In this paper, we define four categories of retrieval noise based on
linguistic properties and noise characteristics, aiming to reflect the
heterogeneity of noise in real-world scenarios.
  Building on this, we introduce Magic Mushroom, a benchmark for replicating
"magic mushroom" noise: contexts that appear relevant on the surface but
covertly mislead RAG systems.
  Magic Mushroom comprises 7,468 single-hop and 3,925 multi-hop question-answer
pairs.
  More importantly, Magic Mushroom enables researchers to flexibly configure
combinations of retrieval noise according to specific research objectives or
application scenarios, allowing for highly controlled evaluation setups.
  We evaluate LLM generators of varying parameter scales and classic RAG
denoising strategies under diverse noise distributions to investigate their
performance dynamics during progressive noise encroachment.
  Our analysis reveals that both generators and denoising strategies have
significant room for improvement and exhibit extreme sensitivity to noise
distributions.
  Magic Mushroom emerges as a promising tool for evaluating and advancing
noise-robust RAG systems, accelerating their widespread deployment in
real-world applications.
  The Magic Mushroom benchmark is available at the
https://drive.google.com/file/d/1aP5kyPuk4L-L_uoI6T9UhxuTyt8oMqjT/view?usp=sharing.

</details>


### [68] [The Harmonic Structure of Information Contours](https://arxiv.org/abs/2506.03902)
*Eleftheria Tsipidi,Samuel Kiegeland,Franz Nowak,Tianyang Xu,Ethan Wilcox,Alex Warstadt,Ryan Cotterell,Mario Giulianelli*

Main category: cs.CL

TL;DR: 论文探讨了语言信息密度的周期性波动，提出信息率可能受周期性压力影响，并通过谐波回归和时间缩放方法在多语言文本中发现了周期性模式。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索语言信息密度波动的原因，挑战传统的均匀信息密度假设，提出周期性压力的新视角。

Method: 采用谐波回归和时间缩放方法，分析英语、西班牙语、德语、荷兰语、巴斯克语和巴西葡萄牙语文本中的信息率周期性。

Result: 在多语言文本中发现了信息率的周期性模式，且主要频率与话语结构一致，表明这些波动反映了有意义的语言组织。

Conclusion: 研究不仅揭示了信息率与话语结构的联系，还为揭示语言结构压力提供了通用框架。

Abstract: The uniform information density (UID) hypothesis proposes that speakers aim
to distribute information evenly throughout a text, balancing production effort
and listener comprehension difficulty. However, language typically does not
maintain a strictly uniform information rate; instead, it fluctuates around a
global average. These fluctuations are often explained by factors such as
syntactic constraints, stylistic choices, or audience design. In this work, we
explore an alternative perspective: that these fluctuations may be influenced
by an implicit linguistic pressure towards periodicity, where the information
rate oscillates at regular intervals, potentially across multiple frequencies
simultaneously. We apply harmonic regression and introduce a novel extension
called time scaling to detect and test for such periodicity in information
contours. Analyzing texts in English, Spanish, German, Dutch, Basque, and
Brazilian Portuguese, we find consistent evidence of periodic patterns in
information rate. Many dominant frequencies align with discourse structure,
suggesting these oscillations reflect meaningful linguistic organization.
Beyond highlighting the connection between information rate and discourse
structure, our approach offers a general framework for uncovering structural
pressures at various levels of linguistic granularity.

</details>


### [69] [When Fairness Isn't Statistical: The Limits of Machine Learning in Evaluating Legal Reasoning](https://arxiv.org/abs/2506.03913)
*Claire Barale,Michael Rovatsos,Nehal Bhuta*

Main category: cs.CL

TL;DR: 论文探讨了机器学习在法律公平性评估中的局限性，尤其是在难民裁决等高风险领域，指出现有统计方法难以捕捉法律自由裁量权、规范复杂性和缺乏真实数据的挑战。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估机器学习方法在法律公平性评估中的有效性，尤其是在自由裁量权和复杂性较高的法律领域。

Method: 通过实证分析三种常见机器学习方法（基于特征的分析、语义聚类和预测建模）在59,000多份加拿大难民裁决数据集（AsyLex）上的表现。

Result: 结果显示这些方法产生的结果不一致甚至矛盾，预测建模依赖上下文和程序特征而非法律特征，语义聚类未能捕捉实质性法律推理。

Conclusion: 结论指出统计公平性评估的局限性，强调公平性评估需结合法律推理和制度背景，而不仅仅是数据驱动。

Abstract: Legal decisions are increasingly evaluated for fairness, consistency, and
bias using machine learning (ML) techniques. In high-stakes domains like
refugee adjudication, such methods are often applied to detect disparities in
outcomes. Yet it remains unclear whether statistical methods can meaningfully
assess fairness in legal contexts shaped by discretion, normative complexity,
and limited ground truth.
  In this paper, we empirically evaluate three common ML approaches
(feature-based analysis, semantic clustering, and predictive modeling) on a
large, real-world dataset of 59,000+ Canadian refugee decisions (AsyLex). Our
experiments show that these methods produce divergent and sometimes
contradictory signals, that predictive modeling often depends on contextual and
procedural features rather than legal features, and that semantic clustering
fails to capture substantive legal reasoning.
  We show limitations of statistical fairness evaluation, challenge the
assumption that statistical regularity equates to fairness, and argue that
current computational approaches fall short of evaluating fairness in legally
discretionary domains. We argue that evaluating fairness in law requires
methods grounded not only in data, but in legal reasoning and institutional
context.

</details>


### [70] [Compositional Generalisation for Explainable Hate Speech Detection](https://arxiv.org/abs/2506.03916)
*Agostina Calabrese,Tom Sherborne,Björn Ross,Mirella Lapata*

Main category: cs.CL

TL;DR: 论文探讨了仇恨言论检测模型的泛化问题，提出通过均衡上下文表达频率的数据集U-PLEAD提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测模型因数据集偏见和句子级标签难以泛化，需改进模型对仇恨言论结构的理解。

Method: 使用包含均衡上下文表达频率的合成数据集U-PLEAD，结合真实数据训练模型。

Result: 结合U-PLEAD和真实数据训练提升了模型的组合泛化能力，并在人类标注的PLEAD数据集上达到最优性能。

Conclusion: 均衡上下文表达频率的数据集有助于提升仇恨言论检测模型的泛化能力。

Abstract: Hate speech detection is key to online content moderation, but current models
struggle to generalise beyond their training data. This has been linked to
dataset biases and the use of sentence-level labels, which fail to teach models
the underlying structure of hate speech. In this work, we show that even when
models are trained with more fine-grained, span-level annotations (e.g.,
"artists" is labeled as target and "are parasites" as dehumanising comparison),
they struggle to disentangle the meaning of these labels from the surrounding
context. As a result, combinations of expressions that deviate from those seen
during training remain particularly difficult for models to detect. We
investigate whether training on a dataset where expressions occur with equal
frequency across all contexts can improve generalisation. To this end, we
create U-PLEAD, a dataset of ~364,000 synthetic posts, along with a novel
compositional generalisation benchmark of ~8,000 manually validated posts.
Training on a combination of U-PLEAD and real data improves compositional
generalisation while achieving state-of-the-art performance on the
human-sourced PLEAD.

</details>


### [71] [HSSBench: Benchmarking Humanities and Social Sciences Ability for Multimodal Large Language Models](https://arxiv.org/abs/2506.03922)
*Zhaolu Kang,Junhao Gong,Jiaxu Yan,Wanke Xia,Yian Wang,Ziwen Wang,Huaxuan Ding,Zhuo Cheng,Wenhao Cao,Zhiyuan Feng,Siqi He,Shannan Yan,Junzhe Chen,Xiaomin He,Chaoya Jiang,Wei Ye,Kaidong Yu,Xuelong Li*

Main category: cs.CL

TL;DR: HSSBench是一个专为评估多模态大语言模型（MLLMs）在人文学科和社会科学（HSS）任务中表现而设计的基准测试，填补了现有评测的不足。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs评测主要关注STEM领域，忽视了HSS领域对跨学科思维和知识整合的需求。

Method: 通过多领域专家与自动化代理协作生成和迭代优化样本，构建了包含13,000多个样本的HSSBench。

Result: 测试了20多个主流MLLMs，发现即使是先进模型也面临显著挑战。

Conclusion: HSSBench有望推动MLLMs在跨学科推理能力方面的研究。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated significant
potential to advance a broad range of domains. However, current benchmarks for
evaluating MLLMs primarily emphasize general knowledge and vertical
step-by-step reasoning typical of STEM disciplines, while overlooking the
distinct needs and potential of the Humanities and Social Sciences (HSS). Tasks
in the HSS domain require more horizontal, interdisciplinary thinking and a
deep integration of knowledge across related fields, which presents unique
challenges for MLLMs, particularly in linking abstract concepts with
corresponding visual representations. Addressing this gap, we present HSSBench,
a dedicated benchmark designed to assess the capabilities of MLLMs on HSS tasks
in multiple languages, including the six official languages of the United
Nations. We also introduce a novel data generation pipeline tailored for HSS
scenarios, in which multiple domain experts and automated agents collaborate to
generate and iteratively refine each sample. HSSBench contains over 13,000
meticulously designed samples, covering six key categories. We benchmark more
than 20 mainstream MLLMs on HSSBench and demonstrate that it poses significant
challenges even for state-of-the-art models. We hope that this benchmark will
inspire further research into enhancing the cross-disciplinary reasoning
abilities of MLLMs, especially their capacity to internalize and connect
knowledge across fields.

</details>


### [72] [More or Less Wrong: A Benchmark for Directional Bias in LLM Comparative Reasoning](https://arxiv.org/abs/2506.03923)
*Mohammadamin Shafiei,Hamidreza Saffari,Nafise Sadat Moosavi*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）在数学比较问题中受输入措辞影响，存在方向性框架偏差，且链式思维提示可部分缓解偏差，但效果因格式而异。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs对输入语义线索的敏感性及其对推理的影响机制。

Method: 使用MathComp基准测试（300个比较场景，14种提示变体，覆盖三种LLM家族），分析模型错误与语言引导的关系。

Result: 模型错误常反映语言引导导致的系统性偏差，链式思维提示可减少偏差，但自由形式推理更稳健。此外，加入人口身份词会放大偏差。

Conclusion: 研究揭示了标准评估中的盲点，呼吁开发框架感知的基准以诊断LLMs的推理鲁棒性和公平性。

Abstract: Large language models (LLMs) are known to be sensitive to input phrasing, but
the mechanisms by which semantic cues shape reasoning remain poorly understood.
We investigate this phenomenon in the context of comparative math problems with
objective ground truth, revealing a consistent and directional framing bias:
logically equivalent questions containing the words ``more'', ``less'', or
``equal'' systematically steer predictions in the direction of the framing
term. To study this effect, we introduce MathComp, a controlled benchmark of
300 comparison scenarios, each evaluated under 14 prompt variants across three
LLM families. We find that model errors frequently reflect linguistic steering,
systematic shifts toward the comparative term present in the prompt.
Chain-of-thought prompting reduces these biases, but its effectiveness varies:
free-form reasoning is more robust, while structured formats may preserve or
reintroduce directional drift. Finally, we show that including demographic
identity terms (e.g., ``a woman'', ``a Black person'') in input scenarios
amplifies directional drift, despite identical underlying quantities,
highlighting the interplay between semantic framing and social referents. These
findings expose critical blind spots in standard evaluation and motivate
framing-aware benchmarks for diagnosing reasoning robustness and fairness in
LLMs.

</details>


### [73] [Hanging in the Balance: Pivotal Moments in Crisis Counseling Conversations](https://arxiv.org/abs/2506.03941)
*Vivian Nguyen,Lillian Lee,Cristian Danescu-Niculescu-Mizil*

Main category: cs.CL

TL;DR: 该论文提出了一种无监督计算方法，用于实时检测对话中的关键转折点，并在心理危机咨询中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在对话中，某些关键时刻的回应可能导致截然不同的结果。开发能够检测这些时刻的系统，有助于在重要领域（如心理危机咨询）中提供辅助。

Method: 基于直觉，如果一个时刻的预期结果因后续对话内容而大幅变化，则该时刻为关键转折点。通过无监督计算方法实时检测这些时刻。

Result: 方法验证显示，检测到的关键时刻与人类感知一致（咨询师回应时间显著延长），且对话轨迹更可能在这些时刻改变。

Conclusion: 该框架可用于探索咨询师在关键时刻的回应与最终会话结果的关系，为重要对话领域提供实用工具。

Abstract: During a conversation, there can come certain moments where its outcome hangs
in the balance. In these pivotal moments, how one responds can put the
conversation on substantially different trajectories leading to significantly
different outcomes. Systems that can detect when such moments arise could
assist conversationalists in domains with highly consequential outcomes, such
as mental health crisis counseling.
  In this work, we introduce an unsupervised computational method for detecting
such pivotal moments as they happen, in an online fashion. Our approach relies
on the intuition that a moment is pivotal if our expectation of the outcome
varies widely depending on what might be said next. By applying our method to
crisis counseling conversations, we first validate it by showing that it aligns
with human perception -- counselors take significantly longer to respond during
moments detected by our method -- and with the eventual conversational
trajectory -- which is more likely to change course at these times. We then use
our framework to explore the relation of the counselor's response during
pivotal moments with the eventual outcome of the session.

</details>


### [74] [TableEval: A Real-World Benchmark for Complex, Multilingual, and Multi-Structured Table Question Answering](https://arxiv.org/abs/2506.03949)
*Junnan Zhu,Jingyi Wang,Bohan Yu,Xiaoyu Wu,Junbo Li,Lei Wang,Nan Xu*

Main category: cs.CL

TL;DR: TableEval是一个新的TableQA基准测试，旨在评估LLMs在复杂现实任务中的表现，包括多语言和多领域数据，并提出了新的评估框架SEAT。


<details>
  <summary>Details</summary>
Motivation: 现有TableQA基准测试局限于简单表格和单语言数据，无法反映实际应用中的复杂性和多样性。

Method: TableEval包含多种结构的表格（如层次表和嵌套表）和跨语言数据（中文简繁体、英文），并提出了SEAT评估框架。

Result: 实验表明SEAT与人类判断高度一致，现有LLMs在复杂TableQA任务中存在显著不足。

Conclusion: TableEval为未来改进提供了方向，数据集已公开。

Abstract: LLMs have shown impressive progress in natural language processing. However,
they still face significant challenges in TableQA, where real-world
complexities such as diverse table structures, multilingual data, and
domain-specific reasoning are crucial. Existing TableQA benchmarks are often
limited by their focus on simple flat tables and suffer from data leakage.
Furthermore, most benchmarks are monolingual and fail to capture the
cross-lingual and cross-domain variability in practical applications. To
address these limitations, we introduce TableEval, a new benchmark designed to
evaluate LLMs on realistic TableQA tasks. Specifically, TableEval includes
tables with various structures (such as concise, hierarchical, and nested
tables) collected from four domains (including government, finance, academia,
and industry reports). Besides, TableEval features cross-lingual scenarios with
tables in Simplified Chinese, Traditional Chinese, and English. To minimize the
risk of data leakage, we collect all data from recent real-world documents.
Considering that existing TableQA metrics fail to capture semantic accuracy, we
further propose SEAT, a new evaluation framework that assesses the alignment
between model responses and reference answers at the sub-question level.
Experimental results have shown that SEAT achieves high agreement with human
judgment. Extensive experiments on TableEval reveal critical gaps in the
ability of state-of-the-art LLMs to handle these complex, real-world TableQA
tasks, offering insights for future improvements. We make our dataset available
here: https://github.com/wenge-research/TableEval.

</details>


### [75] [From Real to Synthetic: Synthesizing Millions of Diversified and Complicated User Instructions with Attributed Grounding](https://arxiv.org/abs/2506.03968)
*Chiwei Zhu,Benfeng Xu,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: 论文提出了一种基于属性接地的方法，用于生成多样且复杂的指令数据，以优化大型语言模型的自动对齐。


<details>
  <summary>Details</summary>
Motivation: 当前生成合成指令的方法要么接地源有限导致分布狭窄，要么依赖简单扩展无法产生有意义的复杂轨迹。高效对齐的指令通常需要认知洞察和真实用例支持。

Method: 采用属性接地方法，包括自上而下的属性过程（将真实指令接地到特定用户）和自下而上的合成过程（利用网络文档生成情境和指令）。

Result: 构建了包含100万条指令的SynthQuestions数据集，模型在该数据集上训练后在多个基准测试中表现领先，且性能随网络语料增加持续提升。

Conclusion: 属性接地方法能有效生成多样且复杂的指令数据，显著提升模型对齐性能。

Abstract: The pursuit of diverse, complex, and large-scale instruction data is crucial
for automatically aligning large language models (LLMs). While there are
methods capable of generating synthetic instructions at scale, they either
suffer from limited grounding sources, leading to a narrow distribution, or
rely on trivial extensions that fail to produce meaningful trajectories in
terms of complexity. In contrast, instructions that benefit efficient alignment
are typically crafted with cognitive insights and grounded in real-world use
cases. In this paper, we synthesize such instructions using attributed
grounding, which involves 1) a top-down attribution process that grounds a
selective set of real instructions to situated users, and 2) a bottom-up
synthesis process that leverages web documents to first generate a situation,
then a meaningful instruction. This framework allows us to harvest diverse and
complex instructions at scale, utilizing the vast range of web documents.
Specifically, we construct a dataset of 1 million instructions, called
SynthQuestions, and demonstrate that models trained on it achieve leading
performance on several common benchmarks, with improvements that continually
scale with more web corpora. Data, models and codes will be available at
https://github.com/Ignoramus0817/SynthQuestions.

</details>


### [76] [Structured Pruning for Diverse Best-of-N Reasoning Optimization](https://arxiv.org/abs/2506.03978)
*Hieu Trung Nguyen,Bao Nguyen,Viet Anh Nguyen*

Main category: cs.CL

TL;DR: 通过选择性剪枝注意力头提升Transformer语言模型的推理能力，提出SPRINT框架动态优化剪枝配置，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 发现选择性剪枝注意力头能提升推理性能，尤其在复杂任务上，从而提出动态优化剪枝的方法。

Method: 提出SPRINT框架，通过对比学习动态选择剪枝的注意力头和层，对齐问题和头嵌入以优化推理。

Result: 在MATH500和GSM8K数据集上显著优于传统最佳选择和随机选择策略。

Conclusion: SPRINT通过动态剪枝优化推理性能，为模型剪枝提供了新视角。

Abstract: Model pruning in transformer-based language models, traditionally viewed as a
means of achieving computational savings, can enhance the model's reasoning
capabilities. In this work, we uncover a surprising phenomenon: the selective
pruning of certain attention heads leads to improvements in reasoning
performance, particularly on challenging tasks. Motivated by this observation,
we propose SPRINT, a novel contrastive learning framework that dynamically
selects the optimal head and layer to prune during inference. By aligning
question embeddings with head embeddings, SPRINT identifies those pruned-head
configurations that result in more accurate reasoning. Extensive experiments
demonstrate that our method significantly outperforms traditional best-of-$N$
and random head selection strategies on the MATH500 and GSM8K datasets.

</details>


### [77] [Voice Activity Projection Model with Multimodal Encoders](https://arxiv.org/abs/2506.03980)
*Takeshi Saga,Catherine Pelachaud*

Main category: cs.CL

TL;DR: 本文提出了一种多模态模型，结合预训练的音频和面部编码器，显著提升了对话轮转预测的性能。


<details>
  <summary>Details</summary>
Motivation: 由于社交环境的复杂性和多模态特性，人机交互中的轮转管理具有挑战性。现有基于静音时长的传统系统效果有限，而多模态VAP模型在性能上已超越之前的先进模型。

Method: 提出了一种增强的多模态VAP模型，利用预训练的音频和面部编码器捕捉细微表情，以改进轮转预测。

Result: 模型在轮转指标上表现优异，部分情况下甚至优于现有最先进模型。

Conclusion: 该模型通过多模态特征显著提升了轮转预测性能，代码和预训练模型已开源。

Abstract: Turn-taking management is crucial for any social interaction. Still, it is
challenging to model human-machine interaction due to the complexity of the
social context and its multimodal nature. Unlike conventional systems based on
silence duration, previous existing voice activity projection (VAP) models
successfully utilized a unified representation of turn-taking behaviors as
prediction targets, which improved turn-taking prediction performance.
Recently, a multimodal VAP model outperformed the previous state-of-the-art
model by a significant margin. In this paper, we propose a multimodal model
enhanced with pre-trained audio and face encoders to improve performance by
capturing subtle expressions. Our model performed competitively, and in some
cases, even better than state-of-the-art models on turn-taking metrics. All the
source codes and pretrained models are available at
https://github.com/sagatake/VAPwithAudioFaceEncoders.

</details>


### [78] [Around the World in 24 Hours: Probing LLM Knowledge of Time and Place](https://arxiv.org/abs/2506.03984)
*Carolin Holtermann,Paul Röttger,Anne Lauscher*

Main category: cs.CL

TL;DR: 该论文评估了语言模型在时间和空间联合推理上的能力，发现模型在纯时间推理上表现良好，但在时空联合任务上表现受限，且性能与模型规模和提示形式密切相关。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型在时间和空间联合推理上的能力，填补此前研究仅关注单一维度或简单环境的空白。

Method: 创建GeoTemp数据集（320k提示，覆盖289个城市、217个国家、37个时区），评估8个开放聊天模型在不同时空知识组合上的表现。

Result: 模型在纯时间任务上表现良好，性能随规模提升；时空联合任务表现受限，且与地点名称的模型困惑度相关。提示形式对性能影响显著。

Conclusion: 语言模型在时空联合推理上仍有局限，提示设计和训练数据重复性对性能有重要影响。

Abstract: Reasoning over time and space is essential for understanding our world.
However, the abilities of language models in this area are largely unexplored
as previous work has tested their abilities for logical reasoning in terms of
time and space in isolation or only in simple or artificial environments. In
this paper, we present the first evaluation of the ability of language models
to jointly reason over time and space. To enable our analysis, we create
GeoTemp, a dataset of 320k prompts covering 289 cities in 217 countries and 37
time zones. Using GeoTemp, we evaluate eight open chat models of three
different model families for different combinations of temporal and geographic
knowledge. We find that most models perform well on reasoning tasks involving
only temporal knowledge and that overall performance improves with scale.
However, performance remains constrained in tasks that require connecting
temporal and geographical information. We do not find clear correlations of
performance with specific geographic regions. Instead, we find a significant
performance increase for location names with low model perplexity, suggesting
their repeated occurrence during model training. We further demonstrate that
their performance is heavily influenced by prompt formulation - a direct
injection of geographical knowledge leads to performance gains, whereas,
surprisingly, techniques like chain-of-thought prompting decrease performance
on simpler tasks.

</details>


### [79] [Stronger Baselines for Retrieval-Augmented Generation with Long-Context Language Models](https://arxiv.org/abs/2506.03989)
*Alex Laitenberger,Christopher D. Manning,Nelson F. Liu*

Main category: cs.CL

TL;DR: 比较了多阶段和单阶段检索增强生成（RAG）方法在长上下文语言模型（LMs）中的表现，发现简单的DOS RAG方法在多任务中表现优于复杂方法。


<details>
  <summary>Details</summary>
Motivation: 探讨在长上下文语言模型能力提升的背景下，多阶段RAG方法是否仍比单阶段方法更具优势。

Method: 通过系统化调整token预算，在QA任务中对比两种多阶段RAG方法（ReadAgent和RAPTOR）与三种基线方法（包括DOS RAG）。

Result: DOS RAG在多个长上下文QA基准测试中表现优于或与复杂方法相当。

Conclusion: 建议将DOS RAG作为未来RAG评估的简单但强基线，结合新兴模型评估复杂性与效果的权衡。

Abstract: With the rise of long-context language models (LMs) capable of processing
tens of thousands of tokens in a single pass, do multi-stage
retrieval-augmented generation (RAG) pipelines still offer measurable benefits
over simpler, single-stage approaches? To assess this question, we conduct a
controlled evaluation for QA tasks under systematically scaled token budgets,
comparing two recent multi-stage pipelines, ReadAgent and RAPTOR, against three
baselines, including DOS RAG (Document's Original Structure RAG), a simple
retrieve-then-read method that preserves original passage order. Despite its
straightforward design, DOS RAG consistently matches or outperforms more
intricate methods on multiple long-context QA benchmarks. We recommend
establishing DOS RAG as a simple yet strong baseline for future RAG
evaluations, pairing it with emerging embedding and language models to assess
trade-offs between complexity and effectiveness as model capabilities evolve.

</details>


### [80] [DynTok: Dynamic Compression of Visual Tokens for Efficient and Effective Video Understanding](https://arxiv.org/abs/2506.03990)
*Hongzhi Zhang,Jingyuan Zhang,Xingguang Ji,Qi Wang,Fuzheng Zhang*

Main category: cs.CL

TL;DR: DynTok是一种动态视频令牌压缩策略，通过自适应分组和合并视觉令牌，显著减少计算开销，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 传统视频建模方法（如LLava）处理长视频时会产生大量视觉令牌，导致计算负担过重。

Method: DynTok将视觉令牌自适应分组并合并，在高信息密度区域保留内容，低密度区域实现高压缩。

Result: 令牌数量减少至原大小的44.4%，性能相当；在Video-MME和MLVU上分别达到65.3%和72.5%。

Conclusion: DynTok揭示了视频令牌表示的冗余性，为高效视频建模技术设计提供了新思路。

Abstract: Typical video modeling methods, such as LLava, represent videos as sequences
of visual tokens, which are then processed by the LLM backbone for effective
video understanding. However, this approach leads to a massive number of visual
tokens, especially for long videos. A practical solution is to first extract
relevant visual information from the large visual context before feeding it
into the LLM backbone, thereby reducing computational overhead. In this work,
we introduce DynTok, a novel \textbf{Dyn}amic video \textbf{Tok}en compression
strategy. DynTok adaptively splits visual tokens into groups and merges them
within each group, achieving high compression in regions with low information
density while preserving essential content. Our method reduces the number of
tokens to 44.4% of the original size while maintaining comparable performance.
It further benefits from increasing the number of video frames and achieves
65.3% on Video-MME and 72.5% on MLVU. By applying this simple yet effective
compression method, we expose the redundancy in video token representations and
offer insights for designing more efficient video modeling techniques.

</details>


### [81] [Words of Warmth: Trust and Sociability Norms for over 26k English Words](https://arxiv.org/abs/2506.03993)
*Saif M. Mohammad*

Main category: cs.CL

TL;DR: 论文介绍了Words of Warmth，一个大规模的手工标注词汇库，用于研究温暖（W）、信任（T）和社交性（S）的关联，并展示了其在儿童词汇习得和偏见研究中的应用。


<details>
  <summary>Details</summary>
Motivation: 社会心理学研究表明，温暖（W）和能力（C）是评估他人和群体的主要维度，但温暖的具体构成（如信任和社交性）及其发展机制尚不明确。

Method: 构建了包含26k英语词汇的Words of Warmth库，手工标注词汇与温暖、信任、社交性的关联，并验证其可靠性。

Result: 词汇关联高度可靠，可用于研究儿童词汇习得模式，并通过案例展示了其在偏见和刻板印象研究中的应用。

Conclusion: Words of Warmth为研究温暖维度的构成和发展提供了新工具，支持广泛的心理学和社会学研究。

Abstract: Social psychologists have shown that Warmth (W) and Competence (C) are the
primary dimensions along which we assess other people and groups. These
dimensions impact various aspects of our lives from social competence and
emotion regulation to success in the work place and how we view the world. More
recent work has started to explore how these dimensions develop, why they have
developed, and what they constitute. Of particular note, is the finding that
warmth has two distinct components: Trust (T) and Sociability (S). In this
work, we introduce Words of Warmth, the first large-scale repository of
manually derived word--warmth (as well as word--trust and word--sociability)
associations for over 26k English words. We show that the associations are
highly reliable. We use the lexicons to study the rate at which children
acquire WCTS words with age. Finally, we show that the lexicon enables a wide
variety of bias and stereotype research through case studies on various target
entities. Words of Warmth is freely available at:
http://saifmohammad.com/warmth.html

</details>


### [82] [Seeing What Tastes Good: Revisiting Multimodal Distributional Semantics in the Billion Parameter Era](https://arxiv.org/abs/2506.03994)
*Dan Oneata,Desmond Elliott,Stella Frank*

Main category: cs.CL

TL;DR: 论文探讨了大规模模型如何表示具体物体概念的语义特征，发现多模态图像编码器略优于纯语言模型，而纯图像编码器在非视觉属性上表现与语言模型相当。


<details>
  <summary>Details</summary>
Motivation: 研究人类学习与概念表征基于感知运动经验，而现有大规模模型是否能够有效表示具体物体概念的语义特征。

Method: 通过探测任务评估图像编码器（纯图像、多模态）和纯语言模型在预测McRae和Binder数据集属性上的表现。

Result: 多模态图像编码器略优于纯语言模型，纯图像编码器在非视觉属性上与语言模型表现相当。

Conclusion: 研究揭示了单模态学习的潜力及多模态的互补性。

Abstract: Human learning and conceptual representation is grounded in sensorimotor
experience, in contrast to state-of-the-art foundation models. In this paper,
we investigate how well such large-scale models, trained on vast quantities of
data, represent the semantic feature norms of concrete object concepts, e.g. a
ROSE is red, smells sweet, and is a flower. More specifically, we use probing
tasks to test which properties of objects these models are aware of. We
evaluate image encoders trained on image data alone, as well as
multimodally-trained image encoders and language-only models, on predicting an
extended denser version of the classic McRae norms and the newer Binder dataset
of attribute ratings. We find that multimodal image encoders slightly
outperform language-only approaches, and that image-only encoders perform
comparably to the language models, even on non-visual attributes that are
classified as "encyclopedic" or "function". These results offer new insights
into what can be learned from pure unimodal learning, and the complementarity
of the modalities.

</details>


### [83] [QQSUM: A Novel Task and Model of Quantitative Query-Focused Summarization for Review-based Product Question Answering](https://arxiv.org/abs/2506.04020)
*An Quang Tang,Xiuzhen Zhang,Minh Ngoc Dinh,Zhuang Li*

Main category: cs.CL

TL;DR: 论文提出了一种新任务QQSUM，通过量化用户意见的多样性生成代表性关键点（KPs），并扩展了RAG模型为QQSUM-RAG，以提升回答的多样性和量化准确性。


<details>
  <summary>Details</summary>
Motivation: 现有PQA系统仅能生成单一视角的回答，无法反映用户意见的多样性，因此需要一种能总结并量化多样意见的方法。

Method: 提出QQSUM任务，扩展RAG模型为QQSUM-RAG，采用少样本学习联合训练KP检索器和KP生成器。

Result: QQSUM-RAG在文本质量和意见量化准确性上优于现有RAG基线。

Conclusion: QQSUM-RAG能有效捕捉多样意见并量化其普遍性，为PQA任务提供了更全面的解决方案。

Abstract: Review-based Product Question Answering (PQA) allows e-commerce platforms to
automatically address customer queries by leveraging insights from user
reviews. However, existing PQA systems generate answers with only a single
perspective, failing to capture the diversity of customer opinions. In this
paper we introduce a novel task Quantitative Query-Focused Summarization
(QQSUM), which aims to summarize diverse customer opinions into representative
Key Points (KPs) and quantify their prevalence to effectively answer user
queries. While Retrieval-Augmented Generation (RAG) shows promise for PQA, its
generated answers still fall short of capturing the full diversity of
viewpoints. To tackle this challenge, our model QQSUM-RAG, which extends RAG,
employs few-shot learning to jointly train a KP-oriented retriever and a KP
summary generator, enabling KP-based summaries that capture diverse and
representative opinions. Experimental results demonstrate that QQSUM-RAG
achieves superior performance compared to state-of-the-art RAG baselines in
both textual quality and quantification accuracy of opinions. Our source code
is available at: https://github.com/antangrocket1312/QQSUMM

</details>


### [84] [AI Agents for Conversational Patient Triage: Preliminary Simulation-Based Evaluation with Real-World EHR Data](https://arxiv.org/abs/2506.04032)
*Sina Rashidian,Nan Li,Jonathan Amar,Jong Ha Lee,Sam Pugh,Eric Yang,Geoff Masterson,Myoung Cha,Yugang Jia,Akhil Vaid*

Main category: cs.CL

TL;DR: 开发了一个基于真实电子健康记录（EHR）数据的患者模拟器，用于训练和测试医疗AI代理，模拟效果得到临床专家高度认可。


<details>
  <summary>Details</summary>
Motivation: 为医疗AI代理提供真实、多样化的测试环境，提升其诊断和对话能力。

Method: 从真实EHR数据构建患者情景，通过AI代理进行多轮对话模拟，并由临床专家评估模拟效果。

Result: 模拟器在97.7%的情况下与患者情景一致，对话摘要99%相关。

Conclusion: 该方法能有效构建患者模拟器，支持大规模训练和测试医疗AI代理。

Abstract: Background: We present a Patient Simulator that leverages real world patient
encounters which cover a broad range of conditions and symptoms to provide
synthetic test subjects for development and testing of healthcare agentic
models. The simulator provides a realistic approach to patient presentation and
multi-turn conversation with a symptom-checking agent. Objectives: (1) To
construct and instantiate a Patient Simulator to train and test an AI health
agent, based on patient vignettes derived from real EHR data. (2) To test the
validity and alignment of the simulated encounters provided by the Patient
Simulator to expert human clinical providers. (3) To illustrate the evaluation
framework of such an LLM system on the generated realistic, data-driven
simulations -- yielding a preliminary assessment of our proposed system.
Methods: We first constructed realistic clinical scenarios by deriving patient
vignettes from real-world EHR encounters. These vignettes cover a variety of
presenting symptoms and underlying conditions. We then evaluate the performance
of the Patient Simulator as a simulacrum of a real patient encounter across
over 500 different patient vignettes. We leveraged a separate AI agent to
provide multi-turn questions to obtain a history of present illness. The
resulting multiturn conversations were evaluated by two expert clinicians.
Results: Clinicians scored the Patient Simulator as consistent with the patient
vignettes in those same 97.7% of cases. The extracted case summary based on the
conversation history was 99% relevant. Conclusions: We developed a methodology
to incorporate vignettes derived from real healthcare patient data to build a
simulation of patient responses to symptom checking agents. The performance and
alignment of this Patient Simulator could be used to train and test a
multi-turn conversational AI agent at scale.

</details>


### [85] [The mutual exclusivity bias of bilingual visually grounded speech models](https://arxiv.org/abs/2506.04037)
*Dan Oneata,Leanne Nortje,Yevgen Matusevych,Herman Kamper*

Main category: cs.CL

TL;DR: 双语视觉语音模型（VGS）在语言学习中的互斥性（ME）偏置较弱，部分原因是视觉嵌入的方差较小。


<details>
  <summary>Details</summary>
Motivation: 研究双语儿童在语言学习中可能较少使用互斥性（ME）策略的现象，并通过双语VGS模型进行验证。

Method: 训练双语VGS模型（英语、法语、荷兰语组合），比较其与单语模型的ME偏置差异。

Result: 双语模型的ME偏置普遍弱于单语模型，视觉嵌入方差较小导致混淆增加。

Conclusion: 双语VGS模型的ME偏置较弱，揭示了视觉嵌入方差与ME偏置的关系，为ME偏置的成因提供了新见解。

Abstract: Mutual exclusivity (ME) is a strategy where a novel word is associated with a
novel object rather than a familiar one, facilitating language learning in
children. Recent work has found an ME bias in a visually grounded speech (VGS)
model trained on English speech with paired images. But ME has also been
studied in bilingual children, who may employ it less due to cross-lingual
ambiguity. We explore this pattern computationally using bilingual VGS models
trained on combinations of English, French, and Dutch. We find that bilingual
models generally exhibit a weaker ME bias than monolingual models, though
exceptions exist. Analyses show that the combined visual embeddings of
bilingual models have a smaller variance for familiar data, partly explaining
the increase in confusion between novel and familiar concepts. We also provide
new insights into why the ME bias exists in VGS models in the first place. Code
and data: https://github.com/danoneata/me-vgs

</details>


### [86] [LexTime: A Benchmark for Temporal Ordering of Legal Events](https://arxiv.org/abs/2506.04041)
*Claire Barale,Leslie Barrett,Vikram Sunil Bajaj,Michael Rovatsos*

Main category: cs.CL

TL;DR: LexTime是首个评估LLMs在法务文本中事件排序能力的数据集，包含512个美国联邦投诉案例，标注事件对及其时序关系。研究发现LLMs在法务事件排序上表现优于叙事（+10.5%），长上下文和隐式事件提升准确率至80.8%，但法律语言复杂性仍是挑战。


<details>
  <summary>Details</summary>
Motivation: 现有数据集缺乏专家语言评估，无法理解LLMs在法务文本中如何管理事件排序，因此需要专门的数据集LexTime填补这一空白。

Method: 构建LexTime数据集，包含512个法务文本实例，标注事件对及其时序关系，并分析LLMs在不同上下文长度、显隐事件对和法律语言特征下的表现。

Result: LLMs在法务事件排序上准确率高于叙事（+10.5%），长上下文和隐式事件对准确率提升至80.8%，但法律语言复杂性和嵌套从句仍是挑战。

Conclusion: 研究表明需针对法务语言设计特定建模策略，以提升LLMs在时序事件推理中的表现。

Abstract: Temporal reasoning in legal texts is important for applications like case law
analysis and compliance monitoring. However, existing datasets lack expert
language evaluation, leaving a gap in understanding how LLMs manage event
ordering in legal contexts. We introduce LexTime, the first dataset designed to
evaluate LLMs' event ordering capabilities in legal language, consisting of 512
instances from U.S. Federal Complaints with annotated event pairs and their
temporal relations. Our findings show that (1) LLMs are more accurate on legal
event ordering than on narrative (up to +10.5%); (2) longer input contexts and
implicit events boost accuracy, reaching 80.8% for implicit-explicit event
pairs; (3) legal linguistic complexities and nested clauses remain a challenge.
We investigate how context length, explicit vs implicit event pairs, and legal
language features affect model performance, demonstrating the need for specific
modeling strategies to enhance temporal event reasoning.

</details>


### [87] [Unveiling and Eliminating the Shortcut Learning for Locate-Then-Edit Knowledge Editing via Both Subject and Relation Awareness](https://arxiv.org/abs/2506.04042)
*Xiyu Liu,Zhengxiao Liu,Naibin Gu,Zheng Lin,Ji Xiang,Weiping Wang*

Main category: cs.CL

TL;DR: 论文提出了一种两阶段优化方法，解决知识编辑中的捷径学习问题，实现可控的知识编辑。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法在优化过程中倾向于过度学习主体特征而忽视关系特征，导致不可控的副作用。

Method: 提出两阶段优化过程，平衡主体特征和关系特征的学习。

Result: 实验证明该方法有效防止捷径学习，实现最优性能。

Conclusion: 两阶段优化方法为可控知识编辑提供了有效解决方案。

Abstract: Knowledge editing aims to alternate the target knowledge predicted by large
language models while ensuring the least side effects on unrelated knowledge.
An effective way to achieve knowledge editing is to identify pivotal parameters
for predicting factual associations and modify them with an optimization
process to update the predictions. However, these locate-then-edit methods are
uncontrollable since they tend to modify most unrelated relations connected to
the subject of target editing. We unveil that this failure of controllable
editing is due to a shortcut learning issue during the optimization process.
Specifically, we discover two crucial features that are the subject feature and
the relation feature for models to learn during optimization, but the current
optimization process tends to over-learning the subject feature while
neglecting the relation feature. To eliminate this shortcut learning of the
subject feature, we propose a novel two-stage optimization process that
balances the learning of the subject feature and the relation feature.
Experimental results demonstrate that our approach successfully prevents
knowledge editing from shortcut learning and achieves the optimal overall
performance, contributing to controllable knowledge editing.

</details>


### [88] [Think Like a Person Before Responding: A Multi-Faceted Evaluation of Persona-Guided LLMs for Countering Hate](https://arxiv.org/abs/2506.04043)
*Mikel K. Ngueajio,Flor Miriam Plaza-del-Arco,Yi-Ling Chung,Danda B. Rawat,Amanda Cercas Curry*

Main category: cs.CL

TL;DR: 论文提出了一种评估大型语言模型生成反叙事（CN）的框架，发现其存在冗长、可读性不足及伦理风险。


<details>
  <summary>Details</summary>
Motivation: 在线仇恨言论的自动反叙事策略虽有效，但其情感基调、可访问性和伦理风险仍需关注。

Method: 使用GPT-4o-Mini、Cohere的CommandR-7B和Meta的LLaMA 3.1-70B，评估三种提示策略在MT-Conan和HatEval数据集上的表现。

Result: LLM生成的反叙事通常冗长且适合大学文化水平人群，情感引导提示能提高共情和可读性，但安全性和有效性仍有问题。

Conclusion: 需进一步优化反叙事的可访问性和伦理安全性。

Abstract: Automated counter-narratives (CN) offer a promising strategy for mitigating
online hate speech, yet concerns about their affective tone, accessibility, and
ethical risks remain. We propose a framework for evaluating Large Language
Model (LLM)-generated CNs across four dimensions: persona framing, verbosity
and readability, affective tone, and ethical robustness. Using GPT-4o-Mini,
Cohere's CommandR-7B, and Meta's LLaMA 3.1-70B, we assess three prompting
strategies on the MT-Conan and HatEval datasets. Our findings reveal that
LLM-generated CNs are often verbose and adapted for people with college-level
literacy, limiting their accessibility. While emotionally guided prompts yield
more empathetic and readable responses, there remain concerns surrounding
safety and effectiveness.

</details>


### [89] [Lacuna Inc. at SemEval-2025 Task 4: LoRA-Enhanced Influence-Based Unlearning for LLMs](https://arxiv.org/abs/2506.04044)
*Aleksey Kudelya,Alexander Shirnin*

Main category: cs.CL

TL;DR: LIBU是一种结合LoRA和影响函数的轻量级算法，用于从大型语言模型中移除特定知识，而无需从头训练。


<details>
  <summary>Details</summary>
Motivation: 解决从大型语言模型中移除敏感知识的问题，同时保持模型的整体性能。

Method: 结合影响函数移除数据对模型的影响，并使用二阶优化稳定模型性能。

Result: 实验表明，LIBU适用于多种任务中的LLM知识移除。

Conclusion: LIBU是一种高效且轻量的解决方案，适用于LLM的知识移除任务。

Abstract: This paper describes LIBU (LoRA enhanced influence-based unlearning), an
algorithm to solve the task of unlearning - removing specific knowledge from a
large language model without retraining from scratch and compromising its
overall utility (SemEval-2025 Task 4: Unlearning sensitive content from Large
Language Models). The algorithm combines classical \textit{influence functions}
to remove the influence of the data from the model and \textit{second-order
optimization} to stabilize the overall utility. Our experiments show that this
lightweight approach is well applicable for unlearning LLMs in different kinds
of task.

</details>


### [90] [On Support Samples of Next Word Prediction](https://arxiv.org/abs/2506.04047)
*Yuqian Li,Yupei Du,Yufang Liu,Feifei Feng,Mou Xiao Feng,Yuanbin Wu*

Main category: cs.CL

TL;DR: 该论文通过数据中心的解释性方法，研究了语言模型在预测任务中的决策依据，揭示了支持样本和非支持样本在模型训练和泛化中的不同作用。


<details>
  <summary>Details</summary>
Motivation: 理解语言模型决策背后的原理是一个挑战，论文旨在通过数据中心的解释性方法揭示模型行为的底层机制。

Method: 使用表示定理分析语言模型中的支持样本和非支持样本，研究它们在预测任务中的作用。

Result: 支持样本是固有属性，可在训练前预测；非支持样本虽对直接预测影响较小，但在防止过拟合和形成中间表示中起关键作用。

Conclusion: 研究揭示了数据与模型决策之间的相互作用，为理解语言模型的行为和解释性提供了新视角。

Abstract: Language models excel in various tasks by making complex decisions, yet
understanding the rationale behind these decisions remains a challenge. This
paper investigates \emph{data-centric interpretability} in language models,
focusing on the next-word prediction task. Using representer theorem, we
identify two types of \emph{support samples}-those that either promote or deter
specific predictions. Our findings reveal that being a support sample is an
intrinsic property, predictable even before training begins. Additionally,
while non-support samples are less influential in direct predictions, they play
a critical role in preventing overfitting and shaping generalization and
representation learning. Notably, the importance of non-support samples
increases in deeper layers, suggesting their significant role in intermediate
representation formation.These insights shed light on the interplay between
data and model decisions, offering a new dimension to understanding language
model behavior and interpretability.

</details>


### [91] [Explainability-Based Token Replacement on LLM-Generated Text](https://arxiv.org/abs/2506.04050)
*Hadi Mohammadi,Anastasia Giachanou,Daniel L. Oberski,Ayoub Bagheri*

Main category: cs.CL

TL;DR: 本文研究了如何利用可解释AI（XAI）方法降低AI生成文本（AIGT）的可检测性，并提出了一种基于集成分类器的检测方法。通过替换关键令牌，AIGT的检测难度显著降低，但集成分类器仍能保持高性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）生成的文本接近人类水平，但其输出仍容易被检测。研究旨在利用XAI方法减少AIGT的可检测性，并开发更鲁棒的检测策略。

Method: 训练集成分类器区分AIGT与人类文本，使用SHAP和LIME识别关键令牌，提出四种基于可解释性的令牌替换策略。

Result: 令牌替换策略显著降低了单分类器的检测能力，但集成分类器在多语言和多领域中表现稳健。

Conclusion: XAI方法可通过关注关键令牌降低AIGT的可检测性，但需依赖鲁棒的集成检测策略以应对不断演变的隐藏方法。

Abstract: Generative models, especially large language models (LLMs), have shown
remarkable progress in producing text that appears human-like. However, they
often exhibit patterns that make their output easier to detect than text
written by humans. In this paper, we investigate how explainable AI (XAI)
methods can be used to reduce the detectability of AI-generated text (AIGT)
while also introducing a robust ensemble-based detection approach. We begin by
training an ensemble classifier to distinguish AIGT from human-written text,
then apply SHAP and LIME to identify tokens that most strongly influence its
predictions. We propose four explainability-based token replacement strategies
to modify these influential tokens. Our findings show that these token
replacement approaches can significantly diminish a single classifier's ability
to detect AIGT. However, our ensemble classifier maintains strong performance
across multiple languages and domains, showing that a multi-model approach can
mitigate the impact of token-level manipulations. These results show that XAI
methods can make AIGT harder to detect by focusing on the most influential
tokens. At the same time, they highlight the need for robust, ensemble-based
detection strategies that can adapt to evolving approaches for hiding AIGT.

</details>


### [92] [High Accuracy, Less Talk (HALT): Reliable LLMs through Capability-Aligned Finetuning](https://arxiv.org/abs/2506.04051)
*Tim Franzmeyer,Archie Sravankumar,Lijuan Liu,Yuning Mao,Rui Hou,Sinong Wang,Jakob N. Foerster,Luke Zettlemoyer,Madian Khabsa*

Main category: cs.CL

TL;DR: HALT方法通过后训练LLM，使其仅在确信正确时生成内容，否则部分或完全放弃回答，显著提高了回答的正确性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM因缺乏知识或能力而产生的幻觉问题，即生成不正确的内容。

Method: 将预训练LLM的响应拆分为事实片段，利用真实信息识别错误片段，并通过移除或替换为“Unsure from Here”进行微调。

Result: 在四个领域中，HALT平均提高响应片段的正确性15%，F1分数提升4%，最高正确性模型从51%提升至87%。

Conclusion: HALT有效平衡了回答完整性与正确性，显著提升了LLM的可靠性。

Abstract: Large Language Models (LLMs) currently respond to every prompt. However, they
can produce incorrect answers when they lack knowledge or capability -- a
problem known as hallucination. We instead propose post-training an LLM to
generate content only when confident in its correctness and to otherwise
(partially) abstain. Specifically, our method, HALT, produces
capability-aligned post-training data that encodes what the model can and
cannot reliably generate. We generate this data by splitting responses of the
pretrained LLM into factual fragments (atomic statements or reasoning steps),
and use ground truth information to identify incorrect fragments. We achieve
capability-aligned finetuning responses by either removing incorrect fragments
or replacing them with "Unsure from Here" -- according to a tunable threshold
that allows practitioners to trade off response completeness and mean
correctness of the response's fragments. We finetune four open-source models
for biography writing, mathematics, coding, and medicine with HALT for three
different trade-off thresholds. HALT effectively trades off response
completeness for correctness, increasing the mean correctness of response
fragments by 15% on average, while resulting in a 4% improvement in the F1
score (mean of completeness and correctness of the response) compared to the
relevant baselines. By tuning HALT for highest correctness, we train a single
reliable Llama3-70B model with correctness increased from 51% to 87% across all
four domains while maintaining 53% of the response completeness achieved with
standard finetuning.

</details>


### [93] [Progressive Mastery: Customized Curriculum Learning with Guided Prompting for Mathematical Reasoning](https://arxiv.org/abs/2506.04065)
*Muling Wu,Qi Qian,Wenhao Liu,Xiaohua Wang,Zisu Huang,Di Liang,LI Miao,Shihan Dou,Changze Lv,Zhenghua Wang,Zhibo Xu,Lina Chen,Tianlong Li,Xiaoqing Zheng,Xuanjing Huang*

Main category: cs.CL

TL;DR: 论文提出了一种名为定制化课程学习（CCL）的新框架，通过模型自适应难度定义和动态提示技术，显著提升了大型语言模型在推理任务中的样本利用率和性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在推理任务中表现优异，但训练后存在样本利用率低和难度样本处理不灵活的问题。

Method: CCL框架包含两个创新点：1）模型自适应难度定义，根据模型能力定制课程数据集；2）动态提示技术（Guided Prompting），通过策略性提示降低样本难度。

Result: 在监督微调和强化学习的实验中，CCL在五个数学推理基准测试中显著优于统一训练方法。

Conclusion: CCL有效提升了样本利用率和模型性能，适用于多种训练范式。

Abstract: Large Language Models (LLMs) have achieved remarkable performance across
various reasoning tasks, yet post-training is constrained by inefficient sample
utilization and inflexible difficulty samples processing. To address these
limitations, we propose Customized Curriculum Learning (CCL), a novel framework
with two key innovations. First, we introduce model-adaptive difficulty
definition that customizes curriculum datasets based on each model's individual
capabilities rather than using predefined difficulty metrics. Second, we
develop "Guided Prompting," which dynamically reduces sample difficulty through
strategic hints, enabling effective utilization of challenging samples that
would otherwise degrade performance. Comprehensive experiments on supervised
fine-tuning and reinforcement learning demonstrate that CCL significantly
outperforms uniform training approaches across five mathematical reasoning
benchmarks, confirming its effectiveness across both paradigms in enhancing
sample utilization and model performance.

</details>


### [94] [LaF-GRPO: In-Situ Navigation Instruction Generation for the Visually Impaired via GRPO with LLM-as-Follower Reward](https://arxiv.org/abs/2506.04070)
*Yi Zhao,Siqi Wang,Jing Li*

Main category: cs.CL

TL;DR: 该研究提出了一种名为LaF-GRPO的方法，利用大型语言模型（LLM）模拟视障用户反应，生成奖励以指导视觉语言模型（VLM）的训练，从而提升导航指令的实用性。同时，研究还开源了一个包含27k样本的基准数据集NIG4VI，用于训练和测试。实验结果表明，该方法在定量指标和指令直观性上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为视障人士生成精确、实用的导航指令是一个重要但研究较少的领域。现有方法通常依赖昂贵的真实数据，且指令实用性不足。

Method: 提出LaF-GRPO方法，利用LLM模拟视障用户反应生成奖励，指导VLM的后训练。同时开源NIG4VI基准数据集，支持详细的开放式指令生成。

Result: 实验显示，LaF-GRPO在定量指标上显著提升（如BLEU +14%，METEOR 0.542 vs. GPT-4o的0.323），并生成更直观、安全的指令。

Conclusion: LaF-GRPO方法有效提升了导航指令的实用性，同时减少了真实数据的需求。NIG4VI数据集为未来研究提供了重要资源。

Abstract: Navigation instruction generation for visually impaired (VI) individuals
(NIG-VI) is critical yet relatively underexplored. This study, hence, focuses
on producing precise, in-situ, step-by-step navigation instructions that are
practically usable by VI users. Concretely, we propose LaF-GRPO
(LLM-as-Follower GRPO), where an LLM simulates VI user responses to generate
rewards guiding the Vision-Language Model (VLM) post-training. This enhances
instruction usability while reducing costly real-world data needs. To
facilitate training and testing, we introduce NIG4VI, a 27k-sample open-sourced
benchmark. It provides diverse navigation scenarios with accurate spatial
coordinates, supporting detailed, open-ended in-situ instruction generation.
Experiments on NIG4VI show the effectiveness of LaF-GRPO by quantitative
metrics (e.g., Zero-(LaF-GRPO) boosts BLEU +14\%; SFT+(LaF-GRPO) METEOR 0.542
vs. GPT-4o's 0.323) and yields more intuitive, safer instructions. Code and
benchmark are available at
\href{https://github.com/YiyiyiZhao/NIG4VI}{https://github.com/YiyiyiZhao/NIG4VI}.

</details>


### [95] [Controlling Difficulty of Generated Text for AI-Assisted Language Learning](https://arxiv.org/abs/2506.04072)
*Meiqing Jin,Liam Dugan,Chris Callison-Burch*

Main category: cs.CL

TL;DR: 研究探讨了如何通过可控生成技术调整大语言模型（LLM）的输出，以更好地支持初学者语言学习，并引入了一种新的评估指标Token Miss Rate（TMR）。


<details>
  <summary>Details</summary>
Motivation: 传统LLM生成的文本复杂度较高，不适合初学者（CEFR: A1-A2），因此需要探索无需微调的方法来适配初学者需求。

Method: 采用模块化可控生成技术（如未来判别器）调整LLM输出，并通过自动指标和用户研究（日语学习者）评估效果。

Result: 未来判别器显著提高了输出可理解性（从40.4%提升至84.3%），并验证了TMR指标与人类判断的强相关性。

Conclusion: 研究为AI辅助语言学习提供了有效工具和方法，并公开了代码、模型和数据以支持未来研究。

Abstract: Practicing conversations with large language models (LLMs) presents a
promising alternative to traditional in-person language learning. However, most
LLMs generate text at a near-native level of complexity, making them ill-suited
for beginner learners (CEFR: A1-A2). In this paper, we investigate whether
controllable generation techniques -- specifically modular methods that do not
require model fine-tuning -- can adapt LLM outputs to better support absolute
beginners. We evaluate these methods through both automatic metrics and a user
study with university-level learners of Japanese. Our findings show that while
prompting alone fails to control output difficulty, the use of future
discriminators (Yang and Klein, 2021) significantly improves output
comprehensibility (from 40.4\% to 84.3\%). We further introduce a novel
token-level evaluation metric, Token Miss Rate (TMR), that quantifies the
proportion of incomprehensible tokens per utterance and correlates strongly
with human judgments. To support future research in AI-assisted language
learning, we release our code, models, annotation tools, and dataset.

</details>


### [96] [Acoustically Precise Hesitation Tagging Is Essential for End-to-End Verbatim Transcription Systems](https://arxiv.org/abs/2506.04076)
*Jhen-Ke Lin,Hao-Chien Lu,Chung-Chun Wang,Hong-Yun Lin,Berlin Chen*

Main category: cs.CL

TL;DR: 通过微调Whisper模型并使用不同标注方案，研究显示精确标注填充词能显著提升ASR对非母语口语转录的准确性。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别（ASR）系统在处理非流利口语时，常忽略或泛化犹豫现象，导致重要声学细节丢失，影响后续任务如错误分析和反馈。

Method: 使用低秩适应（LoRA）微调Whisper模型，基于Speak & Improve 2025语料库，比较三种标注方案：去除犹豫（Pure）、通用标签（Rich）和由Gemini 2.0 Flash推断的声学精确填充词（Extra）。

Result: "Extra"方案在挑战系统中取得5.81% WER，后续实验中Whisper Large V3 Turbo微调后WER降至5.5%，比"Pure"方案（6.2% WER）相对提升11.3%。

Conclusion: 精确且真实的填充词标注能显著提升ASR对非母语口语的转录准确性。

Abstract: Verbatim transcription for automatic speaking assessment demands accurate
capture of disfluencies, crucial for downstream tasks like error analysis and
feedback. However, many ASR systems discard or generalize hesitations, losing
important acoustic details. We fine-tune Whisper models on the Speak & Improve
2025 corpus using low-rank adaptation (LoRA), without recourse to external
audio training data. We compare three annotation schemes: removing hesitations
(Pure), generic tags (Rich), and acoustically precise fillers inferred by
Gemini 2.0 Flash from existing audio-transcript pairs (Extra). Our challenge
system achieved 6.47% WER (Pure) and 5.81% WER (Extra). Post-challenge
experiments reveal that fine-tuning Whisper Large V3 Turbo with the "Extra"
scheme yielded a 5.5% WER, an 11.3% relative improvement over the "Pure" scheme
(6.2% WER). This demonstrates that explicit, realistic filled-pause labeling
significantly enhances ASR accuracy for verbatim L2 speech transcription.

</details>


### [97] [A Novel Data Augmentation Approach for Automatic Speaking Assessment on Opinion Expressions](https://arxiv.org/abs/2506.04077)
*Chung-Chun Wang,Jhen-Ke Lin,Hao-Chien Lu,Hong-Yun Lin,Berlin Chen*

Main category: cs.CL

TL;DR: 论文提出了一种利用大语言模型生成多样化响应、合成语音并结合动态重要性损失的方法，以解决自动口语评估中数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 解决自动口语评估中因标注录音稀缺导致的提示多样性和评分可靠性问题。

Method: 利用大语言模型生成多样化响应，通过语音合成转换为语音，结合动态重要性损失训练，并使用多模态大语言模型预测分数。

Result: 在LTTC数据集上，该方法优于依赖真实数据或传统增强的方法。

Conclusion: 该方法有效缓解了低资源限制，支持结合跨模态信息的意见表达自动评估。

Abstract: Automated speaking assessment (ASA) on opinion expressions is often hampered
by the scarcity of labeled recordings, which restricts prompt diversity and
undermines scoring reliability. To address this challenge, we propose a novel
training paradigm that leverages a large language models (LLM) to generate
diverse responses of a given proficiency level, converts responses into
synthesized speech via speaker-aware text-to-speech synthesis, and employs a
dynamic importance loss to adaptively reweight training instances based on
feature distribution differences between synthesized and real speech.
Subsequently, a multimodal large language model integrates aligned textual
features with speech signals to predict proficiency scores directly.
Experiments conducted on the LTTC dataset show that our approach outperforms
methods relying on real data or conventional augmentation, effectively
mitigating low-resource constraints and enabling ASA on opinion expressions
with cross-modal information.

</details>


### [98] [LLMEval-Med: A Real-world Clinical Benchmark for Medical LLMs with Physician Validation](https://arxiv.org/abs/2506.04078)
*Ming Zhang,Yujiong Shen,Zelin Li,Huayu Sha,Binze Hu,Yuhui Wang,Chenhao Huang,Shichun Liu,Jingqi Tong,Changhao Jiang,Mingxu Chai,Zhiheng Xi,Shihan Dou,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: LLMEval-Med是一个新的医学基准测试，覆盖五个核心医学领域，包含2,996个问题，基于真实电子健康记录和专家设计的临床场景，旨在解决现有医学基准的局限性。


<details>
  <summary>Details</summary>
Motivation: 医学应用需要高准确性，现有医学基准在问题设计、数据来源和评估方法上存在不足，无法满足复杂推理的需求。

Method: 提出LLMEval-Med基准，设计自动化评估流程，结合专家开发的检查表和LLM-as-Judge框架，并通过人机一致性分析验证机器评分。

Result: 评估了13种LLM，涵盖专业医学模型、开源模型和闭源模型，为医学领域安全有效部署LLM提供了见解。

Conclusion: LLMEval-Med通过真实数据和动态优化提升了医学LLM评估的可靠性，数据集已公开。

Abstract: Evaluating large language models (LLMs) in medicine is crucial because
medical applications require high accuracy with little room for error. Current
medical benchmarks have three main types: medical exam-based, comprehensive
medical, and specialized assessments. However, these benchmarks have
limitations in question design (mostly multiple-choice), data sources (often
not derived from real clinical scenarios), and evaluation methods (poor
assessment of complex reasoning). To address these issues, we present
LLMEval-Med, a new benchmark covering five core medical areas, including 2,996
questions created from real-world electronic health records and expert-designed
clinical scenarios. We also design an automated evaluation pipeline,
incorporating expert-developed checklists into our LLM-as-Judge framework.
Furthermore, our methodology validates machine scoring through human-machine
agreement analysis, dynamically refining checklists and prompts based on expert
feedback to ensure reliability. We evaluate 13 LLMs across three categories
(specialized medical models, open-source models, and closed-source models) on
LLMEval-Med, providing valuable insights for the safe and effective deployment
of LLMs in medical domains. The dataset is released in
https://github.com/llmeval/LLMEval-Med.

</details>


### [99] [EuroLLM-9B: Technical Report](https://arxiv.org/abs/2506.04079)
*Pedro Henrique Martins,João Alves,Patrick Fernandes,Nuno M. Guerreiro,Ricardo Rei,Amin Farajian,Mateusz Klimaszewski,Duarte M. Alves,José Pombal,Manuel Faysse,Pierre Colombo,François Yvon,Barry Haddow,José G. C. de Souza,Alexandra Birch,André F. T. Martins*

Main category: cs.CL

TL;DR: EuroLLM-9B是一个支持24种欧盟官方语言和11种其他语言的大型语言模型，旨在解决欧洲语言在现有开放模型中的不足。


<details>
  <summary>Details</summary>
Motivation: 欧洲语言在现有开放大型语言模型中代表性不足，EuroLLM-9B旨在填补这一空白。

Method: 开发包括分词器设计、架构规范、数据过滤和训练流程，并引入EuroFilter和EuroBlocks-Synthetic数据集。

Result: 在多语言基准测试和机器翻译任务中表现优异，成为同类欧洲开源模型的领先者。

Conclusion: EuroLLM-9B为欧洲语言提供了强大的支持，并公开了模型、工具和数据集以促进研究和应用。

Abstract: This report presents EuroLLM-9B, a large language model trained from scratch
to support the needs of European citizens by covering all 24 official European
Union languages and 11 additional languages. EuroLLM addresses the issue of
European languages being underrepresented and underserved in existing open
large language models. We provide a comprehensive overview of EuroLLM-9B's
development, including tokenizer design, architectural specifications, data
filtering, and training procedures. We describe the pre-training data
collection and filtering pipeline, including the creation of EuroFilter, an
AI-based multilingual filter, as well as the design of EuroBlocks-Synthetic, a
novel synthetic dataset for post-training that enhances language coverage for
European languages. Evaluation results demonstrate EuroLLM-9B's competitive
performance on multilingual benchmarks and machine translation tasks,
establishing it as the leading open European-made LLM of its size. To support
open research and adoption, we release all major components of this work,
including the base and instruction-tuned models, the EuroFilter classifier, and
the synthetic post-training dataset.

</details>


### [100] [TextAtari: 100K Frames Game Playing with Language Agents](https://arxiv.org/abs/2506.04098)
*Wenhao Li,Wenwu Li,Chuyun Shen,Junjie Sheng,Zixiao Huang,Di Wu,Yun Hua,Wei Yin,Xiangfeng Wang,Hongyuan Zha,Bo Jin*

Main category: cs.CL

TL;DR: TextAtari是一个评估语言代理在长时程决策任务（最多10万步）上的基准测试，通过将Atari游戏的视觉状态转化为文本描述，创建了一个结合决策与自然语言处理的挑战性测试平台。


<details>
  <summary>Details</summary>
Motivation: 研究语言代理在长时程决策任务中的表现，探索其语义理解、指令理解和专家示范对决策的影响。

Method: 使用AtariARI框架将100个Atari任务转化为文本描述，评估三种语言模型（Qwen2.5-7B、Gemma-7B、Llama3.1-8B）在三种代理框架（零样本、少样本思维链、反思推理）下的表现。

Result: 语言代理在长时程规划任务中与人类玩家存在显著性能差距，尤其在顺序推理、状态跟踪和战略规划方面。

Conclusion: TextAtari为语言模型与规划研究的交叉领域提供了标准化评估工具和基线实现。

Abstract: We present TextAtari, a benchmark for evaluating language agents on very
long-horizon decision-making tasks spanning up to 100,000 steps. By translating
the visual state representations of classic Atari games into rich textual
descriptions, TextAtari creates a challenging test bed that bridges sequential
decision-making with natural language processing. The benchmark includes nearly
100 distinct tasks with varying complexity, action spaces, and planning
horizons, all rendered as text through an unsupervised representation learning
framework (AtariARI). We evaluate three open-source large language models
(Qwen2.5-7B, Gemma-7B, and Llama3.1-8B) across three agent frameworks
(zero-shot, few-shot chain-of-thought, and reflection reasoning) to assess how
different forms of prior knowledge affect performance on these long-horizon
challenges. Four scenarios-Basic, Obscured, Manual Augmentation, and
Reference-based-investigate the impact of semantic understanding, instruction
comprehension, and expert demonstrations on agent decision-making. Our results
reveal significant performance gaps between language agents and human players
in extensive planning tasks, highlighting challenges in sequential reasoning,
state tracking, and strategic planning across tens of thousands of steps.
TextAtari provides standardized evaluation protocols, baseline implementations,
and a framework for advancing research at the intersection of language models
and planning.

</details>


### [101] [Rectified Sparse Attention](https://arxiv.org/abs/2506.04108)
*Yutao Sun,Tianzhu Ye,Li Dong,Yuqing Xia,Jian Chen,Yizhao Gao,Shijie Cao,Jianyong Wang,Furu Wei*

Main category: cs.CL

TL;DR: ReSA提出了一种结合块稀疏注意力和周期性密集校正的方法，有效解决了KV缓存对齐问题，提升了长序列生成的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 长序列生成是大型语言模型的关键挑战，现有稀疏解码方法因KV缓存对齐问题导致生成质量下降。

Method: 结合块稀疏注意力和周期性密集校正（ReSA），通过固定间隔刷新KV缓存以限制误差累积。

Result: 在数学推理、语言建模和检索任务中，ReSA实现了近乎无损的生成质量，并在256K序列长度下达到2.42倍端到端加速。

Conclusion: ReSA是一种实用的长上下文推理解决方案，显著提升了生成效率和质量。

Abstract: Efficient long-sequence generation is a critical challenge for Large Language
Models. While recent sparse decoding methods improve efficiency, they suffer
from KV cache misalignment, where approximation errors accumulate and degrade
generation quality. In this work, we propose Rectified Sparse Attention (ReSA),
a simple yet effective method that combines block-sparse attention with
periodic dense rectification. By refreshing the KV cache at fixed intervals
using a dense forward pass, ReSA bounds error accumulation and preserves
alignment with the pretraining distribution. Experiments across math reasoning,
language modeling, and retrieval tasks demonstrate that ReSA achieves
near-lossless generation quality with significantly improved efficiency.
Notably, ReSA delivers up to 2.42$\times$ end-to-end speedup under decoding at
256K sequence length, making it a practical solution for scalable long-context
inference. Code is available at https://aka.ms/ReSA-LM.

</details>


### [102] [CLAIM: An Intent-Driven Multi-Agent Framework for Analyzing Manipulation in Courtroom Dialogues](https://arxiv.org/abs/2506.04131)
*Disha Sheshanarayana,Tanishka Magar,Ayushi Mittal,Neelam Chaplot*

Main category: cs.CL

TL;DR: 论文介绍了LegalCon数据集和CLAIM框架，用于检测和分析法庭对话中的操纵行为，旨在提升司法过程的公平性和透明度。


<details>
  <summary>Details</summary>
Motivation: 法庭对话中的操纵行为可能影响法官决策，但现有NLP技术在此领域的应用不足。

Method: 提出了LegalCon数据集（1,063条标注对话）和CLAIM框架（两阶段、意图驱动的多智能体框架）。

Result: CLAIM框架能有效分析操纵行为，提升司法决策的公平性和透明度。

Conclusion: 该研究为法律话语分析提供了新工具，支持司法公平的实现。

Abstract: Courtrooms are places where lives are determined and fates are sealed, yet
they are not impervious to manipulation. Strategic use of manipulation in legal
jargon can sway the opinions of judges and affect the decisions. Despite the
growing advancements in NLP, its application in detecting and analyzing
manipulation within the legal domain remains largely unexplored. Our work
addresses this gap by introducing LegalCon, a dataset of 1,063 annotated
courtroom conversations labeled for manipulation detection, identification of
primary manipulators, and classification of manipulative techniques, with a
focus on long conversations. Furthermore, we propose CLAIM, a two-stage,
Intent-driven Multi-agent framework designed to enhance manipulation analysis
by enabling context-aware and informed decision-making. Our results highlight
the potential of incorporating agentic frameworks to improve fairness and
transparency in judicial processes. We hope that this contributes to the
broader application of NLP in legal discourse analysis and the development of
robust tools to support fairness in legal decision-making. Our code and data
are available at https://github.com/Disha1001/CLAIM.

</details>


### [103] [Are Lexicon-Based Tools Still the Gold Standard for Valence Analysis in Low-Resource Flemish?](https://arxiv.org/abs/2506.04139)
*Ratna Kandala,Katie Hoemann*

Main category: cs.CL

TL;DR: 研究比较了荷兰语LLMs与传统工具LIWC和Pattern在捕捉日常叙述情感效价的表现，发现LLMs在准确性上仍有不足，呼吁开发更适应文化和语言特点的模型。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在捕捉荷兰语日常叙述情感效价的能力，以弥补传统工具的局限性。

Method: 通过102名荷兰语参与者的25,000条文本数据，结合自评效价分数，对比三种荷兰语LLMs与LIWC、Pattern的表现。

Result: 荷兰语LLMs在捕捉真实叙述情感效价上表现不佳，未能超越传统工具。

Conclusion: 需开发文化和语言适配的模型，加强低资源语言（如弗拉芒语）的数据集和LLMs微调，以提升情感分析能力。

Abstract: Understanding the nuances in everyday language is pivotal for advancements in
computational linguistics & emotions research. Traditional lexicon-based tools
such as LIWC and Pattern have long served as foundational instruments in this
domain. LIWC is the most extensively validated word count based text analysis
tool in the social sciences and Pattern is an open source Python library
offering functionalities for NLP. However, everyday language is inherently
spontaneous, richly expressive, & deeply context dependent. To explore the
capabilities of LLMs in capturing the valences of daily narratives in Flemish,
we first conducted a study involving approximately 25,000 textual responses
from 102 Dutch-speaking participants. Each participant provided narratives
prompted by the question, "What is happening right now and how do you feel
about it?", accompanied by self-assessed valence ratings on a continuous scale
from -50 to +50. We then assessed the performance of three Dutch-specific LLMs
in predicting these valence scores, and compared their outputs to those
generated by LIWC and Pattern. Our findings indicate that, despite advancements
in LLM architectures, these Dutch tuned models currently fall short in
accurately capturing the emotional valence present in spontaneous, real-world
narratives. This study underscores the imperative for developing culturally and
linguistically tailored models/tools that can adeptly handle the complexities
of natural language use. Enhancing automated valence analysis is not only
pivotal for advancing computational methodologies but also holds significant
promise for psychological research with ecologically valid insights into human
daily experiences. We advocate for increased efforts in creating comprehensive
datasets & finetuning LLMs for low-resource languages like Flemish, aiming to
bridge the gap between computational linguistics & emotion research.

</details>


### [104] [Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis](https://arxiv.org/abs/2506.04142)
*Kejian Zhu,Shangqing Tu,Zhuoran Jin,Lei Hou,Juanzi Li,Jun Zhao*

Main category: cs.CL

TL;DR: 该论文提出了一种通过分析污染模型的机制来识别和抑制捷径神经元的新方法，以解决大型语言模型评估中的数据污染问题。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型评估依赖公共基准，但数据污染问题严重影响了公平性，而动态构建新基准成本高且循环往复。

Method: 通过比较和因果分析识别捷径神经元，并提出捷径神经元修补方法抑制其影响。

Result: 实验验证了方法的有效性，与可信基准MixEval的Spearman系数超过0.95，表明方法能准确揭示模型真实能力。

Conclusion: 该方法具有广泛适用性，为可信评估提供了新思路。

Abstract: The development of large language models (LLMs) depends on trustworthy
evaluation. However, most current evaluations rely on public benchmarks, which
are prone to data contamination issues that significantly compromise fairness.
Previous researches have focused on constructing dynamic benchmarks to address
contamination. However, continuously building new benchmarks is costly and
cyclical. In this work, we aim to tackle contamination by analyzing the
mechanisms of contaminated models themselves. Through our experiments, we
discover that the overestimation of contaminated models is likely due to
parameters acquiring shortcut solutions in training. We further propose a novel
method for identifying shortcut neurons through comparative and causal
analysis. Building on this, we introduce an evaluation method called shortcut
neuron patching to suppress shortcut neurons. Experiments validate the
effectiveness of our approach in mitigating contamination. Additionally, our
evaluation results exhibit a strong linear correlation with MixEval, a recently
released trustworthy benchmark, achieving a Spearman coefficient ($\rho$)
exceeding 0.95. This high correlation indicates that our method closely reveals
true capabilities of the models and is trustworthy. We conduct further
experiments to demonstrate the generalizability of our method across various
benchmarks and hyperparameter settings. Code:
https://github.com/GaryStack/Trustworthy-Evaluation

</details>


### [105] [A Dataset for Addressing Patient's Information Needs related to Clinical Course of Hospitalization](https://arxiv.org/abs/2506.04156)
*Sarvesh Soni,Dina Demner-Fushman*

Main category: cs.CL

TL;DR: ArchEHR-QA是一个专家标注的数据集，用于评估AI在电子健康记录（EHR）中回答患者问题的准确性和相关性，并测试了三种大型语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 患者对住院信息的需求可以通过EHR数据满足，但缺乏相关数据集来评估AI生成回答的准确性和相关性。

Method: 基于真实ICU和急诊科病例，构建了包含患者问题、临床笔记摘录和专家答案的数据集，并测试了三种LLM模型和三种提示策略。

Result: Llama 4在答案优先提示策略中表现最佳，但存在遗漏关键证据或生成矛盾内容的问题。

Conclusion: ArchEHR-QA为开发患者为中心的EHR问答系统提供了基准，强调了在临床环境中生成准确和相关回答的重要性。

Abstract: Patients have distinct information needs about their hospitalization that can
be addressed using clinical evidence from electronic health records (EHRs).
While artificial intelligence (AI) systems show promise in meeting these needs,
robust datasets are needed to evaluate the factual accuracy and relevance of
AI-generated responses. To our knowledge, no existing dataset captures patient
information needs in the context of their EHRs. We introduce ArchEHR-QA, an
expert-annotated dataset based on real-world patient cases from intensive care
unit and emergency department settings. The cases comprise questions posed by
patients to public health forums, clinician-interpreted counterparts, relevant
clinical note excerpts with sentence-level relevance annotations, and
clinician-authored answers. To establish benchmarks for grounded EHR question
answering (QA), we evaluated three open-weight large language models
(LLMs)--Llama 4, Llama 3, and Mixtral--across three prompting strategies:
generating (1) answers with citations to clinical note sentences, (2) answers
before citations, and (3) answers from filtered citations. We assessed
performance on two dimensions: Factuality (overlap between cited note sentences
and ground truth) and Relevance (textual and semantic similarity between system
and reference answers). The final dataset contains 134 patient cases. The
answer-first prompting approach consistently performed best, with Llama 4
achieving the highest scores. Manual error analysis supported these findings
and revealed common issues such as omitted key clinical evidence and
contradictory or hallucinated content. Overall, ArchEHR-QA provides a strong
benchmark for developing and evaluating patient-centered EHR QA systems,
underscoring the need for further progress toward generating factual and
relevant responses in clinical contexts.

</details>


### [106] [SkipGPT: Dynamic Layer Pruning Reinvented with Token Awareness and Module Decoupling](https://arxiv.org/abs/2506.04179)
*Anhao Zhao,Fanghua Ye,Yingqi Fan,Junlong Tong,Zhiwei Fei,Hui Su,Xiaoyu Shen*

Main category: cs.CL

TL;DR: SkipGPT是一种动态层剪枝框架，通过全局令牌感知路由和分离的MLP与自注意力剪枝策略，显著减少计算成本，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）计算成本高，静态剪枝方法忽略了令牌级异质性和不同层功能角色的动态性。

Method: 提出SkipGPT框架，包括全局令牌感知路由和分离的剪枝策略，采用两阶段优化（解耦训练和LoRA微调）。

Result: 实验表明SkipGPT减少40%以上参数，性能与原密集模型相当或更好。

Conclusion: SkipGPT通过动态剪枝提升LLM的实用部署效率。

Abstract: Large language models (LLMs) achieve remarkable performance across tasks but
incur substantial computational costs due to their deep, multi-layered
architectures. Layer pruning has emerged as a strategy to alleviate these
inefficiencies, but conventional static pruning methods overlook two critical
dynamics inherent to LLM inference: (1) horizontal dynamics, where token-level
heterogeneity demands context-aware pruning decisions, and (2) vertical
dynamics, where the distinct functional roles of MLP and self-attention layers
necessitate component-specific pruning policies. We introduce SkipGPT, a
dynamic layer pruning framework designed to optimize computational resource
allocation through two core innovations: (1) global token-aware routing to
prioritize critical tokens, and (2) decoupled pruning policies for MLP and
self-attention components. To mitigate training instability, we propose a
two-stage optimization paradigm: first, a disentangled training phase that
learns routing strategies via soft parameterization to avoid premature pruning
decisions, followed by parameter-efficient LoRA fine-tuning to restore
performance impacted by layer removal. Extensive experiments demonstrate that
SkipGPT reduces over 40% of model parameters while matching or exceeding the
performance of the original dense model across benchmarks. By harmonizing
dynamic efficiency with preserved expressivity, SkipGPT advances the practical
deployment of scalable, resource-aware LLMs. Our code is publicly available at:
https://github.com/EIT-NLP/SkipGPT.

</details>


### [107] [SuperWriter: Reflection-Driven Long-Form Generation with Large Language Models](https://arxiv.org/abs/2506.04180)
*Yuhao Wu,Yushi Bai,Zhiqiang Hu,Juanzi Li,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: SuperWriter-Agent框架通过结构化思维和层次化优化提升长文本生成质量，实验证明其性能优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 长文本生成在连贯性、逻辑一致性和质量保持方面存在挑战，需改进现有方法。

Method: 提出SuperWriter-Agent框架，结合结构化思维、监督微调和层次化DPO优化。

Result: SuperWriter-LM在自动和人工评估中表现优异，超越基线模型。

Conclusion: 结构化思维和层次化优化显著提升长文本生成质量。

Abstract: Long-form text generation remains a significant challenge for large language
models (LLMs), particularly in maintaining coherence, ensuring logical
consistency, and preserving text quality as sequence length increases. To
address these limitations, we propose SuperWriter-Agent, an agent-based
framework designed to enhance the quality and consistency of long-form text
generation. SuperWriter-Agent introduces explicit structured thinking-through
planning and refinement stages into the generation pipeline, guiding the model
to follow a more deliberate and cognitively grounded process akin to that of a
professional writer. Based on this framework, we construct a supervised
fine-tuning dataset to train a 7B SuperWriter-LM. We further develop a
hierarchical Direct Preference Optimization (DPO) procedure that uses Monte
Carlo Tree Search (MCTS) to propagate final quality assessments and optimize
each generation step accordingly. Empirical results across diverse benchmarks
demonstrate that SuperWriter-LM achieves state-of-the-art performance,
surpassing even larger-scale baseline models in both automatic evaluation and
human evaluation. Furthermore, comprehensive ablation studies demonstrate the
effectiveness of hierarchical DPO and underscore the value of incorporating
structured thinking steps to improve the quality of long-form text generation.

</details>


### [108] [Long or short CoT? Investigating Instance-level Switch of Large Reasoning Models](https://arxiv.org/abs/2506.04182)
*Ruiqi Zhang,Changyi Xiao,Yixin Cao*

Main category: cs.CL

TL;DR: 论文分析了长链思维（CoT）提示与短链思维提示的性能与资源消耗，提出了一种动态选择策略的框架SwitchCoT，以在推理准确性和计算效率之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 随着大型推理模型的快速发展，长链思维提示在复杂任务中表现出色，但伴随显著的令牌消耗增加。本文旨在比较长短链思维策略的优劣，并探索更高效的解决方案。

Method: 通过全面的实证分析比较长短链思维策略，提出SwitchCoT框架，动态选择策略以适应任务上下文和资源限制。

Result: 实验表明，SwitchCoT可降低推理成本达50%，同时在有限令牌预算下保持或超越单一策略的性能。

Conclusion: SwitchCoT为资源受限场景提供了一种高效的动态选择方案，平衡了性能与成本。

Abstract: With the rapid advancement of large reasoning models, long Chain-of-Thought
(CoT) prompting has demonstrated strong performance on complex tasks. However,
this often comes with a significant increase in token usage. In this paper, we
conduct a comprehensive empirical analysis comparing long and short CoT
strategies. Our findings reveal that while long CoT can lead to performance
improvements, its benefits are often marginal relative to its significantly
higher token consumption. Specifically, long CoT tends to outperform when ample
generation budgets are available, whereas short CoT is more effective under
tighter budget constraints. These insights underscore the need for a dynamic
approach that selects the proper CoT strategy based on task context and
resource availability. To address this, we propose SwitchCoT, an automatic
framework that adaptively chooses between long and short CoT strategies to
balance reasoning accuracy and computational efficiency. Moreover, SwitchCoT is
designed to be budget-aware, making it broadly applicable across scenarios with
varying resource constraints. Experimental results demonstrate that SwitchCoT
can reduce inference costs by up to 50% while maintaining high accuracy.
Notably, under limited token budgets, it achieves performance comparable to, or
even exceeding, that of using either long or short CoT alone.

</details>


### [109] [R-Search: Empowering LLM Reasoning with Search via Multi-Reward Reinforcement Learning](https://arxiv.org/abs/2506.04185)
*Qingfei Zhao,Ruobing Wang,Dingling Xu,Daren Zha,Limin Liu*

Main category: cs.CL

TL;DR: R-Search是一种强化学习框架，用于优化大语言模型（LLMs）在复杂任务中的推理与搜索交互，显著提升响应质量。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在多步推理和搜索交互中表现不佳，难以找到最优的推理-搜索交互轨迹，导致响应质量下降。

Method: 提出R-Search框架，通过多奖励信号优化推理-搜索交互轨迹，动态决定何时检索或推理，并全局整合关键证据。

Result: 在七个数据集上，R-Search比先进RAG基线性能提升高达32.2%（领域内）和25.1%（领域外）。

Conclusion: R-Search有效提升了LLMs在复杂逻辑和知识密集型任务中的推理与搜索交互能力。

Abstract: Large language models (LLMs) have notably progressed in multi-step and
long-chain reasoning. However, extending their reasoning capabilities to
encompass deep interactions with search remains a non-trivial challenge, as
models often fail to identify optimal reasoning-search interaction
trajectories, resulting in suboptimal responses. We propose R-Search, a novel
reinforcement learning framework for Reasoning-Search integration, designed to
enable LLMs to autonomously execute multi-step reasoning with deep search
interaction, and learn optimal reasoning search interaction trajectories via
multi-reward signals, improving response quality in complex logic- and
knowledge-intensive tasks. R-Search guides the LLM to dynamically decide when
to retrieve or reason, while globally integrating key evidence to enhance deep
knowledge interaction between reasoning and search. During RL training,
R-Search provides multi-stage, multi-type rewards to jointly optimize the
reasoning-search trajectory. Experiments on seven datasets show that R-Search
outperforms advanced RAG baselines by up to 32.2% (in-domain) and 25.1%
(out-of-domain). The code and data are available at
https://github.com/QingFei1/R-Search.

</details>


### [110] [Efficient Knowledge Editing via Minimal Precomputation](https://arxiv.org/abs/2506.04226)
*Akshat Gupta,Maochuan Lu,Thomas Hartvigsen,Gopala Anumanchipalli*

Main category: cs.CL

TL;DR: 本文提出了一种减少知识编辑方法（如MEMIT）预计算步骤中隐藏向量数量的方法，显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法（如MEMIT）需要预计算大量隐藏向量，导致计算成本高昂，限制了其实际应用。本文旨在解决这一问题。

Method: 通过理论分析和实验验证，确定知识编辑所需的最小隐藏向量数量，并大幅减少预计算量。

Result: 实验表明，预计算量可减少至原数量的0.3%，显著节省时间和资源。

Conclusion: 该方法显著降低了知识编辑的计算成本，使其更实用和高效。

Abstract: Knowledge editing methods like MEMIT are able to make data and compute
efficient updates of factual knowledge by using a single sentence to update
facts and their consequences. However, what is often overlooked is a
"precomputation step", which requires a one-time but significant computational
cost. The authors of MEMIT originally precompute approximately 44 million
hidden vectors per edited layer, which requires a forward pass over 44 million
tokens. For GPT-J (6B), this precomputation step takes 36 hours on a single
GPU, while it takes approximately 40 hours for Llama2-7B. Additionally, this
precomputation time grows with model size. In this paper, we show that this
excessive computational cost is unnecessary. Knowledge editing using MEMIT and
related methods, such as ROME and EMMET, can be performed by pre-computing a
very small portion of the 44 million hidden vectors. We first present the
theoretical minimum number of hidden vector precomputation required for
solutions of these editing methods to exist. We then empirically show that
knowledge editing using these methods can be done by pre-computing
significantly fewer hidden vectors. Specifically, we show that the
precomputation step can be done with less than 0.3% of the originally
stipulated number of hidden vectors. This saves a significant amount of
precomputation time and allows users to begin editing new models within a few
minutes.

</details>


### [111] [Evaluating Large Language Models for Zero-Shot Disease Labeling in CT Radiology Reports Across Organ Systems](https://arxiv.org/abs/2506.03259)
*Michael E. Garcia-Alcoser,Mobina GhojoghNejad,Fakrul Islam Tushar,David Kim,Kyle J. Lafata,Geoffrey D. Rubin,Joseph Y. Lo*

Main category: cs.CL

TL;DR: 轻量级LLM在CT报告疾病标注中表现优于基于规则的方法，并能通过零样本提示泛化到不同器官系统。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在自动化CT放射学报告疾病标注中的有效性，并与基于规则的算法（RBA）进行比较。

Method: 回顾性研究分析了40,833份CT报告，测试了三种轻量级LLM的零样本提示性能，使用Cohen's Kappa和F1分数进行评估。

Result: Gemma-3 27B和Llama-3.1 8B表现最佳，在Duke CAP报告中Kappa中位数为0.87，Gemma-3 27B的宏F1分数最高（0.82）。

Conclusion: 轻量级LLM为CT报告标注提供了灵活高效的解决方案，但二元标签无法完全捕捉报告的细微差别。

Abstract: Purpose: This study aims to evaluate the effectiveness of large language
models (LLMs) in automating disease annotation of CT radiology reports. We
compare a rule-based algorithm (RBA), RadBERT, and three lightweight
open-weight LLMs for multi-disease labeling of chest, abdomen, and pelvis (CAP)
CT reports.
  Materials and Methods: This retrospective study analyzed 40,833 CT reports
from 29,540 patients, with 1,789 CAP reports manually annotated across three
organ systems. External validation was conducted using the CT-RATE dataset.
Three open-weight LLMs were tested with zero-shot prompting. Performance was
evaluated using Cohen's Kappa and micro/macro-averaged F1 scores.
  Results: In 12,197 Duke CAP reports from 8,854 patients, Llama-3.1 8B and
Gemma-3 27B showed the highest agreement ($\kappa$ median: 0.87). On the
manually annotated set, Gemma-3 27B achieved the top macro-F1 (0.82), followed
by Llama-3.1 8B (0.79), while the RBA scored lowest (0.64). On the CT-RATE
dataset (lungs/pleura only), Llama-3.1 8B performed best (0.91), with Gemma-3
27B close behind (0.89). Performance differences were mainly due to differing
labeling practices, especially for lung atelectasis.
  Conclusion: Lightweight LLMs outperform rule-based methods for CT report
annotation and generalize across organ systems with zero-shot prompting.
However, binary labels alone cannot capture the full nuance of report language.
LLMs can provide a flexible, efficient solution aligned with clinical judgment
and user needs.

</details>


### [112] [A conclusive remark on linguistic theorizing and language modeling](https://arxiv.org/abs/2506.03268)
*Cristiano Chesi*

Main category: cs.CL

TL;DR: 对目标论文收到的回复的总结性评论。


<details>
  <summary>Details</summary>
Motivation: 总结和回应意大利语言学杂志中对目标论文的反馈。

Method: 分析收到的回复，进行综合评述。

Result: 提供了对回复的深入见解和总结。

Conclusion: 完成了对目标论文讨论的闭环，强调了其学术价值。

Abstract: This is the final remark on the replies received to my target paper in the
Italian Journal of Linguistics

</details>


### [113] [FailureSensorIQ: A Multi-Choice QA Dataset for Understanding Sensor Relationships and Failure Modes](https://arxiv.org/abs/2506.03278)
*Christodoulos Constantinides,Dhaval Patel,Shuxin Lin,Claudio Guerrero,Sunil Dagajirao Patil,Jayant Kalagnanam*

Main category: cs.CL

TL;DR: FailureSensorIQ是一个多选问答基准系统，用于评估大语言模型在工业4.0中复杂场景的推理能力。通过多维度分析，揭示了模型在扰动和知识缺口下的性能下降，并提供了实际案例和开源工具。


<details>
  <summary>Details</summary>
Motivation: 传统QA基准无法全面评估工业场景中的复杂推理能力，需要一种结合数据驱动和领域驱动的方法，以提升大语言模型在工业4.0中的应用。

Method: 开发了FailureSensorIQ系统，结合扰动-不确定性-复杂性分析、专家评估、知识缺口分析等方法，评估了多种大语言模型的性能。

Result: 尽管部分闭源模型表现接近专家水平，但整体性能对扰动和知识缺口敏感，存在显著下降。

Conclusion: FailureSensorIQ为工业4.0中的模型评估提供了新范式，并开源了基准工具和特征选择流程。

Abstract: We introduce FailureSensorIQ, a novel Multi-Choice Question-Answering (MCQA)
benchmarking system designed to assess the ability of Large Language Models
(LLMs) to reason and understand complex, domain-specific scenarios in Industry
4.0. Unlike traditional QA benchmarks, our system focuses on multiple aspects
of reasoning through failure modes, sensor data, and the relationships between
them across various industrial assets. Through this work, we envision a
paradigm shift where modeling decisions are not only data-driven using
statistical tools like correlation analysis and significance tests, but also
domain-driven by specialized LLMs which can reason about the key contributors
and useful patterns that can be captured with feature engineering. We evaluate
the Industrial knowledge of over a dozen LLMs-including GPT-4, Llama, and
Mistral-on FailureSensorIQ from different lens using
Perturbation-Uncertainty-Complexity analysis, Expert Evaluation study,
Asset-Specific Knowledge Gap analysis, ReAct agent using external
knowledge-bases. Even though closed-source models with strong reasoning
capabilities approach expert-level performance, the comprehensive benchmark
reveals a significant drop in performance that is fragile to perturbations,
distractions, and inherent knowledge gaps in the models. We also provide a
real-world case study of how LLMs can drive the modeling decisions on 3
different failure prediction datasets related to various assets. We release:
(a) expert-curated MCQA for various industrial assets, (b) FailureSensorIQ
benchmark and Hugging Face leaderboard based on MCQA built from non-textual
data found in ISO documents, and (c) LLMFeatureSelector, an LLM-based feature
selection scikit-learn pipeline. The software is available at
https://github.com/IBM/FailureSensorIQ.

</details>


### [114] [HyperSteer: Activation Steering at Scale with Hypernetworks](https://arxiv.org/abs/2506.03292)
*Jiuding Sun,Sidharth Baskaran,Zhengxuan Wu,Michael Sklar,Christopher Potts,Atticus Geiger*

Main category: cs.CL

TL;DR: HyperSteer是一种基于超网络的架构，通过自然语言提示生成语言模型的转向向量，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有无监督方法生成的转向向量缺乏个体效能保证，而有监督方法需要大量数据收集和训练。

Method: 引入HyperSteer，一种基于超网络的架构，通过端到端训练生成转向向量。

Result: HyperSteer在数千个转向提示下表现优于现有方法，甚至适用于未见过的提示。

Conclusion: HyperSteer在性能上与提示转向方法相当，且更具扩展性。

Abstract: Steering language models (LMs) by modifying internal activations is a popular
approach for controlling text generation. Unsupervised dictionary learning
methods, e.g., sparse autoencoders, can be scaled to produce many steering
vectors, but lack guarantees on the individual efficacy of each vector and
control over the coverage of relevant steering tasks. In contrast, supervised
methods for constructing steering vectors are targeted and effective, but
require more data collection and training for each additional steering vector
produced. In this work, we introduce HyperSteer, a family of hypernetwork-based
architectures which are trained end-to-end to generate steering vectors
conditioned on the natural language steering prompts and the internals of the
steered LM. In our evaluations, we show that scaling HyperSteer with thousands
of steering prompts exceeds the performance of state-of-the-art activation
steering methods, even on steering prompts never seen during training.
Moreover, HyperSteer performs on par with steering-via-prompting.

</details>


### [115] [Unleashing the Reasoning Potential of Pre-trained LLMs by Critique Fine-Tuning on One Problem](https://arxiv.org/abs/2506.03295)
*Yubo Wang,Ping Nie,Kai Zou,Lijun Wu,Wenhu Chen*

Main category: cs.CL

TL;DR: 论文提出了一种名为Critique Fine-Tuning (CFT)的方法，通过单问题微调释放大型语言模型（LLMs）的推理潜力，相比强化学习（RL）更高效且计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 尽管RL可以显著提升LLMs的推理能力，但其计算成本高且不稳定。因此，研究旨在寻找更高效的方法来释放LLMs的推理潜力。

Method: 通过收集单问题的多样化模型生成解决方案，并利用教师LLMs提供详细批评，构建CFT数据，对Qwen和Llama系列模型进行微调。

Result: 仅用5 GPU小时的训练，Qwen-Math-7B-CFT在数学和逻辑推理任务上分别实现了15%和16%的平均提升，性能与RL相当但计算成本低20倍。

Conclusion: 单次CFT是一种简单、通用且计算高效的方法，能够有效释放现代LLMs的推理能力。

Abstract: We have witnessed that strong LLMs like Qwen-Math, MiMo, and Phi-4 possess
immense reasoning potential inherited from the pre-training stage. With
reinforcement learning (RL), these models can improve dramatically on reasoning
tasks. Recent studies have shown that even RL on a single problem can unleash
these models' reasoning capabilities. However, RL is not only expensive but
also unstable. Even one-shot RL requires hundreds of GPU hours. This raises a
critical question: Is there a more efficient way to unleash the reasoning
potential of these powerful base LLMs? In this work, we demonstrate that
Critique Fine-Tuning (CFT) on only one problem can effectively unleash the
reasoning potential of LLMs. Our method constructs critique data by collecting
diverse model-generated solutions to a single problem and using teacher LLMs to
provide detailed critiques. We fine-tune Qwen and Llama family models, ranging
from 1.5B to 14B parameters, on the CFT data and observe significant
performance gains across diverse reasoning tasks. For example, with just 5 GPU
hours of training, Qwen-Math-7B-CFT show an average improvement of 15% on six
math benchmarks and 16% on three logic reasoning benchmarks. These results are
comparable to or even surpass the results from RL with 20x less compute.
Ablation studies reveal the robustness of one-shot CFT across different prompt
problems. These results highlight one-shot CFT as a simple, general, and
compute-efficient approach to unleashing the reasoning capabilities of modern
LLMs.

</details>


### [116] [From Instructions to ODRL Usage Policies: An Ontology Guided Approach](https://arxiv.org/abs/2506.03301)
*Daham M. Mustafa,Abhishek Nadgeri,Diego Collarana,Benedikt T. Arnold,Christoph Quix,Christoph Lange,Stefan Decker*

Main category: cs.CL

TL;DR: 利用GPT-4等大型语言模型，从自然语言指令自动生成W3C ODRL的使用策略，通过ODRL本体及其文档优化提示，生成准确率高达91.95%的知识图谱。


<details>
  <summary>Details</summary>
Motivation: 研究假设认为，经过整理的现有本体文档能更好地指导策略生成，特别是在文化领域的数据空间背景下。

Method: 使用ODRL本体及其文档作为提示核心，提出多种启发式方法，适配ODRL本体以指导端到端知识图谱构建。

Result: 在12个不同复杂度的用例中，生成的知识图谱准确率高达91.95%。

Conclusion: 该方法在文化领域数据空间中表现出色，验证了优化本体文档对策略生成的有效性。

Abstract: This study presents an approach that uses large language models such as GPT-4
to generate usage policies in the W3C Open Digital Rights Language ODRL
automatically from natural language instructions. Our approach uses the ODRL
ontology and its documentation as a central part of the prompt. Our research
hypothesis is that a curated version of existing ontology documentation will
better guide policy generation. We present various heuristics for adapting the
ODRL ontology and its documentation to guide an end-to-end KG construction
process. We evaluate our approach in the context of dataspaces, i.e.,
distributed infrastructures for trustworthy data exchange between multiple
participating organizations for the cultural domain. We created a benchmark
consisting of 12 use cases of varying complexity. Our evaluation shows
excellent results with up to 91.95% accuracy in the resulting knowledge graph.

</details>


### [117] [Hopscotch: Discovering and Skipping Redundancies in Language Models](https://arxiv.org/abs/2506.03303)
*Mustafa Eyceoz,Nikhil Shivakumar Nayak,Hao Wang,Ligong Han,Akash Srivastava*

Main category: cs.CL

TL;DR: Hopscotch是一种简单有效的方法，通过跳过贡献最小的注意力块并调整剩余层的输出，以减少计算量，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 现代因果语言模型通过堆叠多个注意力块提升性能，但并非所有块对每个任务都必要。Hopscotch旨在优化计算效率。

Method: Hopscotch联合优化跳过哪些注意力块及如何缩放剩余层的输出，引入轻量级可训练缩放参数以缓解分布偏移。

Result: 在Llama-3.1-8B和Qwen2.5-7B上应用Hopscotch，跳过四个注意力块后性能下降不到2%。

Conclusion: Hopscotch无需修改模型权重或访问预训练数据，兼容现有压缩技术，是一种高效的计算优化方法。

Abstract: Modern causal language models stack many attention blocks to improve
performance, but not all blocks are necessary for every task. We propose
Hopscotch, a simple yet effective method that identifies and skips attention
blocks with least contributions to a task and adapts to preserve output
quality. Hopscotch jointly optimizes which blocks to skip and how to scale the
outputs of the remaining layers. By introducing lightweight, trainable scaling
parameters to attention and MLP blocks, it mitigates distribution shifts in
hidden states caused by removing attention blocks. Hopscotch does not modify
model weights or require access to pretraining or instruction-tuning data, and
is compatible with existing model compression techniques. When applied to
$\texttt{Llama-3.1-8B}$ and $\texttt{Qwen2.5-7B}$, Hopscotch achieves less than
a 2% drop in performance even after skipping four attention blocks.

</details>


### [118] [The Reader is the Metric: How Textual Features and Reader Profiles Explain Conflicting Evaluations of AI Creative Writing](https://arxiv.org/abs/2506.03310)
*Guillermo Marco,Julio Gonzalo,Víctor Fresno*

Main category: cs.CL

TL;DR: 研究探讨了AI生成与人类创作文学文本的评价差异，发现读者偏好是解释分歧的关键。通过分析文本特征和读者偏好，揭示了两种读者类型及其对文学质量评价的影响。


<details>
  <summary>Details</summary>
Motivation: 解决AI与人类文学文本评价结果不一致的问题，探究读者偏好如何影响评价。

Method: 使用五个公共数据集（1,471个故事，101名注释者），提取17个无参考文本特征，建模读者偏好，分析偏好空间。

Result: 读者偏好分为两类：表面关注型（非专家）和整体关注型（专家），文学质量评价取决于文本特征与读者偏好的匹配程度。

Conclusion: 建议在创意文本生成领域采用读者敏感的评价框架。

Abstract: Recent studies comparing AI-generated and human-authored literary texts have
produced conflicting results: some suggest AI already surpasses human quality,
while others argue it still falls short. We start from the hypothesis that such
divergences can be largely explained by genuine differences in how readers
interpret and value literature, rather than by an intrinsic quality of the
texts evaluated. Using five public datasets (1,471 stories, 101 annotators
including critics, students, and lay readers), we (i) extract 17 reference-less
textual features (e.g., coherence, emotional variance, average sentence
length...); (ii) model individual reader preferences, deriving feature
importance vectors that reflect their textual priorities; and (iii) analyze
these vectors in a shared "preference space". Reader vectors cluster into two
profiles: 'surface-focused readers' (mainly non-experts), who prioritize
readability and textual richness; and 'holistic readers' (mainly experts), who
value thematic development, rhetorical variety, and sentiment dynamics. Our
results quantitatively explain how measurements of literary quality are a
function of how text features align with each reader's preferences. These
findings advocate for reader-sensitive evaluation frameworks in the field of
creative text generation.

</details>


### [119] [Cross-Platform Violence Detection on Social Media: A Dataset and Analysis](https://arxiv.org/abs/2506.03312)
*Celia Chen,Scotty Beland,Ingo Burghardt,Jill Byczek,William J. Conway,Eric Cotugno,Sadaf Davre,Megan Fletcher,Rajesh Kumar Gnanasekaran,Kristin Hamilton,Marilyn Harbert,Jordan Heustis,Tanaya Jha,Emily Klein,Hayden Kramer,Alex Leitch,Jessica Perkins,Casi Sherman,Celia Sterrn,Logan Stevens,Rebecca Zarrella,Jennifer Golbeck*

Main category: cs.CL

TL;DR: 论文介绍了一个跨平台的暴力威胁数据集，并通过机器学习分析验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的暴力威胁问题严重，高质量数据有助于研究和检测恶意内容。

Method: 引入了一个包含30,000条手动编码帖子的数据集，并使用YouTube的暴力评论数据集进行机器学习分析。

Result: 尽管数据集来自不同平台且编码标准不同，分类准确率仍然很高。

Conclusion: 研究结果对内容分类策略和跨平台暴力内容理解具有重要意义。

Abstract: Violent threats remain a significant problem across social media platforms.
Useful, high-quality data facilitates research into the understanding and
detection of malicious content, including violence. In this paper, we introduce
a cross-platform dataset of 30,000 posts hand-coded for violent threats and
sub-types of violence, including political and sexual violence. To evaluate the
signal present in this dataset, we perform a machine learning analysis with an
existing dataset of violent comments from YouTube. We find that, despite
originating from different platforms and using different coding criteria, we
achieve high classification accuracy both by training on one dataset and
testing on the other, and in a merged dataset condition. These results have
implications for content-classification strategies and for understanding
violent content across social media.

</details>


### [120] [Ask a Local: Detecting Hallucinations With Specialized Model Divergence](https://arxiv.org/abs/2506.03357)
*Aldan Creo,Héctor Cerezo-Costas,Pedro Alonso-Doval,Maximiliano Hormazábal-Lagos*

Main category: cs.CL

TL;DR: 论文提出了一种名为'Ask a Local'的新方法，用于检测大型语言模型（LLMs）中的幻觉现象（生成看似合理但事实错误的信息）。该方法通过计算领域专用模型的困惑度分布差异来识别幻觉内容，适用于多语言环境且无需额外训练或外部数据。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型生成的幻觉信息对AI应用构成挑战，需要一种无需语言特定适应、可扩展的检测方法。

Method: 利用领域专用模型的困惑度分布差异识别幻觉内容，选择计算高效模型，适用于多语言和多领域。

Result: 在14种语言的问答数据集上表现一致，IoU分数约为0.3，意大利语和加泰罗尼亚语表现尤为突出（IoU分别为0.42和0.38）。

Conclusion: 该方法在多语言幻觉检测中有效且可扩展，代码和架构已开源以促进进一步研究。

Abstract: Hallucinations in large language models (LLMs) - instances where models
generate plausible but factually incorrect information - present a significant
challenge for AI.
  We introduce "Ask a Local", a novel hallucination detection method exploiting
the intuition that specialized models exhibit greater surprise when
encountering domain-specific inaccuracies. Our approach computes divergence
between perplexity distributions of language-specialized models to identify
potentially hallucinated spans. Our method is particularly well-suited for a
multilingual context, as it naturally scales to multiple languages without the
need for adaptation, relying on external data sources, or performing training.
Moreover, we select computationally efficient models, providing a scalable
solution that can be applied to a wide range of languages and domains.
  Our results on a human-annotated question-answer dataset spanning 14
languages demonstrate consistent performance across languages, with
Intersection-over-Union (IoU) scores around 0.3 and comparable Spearman
correlation values. Our model shows particularly strong performance on Italian
and Catalan, with IoU scores of 0.42 and 0.38, respectively, while maintaining
cross-lingual effectiveness without language-specific adaptations. We release
our code and architecture to facilitate further research in multilingual
hallucination detection.

</details>


### [121] [A Multimodal, Multilingual, and Multidimensional Pipeline for Fine-grained Crowdsourcing Earthquake Damage Evaluation](https://arxiv.org/abs/2506.03360)
*Zihui Ma,Lingyao Li,Juan Li,Wenyue Hua,Jingxiao Liu,Qingyuan Feng,Yuki Miura*

Main category: cs.CL

TL;DR: 该研究提出了一种多模态、多语言、多维度的3M管道，利用多模态大语言模型（MLLMs）评估灾害影响，结果显示MLLMs能有效整合图像-文本信号并与地震数据强相关，但性能受语言、震中距离和输入模态影响。


<details>
  <summary>Details</summary>
Motivation: 快速、细粒度的灾害损害评估对应急响应至关重要，但传统方法受限于地面传感器不足和官方报告延迟，而社交媒体提供了丰富的实时人类观察数据。

Method: 研究提出了一种3M管道，利用MLLMs评估灾害影响，并在两次大地震事件中通过宏观和微观分析评估了三种基础模型。

Result: MLLMs能有效整合图像-文本信号，并与地震数据强相关，但性能受语言、震中距离和输入模态影响。

Conclusion: 该研究展示了MLLMs在灾害评估中的潜力，为未来实时危机应用奠定了基础，并公开了代码和数据。

Abstract: Rapid, fine-grained disaster damage assessment is essential for effective
emergency response, yet remains challenging due to limited ground sensors and
delays in official reporting. Social media provides a rich, real-time source of
human-centric observations, but its multimodal and unstructured nature presents
challenges for traditional analytical methods. In this study, we propose a
structured Multimodal, Multilingual, and Multidimensional (3M) pipeline that
leverages multimodal large language models (MLLMs) to assess disaster impacts.
We evaluate three foundation models across two major earthquake events using
both macro- and micro-level analyses. Results show that MLLMs effectively
integrate image-text signals and demonstrate a strong correlation with
ground-truth seismic data. However, performance varies with language,
epicentral distance, and input modality. This work highlights the potential of
MLLMs for disaster assessment and provides a foundation for future research in
applying MLLMs to real-time crisis contexts. The code and data are released at:
https://github.com/missa7481/EMNLP25_earthquake

</details>


### [122] [Trajectory Prediction Meets Large Language Models: A Survey](https://arxiv.org/abs/2506.03408)
*Yi Xu,Ruining Yang,Yitian Zhang,Yizhou Wang,Jianglin Lu,Mingyuan Zhang,Lili Su,Yun Fu*

Main category: cs.CL

TL;DR: 该综述探讨了如何利用大语言模型（LLMs）的语义和推理能力改进轨迹预测，总结了五个研究方向及其挑战。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的发展，研究者希望利用其语义和推理能力提升轨迹预测的准确性和可解释性。

Method: 综述将相关研究分为五类：语言建模范式、预训练模型直接预测、语言引导的场景理解、语言驱动的数据生成以及语言推理与可解释性。

Result: 分析了每类方法的代表性研究、核心设计选择，并指出了开放性问题。

Conclusion: 该综述为自然语言处理与轨迹预测的交叉研究提供了统一视角，展示了语言如何丰富轨迹预测。

Abstract: Recent advances in large language models (LLMs) have sparked growing interest
in integrating language-driven techniques into trajectory prediction. By
leveraging their semantic and reasoning capabilities, LLMs are reshaping how
autonomous systems perceive, model, and predict trajectories. This survey
provides a comprehensive overview of this emerging field, categorizing recent
work into five directions: (1) Trajectory prediction via language modeling
paradigms, (2) Direct trajectory prediction with pretrained language models,
(3) Language-guided scene understanding for trajectory prediction, (4)
Language-driven data generation for trajectory prediction, (5) Language-based
reasoning and interpretability for trajectory prediction. For each, we analyze
representative methods, highlight core design choices, and identify open
challenges. This survey bridges natural language processing and trajectory
prediction, offering a unified perspective on how language can enrich
trajectory prediction.

</details>


### [123] [DistRAG: Towards Distance-Based Spatial Reasoning in LLMs](https://arxiv.org/abs/2506.03424)
*Nicole R Schneider,Nandini Ramachandran,Kent O'Sullivan,Hanan Samet*

Main category: cs.CL

TL;DR: DistRAG方法通过检索空间信息增强LLM的空间推理能力，解决其无法处理距离相关问题的缺陷。


<details>
  <summary>Details</summary>
Motivation: LLMs在空间推理（如距离计算）方面能力不足，限制了其在POI推荐和行程规划等任务中的应用。

Method: 提出DistRAG方法，将城市间的地理距离编码为图结构，并检索与问题相关的子图作为上下文。

Result: DistRAG使LLM能够回答原本无法处理的基于距离的推理问题。

Conclusion: DistRAG为LLM提供了一种初步的‘世界模型’，补充其语言知识，扩展了应用范围。

Abstract: Many real world tasks where Large Language Models (LLMs) can be used require
spatial reasoning, like Point of Interest (POI) recommendation and itinerary
planning. However, on their own LLMs lack reliable spatial reasoning
capabilities, especially about distances. To address this problem, we develop a
novel approach, DistRAG, that enables an LLM to retrieve relevant spatial
information not explicitly learned during training. Our method encodes the
geodesic distances between cities and towns in a graph and retrieves a context
subgraph relevant to the question. Using this technique, our method enables an
LLM to answer distance-based reasoning questions that it otherwise cannot
answer. Given the vast array of possible places an LLM could be asked about,
DistRAG offers a flexible first step towards providing a rudimentary `world
model' to complement the linguistic knowledge held in LLMs.

</details>


### [124] [Time Course MechInterp: Analyzing the Evolution of Components and Knowledge in Large Language Models](https://arxiv.org/abs/2506.03434)
*Ahmad Dawar Hakimi,Ali Modarressi,Philipp Wicke,Hinrich Schütze*

Main category: cs.CL

TL;DR: 论文分析了OLMo-7B模型中事实知识表示的演变，发现模型从通用组件逐渐转向专用组件，且注意力头变化最大，FFNs更稳定。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）如何获取和存储事实知识，以提高其可解释性和可靠性。

Method: 通过追踪OLMo-7B模型在预训练过程中注意力头和FFNs的作用，将其分为四类角色，并分析其稳定性和转变。

Result: 模型初始依赖通用组件，后期逐渐专用化；注意力头变化最大，FFNs更稳定；基于位置的关系比基于名称的关系更早收敛。

Conclusion: 研究揭示了LLMs中知识形成的机制，为模型优化提供了新视角。

Abstract: Understanding how large language models (LLMs) acquire and store factual
knowledge is crucial for enhancing their interpretability and reliability. In
this work, we analyze the evolution of factual knowledge representation in the
OLMo-7B model by tracking the roles of its attention heads and feed forward
networks (FFNs) over the course of pre-training. We classify these components
into four roles: general, entity, relation-answer, and fact-answer specific,
and examine their stability and transitions. Our results show that LLMs
initially depend on broad, general-purpose components, which later specialize
as training progresses. Once the model reliably predicts answers, some
components are repurposed, suggesting an adaptive learning process. Notably,
attention heads display the highest turnover. We also present evidence that
FFNs remain more stable throughout training. Furthermore, our probing
experiments reveal that location-based relations converge to high accuracy
earlier in training than name-based relations, highlighting how task complexity
shapes acquisition dynamics. These insights offer a mechanistic view of
knowledge formation in LLMs.

</details>


### [125] [Culture Matters in Toxic Language Detection in Persian](https://arxiv.org/abs/2506.03458)
*Zahra Bokaei,Walid Magdy,Bonnie Webber*

Main category: cs.CL

TL;DR: 本文比较了波斯语中有毒语言检测的不同方法，包括微调、数据增强、零样本和少样本学习以及跨语言迁移学习，并探讨了文化背景对迁移学习的影响。


<details>
  <summary>Details</summary>
Motivation: 有毒语言检测对创建更安全的在线环境和限制有害内容传播至关重要，而波斯语中的相关研究较少。

Method: 比较了微调、数据增强、零样本和少样本学习以及跨语言迁移学习等方法。

Result: 文化背景对迁移学习效果有显著影响：与波斯语文化相似的语言迁移效果更好，而文化差异大的语言改进较小。

Conclusion: 文化背景是波斯语有毒语言检测中迁移学习效果的关键因素。

Abstract: Toxic language detection is crucial for creating safer online environments
and limiting the spread of harmful content. While toxic language detection has
been under-explored in Persian, the current work compares different methods for
this task, including fine-tuning, data enrichment, zero-shot and few-shot
learning, and cross-lingual transfer learning. What is especially compelling is
the impact of cultural context on transfer learning for this task: We show that
the language of a country with cultural similarities to Persian yields better
results in transfer learning. Conversely, the improvement is lower when the
language comes from a culturally distinct country. Warning: This paper contains
examples of toxic language that may disturb some readers. These examples are
included for the purpose of research on toxic detection.

</details>


### [126] [Delta-KNN: Improving Demonstration Selection in In-Context Learning for Alzheimer's Disease Detection](https://arxiv.org/abs/2506.03476)
*Chuyuan Li,Raymond Li,Thalia S. Field,Giuseppe Carenini*

Main category: cs.CL

TL;DR: Delta-KNN方法通过动态选择训练示例提升大型语言模型在阿尔茨海默病诊断中的表现，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）的早期干预需要分析语言异常，但传统上下文学习方法效果不佳。

Method: 提出Delta-KNN策略，结合delta评分和KNN检索器动态选择最优训练示例。

Result: 在三个开源LLM上实验显示Delta-KNN优于现有方法，使用Llama-3.1时达到新SOTA。

Conclusion: Delta-KNN为AD诊断提供了高效的工具，优于监督分类器。

Abstract: Alzheimer's Disease (AD) is a progressive neurodegenerative disorder that
leads to dementia, and early intervention can greatly benefit from analyzing
linguistic abnormalities. In this work, we explore the potential of Large
Language Models (LLMs) as health assistants for AD diagnosis from
patient-generated text using in-context learning (ICL), where tasks are defined
through a few input-output examples. Empirical results reveal that conventional
ICL methods, such as similarity-based selection, perform poorly for AD
diagnosis, likely due to the inherent complexity of this task. To address this,
we introduce Delta-KNN, a novel demonstration selection strategy that enhances
ICL performance. Our method leverages a delta score to assess the relative
gains of each training example, coupled with a KNN-based retriever that
dynamically selects optimal "representatives" for a given input. Experiments on
two AD detection datasets across three open-source LLMs demonstrate that
Delta-KNN consistently outperforms existing ICL baselines. Notably, when using
the Llama-3.1 model, our approach achieves new state-of-the-art results,
surpassing even supervised classifiers.

</details>


### [127] [APT: Improving Specialist LLM Performance with Weakness Case Acquisition and Iterative Preference Training](https://arxiv.org/abs/2506.03483)
*Jun Rao,Zepeng Lin,Xuebo Liu,Xiaopeng Ke,Lian Lian,Dong Jin,Shengjun Cheng,Jun Yu,Min Zhang*

Main category: cs.CL

TL;DR: APT方法通过自生成的弱点和相似数据增强领域性能，同时保留模型的通用能力。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在领域微调中通用能力下降的问题。

Method: 使用自生成的弱点和相似数据，仅针对错误样本进行训练。

Result: 在LLama-2和Mistral-V0.3上验证，APT保持通用能力且在领域任务中表现更优。

Conclusion: APT是一种有效策略，可在增强领域性能的同时不牺牲通用性。

Abstract: Large Language Models (LLMs) often require domain-specific fine-tuning to
address targeted tasks, which risks degrading their general capabilities.
Maintaining a balance between domain-specific enhancements and general model
utility is a key challenge. This paper proposes a novel approach named APT
(Weakness Case Acquisition and Iterative Preference Training) to enhance
domain-specific performance with self-generated dis-preferred weakness data
(bad cases and similar cases). APT uniquely focuses on training the model using
only those samples where errors occur, alongside a small, similar set of
samples retrieved for this purpose. This targeted training minimizes
interference with the model's existing knowledge base, effectively retaining
generic capabilities. Experimental results on the LLama-2 and Mistral-V0.3
models across various benchmarks demonstrate that APT ensures no reduction in
generic capacity and achieves superior performance on downstream tasks compared
to various existing methods. This validates our method as an effective strategy
for enhancing domain-specific capabilities without sacrificing the model's
broader applicability.

</details>


### [128] [Explainable AI: XAI-Guided Context-Aware Data Augmentation](https://arxiv.org/abs/2506.03484)
*Melkamu Abay Mersha,Mesay Gemeda Yigezu,Atnafu Lambebo Tonja,Hassan Shakil,Samer Iskander,Olga Kolesnikova,Jugal Kalita*

Main category: cs.CL

TL;DR: 论文提出了一种基于可解释AI（XAI）的上下文感知数据增强框架XAI-Guided Context-Aware Data Augmentation，通过选择性保留任务相关特征，显著提升了低资源语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统数据增强技术在低资源语言中引入噪声、语义偏移和过拟合的问题，同时利用XAI技术提升模型的可解释性和性能。

Method: 提出XAI-SR-BT和XAI-PR-BT框架，通过XAI技术迭代优化数据增强过程，保留关键特征并减少噪声。

Result: 在Amharic数据集上，XAI-SR-BT和XAI-PR-BT分别比基线模型提升了6.6%和8.1%的准确率，且优于现有数据增强技术。

Conclusion: 该研究为数据增强提供了更可控、可解释的解决方案，并展示了XAI技术在提升AI模型训练中的潜力。

Abstract: Explainable AI (XAI) has emerged as a powerful tool for improving the
performance of AI models, going beyond providing model transparency and
interpretability. The scarcity of labeled data remains a fundamental challenge
in developing robust and generalizable AI models, particularly for low-resource
languages. Conventional data augmentation techniques introduce noise, cause
semantic drift, disrupt contextual coherence, lack control, and lead to
overfitting. To address these challenges, we propose XAI-Guided Context-Aware
Data Augmentation. This novel framework leverages XAI techniques to modify less
critical features while selectively preserving most task-relevant features. Our
approach integrates an iterative feedback loop, which refines augmented data
over multiple augmentation cycles based on explainability-driven insights and
the model performance gain. Our experimental results demonstrate that XAI-SR-BT
and XAI-PR-BT improve the accuracy of models on hate speech and sentiment
analysis tasks by 6.6% and 8.1%, respectively, compared to the baseline, using
the Amharic dataset with the XLM-R model. XAI-SR-BT and XAI-PR-BT outperform
existing augmentation techniques by 4.8% and 5%, respectively, on the same
dataset and model. Overall, XAI-SR-BT and XAI-PR-BT consistently outperform
both baseline and conventional augmentation techniques across all tasks and
models. This study provides a more controlled, interpretable, and context-aware
solution to data augmentation, addressing critical limitations of existing
augmentation techniques and offering a new paradigm shift for leveraging XAI
techniques to enhance AI model training.

</details>


### [129] [EpiCoDe: Boosting Model Performance Beyond Training with Extrapolation and Contrastive Decoding](https://arxiv.org/abs/2506.03489)
*Mingxu Tao,Jie Hu,Mingchuan Yang,Yunhuai Liu,Dongyan Zhao,Yansong Feng*

Main category: cs.CL

TL;DR: EpiCoDe是一种新方法，通过在数据稀缺场景中利用模型外推和对比解码，显著提升LLM性能，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 由于高质量标注数据获取成本高，模型在下游任务中表现受限，EpiCoDe旨在解决这一问题。

Method: 结合模型外推和对比解码，通过比较外推模型和原始微调模型的logit分数减少预测错误。

Result: 在四个LLM上的三个任务中，EpiCoDe显著优于现有方法。

Conclusion: EpiCoDe有效提升数据稀缺场景下的模型性能，并通过理论框架揭示了对比解码的机制。

Abstract: The remarkable performance of Large language models (LLMs) relies heavily on
the availability of abundant high-quality training data. However, the high cost
of acquiring annotated data often prevents models from obtaining capabilities
to tackle downstream tasks. In this paper, we introduce a novel method, EpiCoDe
that boosts model performance in data-scarcity scenarios without extra
training. We first employ model extrapolation to enhance a finetuned model with
its inferior version, and then adopt contrastive decoding to further reduce
predicted errors, by comparing the logit scores given by the extrapolated and
the vanilla finetuned model. Experiments across three tasks over four different
LLMs show that EpiCoDe consistently outperforms existing methods with
significant and robust improvement. We also propose a new theoretical framework
to reveal the mechanism behind contrastive decoding in data-scarcity scenarios,
which further helps us better understand the effectiveness of EpiCoDe.

</details>


### [130] [Beyond Memorization: A Rigorous Evaluation Framework for Medical Knowledge Editing](https://arxiv.org/abs/2506.03490)
*Shigeng Chen,Linhao Luo,Zhangchi Qiu,Yanan Cao,Carl Yang,Shirui Pan*

Main category: cs.CL

TL;DR: 本文提出MedEditBench框架，用于评估知识编辑（KE）方法在医学领域的有效性，并发现现有方法仅能实现浅层记忆。作者提出SGR-Edit方法，通过模型自生成推理改进效果。


<details>
  <summary>Details</summary>
Motivation: 现有KE方法在通用领域有效，但在复杂医学领域的适用性未充分探索，需评估其能否支持可解释的决策。

Method: 提出MedEditBench框架，包括新医学知识编辑基准和三种编辑范式，并开发SGR-Edit方法，利用模型自生成推理作为编辑目标。

Result: 现有KE方法仅实现浅层记忆，无法泛化到新场景；SGR-Edit显著优于现有方法。

Conclusion: SGR-Edit通过揭示推理过程改进医学知识编辑效果，为实际应用提供指导。

Abstract: Recently, knowledge editing (KE) has emerged as a promising approach to
update specific facts in Large Language Models (LLMs) without the need for full
retraining. Despite the effectiveness in general-domain benchmarks, their
applicability to complex medical domain remains largely unexplored. Medical
knowledge editing is particularly challenging, as it requires LLMs to
internalize the knowledge and generalize to unseen scenarios for effective and
interpretable decision-making. In this work, we propose a novel framework
called MedEditBench to rigorously evaluate the effectiveness of existing KE
methods in the medical domain. In MedEditBench, we introduce a new medical
knowledge editing benchmark as well as three different knowledge editing
paradigms, which are designed to assess the impact of different knowledge
sources for editing. Our findings indicate that current KE methods result in
only superficial memorization of the injected information, failing to
generalize to new scenarios. To overcome this limitation, we present
Self-Generated Rationale Editing (SGR-Edit), which utilizes model-derived
rationales as the target knowledge for editing, thereby uncovering the
underlying reasoning process and demonstrating significant improvements over
existing KE approaches. Additionally, we offer deeper insights into medical
knowledge editing, including the localization of medical knowledge in LLMs and
the impact of sequential editing on evolving knowledge. This could provide
practical guidance for implementing KE methods in real-world medical
applications.

</details>


### [131] [Measuring Human Involvement in AI-Generated Text: A Case Study on Academic Writing](https://arxiv.org/abs/2506.03501)
*Yuchen Guo,Zhicheng Dou,Huy H. Nguyen,Ching-Chun Chang,Saku Sugawara,Isao Echizen*

Main category: cs.CL

TL;DR: 论文提出了一种基于BERTScore和多任务RoBERTa回归器的方法，用于检测文本生成中的人类参与程度，解决了传统二元分类方法的不足。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的普及，人类与机器协作生成文本的现象日益普遍，但现有检测方法仅关注二元分类，无法准确反映人类参与程度。

Method: 使用BERTScore量化人类参与度，并设计多任务RoBERTa回归器进行检测，同时创建连续数据集模拟不同参与程度。

Result: 在模拟学术场景的数据集上，该方法表现优异（F1分数0.9423，回归均方误差0.004），且具有一定泛化能力。

Conclusion: 该方法有效解决了人类参与检测的模糊性问题，为未来研究提供了新方向。

Abstract: Content creation has dramatically progressed with the rapid advancement of
large language models like ChatGPT and Claude. While this progress has greatly
enhanced various aspects of life and work, it has also negatively affected
certain areas of society. A recent survey revealed that nearly 30% of college
students use generative AI to help write academic papers and reports. Most
countermeasures treat the detection of AI-generated text as a binary
classification task and thus lack robustness. This approach overlooks human
involvement in the generation of content even though human-machine
collaboration is becoming mainstream. Besides generating entire texts, people
may use machines to complete or revise texts. Such human involvement varies
case by case, which makes binary classification a less than satisfactory
approach. We refer to this situation as participation detection obfuscation. We
propose using BERTScore as a metric to measure human involvement in the
generation process and a multi-task RoBERTa-based regressor trained on a token
classification task to address this problem. To evaluate the effectiveness of
this approach, we simulated academic-based scenarios and created a continuous
dataset reflecting various levels of human involvement. All of the existing
detectors we examined failed to detect the level of human involvement on this
dataset. Our method, however, succeeded (F1 score of 0.9423 and a regressor
mean squared error of 0.004). Moreover, it demonstrated some generalizability
across generative models. Our code is available at
https://github.com/gyc-nii/CAS-CS-and-dual-head-detector

</details>


### [132] [Accurate Sublayer Pruning for Large Language Models by Exploiting Latency and Tunability Information](https://arxiv.org/abs/2506.03510)
*Seungcheol Park,Sojin Lee,Jongjin Kim,Jinsik Lee,Hyunjik Jo,U Kang*

Main category: cs.CL

TL;DR: SPRINT是一种基于延迟和可调性信息的大语言模型子层剪枝方法，显著提升推理速度且保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型推理速度慢，现有子层剪枝方法因忽略子层特性而准确性不足。

Method: SPRINT通过考虑延迟减少量和子层可调性，迭代剪枝冗余子层并快速调参。

Result: 实验显示，SPRINT在零样本常识推理任务中比现有方法准确率提升23.88%。

Conclusion: SPRINT在速度与准确性间取得最佳平衡，适用于高效LLM推理。

Abstract: How can we accelerate large language models(LLMs) without sacrificing
accuracy? The slow inference speed of LLMs hinders us to benefit from their
remarkable performance in diverse applications. This is mainly because numerous
sublayers are stacked together in LLMs. Sublayer pruning compresses and
expedites LLMs via removing unnecessary sublayers. However, existing sublayer
pruning algorithms are limited in accuracy since they naively select sublayers
to prune, overlooking the different characteristics of each sublayer. In this
paper, we propose SPRINT (Sublayer PRuning wIth LateNcy and Tunability
Information), an accurate sublayer pruning method for LLMs. SPRINT accurately
selects a target sublayer to prune by considering 1) the amount of latency
reduction after pruning and 2) the tunability of sublayers. SPRINT iteratively
prunes redundant sublayers and swiftly tunes the parameters of remaining
sublayers. Experiments show that SPRINT achieves the best accuracy-speedup
trade-off, exhibiting up to 23.88%p higher accuracy on zero-shot commonsense
reasoning benchmarks compared to existing pruning algorithms.

</details>


### [133] [An Efficient Task-Oriented Dialogue Policy: Evolutionary Reinforcement Learning Injected by Elite Individuals](https://arxiv.org/abs/2506.03519)
*Yangyang Zhao,Ben Niu,Libo Qin,Shihan Wang*

Main category: cs.CL

TL;DR: 该论文提出了一种结合进化算法（EA）和深度强化学习（DRL）的方法，通过精英个体注入机制优化任务导向对话系统的探索与利用平衡。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习在任务导向对话系统中难以平衡探索与利用，导致局部最优或收敛性差，而进化算法能有效探索解空间。因此，作者希望结合两者的优势。

Method: 创新性地将EA的全局搜索能力与DRL的局部优化结合，并引入精英个体注入机制以提高EA的搜索效率。

Result: 在四个数据集上的实验表明，该方法显著改善了探索与利用的平衡，提升了性能，同时精英个体注入机制有效减少了探索时间。

Conclusion: 该方法成功实现了EA与DRL在任务导向对话策略任务中的高效结合，为类似问题提供了新思路。

Abstract: Deep Reinforcement Learning (DRL) is widely used in task-oriented dialogue
systems to optimize dialogue policy, but it struggles to balance exploration
and exploitation due to the high dimensionality of state and action spaces.
This challenge often results in local optima or poor convergence. Evolutionary
Algorithms (EAs) have been proven to effectively explore the solution space of
neural networks by maintaining population diversity. Inspired by this, we
innovatively combine the global search capabilities of EA with the local
optimization of DRL to achieve a balance between exploration and exploitation.
Nevertheless, the inherent flexibility of natural language in dialogue tasks
complicates this direct integration, leading to prolonged evolutionary times.
Thus, we further propose an elite individual injection mechanism to enhance
EA's search efficiency by adaptively introducing best-performing individuals
into the population. Experiments across four datasets show that our approach
significantly improves the balance between exploration and exploitation,
boosting performance. Moreover, the effectiveness of the EII mechanism in
reducing exploration time has been demonstrated, achieving an efficient
integration of EA and DRL on task-oriented dialogue policy tasks.

</details>


### [134] [TokAlign: Efficient Vocabulary Adaptation via Token Alignment](https://arxiv.org/abs/2506.03523)
*Chong Li,Jiajun Zhang,Chengqing Zong*

Main category: cs.CL

TL;DR: TokAlign是一种高效方法，通过词汇替换和知识迁移优化LLM的tokenizer，显著提升多语言文本压缩率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决新领域或语言中tokenizer效率低下及词汇不匹配问题，促进LLM间的知识迁移。

Method: 通过token共现学习一对一映射矩阵，调整模型参数并微调，实现词汇对齐和知识转移。

Result: 多语言文本压缩率提升，困惑度从3.4e²降至1.2e²，仅需5k步恢复性能。

Conclusion: TokAlign有效统一词汇并提升token级蒸馏效果，成本低且泛化性强。

Abstract: Tokenization serves as a foundational step for Large Language Models (LLMs)
to process text. In new domains or languages, the inefficiency of the tokenizer
will slow down the training and generation of LLM. The mismatch in vocabulary
also hinders deep knowledge transfer between LLMs like token-level
distillation. To mitigate this gap, we propose an efficient method named
TokAlign to replace the vocabulary of LLM from the token co-occurrences view,
and further transfer the token-level knowledge between models. It first aligns
the source vocabulary to the target one by learning a one-to-one mapping matrix
for token IDs. Model parameters, including embeddings, are rearranged and
progressively fine-tuned for the new vocabulary. Our method significantly
improves multilingual text compression rates and vocabulary initialization for
LLMs, decreasing the perplexity from 3.4$\text{e}^2$ of strong baseline methods
to 1.2$\text{e}^2$ after initialization. Experimental results on models across
multiple parameter scales demonstrate the effectiveness and generalization of
TokAlign, which costs as few as 5k steps to restore the performance of the
vanilla model. After unifying vocabularies between LLMs, token-level
distillation can remarkably boost (+4.4% than sentence-level distillation) the
base model, costing only 235M tokens.

</details>


### [135] [Seed-Coder: Let the Code Model Curate Data for Itself](https://arxiv.org/abs/2506.03524)
*Yuyu Zhang,Jing Su,Yifan Sun,Chenguang Xi,Xia Xiao,Shen Zheng,Anxiang Zhang,Kaibo Liu,Daoguang Zan,Tao Sun,Jinhua Zhu,Shulin Xin,Dong Huang,Yetao Bai,Lixin Dong,Chao Li,Jianchong Chen,Hanzhi Zhou,Yifan Huang,Guanghan Ning,Xierui Song,Jiaze Chen,Siyao Liu,Kai Shen,Liang Xiang,Yonghui Wu*

Main category: cs.CL

TL;DR: Seed-Coder是一个开源LLM系列，通过模型中心的数据管道减少人工干预，在代码生成、推理等任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前开源LLM的代码预训练数据依赖人工，存在扩展性差、主观偏见和成本高的问题。

Method: 采用模型中心的数据管道，利用LLM评分和过滤代码数据；指导模型通过监督微调和偏好优化训练；推理模型使用LongCoT强化学习。

Result: Seed-Coder在同类开源模型中表现最佳，甚至超越部分更大模型。

Conclusion: Seed-Coder展示了模型中心数据管道的有效性，为代码相关任务提供了高效解决方案。

Abstract: Code data in large language model (LLM) pretraining is recognized crucial not
only for code-related tasks but also for enhancing general intelligence of
LLMs. Current open-source LLMs often heavily rely on human effort to produce
their code pretraining data, such as employing hand-crafted filtering rules
tailored to individual programming languages, or using human-annotated data to
train quality filters. However, these approaches are inherently limited in
scalability, prone to subjective biases, and costly to extend and maintain
across diverse programming languages. To address these challenges, we introduce
Seed-Coder, a series of open-source LLMs comprising base, instruct and
reasoning models of 8B size, minimizing human involvement in data construction.
Our code pretraining data is produced by a model-centric data pipeline, which
predominantly leverages LLMs for scoring and filtering code data. The instruct
model is further trained via supervised fine-tuning and preference
optimization, and the reasoning model leverages Long-Chain-of-Thought (LongCoT)
reinforcement learning to improve multi-step code reasoning. Seed-Coder
achieves state-of-the-art results among open-source models of similar size and
even surpasses some much larger models, demonstrating superior performance in
code generation, code completion, code editing, code reasoning, and software
engineering tasks.

</details>


### [136] [Go-Browse: Training Web Agents with Structured Exploration](https://arxiv.org/abs/2506.03533)
*Apurva Gandhi,Graham Neubig*

Main category: cs.CL

TL;DR: Go-Browse提出了一种通过结构化探索网络环境自动收集多样化、真实网络代理数据的方法，显著提升了数字代理对环境的理解能力。


<details>
  <summary>Details</summary>
Motivation: 数字代理在陌生网络环境中容易迷失方向，缺乏对环境的理解，导致任务执行效率低下。

Method: 将数据收集问题建模为图搜索，通过结构化探索网络环境，实现了信息的跨探索片段复用。

Result: 在WebArena基准测试中，收集了10K成功任务轨迹和40K交互步骤，微调后的7B参数模型成功率达到21.7%，超越了GPT-4o mini和当前最先进的小模型。

Conclusion: Go-Browse方法有效提升了网络代理的任务执行能力，为小模型在复杂环境中的表现提供了新思路。

Abstract: One of the fundamental problems in digital agents is their lack of
understanding of their environment. For instance, a web browsing agent may get
lost in unfamiliar websites, uncertain what pages must be visited to achieve
its goals. To address this, we propose Go-Browse, a method for automatically
collecting diverse and realistic web agent data at scale through structured
exploration of web environments. Go-Browse achieves efficient exploration by
framing data collection as a graph search, enabling reuse of information across
exploration episodes. We instantiate our method on the WebArena benchmark,
collecting a dataset of 10K successful task-solving trajectories and 40K
interaction steps across 100 URLs. Fine-tuning a 7B parameter language model on
this dataset achieves a success rate of 21.7% on the WebArena benchmark,
beating GPT-4o mini by 2.4% and exceeding current state-of-the-art results for
sub-10B parameter models by 2.9%.

</details>


### [137] [Debate, Reflect, and Distill: Multi-Agent Feedback with Tree-Structured Preference Optimization for Efficient Language Model Enhancement](https://arxiv.org/abs/2506.03541)
*Xiaofeng Zhou,Heyan Huang,Lizi Liao*

Main category: cs.CL

TL;DR: 论文提出了一种新颖的Debate and Reflect (D&R)框架，通过小模型与强教师模型的多轮辩论生成反馈，并结合Tree-structured Direct Preference Optimization (T-DPO)高效利用辩论日志，显著提升了小模型的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在知识密集和复杂推理任务中表现出色，但其高计算需求限制了广泛应用。现有蒸馏技术难以实现显著且持久的性能提升。

Method: 提出了D&R框架，组织小模型与教师模型的多轮辩论以生成反馈，并引入T-DPO方法，将辩论日志组织为层次结构以优化训练。

Result: 在多个NLP基准测试中，该方法显著提升了小模型的准确性、鲁棒性和泛化能力，远超传统基线。

Conclusion: D&R框架和T-DPO方法为小模型的高效训练提供了可持续解决方案，具有广泛的应用潜力。

Abstract: Large Language Models (LLMs) continue to set new standards in
knowledge-intensive and complex reasoning tasks, yet their high computational
demands limit widespread adoption. While distilling large models into smaller
ones offers a sustainable solution, current techniques--such as static
knowledge distillation, resource-intensive reinforcement learning from human
feedback, or limited self-reflection--struggle to yield substantial and lasting
performance gains. In this paper, we present a novel Debate and Reflect (D&R)
framework that orchestrates multi-turn debates between smaller models and
stronger teacher models, eliciting actionable feedback (e.g., error analysis,
corrective strategies) to guide student models. Further, we introduce
Tree-structured Direct Preference Optimization (T-DPO) to efficiently leverage
these debate logs, organizing interactions into a hierarchical format for
effective training. Empirical evaluations across diverse NLP benchmarks
demonstrate that our approach significantly improves smaller-model accuracy,
robustness, and generalization, outperforming conventional baselines by a large
margin.

</details>


### [138] [BPO: Revisiting Preference Modeling in Direct Preference Optimization](https://arxiv.org/abs/2506.03557)
*Lin Sun,Chuang Liu,Peng Liu,Bingyang Li,Weijia Lu,Ning Wu*

Main category: cs.CL

TL;DR: BPO是一种新框架，通过动态平衡选择和拒绝响应的优化，解决了DPO中绝对奖励幅度忽略的问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: DPO方法虽然有效，但忽略了绝对奖励幅度，导致选择响应概率下降和分布外响应风险增加（DCR问题）。

Method: BPO通过平衡奖励边际和间隙适配器动态优化选择和拒绝响应，无需额外约束。

Result: 在数学推理任务中，BPO显著优于DPO和其他变体，准确率提升最高达11.7%。

Conclusion: BPO简单易实现，仅需一行代码修改，且完全兼容现有DPO框架。

Abstract: Direct Preference Optimization (DPO) have emerged as a popular method for
aligning Large Language Models (LLMs) with human preferences. While DPO
effectively preserves the relative ordering between chosen and rejected
responses through pairwise ranking losses, it often neglects absolute reward
magnitudes. This oversight can decrease the likelihood of chosen responses and
increase the risk of generating out-of-distribution responses, leading to poor
performance. We term this issue Degraded Chosen Responses (DCR).To address this
issue, we propose Balanced Preference Optimization (BPO), a novel framework
that dynamically balances the optimization of chosen and rejected responses
through two key components: balanced reward margin and gap adaptor. Unlike
previous methods, BPO can fundamentally resolve DPO's DCR issue, without
introducing additional constraints to the loss function. Experimental results
on multiple mathematical reasoning tasks show that BPO significantly
outperforms DPO, improving accuracy by +10.1% with Llama-3.1-8B-Instruct (18.8%
to 28.9%) and +11.7% with Qwen2.5-Math-7B (35.0% to 46.7%). It also surpasses
DPO variants by +3.6% over IPO (43.1%), +5.0% over SLiC (41.7%), and +3.1% over
Cal-DPO (43.6%) on the same model. Remarkably, our algorithm requires only a
single line of code modification, making it simple to implement and fully
compatible with existing DPO-based frameworks.

</details>


### [139] [ConsistentChat: Building Skeleton-Guided Consistent Dialogues for Large Language Models from Scratch](https://arxiv.org/abs/2506.03558)
*Jiawei Chen,Xinyan Guan,Qianhao Yuan,Guozhao Mo,Weixiang Zhou,Yaojie Lu,Hongyu Lin,Ben He,Le Sun,Xianpei Han*

Main category: cs.CL

TL;DR: 论文提出了一种骨架引导的多轮对话生成框架，通过明确建模人类对话意图，解决了现有单轮指令数据合成方法在多轮对话中的连贯性问题。


<details>
  <summary>Details</summary>
Motivation: 现有指令数据合成方法主要关注单轮指令，忽视了多轮对话的连贯性，导致上下文漂移和任务完成率下降。

Method: 框架分为两阶段：意图建模（将对话归类到九种预定义意图轨迹）和骨架生成（构建与意图对齐的用户查询序列）。

Result: 构建了ConsistentChat数据集，实验显示模型在多轮对话连贯性和任务成功率上显著提升。

Conclusion: 该方法在多轮对话生成中表现出色，显著优于现有单轮和多轮指令数据集训练的模型。

Abstract: Current instruction data synthesis methods primarily focus on single-turn
instructions and often neglect cross-turn coherence, resulting in context drift
and reduced task completion rates in extended conversations. To address this
limitation, we propose Skeleton-Guided Multi-Turn Dialogue Generation, a
framework that constrains multi-turn instruction synthesis by explicitly
modeling human conversational intent. It operates in two stages: (1) Intent
Modeling, which captures the global structure of human dialogues by assigning
each conversation to one of nine well-defined intent trajectories, ensuring a
coherent and goal-oriented information flow; and (2) Skeleton Generation, which
constructs a structurally grounded sequence of user queries aligned with the
modeled intent, thereby serving as a scaffold that constrains and guides the
downstream instruction synthesis process. Based on this process, we construct
ConsistentChat, a multi-turn instruction dataset with approximately 15,000
multi-turn conversations and 224,392 utterances. Experiments on the Light,
Topdial, and MT-Eval benchmarks show that models fine-tuned on ConsistentChat
achieve a 20-30% improvement in chat consistency and up to a 15% increase in
task success rate, significantly outperforming models trained on existing
single-turn and multi-turn instruction datasets.

</details>


### [140] [POSS: Position Specialist Generates Better Draft for Speculative Decoding](https://arxiv.org/abs/2506.03566)
*Langlin Huang,Chengsong Huang,Jixuan Leng,Di Huang,Jiaxin Huang*

Main category: cs.CL

TL;DR: 提出了一种名为Position Specialists (PosS)的方法，通过多个位置专用的草稿层提升大型语言模型推理中的令牌接受率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在草稿模型生成的特征中因错误累积导致后期位置预测质量下降，需要改进。

Method: 使用多个位置专用的草稿层（PosS），每个层专注于处理特定位置的令牌预测。

Result: 在Llama-3-8B-Instruct和Llama-2-13B-chat模型上，PosS显著提升了平均接受长度和加速比。

Conclusion: PosS有效解决了草稿模型后期预测质量下降的问题，提升了推理效率。

Abstract: Speculative decoding accelerates Large Language Model (LLM) inference by
using a small draft model to predict multiple tokens, and a large target model
to verify these tokens in parallel. Recent studies leverage the hidden state of
the target model to enhance draft model prediction accuracy. However, existing
methods suffer from the degrading quality of draft token predictions at later
positions, due to error accumulation in draft model generated features. In this
paper, we propose Position Specialists (PosS), which consist of multiple
position-specialized draft layers to generate tokens at assigned position(s).
Position specialists greatly improve token acceptance rate at later positions
per drafting round, as each specialist only needs to focus on handling a
certain level of draft model feature deviation. Experiment results on
Llama-3-8B-Instruct and Llama-2-13B-chat across six datasets demonstrate that
PosS effectively improves over baselines on average acceptance length and
speed-up ratio. Our codebase is available at https://github.com/shrango/PosS.

</details>


### [141] [MiMo-VL Technical Report](https://arxiv.org/abs/2506.03569)
*Xiaomi LLM-Core Team,:,Zihao Yue,Zhenru Lin,Yifan Song,Weikun Wang,Shuhuai Ren,Shuhao Gu,Shicheng Li,Peidian Li,Liang Zhao,Lei Li,Kainan Bao,Hao Tian,Hailin Zhang,Gang Wang,Dawei Zhu,Cici,Chenhong He,Bowen Ye,Bowen Shen,Zihan Zhang,Zihan Jiang,Zhixian Zheng,Zhichao Song,Zhenbo Luo,Yue Yu,Yudong Wang,Yuanyuan Tian,Yu Tu,Yihan Yan,Yi Huang,Xu Wang,Xinzhe Xu,Xingchen Song,Xing Zhang,Xing Yong,Xin Zhang,Xiangwei Deng,Wenyu Yang,Wenhan Ma,Weiwei Lv,Weiji Zhuang,Wei Liu,Sirui Deng,Shuo Liu,Shimao Chen,Shihua Yu,Shaohui Liu,Shande Wang,Rui Ma,Qiantong Wang,Peng Wang,Nuo Chen,Menghang Zhu,Kangyang Zhou,Kang Zhou,Kai Fang,Jun Shi,Jinhao Dong,Jiebao Xiao,Jiaming Xu,Huaqiu Liu,Hongshen Xu,Heng Qu,Haochen Zhao,Hanglong Lv,Guoan Wang,Duo Zhang,Dong Zhang,Di Zhang,Chong Ma,Chang Liu,Can Cai,Bingquan Xia*

Main category: cs.CL

TL;DR: MiMo-VL-7B-SFT和MiMo-VL-7B-RL是两个开源的视觉语言模型，在多模态推理和视觉理解任务中表现优异，尤其在GUI任务中表现突出。


<details>
  <summary>Details</summary>
Motivation: 推动视觉语言模型在多模态任务中的性能提升，特别是在通用视觉理解和GUI任务中。

Method: 采用四阶段预训练（2.4万亿token）和混合策略强化学习（MORL），结合高质量推理数据和长链思维。

Result: MiMo-VL-7B-RL在40项任务中35项优于Qwen2.5-VL-7B，并在OlympiadBench和OSWorld-G任务中表现卓越。

Conclusion: 模型通过预训练和强化学习的结合显著提升了性能，同时提供了全面的评估套件以促进研究复现。

Abstract: We open-source MiMo-VL-7B-SFT and MiMo-VL-7B-RL, two powerful vision-language
models delivering state-of-the-art performance in both general visual
understanding and multimodal reasoning. MiMo-VL-7B-RL outperforms Qwen2.5-VL-7B
on 35 out of 40 evaluated tasks, and scores 59.4 on OlympiadBench, surpassing
models with up to 78B parameters. For GUI grounding applications, it sets a new
standard with 56.1 on OSWorld-G, even outperforming specialized models such as
UI-TARS. Our training combines four-stage pre-training (2.4 trillion tokens)
with Mixed On-policy Reinforcement Learning (MORL) integrating diverse reward
signals. We identify the importance of incorporating high-quality reasoning
data with long Chain-of-Thought into pre-training stages, and the benefits of
mixed RL despite challenges in simultaneous multi-domain optimization. We also
contribute a comprehensive evaluation suite covering 50+ tasks to promote
reproducibility and advance the field. The model checkpoints and full
evaluation suite are available at https://github.com/XiaomiMiMo/MiMo-VL.

</details>


### [142] [FreePRM: Training Process Reward Models Without Ground Truth Process Labels](https://arxiv.org/abs/2506.03570)
*Lin Sun,Chuang Liu,Xiaofeng Ma,Tao Yang,Weijia Lu,Ning Wu*

Main category: cs.CL

TL;DR: FreePRM是一个弱监督框架，无需真实步骤级标签即可训练过程奖励模型（PRM），通过伪标签生成和缓冲概率去噪，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 训练PRM通常需要步骤级标签，成本高且难以大规模获取，FreePRM旨在解决这一问题。

Method: FreePRM基于最终结果的正确性生成伪步骤级标签，并使用缓冲概率减少噪声影响。

Result: 在ProcessBench上平均F1得分为53.0%，优于其他PRM模型，提升显著。

Conclusion: FreePRM为PRM训练提供了新范式，减少对昂贵标签的依赖，同时保持高性能。

Abstract: Recent advancements in Large Language Models (LLMs) have demonstrated that
Process Reward Models (PRMs) play a crucial role in enhancing model
performance. However, training PRMs typically requires step-level labels,
either manually annotated or automatically generated, which can be costly and
difficult to obtain at scale. To address this challenge, we introduce FreePRM,
a weakly supervised framework for training PRMs without access to ground-truth
step-level labels. FreePRM first generates pseudo step-level labels based on
the correctness of final outcome, and then employs Buffer Probability to
eliminate impact of noise inherent in pseudo labeling. Experimental results
show that FreePRM achieves an average F1 score of 53.0% on ProcessBench,
outperforming fully supervised PRM trained on Math-Shepherd by +24.1%. Compared
to other open-source PRMs, FreePRM outperforms upon RLHFlow-PRM-Mistral-8B
(28.4%) by +24.6%, EurusPRM (31.3%) by +21.7%, and Skywork-PRM-7B (42.1%) by
+10.9%. This work introduces a new paradigm in PRM training, significantly
reducing reliance on costly step-level annotations while maintaining strong
performance.

</details>


### [143] [Exchange of Perspective Prompting Enhances Reasoning in Large Language Models](https://arxiv.org/abs/2506.03573)
*Lin Sun,Can Zhang*

Main category: cs.CL

TL;DR: 提出了一种名为Exchange-of-Perspective (EoP)的新框架，通过交换不同问题定义的视角，打破固定思维模式，显著提升大语言模型在多种NLP任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在解决多样化NLP任务时表现受限，主要源于对问题的固有理解不足。

Method: 提出EoP框架，通过交换不同问题定义的视角，打破固定思维模式。

Result: 在8个基准测试中，EoP显著提升了性能，例如GPT-3.5-Turbo结合EoP在AQuA上提升了3.6%，GPT-4结合EoP在Math上提升了7.7%。

Conclusion: EoP框架有效提升了大语言模型在复杂任务中的表现，展示了其潜力。

Abstract: Large language models (LLMs) have made significant advancements in addressing
diverse natural language processing (NLP) tasks. However, their performance is
often limited by inherent comprehension of problems. To address this
limitation, we propose Exchange-of-Perspective (EoP), a novel framework
designed to exchange perspectives across different definitions of problem, so
that it can break the fixed mindset from any particular formulation of the
question. We conducted extensive and comprehensive experiments on 8 benchmarks.
The results show that EoP can significantly improve performance. For instance,
compared to the non-commutative baseline PHP, with GPT-3.5-Turbo and EoP, we
observe a 3.6% improvement on AQuA (60.6% to 64.2%), while GPT-4-powered EoP
demonstrates a 7.7% overall accuracy enhancement on Math (53.9% to 61.6%) and a
3.5% improvement on OlympiadBench Maths (43.5% to 47.0%) when using
Qwen-2.5-72b.

</details>


### [144] [KG-BiLM: Knowledge Graph Embedding via Bidirectional Language Models](https://arxiv.org/abs/2506.03576)
*Zirui Chen,Xin Wang,Zhao Li,Wenbin Guo,Dongxiao He*

Main category: cs.CL

TL;DR: KG-BiLM是一个双向语言模型框架，结合知识图谱的结构信息与生成式变换器的语义表达能力，填补了现有方法在统一全局KG连通性、语言上下文和推理语义方面的空白。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常仅关注知识图谱的结构或文本语义，缺乏一个统一框架来同时捕捉全局连通性、语言上下文和推理语义。

Method: KG-BiLM包含三个关键组件：双向知识注意力、知识掩码预测和对比图语义聚合。

Result: 实验表明，KG-BiLM在链接预测任务中优于基线方法，尤其是在具有复杂多跳关系的大规模图谱上。

Conclusion: KG-BiLM有效统一了结构信息和文本语义，验证了其优越性。

Abstract: Recent advances in knowledge representation learning (KRL) highlight the
urgent necessity to unify symbolic knowledge graphs (KGs) with language models
(LMs) for richer semantic understanding. However, existing approaches typically
prioritize either graph structure or textual semantics, leaving a gap: a
unified framework that simultaneously captures global KG connectivity, nuanced
linguistic context, and discriminative reasoning semantics. To bridge this gap,
we introduce KG-BiLM, a bidirectional LM framework that fuses structural cues
from KGs with the semantic expressiveness of generative transformers. KG-BiLM
incorporates three key components: (i) Bidirectional Knowledge Attention, which
removes the causal mask to enable full interaction among all tokens and
entities; (ii) Knowledge-Masked Prediction, which encourages the model to
leverage both local semantic contexts and global graph connectivity; and (iii)
Contrastive Graph Semantic Aggregation, which preserves KG structure via
contrastive alignment of sampled sub-graph representations. Extensive
experiments on standard benchmarks demonstrate that KG-BiLM outperforms strong
baselines in link prediction, especially on large-scale graphs with complex
multi-hop relations - validating its effectiveness in unifying structural
information and textual semantics.

</details>


### [145] [Automatically Suggesting Diverse Example Sentences for L2 Japanese Learners Using Pre-Trained Language Models](https://arxiv.org/abs/2506.03580)
*Enrico Benedetti,Akiko Aizawa,Florian Boudin*

Main category: cs.CL

TL;DR: 研究探讨了使用预训练语言模型（PLMs）为日语学习者生成多样化且符合其水平的例句，发现检索方法优于生成方法。


<details>
  <summary>Details</summary>
Motivation: 为语言学习者提供多样化且符合其水平的例句对语言习得至关重要。

Method: 利用PLMs作为检索系统中的质量评分组件，以及通过零样本学习直接生成例句。

Result: 检索方法在所有评估者中更受欢迎，生成方法评分较低，但PLMs显示出提升句子推荐系统适应性的潜力。

Conclusion: PLMs可用于改进句子推荐系统，从而优化语言学习体验。

Abstract: Providing example sentences that are diverse and aligned with learners'
proficiency levels is essential for fostering effective language acquisition.
This study examines the use of Pre-trained Language Models (PLMs) to produce
example sentences targeting L2 Japanese learners. We utilize PLMs in two ways:
as quality scoring components in a retrieval system that draws from a newly
curated corpus of Japanese sentences, and as direct sentence generators using
zero-shot learning. We evaluate the quality of sentences by considering
multiple aspects such as difficulty, diversity, and naturalness, with a panel
of raters consisting of learners of Japanese, native speakers -- and GPT-4. Our
findings suggest that there is inherent disagreement among participants on the
ratings of sentence qualities, except for difficulty. Despite that, the
retrieval approach was preferred by all evaluators, especially for beginner and
advanced target proficiency, while the generative approaches received lower
scores on average. Even so, our experiments highlight the potential for using
PLMs to enhance the adaptability of sentence suggestion systems and therefore
improve the language learning journey.

</details>


### [146] [From Understanding to Generation: An Efficient Shortcut for Evaluating Language Models](https://arxiv.org/abs/2506.03592)
*Viktor Hangya,Fabian Küch,Darina Gold*

Main category: cs.CL

TL;DR: 论文提出将生成式任务（NLG）转化为更便宜的理解式任务（NLU），以减少评估时间，实验显示两者性能强相关，评估时间平均减少35倍。


<details>
  <summary>Details</summary>
Motivation: 在LLM训练中，生成式任务（如推理和代码生成）评估耗时且计算密集，而理解式任务（NLU）更便宜。目标是降低NLG基准的计算负担，以便在训练中监控关键能力。

Method: 将生成式任务重新设计为更便宜的理解式任务，测试8种不同规模的LM在4种能力（数学推理、代码生成、事实知识和阅读理解）上的性能相关性。

Result: 结果显示两种任务格式间存在强相关性，支持通过更便宜的替代方案评估能力，评估时间平均减少35倍。

Conclusion: 通过将生成式任务转化为理解式任务，可以显著降低评估成本，同时保持能力评估的有效性。

Abstract: Iterative evaluation of LLMs during training is essential to ensure expected
capability development, but can be time- and compute-intensive. While NLU
tasks, where the model selects from fixed answer choices, are cheap to
evaluate, essential capabilities like reasoning and code generation rely on the
more time-consuming NLG (token-by-token generation) format. In this work, our
aim is to decrease the computational burden of NLG benchmarks in order to
enable monitoring crucial LLM capabilities during model training. We
reformulate generative tasks into computationally cheaper NLU alternatives. We
test the performance correlation between the original and reformulated tasks
using 8 LMs of various sizes and 4 capabilities: mathematical reasoning, code
generation, factual knowledge and reading comprehension. Our results show a
strong correlation between task formats, supporting capability assessment via
cheaper alternatives and achieving over 35x average reduction in evaluation
time. We plan to publish our benchmark adaptions.

</details>


### [147] [Is linguistically-motivated data augmentation worth it?](https://arxiv.org/abs/2506.03593)
*Ray Groshan,Michael Ginn,Alexis Palmer*

Main category: cs.CL

TL;DR: 论文系统比较了语言无关和语言相关的数据增强策略在低资源语言任务中的效果，发现语言相关策略在生成数据与训练分布相似时更有效。


<details>
  <summary>Details</summary>
Motivation: 解决数据稀缺问题，探索语言无关和语言相关数据增强策略的实际效果差异。

Method: 对两种低资源语言（Uspanteko和Arapaho）进行多种数据增强策略及其组合的实验，评估机器翻译和词间注释任务的效果。

Result: 语言相关策略在生成数据与训练分布相似时优于语言无关策略。

Conclusion: 语言相关数据增强策略的有效性取决于生成数据与原始数据的分布相似性。

Abstract: Data augmentation, a widely-employed technique for addressing data scarcity,
involves generating synthetic data examples which are then used to augment
available training data. Researchers have seen surprising success from simple
methods, such as random perturbations from natural examples, where models seem
to benefit even from data with nonsense words, or data that doesn't conform to
the rules of the language. A second line of research produces synthetic data
that does in fact follow all linguistic constraints; these methods require some
linguistic expertise and are generally more challenging to implement. No
previous work has done a systematic, empirical comparison of both
linguistically-naive and linguistically-motivated data augmentation strategies,
leaving uncertainty about whether the additional time and effort of
linguistically-motivated data augmentation work in fact yields better
downstream performance.
  In this work, we conduct a careful and comprehensive comparison of
augmentation strategies (both linguistically-naive and
linguistically-motivated) for two low-resource languages with different
morphological properties, Uspanteko and Arapaho. We evaluate the effectiveness
of many different strategies and their combinations across two important
sequence-to-sequence tasks for low-resource languages: machine translation and
interlinear glossing. We find that linguistically-motivated strategies can have
benefits over naive approaches, but only when the new examples they produce are
not significantly unlike the training data distribution.

</details>


### [148] [Auto prompt sql: a resource-efficient architecture for text-to-sql translation in constrained environments](https://arxiv.org/abs/2506.03598)
*Zetong Tang,Qian Ma,Di Wu*

Main category: cs.CL

TL;DR: 本文提出了一种名为AP-SQL的新架构，旨在在资源受限环境中高效实现Text-to-SQL任务，通过分解任务、优化提示工程和微调大模型来提升性能。


<details>
  <summary>Details</summary>
Motivation: 在资源受限环境中使用现有Text-to-SQL方法存在挑战，因为它们依赖资源密集型开源模型。本文旨在通过AP-SQL架构解决这一问题。

Method: AP-SQL将任务分解为模式过滤、基于上下文示例的检索增强Text-to-SQL生成，以及提示驱动的模式链接和SQL生成。通过微调大模型和优化提示工程（如CoT和GoT模板）提升性能。

Result: 在Spider基准测试上的全面评估证明了AP-SQL的有效性。

Conclusion: AP-SQL通过结合小开源模型和大闭源模型的优势，显著提升了资源受限环境中的Text-to-SQL任务性能。

Abstract: Using the best Text-to-SQL methods in resource-constrained environments is
challenging due to their reliance on resource-intensive open-source models.
This paper introduces Auto Prompt SQL(AP-SQL), a novel architecture designed to
bridge the gap between resource-efficient small open-source models and the
powerful capabilities of large closed-source models for Text-to-SQL
translation. Our method decomposes the task into schema filtering,
retrieval-augmented text-to-SQL generation based on in-context examples, and
prompt-driven schema linking and SQL generation. To improve schema selection
accuracy, we fine-tune large language models. Crucially, we also explore the
impact of prompt engineering throughout the process, leveraging
Chain-of-Thought(CoT) and Graph-of-Thought(GoT) templates to significantly
enhance the model's reasoning for accurate SQL generation. Comprehensive
evaluations on the Spider benchmarks demonstrate the effectiveness of AP-SQL.

</details>


### [149] [Learning to Insert [PAUSE] Tokens for Better Reasoning](https://arxiv.org/abs/2506.03616)
*Eunki Kim,Sangryul Kim,James Thorne*

Main category: cs.CL

TL;DR: 提出了一种动态插入标记训练方法（DIT），通过在模型置信度最低的位置插入[PAUSE]标记，显著提升了模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 增强基于Transformer的大语言模型（LLMs）的推理能力，通过动态插入标记优化模型预测。

Method: 在序列中模型置信度最低的位置动态插入[PAUSE]标记，以提升后续标记的预测能力。

Result: 在多个数据集和模型上，DIT方法显著优于传统微调和其他标记插入方法，最高提升4.7%的准确率。

Conclusion: DIT是一种基于模型的动态方法，为推理研究提供了新思路。

Abstract: To enhance reasoning capabilities, previous works have explored incorporating
special-purpose tokens into the training process. These strategies strengthen
the learning mechanism of transformer-based large language models (LLMs).
Building on prior research, in which inserting dummy tokens consecutively just
before reasoning steps can enhance effectiveness, we introduce a novel approach
termed Dynamic Inserting Tokens Training (DIT). Our method identifies positions
within sequences where model confidence is lowest according to token
log-likelihood. Strategically inserting [PAUSE] tokens on these positions
bolsters the model's predictive capabilities for subsequent tokens.
Experimental results across diverse datasets and models, from the 2.7B model to
the 8B model, demonstrate that DIT consistently outperforms traditional
fine-tuning and previous token insertion methods. With this simple yet
effective method, we achieve accuracy gains of up to 4.7%p on GSM8K, 3.23%p on
AQUA-RAT, and pass@1 improvements of up to 3.4%p on MBPP datasets. Our work
shows a model-based, dynamic approach rather than a heuristic one, thereby
broadening the scope of research in reasoning.

</details>


### [150] [Do Large Language Models Know Folktales? A Case Study of Yokai in Japanese Folktales](https://arxiv.org/abs/2506.03619)
*Ayuto Tsutsumi,Yuu Jinnai*

Main category: cs.CL

TL;DR: 该研究评估了大型语言模型（LLMs）对日本妖怪（Yokai）文化的理解能力，并提出了一个名为YokaiEval的基准数据集。结果显示，使用日语资源训练的模型表现优于以英语为中心的模型。


<details>
  <summary>Details</summary>
Motivation: LLMs的文化知识通常局限于英语社区，忽视了非英语社区的文化。研究旨在评估LLMs的文化意识，并探索如何开发更具文化意识的模型。

Method: 研究聚焦于日本妖怪知识，构建了包含809道选择题的YokaiEval数据集，评估了31个日语和多语言LLMs的表现。

Result: 使用日语资源训练的模型表现更好，尤其是基于Llama-3并经过日语持续预训练的模型。

Conclusion: 研究表明，语言资源对LLMs的文化意识有显著影响，强调了多语言和文化多样性在模型开发中的重要性。

Abstract: Although Large Language Models (LLMs) have demonstrated strong language
understanding and generation abilities across various languages, their cultural
knowledge is often limited to English-speaking communities, which can
marginalize the cultures of non-English communities. To address the problem,
evaluation of the cultural awareness of the LLMs and the methods to develop
culturally aware LLMs have been investigated. In this study, we focus on
evaluating knowledge of folktales, a key medium for conveying and circulating
culture. In particular, we focus on Japanese folktales, specifically on
knowledge of Yokai. Yokai are supernatural creatures originating from Japanese
folktales that continue to be popular motifs in art and entertainment today.
Yokai have long served as a medium for cultural expression, making them an
ideal subject for assessing the cultural awareness of LLMs. We introduce
YokaiEval, a benchmark dataset consisting of 809 multiple-choice questions
(each with four options) designed to probe knowledge about yokai. We evaluate
the performance of 31 Japanese and multilingual LLMs on this dataset. The
results show that models trained with Japanese language resources achieve
higher accuracy than English-centric models, with those that underwent
continued pretraining in Japanese, particularly those based on Llama-3,
performing especially well. The code and dataset are available at
https://github.com/CyberAgentA ILab/YokaiEval.

</details>


### [151] [Robustness of Prompting: Enhancing Robustness of Large Language Models Against Prompting Attacks](https://arxiv.org/abs/2506.03627)
*Lin Mu,Guowei Chu,Li Ni,Lei Sang,Zhize Wu,Peiquan Jin,Yiwen Zhang*

Main category: cs.CL

TL;DR: 提出了一种名为RoP的新型提示策略，通过错误校正和引导两阶段增强LLM对输入扰动的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: LLM对输入扰动（如拼写错误或字符顺序错误）高度敏感，现有提示技术难以解决这一问题。

Method: RoP分为错误校正和引导两阶段：校正阶段生成对抗样本并自动纠正输入错误，引导阶段基于校正输入生成最优提示。

Result: 实验表明RoP显著提升LLM在算术、常识和逻辑推理任务中的鲁棒性，且对模型准确率影响极小。

Conclusion: RoP是一种实用且有效的方法，可增强LLM在现实应用中的鲁棒性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across
various tasks by effectively utilizing a prompting strategy. However, they are
highly sensitive to input perturbations, such as typographical errors or slight
character order errors, which can substantially degrade their performance.
Despite advances in prompting techniques, developing a prompting strategy that
explicitly mitigates the negative impact of such perturbations remains an open
challenge. To bridge this gap, we propose Robustness of Prompting (RoP), a
novel prompting strategy specifically designed to enhance the robustness of
LLMs. RoP consists of two stages: Error Correction and Guidance. In the Error
Correction stage, RoP applies diverse perturbation methods to generate
adversarial examples, which are then used to construct prompts that
automatically correct input errors. In the Guidance stage, RoP generates an
optimal guidance prompting based on the corrected input, steering the model
toward more robust and accurate inferences. Through comprehensive experiments
spanning arithmetic, commonsense, and logical reasoning tasks, we demonstrate
that RoP significantly improves LLMs' robustness against adversarial
perturbations. Notably, it maintains model accuracy with only minimal
degradation compared to clean input scenarios, thereby establishing RoP as a
practical and effective approach for enhancing LLM robustness in real-world
applications.

</details>


### [152] [RewardAnything: Generalizable Principle-Following Reward Models](https://arxiv.org/abs/2506.03637)
*Zhuohao Yu,Jiali Zeng,Weizheng Gu,Yidong Wang,Jindong Wang,Fandong Meng,Jie Zhou,Yue Zhang,Shikun Zhang,Wei Ye*

Main category: cs.CL

TL;DR: 论文提出了一种通用、遵循原则的奖励模型（RewardAnything），通过动态自然语言规范指导奖励模型，解决了传统固定偏好数据集训练的奖励模型难以适应多样化需求的问题。


<details>
  <summary>Details</summary>
Motivation: 传统奖励模型依赖固定偏好数据集，导致无法灵活适应多样化任务需求，且任务特定数据收集和模型重训练成本高、易产生偏差。

Method: 提出RewardAnything模型，通过理解和遵循动态提供的自然语言奖励原则，实现通用化奖励建模。开发RABench基准测试评估模型的泛化能力。

Result: RewardAnything在传统基准测试中表现优异，且在RABench上展示了无需重训练即可适应新原则的能力。

Conclusion: RewardAnything为奖励模型提供了一种高效、灵活的解决方案，能够无缝集成现有RLHF方法，并通过自然语言原则自动对齐LLMs。

Abstract: Reward Models, essential for guiding Large Language Model optimization, are
typically trained on fixed preference datasets, resulting in rigid alignment to
single, implicit preference distributions. This prevents adaptation to diverse
real-world needs-from conciseness in one task to detailed explanations in
another. The standard practice of collecting task-specific preference data and
retraining reward models is resource-intensive, often producing biased rewards,
and limits practical application. We introduce generalizable,
principle-following reward models. We propose that RMs should understand and
adhere to dynamically provided natural language specifications of reward
principles, similar to instruction-following in LLMs. To measure this
capability, we develop RABench, a comprehensive benchmark for RMs focusing on
generalization across diverse principles. Evaluations on RABench reveal poor
generalization of current RMs. As a solution, we present RewardAnything, a
novel RM designed and trained to explicitly follow natural language principles.
We achieve SotA performance with RewardAnything in traditional RM benchmark
simply by specifying a well-defined principle, and results on RABench show we
excel in adapting to novel principles without retraining. Furthermore,
RewardAnything integrates seamlessly with existing RLHF methods and we show by
a case study on how to automatically and efficiently align LLMs with only
natural language principles.

</details>


### [153] [Trustworthy Medical Question Answering: An Evaluation-Centric Survey](https://arxiv.org/abs/2506.03659)
*Yinuo Wang,Robert E. Mercer,Frank Rudzicz,Sudipta Singha Roy,Pengjie Ren,Zhumin Chen,Xindi Wang*

Main category: cs.CL

TL;DR: 本文综述了医疗问答系统中信任度的六个关键维度，并分析了现有评估方法和技术改进方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在医疗领域的应用增多，确保其回答的可靠性对临床决策和患者安全至关重要。

Method: 系统性地研究了医疗问答系统中的六个信任度维度（事实性、鲁棒性、公平性、安全性、可解释性和校准性），并比较了相关评估基准和技术改进方法。

Result: 总结了现有评估方法和技术改进方向，如检索增强、对抗微调和安全对齐。

Conclusion: 提出了未来研究方向，包括专家评估扩展、多维指标整合和实际部署研究，以推动医疗问答系统的安全可靠应用。

Abstract: Trustworthiness in healthcare question-answering (QA) systems is important
for ensuring patient safety, clinical effectiveness, and user confidence. As
large language models (LLMs) become increasingly integrated into medical
settings, the reliability of their responses directly influences clinical
decision-making and patient outcomes. However, achieving comprehensive
trustworthiness in medical QA poses significant challenges due to the inherent
complexity of healthcare data, the critical nature of clinical scenarios, and
the multifaceted dimensions of trustworthy AI. In this survey, we
systematically examine six key dimensions of trustworthiness in medical QA,
i.e., Factuality, Robustness, Fairness, Safety, Explainability, and
Calibration. We review how each dimension is evaluated in existing LLM-based
medical QA systems. We compile and compare major benchmarks designed to assess
these dimensions and analyze evaluation-guided techniques that drive model
improvements, such as retrieval-augmented grounding, adversarial fine-tuning,
and safety alignment. Finally, we identify open challenges-such as scalable
expert evaluation, integrated multi-dimensional metrics, and real-world
deployment studies-and propose future research directions to advance the safe,
reliable, and transparent deployment of LLM-powered medical QA.

</details>


### [154] [ROSA: Addressing text understanding challenges in photographs via ROtated SAmpling](https://arxiv.org/abs/2506.03665)
*Hernán Maina,Guido Ivetta,Mateo Lione Stuto,Julian Martin Eisenschlos,Jorge Sánchez,Luciana Benotti*

Main category: cs.CL

TL;DR: ROSA解码策略提升视觉问答系统在文本方向错误图像中的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉障碍人士拍摄的照片中文本方向常不准确，现有VQA模型难以处理此类问题。

Method: 提出ROSA解码策略，优化文本方向错误的图像处理。

Result: ROSA在最佳模型中比Greedy解码性能提升11.7个百分点。

Conclusion: ROSA有效解决了视觉障碍人士拍摄图像中文本方向错误的问题。

Abstract: Visually impaired people could benefit from Visual Question Answering (VQA)
systems to interpret text in their surroundings. However, current models often
struggle with recognizing text in the photos taken by this population. Through
in-depth interviews with visually impaired individuals, we identified common
framing conventions that frequently result in misaligned text. Existing VQA
benchmarks primarily feature well-oriented text captured by sighted users,
under-representing these challenges. To address this gap, we introduce ROtated
SAmpling (ROSA), a decoding strategy that enhances VQA performance in text-rich
images with incorrectly oriented text. ROSA outperforms Greedy decoding by 11.7
absolute points in the best-performing model.

</details>


### [155] [Efficient Data Selection for Domain Adaptation of ASR Using Pseudo-Labels and Multi-Stage Filtering](https://arxiv.org/abs/2506.03681)
*Pradeep Rangappa,Andres Carofilis,Jeena Prakash,Shashi Kumar,Sergio Burdisso,Srikanth Madikeri,Esau Villatoro-Tello,Bidisha Sharma,Petr Motlicek,Kadri Hacioglu,Shankar Venkatesan,Saurabh Vyas,Andreas Stolcke*

Main category: cs.CL

TL;DR: 论文提出了一种通过筛选伪标签来优化ASR模型微调的方法，结合多种策略选择高质量数据，显著减少所需数据量并保持性能。


<details>
  <summary>Details</summary>
Motivation: 针对小组织在有限标注数据和计算资源下微调ASR模型的挑战，研究如何高效选择数据以提升模型适应性。

Method: 提出一种结合WER预测、NER和CER分析的多策略数据选择方法，筛选Whisper和Zipformer生成的伪标签。

Result: 在7500小时伪标注数据上微调后WER为12.3%，而筛选后的100小时数据（1.4%）性能相近；Fisher English数据集上也观察到类似趋势。

Conclusion: 该方法能显著减少微调所需数据量，同时保持模型性能，适用于资源有限的环境。

Abstract: Fine-tuning pretrained ASR models for specific domains is challenging for
small organizations with limited labeled data and computational resources.
Here, we explore different data selection pipelines and propose a robust
approach that improves ASR adaptation by filtering pseudo-labels generated
using Whisper (encoder-decoder) and Zipformer (transducer) models. Our approach
integrates multiple selection strategies -- including word error rate (WER)
prediction, named entity recognition (NER), and character error rate (CER)
analysis -- to extract high-quality training segments. We evaluate our method
on Whisper and Zipformer using a 7500-hour baseline, comparing it to a
CER-based approach relying on hypotheses from three ASR systems. Fine-tuning on
7500 hours of pseudo-labeled call center data achieves 12.3% WER, while our
filtering reduces the dataset to 100 hours (1.4%) with similar performance; a
similar trend is observed on Fisher English.

</details>


### [156] [Robust Preference Optimization via Dynamic Target Margins](https://arxiv.org/abs/2506.03690)
*Jie Sun,Junkang Wu,Jiancan Wu,Zhibo Zhu,Xingyu Lu,Jun Zhou,Lintao Ma,Xiang Wang*

Main category: cs.CL

TL;DR: 提出了一种动态目标边界的偏好优化算法γ-PO，通过校准实例特定边界，优先处理高置信度对并抑制噪声，显著提升了LLM的对齐性能。


<details>
  <summary>Details</summary>
Motivation: LLM的对齐对安全性和可靠性至关重要，但现有方法（如DPO）受数据质量影响较大，噪声问题突出。

Method: γ-PO通过动态调整奖励边界，优先高置信度对并抑制噪声，是一种即插即用的方法，兼容多种DPO变体。

Result: 在AlpacaEval2和Arena-Hard等基准测试中，γ-PO平均提升4.4%，且对训练效率影响极小。

Conclusion: γ-PO是一种高效、兼容性强的LLM对齐增强方案，代码开源。

Abstract: The alignment of Large Language Models (LLMs) is crucial for ensuring their
safety and reliability in practical applications. Direct Preference
Optimization (DPO) has emerged as an efficient method that directly optimizes
models using preference pairs, significantly reducing resource demands.
However, the effectiveness of DPO heavily depends on the data quality, which is
frequently compromised by noise. In this work, we propose $\gamma$-PO, a
dynamic target margin preference optimization algorithm that adjust reward
margins at the pairwise level. By introducing instance-specific margin
calibration, $\gamma$-PO strategically prioritizes high-confidence pairs (those
demonstrating higher reward margins) while suppressing potential noise from
ambiguous pairs. Moreover, $\gamma$-PO is a plug-and-play method, compatible
with variants of DPO that rely on reward margin between preference pairs.
Across benchmarks such as AlpacaEval2 and Arena-Hard, $\gamma$-PO achieves an
average 4.4\% improvement over other baselines, setting new benchmarks for
state-of-the-art performance. Additionally, $\gamma$-PO requires minimal code
changes and has a negligible impact on training efficiency, making it a robust
solution for enhancing LLMs alignment. Our codes are available at
\href{https://github.com/sunjie279/gammaPO}{https://github.com/sunjie279/gammaPO}.

</details>


### [157] [AdaDecode: Accelerating LLM Decoding with Adaptive Layer Parallelism](https://arxiv.org/abs/2506.03700)
*Zhepei Wei,Wei-Lin Chen,Xinyu Zhu,Yu Meng*

Main category: cs.CL

TL;DR: AdaDecode是一种无需辅助模型或修改原始模型参数即可加速大语言模型解码的方法，通过自适应地在中间层生成高置信度令牌，并行处理剩余层计算，实现1.73倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有方法如推测解码和层跳过存在辅助模型依赖或输出不一致的问题，需一种高效且保持输出一致性的解码加速方法。

Method: AdaDecode利用中间层生成高置信度令牌，并行处理剩余层计算，并通过验证步骤确保输出一致性。

Result: 实验表明AdaDecode在多种生成任务中实现1.73倍加速，且输出与标准自回归解码一致。

Conclusion: AdaDecode是一种高效且可靠的解码加速方法，适用于大语言模型的长内容生成任务。

Abstract: Large language models (LLMs) are increasingly used for long-content
generation (e.g., long Chain-of-Thought reasoning) where decoding efficiency
becomes a critical bottleneck: Autoregressive decoding is inherently limited by
its sequential token generation process, where each token must be generated
before the next can be processed. This sequential dependency restricts the
ability to fully leverage modern hardware's parallel processing capabilities.
Existing methods like speculative decoding and layer skipping offer potential
speedups but have notable drawbacks: speculative decoding relies on an
auxiliary "drafter" model, which can be challenging to acquire and increases
memory overhead, while layer skipping may introduce discrepancies in the
outputs due to the missing key-value cache at skipped layers. In this work, we
propose AdaDecode, which accelerates LLM decoding without requiring auxiliary
models or changes to the original model parameters, while ensuring output
consistency. AdaDecode leverages the insight that many tokens can accurately be
generated at intermediate layers, as further layers often do not significantly
alter predictions once the model reaches a certain confidence. By adaptively
generating tokens at intermediate layers when confidence is high, AdaDecode
enables the next token's computation to begin immediately. The remaining layer
computations for early-predicted tokens are deferred and executed in parallel
with subsequent tokens when needed, maximizing hardware utilization and
reducing decoding latency. A final verification step ensures that early
predictions match the results of standard autoregressive decoding, preserving
output parity. Experiments across diverse generation tasks shows that AdaDecode
consistently achieves superior decoding throughput with up to 1.73x speedup,
while guaranteeing output parity with standard autoregressive decoding.

</details>


### [158] [ScoreRAG: A Retrieval-Augmented Generation Framework with Consistency-Relevance Scoring and Structured Summarization for News Generation](https://arxiv.org/abs/2506.03704)
*Pei-Yun Lin,Yen-lung Tsai*

Main category: cs.CL

TL;DR: ScoreRAG通过多阶段框架提升新闻生成质量，结合检索增强生成、一致性评估和结构化摘要，显著提高准确性、连贯性和专业性。


<details>
  <summary>Details</summary>
Motivation: 当前新闻生成方法存在幻觉、事实不一致和领域专业知识不足的问题，ScoreRAG旨在解决这些挑战。

Method: 系统从向量数据库检索相关新闻文档，评估一致性相关性并重新排序，生成分级摘要指导语言模型生成专业新闻。

Result: ScoreRAG显著提高了生成新闻的准确性、连贯性、信息量和专业性。

Conclusion: ScoreRAG通过系统性方法优化新闻生成，同时保持稳定性和一致性。

Abstract: This research introduces ScoreRAG, an approach to enhance the quality of
automated news generation. Despite advancements in Natural Language Processing
and large language models, current news generation methods often struggle with
hallucinations, factual inconsistencies, and lack of domain-specific expertise
when producing news articles. ScoreRAG addresses these challenges through a
multi-stage framework combining retrieval-augmented generation, consistency
relevance evaluation, and structured summarization. The system first retrieves
relevant news documents from a vector database, maps them to complete news
items, and assigns consistency relevance scores based on large language model
evaluations. These documents are then reranked according to relevance, with
low-quality items filtered out. The framework proceeds to generate graded
summaries based on relevance scores, which guide the large language model in
producing complete news articles following professional journalistic standards.
Through this methodical approach, ScoreRAG aims to significantly improve the
accuracy, coherence, informativeness, and professionalism of generated news
articles while maintaining stability and consistency throughout the generation
process. The code and demo are available at:
https://github.com/peiyun2260/ScoreRAG.

</details>


### [159] [MFLA: Monotonic Finite Look-ahead Attention for Streaming Speech Recognition](https://arxiv.org/abs/2506.03722)
*Yinfeng Xia,Huiyan Li,Chenyang Le,Manhong Wang,Yutao Sun,Xingyang Ma,Yanmin Qian*

Main category: cs.CL

TL;DR: 提出了一种基于Whisper的流式语音识别框架，通过前缀到前缀训练和连续积分-触发机制，实现了低延迟与高质量的平衡。


<details>
  <summary>Details</summary>
Motivation: 尽管大型预训练语音模型（如Whisper）在降低训练成本方面表现出色，但其在流式系统中的集成仍具挑战性。

Method: 采用前缀到前缀训练框架，结合连续积分-触发机制和单调有限前瞻注意力，并使用wait-k解码策略。

Result: 实验证明该方法在延迟与质量之间实现了可控的权衡。

Conclusion: 该框架适用于多种流式应用场景。

Abstract: Applying large pre-trained speech models like Whisper has shown promise in
reducing training costs for various speech tasks. However, integrating these
models into streaming systems remains a challenge. This paper presents a novel
prefix-to-prefix training framework for streaming recognition by fine-tuning
the Whisper. We introduce the Continuous Integrate-and-Fire mechanism to
establish a quasi-monotonic alignment between continuous speech sequences and
discrete text tokens. Additionally, we design Monotonic Finite Look-ahead
Attention, allowing each token to attend to infinite left-context and finite
right-context from the speech sequences. We also employ the wait-k decoding
strategy to simplify the decoding process while ensuring consistency between
training and testing. Our theoretical analysis and experiments demonstrate that
this approach achieves a controllable trade-off between latency and quality,
making it suitable for various streaming applications.

</details>


### [160] [Verbalized Confidence Triggers Self-Verification: Emergent Behavior Without Explicit Reasoning Supervision](https://arxiv.org/abs/2506.03723)
*Chaeyun Jang,Moonseok Choi,Yegon Kim,Hyungi Lee,Juho Lee*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）在链式思维（CoT）推理中的不确定性校准问题，发现仅通过标量置信度标签的监督微调即可引发模型的自我验证行为，无需显式推理监督或强化学习奖励。


<details>
  <summary>Details</summary>
Motivation: LLMs的不确定性校准对安全部署至关重要，尤其是用户依赖其置信度估计时。现有研究多关注分类器或短文本生成，而CoT推理的置信度校准尚未充分探索。

Method: 通过监督微调，仅使用标量置信度标签训练模型，无需额外推理监督或强化学习。进一步提出一种简单的重新思考方法，基于校准的不确定性在测试时调整性能。

Result: 实验表明，置信度感知的微调在GSM8K、MATH-500和ARC-Challenge等任务中提升了校准性和准确性，同时增强了模型推理路径与置信度的一致性。

Conclusion: 仅通过标量置信度标签的监督微调即可有效校准LLMs的不确定性，并提升其自我验证能力和推理表现。

Abstract: Uncertainty calibration is essential for the safe deployment of large
language models (LLMs), particularly when users rely on verbalized confidence
estimates. While prior work has focused on classifiers or short-form
generation, confidence calibration for chain-of-thought (CoT) reasoning remains
largely unexplored. Surprisingly, we find that supervised fine-tuning with
scalar confidence labels alone suffices to elicit self-verification behavior of
language models, without any explicit reasoning supervision or reinforcement
learning-based rewards. Despite being trained only to produce a verbalized
confidence score without any self-verifying examples, the model learns to
generate longer and self-checking responses for low-confidence queries while
providing more concise answers for high-confidence ones. We further propose a
simple rethinking method that boosts performance via test-time scaling based on
calibrated uncertainty. Experiments on GSM8K and held-out reasoning tasks such
as MATH-500 and ARC-Challenge show that our confidence-aware fine-tuning
improves both calibration and accuracy, while also enhancing interpretability
by aligning the model's reasoning path with its confidence.

</details>


### [161] [Generating Pedagogically Meaningful Visuals for Math Word Problems: A New Benchmark and Analysis of Text-to-Image Models](https://arxiv.org/abs/2506.03735)
*Junling Wang,Anna Rutkiewicz,April Yi Wang,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: Math2Visual是一个自动生成数学应用题教学视觉内容的框架，基于预定义的视觉语言和教师访谈设计，提升了教育视觉生成的质量。


<details>
  <summary>Details</summary>
Motivation: 数学应用题的教学视觉内容生成过程繁琐且缺乏自动化支持，Math2Visual旨在解决这一问题。

Method: 利用预定义的视觉语言和教师访谈设计空间，生成教学视觉内容，并构建标注数据集评估和改进文本到图像模型。

Result: 生成了1,903个标注视觉内容，微调后的文本到图像模型在教育视觉生成上表现更优。

Conclusion: Math2Visual为自动化生成教学视觉内容设立了新基准，并揭示了多模态教育内容生成中的关键挑战。

Abstract: Visuals are valuable tools for teaching math word problems (MWPs), helping
young learners interpret textual descriptions into mathematical expressions
before solving them. However, creating such visuals is labor-intensive and
there is a lack of automated methods to support this process. In this paper, we
present Math2Visual, an automatic framework for generating pedagogically
meaningful visuals from MWP text descriptions. Math2Visual leverages a
pre-defined visual language and a design space grounded in interviews with math
teachers, to illustrate the core mathematical relationships in MWPs. Using
Math2Visual, we construct an annotated dataset of 1,903 visuals and evaluate
Text-to-Image (TTI) models for their ability to generate visuals that align
with our design. We further fine-tune several TTI models with our dataset,
demonstrating improvements in educational visual generation. Our work
establishes a new benchmark for automated generation of pedagogically
meaningful visuals and offers insights into key challenges in producing
multimodal educational content, such as the misrepresentation of mathematical
relationships and the omission of essential visual elements.

</details>


### [162] [Act-as-Pet: Benchmarking the Abilities of Large Language Models as E-Pets in Social Network Services](https://arxiv.org/abs/2506.03761)
*Hongcheng Guo,Zheyong Xie,Shaosheng Cao,Boyang Wang,Weiting Liu,Zheyu Ye,Zhoujun Li,Zuozhu Liu*

Main category: cs.CL

TL;DR: Pet-Bench是一个专门用于评估大型语言模型（LLM）在虚拟宠物陪伴领域的基准测试，强调自我进化和互动行为，包含7500多个交互实例。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注基本宠物角色扮演，缺乏对LLM在全面陪伴能力上的系统评估。

Method: 提出Pet-Bench基准，涵盖自我互动和人类互动维度，包括智能调度、记忆对话和心理对话等任务。

Result: 对28个LLM的评估显示性能差异显著，与模型规模和能力相关。

Conclusion: Pet-Bench为宠物相关LLM能力提供了基准资源，推动了情感沉浸式人宠互动的发展。

Abstract: As interest in using Large Language Models (LLMs) for interactive and
emotionally rich experiences grows, virtual pet companionship emerges as a
novel yet underexplored application. Existing approaches focus on basic pet
role-playing interactions without systematically benchmarking LLMs for
comprehensive companionship. In this paper, we introduce Pet-Bench, a dedicated
benchmark that evaluates LLMs across both self-interaction and
human-interaction dimensions. Unlike prior work, Pet-Bench emphasizes
self-evolution and developmental behaviors alongside interactive engagement,
offering a more realistic reflection of pet companionship. It features diverse
tasks such as intelligent scheduling, memory-based dialogues, and psychological
conversations, with over 7,500 interaction instances designed to simulate
complex pet behaviors. Evaluation of 28 LLMs reveals significant performance
variations linked to model size and inherent capabilities, underscoring the
need for specialized optimization in this domain. Pet-Bench serves as a
foundational resource for benchmarking pet-related LLM abilities and advancing
emotionally immersive human-pet interactions.

</details>


### [163] [AhaKV: Adaptive Holistic Attention-Driven KV Cache Eviction for Efficient Inference of Large Language Models](https://arxiv.org/abs/2506.03762)
*Yifeng Gu,Zicong Jiang,Jianxiu Jin,Kailing Guo,Ziyang Zhang,Xiangmin Xu*

Main category: cs.CL

TL;DR: 论文提出AhaKV方法，通过自适应调整softmax尺度减少KV缓存中的偏差，提升模型对全局上下文信息的访问能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖累积注意力分数作为淘汰标准，但该分数存在偏差，导致模型过度依赖初始位置信息，限制了全局上下文的理解。

Method: 提出AhaKV方法，通过自适应调整softmax尺度，并结合值向量信息，减少注意力分数的偏差。

Result: 实验表明，AhaKV在固定缓存预算下成功减少偏差，保留全局关键信息，并在多个基准任务中取得最优结果。

Conclusion: AhaKV通过减少注意力分数偏差，显著提升了模型对全局上下文的理解能力。

Abstract: Large Language Models (LLMs) have significantly advanced the field of
Artificial Intelligence. However, their deployment is resource-intensive, not
only due to the large number of model parameters but also because the
(Key-Value) KV cache consumes a lot of memory during inference. While several
works propose reducing the KV cache by evicting the unnecessary tokens, these
approaches rely on accumulated attention score as eviction score to quantify
the importance of the token. We identify the accumulated attention score is
biased and it decreases with the position of the tokens in the mathematical
expectation. As a result, the retained tokens concentrate on the initial
positions, limiting model's access to global contextual information. To address
this issue, we propose Adaptive holistic attention KV (AhaKV), it addresses the
bias of the accumulated attention score by adaptively tuning the scale of
softmax according the expectation of information entropy of attention scores.
To make use of the holistic attention information in self-attention mechanism,
AhaKV utilize the information of value vectors, which is overlooked in previous
works, to refine the adaptive score. We show theoretically that our method is
well suited for bias reduction. We deployed AhaKV on different models with a
fixed cache budget. Experiments show that AhaKV successfully mitigates bias and
retains crucial tokens across global context and achieve state-of-the-art
results against other related work on several benchmark tasks.

</details>


### [164] [ClozeMath: Improving Mathematical Reasoning in Language Models by Learning to Fill Equations](https://arxiv.org/abs/2506.03763)
*Quang Hieu Pham,Thuy Duong Nguyen,Tung Pham,Anh Tuan Luu,Dat Quoc Nguyen*

Main category: cs.CL

TL;DR: 论文提出了一种名为ClozeMath的新方法，通过文本填充任务优化大语言模型（LLMs）的数学推理能力，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型通过链式思维训练提升了能力，但传统的逐词预测方法未能完全模拟人类学习思维的方式。

Method: 提出ClozeMath方法，通过预测给定解中的掩码方程（类似填空练习）来微调LLMs。实验使用了Beam Search和Chain-of-Thought解码算法。

Result: 在GSM8K、MATH和GSM-Symbolic数据集上，ClozeMath在性能和鲁棒性上均优于基线方法Masked Thought。

Conclusion: ClozeMath方法在数学推理任务中表现出色，并通过消融实验验证了其架构和实现选择的有效性。

Abstract: The capabilities of large language models (LLMs) have been enhanced by
training on data that reflects human thought processes, such as the
Chain-of-Thought format. However, evidence suggests that the conventional
scheme of next-word prediction may not fully capture how humans learn to think.
Inspired by how humans generalize mathematical reasoning, we propose a new
approach named ClozeMath to fine-tune LLMs for mathematical reasoning. Our
ClozeMath involves a text-infilling task that predicts masked equations from a
given solution, analogous to cloze exercises used in human learning.
Experiments on GSM8K, MATH, and GSM-Symbolic show that ClozeMath surpasses the
strong baseline Masked Thought in performance and robustness, with two
test-time scaling decoding algorithms, Beam Search and Chain-of-Thought
decoding. Additionally, we conduct an ablation study to analyze the effects of
various architectural and implementation choices on our approach.

</details>


### [165] [Unifying Uniform and Binary-coding Quantization for Accurate Compression of Large Language Models](https://arxiv.org/abs/2506.03781)
*Seungcheol Park,Jeongin Bae,Beomseok Kwon,Minjun Kim,Byeongwook Kim,Se Jung Kwon,U Kang,Dongsoo Lee*

Main category: cs.CL

TL;DR: UniQuanF是一种统一量化方法，结合了BCQ和UQ的优势，通过灵活映射技术提升大语言模型的量化精度，且不增加额外部署成本。


<details>
  <summary>Details</summary>
Motivation: 量化对于高效部署大语言模型至关重要，但现有方法如BCQ和UQ各有局限，无法同时兼顾表达能力和优化能力。

Method: 提出UniQuanF方法，结合UQ的灵活映射和BCQ的非均匀量化级别，采用统一初始化及局部和周期性映射技术优化参数。

Result: 实验显示UniQuanF在GSM8K基准上比现有方法准确率提升高达4.60%。

Conclusion: UniQuanF成功统一了BCQ和UQ的优势，实现了高精度量化且无额外部署成本。

Abstract: How can we quantize large language models while preserving accuracy?
Quantization is essential for deploying large language models (LLMs)
efficiently. Binary-coding quantization (BCQ) and uniform quantization (UQ) are
promising quantization schemes that have strong expressiveness and
optimizability, respectively. However, neither scheme leverages both
advantages. In this paper, we propose UniQuanF (Unified Quantization with
Flexible Mapping), an accurate quantization method for LLMs. UniQuanF harnesses
both strong expressiveness and optimizability by unifying the flexible mapping
technique in UQ and non-uniform quantization levels of BCQ. We propose unified
initialization, and local and periodic mapping techniques to optimize the
parameters in UniQuanF precisely. After optimization, our unification theorem
removes computational and memory overhead, allowing us to utilize the superior
accuracy of UniQuanF without extra deployment costs induced by the unification.
Experimental results demonstrate that UniQuanF outperforms existing UQ and BCQ
methods, achieving up to 4.60% higher accuracy on GSM8K benchmark.

</details>


### [166] [Knockout LLM Assessment: Using Large Language Models for Evaluations through Iterative Pairwise Comparisons](https://arxiv.org/abs/2506.03785)
*Isik Baran Sandan,Tu Anh Dinh,Jan Niehues*

Main category: cs.CL

TL;DR: Knockout Assessment方法通过淘汰赛系统改进LLM评估的准确性，使其更接近人类评分。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估方法缺乏全局排名视角，限制了评估效果。

Method: 提出Knockout Assessment，采用淘汰赛系统进行迭代成对比较。

Result: 实验显示，该方法在评分准确性上提升，Pearson相关性平均增加0.07。

Conclusion: Knockout Assessment能更紧密地使LLM评估与人类评分对齐。

Abstract: Large Language Models (LLMs) have shown to be effective evaluators across
various domains such as machine translations or the scientific domain. Current
LLM-as-a-Judge approaches rely mostly on individual assessments or a single
round of pairwise assessments, preventing the judge LLM from developing a
global ranking perspective. To address this, we present Knockout Assessment, an
LLM-asa Judge method using a knockout tournament system with iterative pairwise
comparisons. Experiments across three LLMs on two datasets show that knockout
assessment improves scoring accuracy, increasing Pearson correlation with
expert evaluations by 0.07 on average for university-level exam scoring and
machine translation evaluations, aligning LLM assessments more closely with
human scoring.

</details>


### [167] [Mark My Words: A Robust Multilingual Model for Punctuation in Text and Speech Transcripts](https://arxiv.org/abs/2506.03793)
*Sidharth Pulipaka,Sparsh Jain,Ashwin Sankar,Raj Dabre*

Main category: cs.CL

TL;DR: Cadence是一个基于预训练大语言模型的通用标点恢复模型，适用于书面文本和口语转录，支持22种印度语言和英语，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 当前模型在口语转录中标点恢复效果不佳，影响下游任务质量，如翻译和文本转语音。

Method: 基于预训练大语言模型开发Cadence，支持多语言标点恢复，并分析其行为。

Result: Cadence在性能上超越现有技术，支持更多语言，但在领域迁移和罕见标点方面仍有挑战。

Conclusion: 预训练语言模型在多语言标点恢复中有效，Cadence对低资源NLP任务具有实用价值。

Abstract: Punctuation plays a vital role in structuring meaning, yet current models
often struggle to restore it accurately in transcripts of spontaneous speech,
especially in the presence of disfluencies such as false starts and
backtracking. These limitations hinder the performance of downstream tasks like
translation, text to speech, summarization, etc. where sentence boundaries are
critical for preserving quality. In this work, we introduce Cadence, a
generalist punctuation restoration model adapted from a pretrained large
language model. Cadence is designed to handle both clean written text and
highly spontaneous spoken transcripts. It surpasses the previous state of the
art in performance while expanding support from 14 to all 22 Indian languages
and English. We conduct a comprehensive analysis of model behavior across
punctuation types and language families, identifying persistent challenges
under domain shift and with rare punctuation marks. Our findings demonstrate
the efficacy of utilizing pretrained language models for multilingual
punctuation restoration and highlight Cadence practical value for low resource
NLP pipelines at scale.

</details>


### [168] [Automatic Correction of Writing Anomalies in Hausa Texts](https://arxiv.org/abs/2506.03820)
*Ahmad Mustapha Wali,Sergiu Nisioi*

Main category: cs.CL

TL;DR: 本文提出了一种基于Transformer模型的自动校正豪萨语文本异常的方法，通过合成噪声生成大规模平行数据集，并微调多语言模型，显著提升了文本校正的性能指标。


<details>
  <summary>Details</summary>
Motivation: 豪萨语文本常因字符替换和间距错误等异常问题影响自然语言处理应用，亟需一种自动校正方法。

Method: 通过合成噪声生成450,000对噪声-干净豪萨语句对，并微调M2M100、AfriTEVA、mBART和Opus-MT等模型。

Result: 实验结果显示F1、BLEU和METEOR分数显著提升，同时字符错误率（CER）和词错误率（WER）降低。

Conclusion: 本研究为豪萨语文本质量提升提供了方法论、公开数据集和有效模型，对低资源语言具有借鉴意义。

Abstract: Hausa texts are often characterized by writing anomalies such as incorrect
character substitutions and spacing errors, which sometimes hinder natural
language processing (NLP) applications. This paper presents an approach to
automatically correct the anomalies by finetuning transformer-based models.
Using a corpus gathered from several public sources, we created a large-scale
parallel dataset of over 450,000 noisy-clean Hausa sentence pairs by
introducing synthetically generated noise, fine-tuned to mimic realistic
writing errors. Moreover, we adapted several multilingual and African
language-focused models, including M2M100, AfriTEVA, mBART, and Opus-MT
variants for this correction task using SentencePiece tokenization. Our
experimental results demonstrate significant increases in F1, BLEU and METEOR
scores, as well as reductions in Character Error Rate (CER) and Word Error Rate
(WER). This research provides a robust methodology, a publicly available
dataset, and effective models to improve Hausa text quality, thereby advancing
NLP capabilities for the language and offering transferable insights for other
low-resource languages.

</details>


### [169] [CRAWLDoc: A Dataset for Robust Ranking of Bibliographic Documents](https://arxiv.org/abs/2506.03822)
*Fabian Karl,Ansgar Scherp*

Main category: cs.CL

TL;DR: CRAWLDoc是一种新的上下文排名方法，用于从网页中提取和排名相关文档，解决了不同布局和格式的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决网页布局和数据格式多样性对元数据提取的挑战。

Method: 通过URL检索网页及其链接资源（如PDF、ORCID等），并将其嵌入统一表示中进行排名。

Result: 在600篇计算机科学出版物上测试，CRAWLDoc表现出对布局和格式的鲁棒性。

Conclusion: CRAWLDoc为多样布局和格式的元数据提取提供了新基础，代码和数据集已开源。

Abstract: Publication databases rely on accurate metadata extraction from diverse web
sources, yet variations in web layouts and data formats present challenges for
metadata providers. This paper introduces CRAWLDoc, a new method for contextual
ranking of linked web documents. Starting with a publication's URL, such as a
digital object identifier, CRAWLDoc retrieves the landing page and all linked
web resources, including PDFs, ORCID profiles, and supplementary materials. It
embeds these resources, along with anchor texts and the URLs, into a unified
representation. For evaluating CRAWLDoc, we have created a new, manually
labeled dataset of 600 publications from six top publishers in computer
science. Our method CRAWLDoc demonstrates a robust and layout-independent
ranking of relevant documents across publishers and data formats. It lays the
foundation for improved metadata extraction from web documents with various
layouts and formats. Our source code and dataset can be accessed at
https://github.com/FKarl/CRAWLDoc.

</details>


### [170] [Multi-objective Aligned Bidword Generation Model for E-commerce Search Advertising](https://arxiv.org/abs/2506.03827)
*Zhenhui Liu,Chunyuan Yuan,Ming Pang,Zheng Fang,Li Yuan,Xue Jiang,Changping Peng,Zhangang Lin,Zheng Luo,Jingping Shao*

Main category: cs.CL

TL;DR: 论文提出了一种多目标对齐的竞价词生成模型（MoBGM），通过判别器、生成器和偏好对齐模块，同时优化查询改写与广告召回的相关性、真实性和平台收入。


<details>
  <summary>Details</summary>
Motivation: 解决电子商务搜索广告中长尾查询与商家竞价词或产品标题不匹配的问题，提升广告召回效率和用户体验。

Method: 设计了判别器优化关键目标，并训练多目标对齐的竞价词生成器，结合反馈信号最大化三个目标的综合效果。

Result: 离线和在线实验表明，该算法显著优于现有技术，部署后为平台创造了巨大商业价值。

Conclusion: MoBGM在提升广告召回效果和平台收入方面具有可行性和鲁棒性。

Abstract: Retrieval systems primarily address the challenge of matching user queries
with the most relevant advertisements, playing a crucial role in e-commerce
search advertising. The diversity of user needs and expressions often produces
massive long-tail queries that cannot be matched with merchant bidwords or
product titles, which results in some advertisements not being recalled,
ultimately harming user experience and search efficiency. Existing query
rewriting research focuses on various methods such as query log mining,
query-bidword vector matching, or generation-based rewriting. However, these
methods often fail to simultaneously optimize the relevance and authenticity of
the user's original query and rewrite and maximize the revenue potential of
recalled ads.
  In this paper, we propose a Multi-objective aligned Bidword Generation Model
(MoBGM), which is composed of a discriminator, generator, and preference
alignment module, to address these challenges. To simultaneously improve the
relevance and authenticity of the query and rewrite and maximize the platform
revenue, we design a discriminator to optimize these key objectives. Using the
feedback signal of the discriminator, we train a multi-objective aligned
bidword generator that aims to maximize the combined effect of the three
objectives. Extensive offline and online experiments show that our proposed
algorithm significantly outperforms the state of the art. After deployment, the
algorithm has created huge commercial value for the platform, further verifying
its feasibility and robustness.

</details>


### [171] [Brain-tuned Speech Models Better Reflect Speech Processing Stages in the Brain](https://arxiv.org/abs/2506.03832)
*Omer Moussa,Mariya Toneva*

Main category: cs.CL

TL;DR: 脑调优的自监督语音模型在语义理解上优于预训练模型，并展现出从声学到语义的层次化处理。


<details>
  <summary>Details</summary>
Motivation: 研究脑调优模型是否能更好地反映人脑对语音处理的中间阶段。

Method: 通过脑调优（使用人脑记录微调模型）改进语音模型，并进行层次化分析。

Result: 脑调优模型的后期层在语义区域对齐上显著提升，早期层专注于声学特征，后期层擅长高级任务。

Conclusion: 脑调优模型不仅性能更好，还展现出层次化处理，更接近人脑语音处理机制。

Abstract: Pretrained self-supervised speech models excel in speech tasks but do not
reflect the hierarchy of human speech processing, as they encode rich semantics
in middle layers and poor semantics in late layers. Recent work showed that
brain-tuning (fine-tuning models using human brain recordings) improves speech
models' semantic understanding. Here, we examine how well brain-tuned models
further reflect the brain's intermediate stages of speech processing. We find
that late layers of brain-tuned models substantially improve over pretrained
models in their alignment with semantic language regions. Further layer-wise
probing reveals that early layers remain dedicated to low-level acoustic
features, while late layers become the best at complex high-level tasks. These
findings show that brain-tuned models not only perform better but also exhibit
a well-defined hierarchical processing going from acoustic to semantic
representations, making them better model organisms for human speech
processing.

</details>


### [172] [PulseReddit: A Novel Reddit Dataset for Benchmarking MAS in High-Frequency Cryptocurrency Trading](https://arxiv.org/abs/2506.03861)
*Qiuhan Han,Qian Wang,Atsushi Yoshikawa,Masayuki Yamamura*

Main category: cs.CL

TL;DR: 论文提出PulseReddit数据集，将Reddit讨论与高频加密货币市场数据对齐，用于短期交易分析。通过LLM多智能体系统研究发现，结合社交情绪数据能提升交易表现，尤其在牛市。


<details>
  <summary>Details</summary>
Motivation: 高频交易需快速决策，社交媒体如Reddit提供未充分探索的信息。研究旨在探索社交情绪对高频交易的影响。

Method: 使用PulseReddit数据集和LLM多智能体系统，分析社交情绪对交易表现的影响。

Result: 结合PulseReddit数据的MAS在交易表现上优于传统方法，尤其在牛市，且适应性强。

Conclusion: PulseReddit为高频交易研究奠定基础，证明社交媒体整合的实际价值。

Abstract: High-Frequency Trading (HFT) is pivotal in cryptocurrency markets, demanding
rapid decision-making. Social media platforms like Reddit offer valuable, yet
underexplored, information for such high-frequency, short-term trading. This
paper introduces \textbf{PulseReddit}, a novel dataset that is the first to
align large-scale Reddit discussion data with high-frequency cryptocurrency
market statistics for short-term trading analysis. We conduct an extensive
empirical study using Large Language Model (LLM)-based Multi-Agent Systems
(MAS) to investigate the impact of social sentiment from PulseReddit on trading
performance. Our experiments conclude that MAS augmented with PulseReddit data
achieve superior trading outcomes compared to traditional baselines,
particularly in bull markets, and demonstrate robust adaptability across
different market regimes. Furthermore, our research provides conclusive
insights into the performance-efficiency trade-offs of different LLMs,
detailing significant considerations for practical model selection in HFT
applications. PulseReddit and our findings establish a foundation for advanced
MAS research in HFT, demonstrating the tangible benefits of integrating social
media.

</details>


### [173] [EuroGEST: Investigating gender stereotypes in multilingual language models](https://arxiv.org/abs/2506.03867)
*Jacqueline Rowe,Mateusz Klimaszewski,Liane Guillou,Shannon Vallor,Alexandra Birch*

Main category: cs.CL

TL;DR: EuroGEST是一个用于测量多语言大模型性别偏见的数据集，覆盖英语和29种欧洲语言，发现模型普遍存在性别刻板印象。


<details>
  <summary>Details</summary>
Motivation: 现有性别偏见基准多为英语中心，缺乏多语言评估，EuroGEST填补了这一空白。

Method: 基于专家标注的16种性别刻板印象，通过翻译工具、质量评估指标和形态启发式方法扩展数据集。

Result: 模型普遍认为女性美丽、同理心强、整洁，男性是领导者、强壮、专业；更大模型刻板印象更强。

Conclusion: 需更多多语言公平性研究，EuroGEST为跨语言性别偏见审计提供可扩展方法。

Abstract: Large language models increasingly support multiple languages, yet most
benchmarks for gender bias remain English-centric. We introduce EuroGEST, a
dataset designed to measure gender-stereotypical reasoning in LLMs across
English and 29 European languages. EuroGEST builds on an existing
expert-informed benchmark covering 16 gender stereotypes, expanded in this work
using translation tools, quality estimation metrics, and morphological
heuristics. Human evaluations confirm that our data generation method results
in high accuracy of both translations and gender labels across languages. We
use EuroGEST to evaluate 24 multilingual language models from six model
families, demonstrating that the strongest stereotypes in all models across all
languages are that women are \textit{beautiful,} \textit{empathetic} and
\textit{neat} and men are \textit{leaders}, \textit{strong, tough} and
\textit{professional}. We also show that larger models encode gendered
stereotypes more strongly and that instruction finetuning does not consistently
reduce gendered stereotypes. Our work highlights the need for more multilingual
studies of fairness in LLMs and offers scalable methods and resources to audit
gender bias across languages.

</details>


### [174] [RadialRouter: Structured Representation for Efficient and Robust Large Language Models Routing](https://arxiv.org/abs/2506.03880)
*Ruihan Jin,Pengpeng Shao,Zhengqi Wen,Jinyang Wu,Mingkuan Feng,Shuai Zhang,Jianhua Tao*

Main category: cs.CL

TL;DR: RadialRouter是一种新型的LLM路由框架，通过轻量级Transformer结构RadialFormer优化查询与LLM之间的关系，显著提升了路由性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM路由方法在探索用户查询与LLM特性之间的内在联系方面不足，限制了其有效性。

Method: 采用RadialFormer结构，结合Kullback-Leibler散度和查询对比损失的目标函数，优化LLM选择。

Result: 在RouterBench上，RadialRouter在Balance和Cost First场景中分别比现有方法高出9.2%和5.8%。

Conclusion: RadialRouter展示了在不同性能-成本权衡和动态LLM池中的适应性，具有实际应用潜力。

Abstract: The rapid advancements in large language models (LLMs) have led to the
emergence of routing techniques, which aim to efficiently select the optimal
LLM from diverse candidates to tackle specific tasks, optimizing performance
while reducing costs. Current LLM routing methods are limited in effectiveness
due to insufficient exploration of the intrinsic connection between user
queries and the characteristics of LLMs. To address this issue, in this paper,
we present RadialRouter, a novel framework for LLM routing which employs a
lightweight Transformer-based backbone with a radial structure named
RadialFormer to articulate the query-LLMs relationship. The optimal LLM
selection is performed based on the final states of RadialFormer. The pipeline
is further refined by an objective function that combines Kullback-Leibler
divergence with the query-query contrastive loss to enhance robustness.
Experimental results on RouterBench show that RadialRouter significantly
outperforms existing routing methods by 9.2\% and 5.8\% in the Balance and Cost
First scenarios, respectively. Additionally, its adaptability toward different
performance-cost trade-offs and the dynamic LLM pool demonstrates practical
application potential.

</details>


### [175] [Kinship in Speech: Leveraging Linguistic Relatedness for Zero-Shot TTS in Indian Languages](https://arxiv.org/abs/2506.03884)
*Utkarsh Pathak,Chandra Sai Krishna Gunda,Anusha Prakash,Keshav Agarwal,Hema A. Murthy*

Main category: cs.CL

TL;DR: 该论文提出了一种零样本合成方法，通过共享音素表示和调整文本解析规则，为资源稀缺的印度语言生成可理解和自然的语音。


<details>
  <summary>Details</summary>
Motivation: 印度有1369种语言，其中许多缺乏数字资源，训练TTS系统具有挑战性。研究旨在为这些语言提供快速适应的语音合成方案。

Method: 通过共享音素表示和修改文本解析规则，以适应目标语言的音位规则，降低合成器开销。

Result: 成功为梵语、马哈拉施特拉语、卡纳拉孔卡尼语、迈蒂利语和库鲁克语生成了可理解和自然的语音。

Conclusion: 该方法有效扩展了语音技术对资源稀缺语言的覆盖，具有广泛应用潜力。

Abstract: Text-to-speech (TTS) systems typically require high-quality studio data and
accurate transcriptions for training. India has 1369 languages, with 22
official using 13 scripts. Training a TTS system for all these languages, most
of which have no digital resources, seems a Herculean task. Our work focuses on
zero-shot synthesis, particularly for languages whose scripts and phonotactics
come from different families. The novelty of our work is in the augmentation of
a shared phone representation and modifying the text parsing rules to match the
phonotactics of the target language, thus reducing the synthesiser overhead and
enabling rapid adaptation. Intelligible and natural speech was generated for
Sanskrit, Maharashtrian and Canara Konkani, Maithili and Kurukh by leveraging
linguistic connections across languages with suitable synthesisers. Evaluations
confirm the effectiveness of this approach, highlighting its potential to
expand speech technology access for under-represented languages.

</details>


### [176] [Pre$^3$: Enabling Deterministic Pushdown Automata for Faster Structured LLM Generation](https://arxiv.org/abs/2506.03887)
*Junyi Chen,Shihao Bai,Zaijun Wang,Siyu Wu,Chuheng Du,Hailong Yang,Ruihao Gong,Shengzhong Liu,Fan Wu,Guihai Chen*

Main category: cs.CL

TL;DR: Pre$^3$通过利用确定性下推自动机（DPDA）优化LLM解码效率，减少运行时开销，提升生成速度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理LR(1)文法时存在运行时执行开销，尤其是在大规模推理批次下效率低下。

Method: Pre$^3$通过预处理前缀条件边实现并行转换处理，并将LR(1)转换图转化为DPDA，避免运行时路径探索。

Result: 实验显示，Pre$^3$将每个输出令牌的时间减少40%，吞吐量提升36%。

Conclusion: Pre$^3$是一种高效的方法，可无缝集成到标准LLM推理框架中，显著提升性能。

Abstract: Extensive LLM applications demand efficient structured generations,
particularly for LR(1) grammars, to produce outputs in specified formats (e.g.,
JSON). Existing methods primarily parse LR(1) grammars into a pushdown
automaton (PDA), leading to runtime execution overhead for context-dependent
token processing, especially inefficient under large inference batches. To
address these issues, we propose Pre$^3$ that exploits deterministic pushdown
automata (DPDA) to optimize the constrained LLM decoding efficiency. First, by
precomputing prefix-conditioned edges during the preprocessing, Pre$^3$ enables
ahead-of-time edge analysis and thus makes parallel transition processing
possible. Second, by leveraging the prefix-conditioned edges, Pre$^3$
introduces a novel approach that transforms LR(1) transition graphs into DPDA,
eliminating the need for runtime path exploration and achieving edge
transitions with minimal overhead. Pre$^3$ can be seamlessly integrated into
standard LLM inference frameworks, reducing time per output token (TPOT) by up
to 40% and increasing throughput by up to 36% in our experiments. Our code is
available at https://github.com/ModelTC/lightllm.

</details>


### [177] [Magic Mushroom: A Customizable Benchmark for Fine-grained Analysis of Retrieval Noise Erosion in RAG Systems](https://arxiv.org/abs/2506.03901)
*Yuxin Zhang,Yan Wang,Yongrui Chen,Shenyu Zhang,Xinbang Dai,Sheng Bi,Guilin Qi*

Main category: cs.CL

TL;DR: 本文介绍了Magic Mushroom基准，用于模拟真实检索环境中的复杂噪声，评估和提升RAG系统的抗噪能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法模拟真实检索环境中的复杂噪声分布，影响RAG系统的稳健性评估。

Method: 定义了四类检索噪声，并开发Magic Mushroom基准，包含单跳和多跳问答对，支持灵活配置噪声组合。

Result: 评估显示生成器和去噪策略在噪声分布下有显著改进空间，且对噪声分布极为敏感。

Conclusion: Magic Mushroom是评估和提升RAG系统抗噪能力的有力工具，推动其实际应用。

Abstract: Retrieval-Augmented Generation (RAG) systems enhance Large Language Models
(LLMs) by incorporating external retrieved information, mitigating issues such
as hallucination and outdated knowledge.
  However, RAG systems are highly sensitive to retrieval noise prevalent in
real-world scenarios.
  Existing benchmarks fail to emulate the complex and heterogeneous noise
distributions encountered in real-world retrieval environments, undermining
reliable robustness assessment.
  In this paper, we define four categories of retrieval noise based on
linguistic properties and noise characteristics, aiming to reflect the
heterogeneity of noise in real-world scenarios.
  Building on this, we introduce Magic Mushroom, a benchmark for replicating
"magic mushroom" noise: contexts that appear relevant on the surface but
covertly mislead RAG systems.
  Magic Mushroom comprises 7,468 single-hop and 3,925 multi-hop question-answer
pairs.
  More importantly, Magic Mushroom enables researchers to flexibly configure
combinations of retrieval noise according to specific research objectives or
application scenarios, allowing for highly controlled evaluation setups.
  We evaluate LLM generators of varying parameter scales and classic RAG
denoising strategies under diverse noise distributions to investigate their
performance dynamics during progressive noise encroachment.
  Our analysis reveals that both generators and denoising strategies have
significant room for improvement and exhibit extreme sensitivity to noise
distributions.
  Magic Mushroom emerges as a promising tool for evaluating and advancing
noise-robust RAG systems, accelerating their widespread deployment in
real-world applications.
  The Magic Mushroom benchmark is available at the
https://drive.google.com/file/d/1aP5kyPuk4L-L_uoI6T9UhxuTyt8oMqjT/view?usp=sharing.

</details>


### [178] [The Harmonic Structure of Information Contours](https://arxiv.org/abs/2506.03902)
*Eleftheria Tsipidi,Samuel Kiegeland,Franz Nowak,Tianyang Xu,Ethan Wilcox,Alex Warstadt,Ryan Cotterell,Mario Giulianelli*

Main category: cs.CL

TL;DR: 论文探讨了语言信息密度的周期性波动，提出了一种新的分析方法，发现信息率在多种语言中存在周期性模式，并与话语结构相关。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索语言信息密度波动的原因，尤其是周期性压力对信息分布的影响。

Method: 采用谐波回归和时间缩放方法，分析六种语言文本中的信息率周期性。

Result: 发现信息率存在周期性模式，且主要频率与话语结构一致。

Conclusion: 研究表明信息率的周期性波动反映了语言组织的深层结构，为语言分析提供了新框架。

Abstract: The uniform information density (UID) hypothesis proposes that speakers aim
to distribute information evenly throughout a text, balancing production effort
and listener comprehension difficulty. However, language typically does not
maintain a strictly uniform information rate; instead, it fluctuates around a
global average. These fluctuations are often explained by factors such as
syntactic constraints, stylistic choices, or audience design. In this work, we
explore an alternative perspective: that these fluctuations may be influenced
by an implicit linguistic pressure towards periodicity, where the information
rate oscillates at regular intervals, potentially across multiple frequencies
simultaneously. We apply harmonic regression and introduce a novel extension
called time scaling to detect and test for such periodicity in information
contours. Analyzing texts in English, Spanish, German, Dutch, Basque, and
Brazilian Portuguese, we find consistent evidence of periodic patterns in
information rate. Many dominant frequencies align with discourse structure,
suggesting these oscillations reflect meaningful linguistic organization.
Beyond highlighting the connection between information rate and discourse
structure, our approach offers a general framework for uncovering structural
pressures at various levels of linguistic granularity.

</details>


### [179] [When Fairness Isn't Statistical: The Limits of Machine Learning in Evaluating Legal Reasoning](https://arxiv.org/abs/2506.03913)
*Claire Barale,Michael Rovatsos,Nehal Bhuta*

Main category: cs.CL

TL;DR: 论文探讨了机器学习在法律公平性评估中的局限性，通过实证分析三种常见方法在难民案件数据集上的表现，发现其信号不一致且依赖非法律特征，强调需结合法律推理和制度背景。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估机器学习方法在法律公平性评估中的有效性，尤其是在难民裁决等高风险领域，现有方法是否能真正衡量公平性。

Method: 采用三种机器学习方法（基于特征的分析、语义聚类和预测建模）对59,000+加拿大难民案件数据集（AsyLex）进行实证分析。

Result: 实验结果显示这些方法产生不一致甚至矛盾的信号，预测建模依赖上下文和程序特征而非法律特征，语义聚类未能捕捉实质性法律推理。

Conclusion: 结论指出统计公平性评估的局限性，强调公平性评估需结合数据、法律推理和制度背景，当前计算方法不足以衡量法律领域的公平性。

Abstract: Legal decisions are increasingly evaluated for fairness, consistency, and
bias using machine learning (ML) techniques. In high-stakes domains like
refugee adjudication, such methods are often applied to detect disparities in
outcomes. Yet it remains unclear whether statistical methods can meaningfully
assess fairness in legal contexts shaped by discretion, normative complexity,
and limited ground truth.
  In this paper, we empirically evaluate three common ML approaches
(feature-based analysis, semantic clustering, and predictive modeling) on a
large, real-world dataset of 59,000+ Canadian refugee decisions (AsyLex). Our
experiments show that these methods produce divergent and sometimes
contradictory signals, that predictive modeling often depends on contextual and
procedural features rather than legal features, and that semantic clustering
fails to capture substantive legal reasoning.
  We show limitations of statistical fairness evaluation, challenge the
assumption that statistical regularity equates to fairness, and argue that
current computational approaches fall short of evaluating fairness in legally
discretionary domains. We argue that evaluating fairness in law requires
methods grounded not only in data, but in legal reasoning and institutional
context.

</details>


### [180] [Compositional Generalisation for Explainable Hate Speech Detection](https://arxiv.org/abs/2506.03916)
*Agostina Calabrese,Tom Sherborne,Björn Ross,Mirella Lapata*

Main category: cs.CL

TL;DR: 论文探讨了仇恨言论检测模型的泛化问题，提出通过均衡上下文表达频率的数据集U-PLEAD提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论检测模型因数据集偏见和句子级标签难以泛化，需要更细粒度的标注和上下文均衡的数据。

Method: 使用U-PLEAD数据集（36.4万合成帖子）和真实数据训练模型，并验证其组合泛化能力。

Result: 结合U-PLEAD和真实数据训练后，模型在组合泛化上表现更优，并在人工标注的PLEAD上达到最佳性能。

Conclusion: 均衡上下文表达频率的数据集能有效提升仇恨言论检测模型的泛化能力。

Abstract: Hate speech detection is key to online content moderation, but current models
struggle to generalise beyond their training data. This has been linked to
dataset biases and the use of sentence-level labels, which fail to teach models
the underlying structure of hate speech. In this work, we show that even when
models are trained with more fine-grained, span-level annotations (e.g.,
"artists" is labeled as target and "are parasites" as dehumanising comparison),
they struggle to disentangle the meaning of these labels from the surrounding
context. As a result, combinations of expressions that deviate from those seen
during training remain particularly difficult for models to detect. We
investigate whether training on a dataset where expressions occur with equal
frequency across all contexts can improve generalisation. To this end, we
create U-PLEAD, a dataset of ~364,000 synthetic posts, along with a novel
compositional generalisation benchmark of ~8,000 manually validated posts.
Training on a combination of U-PLEAD and real data improves compositional
generalisation while achieving state-of-the-art performance on the
human-sourced PLEAD.

</details>


### [181] [HSSBench: Benchmarking Humanities and Social Sciences Ability for Multimodal Large Language Models](https://arxiv.org/abs/2506.03922)
*Zhaolu Kang,Junhao Gong,Jiaxu Yan,Wanke Xia,Yian Wang,Ziwen Wang,Huaxuan Ding,Zhuo Cheng,Wenhao Cao,Zhiyuan Feng,Siqi He,Shannan Yan,Junzhe Chen,Xiaomin He,Chaoya Jiang,Wei Ye,Kaidong Yu,Xuelong Li*

Main category: cs.CL

TL;DR: HSSBench是一个专为评估多模态大语言模型（MLLMs）在人文学科和社会科学（HSS）任务中的表现而设计的基准测试，填补了现有基准测试的不足。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs的基准测试主要关注STEM领域的垂直推理，忽视了HSS领域对跨学科横向思维的需求。HSSBench旨在解决这一差距。

Method: 通过多领域专家与自动化代理协作生成和迭代优化样本，构建了包含13,000多个样本的HSSBench，涵盖六种联合国官方语言和六个关键类别。

Result: 对20多个主流MLLMs的测试表明，HSSBench对最先进模型仍具挑战性。

Conclusion: HSSBench有望推动MLLMs在跨学科推理能力上的进一步研究。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated significant
potential to advance a broad range of domains. However, current benchmarks for
evaluating MLLMs primarily emphasize general knowledge and vertical
step-by-step reasoning typical of STEM disciplines, while overlooking the
distinct needs and potential of the Humanities and Social Sciences (HSS). Tasks
in the HSS domain require more horizontal, interdisciplinary thinking and a
deep integration of knowledge across related fields, which presents unique
challenges for MLLMs, particularly in linking abstract concepts with
corresponding visual representations. Addressing this gap, we present HSSBench,
a dedicated benchmark designed to assess the capabilities of MLLMs on HSS tasks
in multiple languages, including the six official languages of the United
Nations. We also introduce a novel data generation pipeline tailored for HSS
scenarios, in which multiple domain experts and automated agents collaborate to
generate and iteratively refine each sample. HSSBench contains over 13,000
meticulously designed samples, covering six key categories. We benchmark more
than 20 mainstream MLLMs on HSSBench and demonstrate that it poses significant
challenges even for state-of-the-art models. We hope that this benchmark will
inspire further research into enhancing the cross-disciplinary reasoning
abilities of MLLMs, especially their capacity to internalize and connect
knowledge across fields.

</details>


### [182] [More or Less Wrong: A Benchmark for Directional Bias in LLM Comparative Reasoning](https://arxiv.org/abs/2506.03923)
*Mohammadamin Shafiei,Hamidreza Saffari,Nafise Sadat Moosavi*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）在数学比较问题中受输入措辞影响，存在方向性框架偏差，且链式思维提示可部分缓解偏差，但效果因形式而异。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs对语义框架的敏感性及其对推理的影响，揭示输入措辞如何系统性引导预测。

Method: 引入MathComp基准，包含300个比较场景，每种场景在14种提示变体下评估三种LLM家族的表现。

Result: 模型错误常反映语言引导，链式思维提示可减少偏差，但自由形式推理更稳健。此外，包含人口统计身份词会放大偏差。

Conclusion: 研究揭示了标准评估中的盲点，呼吁开发框架感知的基准以诊断LLMs的推理鲁棒性和公平性。

Abstract: Large language models (LLMs) are known to be sensitive to input phrasing, but
the mechanisms by which semantic cues shape reasoning remain poorly understood.
We investigate this phenomenon in the context of comparative math problems with
objective ground truth, revealing a consistent and directional framing bias:
logically equivalent questions containing the words ``more'', ``less'', or
``equal'' systematically steer predictions in the direction of the framing
term. To study this effect, we introduce MathComp, a controlled benchmark of
300 comparison scenarios, each evaluated under 14 prompt variants across three
LLM families. We find that model errors frequently reflect linguistic steering,
systematic shifts toward the comparative term present in the prompt.
Chain-of-thought prompting reduces these biases, but its effectiveness varies:
free-form reasoning is more robust, while structured formats may preserve or
reintroduce directional drift. Finally, we show that including demographic
identity terms (e.g., ``a woman'', ``a Black person'') in input scenarios
amplifies directional drift, despite identical underlying quantities,
highlighting the interplay between semantic framing and social referents. These
findings expose critical blind spots in standard evaluation and motivate
framing-aware benchmarks for diagnosing reasoning robustness and fairness in
LLMs.

</details>


### [183] [Hanging in the Balance: Pivotal Moments in Crisis Counseling Conversations](https://arxiv.org/abs/2506.03941)
*Vivian Nguyen,Lillian Lee,Cristian Danescu-Niculescu-Mizil*

Main category: cs.CL

TL;DR: 该论文提出了一种无监督计算方法，用于实时检测对话中的关键转折点，并在心理危机咨询中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 对话中的某些关键时刻可能对结果产生重大影响，尤其是在心理危机咨询等高后果领域。若能检测这些时刻，可为对话者提供帮助。

Method: 通过分析对话中不同回应对结果预期的影响，提出了一种无监督计算方法，用于在线检测关键转折点。

Result: 方法验证显示，检测到的关键时刻与人类感知一致（咨询师回应时间显著延长），且对话轨迹更易改变。此外，还探讨了咨询师回应与最终结果的关系。

Conclusion: 该方法能有效检测对话中的关键转折点，为高后果对话领域提供了实用工具。

Abstract: During a conversation, there can come certain moments where its outcome hangs
in the balance. In these pivotal moments, how one responds can put the
conversation on substantially different trajectories leading to significantly
different outcomes. Systems that can detect when such moments arise could
assist conversationalists in domains with highly consequential outcomes, such
as mental health crisis counseling.
  In this work, we introduce an unsupervised computational method for detecting
such pivotal moments as they happen, in an online fashion. Our approach relies
on the intuition that a moment is pivotal if our expectation of the outcome
varies widely depending on what might be said next. By applying our method to
crisis counseling conversations, we first validate it by showing that it aligns
with human perception -- counselors take significantly longer to respond during
moments detected by our method -- and with the eventual conversational
trajectory -- which is more likely to change course at these times. We then use
our framework to explore the relation of the counselor's response during
pivotal moments with the eventual outcome of the session.

</details>


### [184] [TableEval: A Real-World Benchmark for Complex, Multilingual, and Multi-Structured Table Question Answering](https://arxiv.org/abs/2506.03949)
*Junnan Zhu,Jingyi Wang,Bohan Yu,Xiaoyu Wu,Junbo Li,Lei Wang,Nan Xu*

Main category: cs.CL

TL;DR: TableEval是一个新的TableQA基准，旨在评估LLMs在复杂现实任务中的表现，包括多语言和多领域数据，并提出SEAT评估框架以提高语义准确性。


<details>
  <summary>Details</summary>
Motivation: 现有TableQA基准局限于简单表格和单语言数据，无法反映现实中的复杂性和多样性，因此需要更全面的评估工具。

Method: TableEval包含多种结构的表格（如简洁、分层和嵌套表格）和跨语言数据（简体中文、繁体中文和英文），并采用SEAT框架评估语义准确性。

Result: 实验表明SEAT与人类判断高度一致，且当前LLMs在处理复杂TableQA任务时存在显著不足。

Conclusion: TableEval和SEAT为未来LLMs在TableQA领域的改进提供了重要参考和工具。

Abstract: LLMs have shown impressive progress in natural language processing. However,
they still face significant challenges in TableQA, where real-world
complexities such as diverse table structures, multilingual data, and
domain-specific reasoning are crucial. Existing TableQA benchmarks are often
limited by their focus on simple flat tables and suffer from data leakage.
Furthermore, most benchmarks are monolingual and fail to capture the
cross-lingual and cross-domain variability in practical applications. To
address these limitations, we introduce TableEval, a new benchmark designed to
evaluate LLMs on realistic TableQA tasks. Specifically, TableEval includes
tables with various structures (such as concise, hierarchical, and nested
tables) collected from four domains (including government, finance, academia,
and industry reports). Besides, TableEval features cross-lingual scenarios with
tables in Simplified Chinese, Traditional Chinese, and English. To minimize the
risk of data leakage, we collect all data from recent real-world documents.
Considering that existing TableQA metrics fail to capture semantic accuracy, we
further propose SEAT, a new evaluation framework that assesses the alignment
between model responses and reference answers at the sub-question level.
Experimental results have shown that SEAT achieves high agreement with human
judgment. Extensive experiments on TableEval reveal critical gaps in the
ability of state-of-the-art LLMs to handle these complex, real-world TableQA
tasks, offering insights for future improvements. We make our dataset available
here: https://github.com/wenge-research/TableEval.

</details>


### [185] [From Real to Synthetic: Synthesizing Millions of Diversified and Complicated User Instructions with Attributed Grounding](https://arxiv.org/abs/2506.03968)
*Chiwei Zhu,Benfeng Xu,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: 论文提出了一种基于属性接地的指令合成方法，通过结合自上而下的用户情境接地的指令选择与自下而上的基于网络文档的情境生成，实现了大规模、多样化和复杂指令的生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法生成合成指令时，要么缺乏广泛的接地来源导致分布狭窄，要么依赖简单扩展而无法产生有意义的复杂指令。高效对齐LLMs需要基于认知洞察和真实用例的指令。

Method: 采用属性接地框架：1）自上而下将真实指令与用户情境接地；2）自下而上利用网络文档首先生成情境，再生成有意义的指令。

Result: 构建了包含100万条指令的SynthQuestions数据集，模型在其上训练后在多个基准测试中表现领先，且性能随网络语料增加持续提升。

Conclusion: 属性接地方法能有效生成多样化和复杂的指令，显著提升LLMs对齐性能。

Abstract: The pursuit of diverse, complex, and large-scale instruction data is crucial
for automatically aligning large language models (LLMs). While there are
methods capable of generating synthetic instructions at scale, they either
suffer from limited grounding sources, leading to a narrow distribution, or
rely on trivial extensions that fail to produce meaningful trajectories in
terms of complexity. In contrast, instructions that benefit efficient alignment
are typically crafted with cognitive insights and grounded in real-world use
cases. In this paper, we synthesize such instructions using attributed
grounding, which involves 1) a top-down attribution process that grounds a
selective set of real instructions to situated users, and 2) a bottom-up
synthesis process that leverages web documents to first generate a situation,
then a meaningful instruction. This framework allows us to harvest diverse and
complex instructions at scale, utilizing the vast range of web documents.
Specifically, we construct a dataset of 1 million instructions, called
SynthQuestions, and demonstrate that models trained on it achieve leading
performance on several common benchmarks, with improvements that continually
scale with more web corpora. Data, models and codes will be available at
https://github.com/Ignoramus0817/SynthQuestions.

</details>


### [186] [Structured Pruning for Diverse Best-of-N Reasoning Optimization](https://arxiv.org/abs/2506.03978)
*Hieu Trung Nguyen,Bao Nguyen,Viet Anh Nguyen*

Main category: cs.CL

TL;DR: 模型剪枝在基于Transformer的语言模型中不仅能节省计算资源，还能提升推理能力。研究发现选择性剪枝某些注意力头可以显著提升推理性能，尤其是在复杂任务上。为此，作者提出了SPRINT框架，通过对比学习动态选择最优剪枝配置，实验证明其在MATH500和GSM8K数据集上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统模型剪枝主要用于节省计算资源，但研究发现选择性剪枝某些注意力头可以提升模型的推理能力，尤其是在复杂任务上。这一现象激发了作者探索动态剪枝策略的研究。

Method: 提出了SPRINT框架，通过对比学习动态选择最优的注意力头和层进行剪枝。具体方法是通过对齐问题嵌入和注意力头嵌入，识别出能提升推理准确性的剪枝配置。

Result: 在MATH500和GSM8K数据集上的实验表明，SPRINT显著优于传统的best-of-N和随机剪枝策略。

Conclusion: 选择性剪枝不仅能节省计算资源，还能提升模型的推理能力。SPRINT框架通过动态选择剪枝配置，为模型优化提供了新思路。

Abstract: Model pruning in transformer-based language models, traditionally viewed as a
means of achieving computational savings, can enhance the model's reasoning
capabilities. In this work, we uncover a surprising phenomenon: the selective
pruning of certain attention heads leads to improvements in reasoning
performance, particularly on challenging tasks. Motivated by this observation,
we propose SPRINT, a novel contrastive learning framework that dynamically
selects the optimal head and layer to prune during inference. By aligning
question embeddings with head embeddings, SPRINT identifies those pruned-head
configurations that result in more accurate reasoning. Extensive experiments
demonstrate that our method significantly outperforms traditional best-of-$N$
and random head selection strategies on the MATH500 and GSM8K datasets.

</details>


### [187] [Voice Activity Projection Model with Multimodal Encoders](https://arxiv.org/abs/2506.03980)
*Takeshi Saga,Catherine Pelachaud*

Main category: cs.CL

TL;DR: 本文提出了一种多模态模型，结合预训练的音频和面部编码器，显著提升了对话轮次预测的性能。


<details>
  <summary>Details</summary>
Motivation: 由于社交环境的复杂性和多模态特性，人机交互中的轮次管理具有挑战性。现有基于静音时长的传统系统效果有限，而多模态VAP模型表现更优。

Method: 提出了一种增强的多模态VAP模型，利用预训练的音频和面部编码器捕捉细微表情。

Result: 模型在轮次预测指标上表现优异，部分情况下甚至优于现有最佳模型。

Conclusion: 该模型为轮次管理提供了更高效的解决方案，代码和预训练模型已开源。

Abstract: Turn-taking management is crucial for any social interaction. Still, it is
challenging to model human-machine interaction due to the complexity of the
social context and its multimodal nature. Unlike conventional systems based on
silence duration, previous existing voice activity projection (VAP) models
successfully utilized a unified representation of turn-taking behaviors as
prediction targets, which improved turn-taking prediction performance.
Recently, a multimodal VAP model outperformed the previous state-of-the-art
model by a significant margin. In this paper, we propose a multimodal model
enhanced with pre-trained audio and face encoders to improve performance by
capturing subtle expressions. Our model performed competitively, and in some
cases, even better than state-of-the-art models on turn-taking metrics. All the
source codes and pretrained models are available at
https://github.com/sagatake/VAPwithAudioFaceEncoders.

</details>


### [188] [Around the World in 24 Hours: Probing LLM Knowledge of Time and Place](https://arxiv.org/abs/2506.03984)
*Carolin Holtermann,Paul Röttger,Anne Lauscher*

Main category: cs.CL

TL;DR: 论文评估了语言模型在时空联合推理上的能力，发现模型在纯时间推理上表现良好，但在时空结合任务中表现受限，且表现与提示形式密切相关。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型在时空联合推理上的能力，填补此前研究仅关注孤立或简单环境的空白。

Method: 创建GeoTemp数据集（320k提示，覆盖289城市、217国家、37时区），评估8个开放聊天模型在不同时空知识组合上的表现。

Result: 模型在纯时间推理上表现良好，规模越大表现越好；时空结合任务表现受限；提示形式对性能影响显著。

Conclusion: 语言模型在时空联合推理上仍有局限，提示形式是关键影响因素，未来需优化训练和推理方法。

Abstract: Reasoning over time and space is essential for understanding our world.
However, the abilities of language models in this area are largely unexplored
as previous work has tested their abilities for logical reasoning in terms of
time and space in isolation or only in simple or artificial environments. In
this paper, we present the first evaluation of the ability of language models
to jointly reason over time and space. To enable our analysis, we create
GeoTemp, a dataset of 320k prompts covering 289 cities in 217 countries and 37
time zones. Using GeoTemp, we evaluate eight open chat models of three
different model families for different combinations of temporal and geographic
knowledge. We find that most models perform well on reasoning tasks involving
only temporal knowledge and that overall performance improves with scale.
However, performance remains constrained in tasks that require connecting
temporal and geographical information. We do not find clear correlations of
performance with specific geographic regions. Instead, we find a significant
performance increase for location names with low model perplexity, suggesting
their repeated occurrence during model training. We further demonstrate that
their performance is heavily influenced by prompt formulation - a direct
injection of geographical knowledge leads to performance gains, whereas,
surprisingly, techniques like chain-of-thought prompting decrease performance
on simpler tasks.

</details>


### [189] [Stronger Baselines for Retrieval-Augmented Generation with Long-Context Language Models](https://arxiv.org/abs/2506.03989)
*Alex Laitenberger,Christopher D. Manning,Nelson F. Liu*

Main category: cs.CL

TL;DR: 本文探讨了在多阶段检索增强生成（RAG）与简单单阶段方法之间的比较，发现简单的DOS RAG方法在长上下文QA任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着长上下文语言模型（LMs）的发展，研究是否需要复杂的多阶段RAG方法，还是简单的单阶段方法已经足够。

Method: 通过系统化的评估，比较了两种多阶段RAG方法（ReadAgent和RAPTOR）与三种基线方法（包括DOS RAG）在QA任务中的表现。

Result: DOS RAG在多个长上下文QA基准测试中表现优于或与复杂方法相当。

Conclusion: 建议将DOS RAG作为未来RAG评估的简单但强基线，以权衡复杂性与效果。

Abstract: With the rise of long-context language models (LMs) capable of processing
tens of thousands of tokens in a single pass, do multi-stage
retrieval-augmented generation (RAG) pipelines still offer measurable benefits
over simpler, single-stage approaches? To assess this question, we conduct a
controlled evaluation for QA tasks under systematically scaled token budgets,
comparing two recent multi-stage pipelines, ReadAgent and RAPTOR, against three
baselines, including DOS RAG (Document's Original Structure RAG), a simple
retrieve-then-read method that preserves original passage order. Despite its
straightforward design, DOS RAG consistently matches or outperforms more
intricate methods on multiple long-context QA benchmarks. We recommend
establishing DOS RAG as a simple yet strong baseline for future RAG
evaluations, pairing it with emerging embedding and language models to assess
trade-offs between complexity and effectiveness as model capabilities evolve.

</details>


### [190] [DynTok: Dynamic Compression of Visual Tokens for Efficient and Effective Video Understanding](https://arxiv.org/abs/2506.03990)
*Hongzhi Zhang,Jingyuan Zhang,Xingguang Ji,Qi Wang,Fuzheng Zhang*

Main category: cs.CL

TL;DR: DynTok是一种动态视频令牌压缩策略，通过自适应分组和合并视觉令牌，减少计算开销，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频建模方法（如LLava）处理长视频时会产生大量视觉令牌，导致计算负担。

Method: DynTok将视觉令牌自适应分组并合并，高压缩低信息密度区域，保留关键内容。

Result: 令牌数量减少至原44.4%，性能相当；在Video-MME和MLVU上分别达到65.3%和72.5%。

Conclusion: DynTok揭示了视频令牌表示的冗余性，为高效视频建模技术设计提供了思路。

Abstract: Typical video modeling methods, such as LLava, represent videos as sequences
of visual tokens, which are then processed by the LLM backbone for effective
video understanding. However, this approach leads to a massive number of visual
tokens, especially for long videos. A practical solution is to first extract
relevant visual information from the large visual context before feeding it
into the LLM backbone, thereby reducing computational overhead. In this work,
we introduce DynTok, a novel \textbf{Dyn}amic video \textbf{Tok}en compression
strategy. DynTok adaptively splits visual tokens into groups and merges them
within each group, achieving high compression in regions with low information
density while preserving essential content. Our method reduces the number of
tokens to 44.4% of the original size while maintaining comparable performance.
It further benefits from increasing the number of video frames and achieves
65.3% on Video-MME and 72.5% on MLVU. By applying this simple yet effective
compression method, we expose the redundancy in video token representations and
offer insights for designing more efficient video modeling techniques.

</details>


### [191] [Words of Warmth: Trust and Sociability Norms for over 26k English Words](https://arxiv.org/abs/2506.03993)
*Saif M. Mohammad*

Main category: cs.CL

TL;DR: 论文介绍了首个大规模手动标注的词汇-温暖（及信任、社交性）关联数据库Words of Warmth，并验证了其可靠性。通过该数据库研究了儿童词汇习得速度，并展示了其在偏见和刻板印象研究中的应用。


<details>
  <summary>Details</summary>
Motivation: 探索温暖（Warmth）和信任（Trust）、社交性（Sociability）等维度如何构成，以及这些维度在人类社会认知中的作用。

Method: 构建了包含26k英语词汇的词汇-温暖关联数据库，验证其可靠性，并应用于儿童词汇习得和偏见研究。

Result: 数据库高度可靠，可用于研究儿童词汇习得速度，并支持多种偏见和刻板印象研究。

Conclusion: Words of Warmth为研究社会认知提供了重要工具，尤其在儿童发展和偏见研究领域具有广泛应用价值。

Abstract: Social psychologists have shown that Warmth (W) and Competence (C) are the
primary dimensions along which we assess other people and groups. These
dimensions impact various aspects of our lives from social competence and
emotion regulation to success in the work place and how we view the world. More
recent work has started to explore how these dimensions develop, why they have
developed, and what they constitute. Of particular note, is the finding that
warmth has two distinct components: Trust (T) and Sociability (S). In this
work, we introduce Words of Warmth, the first large-scale repository of
manually derived word--warmth (as well as word--trust and word--sociability)
associations for over 26k English words. We show that the associations are
highly reliable. We use the lexicons to study the rate at which children
acquire WCTS words with age. Finally, we show that the lexicon enables a wide
variety of bias and stereotype research through case studies on various target
entities. Words of Warmth is freely available at:
http://saifmohammad.com/warmth.html

</details>


### [192] [Seeing What Tastes Good: Revisiting Multimodal Distributional Semantics in the Billion Parameter Era](https://arxiv.org/abs/2506.03994)
*Dan Oneata,Desmond Elliott,Stella Frank*

Main category: cs.CL

TL;DR: 论文研究了大规模模型在表示具体物体概念的语义特征（如颜色、气味等）方面的表现，发现多模态图像编码器略优于纯语言模型，而纯图像编码器在非视觉属性上表现与语言模型相当。


<details>
  <summary>Details</summary>
Motivation: 探索大规模模型是否能像人类一样基于感知运动经验表示具体物体概念的语义特征。

Method: 使用探测任务评估图像编码器（纯图像、多模态）和纯语言模型在预测McRae和Binder数据集属性评分上的表现。

Result: 多模态图像编码器略优于纯语言模型；纯图像编码器在非视觉属性上与语言模型表现相当。

Conclusion: 研究揭示了单模态学习的潜力及多模态的互补性。

Abstract: Human learning and conceptual representation is grounded in sensorimotor
experience, in contrast to state-of-the-art foundation models. In this paper,
we investigate how well such large-scale models, trained on vast quantities of
data, represent the semantic feature norms of concrete object concepts, e.g. a
ROSE is red, smells sweet, and is a flower. More specifically, we use probing
tasks to test which properties of objects these models are aware of. We
evaluate image encoders trained on image data alone, as well as
multimodally-trained image encoders and language-only models, on predicting an
extended denser version of the classic McRae norms and the newer Binder dataset
of attribute ratings. We find that multimodal image encoders slightly
outperform language-only approaches, and that image-only encoders perform
comparably to the language models, even on non-visual attributes that are
classified as "encyclopedic" or "function". These results offer new insights
into what can be learned from pure unimodal learning, and the complementarity
of the modalities.

</details>


### [193] [QQSUM: A Novel Task and Model of Quantitative Query-Focused Summarization for Review-based Product Question Answering](https://arxiv.org/abs/2506.04020)
*An Quang Tang,Xiuzhen Zhang,Minh Ngoc Dinh,Zhuang Li*

Main category: cs.CL

TL;DR: 论文提出了一种新任务QQSUM，通过量化用户评论中的多样观点生成代表性关键点（KPs），并扩展了RAG模型为QQSUM-RAG，以更好地捕捉观点多样性。


<details>
  <summary>Details</summary>
Motivation: 现有PQA系统仅能生成单一视角的答案，无法反映用户评论的多样性。

Method: 提出QQSUM任务，并开发QQSUM-RAG模型，结合少样本学习训练KP检索器和KP生成器。

Result: QQSUM-RAG在文本质量和观点量化准确性上优于现有RAG基线。

Conclusion: QQSUM-RAG能有效捕捉多样观点，提升PQA系统的回答质量。

Abstract: Review-based Product Question Answering (PQA) allows e-commerce platforms to
automatically address customer queries by leveraging insights from user
reviews. However, existing PQA systems generate answers with only a single
perspective, failing to capture the diversity of customer opinions. In this
paper we introduce a novel task Quantitative Query-Focused Summarization
(QQSUM), which aims to summarize diverse customer opinions into representative
Key Points (KPs) and quantify their prevalence to effectively answer user
queries. While Retrieval-Augmented Generation (RAG) shows promise for PQA, its
generated answers still fall short of capturing the full diversity of
viewpoints. To tackle this challenge, our model QQSUM-RAG, which extends RAG,
employs few-shot learning to jointly train a KP-oriented retriever and a KP
summary generator, enabling KP-based summaries that capture diverse and
representative opinions. Experimental results demonstrate that QQSUM-RAG
achieves superior performance compared to state-of-the-art RAG baselines in
both textual quality and quantification accuracy of opinions. Our source code
is available at: https://github.com/antangrocket1312/QQSUMM

</details>


### [194] [AI Agents for Conversational Patient Triage: Preliminary Simulation-Based Evaluation with Real-World EHR Data](https://arxiv.org/abs/2506.04032)
*Sina Rashidian,Nan Li,Jonathan Amar,Jong Ha Lee,Sam Pugh,Eric Yang,Geoff Masterson,Myoung Cha,Yugang Jia,Akhil Vaid*

Main category: cs.CL

TL;DR: 开发了一个基于真实电子健康记录（EHR）数据的患者模拟器，用于训练和测试医疗AI代理，模拟真实患者对话，并通过专家评估验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 为医疗AI代理提供真实且可扩展的训练和测试环境，以提升其在多轮对话中的表现。

Method: 从真实EHR数据中提取患者案例，构建临床场景，并通过AI代理进行多轮对话模拟，最后由专家评估模拟效果。

Result: 模拟器在97.7%的情况下与患者案例一致，对话摘要的关联性达到99%。

Conclusion: 该方法成功构建了一个高性能的患者模拟器，可用于大规模训练和测试医疗AI代理。

Abstract: Background: We present a Patient Simulator that leverages real world patient
encounters which cover a broad range of conditions and symptoms to provide
synthetic test subjects for development and testing of healthcare agentic
models. The simulator provides a realistic approach to patient presentation and
multi-turn conversation with a symptom-checking agent. Objectives: (1) To
construct and instantiate a Patient Simulator to train and test an AI health
agent, based on patient vignettes derived from real EHR data. (2) To test the
validity and alignment of the simulated encounters provided by the Patient
Simulator to expert human clinical providers. (3) To illustrate the evaluation
framework of such an LLM system on the generated realistic, data-driven
simulations -- yielding a preliminary assessment of our proposed system.
Methods: We first constructed realistic clinical scenarios by deriving patient
vignettes from real-world EHR encounters. These vignettes cover a variety of
presenting symptoms and underlying conditions. We then evaluate the performance
of the Patient Simulator as a simulacrum of a real patient encounter across
over 500 different patient vignettes. We leveraged a separate AI agent to
provide multi-turn questions to obtain a history of present illness. The
resulting multiturn conversations were evaluated by two expert clinicians.
Results: Clinicians scored the Patient Simulator as consistent with the patient
vignettes in those same 97.7% of cases. The extracted case summary based on the
conversation history was 99% relevant. Conclusions: We developed a methodology
to incorporate vignettes derived from real healthcare patient data to build a
simulation of patient responses to symptom checking agents. The performance and
alignment of this Patient Simulator could be used to train and test a
multi-turn conversational AI agent at scale.

</details>


### [195] [The mutual exclusivity bias of bilingual visually grounded speech models](https://arxiv.org/abs/2506.04037)
*Dan Oneata,Leanne Nortje,Yevgen Matusevych,Herman Kamper*

Main category: cs.CL

TL;DR: 双语视觉语音模型中的互斥性（ME）偏置比单语模型弱，部分原因是视觉嵌入的方差较小。


<details>
  <summary>Details</summary>
Motivation: 研究双语儿童在语言学习中较少使用互斥性（ME）策略的现象，并通过计算模型探索其机制。

Method: 使用英语、法语和荷兰语的组合训练双语视觉语音（VGS）模型，分析其ME偏置。

Result: 双语模型的ME偏置普遍弱于单语模型，视觉嵌入方差较小导致对熟悉概念的混淆增加。

Conclusion: 双语模型的ME偏置较弱，揭示了视觉嵌入方差对ME偏置的影响，并为VGS模型中ME偏置的存在提供了新见解。

Abstract: Mutual exclusivity (ME) is a strategy where a novel word is associated with a
novel object rather than a familiar one, facilitating language learning in
children. Recent work has found an ME bias in a visually grounded speech (VGS)
model trained on English speech with paired images. But ME has also been
studied in bilingual children, who may employ it less due to cross-lingual
ambiguity. We explore this pattern computationally using bilingual VGS models
trained on combinations of English, French, and Dutch. We find that bilingual
models generally exhibit a weaker ME bias than monolingual models, though
exceptions exist. Analyses show that the combined visual embeddings of
bilingual models have a smaller variance for familiar data, partly explaining
the increase in confusion between novel and familiar concepts. We also provide
new insights into why the ME bias exists in VGS models in the first place. Code
and data: https://github.com/danoneata/me-vgs

</details>


### [196] [LexTime: A Benchmark for Temporal Ordering of Legal Events](https://arxiv.org/abs/2506.04041)
*Claire Barale,Leslie Barrett,Vikram Sunil Bajaj,Michael Rovatsos*

Main category: cs.CL

TL;DR: LexTime是首个用于评估LLMs在法律文本中事件排序能力的数据集，包含512个美国联邦投诉案例的事件对及其时间关系标注。研究发现LLMs在法律事件排序上比叙事更准确，但法律语言的复杂性仍是挑战。


<details>
  <summary>Details</summary>
Motivation: 现有数据集缺乏专家语言评估，无法理解LLMs在法律文本中的事件排序能力，因此需要专门的数据集和方法。

Method: 引入LexTime数据集，分析LLMs在法律文本中的事件排序表现，探讨上下文长度、显隐事件对及法律语言特征的影响。

Result: LLMs在法律事件排序上比叙事更准确（最高+10.5%），长上下文和隐式事件对提升准确率至80.8%，但法律语言复杂性仍是难点。

Conclusion: 需针对法律语言特点设计建模策略，以提升LLMs在时间事件推理中的表现。

Abstract: Temporal reasoning in legal texts is important for applications like case law
analysis and compliance monitoring. However, existing datasets lack expert
language evaluation, leaving a gap in understanding how LLMs manage event
ordering in legal contexts. We introduce LexTime, the first dataset designed to
evaluate LLMs' event ordering capabilities in legal language, consisting of 512
instances from U.S. Federal Complaints with annotated event pairs and their
temporal relations. Our findings show that (1) LLMs are more accurate on legal
event ordering than on narrative (up to +10.5%); (2) longer input contexts and
implicit events boost accuracy, reaching 80.8% for implicit-explicit event
pairs; (3) legal linguistic complexities and nested clauses remain a challenge.
We investigate how context length, explicit vs implicit event pairs, and legal
language features affect model performance, demonstrating the need for specific
modeling strategies to enhance temporal event reasoning.

</details>


### [197] [Unveiling and Eliminating the Shortcut Learning for Locate-Then-Edit Knowledge Editing via Both Subject and Relation Awareness](https://arxiv.org/abs/2506.04042)
*Xiyu Liu,Zhengxiao Liu,Naibin Gu,Zheng Lin,Ji Xiang,Weiping Wang*

Main category: cs.CL

TL;DR: 论文提出了一种两阶段优化方法，解决了知识编辑中因主题特征过度学习而导致的不可控问题，实现了更可控的知识编辑。


<details>
  <summary>Details</summary>
Motivation: 知识编辑的目标是修改大语言模型中的目标知识，同时最小化对无关知识的影响。现有方法因主题特征过度学习而无法实现可控编辑。

Method: 提出了一种两阶段优化过程，平衡主题特征和关系特征的学习，避免主题特征的过度学习。

Result: 实验结果表明，该方法有效防止了知识编辑中的捷径学习问题，实现了最优的整体性能。

Conclusion: 两阶段优化方法成功解决了知识编辑中的不可控问题，为可控知识编辑提供了有效解决方案。

Abstract: Knowledge editing aims to alternate the target knowledge predicted by large
language models while ensuring the least side effects on unrelated knowledge.
An effective way to achieve knowledge editing is to identify pivotal parameters
for predicting factual associations and modify them with an optimization
process to update the predictions. However, these locate-then-edit methods are
uncontrollable since they tend to modify most unrelated relations connected to
the subject of target editing. We unveil that this failure of controllable
editing is due to a shortcut learning issue during the optimization process.
Specifically, we discover two crucial features that are the subject feature and
the relation feature for models to learn during optimization, but the current
optimization process tends to over-learning the subject feature while
neglecting the relation feature. To eliminate this shortcut learning of the
subject feature, we propose a novel two-stage optimization process that
balances the learning of the subject feature and the relation feature.
Experimental results demonstrate that our approach successfully prevents
knowledge editing from shortcut learning and achieves the optimal overall
performance, contributing to controllable knowledge editing.

</details>


### [198] [Think Like a Person Before Responding: A Multi-Faceted Evaluation of Persona-Guided LLMs for Countering Hate](https://arxiv.org/abs/2506.04043)
*Mikel K. Ngueajio,Flor Miriam Plaza-del-Arco,Yi-Ling Chung,Danda B. Rawat,Amanda Cercas Curry*

Main category: cs.CL

TL;DR: 论文提出了一种评估大型语言模型生成反叙事（CN）的框架，分析了其在情感、可读性和伦理风险方面的表现。


<details>
  <summary>Details</summary>
Motivation: 在线仇恨言论的自动反叙事（CN）虽有潜力，但其情感基调、可访问性和伦理风险仍需评估。

Method: 使用GPT-4o-Mini、Cohere的CommandR-7B和Meta的LLaMA 3.1-70B，在MT-Conan和HatEval数据集上评估三种提示策略。

Result: LLM生成的CN通常冗长且适合大学文化水平人群，情感引导提示能提高同理心和可读性，但安全性和有效性仍存疑。

Conclusion: 需进一步优化LLM生成的CN的可访问性和伦理安全性。

Abstract: Automated counter-narratives (CN) offer a promising strategy for mitigating
online hate speech, yet concerns about their affective tone, accessibility, and
ethical risks remain. We propose a framework for evaluating Large Language
Model (LLM)-generated CNs across four dimensions: persona framing, verbosity
and readability, affective tone, and ethical robustness. Using GPT-4o-Mini,
Cohere's CommandR-7B, and Meta's LLaMA 3.1-70B, we assess three prompting
strategies on the MT-Conan and HatEval datasets. Our findings reveal that
LLM-generated CNs are often verbose and adapted for people with college-level
literacy, limiting their accessibility. While emotionally guided prompts yield
more empathetic and readable responses, there remain concerns surrounding
safety and effectiveness.

</details>


### [199] [Lacuna Inc. at SemEval-2025 Task 4: LoRA-Enhanced Influence-Based Unlearning for LLMs](https://arxiv.org/abs/2506.04044)
*Aleksey Kudelya,Alexander Shirnin*

Main category: cs.CL

TL;DR: LIBU是一种结合LoRA和影响函数的轻量级算法，用于从大语言模型中移除特定知识，无需从头训练且保持模型整体性能。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型中移除敏感知识的需求，避免从头训练的昂贵成本。

Method: 结合影响函数移除数据影响，并通过二阶优化稳定模型性能。

Result: 实验表明LIBU适用于多种任务中的大语言模型知识移除。

Conclusion: LIBU是一种高效且轻量的解决方案，适用于大语言模型的知识移除任务。

Abstract: This paper describes LIBU (LoRA enhanced influence-based unlearning), an
algorithm to solve the task of unlearning - removing specific knowledge from a
large language model without retraining from scratch and compromising its
overall utility (SemEval-2025 Task 4: Unlearning sensitive content from Large
Language Models). The algorithm combines classical \textit{influence functions}
to remove the influence of the data from the model and \textit{second-order
optimization} to stabilize the overall utility. Our experiments show that this
lightweight approach is well applicable for unlearning LLMs in different kinds
of task.

</details>


### [200] [On Support Samples of Next Word Prediction](https://arxiv.org/abs/2506.04047)
*Yuqian Li,Yupei Du,Yufang Liu,Feifei Feng,Mou Xiao Feng,Yuanbin Wu*

Main category: cs.CL

TL;DR: 该论文研究了语言模型中的数据中心可解释性，通过支持样本分析揭示了数据对模型决策的影响。


<details>
  <summary>Details</summary>
Motivation: 理解语言模型决策背后的逻辑是一个挑战，本文旨在通过数据中心方法探索模型的可解释性。

Method: 利用表示定理识别支持样本（促进或抑制预测的样本），并分析其特性。

Result: 支持样本是固有特性，非支持样本在防止过拟合和形成中间表示中起关键作用。

Conclusion: 研究揭示了数据与模型决策的相互作用，为语言模型行为提供了新的理解维度。

Abstract: Language models excel in various tasks by making complex decisions, yet
understanding the rationale behind these decisions remains a challenge. This
paper investigates \emph{data-centric interpretability} in language models,
focusing on the next-word prediction task. Using representer theorem, we
identify two types of \emph{support samples}-those that either promote or deter
specific predictions. Our findings reveal that being a support sample is an
intrinsic property, predictable even before training begins. Additionally,
while non-support samples are less influential in direct predictions, they play
a critical role in preventing overfitting and shaping generalization and
representation learning. Notably, the importance of non-support samples
increases in deeper layers, suggesting their significant role in intermediate
representation formation.These insights shed light on the interplay between
data and model decisions, offering a new dimension to understanding language
model behavior and interpretability.

</details>


### [201] [Explainability-Based Token Replacement on LLM-Generated Text](https://arxiv.org/abs/2506.04050)
*Hadi Mohammadi,Anastasia Giachanou,Daniel L. Oberski,Ayoub Bagheri*

Main category: cs.CL

TL;DR: 论文研究了如何利用可解释AI方法降低AI生成文本的可检测性，并提出了基于集成分类器的检测方法。通过替换关键标记，显著降低了单一分类器的检测能力，但集成分类器仍能保持高性能。


<details>
  <summary>Details</summary>
Motivation: 生成模型（如大语言模型）的文本容易被检测，研究旨在通过可解释AI方法降低其可检测性，同时开发更鲁棒的检测策略。

Method: 训练集成分类器区分AI生成与人类文本，应用SHAP和LIME识别关键标记，提出四种基于可解释性的标记替换策略。

Result: 标记替换策略显著降低单一分类器的检测能力，但集成分类器在多语言和多领域表现稳健。

Conclusion: 可解释AI方法能有效降低AI文本的可检测性，但需依赖鲁棒的集成检测策略以应对不断演变的隐藏方法。

Abstract: Generative models, especially large language models (LLMs), have shown
remarkable progress in producing text that appears human-like. However, they
often exhibit patterns that make their output easier to detect than text
written by humans. In this paper, we investigate how explainable AI (XAI)
methods can be used to reduce the detectability of AI-generated text (AIGT)
while also introducing a robust ensemble-based detection approach. We begin by
training an ensemble classifier to distinguish AIGT from human-written text,
then apply SHAP and LIME to identify tokens that most strongly influence its
predictions. We propose four explainability-based token replacement strategies
to modify these influential tokens. Our findings show that these token
replacement approaches can significantly diminish a single classifier's ability
to detect AIGT. However, our ensemble classifier maintains strong performance
across multiple languages and domains, showing that a multi-model approach can
mitigate the impact of token-level manipulations. These results show that XAI
methods can make AIGT harder to detect by focusing on the most influential
tokens. At the same time, they highlight the need for robust, ensemble-based
detection strategies that can adapt to evolving approaches for hiding AIGT.

</details>


### [202] [High Accuracy, Less Talk (HALT): Reliable LLMs through Capability-Aligned Finetuning](https://arxiv.org/abs/2506.04051)
*Tim Franzmeyer,Archie Sravankumar,Lijuan Liu,Yuning Mao,Rui Hou,Sinong Wang,Jakob N. Foerster,Luke Zettlemoyer,Madian Khabsa*

Main category: cs.CL

TL;DR: 论文提出了一种名为HALT的方法，通过后训练让大语言模型（LLM）仅在对其答案正确性有信心时生成内容，否则部分或完全放弃回答。该方法通过生成能力对齐的数据，显著提高了回答的正确性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM会对所有提示生成回答，即使缺乏相关知识或能力，导致错误答案（幻觉问题）。HALT旨在解决这一问题，让模型在不确定时选择放弃回答。

Method: HALT将预训练LLM的回答拆分为事实片段，利用真实信息识别错误片段，并通过移除或替换为“Unsure from Here”来生成能力对齐的数据。通过可调阈值平衡回答完整性和正确性。

Result: 在四个开源模型上测试，HALT平均提高了15%的回答片段正确性，F1分数提升4%。最高正确性设置下，Llama3-70B的正确性从51%提升至87%。

Conclusion: HALT有效平衡了回答完整性和正确性，显著减少了LLM的幻觉问题，为实际应用提供了更可靠的模型。

Abstract: Large Language Models (LLMs) currently respond to every prompt. However, they
can produce incorrect answers when they lack knowledge or capability -- a
problem known as hallucination. We instead propose post-training an LLM to
generate content only when confident in its correctness and to otherwise
(partially) abstain. Specifically, our method, HALT, produces
capability-aligned post-training data that encodes what the model can and
cannot reliably generate. We generate this data by splitting responses of the
pretrained LLM into factual fragments (atomic statements or reasoning steps),
and use ground truth information to identify incorrect fragments. We achieve
capability-aligned finetuning responses by either removing incorrect fragments
or replacing them with "Unsure from Here" -- according to a tunable threshold
that allows practitioners to trade off response completeness and mean
correctness of the response's fragments. We finetune four open-source models
for biography writing, mathematics, coding, and medicine with HALT for three
different trade-off thresholds. HALT effectively trades off response
completeness for correctness, increasing the mean correctness of response
fragments by 15% on average, while resulting in a 4% improvement in the F1
score (mean of completeness and correctness of the response) compared to the
relevant baselines. By tuning HALT for highest correctness, we train a single
reliable Llama3-70B model with correctness increased from 51% to 87% across all
four domains while maintaining 53% of the response completeness achieved with
standard finetuning.

</details>


### [203] [Progressive Mastery: Customized Curriculum Learning with Guided Prompting for Mathematical Reasoning](https://arxiv.org/abs/2506.04065)
*Muling Wu,Qi Qian,Wenhao Liu,Xiaohua Wang,Zisu Huang,Di Liang,LI Miao,Shihan Dou,Changze Lv,Zhenghua Wang,Zhibo Xu,Lina Chen,Tianlong Li,Xiaoqing Zheng,Xuanjing Huang*

Main category: cs.CL

TL;DR: 提出了一种名为CCL的新框架，通过模型自适应难度定义和动态提示技术，显著提升了LLMs在数学推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs后训练中样本利用率低和难度样本处理不灵活的问题。

Method: 采用模型自适应难度定义和动态提示技术（Guided Prompting）来优化训练过程。

Result: 在五个数学推理基准测试中，CCL显著优于统一训练方法。

Conclusion: CCL有效提高了样本利用率和模型性能，适用于监督微调和强化学习。

Abstract: Large Language Models (LLMs) have achieved remarkable performance across
various reasoning tasks, yet post-training is constrained by inefficient sample
utilization and inflexible difficulty samples processing. To address these
limitations, we propose Customized Curriculum Learning (CCL), a novel framework
with two key innovations. First, we introduce model-adaptive difficulty
definition that customizes curriculum datasets based on each model's individual
capabilities rather than using predefined difficulty metrics. Second, we
develop "Guided Prompting," which dynamically reduces sample difficulty through
strategic hints, enabling effective utilization of challenging samples that
would otherwise degrade performance. Comprehensive experiments on supervised
fine-tuning and reinforcement learning demonstrate that CCL significantly
outperforms uniform training approaches across five mathematical reasoning
benchmarks, confirming its effectiveness across both paradigms in enhancing
sample utilization and model performance.

</details>


### [204] [LaF-GRPO: In-Situ Navigation Instruction Generation for the Visually Impaired via GRPO with LLM-as-Follower Reward](https://arxiv.org/abs/2506.04070)
*Yi Zhao,Siqi Wang,Jing Li*

Main category: cs.CL

TL;DR: 该论文提出了一种名为LaF-GRPO的方法，利用LLM模拟视障用户响应，生成奖励以指导VLM后训练，从而提升导航指令的实用性并减少真实数据需求。同时，论文还发布了NIG4VI基准数据集，实验证明该方法在生成更直观、安全的指令方面优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 为视障人士生成精确、实用的导航指令是一个重要但研究较少的领域。当前方法在真实数据需求和指令实用性方面存在不足。

Method: 提出LaF-GRPO方法，利用LLM模拟视障用户响应生成奖励，指导VLM后训练。同时，发布NIG4VI基准数据集，包含27k样本，支持详细、开放的导航指令生成。

Result: 实验表明，LaF-GRPO在定量指标（如BLEU提升14%）和生成更直观、安全的指令方面优于基线模型（如GPT-4o）。

Conclusion: LaF-GRPO方法有效提升了导航指令的实用性，同时减少了真实数据需求，为视障人士提供了更好的导航支持。

Abstract: Navigation instruction generation for visually impaired (VI) individuals
(NIG-VI) is critical yet relatively underexplored. This study, hence, focuses
on producing precise, in-situ, step-by-step navigation instructions that are
practically usable by VI users. Concretely, we propose LaF-GRPO
(LLM-as-Follower GRPO), where an LLM simulates VI user responses to generate
rewards guiding the Vision-Language Model (VLM) post-training. This enhances
instruction usability while reducing costly real-world data needs. To
facilitate training and testing, we introduce NIG4VI, a 27k-sample open-sourced
benchmark. It provides diverse navigation scenarios with accurate spatial
coordinates, supporting detailed, open-ended in-situ instruction generation.
Experiments on NIG4VI show the effectiveness of LaF-GRPO by quantitative
metrics (e.g., Zero-(LaF-GRPO) boosts BLEU +14\%; SFT+(LaF-GRPO) METEOR 0.542
vs. GPT-4o's 0.323) and yields more intuitive, safer instructions. Code and
benchmark are available at
\href{https://github.com/YiyiyiZhao/NIG4VI}{https://github.com/YiyiyiZhao/NIG4VI}.

</details>


### [205] [Controlling Difficulty of Generated Text for AI-Assisted Language Learning](https://arxiv.org/abs/2506.04072)
*Meiqing Jin,Liam Dugan,Chris Callison-Burch*

Main category: cs.CL

TL;DR: 研究探讨了如何通过可控生成技术调整大型语言模型（LLM）的输出，以更好地支持初学者语言学习。


<details>
  <summary>Details</summary>
Motivation: 传统LLM生成的文本复杂度高，不适合初学者（CEFR: A1-A2），需要找到无需微调的方法来降低输出难度。

Method: 采用模块化可控生成技术（如未来判别器）调整LLM输出，并通过自动指标和用户研究（日语学习者）评估效果。

Result: 未来判别器显著提升了输出可理解性（从40.4%到84.3%），并提出了新的评估指标Token Miss Rate（TMR）。

Conclusion: 可控生成技术能有效支持初学者语言学习，未来研究可通过发布的代码、模型和数据进一步探索。

Abstract: Practicing conversations with large language models (LLMs) presents a
promising alternative to traditional in-person language learning. However, most
LLMs generate text at a near-native level of complexity, making them ill-suited
for beginner learners (CEFR: A1-A2). In this paper, we investigate whether
controllable generation techniques -- specifically modular methods that do not
require model fine-tuning -- can adapt LLM outputs to better support absolute
beginners. We evaluate these methods through both automatic metrics and a user
study with university-level learners of Japanese. Our findings show that while
prompting alone fails to control output difficulty, the use of future
discriminators (Yang and Klein, 2021) significantly improves output
comprehensibility (from 40.4\% to 84.3\%). We further introduce a novel
token-level evaluation metric, Token Miss Rate (TMR), that quantifies the
proportion of incomprehensible tokens per utterance and correlates strongly
with human judgments. To support future research in AI-assisted language
learning, we release our code, models, annotation tools, and dataset.

</details>


### [206] [Acoustically Precise Hesitation Tagging Is Essential for End-to-End Verbatim Transcription Systems](https://arxiv.org/abs/2506.04076)
*Jhen-Ke Lin,Hao-Chien Lu,Chung-Chun Wang,Hong-Yun Lin,Berlin Chen*

Main category: cs.CL

TL;DR: 通过LoRA微调Whisper模型，使用三种标注方案（Pure、Rich、Extra）提升ASR对非流利L2语音的转录准确性，其中Extra方案显著降低WER。


<details>
  <summary>Details</summary>
Motivation: 现有ASR系统常忽略或泛化非流利现象（如犹豫），导致重要声学细节丢失，影响自动口语评估的准确性。

Method: 使用低秩适应（LoRA）微调Whisper模型，基于Speak & Improve 2025语料库，比较三种标注方案：Pure（去除犹豫）、Rich（通用标签）、Extra（精确填充词）。

Result: Extra方案在挑战系统中WER为5.81%，后续实验进一步降至5.5%，比Pure方案（6.2%）提升11.3%。

Conclusion: 精确标注非流利现象（如填充词）显著提升ASR对L2语音的转录准确性。

Abstract: Verbatim transcription for automatic speaking assessment demands accurate
capture of disfluencies, crucial for downstream tasks like error analysis and
feedback. However, many ASR systems discard or generalize hesitations, losing
important acoustic details. We fine-tune Whisper models on the Speak & Improve
2025 corpus using low-rank adaptation (LoRA), without recourse to external
audio training data. We compare three annotation schemes: removing hesitations
(Pure), generic tags (Rich), and acoustically precise fillers inferred by
Gemini 2.0 Flash from existing audio-transcript pairs (Extra). Our challenge
system achieved 6.47% WER (Pure) and 5.81% WER (Extra). Post-challenge
experiments reveal that fine-tuning Whisper Large V3 Turbo with the "Extra"
scheme yielded a 5.5% WER, an 11.3% relative improvement over the "Pure" scheme
(6.2% WER). This demonstrates that explicit, realistic filled-pause labeling
significantly enhances ASR accuracy for verbatim L2 speech transcription.

</details>


### [207] [A Novel Data Augmentation Approach for Automatic Speaking Assessment on Opinion Expressions](https://arxiv.org/abs/2506.04077)
*Chung-Chun Wang,Jhen-Ke Lin,Hao-Chien Lu,Hong-Yun Lin,Berlin Chen*

Main category: cs.CL

TL;DR: 提出了一种利用大语言模型生成多样化语音响应，结合动态重要性损失和多模态大语言模型的方法，以解决自动口语评估中数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 自动口语评估中标记数据的稀缺性限制了提示多样性并影响评分可靠性，需要一种新方法来解决这一问题。

Method: 利用大语言模型生成多样化响应，通过语音合成转换为语音，使用动态重要性损失调整训练权重，并整合多模态特征预测评分。

Result: 在LTTC数据集上，该方法优于依赖真实数据或传统增强的方法，有效缓解了低资源限制。

Conclusion: 该方法通过跨模态信息实现了对意见表达的自动口语评估，解决了数据稀缺问题。

Abstract: Automated speaking assessment (ASA) on opinion expressions is often hampered
by the scarcity of labeled recordings, which restricts prompt diversity and
undermines scoring reliability. To address this challenge, we propose a novel
training paradigm that leverages a large language models (LLM) to generate
diverse responses of a given proficiency level, converts responses into
synthesized speech via speaker-aware text-to-speech synthesis, and employs a
dynamic importance loss to adaptively reweight training instances based on
feature distribution differences between synthesized and real speech.
Subsequently, a multimodal large language model integrates aligned textual
features with speech signals to predict proficiency scores directly.
Experiments conducted on the LTTC dataset show that our approach outperforms
methods relying on real data or conventional augmentation, effectively
mitigating low-resource constraints and enabling ASA on opinion expressions
with cross-modal information.

</details>


### [208] [LLMEval-Med: A Real-world Clinical Benchmark for Medical LLMs with Physician Validation](https://arxiv.org/abs/2506.04078)
*Ming Zhang,Yujiong Shen,Zelin Li,Huayu Sha,Binze Hu,Yuhui Wang,Chenhao Huang,Shichun Liu,Jingqi Tong,Changhao Jiang,Mingxu Chai,Zhiheng Xi,Shihan Dou,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: LLMEval-Med是一个新的医学基准测试，覆盖五个核心医学领域，包含2,996个问题，基于真实电子健康记录和专家设计的临床场景。通过自动化评估流程和专家反馈动态优化，评估了13种大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 当前医学基准测试存在设计、数据来源和评估方法的局限性，无法满足医学应用对高准确率的需求。

Method: 开发了LLMEval-Med基准测试，结合真实临床数据和专家设计的场景，并设计自动化评估流程，通过专家反馈动态优化。

Result: 评估了13种大型语言模型，提供了医学领域安全有效部署LLM的见解。

Conclusion: LLMEval-Med为医学领域的大型语言模型评估提供了更可靠的基准，数据集已开源。

Abstract: Evaluating large language models (LLMs) in medicine is crucial because
medical applications require high accuracy with little room for error. Current
medical benchmarks have three main types: medical exam-based, comprehensive
medical, and specialized assessments. However, these benchmarks have
limitations in question design (mostly multiple-choice), data sources (often
not derived from real clinical scenarios), and evaluation methods (poor
assessment of complex reasoning). To address these issues, we present
LLMEval-Med, a new benchmark covering five core medical areas, including 2,996
questions created from real-world electronic health records and expert-designed
clinical scenarios. We also design an automated evaluation pipeline,
incorporating expert-developed checklists into our LLM-as-Judge framework.
Furthermore, our methodology validates machine scoring through human-machine
agreement analysis, dynamically refining checklists and prompts based on expert
feedback to ensure reliability. We evaluate 13 LLMs across three categories
(specialized medical models, open-source models, and closed-source models) on
LLMEval-Med, providing valuable insights for the safe and effective deployment
of LLMs in medical domains. The dataset is released in
https://github.com/llmeval/LLMEval-Med.

</details>


### [209] [EuroLLM-9B: Technical Report](https://arxiv.org/abs/2506.04079)
*Pedro Henrique Martins,João Alves,Patrick Fernandes,Nuno M. Guerreiro,Ricardo Rei,Amin Farajian,Mateusz Klimaszewski,Duarte M. Alves,José Pombal,Manuel Faysse,Pierre Colombo,François Yvon,Barry Haddow,José G. C. de Souza,Alexandra Birch,André F. T. Martins*

Main category: cs.CL

TL;DR: EuroLLM-9B是一个为欧洲语言设计的大型语言模型，覆盖24种欧盟官方语言和11种其他语言，旨在解决现有开放模型中欧洲语言代表性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 解决欧洲语言在现有开放大型语言模型中代表性不足的问题，满足欧洲公民的多语言需求。

Method: 开发EuroLLM-9B，包括分词器设计、架构规范、数据过滤和训练流程，并创建EuroFilter和EuroBlocks-Synthetic数据集以增强语言覆盖。

Result: EuroLLM-9B在多语言基准测试和机器翻译任务中表现优异，成为同类规模中领先的欧洲开源LLM。

Conclusion: EuroLLM-9B填补了欧洲语言在开放LLM中的空白，并开源了模型、工具和数据集以促进研究和采用。

Abstract: This report presents EuroLLM-9B, a large language model trained from scratch
to support the needs of European citizens by covering all 24 official European
Union languages and 11 additional languages. EuroLLM addresses the issue of
European languages being underrepresented and underserved in existing open
large language models. We provide a comprehensive overview of EuroLLM-9B's
development, including tokenizer design, architectural specifications, data
filtering, and training procedures. We describe the pre-training data
collection and filtering pipeline, including the creation of EuroFilter, an
AI-based multilingual filter, as well as the design of EuroBlocks-Synthetic, a
novel synthetic dataset for post-training that enhances language coverage for
European languages. Evaluation results demonstrate EuroLLM-9B's competitive
performance on multilingual benchmarks and machine translation tasks,
establishing it as the leading open European-made LLM of its size. To support
open research and adoption, we release all major components of this work,
including the base and instruction-tuned models, the EuroFilter classifier, and
the synthetic post-training dataset.

</details>


### [210] [TextAtari: 100K Frames Game Playing with Language Agents](https://arxiv.org/abs/2506.04098)
*Wenhao Li,Wenwu Li,Chuyun Shen,Junjie Sheng,Zixiao Huang,Di Wu,Yun Hua,Wei Yin,Xiangfeng Wang,Hongyuan Zha,Bo Jin*

Main category: cs.CL

TL;DR: TextAtari是一个评估语言代理在长时程决策任务（长达100,000步）上的基准测试，通过将Atari游戏的视觉状态转换为文本描述，创建了一个结合序列决策与自然语言处理的挑战性测试平台。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索语言代理在长时程任务中的表现，并评估不同先验知识对其性能的影响，以推动语言模型与规划研究的结合。

Method: 通过AtariARI框架将Atari游戏状态转换为文本描述，构建包含100个任务的测试集。评估了三种大型语言模型（Qwen2.5-7B、Gemma-7B、Llama3.1-8B）在三种代理框架（零样本、少样本思维链、反思推理）上的表现。

Result: 结果显示语言代理与人类玩家在长时程规划任务中存在显著性能差距，尤其在序列推理、状态跟踪和战略规划方面。

Conclusion: TextAtari为语言模型与规划研究提供了标准化评估协议和基准实现，揭示了当前语言代理在复杂任务中的局限性。

Abstract: We present TextAtari, a benchmark for evaluating language agents on very
long-horizon decision-making tasks spanning up to 100,000 steps. By translating
the visual state representations of classic Atari games into rich textual
descriptions, TextAtari creates a challenging test bed that bridges sequential
decision-making with natural language processing. The benchmark includes nearly
100 distinct tasks with varying complexity, action spaces, and planning
horizons, all rendered as text through an unsupervised representation learning
framework (AtariARI). We evaluate three open-source large language models
(Qwen2.5-7B, Gemma-7B, and Llama3.1-8B) across three agent frameworks
(zero-shot, few-shot chain-of-thought, and reflection reasoning) to assess how
different forms of prior knowledge affect performance on these long-horizon
challenges. Four scenarios-Basic, Obscured, Manual Augmentation, and
Reference-based-investigate the impact of semantic understanding, instruction
comprehension, and expert demonstrations on agent decision-making. Our results
reveal significant performance gaps between language agents and human players
in extensive planning tasks, highlighting challenges in sequential reasoning,
state tracking, and strategic planning across tens of thousands of steps.
TextAtari provides standardized evaluation protocols, baseline implementations,
and a framework for advancing research at the intersection of language models
and planning.

</details>


### [211] [Rectified Sparse Attention](https://arxiv.org/abs/2506.04108)
*Yutao Sun,Tianzhu Ye,Li Dong,Yuqing Xia,Jian Chen,Yizhao Gao,Shijie Cao,Jianyong Wang,Furu Wei*

Main category: cs.CL

TL;DR: ReSA提出了一种结合块稀疏注意力和周期性密集校正的方法，显著提升了长序列生成的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏解码方法中KV缓存对齐问题导致的误差累积和生成质量下降。

Method: 结合块稀疏注意力和周期性密集校正，定期刷新KV缓存以减少误差累积。

Result: 在数学推理、语言建模和检索任务中，ReSA实现了接近无损的生成质量和2.42倍的端到端加速。

Conclusion: ReSA是一种高效且实用的长上下文推理解决方案。

Abstract: Efficient long-sequence generation is a critical challenge for Large Language
Models. While recent sparse decoding methods improve efficiency, they suffer
from KV cache misalignment, where approximation errors accumulate and degrade
generation quality. In this work, we propose Rectified Sparse Attention (ReSA),
a simple yet effective method that combines block-sparse attention with
periodic dense rectification. By refreshing the KV cache at fixed intervals
using a dense forward pass, ReSA bounds error accumulation and preserves
alignment with the pretraining distribution. Experiments across math reasoning,
language modeling, and retrieval tasks demonstrate that ReSA achieves
near-lossless generation quality with significantly improved efficiency.
Notably, ReSA delivers up to 2.42$\times$ end-to-end speedup under decoding at
256K sequence length, making it a practical solution for scalable long-context
inference. Code is available at https://aka.ms/ReSA-LM.

</details>


### [212] [CLAIM: An Intent-Driven Multi-Agent Framework for Analyzing Manipulation in Courtroom Dialogues](https://arxiv.org/abs/2506.04131)
*Disha Sheshanarayana,Tanishka Magar,Ayushi Mittal,Neelam Chaplot*

Main category: cs.CL

TL;DR: 论文提出LegalCon数据集和CLAIM框架，用于检测和分析法律领域中的操纵行为，旨在提升司法过程的公平性和透明度。


<details>
  <summary>Details</summary>
Motivation: 法庭操纵行为可能影响判决，但NLP在此领域的应用尚未充分探索。

Method: 引入LegalCon数据集（1,063条标注对话）和CLAIM框架（两阶段、意图驱动的多智能体框架）。

Result: CLAIM框架能有效分析操纵行为，提升司法公平性和透明度。

Conclusion: 该研究为法律话语分析提供了新工具，支持公平决策。

Abstract: Courtrooms are places where lives are determined and fates are sealed, yet
they are not impervious to manipulation. Strategic use of manipulation in legal
jargon can sway the opinions of judges and affect the decisions. Despite the
growing advancements in NLP, its application in detecting and analyzing
manipulation within the legal domain remains largely unexplored. Our work
addresses this gap by introducing LegalCon, a dataset of 1,063 annotated
courtroom conversations labeled for manipulation detection, identification of
primary manipulators, and classification of manipulative techniques, with a
focus on long conversations. Furthermore, we propose CLAIM, a two-stage,
Intent-driven Multi-agent framework designed to enhance manipulation analysis
by enabling context-aware and informed decision-making. Our results highlight
the potential of incorporating agentic frameworks to improve fairness and
transparency in judicial processes. We hope that this contributes to the
broader application of NLP in legal discourse analysis and the development of
robust tools to support fairness in legal decision-making. Our code and data
are available at https://github.com/Disha1001/CLAIM.

</details>


### [213] [Are Lexicon-Based Tools Still the Gold Standard for Valence Analysis in Low-Resource Flemish?](https://arxiv.org/abs/2506.04139)
*Ratna Kandala,Katie Hoemann*

Main category: cs.CL

TL;DR: 该研究探讨了大型语言模型（LLMs）在捕捉弗拉芒语日常叙述情感效价方面的表现，发现现有荷兰语LLMs在准确性上不及传统工具（如LIWC和Pattern），并呼吁开发针对低资源语言的定制模型。


<details>
  <summary>Details</summary>
Motivation: 日常语言具有自发性、丰富表达性和高度语境依赖性，传统工具（如LIWC和Pattern）在捕捉情感效价方面存在局限，因此需要探索LLMs的潜力。

Method: 研究收集了102名荷兰语参与者的约25,000条文本叙述，并评估了三种荷兰语LLMs在预测情感效价（-50至+50）上的表现，与传统工具进行对比。

Result: 荷兰语LLMs在捕捉自发叙述的情感效价上表现不佳，准确性低于传统工具。

Conclusion: 研究强调需要开发针对文化和语言定制的模型，以提升自然语言处理的复杂性，并呼吁为低资源语言（如弗拉芒语）构建更全面的数据集和优化LLMs。

Abstract: Understanding the nuances in everyday language is pivotal for advancements in
computational linguistics & emotions research. Traditional lexicon-based tools
such as LIWC and Pattern have long served as foundational instruments in this
domain. LIWC is the most extensively validated word count based text analysis
tool in the social sciences and Pattern is an open source Python library
offering functionalities for NLP. However, everyday language is inherently
spontaneous, richly expressive, & deeply context dependent. To explore the
capabilities of LLMs in capturing the valences of daily narratives in Flemish,
we first conducted a study involving approximately 25,000 textual responses
from 102 Dutch-speaking participants. Each participant provided narratives
prompted by the question, "What is happening right now and how do you feel
about it?", accompanied by self-assessed valence ratings on a continuous scale
from -50 to +50. We then assessed the performance of three Dutch-specific LLMs
in predicting these valence scores, and compared their outputs to those
generated by LIWC and Pattern. Our findings indicate that, despite advancements
in LLM architectures, these Dutch tuned models currently fall short in
accurately capturing the emotional valence present in spontaneous, real-world
narratives. This study underscores the imperative for developing culturally and
linguistically tailored models/tools that can adeptly handle the complexities
of natural language use. Enhancing automated valence analysis is not only
pivotal for advancing computational methodologies but also holds significant
promise for psychological research with ecologically valid insights into human
daily experiences. We advocate for increased efforts in creating comprehensive
datasets & finetuning LLMs for low-resource languages like Flemish, aiming to
bridge the gap between computational linguistics & emotion research.

</details>


### [214] [Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis](https://arxiv.org/abs/2506.04142)
*Kejian Zhu,Shangqing Tu,Zhuoran Jin,Lei Hou,Juanzi Li,Jun Zhao*

Main category: cs.CL

TL;DR: 该论文提出了一种通过分析污染模型机制来识别和抑制捷径神经元的方法，以解决大型语言模型评估中的数据污染问题。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型的评估依赖于公共基准，但数据污染问题严重影响了公平性。动态基准构建成本高且循环往复，因此需要一种更高效的方法。

Method: 通过比较和因果分析识别捷径神经元，并提出捷径神经元修补方法以抑制其影响。

Result: 实验验证了方法的有效性，与MixEval基准的Spearman系数超过0.95，表明方法可信且能揭示模型的真实能力。

Conclusion: 该方法在多种基准和超参数设置下具有普适性，为大型语言模型的评估提供了更可靠的解决方案。

Abstract: The development of large language models (LLMs) depends on trustworthy
evaluation. However, most current evaluations rely on public benchmarks, which
are prone to data contamination issues that significantly compromise fairness.
Previous researches have focused on constructing dynamic benchmarks to address
contamination. However, continuously building new benchmarks is costly and
cyclical. In this work, we aim to tackle contamination by analyzing the
mechanisms of contaminated models themselves. Through our experiments, we
discover that the overestimation of contaminated models is likely due to
parameters acquiring shortcut solutions in training. We further propose a novel
method for identifying shortcut neurons through comparative and causal
analysis. Building on this, we introduce an evaluation method called shortcut
neuron patching to suppress shortcut neurons. Experiments validate the
effectiveness of our approach in mitigating contamination. Additionally, our
evaluation results exhibit a strong linear correlation with MixEval, a recently
released trustworthy benchmark, achieving a Spearman coefficient ($\rho$)
exceeding 0.95. This high correlation indicates that our method closely reveals
true capabilities of the models and is trustworthy. We conduct further
experiments to demonstrate the generalizability of our method across various
benchmarks and hyperparameter settings. Code:
https://github.com/GaryStack/Trustworthy-Evaluation

</details>


### [215] [A Dataset for Addressing Patient's Information Needs related to Clinical Course of Hospitalization](https://arxiv.org/abs/2506.04156)
*Sarvesh Soni,Dina Demner-Fushman*

Main category: cs.CL

TL;DR: ArchEHR-QA是一个专家标注的数据集，用于评估AI在电子健康记录（EHR）中回答患者问题的准确性和相关性，并提供了基准测试结果。


<details>
  <summary>Details</summary>
Motivation: 患者对住院信息有独特需求，但缺乏基于EHR的AI系统评估数据集。

Method: 基于真实ICU和急诊病例，构建包含患者问题、临床笔记和医生答案的数据集，并测试三种大型语言模型（LLMs）的提示策略。

Result: Llama 4在“答案优先”提示策略中表现最佳，但仍存在遗漏关键证据或生成矛盾内容的问题。

Conclusion: ArchEHR-QA为开发患者为中心的EHR问答系统提供了基准，但需进一步改进生成内容的准确性和相关性。

Abstract: Patients have distinct information needs about their hospitalization that can
be addressed using clinical evidence from electronic health records (EHRs).
While artificial intelligence (AI) systems show promise in meeting these needs,
robust datasets are needed to evaluate the factual accuracy and relevance of
AI-generated responses. To our knowledge, no existing dataset captures patient
information needs in the context of their EHRs. We introduce ArchEHR-QA, an
expert-annotated dataset based on real-world patient cases from intensive care
unit and emergency department settings. The cases comprise questions posed by
patients to public health forums, clinician-interpreted counterparts, relevant
clinical note excerpts with sentence-level relevance annotations, and
clinician-authored answers. To establish benchmarks for grounded EHR question
answering (QA), we evaluated three open-weight large language models
(LLMs)--Llama 4, Llama 3, and Mixtral--across three prompting strategies:
generating (1) answers with citations to clinical note sentences, (2) answers
before citations, and (3) answers from filtered citations. We assessed
performance on two dimensions: Factuality (overlap between cited note sentences
and ground truth) and Relevance (textual and semantic similarity between system
and reference answers). The final dataset contains 134 patient cases. The
answer-first prompting approach consistently performed best, with Llama 4
achieving the highest scores. Manual error analysis supported these findings
and revealed common issues such as omitted key clinical evidence and
contradictory or hallucinated content. Overall, ArchEHR-QA provides a strong
benchmark for developing and evaluating patient-centered EHR QA systems,
underscoring the need for further progress toward generating factual and
relevant responses in clinical contexts.

</details>


### [216] [SkipGPT: Dynamic Layer Pruning Reinvented with Token Awareness and Module Decoupling](https://arxiv.org/abs/2506.04179)
*Anhao Zhao,Fanghua Ye,Yingqi Fan,Junlong Tong,Zhiwei Fei,Hui Su,Xiaoyu Shen*

Main category: cs.CL

TL;DR: SkipGPT是一种动态层剪枝框架，通过全局令牌感知路由和分离的MLP与自注意力剪枝策略，显著降低计算成本，同时保持或提升性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）计算成本高，静态剪枝方法忽略了令牌级异质性和不同层功能角色的动态需求。

Method: SkipGPT采用全局令牌感知路由和分离的MLP与自注意力剪枝策略，并通过两阶段优化（解耦训练和LoRA微调）解决训练不稳定性。

Result: 实验显示SkipGPT减少40%以上模型参数，性能与原密集模型相当或更优。

Conclusion: SkipGPT通过动态效率与表达性平衡，推动了资源感知LLMs的实际部署。

Abstract: Large language models (LLMs) achieve remarkable performance across tasks but
incur substantial computational costs due to their deep, multi-layered
architectures. Layer pruning has emerged as a strategy to alleviate these
inefficiencies, but conventional static pruning methods overlook two critical
dynamics inherent to LLM inference: (1) horizontal dynamics, where token-level
heterogeneity demands context-aware pruning decisions, and (2) vertical
dynamics, where the distinct functional roles of MLP and self-attention layers
necessitate component-specific pruning policies. We introduce SkipGPT, a
dynamic layer pruning framework designed to optimize computational resource
allocation through two core innovations: (1) global token-aware routing to
prioritize critical tokens, and (2) decoupled pruning policies for MLP and
self-attention components. To mitigate training instability, we propose a
two-stage optimization paradigm: first, a disentangled training phase that
learns routing strategies via soft parameterization to avoid premature pruning
decisions, followed by parameter-efficient LoRA fine-tuning to restore
performance impacted by layer removal. Extensive experiments demonstrate that
SkipGPT reduces over 40% of model parameters while matching or exceeding the
performance of the original dense model across benchmarks. By harmonizing
dynamic efficiency with preserved expressivity, SkipGPT advances the practical
deployment of scalable, resource-aware LLMs. Our code is publicly available at:
https://github.com/EIT-NLP/SkipGPT.

</details>


### [217] [SuperWriter: Reflection-Driven Long-Form Generation with Large Language Models](https://arxiv.org/abs/2506.04180)
*Yuhao Wu,Yushi Bai,Zhiqiang Hu,Juanzi Li,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: SuperWriter-Agent是一个基于代理的框架，通过结构化思维和优化步骤提升长文本生成的质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在生成长文本时面临的连贯性、逻辑一致性和质量保持问题。

Method: 提出SuperWriter-Agent框架，结合结构化思维、监督微调数据集和分层直接偏好优化（DPO）方法。

Result: SuperWriter-LM在多个基准测试中表现优异，超越更大规模的基线模型。

Conclusion: 结构化思维步骤和分层DPO显著提升了长文本生成的质量。

Abstract: Long-form text generation remains a significant challenge for large language
models (LLMs), particularly in maintaining coherence, ensuring logical
consistency, and preserving text quality as sequence length increases. To
address these limitations, we propose SuperWriter-Agent, an agent-based
framework designed to enhance the quality and consistency of long-form text
generation. SuperWriter-Agent introduces explicit structured thinking-through
planning and refinement stages into the generation pipeline, guiding the model
to follow a more deliberate and cognitively grounded process akin to that of a
professional writer. Based on this framework, we construct a supervised
fine-tuning dataset to train a 7B SuperWriter-LM. We further develop a
hierarchical Direct Preference Optimization (DPO) procedure that uses Monte
Carlo Tree Search (MCTS) to propagate final quality assessments and optimize
each generation step accordingly. Empirical results across diverse benchmarks
demonstrate that SuperWriter-LM achieves state-of-the-art performance,
surpassing even larger-scale baseline models in both automatic evaluation and
human evaluation. Furthermore, comprehensive ablation studies demonstrate the
effectiveness of hierarchical DPO and underscore the value of incorporating
structured thinking steps to improve the quality of long-form text generation.

</details>


### [218] [Long or short CoT? Investigating Instance-level Switch of Large Reasoning Models](https://arxiv.org/abs/2506.04182)
*Ruiqi Zhang,Changyi Xiao,Yixin Cao*

Main category: cs.CL

TL;DR: 论文分析了长链思维（CoT）提示与短链思维提示的性能与资源消耗，提出了一种动态选择策略的框架SwitchCoT，以平衡准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 长链思维提示虽然能提升性能，但资源消耗显著增加，需在性能与效率之间找到平衡。

Method: 通过实证分析比较长短CoT策略，提出SwitchCoT框架，动态选择策略以适应不同资源限制。

Result: SwitchCoT能减少50%推理成本，同时在有限预算下性能优于单一策略。

Conclusion: 动态选择CoT策略能有效平衡性能与效率，SwitchCoT为资源受限场景提供了实用解决方案。

Abstract: With the rapid advancement of large reasoning models, long Chain-of-Thought
(CoT) prompting has demonstrated strong performance on complex tasks. However,
this often comes with a significant increase in token usage. In this paper, we
conduct a comprehensive empirical analysis comparing long and short CoT
strategies. Our findings reveal that while long CoT can lead to performance
improvements, its benefits are often marginal relative to its significantly
higher token consumption. Specifically, long CoT tends to outperform when ample
generation budgets are available, whereas short CoT is more effective under
tighter budget constraints. These insights underscore the need for a dynamic
approach that selects the proper CoT strategy based on task context and
resource availability. To address this, we propose SwitchCoT, an automatic
framework that adaptively chooses between long and short CoT strategies to
balance reasoning accuracy and computational efficiency. Moreover, SwitchCoT is
designed to be budget-aware, making it broadly applicable across scenarios with
varying resource constraints. Experimental results demonstrate that SwitchCoT
can reduce inference costs by up to 50% while maintaining high accuracy.
Notably, under limited token budgets, it achieves performance comparable to, or
even exceeding, that of using either long or short CoT alone.

</details>


### [219] [R-Search: Empowering LLM Reasoning with Search via Multi-Reward Reinforcement Learning](https://arxiv.org/abs/2506.04185)
*Qingfei Zhao,Ruobing Wang,Dingling Xu,Daren Zha,Limin Liu*

Main category: cs.CL

TL;DR: R-Search是一种强化学习框架，旨在优化大型语言模型（LLM）在复杂任务中的推理与搜索交互，提升响应质量。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在多步推理和搜索交互中表现不佳，难以找到最优的推理-搜索交互轨迹。

Method: 提出R-Search框架，通过多奖励信号训练LLM动态决定何时检索或推理，并全局整合关键证据。

Result: 在七个数据集上，R-Search优于先进RAG基线，最高提升32.2%（领域内）和25.1%（领域外）。

Conclusion: R-Search显著提升了LLM在复杂逻辑和知识密集型任务中的表现。

Abstract: Large language models (LLMs) have notably progressed in multi-step and
long-chain reasoning. However, extending their reasoning capabilities to
encompass deep interactions with search remains a non-trivial challenge, as
models often fail to identify optimal reasoning-search interaction
trajectories, resulting in suboptimal responses. We propose R-Search, a novel
reinforcement learning framework for Reasoning-Search integration, designed to
enable LLMs to autonomously execute multi-step reasoning with deep search
interaction, and learn optimal reasoning search interaction trajectories via
multi-reward signals, improving response quality in complex logic- and
knowledge-intensive tasks. R-Search guides the LLM to dynamically decide when
to retrieve or reason, while globally integrating key evidence to enhance deep
knowledge interaction between reasoning and search. During RL training,
R-Search provides multi-stage, multi-type rewards to jointly optimize the
reasoning-search trajectory. Experiments on seven datasets show that R-Search
outperforms advanced RAG baselines by up to 32.2% (in-domain) and 25.1%
(out-of-domain). The code and data are available at
https://github.com/QingFei1/R-Search.

</details>


### [220] [Efficient Knowledge Editing via Minimal Precomputation](https://arxiv.org/abs/2506.04226)
*Akshat Gupta,Maochuan Lu,Thomas Hartvigsen,Gopala Anumanchipalli*

Main category: cs.CL

TL;DR: 论文提出了一种减少知识编辑方法（如MEMIT）预计算步骤中隐藏向量数量的方法，显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法（如MEMIT）需要预计算大量隐藏向量，导致高昂的计算成本和时间消耗，限制了实际应用。

Method: 通过理论分析和实证研究，确定并验证了预计算隐藏向量的最小数量需求。

Result: 实验表明，仅需预计算原隐藏向量数量的0.3%，即可实现知识编辑，大幅节省时间和计算资源。

Conclusion: 该方法显著降低了知识编辑的预计算成本，使新模型的编辑能够在几分钟内开始。

Abstract: Knowledge editing methods like MEMIT are able to make data and compute
efficient updates of factual knowledge by using a single sentence to update
facts and their consequences. However, what is often overlooked is a
"precomputation step", which requires a one-time but significant computational
cost. The authors of MEMIT originally precompute approximately 44 million
hidden vectors per edited layer, which requires a forward pass over 44 million
tokens. For GPT-J (6B), this precomputation step takes 36 hours on a single
GPU, while it takes approximately 40 hours for Llama2-7B. Additionally, this
precomputation time grows with model size. In this paper, we show that this
excessive computational cost is unnecessary. Knowledge editing using MEMIT and
related methods, such as ROME and EMMET, can be performed by pre-computing a
very small portion of the 44 million hidden vectors. We first present the
theoretical minimum number of hidden vector precomputation required for
solutions of these editing methods to exist. We then empirically show that
knowledge editing using these methods can be done by pre-computing
significantly fewer hidden vectors. Specifically, we show that the
precomputation step can be done with less than 0.3% of the originally
stipulated number of hidden vectors. This saves a significant amount of
precomputation time and allows users to begin editing new models within a few
minutes.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [221] [Dual Branch VideoMamba with Gated Class Token Fusion for Violence Detection](https://arxiv.org/abs/2506.03162)
*Damith Chamalke Senadeera,Xiaoyun Yang,Dimitrios Kollias,Gregory Slabaugh*

Main category: cs.CV

TL;DR: 提出了一种结合双分支设计和状态空间模型（SSM）的高效架构Dual Branch VideoMamba with Gated Class Token Fusion（GCTF），用于暴力检测，并在新基准上实现了最优性能。


<details>
  <summary>Details</summary>
Motivation: 随着监控摄像头的快速普及，对自动化暴力检测的需求增加。现有方法如CNN和Transformer在时空特征提取上表现良好，但在长期依赖和计算效率方面存在不足。

Method: 采用双分支设计，一支捕捉空间特征，另一支关注时间动态，通过门控机制持续融合。使用状态空间模型（SSM）作为主干，并结合新构建的暴力检测数据集基准。

Result: 模型在新基准上实现了最优性能，平衡了准确性和计算效率。

Conclusion: 该研究表明状态空间模型在可扩展、实时监控暴力检测中具有潜力。

Abstract: The rapid proliferation of surveillance cameras has increased the demand for
automated violence detection. While CNNs and Transformers have shown success in
extracting spatio-temporal features, they struggle with long-term dependencies
and computational efficiency. We propose Dual Branch VideoMamba with Gated
Class Token Fusion (GCTF), an efficient architecture combining a dual-branch
design and a state-space model (SSM) backbone where one branch captures spatial
features, while the other focuses on temporal dynamics, with continuous fusion
via a gating mechanism. We also present a new benchmark by merging RWF-2000,
RLVS, and VioPeru datasets in video violence detection, ensuring strict
separation between training and testing sets. Our model achieves
state-of-the-art performance on this benchmark offering an optimal balance
between accuracy and computational efficiency, demonstrating the promise of
SSMs for scalable, real-time surveillance violence detection.

</details>


### [222] [Farm-LightSeek: An Edge-centric Multimodal Agricultural IoT Data Analytics Framework with Lightweight LLMs](https://arxiv.org/abs/2506.03168)
*Dawen Jiang,Zhishu Shen,Qiushi Zheng,Tiehua Zhang,Wei Xiang,Jiong Jin*

Main category: cs.CV

TL;DR: Farm-LightSeek是一个基于边缘计算和多模态数据融合的农业物联网框架，利用大语言模型（LLMs）解决智能农业中的实时决策和动态环境适应问题。


<details>
  <summary>Details</summary>
Motivation: 全球人口增长和气候变化对农业提出挑战，传统农业物联网系统在数据处理、实时决策和动态环境适应方面存在瓶颈，需要更高效的解决方案。

Method: 提出Farm-LightSeek框架，结合LLMs和边缘计算，通过多源数据采集、跨模态推理和边缘节点决策，实现低延迟管理和云协作。

Result: 在真实数据集上的实验表明，Farm-LightSeek在边缘计算资源限制下仍能可靠完成任务。

Conclusion: Farm-LightSeek为智能农业提供了实时解决方案，展示了农业物联网与LLMs深度融合的潜力。

Abstract: Amid the challenges posed by global population growth and climate change,
traditional agricultural Internet of Things (IoT) systems is currently
undergoing a significant digital transformation to facilitate efficient big
data processing. While smart agriculture utilizes artificial intelligence (AI)
technologies to enable precise control, it still encounters significant
challenges, including excessive reliance on agricultural expert knowledge,
difficulties in fusing multimodal data, poor adaptability to dynamic
environments, and bottlenecks in real-time decision-making at the edge. Large
language models (LLMs), with their exceptional capabilities in knowledge
acquisition and semantic understanding, provide a promising solution to address
these challenges. To this end, we propose Farm-LightSeek, an edge-centric
multimodal agricultural IoT data analytics framework that integrates LLMs with
edge computing. This framework collects real-time farmland multi-source data
(images, weather, geographic information) via sensors, performs cross-modal
reasoning and disease detection at edge nodes, conducts low-latency management
decisions, and enables cloud collaboration for model updates. The main
innovations of Farm-LightSeek include: (1) an agricultural
"perception-decision-action" closed-loop architecture; (2) cross-modal adaptive
monitoring; and (3)a lightweight LLM deployment strategy balancing performance
and efficiency. Experiments conducted on two real-world datasets demonstrate
that Farm-LightSeek consistently achieves reliable performance in
mission-critical tasks, even under the limitations of edge computing resources.
This work advances intelligent real-time agricultural solutions and highlights
the potential for deeper integration of agricultural IoT with LLMs.

</details>


### [223] [Improvement of human health lifespan with hybrid group pose estimation methods](https://arxiv.org/abs/2506.03169)
*Arindam Chaudhuri*

Main category: cs.CV

TL;DR: 提出了一种混合集成群体姿态估计方法，结合改进的群体姿态估计和实时姿态估计，提升多人姿态检测效果，优化实时性能。


<details>
  <summary>Details</summary>
Motivation: 人类姿态估计在健康监测等应用中需求增加，现有方法需改进以适应多人场景和实时性要求。

Method: 采用混合集成方法，结合改进的群体姿态估计和实时姿态估计，通过特征融合和预训练模型优化性能。

Result: 在公共基准数据集上验证，方法在实时性、遮挡鲁棒性和回归精度上表现优异。

Conclusion: 该方法在实时应用中潜力显著，有望提升人类健康监测效果。

Abstract: Human beings rely heavily on estimation of poses in order to access their
body movements. Human pose estimation methods take advantage of computer vision
advances in order to track human body movements in real life applications. This
comes from videos which are recorded through available devices. These
para-digms provide potential to make human movement measurement more accessible
to users. The consumers of pose estimation movements believe that human poses
content tend to supplement available videos. This has increased pose estimation
software usage to estimate human poses. In order to address this problem, we
develop hybrid-ensemble-based group pose estimation method to improve human
health. This proposed hybrid-ensemble-based group pose estimation method aims
to detect multi-person poses using modified group pose estimation and modified
real time pose estimation. This ensemble allows fusion of performance of stated
methods in real time. The input poses from images are fed into individual
meth-ods. The pose transformation method helps to identify relevant features
for en-semble to perform training effectively. After this, customized
pre-trained hybrid ensemble is trained on public benchmarked datasets which is
being evaluated through test datasets. The effectiveness and viability of
proposed method is estab-lished based on comparative analysis of group pose
estimation methods and ex-periments conducted on benchmarked datasets. It
provides best optimized results in real-time pose estimation. It makes pose
estimation method more robust to oc-clusion and improves dense regression
accuracy. These results have affirmed po-tential application of this method in
several real-time situations with improvement in human health life span

</details>


### [224] [PALADIN : Robust Neural Fingerprinting for Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.03170)
*Murthy L,Subarna Tripathi*

Main category: cs.CV

TL;DR: 本文提出了一种基于循环纠错码的神经指纹技术，用于提高文本到图像扩散模型的溯源准确性。


<details>
  <summary>Details</summary>
Motivation: 开源文本到图像生成模型的滥用风险日益严重，现有神经指纹技术无法达到100%的溯源准确性，限制了实际应用。

Method: 利用编码理论中的循环纠错码概念，为文本到图像扩散模型设计了一种神经指纹方法。

Result: 该方法显著提高了溯源准确性，解决了现有技术无法达到完美准确性的问题。

Conclusion: 提出的方法为神经指纹技术在文本到图像生成模型中的实际部署提供了可行方案。

Abstract: The risk of misusing text-to-image generative models for malicious uses,
especially due to the open-source development of such models, has become a
serious concern. As a risk mitigation strategy, attributing generative models
with neural fingerprinting is emerging as a popular technique. There has been a
plethora of recent work that aim for addressing neural fingerprinting. A
trade-off between the attribution accuracy and generation quality of such
models has been studied extensively. None of the existing methods yet achieved
$100\%$ attribution accuracy. However, any model with less than \emph{perfect}
accuracy is practically non-deployable. In this work, we propose an accurate
method to incorporate neural fingerprinting for text-to-image diffusion models
leveraging the concepts of cyclic error correcting codes from the literature of
coding theory.

</details>


### [225] [EdgeVidSum: Real-Time Personalized Video Summarization at the Edge](https://arxiv.org/abs/2506.03171)
*Ghulam Mujtaba,Eun-Seok Ryu*

Main category: cs.CV

TL;DR: EdgeVidSum是一种轻量级方法，直接在边缘设备上生成长视频的个性化快进摘要，通过本地数据处理保护隐私，并利用缩略图技术和高效神经架构降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决传统视频摘要方法计算复杂度高、无法在边缘设备上实时处理以及用户隐私保护不足的问题。

Method: 采用基于缩略图的容器技术，结合轻量级2D CNN模型进行分层分析，识别用户偏好内容并生成时间戳以创建摘要。

Result: 能够在资源受限的设备（如Jetson Nano）上实时生成个性化视频摘要，适用于电影、体育赛事和电视节目等长视频。

Conclusion: EdgeVidSum在计算效率、个性化和隐私保护方面为现代视频消费环境提供了有效的解决方案。

Abstract: EdgeVidSum is a lightweight method that generates personalized, fast-forward
summaries of long-form videos directly on edge devices. The proposed approach
enables real-time video summarization while safeguarding user privacy through
local data processing using innovative thumbnail-based techniques and efficient
neural architectures. Unlike conventional methods that process entire videos
frame by frame, the proposed method uses thumbnail containers to significantly
reduce computational complexity without sacrificing semantic relevance. The
framework employs a hierarchical analysis approach, where a lightweight 2D CNN
model identifies user-preferred content from thumbnails and generates
timestamps to create fast-forward summaries. Our interactive demo highlights
the system's ability to create tailored video summaries for long-form videos,
such as movies, sports events, and TV shows, based on individual user
preferences. The entire computation occurs seamlessly on resource-constrained
devices like Jetson Nano, demonstrating how EdgeVidSum addresses the critical
challenges of computational efficiency, personalization, and privacy in modern
video consumption environments.

</details>


### [226] [FOLIAGE: Towards Physical Intelligence World Models Via Unbounded Surface Evolution](https://arxiv.org/abs/2506.03173)
*Xiaoyi Liu,Hao Tang*

Main category: cs.CV

TL;DR: FOLIAGE是一种物理信息多模态世界模型，用于无界表面增长，通过多模态编码和物理感知预测生成通用生长嵌入，并在多种任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 下一代世界模型需要物理智能，能够从部分多感官观察中预测和塑造世界。

Method: FOLIAGE采用统一上下文编码器将多模态数据映射到共享潜在状态，并通过物理感知预测器生成Modality-Agnostic Growth Embedding (MAGE)。

Result: FOLIAGE在多种任务和压力测试中优于专业基线模型，表现出鲁棒性。

Conclusion: FOLIAGE为物理智能提供了一种新的多模态世界模型路径。

Abstract: Physical intelligence -- anticipating and shaping the world from partial,
multisensory observations -- is critical for next-generation world models. We
propose FOLIAGE, a physics-informed multimodal world model for unbounded
accretive surface growth. In its Action-Perception loop, a unified context
encoder maps images, mesh connectivity, and point clouds to a shared latent
state. A physics-aware predictor, conditioned on physical control actions,
advances this latent state in time to align with the target latent of the
surface, yielding a Modality-Agnostic Growth Embedding (MAGE) that interfaces
with critic heads for downstream objectives. FOLIAGE's Accretive Graph Network
(AGN) captures dynamic connectivity through Age Positional Encoding and
Energy-Gated Message-Passing. Geometry-Correspondence Fusion and Cross-Patch
Masking enhance MAGE's expressiveness, while Hierarchical Pooling balances
global context with local dynamics. We create SURF-GARDEN, a world model
learning platform comprising a Counterfactual Physics Simulator, a Multimodal
Correspondence Extractor, and Evolution Tracing, which generates 7,200 diverse
surface-growth sequences. SURF-BENCH, our physical-intelligence evaluation
suite, evaluates six core tasks -- topology recognition, inverse material
estimation, growth-stage classification, latent roll-out, cross-modal
retrieval, and dense correspondence -- and four stress tests -- sensor dropout,
zero-shot modality transfer, long-horizon prediction, and physics ablation --
to probe resilience. FOLIAGE outperforms specialized baselines while remaining
robust across dynamic environments, establishing a new world-model based,
multimodal pathway to physical intelligence.

</details>


### [227] [Multimodal Foundation Model for Cross-Modal Retrieval and Activity Recognition Tasks](https://arxiv.org/abs/2506.03174)
*Koki Matsuishi,Kosuke Ukita,Tsuyoshi Okita*

Main category: cs.CV

TL;DR: 论文提出AURA-MFM模型，整合四种模态数据（第三人称视频、动作捕捉、IMU和文本），以提升对人类活动的多维理解，并在检索和活动识别任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多模态基础模型主要依赖第一人称视频和文本数据，无法全面分析全身活动，因此需要一种更全面的模型。

Method: 提出AURA-MFM模型，整合第三人称视频、动作捕捉、IMU和文本四种模态，并使用基于Transformer的IMU编码器提升性能。

Result: 在零样本动作识别任务中，AURA-MFM的F1分数为0.6226，准确率为0.7320，显著优于现有方法（F1分数0.0747，准确率0.1961）。

Conclusion: AURA-MFM通过多模态整合显著提升了人类活动理解的性能，尤其在零样本任务中表现突出。

Abstract: In recent years, the widespread adoption of wearable devices has highlighted
the growing importance of behavior analysis using IMU. While applications span
diverse fields such as healthcare and robotics, recent studies have
increasingly focused on multimodal analysis, in addition to unimodal analysis.
Several studies have proposed multimodal foundation models that incorporate
first-person video and text data; however, these models still fall short in
providing a detailed analysis of full-body human activity. To address this
limitation, we propose Activity Understanding and Representations Alignment -
Multimodal Foundation Model (AURA-MFM), a foundational model integrating four
modalities: third-person video, motion capture, IMU, and text. By incorporating
third-person video and motion capture data, the model enables a detailed and
multidimensional understanding of human activity, which first-person
perspectives alone fail to capture. Additionally, a Transformer-based IMU
encoder is employed to enhance the model's overall performance. Experimental
evaluations on retrieval and activity recognition tasks demonstrate that our
model surpasses existing methods. Notably, in the zero-shot classification for
action recognition, our method achieved significantly higher performance, with
an F1-score of 0.6226 and an accuracy of 0.7320, whereas the existing method
recorded an F1-score of 0.0747 and an accuracy of 0.1961.

</details>


### [228] [Vid-SME: Membership Inference Attacks against Large Video Understanding Models](https://arxiv.org/abs/2506.03179)
*Qi Li,Runpeng Yu,Xinchao Wang*

Main category: cs.CV

TL;DR: Vid-SME是一种针对视频理解大语言模型（VULLMs）的成员推断方法，解决了现有方法在视频领域泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在视频理解中的应用引发了数据隐私问题，尤其是敏感视频内容可能被不当用于训练。现有成员推断方法（MIAs）在视频领域效果不佳。

Method: Vid-SME利用模型输出的置信度，结合自适应参数化计算Sharma-Mittal熵（SME），并通过自然与时间反转视频帧的SME差异生成成员分数。

Result: 实验表明，Vid-SME在多种自训练和开源VULLMs中表现优异。

Conclusion: Vid-SME为视频数据隐私保护提供了有效的解决方案。

Abstract: Multimodal large language models (MLLMs) demonstrate remarkable capabilities
in handling complex multimodal tasks and are increasingly adopted in video
understanding applications. However, their rapid advancement raises serious
data privacy concerns, particularly given the potential inclusion of sensitive
video content, such as personal recordings and surveillance footage, in their
training datasets. Determining improperly used videos during training remains a
critical and unresolved challenge. Despite considerable progress on membership
inference attacks (MIAs) for text and image data in MLLMs, existing methods
fail to generalize effectively to the video domain. These methods suffer from
poor scalability as more frames are sampled and generally achieve negligible
true positive rates at low false positive rates (TPR@Low FPR), mainly due to
their failure to capture the inherent temporal variations of video frames and
to account for model behavior differences as the number of frames varies. To
address these challenges, we introduce Vid-SME, the first membership inference
method tailored for video data used in video understanding LLMs (VULLMs).
Vid-SME leverages the confidence of model output and integrates adaptive
parameterization to compute Sharma-Mittal entropy (SME) for video inputs. By
leveraging the SME difference between natural and temporally-reversed video
frames, Vid-SME derives robust membership scores to determine whether a given
video is part of the model's training set. Experiments on various self-trained
and open-sourced VULLMs demonstrate the strong effectiveness of Vid-SME.

</details>


### [229] [TerraIncognita: A Dynamic Benchmark for Species Discovery Using Frontier Models](https://arxiv.org/abs/2506.03182)
*Shivani Chiranjeevi,Hossein Zaremehrjerdi,Zi K. Deng,Talukder Z. Jubery,Ari Grele,Arti Singh,Asheesh K Singh,Soumik Sarkar,Nirav Merchant,Harold F. Greeney,Baskar Ganapathysubramanian,Chinmay Hegde*

Main category: cs.CV

TL;DR: TerraIncognita是一个动态基准测试，用于评估多模态模型在识别未知昆虫物种方面的能力，结合已知和稀有物种图像，模拟真实生态发现场景。


<details>
  <summary>Details</summary>
Motivation: 全球生物多样性快速丧失，尤其是昆虫，当前物种发现方法效率低下，亟需新技术支持。

Method: 构建包含已知和稀有昆虫物种图像的基准数据集，评估模型在分类、检测OOD样本和生成专家级解释的能力。

Result: 模型在粗分类（如目级）表现优异（F1>90%），但在细分类（如种级）表现极差（F1<2%）。

Conclusion: TerraIncognita为AI方法提供了一个动态评估平台，未来将定期更新数据以支持长期研究。

Abstract: The rapid global loss of biodiversity, particularly among insects, represents
an urgent ecological crisis. Current methods for insect species discovery are
manual, slow, and severely constrained by taxonomic expertise, hindering timely
conservation actions. We introduce TerraIncognita, a dynamic benchmark designed
to evaluate state-of-the-art multimodal models for the challenging problem of
identifying unknown, potentially undescribed insect species from image data.
Our benchmark dataset combines a mix of expertly annotated images of insect
species likely known to frontier AI models, and images of rare and poorly known
species, for which few/no publicly available images exist. These images were
collected from underexplored biodiversity hotspots, realistically mimicking
open-world discovery scenarios faced by ecologists. The benchmark assesses
models' proficiency in hierarchical taxonomic classification, their capability
to detect and abstain from out-of-distribution (OOD) samples representing novel
species, and their ability to generate explanations aligned with expert
taxonomic knowledge. Notably, top-performing models achieve over 90\% F1 at the
Order level on known species, but drop below 2\% at the Species level,
highlighting the sharp difficulty gradient from coarse to fine taxonomic
prediction (Order $\rightarrow$ Family $\rightarrow$ Genus $\rightarrow$
Species). TerraIncognita will be updated regularly, and by committing to
quarterly dataset expansions (of both known and novel species), will provide an
evolving platform for longitudinal benchmarking of frontier AI methods. All
TerraIncognita data, results, and future updates are available
\href{https://baskargroup.github.io/TerraIncognita/}{here}.

</details>


### [230] [Impact of Tuning Parameters in Deep Convolutional Neural Network Using a Crack Image Dataset](https://arxiv.org/abs/2506.03184)
*Mahe Zabin,Ho-Jin Choi,Md. Monirul Islam,Jia Uddin*

Main category: cs.CV

TL;DR: 研究了深度卷积神经网络（DCNN）中不同调参对性能的影响，发现使用maxpooling、adam优化器和tanh激活函数时性能最佳。


<details>
  <summary>Details</summary>
Motivation: 探索DCNN中调参对分类性能的影响，以优化模型表现。

Method: 使用包含2个卷积层、2个池化层、1个dropout层和1个密集层的DCNN，在裂缝图像数据集上测试不同参数组合。

Result: 实验表明，maxpooling、adam优化器和tanh激活函数的组合性能最优。

Conclusion: 调参对DCNN性能有显著影响，maxpooling、adam和tanh是较优选择。

Abstract: The performance of a classifier depends on the tuning of its parame ters. In
this paper, we have experimented the impact of various tuning parameters on the
performance of a deep convolutional neural network (DCNN). In the ex perimental
evaluation, we have considered a DCNN classifier that consists of 2
convolutional layers (CL), 2 pooling layers (PL), 1 dropout, and a dense layer.
To observe the impact of pooling, activation function, and optimizer tuning pa
rameters, we utilized a crack image dataset having two classes: negative and
pos itive. The experimental results demonstrate that with the maxpooling, the
DCNN demonstrates its better performance for adam optimizer and tanh activation
func tion.

</details>


### [231] [Continual Learning in Vision-Language Models via Aligned Model Merging](https://arxiv.org/abs/2506.03189)
*Ghada Sokar,Gintare Karolina Dziugaite,Anurag Arnab,Ahmet Iscen,Pablo Samuel Castro,Cordelia Schmid*

Main category: cs.CV

TL;DR: 提出了一种基于模型合并的持续学习方法，通过合并新任务参数与旧任务参数，平衡稳定性和可塑性，减少遗忘。


<details>
  <summary>Details</summary>
Motivation: 传统持续学习方法通过顺序微调，倾向于可塑性而牺牲稳定性，导致对近期任务的偏见和遗忘问题。

Method: 提出模型合并方法，通过合并新任务参数与旧任务参数，并设计机制确保权重对齐，避免干扰。

Result: 在大型视觉语言模型上验证，有效减少遗忘，提高对任务顺序和相似性的鲁棒性，并改善泛化能力。

Conclusion: 模型合并方法在持续学习中实现了稳定性和可塑性的平衡，显著优于传统顺序微调方法。

Abstract: Continual learning is conventionally tackled through sequential fine-tuning,
a process that, while enabling adaptation, inherently favors plasticity over
the stability needed to retain prior knowledge. While existing approaches
attempt to mitigate catastrophic forgetting, a bias towards recent tasks
persists as they build upon this sequential nature. In this work we present a
new perspective based on model merging to maintain stability while still
retaining plasticity. Rather than just sequentially updating the model weights,
we propose merging newly trained task parameters with previously learned ones,
promoting a better balance. To maximize the effectiveness of the merging
process, we propose a simple mechanism that promotes learning aligned weights
with previous ones, thereby avoiding interference when merging. We evaluate
this approach on large Vision-Language Models (VLMs), and demonstrate its
effectiveness in reducing forgetting, increasing robustness to various task
orders and similarities, and improving generalization.

</details>


### [232] [MINT: Memory-Infused Prompt Tuning at Test-time for CLIP](https://arxiv.org/abs/2506.03190)
*Jiaming Yi,Ruirui Pan,Jishen Yang,Xiulong Yang*

Main category: cs.CV

TL;DR: 提出了一种名为MINT的新框架，通过记忆提示库动态调整视觉语言预训练模型，提升其在测试时数据分布变化下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有测试时适应方法未能充分利用模型内部知识，特别是在动态适应复杂分层的视觉语义信息方面。

Method: MINT引入记忆提示库（MPB），存储可学习的键值提示对，通过测试图像的分层视觉特征检索相关提示对，动态组装关联提示并注入图像编码器。

Result: MINT无需源数据或重新训练，即可实现快速、精确的视觉语言模型适应。

Conclusion: MINT通过记忆提示库显著提升了视觉语言预训练模型在测试时的适应能力和泛化性能。

Abstract: Improving the generalization ability of Vision-Language Pre-trained Models
(VLMs) under test-time data distribution shifts remains a critical challenge.
The existing Test-Time Adaptation (TTA) methods fall short in fully leveraging
the model's internal knowledge, particularly in dynamically adapting to complex
and hierarchical visual semantic information. In this paper, we propose
Memory-Infused Prompt Tuning (MINT), a novel framework to address this issue.
Inspired by human associative memory theory, MINT introduces a Memory Prompt
Bank (MPB), which stores learnable key-value prompt pairs that work as a memory
of previously seen samples. During the test time, relevant prompt pairs in the
MPB are retrieved by the hierarchical visual features of test images to
dynamically assemble Associative Prompts. The associative prompts are then
injected into the image encoder for fine-grained, customized visual contextual
guidance. MINT also utilizes learnable text prompts. MINT thus enables rapid,
precise VLM adaptation at test time by leveraging this MPB-acquired memory,
without source data or retraining. The code is available at
https://github.com/Jamieyi2004/MINT.

</details>


### [233] [Multimodal Generative AI with Autoregressive LLMs for Human Motion Understanding and Generation: A Way Forward](https://arxiv.org/abs/2506.03191)
*Muhammad Islam,Tao Huang,Euijoon Ahn,Usman Naseem*

Main category: cs.CV

TL;DR: 本文综述了多模态生成人工智能（GenAI）和自回归大语言模型（LLMs）在人类运动理解与生成中的应用，探讨了新兴方法、架构及其在提升运动合成逼真性和多样性方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索如何通过文本描述指导复杂、类人运动序列的生成，以推动文本到运动生成技术的发展。

Method: 分析了多种生成方法，包括自回归模型、扩散模型、生成对抗网络（GANs）、变分自编码器（VAEs）和基于Transformer的模型，评估其在运动质量、计算效率和适应性方面的优劣。

Result: 研究表明，结合LLMs的文本条件运动生成技术能够实现语义对齐，提升运动的连贯性和上下文相关性。

Conclusion: 文本到运动的GenAI和LLM架构在医疗、人形机器人、游戏、动画和辅助技术等领域具有变革潜力，但仍需解决生成高效且逼真运动的技术挑战。

Abstract: This paper presents an in-depth survey on the use of multimodal Generative
Artificial Intelligence (GenAI) and autoregressive Large Language Models (LLMs)
for human motion understanding and generation, offering insights into emerging
methods, architectures, and their potential to advance realistic and versatile
motion synthesis. Focusing exclusively on text and motion modalities, this
research investigates how textual descriptions can guide the generation of
complex, human-like motion sequences. The paper explores various generative
approaches, including autoregressive models, diffusion models, Generative
Adversarial Networks (GANs), Variational Autoencoders (VAEs), and
transformer-based models, by analyzing their strengths and limitations in terms
of motion quality, computational efficiency, and adaptability. It highlights
recent advances in text-conditioned motion generation, where textual inputs are
used to control and refine motion outputs with greater precision. The
integration of LLMs further enhances these models by enabling semantic
alignment between instructions and motion, improving coherence and contextual
relevance. This systematic survey underscores the transformative potential of
text-to-motion GenAI and LLM architectures in applications such as healthcare,
humanoids, gaming, animation, and assistive technologies, while addressing
ongoing challenges in generating efficient and realistic human motion.

</details>


### [234] [Human Fall Detection using Transfer Learning-based 3D CNN](https://arxiv.org/abs/2506.03193)
*Ekram Alam,Abu Sufian,Paramartha Dutta,Marco Leo*

Main category: cs.CV

TL;DR: 本文提出了一种基于预训练3D CNN的视觉跌倒检测系统，利用时空特征和SVM分类器，减少了训练时间，并在两个数据集上验证了效果。


<details>
  <summary>Details</summary>
Motivation: 老年人跌倒是一个严重的健康问题，随着老年人口增加，需要自动化的跌倒检测系统。

Method: 使用预训练的3D CNN提取时空特征，仅训练SVM分类器，采用分层五折交叉验证。

Result: 在两个数据集（GMDCSA和CAUCAFall）上验证了模型的有效性。

Conclusion: 该方法通过预训练模型和SVM分类器，实现了高效的跌倒检测。

Abstract: Unintentional or accidental falls are one of the significant health issues in
senior persons. The population of senior persons is increasing steadily. So,
there is a need for an automated fall detection monitoring system. This paper
introduces a vision-based fall detection system using a pre-trained 3D CNN.
Unlike 2D CNN, 3D CNN extracts not only spatial but also temporal features. The
proposed model leverages the original learned weights of a 3D CNN model
pre-trained on the Sports1M dataset to extract the spatio-temporal features.
Only the SVM classifier was trained, which saves the time required to train the
3D CNN. Stratified shuffle five split cross-validation has been used to split
the dataset into training and testing data. Extracted features from the
proposed 3D CNN model were fed to an SVM classifier to classify the activity as
fall or ADL. Two datasets, GMDCSA and CAUCAFall, were utilized to conduct the
experiment. The source code for this work can be accessed via the following
link: https://github.com/ekramalam/HFD_3DCNN.

</details>


### [235] [HueManity: Probing Fine-Grained Visual Perception in MLLMs](https://arxiv.org/abs/2506.03194)
*Rynaa Grover,Jayant Sravan Tamarapalli,Sahiti Yerramilli,Nilay Pande*

Main category: cs.CV

TL;DR: HueManity是一个评估多模态大语言模型（MLLMs）视觉感知能力的基准测试，结果显示MLLMs在精确模式识别任务上表现显著低于人类和传统计算机视觉模型。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在高层次视觉推理上表现优异，但在细微感知任务上的性能仍然有限，因此需要评估和改进其视觉能力。

Method: HueManity数据集包含83,850张图像，模拟石原氏色盲测试风格的点阵图案，测试MLLMs的精确模式识别能力。评估了9种先进的MLLMs。

Result: MLLMs表现不佳，最佳模型在“简单”数字任务上准确率为33.6%，在“困难”字母数字任务上仅为3%，远低于人类（100%和95.6%）和ResNet50模型（96.5%和94.5%）。

Conclusion: 当前MLLMs在视觉感知能力上存在显著不足，需改进架构和训练范式。HueManity数据集和代码已开源以促进研究。

Abstract: Multimodal Large Language Models (MLLMs) excel at high-level visual
reasoning, but their performance on nuanced perceptual tasks remains
surprisingly limited. We present HueManity, a benchmark designed to assess
visual perception in MLLMs. The dataset comprises 83,850 images featuring
two-character alphanumeric strings embedded in Ishihara test style dot
patterns, challenging models on precise pattern recognition. Our evaluation of
nine state-of-the-art MLLMs on HueManity demonstrates a significant performance
deficit compared to human and traditional computer vision baselines. The
best-performing MLLM achieved a 33.6% accuracy on the numeric `easy' task and a
striking 3% on the alphanumeric `hard' task. In contrast, human participants
achieved near-perfect scores (100% and 95.6%), and a fine-tuned ResNet50 model
reached accuracies of 96.5% and 94.5%. These results highlight a critical gap
in the visual capabilities of current MLLMs. Our analysis further explores
potential architectural and training-paradigm factors contributing to this
perceptual gap in MLLMs. We open-source HueManity dataset and code to foster
further research in improving perceptual robustness of MLLMs.

</details>


### [236] [Unlabeled Data Improves Fine-Grained Image Zero-shot Classification with Multimodal LLMs](https://arxiv.org/abs/2506.03195)
*Yunqi Hong,Sohyun An,Andrew Bai,Neil Y. C. Lin,Cho-Jui Hsieh*

Main category: cs.CV

TL;DR: AutoSEP是一种自监督提示学习框架，旨在提升多模态大语言模型（MLLMs）在细粒度图像分类任务中的性能，无需标注数据。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在零样本图像分类任务中表现良好，但在细粒度分类中容易忽略细微视觉差异，需要显式指导。

Method: 提出AutoSEP框架，通过无标注数据迭代学习描述提示，引导MLLMs识别关键判别特征，无需训练或微调。

Result: 在多个细粒度分类数据集上，AutoSEP平均比零样本分类提升13%，优于其他无监督基线。

Conclusion: AutoSEP通过自监督优化显著提升了MLLMs的细粒度分类能力，且仅需黑盒访问MLLMs。

Abstract: Despite Multimodal Large Language Models (MLLMs) showing promising results on
general zero-shot image classification tasks, fine-grained image classification
remains challenging. It demands precise attention to subtle visual details to
distinguish between visually similar subcategories--details that MLLMs may
easily overlook without explicit guidance. To address this, we introduce
AutoSEP, an iterative self-supervised prompt learning framework designed to
enhance MLLM fine-grained classification capabilities in a fully unsupervised
manner. Our core idea is to leverage unlabeled data to learn a description
prompt that guides MLLMs in identifying crucial discriminative features within
an image, and boosts classification accuracy. We developed an automatic
self-enhancing prompt learning framework called AutoSEP to iteratively improve
the description prompt using unlabeled data, based on instance-level
classification scoring function. AutoSEP only requires black-box access to
MLLMs, eliminating the need for any training or fine-tuning. We evaluate our
approach on multiple fine-grained classification datasets. It consistently
outperforms other unsupervised baselines, demonstrating the effectiveness of
our self-supervised optimization framework. Notably, AutoSEP on average
improves 13 percent over standard zero-shot classification and 5 percent over
the best-performing baselines. Code is available at:
https://github.com/yq-hong/AutoSEP

</details>


### [237] [Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing](https://arxiv.org/abs/2506.03197)
*Baode Wang,Biao Wu,Weizhen Li,Meng Fang,Yanjie Liang,Zuming Huang,Haozhe Wang,Jun Huang,Ling Chen,Wei Chu,Yuan Qi*

Main category: cs.CV

TL;DR: 论文提出了一种名为layoutRL的端到端强化学习框架，通过优化复合奖励来提升文档解析的布局感知能力，并在新数据集Infinity-Doc-55K上验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 传统多阶段文档解析流程存在错误传播和布局适应性差的问题，亟需一种更高效的方法。

Method: 使用强化学习框架layoutRL，结合标准化编辑距离、段落计数准确性和阅读顺序保持等复合奖励，训练布局感知模型。

Result: Infinity-Parser在OCR、表格和公式提取及阅读顺序检测任务中，实现了新的最佳性能。

Conclusion: layoutRL框架显著提升了文档解析的准确性和结构保真度，代码和数据集将公开以推动文档理解研究。

Abstract: Automated parsing of scanned documents into richly structured,
machine-readable formats remains a critical bottleneck in Document AI, as
traditional multi-stage pipelines suffer from error propagation and limited
adaptability to diverse layouts. We introduce layoutRL, an end-to-end
reinforcement learning framework that trains models to be explicitly
layout-aware by optimizing a composite reward of normalized edit distance,
paragraph count accuracy, and reading order preservation. Leveraging our newly
released dataset, Infinity-Doc-55K, which combines 55K high-fidelity synthetic
scanned document parsing data with expert-filtered real-world documents, we
instantiate layoutRL in a vision-language-model-based parser called
Infinity-Parser. Evaluated on English and Chinese benchmarks for OCR, table and
formula extraction, and reading order detection, Infinity-Parser achieves new
state-of-the-art performance in both accuracy and structural fidelity,
outpacing specialist pipelines and general-purpose vision-language models. We
will publicly release our code and dataset to accelerate progress in robust
document understanding.

</details>


### [238] [FLEX: A Large-Scale Multi-Modal Multi-Action Dataset for Fitness Action Quality Assessment](https://arxiv.org/abs/2506.03198)
*Hao Yin,Lijun Gu,Paritosh Parmar,Lin Xu,Tianxiao Guo,Weiwei Fu,Yang Zhang,Tianyou Zheng*

Main category: cs.CV

TL;DR: 论文提出了FLEX数据集，首个多模态、多动作的大规模数据集，结合表面肌电信号（sEMG）用于动作质量评估（AQA），填补了现有AQA方法和数据集在健身领域的空白。


<details>
  <summary>Details</summary>
Motivation: 随着健康意识的增强和对健美体型的追求，健身成为流行趋势，但健身训练中的潜在风险不容忽视。现有AQA方法和数据集局限于单视角竞技体育场景和RGB模态，缺乏对健身动作的专业评估和指导。

Method: 提出FLEX数据集，包含20种负重动作、38名受试者、3种技能水平、10次重复动作，采集了5种视角的RGB视频、3D姿态、sEMG和生理信息，并结合知识图谱构建了标注规则。

Result: 实验表明，多模态数据、多视角数据和细粒度标注显著提升了模型性能。

Conclusion: FLEX不仅推动了AQA方法和数据集向多模态、多动作场景发展，还促进了人工智能在健身领域的应用。

Abstract: With the increasing awareness of health and the growing desire for aesthetic
physique, fitness has become a prevailing trend. However, the potential risks
associated with fitness training, especially with weight-loaded fitness
actions, cannot be overlooked. Action Quality Assessment (AQA), a technology
that quantifies the quality of human action and provides feedback, holds the
potential to assist fitness enthusiasts of varying skill levels in achieving
better training outcomes. Nevertheless, current AQA methodologies and datasets
are limited to single-view competitive sports scenarios and RGB modality and
lack professional assessment and guidance of fitness actions. To address this
gap, we propose the FLEX dataset, the first multi-modal, multi-action,
large-scale dataset that incorporates surface electromyography (sEMG) signals
into AQA. FLEX utilizes high-precision MoCap to collect 20 different
weight-loaded actions performed by 38 subjects across 3 different skill levels
for 10 repetitions each, containing 5 different views of the RGB video, 3D
pose, sEMG, and physiological information. Additionally, FLEX incorporates
knowledge graphs into AQA, constructing annotation rules in the form of penalty
functions that map weight-loaded actions, action keysteps, error types, and
feedback. We conducted various baseline methodologies on FLEX, demonstrating
that multimodal data, multiview data, and fine-grained annotations
significantly enhance model performance. FLEX not only advances AQA
methodologies and datasets towards multi-modal and multi-action scenarios but
also fosters the integration of artificial intelligence within the fitness
domain. Dataset and code are available at
https://haoyin116.github.io/FLEX_Dataset.

</details>


### [239] [Channel-adaptive Cross-modal Generative Semantic Communication for Point Cloud Transmission](https://arxiv.org/abs/2506.03211)
*Wanting Yang,Zehui Xiong,Qianqian Yang,Ping Zhang,Merouane Debbah,Rahim Tafazolli*

Main category: cs.CV

TL;DR: 提出了一种名为GenSeC-PC的跨模态生成语义通信方法，用于高效点云传输，结合图像和点云语义编码，实现高压缩效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶和扩展现实的快速发展，点云的高效传输变得日益重要。现有方法在压缩效率和鲁棒性方面存在不足。

Method: 采用跨模态语义编码器融合图像和点云，基于PointDif的解码器，设计通道自适应联合语义-信道编码架构，并利用修正去噪扩散隐式模型加速解码。

Result: 仿真结果表明，该方法在低信噪比、带宽限制等多样条件下表现鲁棒，支持完全模拟传输，显著提升压缩效率。

Conclusion: GenSeC-PC通过生成先验和跨模态设计，实现了高效、鲁棒的点云传输，优于现有方法。

Abstract: With the rapid development of autonomous driving and extended reality,
efficient transmission of point clouds (PCs) has become increasingly important.
In this context, we propose a novel channel-adaptive cross-modal generative
semantic communication (SemCom) for PC transmission, called GenSeC-PC.
GenSeC-PC employs a semantic encoder that fuses images and point clouds, where
images serve as non-transmitted side information. Meanwhile, the decoder is
built upon the backbone of PointDif. Such a cross-modal design not only ensures
high compression efficiency but also delivers superior reconstruction
performance compared to PointDif. Moreover, to ensure robust transmission and
reduce system complexity, we design a streamlined and asymmetric
channel-adaptive joint semantic-channel coding architecture, where only the
encoder needs the feedback of average signal-to-noise ratio (SNR) and available
bandwidth. In addition, rectified denoising diffusion implicit models is
employed to accelerate the decoding process to the millisecond level, enabling
real-time PC communication. Unlike existing methods, GenSeC-PC leverages
generative priors to ensure reliable reconstruction even from noisy or
incomplete source PCs. More importantly, it supports fully analog transmission,
improving compression efficiency by eliminating the need for error-free side
information transmission common in prior SemCom approaches. Simulation results
confirm the effectiveness of cross-modal semantic extraction and dual-metric
guided fine-tuning, highlighting the framework's robustness across diverse
conditions, including low SNR, bandwidth limitations, varying numbers of 2D
images, and previously unseen objects.

</details>


### [240] [ConMamba: Contrastive Vision Mamba for Plant Disease Detection](https://arxiv.org/abs/2506.03213)
*Abdullah Al Mamun,Miaohua Zhang,David Ahmedt-Aristizabal,Zeeshan Hayder,Mohammad Awrangjeb*

Main category: cs.CV

TL;DR: ConMamba是一种自监督学习框架，专为植物病害检测设计，通过双向状态空间模型和动态对比损失优化性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法依赖大量标注数据，成本高；自监督学习虽能利用未标注数据，但计算成本高且难以捕捉长距离依赖关系。

Method: 提出ConMamba框架，结合Vision Mamba Encoder（双向状态空间模型）和动态双级对比损失，优化局部-全局特征对齐。

Result: 在三个基准数据集上，ConMamba显著优于现有方法。

Conclusion: ConMamba为植物病害检测提供了高效、鲁棒的解决方案。

Abstract: Plant Disease Detection (PDD) is a key aspect of precision agriculture.
However, existing deep learning methods often rely on extensively annotated
datasets, which are time-consuming and costly to generate. Self-supervised
Learning (SSL) offers a promising alternative by exploiting the abundance of
unlabeled data. However, most existing SSL approaches suffer from high
computational costs due to convolutional neural networks or transformer-based
architectures. Additionally, they struggle to capture long-range dependencies
in visual representation and rely on static loss functions that fail to align
local and global features effectively. To address these challenges, we propose
ConMamba, a novel SSL framework specially designed for PDD. ConMamba integrates
the Vision Mamba Encoder (VME), which employs a bidirectional State Space Model
(SSM) to capture long-range dependencies efficiently. Furthermore, we introduce
a dual-level contrastive loss with dynamic weight adjustment to optimize
local-global feature alignment. Experimental results on three benchmark
datasets demonstrate that ConMamba significantly outperforms state-of-the-art
methods across multiple evaluation metrics. This provides an efficient and
robust solution for PDD.

</details>


### [241] [OpenCarbon: A Contrastive Learning-based Cross-Modality Neural Approach for High-Resolution Carbon Emission Prediction Using Open Data](https://arxiv.org/abs/2506.03224)
*Jinwei Zeng,Yu Liu,Guozhen Zhang,Jingtao Ding,Yuming Lin,Jian Yuan,Yong Li*

Main category: cs.CV

TL;DR: OpenCarbon利用卫星图像和POI数据预测高分辨率城市碳排放，通过跨模态信息提取和邻域聚合模块解决功能性和空间连续性问题，性能提升26.6%。


<details>
  <summary>Details</summary>
Motivation: 传统碳排放核算方法数据收集成本高，开放数据和先进学习技术为高分辨率碳排放估算提供了新思路。

Method: 结合卫星图像和POI数据，设计跨模态信息提取与融合模块及邻域聚合模块。

Result: 模型性能显著提升（R2提高26.6%），验证了其捕捉城市功能与碳排放关系的能力。

Conclusion: OpenCarbon为高效碳排放治理和针对性减排规划提供了潜力，代码和数据已开源。

Abstract: Accurately estimating high-resolution carbon emissions is crucial for
effective emission governance and mitigation planning. While conventional
methods for precise carbon accounting are hindered by substantial data
collection efforts, the rise of open data and advanced learning techniques
offers a promising solution. Once an open data-based prediction model is
developed and trained, it can easily infer emissions for new areas based on
available open data. To address this, we incorporate two modalities of open
data, satellite images and point-of-interest (POI) data, to predict
high-resolution urban carbon emissions, with satellite images providing
macroscopic and static and POI data offering fine-grained and relatively
dynamic functionality information. However, estimating high-resolution carbon
emissions presents two significant challenges: the intertwined and implicit
effects of various functionalities on carbon emissions, and the complex spatial
contiguity correlations that give rise to the agglomeration effect. Our model,
OpenCarbon, features two major designs that target the challenges: a
cross-modality information extraction and fusion module to extract
complementary functionality information from two modules and model their
interactions, and a neighborhood-informed aggregation module to capture the
spatial contiguity correlations. Extensive experiments demonstrate our model's
superiority, with a significant performance gain of 26.6\% on R2. Further
generalizability tests and case studies also show OpenCarbon's capacity to
capture the intrinsic relation between urban functionalities and carbon
emissions, validating its potential to empower efficient carbon governance and
targeted carbon mitigation planning. Codes and data are available:
https://github.com/JinweiZzz/OpenCarbon.

</details>


### [242] [Pre-trained Vision-Language Models Assisted Noisy Partial Label Learning](https://arxiv.org/abs/2506.03229)
*Qian-Wei Wang,Yuqiu Xie,Letian Zhang,Zimo Liu,Shu-Tao Xia*

Main category: cs.CV

TL;DR: 本文提出了一种创新的协同一致性正则化（Co-Reg）方法，用于从预训练视觉语言模型（VLMs）生成的噪声部分标签中学习，解决了实例依赖性噪声问题。


<details>
  <summary>Details</summary>
Motivation: 预训练VLMs生成的噪声与传统对称噪声不同，增加了学习难度。本文旨在利用这些模型实现免手动标注的下游任务训练。

Method: 通过协同伪标签机制和标签空间与特征表示空间的一致性正则化约束，同时训练两个神经网络以净化训练标签。

Result: 实验验证了方法的有效性，并展示了弱监督学习技术与预训练模型知识蒸馏结合的广阔前景。

Conclusion: Co-Reg方法能有效处理预训练模型生成的噪声部分标签，为免手动标注训练提供了新思路。

Abstract: In the context of noisy partial label learning (NPLL), each training sample
is associated with a set of candidate labels annotated by multiple noisy
annotators. With the emergence of high-performance pre-trained vision-language
models (VLMs) such as CLIP, LLaVa and GPT-4V, the direction of using these
models to replace time-consuming manual annotation workflows and achieve
"manual-annotation-free" training for downstream tasks has become a highly
promising research avenue. This paper focuses on learning from noisy partial
labels annotated by pre-trained VLMs and proposes an innovative collaborative
consistency regularization (Co-Reg) method. Unlike the symmetric noise
primarily addressed in traditional noisy label learning, the noise generated by
pre-trained models is instance-dependent, embodying the underlying patterns of
the pre-trained models themselves, which significantly increases the learning
difficulty for the model. To address this, we simultaneously train two neural
networks that implement collaborative purification of training labels through a
"Co-Pseudo-Labeling" mechanism, while enforcing consistency regularization
constraints in both the label space and feature representation space. Our
method can also leverage few-shot manually annotated valid labels to further
enhance its performances. Comparative experiments with different denoising and
disambiguation algorithms, annotation manners, and pre-trained model
application schemes fully validate the effectiveness of the proposed method,
while revealing the broad prospects of integrating weakly-supervised learning
techniques into the knowledge distillation process of pre-trained models.

</details>


### [243] [Chipmunk: Training-Free Acceleration of Diffusion Transformers with Dynamic Column-Sparse Deltas](https://arxiv.org/abs/2506.03275)
*Austin Silveria,Soham V. Govande,Daniel Y. Fu*

Main category: cs.CV

TL;DR: 论文提出Chipmunk方法，通过动态稀疏性减少DiT推理时的冗余计算，显著提升速度而不影响生成质量。


<details>
  <summary>Details</summary>
Motivation: DiT在推理时计算冗余高，噪声向量变化缓慢，表明中间激活值变化较小，可通过动态稀疏性优化。

Method: 研究DiT激活值变化，发现仅5-25%的值贡献70-90%的变化；提出Chipmunk方法，动态稀疏计算变化快的激活值，缓存其余部分，并优化GPU利用和计算重叠。

Result: Chipmunk在HunyuanVideo和FLUX.1-dev上分别实现2.16x和1.41x加速，叠加全步缓存后速度提升更显著。

Conclusion: Chipmunk有效减少DiT推理冗余，显著提升速度且保持生成质量，适用于多种模型。

Abstract: Diffusion Transformers (DiTs) have achieved state-of-the-art performance in
high-quality image and video generation but incur substantial compute cost at
inference. A common observation is that DiT latent noise vectors change slowly
across inference steps, which suggests that the DiT compute may be redundant
across steps. In this paper, we aim to speed up inference by reducing this
redundancy, without additional training. We first study how activations change
between steps in two state-of-the-art open-source DiTs. We find that just 5-25%
of the values in attention and MLP explain 70-90% of the change in activations
across steps. This finding motivates our approach, Chipmunk, which uses dynamic
sparsity at inference time to recompute only the fastest-changing intermediate
activations, while caching the rest. Dynamic sparsity introduces two systems
challenges: (1) sparse attention and MLP operations tend to underutilize GPU
tensor cores; and (2) computing dynamic sparsity patterns at runtime and
caching activations both introduce overhead. To address these challenges,
Chipmunk first uses a voxel-based reordering of input tokens to introduce
column-wise sparsity. We implement column-sparse kernels utilizing efficient
sparse gathers from global to shared GPU memory, achieving a 9.3x speedup at
93% sparsity compared to highly-optimized dense baselines. Second, Chipmunk
overlaps the computation of sparsity patterns and cache updates with other
parts of the computation (e.g., second layer of the MLP) to hide the extra
latency. Chipmunk achieves up to 2.16x speedup on HunyuanVideo and 1.41x on
FLUX.1-dev without compromising generation quality. Furthermore, we show that
Chipmunk can be stacked on top of full step caching, achieving a 3.72x speedup
on HunyuanVideo, a 2.67x speedup on WAN2.1, and a 2.25x speedup on FLUX.1-dev
with minimal quality impact.

</details>


### [244] [Learning Optical Flow Field via Neural Ordinary Differential Equation](https://arxiv.org/abs/2506.03290)
*Leyla Mirvakhabova,Hong Cai,Jisoo Jeong,Hanno Ackermann,Farhad Zanjani,Fatih Porikli*

Main category: cs.CV

TL;DR: 该论文提出了一种基于神经ODE的连续模型，用于动态调整光流估计中的计算步骤，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有光流估计方法使用固定步骤的神经网络进行迭代优化，可能导致性能不佳，因为步骤数未根据输入数据动态调整。

Method: 采用神经ODE模型预测光流导数，动态调整计算步骤，并通过特定架构和超参数实现与现有方法相同的更新。

Result: 在光流基准测试中，该方法显著优于基线模型和现有方法，且仅需单一步骤。

Conclusion: 神经ODE模型为光流估计提供了一种更灵活、高效的解决方案，性能显著提升。

Abstract: Recent works on optical flow estimation use neural networks to predict the
flow field that maps positions of one image to positions of the other. These
networks consist of a feature extractor, a correlation volume, and finally
several refinement steps. These refinement steps mimic the iterative
refinements performed by classical optimization algorithms and are usually
implemented by neural layers (e.g., GRU) which are recurrently executed for a
fixed and pre-determined number of steps. However, relying on a fixed number of
steps may result in suboptimal performance because it is not tailored to the
input data. In this paper, we introduce a novel approach for predicting the
derivative of the flow using a continuous model, namely neural ordinary
differential equations (ODE). One key advantage of this approach is its
capacity to model an equilibrium process, dynamically adjusting the number of
compute steps based on the data at hand. By following a particular neural
architecture, ODE solver, and associated hyperparameters, our proposed model
can replicate the exact same updates as recurrent cells used in existing works,
offering greater generality. Through extensive experimental analysis on optical
flow benchmarks, we demonstrate that our approach achieves an impressive
improvement over baseline and existing models, all while requiring only a
single refinement step.

</details>


### [245] [SportMamba: Adaptive Non-Linear Multi-Object Tracking with State Space Models for Team Sports](https://arxiv.org/abs/2506.03335)
*Dheeraj Khanna,Jerrin Bright,Yuhao Chen,John S. Zelek*

Main category: cs.CV

TL;DR: SportMamba是一种针对团队运动的多目标跟踪技术，通过引入mamba-attention机制和高度自适应空间关联度量，解决了快速运动和遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 团队运动中的多目标跟踪因快速运动和频繁遮挡而极具挑战性，现有方法依赖检测和外观跟踪，难以应对复杂场景。

Method: 提出mamba-attention机制建模非线性运动，引入高度自适应空间关联度量减少遮挡导致的ID切换，并扩展检测搜索空间。

Result: 在SportsMOT数据集上表现优异，并在VIP-HTD冰球数据集中展示了零样本迁移能力。

Conclusion: SportMamba在复杂运动场景中实现了先进的跟踪性能，并具备良好的泛化能力。

Abstract: Multi-object tracking (MOT) in team sports is particularly challenging due to
the fast-paced motion and frequent occlusions resulting in motion blur and
identity switches, respectively. Predicting player positions in such scenarios
is particularly difficult due to the observed highly non-linear motion
patterns. Current methods are heavily reliant on object detection and
appearance-based tracking, which struggle to perform in complex team sports
scenarios, where appearance cues are ambiguous and motion patterns do not
necessarily follow a linear pattern. To address these challenges, we introduce
SportMamba, an adaptive hybrid MOT technique specifically designed for tracking
in dynamic team sports. The technical contribution of SportMamba is twofold.
First, we introduce a mamba-attention mechanism that models non-linear motion
by implicitly focusing on relevant embedding dependencies. Second, we propose a
height-adaptive spatial association metric to reduce ID switches caused by
partial occlusions by accounting for scale variations due to depth changes.
Additionally, we extend the detection search space with adaptive buffers to
improve associations in fast-motion scenarios. Our proposed technique,
SportMamba, demonstrates state-of-the-art performance on various metrics in the
SportsMOT dataset, which is characterized by complex motion and severe
occlusion. Furthermore, we demonstrate its generalization capability through
zero-shot transfer to VIP-HTD, an ice hockey dataset.

</details>


### [246] [Seeing the Arrow of Time in Large Multimodal Models](https://arxiv.org/abs/2506.03340)
*Zihui Xue,Mi Luo,Kristen Grauman*

Main category: cs.CV

TL;DR: 论文提出ArrowRL，一种基于强化学习的训练策略，通过反向奖励机制增强时间方向性感知，显著提升视频理解能力。


<details>
  <summary>Details</summary>
Motivation: 现代大型多模态模型（LMMs）在视频理解中难以感知和利用时间方向性，阻碍了更深层次的时间理解。

Method: 引入ArrowRL，一种基于强化学习的训练策略，通过反向奖励机制鼓励对正向和反向视频帧的不同解释。

Result: ArrowRL在AoTBench和标准视频问答基准上分别实现了超过20%和10%的准确率提升。

Conclusion: ArrowRL的有效性验证了在LMMs中专门理解时间方向性的重要性。

Abstract: The Arrow of Time (AoT)-time's irreversible flow shaping physical events-is
fundamental to video comprehension, yet remains a significant challenge for
modern large multimodal models (LMMs). Current LMMs struggle to perceive and
utilize temporal directionality in video when responding to language queries,
obstructing deeper temporal understanding. We tackle this deficiency by first
providing a critical analysis of existing benchmarks and models. We then
introduce ArrowRL, a reinforcement learning (RL)-based training strategy with
an innovative reverse reward that instills AoT awareness by encouraging
divergent video interpretations between forward and reversed visual frames. For
rigorous evaluation, we additionally develop AoTBench, a new multi-faceted
benchmark probing temporally challenging questions. Experiments show ArrowRL
greatly advances temporal perception: it not only achieves substantial
improvements on our challenging AoTBench but also demonstrably boosts
performance on standard video question answering (VQA) benchmarks (with peak
accuracy gains reaching over 20% and 10% respectively). This validates
ArrowRL's effectiveness and highlights the critical need for dedicated AoT
understanding in LMMs.

</details>


### [247] [Semiconductor SEM Image Defect Classification Using Supervised and Semi-Supervised Learning with Vision Transformers](https://arxiv.org/abs/2506.03345)
*Chien-Fu,Huang,Katherine Sieg,Leonid Karlinksy,Nash Flores,Rebekah Sheraw,Xin Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种基于视觉变换器（ViT）的自动缺陷分类方法，用于半导体晶圆缺陷的扫描电子显微镜图像分类，通过少量样本实现了高准确率。


<details>
  <summary>Details</summary>
Motivation: 半导体工艺中缺陷控制对提高产量、降低成本和预防故障至关重要，但传统人工分类方法效率低且易受主观影响。

Method: 采用视觉变换器（ViT）神经网络，结合DinoV2的迁移学习和半监督学习，对7400多张晶圆缺陷图像进行分类。

Result: 在每类缺陷仅15张图像的情况下，分类准确率超过90%。

Conclusion: 该方法展示了在快速、灵活的平台无关分类工具中的潜力。

Abstract: Controlling defects in semiconductor processes is important for maintaining
yield, improving production cost, and preventing time-dependent critical
component failures. Electron beam-based imaging has been used as a tool to
survey wafers in the line and inspect for defects. However, manual
classification of images for these nano-scale defects is limited by time, labor
constraints, and human biases. In recent years, deep learning computer vision
algorithms have shown to be effective solutions for image-based inspection
applications in industry. This work proposes application of vision transformer
(ViT) neural networks for automatic defect classification (ADC) of scanning
electron microscope (SEM) images of wafer defects. We evaluated our proposed
methods on 300mm wafer semiconductor defect data from our fab in IBM Albany. We
studied 11 defect types from over 7400 total images and investigated the
potential of transfer learning of DinoV2 and semi-supervised learning for
improved classification accuracy and efficient computation. We were able to
achieve classification accuracies of over 90% with less than 15 images per
defect class. Our work demonstrates the potential to apply the proposed
framework for a platform agnostic in-house classification tool with faster
turnaround time and flexibility.

</details>


### [248] [Toward Reliable VLM: A Fine-Grained Benchmark and Framework for Exposure, Bias, and Inference in Korean Street Views](https://arxiv.org/abs/2506.03371)
*Xiaonan Wang,Bo Shao,Hansaem Kim*

Main category: cs.CV

TL;DR: 该论文介绍了KoreaGEO Bench，一个针对韩国街景的细粒度多模态地理定位基准数据集，填补了现有基准在细粒度、多模态和隐私评估方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前的地理定位基准存在粗粒度、语言偏见和缺乏多模态与隐私评估的问题，作者希望通过KoreaGEO Bench解决这些缺陷。

Method: 构建了包含1,080张高分辨率图像的韩国街景数据集，涵盖四种城市集群和九种地点类型，并提供了多上下文注释和两种风格的韩语字幕。采用三路径评估协议测试十种主流视觉语言模型。

Result: 结果显示模型的定位精度受输入模态影响，并存在对核心城市的结构性预测偏见。

Conclusion: KoreaGEO Bench为地理定位研究提供了更全面的评估工具，揭示了模态驱动的精度变化和预测偏见。

Abstract: Recent advances in vision-language models (VLMs) have enabled accurate
image-based geolocation, raising serious concerns about location privacy risks
in everyday social media posts. However, current benchmarks remain
coarse-grained, linguistically biased, and lack multimodal and privacy-aware
evaluations. To address these gaps, we present KoreaGEO Bench, the first
fine-grained, multimodal geolocation benchmark for Korean street views. Our
dataset comprises 1,080 high-resolution images sampled across four urban
clusters and nine place types, enriched with multi-contextual annotations and
two styles of Korean captions simulating real-world privacy exposure. We
introduce a three-path evaluation protocol to assess ten mainstream VLMs under
varying input modalities and analyze their accuracy, spatial bias, and
reasoning behavior. Results reveal modality-driven shifts in localization
precision and highlight structural prediction biases toward core cities.

</details>


### [249] [A Foundation Model for Spatial Proteomics](https://arxiv.org/abs/2506.03373)
*Muhammad Shaban,Yuzhou Chang,Huaying Qiu,Yao Yu Yeo,Andrew H. Song,Guillaume Jaume,Yuchen Wang,Luca L. Weishaupt,Tong Ding,Anurag Vaidya,Abdallah Lamane,Daniel Shao,Mohammed Zidane,Yunhao Bai,Paige McCallum,Shuli Luo,Wenrui Wu,Yang Wang,Precious Cramer,Chi Ngai Chan,Pierre Stephan,Johanna Schaffenrath,Jia Le Lee,Hendrik A. Michel,Caiwei Tian,Cristina Almagro-Perez,Sophia J. Wagner,Sharifa Sahai,Ming Y. Lu,Richard J. Chen,Andrew Zhang,Mark Edward M. Gonzales,Ahmad Makky,Jia-Ying Joey Lee,Hao Cheng,Nourhan El Ahmar,Sayed Matar,Maximilian Haist,Darci Phillips,Yuqi Tan,Garry P. Nolan,W. Richard Burack,Jacob D. Estes,Jonathan T. C. Liu,Toni K Choueiri,Neeraj Agarwal,Marc Barry,Scott J. Rodig,Long Phi Le,Georg Gerber,Christian M. Schürch,Fabian J. Theis,Youn H Kim,Joe Yeong,Sabina Signoretti,Brooke E. Howitt,Lit-Hsin Loo,Qin Ma,Sizun Jiang,Faisal Mahmood*

Main category: cs.CV

TL;DR: KRONOS是一个为空间蛋白质组学设计的基础模型，通过自监督学习在多尺度上学习生物有意义的表示，支持多种下游任务，并在多个任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 空间蛋白质组学在单细胞分辨率下映射蛋白质，但现有基础模型对其影响有限。KRONOS旨在填补这一空白。

Method: KRONOS通过自监督方式训练，覆盖175个蛋白质标记、16种组织类型和8种荧光成像平台，并引入关键架构适应高维多通道成像数据。

Result: KRONOS在11个独立队列中表现出色，支持细胞表型分析、区域分类和患者分层等任务，并实现高效数据处理。

Conclusion: KRONOS是一个灵活且可扩展的空间蛋白质组学工具，支持跨机构比较和图像逆向搜索。

Abstract: Foundation models have begun to transform image analysis by acting as
pretrained generalist backbones that can be adapted to many tasks even when
post-training data are limited, yet their impact on spatial proteomics, imaging
that maps proteins at single-cell resolution, remains limited. Here, we
introduce KRONOS, a foundation model built for spatial proteomics. KRONOS was
trained in a self-supervised manner on over 47 million image patches covering
175 protein markers, 16 tissue types, and 8 fluorescence-based imaging
platforms. We introduce key architectural adaptations to address the
high-dimensional, multi-channel, and heterogeneous nature of multiplex imaging.
We demonstrate that KRONOS learns biologically meaningful representations
across multiple scales, ranging from cellular and microenvironment to tissue
levels, enabling it to address diverse downstream tasks, including cell
phenotyping, region classification, and patient stratification. Evaluated
across 11 independent cohorts, KRONOS achieves state-of-the-art performance
across cell phenotyping, treatment response prediction, and retrieval tasks,
and is highly data-efficient. KRONOS also introduces the paradigm of
segmentation-free patch-level processing for efficient and scalable spatial
proteomics analysis, allowing cross-institutional comparisons, and as an image
reverse search engine for spatial patterns. Together, these results position
KRONOS as a flexible and scalable tool for spatial proteomics. The model is
publicly accessible at https://github.com/mahmoodlab/KRONOS.

</details>


### [250] [Cross-Modal Urban Sensing: Evaluating Sound-Vision Alignment Across Street-Level and Aerial Imagery](https://arxiv.org/abs/2506.03388)
*Pengyu Chen,Xiao Huang,Teng Fei,Sicheng Wang*

Main category: cs.CV

TL;DR: 研究探讨了城市声音与视觉场景的对应关系，通过多模态方法比较了不同视觉表示策略在捕捉声音语义上的效果，发现街景嵌入与声音对齐更强，而遥感分割在生态类别解释上更有效。


<details>
  <summary>Details</summary>
Motivation: 城市声景蕴含丰富的生态和社会信息，但其在大规模地理分析中的潜力尚未充分挖掘。

Method: 采用多模态方法，结合地理参考声音记录、街景和遥感影像，使用AST、CLIP、RemoteCLIP等模型提取嵌入和特征，评估跨模态相似性。

Result: 街景嵌入与声音对齐更强，遥感分割在生态类别解释上更有效。

Conclusion: 嵌入模型提供更好的语义对齐，分割方法则在视觉结构与声学生态之间提供可解释的联系，为多模态城市感知领域提供了新视角。

Abstract: Environmental soundscapes convey substantial ecological and social
information regarding urban environments; however, their potential remains
largely untapped in large-scale geographic analysis. In this study, we
investigate the extent to which urban sounds correspond with visual scenes by
comparing various visual representation strategies in capturing acoustic
semantics. We employ a multimodal approach that integrates geo-referenced sound
recordings with both street-level and remote sensing imagery across three major
global cities: London, New York, and Tokyo. Utilizing the AST model for audio,
along with CLIP and RemoteCLIP for imagery, as well as CLIPSeg and Seg-Earth OV
for semantic segmentation, we extract embeddings and class-level features to
evaluate cross-modal similarity. The results indicate that street view
embeddings demonstrate stronger alignment with environmental sounds compared to
segmentation outputs, whereas remote sensing segmentation is more effective in
interpreting ecological categories through a Biophony--Geophony--Anthrophony
(BGA) framework. These findings imply that embedding-based models offer
superior semantic alignment, while segmentation-based methods provide
interpretable links between visual structure and acoustic ecology. This work
advances the burgeoning field of multimodal urban sensing by offering novel
perspectives for incorporating sound into geospatial analysis.

</details>


### [251] [Temporal Vegetation Index-Based Unsupervised Crop Stress Detection via Eigenvector-Guided Contrastive Learning](https://arxiv.org/abs/2506.03394)
*Shafqaat Ahmad*

Main category: cs.CV

TL;DR: EigenCL是一种无监督对比学习框架，通过时间NDRE动态和生物特征分解实现作物胁迫早期检测，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 早期检测作物胁迫对减少产量损失和及时干预至关重要，但传统方法依赖标记数据或仅能检测可见症状，限制了可扩展性。

Method: 利用Sentinel-2 NDRE图像构建时间序列，通过RBF相似性矩阵和主特征向量定义胁迫感知相似性，进行对比嵌入学习。

Result: 学习到的嵌入形成生理学有意义的聚类，实现76%的早期胁迫检测（提前12天），下游分类准确率达95%（k-NN）和91%（逻辑回归）。

Conclusion: EigenCL提供了一种无需标记、可扩展的早期胁迫检测方法，适用于数据稀缺的农业环境。

Abstract: Early detection of crop stress is vital for minimizing yield loss and
enabling timely intervention in precision agriculture. Traditional approaches
using NDRE often detect stress only after visible symptoms appear or require
labeled datasets, limiting scalability. This study introduces EigenCL, a novel
unsupervised contrastive learning framework guided by temporal NDRE dynamics
and biologically grounded eigen decomposition. Using over 10,000 Sentinel-2
NDRE image patches from drought-affected Iowa cornfields, we constructed
five-point NDRE time series per patch and derived an RBF similarity matrix. The
principal eigenvector explaining 76% of the variance and strongly correlated (r
= 0.95) with raw NDRE values was used to define stress-aware similarity for
contrastive embedding learning. Unlike existing methods that rely on visual
augmentations, EigenCL pulls embeddings together based on biologically similar
stress trajectories and pushes apart divergent ones. The learned embeddings
formed physiologically meaningful clusters, achieving superior clustering
metrics (Silhouette: 0.748, DBI: 0.35) and enabling 76% early stress detection
up to 12 days before conventional NDRE thresholds. Downstream classification
yielded 95% k-NN and 91% logistic regression accuracy. Validation on an
independent 2023 Nebraska dataset confirmed generalizability without
retraining. EigenCL offers a label-free, scalable approach for early stress
detection that aligns with underlying plant physiology and is suitable for
real-world deployment in data-scarce agricultural environments.

</details>


### [252] [ViT-Split: Unleashing the Power of Vision Foundation Models via Efficient Splitting Heads](https://arxiv.org/abs/2506.03433)
*Yifan Li,Xin Li,Tianqin Li,Wenbin He,Yu Kong,Liu Ren*

Main category: cs.CV

TL;DR: ViT-Split是一种新的视觉基础模型（VFM）适配方法，通过分离VFM的提取器和适配器组件，减少训练时间和参数调整，同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有VFM适配器存在梯度反向传播过早和参数调整复杂的问题，且未能充分利用VFM的先验知识。

Method: 提出ViT-Split方法，将VFM分为低层特征提取器和任务特定适配器，并引入任务头和先验头，冻结VFM以减少训练复杂度。

Result: 在多个任务（如分割、检测、深度估计和视觉问答）上验证了ViT-Split的高效性，训练时间减少4倍，性能优于其他适配器。

Conclusion: ViT-Split通过优化VFM的适配方式，显著提升了效率和性能，为VFM的应用提供了新思路。

Abstract: Vision foundation models (VFMs) have demonstrated remarkable performance
across a wide range of downstream tasks. While several VFM adapters have shown
promising results by leveraging the prior knowledge of VFMs, we identify two
inefficiencies in these approaches. First, the interaction between
convolutional neural network (CNN) and VFM backbone triggers early layer
gradient backpropagation. Second, existing methods require tuning all
components, adding complexity. Besides, these adapters alter VFM features,
underutilizing the prior knowledge. To tackle these challenges, we propose a
new approach called ViT-Split, based on a key observation: the layers of
several VFMs, like DINOv2, can be divided into two distinct components: an
extractor for learning low-level features and an adapter for learning
task-specific features. Leveraging this insight, we eliminate the CNN branch
and introduce two heads, task head and prior head, to the frozen VFM. The task
head is designed to learn task-specific features, mitigating the early gradient
propagation issue. The prior head is used to leverage the multi-scale prior
features from the frozen VFM, reducing tuning parameters and overfitting.
Extensive experiments on various tasks (e.g., segmentation, detection, depth
estimation, and visual question answering) validate the effectiveness and
efficiency of ViT-Split. Specifically, ViT-Split reduces training time up to
$4\times$ while achieving comparable or even better results on ADE20K, compared
to other VFM adapters.

</details>


### [253] [Geometric Visual Fusion Graph Neural Networks for Multi-Person Human-Object Interaction Recognition in Videos](https://arxiv.org/abs/2506.03440)
*Tanqiu Qiao,Ruochen Li,Frederick W. B. Li,Yoshiki Kubotani,Shigeo Morishima,Hubert P. H. Shum*

Main category: cs.CV

TL;DR: 论文提出了一种名为GeoVis-GNN的几何视觉融合图神经网络，通过双注意力特征融合和相互依赖的实体图学习，有效结合视觉和几何特征，用于视频中的人-物交互识别。同时，作者还提出了一个多人物交互数据集MPHOI-120，以应对现实场景中的挑战。实验表明该方法在多种场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 人-物交互（HOI）识别需要同时理解视觉模式和几何关系，而现有方法在融合多模态特征时难以保留各自特性。作者认为通过建立实体特定表征再建模交互，可以更好地融合视觉和几何特征。

Method: 提出GeoVis-GNN，采用双注意力特征融合和相互依赖的实体图学习，从实体特定表征逐步构建高层次交互理解。

Result: 在多种HOI场景（如双人交互、单人活动、双手操作和复杂并发部分交互）中，该方法实现了最先进的性能。

Conclusion: GeoVis-GNN通过有效融合视觉和几何特征，显著提升了HOI识别的性能，同时MPHOI-120数据集为复杂现实场景提供了研究基础。

Abstract: Human-Object Interaction (HOI) recognition in videos requires understanding
both visual patterns and geometric relationships as they evolve over time.
Visual and geometric features offer complementary strengths. Visual features
capture appearance context, while geometric features provide structural
patterns. Effectively fusing these multimodal features without compromising
their unique characteristics remains challenging. We observe that establishing
robust, entity-specific representations before modeling interactions helps
preserve the strengths of each modality. Therefore, we hypothesize that a
bottom-up approach is crucial for effective multimodal fusion. Following this
insight, we propose the Geometric Visual Fusion Graph Neural Network
(GeoVis-GNN), which uses dual-attention feature fusion combined with
interdependent entity graph learning. It progressively builds from
entity-specific representations toward high-level interaction understanding. To
advance HOI recognition to real-world scenarios, we introduce the Concurrent
Partial Interaction Dataset (MPHOI-120). It captures dynamic multi-person
interactions involving concurrent actions and partial engagement. This dataset
helps address challenges like complex human-object dynamics and mutual
occlusions. Extensive experiments demonstrate the effectiveness of our method
across various HOI scenarios. These scenarios include two-person interactions,
single-person activities, bimanual manipulations, and complex concurrent
partial interactions. Our method achieves state-of-the-art performance.

</details>


### [254] [RefEdit: A Benchmark and Method for Improving Instruction-based Image Editing Model on Referring Expressions](https://arxiv.org/abs/2506.03448)
*Bimsara Pathiraja,Maitreya Patel,Shivam Singh,Yezhou Yang,Chitta Baral*

Main category: cs.CV

TL;DR: 论文提出RefEdit模型，用于解决复杂场景中多实体编辑问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在编辑复杂场景中的多实体时表现不佳，需要量化并改进这一问题。

Method: 引入RefEdit-Bench基准测试，并提出RefEdit模型，基于合成数据训练。

Result: RefEdit在仅2万样本训练下，性能优于基于数百万样本的基线模型，并在多个基准测试中达到最优。

Conclusion: RefEdit在复杂场景编辑任务中表现优异，且性能与闭源方法相当，数据与模型已开源。

Abstract: Despite recent advances in inversion and instruction-based image editing,
existing approaches primarily excel at editing single, prominent objects but
significantly struggle when applied to complex scenes containing multiple
entities. To quantify this gap, we first introduce RefEdit-Bench, a rigorous
real-world benchmark rooted in RefCOCO, where even baselines trained on
millions of samples perform poorly. To overcome this limitation, we introduce
RefEdit -- an instruction-based editing model trained on our scalable synthetic
data generation pipeline. Our RefEdit, trained on only 20,000 editing triplets,
outperforms the Flux/SD3 model-based baselines trained on millions of data.
Extensive evaluations across various benchmarks demonstrate that our model not
only excels in referring expression tasks but also enhances performance on
traditional benchmarks, achieving state-of-the-art results comparable to
closed-source methods. We release data \& checkpoint for reproducibility.

</details>


### [255] [The effects of using created synthetic images in computer vision training](https://arxiv.org/abs/2506.03449)
*John W. Smutny*

Main category: cs.CV

TL;DR: 论文探讨了使用Unreal Engine 4生成合成图像补充计算机视觉模型数据集的方法，验证了合成图像的有效性，并提供了衡量合成图像质量的实现方案。


<details>
  <summary>Details</summary>
Motivation: 解决真实图像数据稀缺、成本高及潜在毒化问题，提供廉价、可复现且灵活的数据集生成方法。

Method: 通过UE4生成合成图像，测试其在两种分类任务（猫狗分类和焊接缺陷检测）中对VGG16和MobileNetV3-small模型性能的影响，并利用预训练模型评估合成图像质量。

Result: 合成图像补充60%以上时，测试与训练准确率差距缩小至1-2%；真实图像仅需10%即可显著降低分类错误率。

Conclusion: 合成图像可显著减少对真实数据的依赖，为数据稀缺项目提供高效解决方案。

Abstract: This paper investigates how rendering engines, like Unreal Engine 4 (UE), can
be used to create synthetic images to supplement datasets for deep computer
vision (CV) models in image abundant and image limited use cases. Using
rendered synthetic images from UE can provide developers and businesses with a
method of accessing nearly unlimited, reproducible, agile, and cheap training
sets for their customers and applications without the threat of poisoned images
from the internet or the cost of collecting them. The validity of these
generated images are examined by testing the change in model test accuracy in
two different sized CV models across two binary classification cases (Cat vs
Dog and Weld Defect Detection). In addition, this paper provides an
implementation of how to measure the quality of synthetic images by using
pre-trained CV models as auditors. Results imply that for large (VGG16) and
small (MobileNetV3-small) parameter deep CV models, adding >60% additional
synthetic images to a real image dataset during model training can narrow the
test-training accuracy gap to ~1-2% without a conclusive effect on test
accuracy compared to using real world images alone. Likewise, adding <10%
additional real training images to synthetic only training sets decreased the
classification error rate in half, then decreasing further when adding more
real training images. For these cases tested, using synthetic images from
rendering engines allow researchers to only use 10% of their real images during
training, compared to the traditional 50-70%. This research serves as an
example of how to create synthetic images, guidelines on how to use the images,
potential restrictions and possible performance improvements for data-scarce
projects.

</details>


### [256] [RoNFA: Robust Neural Field-based Approach for Few-Shot Image Classification with Noisy Labels](https://arxiv.org/abs/2506.03461)
*Nan Xiang,Lifeng Xing,Dequan Jin*

Main category: cs.CV

TL;DR: 本文提出了一种鲁棒的神经场方法（RoNFA），用于带有噪声标签的小样本图像分类，显著提升了模型在标签错误情况下的鲁棒性和分类准确性。


<details>
  <summary>Details</summary>
Motivation: 小样本学习中标签样本稀缺，标签错误会显著降低分类准确性。因此，提升模型在标签错误情况下的鲁棒性至关重要。

Method: RoNFA包含两个神经场，分别用于特征和类别表示。类别表示场中的神经元通过软聚类生成，并在预测阶段根据神经元激活调整感受野范围。

Result: 实验表明，RoNFA在三种不同标签噪声的真实数据集上显著优于现有方法，甚至在噪声标签下的准确性超过干净标签训练的先进方法。

Conclusion: RoNFA具有卓越的小样本学习能力和对标签噪声的强鲁棒性，适用于实际场景中的小样本分类任务。

Abstract: In few-shot learning (FSL), the labeled samples are scarce. Thus, label
errors can significantly reduce classification accuracy. Since label errors are
inevitable in realistic learning tasks, improving the robustness of the model
in the presence of label errors is critical. This paper proposes a new robust
neural field-based image approach (RoNFA) for few-shot image classification
with noisy labels. RoNFA consists of two neural fields for feature and category
representation. They correspond to the feature space and category set. Each
neuron in the field for category representation (FCR) has a receptive field
(RF) on the field for feature representation (FFR) centered at the
representative neuron for its category generated by soft clustering. In the
prediction stage, the range of these receptive fields adapts according to the
neuronal activation in FCR to ensure prediction accuracy. These learning
strategies provide the proposed model with excellent few-shot learning
capability and strong robustness against label noises. The experimental results
on real-world FSL datasets with three different types of label noise
demonstrate that the proposed method significantly outperforms state-of-the-art
FSL methods. Its accuracy obtained in the presence of noisy labels even
surpasses the results obtained by state-of-the-art FSL methods trained on clean
support sets, indicating its strong robustness against noisy labels.

</details>


### [257] [MamFusion: Multi-Mamba with Temporal Fusion for Partially Relevant Video Retrieval](https://arxiv.org/abs/2506.03473)
*Xinru Ying,Jiaqi Mo,Jingyang Lin,Canghong Jin,Fangfang Wang,Lina Wei*

Main category: cs.CV

TL;DR: 本文提出了一种名为MamFusion的多Mamba模块框架，用于解决部分相关视频检索（PRVR）任务中的长序列视频内容理解问题，通过时间融合技术提升检索效果。


<details>
  <summary>Details</summary>
Motivation: 部分相关视频检索（PRVR）是一个具有挑战性的任务，需要解决长序列视频中的信息冗余问题。

Method: 利用Mamba模块的长时状态空间建模能力和线性可扩展性，设计了多Mamba模块的时间融合框架（MamFusion），并引入Temporal T-to-V Fusion和Temporal V-to-T Fusion来显式建模文本查询与视频片段之间的时间关系。

Result: 在大规模数据集上的实验表明，MamFusion在检索效果上达到了最先进的性能。

Conclusion: MamFusion框架通过有效捕捉长时视频内容的状态相关性，并将其融入文本-视频相关性理解中，显著提升了PRVR任务的检索性能。

Abstract: Partially Relevant Video Retrieval (PRVR) is a challenging task in the domain
of multimedia retrieval. It is designed to identify and retrieve untrimmed
videos that are partially relevant to the provided query. In this work, we
investigate long-sequence video content understanding to address information
redundancy issues. Leveraging the outstanding long-term state space modeling
capability and linear scalability of the Mamba module, we introduce a
multi-Mamba module with temporal fusion framework (MamFusion) tailored for PRVR
task. This framework effectively captures the state-relatedness in long-term
video content and seamlessly integrates it into text-video relevance
understanding, thereby enhancing the retrieval process. Specifically, we
introduce Temporal T-to-V Fusion and Temporal V-to-T Fusion to explicitly model
temporal relationships between text queries and video moments, improving
contextual awareness and retrieval accuracy. Extensive experiments conducted on
large-scale datasets demonstrate that MamFusion achieves state-of-the-art
performance in retrieval effectiveness. Code is available at the link:
https://github.com/Vision-Multimodal-Lab-HZCU/MamFusion.

</details>


### [258] [Heterogeneous Skeleton-Based Action Representation Learning](https://arxiv.org/abs/2506.03481)
*Hongsong Wang,Xiaoyan Ma,Jidong Kuang,Jie Gui*

Main category: cs.CV

TL;DR: 该论文提出了一种处理异构骨架数据的框架，用于基于骨架的人体动作识别，包括异构骨架处理和统一表示学习两部分。


<details>
  <summary>Details</summary>
Motivation: 由于骨架数据来源不同，其关节维度和拓扑结构存在异质性，而现有方法仅针对同质骨架设计模型，忽略了这一特性。

Method: 通过辅助网络将二维骨架转换为三维骨架，并利用骨架特定提示构建统一骨架；同时设计语义运动编码模块。统一表示学习模块使用共享主干网络处理异构骨架。

Result: 在NTU-60、NTU-120和PKU-MMD II数据集上的实验验证了方法的有效性。

Conclusion: 该方法适用于不同人形结构的机器人动作识别。

Abstract: Skeleton-based human action recognition has received widespread attention in
recent years due to its diverse range of application scenarios. Due to the
different sources of human skeletons, skeleton data naturally exhibit
heterogeneity. The previous works, however, overlook the heterogeneity of human
skeletons and solely construct models tailored for homogeneous skeletons. This
work addresses the challenge of heterogeneous skeleton-based action
representation learning, specifically focusing on processing skeleton data that
varies in joint dimensions and topological structures. The proposed framework
comprises two primary components: heterogeneous skeleton processing and unified
representation learning. The former first converts two-dimensional skeleton
data into three-dimensional skeleton via an auxiliary network, and then
constructs a prompted unified skeleton using skeleton-specific prompts. We also
design an additional modality named semantic motion encoding to harness the
semantic information within skeletons. The latter module learns a unified
action representation using a shared backbone network that processes different
heterogeneous skeletons. Extensive experiments on the NTU-60, NTU-120, and
PKU-MMD II datasets demonstrate the effectiveness of our method in various
tasks of action understanding. Our approach can be applied to action
recognition in robots with different humanoid structures.

</details>


### [259] [CHIME: Conditional Hallucination and Integrated Multi-scale Enhancement for Time Series Diffusion Model](https://arxiv.org/abs/2506.03502)
*Yuxuan Chen,Haipeng Xie*

Main category: cs.CV

TL;DR: CHIME是一个用于时间序列扩散模型的条件幻觉和多尺度增强框架，通过多尺度分解和自适应集成解决了多尺度特征对齐和生成能力问题，并在少样本场景中表现出优异的生成泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在时间序列任务中面临多尺度特征对齐和跨实体、长时间尺度的生成能力挑战。

Method: 提出CHIME框架，采用多尺度分解和自适应集成，并引入特征幻觉模块以实现时间特征迁移。

Result: 在公开的真实数据集上，CHIME实现了最先进的性能，并在少样本场景中表现出优异的生成泛化能力。

Conclusion: CHIME通过多尺度特征对齐和条件幻觉模块，显著提升了时间序列扩散模型的生成能力和泛化性能。

Abstract: The denoising diffusion probabilistic model has become a mainstream
generative model, achieving significant success in various computer vision
tasks. Recently, there has been initial exploration of applying diffusion
models to time series tasks. However, existing studies still face challenges in
multi-scale feature alignment and generative capabilities across different
entities and long-time scales. In this paper, we propose CHIME, a conditional
hallucination and integrated multi-scale enhancement framework for time series
diffusion models. By employing multi-scale decomposition and adaptive
integration, CHIME captures the decomposed features of time series, achieving
in-domain distribution alignment between generated and original samples. In
addition, we introduce a feature hallucination module in the conditional
denoising process, enabling the transfer of temporal features through the
training of category-independent transformation layers. Experimental results on
publicly available real-world datasets demonstrate that CHIME achieves
state-of-the-art performance and exhibits excellent generative generalization
capabilities in few-shot scenarios.

</details>


### [260] [EDCFlow: Exploring Temporally Dense Difference Maps for Event-based Optical Flow Estimation](https://arxiv.org/abs/2506.03512)
*Daikun Liu,Lei Cheng,Teng Wang,changyin Sun*

Main category: cs.CV

TL;DR: EDCFlow是一种轻量级事件光流网络，通过结合时间密集特征差异和成本体积，实现高分辨率光流估计，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于事件的光流估计方法存在计算冗余和高分辨率扩展性问题，需要更高效且可扩展的解决方案。

Method: 提出EDCFlow网络，利用注意力机制的多尺度时间特征差异层高效捕获高分辨率运动模式，并自适应融合高低分辨率运动特征。

Result: EDCFlow在性能和复杂度上优于现有方法，具有更好的泛化能力，可作为RAFT类方法的插件模块。

Conclusion: EDCFlow通过高效特征融合和轻量化设计，实现了高质量的高分辨率光流估计，为事件光流领域提供了新思路。

Abstract: Recent learning-based methods for event-based optical flow estimation utilize
cost volumes for pixel matching but suffer from redundant computations and
limited scalability to higher resolutions for flow refinement. In this work, we
take advantage of the complementarity between temporally dense feature
differences of adjacent event frames and cost volume and present a lightweight
event-based optical flow network (EDCFlow) to achieve high-quality flow
estimation at a higher resolution. Specifically, an attention-based multi-scale
temporal feature difference layer is developed to capture diverse motion
patterns at high resolution in a computation-efficient manner. An adaptive
fusion of high-resolution difference motion features and low-resolution
correlation motion features is performed to enhance motion representation and
model generalization. Notably, EDCFlow can serve as a plug-and-play refinement
module for RAFT-like event-based methods to enhance flow details. Extensive
experiments demonstrate that EDCFlow achieves better performance with lower
complexity compared to existing methods, offering superior generalization.

</details>


### [261] [DenseDPO: Fine-Grained Temporal Preference Optimization for Video Diffusion Models](https://arxiv.org/abs/2506.03517)
*Ziyi Wu,Anil Kag,Ivan Skorokhodov,Willi Menapace,Ashkan Mirzaei,Igor Gilitschenski,Sergey Tulyakov,Aliaksandr Siarohin*

Main category: cs.CV

TL;DR: DenseDPO改进Direct Preference Optimization (DPO)，通过生成对齐的视频对和分段标注偏好，减少运动偏差并提高标注效率，同时支持自动标注。


<details>
  <summary>Details</summary>
Motivation: 传统DPO方法在视频生成中存在运动偏差和标注效率低的问题，DenseDPO旨在解决这些问题。

Method: 1. 通过去噪生成对齐的视频对；2. 在短片段上标注偏好；3. 利用VLMs自动标注。

Result: DenseDPO用三分之一的数据显著提升运动生成效果，同时保持文本对齐、视觉质量和时间一致性。

Conclusion: DenseDPO有效解决了DPO的局限性，支持高效自动标注，性能接近人工标注。

Abstract: Direct Preference Optimization (DPO) has recently been applied as a
post-training technique for text-to-video diffusion models. To obtain training
data, annotators are asked to provide preferences between two videos generated
from independent noise. However, this approach prohibits fine-grained
comparisons, and we point out that it biases the annotators towards low-motion
clips as they often contain fewer visual artifacts. In this work, we introduce
DenseDPO, a method that addresses these shortcomings by making three
contributions. First, we create each video pair for DPO by denoising corrupted
copies of a ground truth video. This results in aligned pairs with similar
motion structures while differing in local details, effectively neutralizing
the motion bias. Second, we leverage the resulting temporal alignment to label
preferences on short segments rather than entire clips, yielding a denser and
more precise learning signal. With only one-third of the labeled data, DenseDPO
greatly improves motion generation over vanilla DPO, while matching it in text
alignment, visual quality, and temporal consistency. Finally, we show that
DenseDPO unlocks automatic preference annotation using off-the-shelf Vision
Language Models (VLMs): GPT accurately predicts segment-level preferences
similar to task-specifically fine-tuned video reward models, and DenseDPO
trained on these labels achieves performance close to using human labels.

</details>


### [262] [Target Semantics Clustering via Text Representations for Robust Universal Domain Adaptation](https://arxiv.org/abs/2506.03521)
*Weinan He,Zilei Wang,Yixin Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉语言模型的通用域适应方法（TASC），通过在语义离散的文本表示空间中搜索语义中心，简化了域对齐算法，并提出了UniMS评分函数用于检测开放集样本。实验表明该方法在多种类别偏移场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 通用域适应（UniDA）面临的主要挑战是在域偏移和未知类别偏移下识别共同类样本并对其对齐。现有方法在连续图像表示空间中获取语义中心，导致算法复杂且不鲁棒。

Method: 提出TASC方法，分两阶段：1）在冻结编码器下，通过贪婪搜索寻找最优文本嵌入表示目标语义；2）固定搜索结果，基于梯度下降优化编码器，实现域对齐和私有类聚类。同时提出UniMS评分函数检测开放集样本。

Result: 在四个基准测试上的广泛实验表明，该方法在四种类别偏移场景下均表现优异，达到了最先进的性能。

Conclusion: 基于文本表示空间的语义中心搜索简化了域对齐算法，提升了鲁棒性，UniMS评分函数有效检测开放集样本，为通用域适应提供了高效解决方案。

Abstract: Universal Domain Adaptation (UniDA) focuses on transferring source domain
knowledge to the target domain under both domain shift and unknown category
shift. Its main challenge lies in identifying common class samples and aligning
them. Current methods typically obtain target domain semantics centers from an
unconstrained continuous image representation space. Due to domain shift and
the unknown number of clusters, these centers often result in complex and less
robust alignment algorithm. In this paper, based on vision-language models, we
search for semantic centers in a semantically meaningful and discrete text
representation space. The constrained space ensures almost no domain bias and
appropriate semantic granularity for these centers, enabling a simple and
robust adaptation algorithm. Specifically, we propose TArget Semantics
Clustering (TASC) via Text Representations, which leverages information
maximization as a unified objective and involves two stages. First, with the
frozen encoders, a greedy search-based framework is used to search for an
optimal set of text embeddings to represent target semantics. Second, with the
search results fixed, encoders are refined based on gradient descent,
simultaneously achieving robust domain alignment and private class clustering.
Additionally, we propose Universal Maximum Similarity (UniMS), a scoring
function tailored for detecting open-set samples in UniDA. Experimentally, we
evaluate the universality of UniDA algorithms under four category shift
scenarios. Extensive experiments on four benchmarks demonstrate the
effectiveness and robustness of our method, which has achieved state-of-the-art
performance.

</details>


### [263] [Video-Skill-CoT: Skill-based Chain-of-Thoughts for Domain-Adaptive Video Reasoning](https://arxiv.org/abs/2506.03525)
*Daeun Lee,Jaehong Yoon,Jaemin Cho,Mohit Bansal*

Main category: cs.CV

TL;DR: Video-SKoT框架通过自动构建技能感知的CoT监督，提升了领域自适应视频推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在适应不同视频内容的领域特定技能（如事件检测、空间关系理解、情感理解）时表现不佳。

Method: 1. 构建基于技能的CoT标注：从训练问题中提取领域相关推理技能，聚类为共享技能分类法，并为每个视频-问题对创建多步CoT理由。2. 引入技能特定专家学习框架，每个专家模块专注于一组推理技能，并使用轻量级适配器进行训练。

Result: 在三个视频理解基准测试中，Video-SKoT表现优于基线方法。

Conclusion: Video-SKoT通过技能感知的CoT监督和专家学习框架，显著提升了领域自适应视频推理能力。

Abstract: Recent advances in Chain-of-Thought (CoT) reasoning have improved complex
video understanding, but existing methods often struggle to adapt to
domain-specific skills (e.g., event detection, spatial relation understanding,
emotion understanding) over various video content. To address this, we propose
Video-Skill-CoT (a.k.a. Video-SKoT), a framework that automatically constructs
and leverages skill-aware CoT supervisions for domain-adaptive video reasoning.
First, we construct skill-based CoT annotations: we extract domain-relevant
reasoning skills from training questions, cluster them into a shared skill
taxonomy, and create detailed multi-step CoT rationale tailored to each
video-question pair for training. Second, we introduce a skill-specific expert
learning framework. Each expert module specializes in a subset of reasoning
skills and is trained with lightweight adapters using the collected CoT
supervision. We demonstrate the effectiveness of the proposed approach on three
video understanding benchmarks, where Video-SKoT consistently outperforms
strong baselines. We also provide in-depth analyses on comparing different CoT
annotation pipelines and learned skills over multiple video domains.

</details>


### [264] [Robust Neural Rendering in the Wild with Asymmetric Dual 3D Gaussian Splatting](https://arxiv.org/abs/2506.03538)
*Chengqi Li,Zhihao Shi,Yangdi Lu,Wenbo He,Xiangyu Xu*

Main category: cs.CV

TL;DR: 提出了一种名为Asymmetric Dual 3DGS的新框架，通过并行训练两个3D高斯溅射模型并引入一致性约束，减少重建中的视觉伪影。


<details>
  <summary>Details</summary>
Motivation: 解决野外图像3D重建中因光照条件和瞬态干扰导致的低质量训练数据问题。

Method: 使用两个3DGS模型并行训练，结合一致性约束和互补掩码策略，防止模型陷入相似错误模式。

Result: 在真实数据集上表现优于现有方法，同时保持高效性。

Conclusion: 该方法通过不对称训练和动态EMA代理，显著提升了重建的稳定性和一致性。

Abstract: 3D reconstruction from in-the-wild images remains a challenging task due to
inconsistent lighting conditions and transient distractors. Existing methods
typically rely on heuristic strategies to handle the low-quality training data,
which often struggle to produce stable and consistent reconstructions,
frequently resulting in visual artifacts. In this work, we propose Asymmetric
Dual 3DGS, a novel framework that leverages the stochastic nature of these
artifacts: they tend to vary across different training runs due to minor
randomness. Specifically, our method trains two 3D Gaussian Splatting (3DGS)
models in parallel, enforcing a consistency constraint that encourages
convergence on reliable scene geometry while suppressing inconsistent
artifacts. To prevent the two models from collapsing into similar failure modes
due to confirmation bias, we introduce a divergent masking strategy that
applies two complementary masks: a multi-cue adaptive mask and a
self-supervised soft mask, which leads to an asymmetric training process of the
two models, reducing shared error modes. In addition, to improve the efficiency
of model training, we introduce a lightweight variant called Dynamic EMA Proxy,
which replaces one of the two models with a dynamically updated Exponential
Moving Average (EMA) proxy, and employs an alternating masking strategy to
preserve divergence. Extensive experiments on challenging real-world datasets
demonstrate that our method consistently outperforms existing approaches while
achieving high efficiency. Codes and trained models will be released.

</details>


### [265] [WIFE-Fusion:Wavelet-aware Intra-inter Frequency Enhancement for Multi-model Image Fusion](https://arxiv.org/abs/2506.03555)
*Tianpei Zhang,Jufeng Zhao,Yiming Zhu,Guangmang Cui*

Main category: cs.CV

TL;DR: 提出了一种基于频域交互的多模态图像融合框架WIFE-Fusion，通过频域自注意力机制和频域间交互提升融合效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法常忽略频域特征探索和交互关系，导致融合效果受限。

Method: 采用Intra-Frequency Self-Attention (IFSA)和Inter-Frequency Interaction (IFI)机制，分别提取频域特征并增强交互。

Result: 在五个数据集和三个多模态融合任务中表现优于现有方法。

Conclusion: WIFE-Fusion通过频域交互实现了更精确的特征提取和融合，效果显著。

Abstract: Multimodal image fusion effectively aggregates information from diverse
modalities, with fused images playing a crucial role in vision systems.
However, existing methods often neglect frequency-domain feature exploration
and interactive relationships. In this paper, we propose wavelet-aware
Intra-inter Frequency Enhancement Fusion (WIFE-Fusion), a multimodal image
fusion framework based on frequency-domain components interactions. Its core
innovations include: Intra-Frequency Self-Attention (IFSA) that leverages
inherent cross-modal correlations and complementarity through interactive
self-attention mechanisms to extract enriched frequency-domain features, and
Inter-Frequency Interaction (IFI) that enhances enriched features and filters
latent features via combinatorial interactions between heterogeneous
frequency-domain components across modalities. These processes achieve precise
source feature extraction and unified modeling of feature
extraction-aggregation. Extensive experiments on five datasets across three
multimodal fusion tasks demonstrate WIFE-Fusion's superiority over current
specialized and unified fusion methods. Our code is available at
https://github.com/Lmmh058/WIFE-Fusion.

</details>


### [266] [DiagNet: Detecting Objects using Diagonal Constraints on Adjacency Matrix of Graph Neural Network](https://arxiv.org/abs/2506.03571)
*Chong Hyun Lee,Kibae Lee*

Main category: cs.CV

TL;DR: DaigNet是一种新的目标检测方法，通过在图卷积网络（GCN）的邻接矩阵上应用对角线约束来检测物体边界框，无需设计锚框。实验表明其性能优于多个YOLO版本。


<details>
  <summary>Details</summary>
Motivation: 传统目标检测方法需要设计锚框，而DaigNet通过GCN的对角线约束避免了这一复杂步骤，简化了检测流程。

Method: 提出两种基于硬约束和软约束的对角化算法，以及两种使用对角线约束和互补约束的损失函数。检测头采用YOLO模型。

Result: 在Pascal VOC上mAP50比YOLOv1高7.5%，在MS COCO上mAP分别比YOLOv3u、YOLOv5u和YOLOv8高5.1%、3.7%和2.9%。

Conclusion: DaigNet通过GCN的对角线约束实现了高效的目标检测，性能显著优于传统方法。

Abstract: We propose DaigNet, a new approach to object detection with which we can
detect an object bounding box using diagonal constraints on adjacency matrix of
a graph convolutional network (GCN). We propose two diagonalization algorithms
based on hard and soft constraints on adjacency matrix and two loss functions
using diagonal constraint and complementary constraint. The DaigNet eliminates
the need for designing a set of anchor boxes commonly used. To prove
feasibility of our novel detector, we adopt detection head in YOLO models.
Experiments show that the DiagNet achieves 7.5% higher mAP50 on Pascal VOC than
YOLOv1. The DiagNet also shows 5.1% higher mAP on MS COCO than YOLOv3u, 3.7%
higher mAP than YOLOv5u, and 2.9% higher mAP than YOLOv8.

</details>


### [267] [ViTSGMM: A Robust Semi-Supervised Image Recognition Network Using Sparse Labels](https://arxiv.org/abs/2506.03582)
*Rui Yann,Xianglei Xing*

Main category: cs.CV

TL;DR: ViTSGMM是一种高效的半监督学习图像识别网络，通过优化特征表示与目标类别间的互信息，构建分层混合密度分类决策机制，显著提升了在有限标注数据下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖复杂训练技术和架构，且在标注数据极少时泛化能力不足。ViTSGMM旨在解决这些问题。

Method: 构建分层混合密度分类决策机制，优化互信息以压缩冗余信息并保留关键判别成分。

Result: 在STL-10和CIFAR-10/100数据集上，使用极少标注样本即达到最先进性能。同时发现并解决了STL-10数据集中的数据泄漏问题。

Conclusion: ViTSGMM通过高效半监督学习机制，显著提升了图像识别性能，并揭示了数据集的潜在问题。

Abstract: We present ViTSGMM, an image recognition network that leverages
semi-supervised learning in a highly efficient manner. Existing works often
rely on complex training techniques and architectures, while their
generalization ability when dealing with extremely limited labeled data remains
to be improved. To address these limitations, we construct a hierarchical
mixture density classification decision mechanism by optimizing mutual
information between feature representations and target classes, compressing
redundant information while retaining crucial discriminative components.
Experimental results demonstrate that our method achieves state-of-the-art
performance on STL-10 and CIFAR-10/100 datasets when using negligible labeled
samples. Notably, this paper also reveals a long-overlooked data leakage issue
in the STL-10 dataset for semi-supervised learning tasks and removes duplicates
to ensure the reliability of experimental results. Code available at
https://github.com/Shu1L0n9/ViTSGMM.

</details>


### [268] [A Large-Scale Referring Remote Sensing Image Segmentation Dataset and Benchmark](https://arxiv.org/abs/2506.03583)
*Zhigang Yang,Huiguang Yao,Linmao Tian,Xuezhi Zhao,Qiang Li,Qi Wang*

Main category: cs.CV

TL;DR: 论文提出了NWPU-Refer数据集和MRSNet模型，解决了遥感图像分割中数据集和模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有遥感图像分割数据集在分辨率、场景多样性和类别覆盖上存在不足，限制了模型的泛化和实际应用。

Method: 提出了多尺度参考分割网络（MRSNet），包含Intra-scale Feature Interaction Module（IFIM）和Hierarchical Feature Interaction Module（HFIM）。

Result: 在NWPU-Refer数据集上，MRSNet在多项评估指标中达到最佳性能。

Conclusion: NWPU-Refer和MRSNet为遥感图像分割领域提供了新的数据集和模型，推动了该领域的发展。

Abstract: Referring Remote Sensing Image Segmentation is a complex and challenging task
that integrates the paradigms of computer vision and natural language
processing. Existing datasets for RRSIS suffer from critical limitations in
resolution, scene diversity, and category coverage, which hinders the
generalization and real-world applicability of refer segmentation models. To
facilitate the development of this field, we introduce NWPU-Refer, the largest
and most diverse RRSIS dataset to date, comprising 15,003 high-resolution
images (1024-2048px) spanning 30+ countries with 49,745 annotated targets
supporting single-object, multi-object, and non-object segmentation scenarios.
Additionally, we propose the Multi-scale Referring Segmentation Network
(MRSNet), a novel framework tailored for the unique demands of RRSIS. MRSNet
introduces two key innovations: (1) an Intra-scale Feature Interaction Module
(IFIM) that captures fine-grained details within each encoder stage, and (2) a
Hierarchical Feature Interaction Module (HFIM) to enable seamless cross-scale
feature fusion, preserving spatial integrity while enhancing discriminative
power. Extensive experiments conducte on the proposed NWPU-Refer dataset
demonstrate that MRSNet achieves state-of-the-art performance across multiple
evaluation metrics, validating its effectiveness. The dataset and code are
publicly available at https://github.com/CVer-Yang/NWPU-Refer.

</details>


### [269] [BiMa: Towards Biases Mitigation for Text-Video Retrieval via Scene Element Guidance](https://arxiv.org/abs/2506.03589)
*Huy Le,Nhat Chung,Tung Kieu,Anh Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: BiMa框架通过视觉和文本去偏方法提升文本-视频检索性能，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决文本-视频检索系统中因数据集视觉-语言偏差导致的关键细节被忽略的问题。

Method: 生成场景元素增强视频嵌入（视觉去偏），并解耦文本特征为内容和偏差部分（文本去偏）。

Result: 在五个主要TVR基准测试中表现优异，并在分布外检索任务中验证了去偏能力。

Conclusion: BiMa有效缓解了视觉和文本偏差，提升了检索性能。

Abstract: Text-video retrieval (TVR) systems often suffer from visual-linguistic biases
present in datasets, which cause pre-trained vision-language models to overlook
key details. To address this, we propose BiMa, a novel framework designed to
mitigate biases in both visual and textual representations. Our approach begins
by generating scene elements that characterize each video by identifying
relevant entities/objects and activities. For visual debiasing, we integrate
these scene elements into the video embeddings, enhancing them to emphasize
fine-grained and salient details. For textual debiasing, we introduce a
mechanism to disentangle text features into content and bias components,
enabling the model to focus on meaningful content while separately handling
biased information. Extensive experiments and ablation studies across five
major TVR benchmarks (i.e., MSR-VTT, MSVD, LSMDC, ActivityNet, and DiDeMo)
demonstrate the competitive performance of BiMa. Additionally, the model's bias
mitigation capability is consistently validated by its strong results on
out-of-distribution retrieval tasks.

</details>


### [270] [Resolving Task Objective Conflicts in Unified Multimodal Understanding and Generation via Task-Aware Mixture-of-Experts](https://arxiv.org/abs/2506.03591)
*Jiaxing Zhang,Xinyi Zeng,Hao Tang*

Main category: cs.CV

TL;DR: 论文提出了一种名为UTAMoE的新方法，通过解耦自回归（AR）模型的内部组件，解决多模态大语言模型（MLLMs）中任务目标冲突的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在理解和生成任务之间存在目标冲突，导致性能下降，现有方法未能从根本上解决这一问题。

Method: 设计了UTAMoE框架，通过任务感知的混合专家（MoE）层解耦AR模块，并采用两阶段训练策略增强任务区分。

Result: 实验表明，UTAMoE有效缓解了任务目标冲突，在多模态基准测试中取得了最先进的性能。

Conclusion: UTAMoE通过解耦和任务感知优化，显著提升了多模态大语言模型的性能。

Abstract: Unified multimodal large language models (MLLMs) based on end-to-end
autoregressive (AR) transformers effectively integrate both understanding and
generation tasks within a single framework. However, intrinsic Task Objective
Conflicts between high-level semantic abstraction in understanding and
fine-grained detail preservation in generation pose significant challenges,
often leading to suboptimal trade-offs and task interference. Existing
solutions, such as decoupling shared visual encoders, fall short of
fundamentally resolving these conflicts due to inherent AR architecture. In
this paper, we propose a novel approach that decouples internal components of
AR to resolve task objective conflicts. Specifically, we design UTAMoE, a
Unified Task-Aware Mixture-of-Experts (MoE) framework that decouples internal
AR modules via a Task-Aware MoE Layer to create task-specific optimization
subpaths. To enhance task differentiation while maintaining overall
coordination, we introduce a novel Two-Stage Training Strategy. Extensive
experiments on multimodal benchmarks demonstrate that UTAMoE mitigates task
objective conflicts, achieving state-of-the-art performance across various
tasks. Visualizations and ablation studies further validate the effectiveness
of our approach.

</details>


### [271] [ControlThinker: Unveiling Latent Semantics for Controllable Image Generation through Visual Reasoning](https://arxiv.org/abs/2506.03596)
*Feng Han,Yang Jiao,Shaoxiang Chen,Junhao Xu,Jingjing Chen,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: ControlThinker提出了一种新颖的框架，通过增强多模态语言模型的视觉推理能力，填补文本提示与目标图像之间的语义鸿沟，提升生成图像的质量和语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在稀疏语义的文本提示与目标图像之间存在语义鸿沟，且过度依赖低层控制信号。

Method: 采用“理解后生成”范式，利用MLLM挖掘控制图像的潜在语义以丰富文本提示，并通过基于度量的输出奖励模型（ORM）选择最优推理轨迹。

Result: 实验证明ControlThinker有效缩小了文本提示与目标图像的语义差距，提升了视觉质量和语义一致性。

Conclusion: ControlThinker通过增强语义理解和优化推理轨迹，显著改善了可控图像生成的性能。

Abstract: The field of controllable image generation has seen significant advancements,
with various architectures improving generation layout consistency with control
signals. However, contemporary methods still face challenges in bridging the
semantic gap between input text prompts with sparse semantics and the target
images, often over-relying on low-level control signals to infer regional
details. To address this challenge, we propose ControlThinker, a novel
framework that employs a "comprehend-then-generate" paradigm. Firstly, by
incentivizing the visual reasoning capability of a MLLM, latent semantics from
control images are mined to enrich text prompts. This enriched semantic
understanding then seamlessly aids in image generation without the need for
additional complex modifications. To further tackle the uncertainty arising
from the ambiguity of control images, we encourage broader exploration of
reasoning trajectories and select the optimal one using a metric-based output
reward model (ORM). Extensive experimental results demonstrate that
ControlThinker effectively mitigates the semantic gap between raw text prompts
and target images, resulting in improved visual quality and semantic
consistency across a wide range of benchmarks. The code and models are
available at https://github.com/Maplebb/ControlThinker.

</details>


### [272] [Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision](https://arxiv.org/abs/2506.03605)
*Tomoya Yoshida,Shuhei Kurita,Taichi Nishimura,Shinsuke Mori*

Main category: cs.CV

TL;DR: 提出了一种利用大规模视频数据集提取多样化操作轨迹的框架，并基于视觉和点云语言模型生成轨迹。


<details>
  <summary>Details</summary>
Motivation: 开发交互式机器人需要大量多样化的操作演示数据，但收集这些数据几乎不可行。

Method: 利用Exo-Ego4D视频数据集提取操作轨迹，结合文本描述，开发基于视觉和点云的语言模型生成轨迹。

Result: 在HOT3D数据集上验证了模型能成功生成有效的物体轨迹。

Conclusion: 为从第一视角生成6DoF操作轨迹的新任务提供了数据集和基线模型。

Abstract: Learning to use tools or objects in common scenes, particularly handling them
in various ways as instructed, is a key challenge for developing interactive
robots. Training models to generate such manipulation trajectories requires a
large and diverse collection of detailed manipulation demonstrations for
various objects, which is nearly unfeasible to gather at scale. In this paper,
we propose a framework that leverages large-scale ego- and exo-centric video
datasets -- constructed globally with substantial effort -- of Exo-Ego4D to
extract diverse manipulation trajectories at scale. From these extracted
trajectories with the associated textual action description, we develop
trajectory generation models based on visual and point cloud-based language
models. In the recently proposed egocentric vision-based in-a-quality
trajectory dataset of HOT3D, we confirmed that our models successfully generate
valid object trajectories, establishing a training dataset and baseline models
for the novel task of generating 6DoF manipulation trajectories from action
descriptions in egocentric vision.

</details>


### [273] [Analyzing Transformer Models and Knowledge Distillation Approaches for Image Captioning on Edge AI](https://arxiv.org/abs/2506.03607)
*Wing Man Casca Kwok,Yip Chiu Tung,Kunal Bhagchandani*

Main category: cs.CV

TL;DR: 研究探讨了在边缘计算设备上部署基于Transformer的图像描述模型，通过知识蒸馏技术优化模型，实现在资源受限设备上的高效推理。


<details>
  <summary>Details</summary>
Motivation: 工业自动化和物联网应用中，实时感知和智能决策对自主操作至关重要，但边缘设备计算资源有限，传统深度学习模型难以满足需求。

Method: 评估资源高效的Transformer模型，并应用知识蒸馏技术，优化模型在边缘设备上的性能。

Result: 研究表明，通过知识蒸馏技术，可以在资源受限的设备上加速推理，同时保持模型性能。

Conclusion: 该研究为边缘设备上的实时AI应用提供了可行的解决方案，特别是在工业自动化和机器人领域。

Abstract: Edge computing decentralizes processing power to network edge, enabling
real-time AI-driven decision-making in IoT applications. In industrial
automation such as robotics and rugged edge AI, real-time perception and
intelligence are critical for autonomous operations. Deploying
transformer-based image captioning models at the edge can enhance machine
perception, improve scene understanding for autonomous robots, and aid in
industrial inspection.
  However, these edge or IoT devices are often constrained in computational
resources for physical agility, yet they have strict response time
requirements. Traditional deep learning models can be too large and
computationally demanding for these devices. In this research, we present
findings of transformer-based models for image captioning that operate
effectively on edge devices. By evaluating resource-effective transformer
models and applying knowledge distillation techniques, we demonstrate inference
can be accelerated on resource-constrained devices while maintaining model
performance using these techniques.

</details>


### [274] [PDSE: A Multiple Lesion Detector for CT Images using PANet and Deformable Squeeze-and-Excitation Block](https://arxiv.org/abs/2506.03608)
*Di Fan,Heng Yu,Zhiyuan Xu*

Main category: cs.CV

TL;DR: 论文提出了一种名为PDSE的单阶段病灶检测框架，通过改进Retinanet，结合低层特征图和自适应SE模块，显著提升了多模态CT图像中病灶检测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: CT扫描中病灶的多样性和复杂性（如类型、大小和位置）使得病灶检测成为一项具有挑战性的任务，需要更高效的检测方法。

Method: 通过改进Retinanet，引入低层特征图增强路径聚合流，并采用自适应SE模块和通道特征图注意力机制来提升模型表现。

Result: 在公共DeepLesion基准测试中，PDSE框架的mAP超过0.20，显著优于其他先进算法，尤其在检测小目标和多尺度目标方面表现突出。

Conclusion: PDSE框架通过创新的特征增强和注意力机制，实现了病灶检测的state-of-the-art性能，为医学图像处理提供了高效解决方案。

Abstract: Detecting lesions in Computed Tomography (CT) scans is a challenging task in
medical image processing due to the diverse types, sizes, and locations of
lesions. Recently, various one-stage and two-stage framework networks have been
developed to focus on lesion localization. We introduce a one-stage lesion
detection framework, PDSE, by redesigning Retinanet to achieve higher accuracy
and efficiency for detecting lesions in multimodal CT images. Specifically, we
enhance the path aggregation flow by incorporating a low-level feature map.
Additionally, to improve model representation, we utilize the adaptive
Squeeze-and-Excitation (SE) block and integrate channel feature map attention.
This approach has resulted in achieving new state-of-the-art performance. Our
method significantly improves the detection of small and multiscaled objects.
When evaluated against other advanced algorithms on the public DeepLesion
benchmark, our algorithm achieved an mAP of over 0.20.

</details>


### [275] [VLMs Can Aggregate Scattered Training Patches](https://arxiv.org/abs/2506.03614)
*Zhanhui Zhou,Lingjie Chen,Chao Yang,Chaochao Lu*

Main category: cs.CV

TL;DR: 论文探讨了视觉语言模型（VLMs）中通过分散有害图像为小块绕过数据审核的风险，并提出“视觉缝合”概念，展示了VLMs如何整合分散信息生成有害内容。


<details>
  <summary>Details</summary>
Motivation: 研究动机是揭示VLMs在数据审核中的漏洞，即有害内容可能通过分散为小块绕过审核，并在训练后被模型整合。

Method: 方法包括将图像分割为小块并标记唯一ID，通过微调模型验证其视觉缝合能力，并模拟对抗性数据中毒场景。

Result: 结果显示VLMs能够通过视觉缝合整合分散信息，生成有害内容，从而绕过数据审核。

Conclusion: 结论指出视觉缝合能力对VLM安全性构成严重威胁，需进一步研究防范措施。

Abstract: One way to mitigate risks in vision-language models (VLMs) is to remove
dangerous samples in their training data. However, such data moderation can be
easily bypassed when harmful images are split into small, benign-looking
patches, scattered across many training samples. VLMs may then learn to piece
these fragments together during training and generate harmful responses at
inference, either from full images or text references. For instance, if trained
on image patches from a bloody scene paired with the descriptions "safe," VLMs
may later describe, the full image or a text reference to the scene, as "safe."
We define the core ability of VLMs enabling this attack as $\textit{visual
stitching}$ -- the ability to integrate visual information spread across
multiple training samples that share the same textual descriptions. In our
work, we first demonstrate visual stitching abilities in common open-source
VLMs on three datasets where each image is labeled with a unique synthetic ID:
we split each $(\texttt{image}, \texttt{ID})$ pair into $\{(\texttt{patch},
\texttt{ID})\}$ pairs at different granularity for finetuning, and we find that
tuned models can verbalize the correct IDs from full images or text reference.
Building on this, we simulate the adversarial data poisoning scenario mentioned
above by using patches from dangerous images and replacing IDs with text
descriptions like ``safe'' or ``unsafe'', demonstrating how harmful content can
evade moderation in patches and later be reconstructed through visual
stitching, posing serious VLM safety risks. Code is available at
https://github.com/ZHZisZZ/visual-stitching.

</details>


### [276] [Isharah: A Large-Scale Multi-Scene Dataset for Continuous Sign Language Recognition](https://arxiv.org/abs/2506.03615)
*Sarah Alyami,Hamzah Luqman,Sadam Al-Azani,Maad Alowaifeer,Yazeed Alharbi,Yaser Alonaizan*

Main category: cs.CV

TL;DR: Isharah是一个大型多场景连续手语识别（CSLR）数据集，首次在无约束环境中通过智能手机摄像头采集，包含30,000个视频片段，支持开发鲁棒的手语理解模型。


<details>
  <summary>Details</summary>
Motivation: 现有CSLR数据集在受控环境下采集，限制了其在实际场景中的应用，Isharah旨在填补这一空白。

Method: 通过智能手机摄像头采集18名聋人和专业手语者的视频，提供丰富的语言学标注（gloss-level）。

Result: 数据集包含高变异的录制设置，适用于开发鲁棒的CSLR和手语翻译系统。

Conclusion: Isharah为CSLR和SLT研究提供了首个大规模、多场景的无约束数据集，并设立了多个基准任务。

Abstract: Current benchmarks for sign language recognition (SLR) focus mainly on
isolated SLR, while there are limited datasets for continuous SLR (CSLR), which
recognizes sequences of signs in a video. Additionally, existing CSLR datasets
are collected in controlled settings, which restricts their effectiveness in
building robust real-world CSLR systems. To address these limitations, we
present Isharah, a large multi-scene dataset for CSLR. It is the first dataset
of its type and size that has been collected in an unconstrained environment
using signers' smartphone cameras. This setup resulted in high variations of
recording settings, camera distances, angles, and resolutions. This variation
helps with developing sign language understanding models capable of handling
the variability and complexity of real-world scenarios. The dataset consists of
30,000 video clips performed by 18 deaf and professional signers. Additionally,
the dataset is linguistically rich as it provides a gloss-level annotation for
all dataset's videos, making it useful for developing CSLR and sign language
translation (SLT) systems. This paper also introduces multiple sign language
understanding benchmarks, including signer-independent and unseen-sentence
CSLR, along with gloss-based and gloss-free SLT. The Isharah dataset is
available on https://snalyami.github.io/Isharah_CSLR/.

</details>


### [277] [Negative-Guided Subject Fidelity Optimization for Zero-Shot Subject-Driven Generation](https://arxiv.org/abs/2506.03621)
*Chaehun Shin,Jooyoung Choi,Johan Barthelemy,Jungbeom Lee,Sungroh Yoon*

Main category: cs.CV

TL;DR: SFO是一种新颖的零样本主题驱动生成框架，通过比较学习提升主题保真度。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖正样本和扩散损失，SFO通过引入负样本和成对比较优化模型。

Method: 提出条件退化负采样（CDNS）自动生成负样本，并重新加权扩散时间步以聚焦中间步骤。

Result: SFO在主题保真度和文本对齐上显著优于基线方法。

Conclusion: SFO通过比较学习和CDNS有效提升了主题驱动生成的性能。

Abstract: We present Subject Fidelity Optimization (SFO), a novel comparative learning
framework for zero-shot subject-driven generation that enhances subject
fidelity. Beyond supervised fine-tuning methods that rely only on positive
targets and use the diffusion loss as in the pre-training stage, SFO introduces
synthetic negative targets and explicitly guides the model to favor positives
over negatives through pairwise comparison. For negative targets, we propose
Condition-Degradation Negative Sampling (CDNS), which automatically generates
distinctive and informative negatives by intentionally degrading visual and
textual cues without expensive human annotations. Moreover, we reweight the
diffusion timesteps to focus finetuning on intermediate steps where subject
details emerge. Extensive experiments demonstrate that SFO with CDNS
significantly outperforms baselines in terms of both subject fidelity and text
alignment on a subject-driven generation benchmark. Project page:
https://subjectfidelityoptimization.github.io/

</details>


### [278] [FingerVeinSyn-5M: A Million-Scale Dataset and Benchmark for Finger Vein Recognition](https://arxiv.org/abs/2506.03635)
*Yinfan Wang,Jie Gui,Baosheng Yu,Qi Li,Zhenan Sun,Juho Kannala,Guoying Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种合成手指静脉图像生成器FVeinSyn，并创建了最大的手指静脉数据集FingerVeinSyn-5M，包含500万样本，显著提升了深度学习模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有手指静脉数据集规模小，限制了深度学习方法的进展，因此需要大规模、多样化的数据集。

Method: 使用FVeinSyn生成合成手指静脉图像，创建了包含500万样本的FingerVeinSyn-5M数据集，支持多种变化和全标注。

Result: 在多个基准测试中，使用该数据集预训练并微调的模型平均性能提升了53.91%。

Conclusion: FingerVeinSyn-5M为手指静脉识别领域提供了大规模、多样化的数据集，显著推动了深度学习应用的发展。

Abstract: A major challenge in finger vein recognition is the lack of large-scale
public datasets. Existing datasets contain few identities and limited samples
per finger, restricting the advancement of deep learning-based methods. To
address this, we introduce FVeinSyn, a synthetic generator capable of producing
diverse finger vein patterns with rich intra-class variations. Using FVeinSyn,
we created FingerVeinSyn-5M -- the largest available finger vein dataset --
containing 5 million samples from 50,000 unique fingers, each with 100
variations including shift, rotation, scale, roll, varying exposure levels,
skin scattering blur, optical blur, and motion blur. FingerVeinSyn-5M is also
the first to offer fully annotated finger vein images, supporting deep learning
applications in this field. Models pretrained on FingerVeinSyn-5M and
fine-tuned with minimal real data achieve an average 53.91\% performance gain
across multiple benchmarks. The dataset is publicly available at:
https://github.com/EvanWang98/FingerVeinSyn-5M.

</details>


### [279] [Spatial Understanding from Videos: Structured Prompts Meet Simulation Data](https://arxiv.org/abs/2506.03642)
*Haoyu Zhang,Meng Liu,Zaijing Li,Haokun Wen,Weili Guan,Yaowei Wang,Liqiang Nie*

Main category: cs.CV

TL;DR: 论文提出了一种增强预训练视觉语言模型（VLMs）3D空间推理能力的统一框架，结合结构化提示策略和自动化构建的数据集。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D空间推理中存在空间不确定性和数据稀缺问题，限制了VLMs的能力。

Method: 提出SpatialMind（结构化提示策略）和ScanForgeQA（自动化构建的数据集），无需修改模型架构。

Result: 在多个基准测试中验证了提示和微调策略的有效性。

Conclusion: 该框架为视觉空间理解的未来研究提供了启示。

Abstract: Visual-spatial understanding, the ability to infer object relationships and
layouts from visual input, is fundamental to downstream tasks such as robotic
navigation and embodied interaction. However, existing methods face spatial
uncertainty and data scarcity, limiting the 3D spatial reasoning capability of
pre-trained vision-language models (VLMs). To address these challenges, we
present a unified framework for enhancing 3D spatial reasoning in pre-trained
VLMs without modifying their architecture. This framework combines SpatialMind,
a structured prompting strategy that decomposes complex scenes and questions
into interpretable reasoning steps, with ScanForgeQA, a scalable
question-answering dataset built from diverse 3D simulation scenes through an
automated construction process designed for fine-tuning. Extensive experiments
across multiple benchmarks demonstrate the individual and combined
effectiveness of our prompting and fine-tuning strategies, and yield insights
that may inspire future research on visual-spatial understanding.

</details>


### [280] [Images are Worth Variable Length of Representations](https://arxiv.org/abs/2506.03643)
*Lingjun Mao,Rodolfo Corona,Xin Liang,Wenhao Yan,Zineng Tang*

Main category: cs.CV

TL;DR: DOVE是一种动态视觉编码器，根据图像复杂度生成可变数量的视觉标记，显著减少标记数量同时保持高质量重建，并在多项任务中优于固定长度编码方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉编码器将图像映射为固定长度的标记序列，忽略了不同图像信息量的差异，导致效率低下。

Method: 提出DOVE动态视觉编码器，生成可变数量的视觉标记以重建图像，并扩展为查询条件化标记化，聚焦查询相关区域。

Result: DOVE显著减少平均标记数量且保持高重建质量，在线性探测和多模态任务中表现优于固定长度编码方法。

Conclusion: DOVE通过动态标记化和查询条件化，实现了更高效的语义特征提取，优于传统方法。

Abstract: Most existing vision encoders map images into a fixed-length sequence of
tokens, overlooking the fact that different images contain varying amounts of
information. For example, a visually complex image (e.g., a cluttered room)
inherently carries more information and thus deserves more tokens than a simple
image (e.g., a blank wall). To address this inefficiency, we propose DOVE, a
dynamic vision encoder that produces a variable number of visual tokens (i.e.,
continuous representation vectors) to reconstruct each image. Our results show
that DOVE significantly reduces the average number of tokens while maintaining
high reconstruction quality. In several linear probing and downstream
multimodal tasks, it outperforms existing autoencoder-based tokenization
methods when using far fewer tokens, capturing more expressive semantic
features compared to fixed-length encoding. We further extend DOVE with
query-conditioned tokenization. By guiding the model to focus on query-relevant
regions, it achieves more efficient and targeted semantic extraction. Our code
and checkpoints are available at https://dove-encoder.github.io/dove-encoder.

</details>


### [281] [YOND: Practical Blind Raw Image Denoising Free from Camera-Specific Data Dependency](https://arxiv.org/abs/2506.03645)
*Hansen Feng,Lizhi Wang,Yiqi Huang,Tong Li,Lin Zhu,Hua Huang*

Main category: cs.CV

TL;DR: YOND是一种新型盲原始图像去噪方法，通过合成数据训练，可泛化到未知相机数据。其核心模块包括CNE、EM-VST和SNR-Net，分别用于噪声估计、消除相机依赖性和可控去噪。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法依赖特定相机数据，导致在未知相机数据上性能下降，因此需要一种更通用的去噪方法。

Method: 提出YOND方法，包含三个模块：CNE（粗到细噪声估计）、EM-VST（期望匹配方差稳定变换）和SNR-Net（信噪比引导去噪网络）。

Result: 在未知相机数据上表现优异，具有灵活性和可控性。

Conclusion: YOND通过合成数据训练和模块化设计，实现了对未知相机数据的鲁棒去噪，具有广泛实用性。

Abstract: The rapid advancement of photography has created a growing demand for a
practical blind raw image denoising method. Recently, learning-based methods
have become mainstream due to their excellent performance. However, most
existing learning-based methods suffer from camera-specific data dependency,
resulting in performance drops when applied to data from unknown cameras. To
address this challenge, we introduce a novel blind raw image denoising method
named YOND, which represents You Only Need a Denoiser. Trained solely on
synthetic data, YOND can generalize robustly to noisy raw images captured by
diverse unknown cameras. Specifically, we propose three key modules to
guarantee the practicality of YOND: coarse-to-fine noise estimation (CNE),
expectation-matched variance-stabilizing transform (EM-VST), and SNR-guided
denoiser (SNR-Net). Firstly, we propose CNE to identify the camera noise
characteristic, refining the estimated noise parameters based on the coarse
denoised image. Secondly, we propose EM-VST to eliminate camera-specific data
dependency, correcting the bias expectation of VST according to the noisy
image. Finally, we propose SNR-Net to offer controllable raw image denoising,
supporting adaptive adjustments and manual fine-tuning. Extensive experiments
on unknown cameras, along with flexible solutions for challenging cases,
demonstrate the superior practicality of our method. The source code will be
publicly available at the
\href{https://fenghansen.github.io/publication/YOND}{project homepage}.

</details>


### [282] [EmoArt: A Multidimensional Dataset for Emotion-Aware Artistic Generation](https://arxiv.org/abs/2506.03652)
*Cheng Zhang,Hongxia xie,Bin Wen,Songhan Zuo,Ruoxuan Zhang,Wen-huang Cheng*

Main category: cs.CV

TL;DR: 本文介绍了EmoArt数据集，用于解决文本到图像生成中情感表达不足的问题，并评估了现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成模型在情感表达和抽象艺术生成方面存在不足，主要由于缺乏细粒度情感标注的数据集。

Method: 提出了EmoArt数据集，包含132,664件艺术品，涵盖56种绘画风格，并提供了丰富的结构化标注。

Result: 通过EmoArt数据集，系统评估了流行文本到图像扩散模型的情感对齐能力。

Conclusion: 该数据集为情感驱动的图像合成提供了关键数据和基准，推动了情感计算、多模态学习和计算艺术的发展。

Abstract: With the rapid advancement of diffusion models, text-to-image generation has
achieved significant progress in image resolution, detail fidelity, and
semantic alignment, particularly with models like Stable Diffusion 3.5, Stable
Diffusion XL, and FLUX 1. However, generating emotionally expressive and
abstract artistic images remains a major challenge, largely due to the lack of
large-scale, fine-grained emotional datasets. To address this gap, we present
the EmoArt Dataset -- one of the most comprehensive emotion-annotated art
datasets to date. It contains 132,664 artworks across 56 painting styles (e.g.,
Impressionism, Expressionism, Abstract Art), offering rich stylistic and
cultural diversity. Each image includes structured annotations: objective scene
descriptions, five key visual attributes (brushwork, composition, color, line,
light), binary arousal-valence labels, twelve emotion categories, and potential
art therapy effects. Using EmoArt, we systematically evaluate popular
text-to-image diffusion models for their ability to generate emotionally
aligned images from text. Our work provides essential data and benchmarks for
emotion-driven image synthesis and aims to advance fields such as affective
computing, multimodal learning, and computational art, enabling applications in
art therapy and creative design. The dataset and more details can be accessed
via our project website.

</details>


### [283] [MambaNeXt-YOLO: A Hybrid State Space Model for Real-time Object Detection](https://arxiv.org/abs/2506.03654)
*Xiaochun Lei,Siqi Wu,Weilin Wu,Zetao Jiang*

Main category: cs.CV

TL;DR: MambaNeXt-YOLO是一种新型实时目标检测框架，结合CNN与Mamba模型，平衡精度与效率，支持边缘设备部署。


<details>
  <summary>Details</summary>
Motivation: 实时目标检测在计算资源有限时具有挑战性，Transformer架构因计算复杂度高不适用于实时和边缘部署，需更高效的替代方案。

Method: 提出MambaNeXt Block（CNN与Mamba混合设计）、MAFPN（多尺度特征金字塔）和边缘优化，实现高效序列建模。

Result: 在PASCAL VOC数据集上达到66.6% mAP和31.9 FPS，支持NVIDIA Jetson Xavier NX等边缘设备。

Conclusion: MambaNeXt-YOLO通过混合设计和优化，在实时目标检测中平衡了精度与效率，适用于边缘计算场景。

Abstract: Real-time object detection is a fundamental but challenging task in computer
vision, particularly when computational resources are limited. Although
YOLO-series models have set strong benchmarks by balancing speed and accuracy,
the increasing need for richer global context modeling has led to the use of
Transformer-based architectures. Nevertheless, Transformers have high
computational complexity because of their self-attention mechanism, which
limits their practicality for real-time and edge deployments. To overcome these
challenges, recent developments in linear state space models, such as Mamba,
provide a promising alternative by enabling efficient sequence modeling with
linear complexity. Building on this insight, we propose MambaNeXt-YOLO, a novel
object detection framework that balances accuracy and efficiency through three
key contributions: (1) MambaNeXt Block: a hybrid design that integrates CNNs
with Mamba to effectively capture both local features and long-range
dependencies; (2) Multi-branch Asymmetric Fusion Pyramid Network (MAFPN): an
enhanced feature pyramid architecture that improves multi-scale object
detection across various object sizes; and (3) Edge-focused Efficiency: our
method achieved 66.6\% mAP at 31.9 FPS on the PASCAL VOC dataset without any
pre-training and supports deployment on edge devices such as the NVIDIA Jetson
Xavier NX and Orin NX.

</details>


### [284] [INP-Former++: Advancing Universal Anomaly Detection via Intrinsic Normal Prototypes and Residual Learning](https://arxiv.org/abs/2506.03660)
*Wei Luo,Haiming Yao,Yunkang Cao,Qiyu Chen,Ang Gao,Weiming Shen,Weihang Zhang,Wenyong Yu*

Main category: cs.CV

TL;DR: INP-Former是一种新颖的异常检测方法，通过从测试图像中提取内在正常原型（INPs）来避免依赖外部训练集，显著提升了检测精度。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法依赖训练集中的正常参考图像，但由于外观和位置的变化，这些参考图像与测试图像的对齐困难，限制了检测精度。

Method: 提出INP-Former，通过INP提取器从测试图像中提取内在正常原型，并使用INP一致性损失和软挖掘损失优化模型。

Result: INP-Former在单类、多类和少样本异常检测任务中达到最先进性能，并展示了零样本检测能力。

Conclusion: INP-Former及其改进版本INP-Former++在多种异常检测场景中表现优异，是一种通用且高效的解决方案。

Abstract: Anomaly detection (AD) is essential for industrial inspection and medical
diagnosis, yet existing methods typically rely on ``comparing'' test images to
normal references from a training set. However, variations in appearance and
positioning often complicate the alignment of these references with the test
image, limiting detection accuracy. We observe that most anomalies manifest as
local variations, meaning that even within anomalous images, valuable normal
information remains. We argue that this information is useful and may be more
aligned with the anomalies since both the anomalies and the normal information
originate from the same image. Therefore, rather than relying on external
normality from the training set, we propose INP-Former, a novel method that
extracts Intrinsic Normal Prototypes (INPs) directly from the test image.
Specifically, we introduce the INP Extractor, which linearly combines normal
tokens to represent INPs. We further propose an INP Coherence Loss to ensure
INPs can faithfully represent normality for the testing image. These INPs then
guide the INP-guided Decoder to reconstruct only normal tokens, with
reconstruction errors serving as anomaly scores. Additionally, we propose a
Soft Mining Loss to prioritize hard-to-optimize samples during training.
INP-Former achieves state-of-the-art performance in single-class, multi-class,
and few-shot AD tasks across MVTec-AD, VisA, and Real-IAD, positioning it as a
versatile and universal solution for AD. Remarkably, INP-Former also
demonstrates some zero-shot AD capability. Furthermore, we propose a soft
version of the INP Coherence Loss and enhance INP-Former by incorporating
residual learning, leading to the development of INP-Former++. The proposed
method significantly improves detection performance across single-class,
multi-class, semi-supervised, few-shot, and zero-shot settings.

</details>


### [285] [Zero-Shot Temporal Interaction Localization for Egocentric Videos](https://arxiv.org/abs/2506.03662)
*Erhang Zhang,Junyi Ma,Yin-Dong Zheng,Yixuan Zhou,Hesheng Wang*

Main category: cs.CV

TL;DR: EgoLoc是一种新颖的零样本时序交互定位方法，通过自适应采样策略和闭环反馈，在自我中心视频中高效定位人-物交互的抓取动作。


<details>
  <summary>Details</summary>
Motivation: 当前时序动作定位方法依赖标注数据，存在领域偏差和部署效率低的问题，而现有零样本方法因粗粒度估计和开环流程限制了性能提升。

Method: EgoLoc结合2D和3D观察，通过自适应采样生成高质量初始猜测，并利用视觉和动态线索的闭环反馈优化定位结果。

Result: 在公开数据集和新基准测试中，EgoLoc优于现有基线方法，实现了更高的定位精度和效率。

Conclusion: EgoLoc为零样本时序交互定位提供了高效解决方案，代码和数据将开源。

Abstract: Locating human-object interaction (HOI) actions within video serves as the
foundation for multiple downstream tasks, such as human behavior analysis and
human-robot skill transfer. Current temporal action localization methods
typically rely on annotated action and object categories of interactions for
optimization, which leads to domain bias and low deployment efficiency.
Although some recent works have achieved zero-shot temporal action localization
(ZS-TAL) with large vision-language models (VLMs), their coarse-grained
estimations and open-loop pipelines hinder further performance improvements for
temporal interaction localization (TIL). To address these issues, we propose a
novel zero-shot TIL approach dubbed EgoLoc to locate the timings of grasp
actions for human-object interaction in egocentric videos. EgoLoc introduces a
self-adaptive sampling strategy to generate reasonable visual prompts for VLM
reasoning. By absorbing both 2D and 3D observations, it directly samples
high-quality initial guesses around the possible contact/separation timestamps
of HOI according to 3D hand velocities, leading to high inference accuracy and
efficiency. In addition, EgoLoc generates closed-loop feedback from visual and
dynamic cues to further refine the localization results. Comprehensive
experiments on the publicly available dataset and our newly proposed benchmark
demonstrate that EgoLoc achieves better temporal interaction localization for
egocentric videos compared to state-of-the-art baselines. We will release our
code and relevant data as open-source at https://github.com/IRMVLab/EgoLoc.

</details>


### [286] [Intersectional Bias in Pre-Trained Image Recognition Models](https://arxiv.org/abs/2506.03664)
*Valerie Krug,Sebastian Stober*

Main category: cs.CV

TL;DR: 研究发现ImageNet分类器在面部图像中存在年龄、种族和性别的偏见，年龄差异尤为明显。


<details>
  <summary>Details</summary>
Motivation: 探讨深度学习模型中预训练模型可能存在的偏见，特别是在面部图像中对年龄、种族和性别的编码偏差。

Method: 使用线性分类器探针和地形图可视化激活，分析ImageNet分类器的表示。

Result: 模型尤其能区分年龄，对某些种族和中年性别群体也有较弱的区分能力。

Conclusion: ImageNet分类器在面部图像中存在显著的年龄偏见，同时对种族和性别也有一定程度的区分能力。

Abstract: Deep Learning models have achieved remarkable success. Training them is often
accelerated by building on top of pre-trained models which poses the risk of
perpetuating encoded biases. Here, we investigate biases in the representations
of commonly used ImageNet classifiers for facial images while considering
intersections of sensitive variables age, race and gender. To assess the
biases, we use linear classifier probes and visualize activations as
topographic maps. We find that representations in ImageNet classifiers
particularly allow differentiation between ages. Less strongly pronounced, the
models appear to associate certain ethnicities and distinguish genders in
middle-aged groups.

</details>


### [287] [Accelerating SfM-based Pose Estimation with Dominating Set](https://arxiv.org/abs/2506.03667)
*Joji Joseph,Bharadwaj Amrutur,Shalabh Bhatnagar*

Main category: cs.CV

TL;DR: 本文提出了一种基于图论支配集的预处理技术，显著提升了SfM姿态估计的速度，适用于实时应用如AR、VR和机器人。


<details>
  <summary>Details</summary>
Motivation: 解决SfM姿态估计在实时应用中的速度瓶颈问题。

Method: 利用图论中的支配集概念预处理SfM模型，减少计算量。

Result: 处理速度提升1.5至14.48倍，参考图像和点云规模分别减少17-23倍和2.27-4倍。

Conclusion: 该方法在速度和精度之间取得了平衡，为实时3D姿态估计提供了高效解决方案。

Abstract: This paper introduces a preprocessing technique to speed up
Structure-from-Motion (SfM) based pose estimation, which is critical for
real-time applications like augmented reality (AR), virtual reality (VR), and
robotics. Our method leverages the concept of a dominating set from graph
theory to preprocess SfM models, significantly enhancing the speed of the pose
estimation process without losing significant accuracy. Using the OnePose
dataset, we evaluated our method across various SfM-based pose estimation
techniques. The results demonstrate substantial improvements in processing
speed, ranging from 1.5 to 14.48 times, and a reduction in reference images and
point cloud size by factors of 17-23 and 2.27-4, respectively. This work offers
a promising solution for efficient and accurate 3D pose estimation, balancing
speed and accuracy in real-time applications.

</details>


### [288] [BiXFormer: A Robust Framework for Maximizing Modality Effectiveness in Multi-Modal Semantic Segmentation](https://arxiv.org/abs/2506.03675)
*Jialei Chen,Xu Zheng,Danda Pani Paudel,Luc Van Gool,Hiroshi Murase,Daisuke Deguchi*

Main category: cs.CV

TL;DR: BiXFormer通过统一模态匹配（UMM）和跨模态对齐（CMA）优化多模态语义分割，提升模态利用效率并处理缺失模态问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法融合多模态特征时限制了各模态在不同情境下的优势发挥，BiXFormer旨在最大化模态效果并处理缺失模态。

Method: BiXFormer将多模态输入分为RGB和非RGB（X）模态分别处理，提出UMM（含MAM和CM）和CMA，优化模态匹配和对齐。

Result: 在合成和真实多模态基准测试中，mIoU分别提升2.75%和22.74%。

Conclusion: BiXFormer通过模态分类和匹配策略显著提升多模态语义分割性能。

Abstract: Utilizing multi-modal data enhances scene understanding by providing
complementary semantic and geometric information. Existing methods fuse
features or distill knowledge from multiple modalities into a unified
representation, improving robustness but restricting each modality's ability to
fully leverage its strengths in different situations. We reformulate
multi-modal semantic segmentation as a mask-level classification task and
propose BiXFormer, which integrates Unified Modality Matching (UMM) and Cross
Modality Alignment (CMA) to maximize modality effectiveness and handle missing
modalities. Specifically, BiXFormer first categorizes multi-modal inputs into
RGB and X, where X represents any non-RGB modalities, e.g., depth, allowing
separate processing for each. This design leverages the well-established
pretraining for RGB, while addressing the relative lack of attention to X
modalities. Then, we propose UMM, which includes Modality Agnostic Matching
(MAM) and Complementary Matching (CM). MAM assigns labels to features from all
modalities without considering modality differences, leveraging each modality's
strengths. CM then reassigns unmatched labels to remaining unassigned features
within their respective modalities, ensuring that each available modality
contributes to the final prediction and mitigating the impact of missing
modalities. Moreover, to further facilitate UMM, we introduce CMA, which
enhances the weaker queries assigned in CM by aligning them with optimally
matched queries from MAM. Experiments on both synthetic and real-world
multi-modal benchmarks demonstrate the effectiveness of our method, achieving
significant improvements in mIoU of +2.75% and +22.74% over the prior arts.

</details>


### [289] [How PARTs assemble into wholes: Learning the relative composition of images](https://arxiv.org/abs/2506.03682)
*Melika Ayoughi,Samira Abnar,Chen Huang,Chris Sandino,Sayeri Lala,Eeshan Gunesh Dhekane,Dan Busbridge,Shuangfei Zhai,Vimal Thilak,Josh Susskind,Pascal Mettes,Paul Groth,Hanlin Goh*

Main category: cs.CV

TL;DR: PART是一种自监督学习方法，通过连续相对变换克服网格方法的局限性，提升空间理解任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有网格方法无法捕捉真实世界中物体组合的连续性和流动性，限制了自监督学习的效果。

Method: 提出PART方法，利用非网格补丁间的连续相对变换建模图像部分的相对组合关系。

Result: 在对象检测和时间序列预测等任务中表现优于MAE和DropPos等网格方法，全局分类任务中也有竞争力。

Conclusion: PART突破了网格限制，为跨数据类型的通用自监督预训练开辟了新方向。

Abstract: The composition of objects and their parts, along with object-object
positional relationships, provides a rich source of information for
representation learning. Hence, spatial-aware pretext tasks have been actively
explored in self-supervised learning. Existing works commonly start from a grid
structure, where the goal of the pretext task involves predicting the absolute
position index of patches within a fixed grid. However, grid-based approaches
fall short of capturing the fluid and continuous nature of real-world object
compositions. We introduce PART, a self-supervised learning approach that
leverages continuous relative transformations between off-grid patches to
overcome these limitations. By modeling how parts relate to each other in a
continuous space, PART learns the relative composition of images-an off-grid
structural relative positioning process that generalizes beyond occlusions and
deformations. In tasks requiring precise spatial understanding such as object
detection and time series prediction, PART outperforms strong grid-based
methods like MAE and DropPos, while also maintaining competitive performance on
global classification tasks with minimal hyperparameter tuning. By breaking
free from grid constraints, PART opens up an exciting new trajectory for
universal self-supervised pretraining across diverse datatypes-from natural
images to EEG signals-with promising potential in video, medical imaging, and
audio.

</details>


### [290] [PRJ: Perception-Retrieval-Judgement for Generated Images](https://arxiv.org/abs/2506.03683)
*Qiang Fu,Zonglei Jing,Zonghao Ying,Xiaoqian Li*

Main category: cs.CV

TL;DR: PRJ框架通过感知-检索-判断三阶段设计，提升AI生成视觉内容的安全性检测能力，解决了现有系统在上下文理解和动态毒性评估上的不足。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的快速发展带来了视觉内容的安全隐患，现有系统缺乏对上下文和动态毒性的处理能力。

Method: 提出PRJ框架，通过语言描述、外部知识检索和规则判断三阶段，检测显性和隐性危害。

Result: PRJ在检测准确性和鲁棒性上优于现有安全检测器，并支持结构化毒性解释。

Conclusion: PRJ为AI生成内容的安全检测提供了更灵活、可解释的解决方案。

Abstract: The rapid progress of generative AI has enabled remarkable creative
capabilities, yet it also raises urgent concerns regarding the safety of
AI-generated visual content in real-world applications such as content
moderation, platform governance, and digital media regulation. This includes
unsafe material such as sexually explicit images, violent scenes, hate symbols,
propaganda, and unauthorized imitations of copyrighted artworks. Existing image
safety systems often rely on rigid category filters and produce binary outputs,
lacking the capacity to interpret context or reason about nuanced,
adversarially induced forms of harm. In addition, standard evaluation metrics
(e.g., attack success rate) fail to capture the semantic severity and dynamic
progression of toxicity. To address these limitations, we propose
Perception-Retrieval-Judgement (PRJ), a cognitively inspired framework that
models toxicity detection as a structured reasoning process. PRJ follows a
three-stage design: it first transforms an image into descriptive language
(perception), then retrieves external knowledge related to harm categories and
traits (retrieval), and finally evaluates toxicity based on legal or normative
rules (judgement). This language-centric structure enables the system to detect
both explicit and implicit harms with improved interpretability and categorical
granularity. In addition, we introduce a dynamic scoring mechanism based on a
contextual toxicity risk matrix to quantify harmfulness across different
semantic dimensions. Experiments show that PRJ surpasses existing safety
checkers in detection accuracy and robustness while uniquely supporting
structured category-level toxicity interpretation.

</details>


### [291] [DSSAU-Net:U-Shaped Hybrid Network for Pubic Symphysis and Fetal Head Segmentation](https://arxiv.org/abs/2506.03684)
*Zunhui Xia,Hongxing Li,Libin Lan*

Main category: cs.CV

TL;DR: 论文提出了一种名为DSSAU-Net的稀疏自注意力网络架构，用于胎儿头部和耻骨联合的精确分割，以提高分娩过程中超声辅助诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统分娩过程中的阴道检查方法主观且不准确，超声辅助诊断通过胎儿头部和耻骨联合的分割提供客观评估，但需要高效且精确的分割方法。

Method: 采用对称的U形编码器-解码器网络架构，结合双稀疏选择注意力（DSSA）块，通过区域和像素级别的稀疏标记选择降低计算复杂度，并设计跳跃连接和多尺度特征融合以增强信息提取。

Result: 在MICCAI IUGC 2024竞赛的测试集上验证了DSSAU-Net的有效性，获得了分类和分割任务的第四名。

Conclusion: DSSAU-Net在计算效率和性能上表现优异，为超声辅助分娩诊断提供了可靠的工具。

Abstract: In the childbirth process, traditional methods involve invasive vaginal
examinations, but research has shown that these methods are both subjective and
inaccurate. Ultrasound-assisted diagnosis offers an objective yet effective way
to assess fetal head position via two key parameters: Angle of Progression
(AoP) and Head-Symphysis Distance (HSD), calculated by segmenting the fetal
head (FH) and pubic symphysis (PS), which aids clinicians in ensuring a smooth
delivery process. Therefore, accurate segmentation of FH and PS is crucial. In
this work, we propose a sparse self-attention network architecture with good
performance and high computational efficiency, named DSSAU-Net, for the
segmentation of FH and PS. Specifically, we stack varying numbers of Dual
Sparse Selection Attention (DSSA) blocks at each stage to form a symmetric
U-shaped encoder-decoder network architecture. For a given query, DSSA is
designed to explicitly perform one sparse token selection at both the region
and pixel levels, respectively, which is beneficial for further reducing
computational complexity while extracting the most relevant features. To
compensate for the information loss during the upsampling process, skip
connections with convolutions are designed. Additionally, multiscale feature
fusion is employed to enrich the model's global and local information. The
performance of DSSAU-Net has been validated using the Intrapartum Ultrasound
Grand Challenge (IUGC) 2024 \textit{test set} provided by the organizer in the
MICCAI IUGC 2024
competition\footnote{\href{https://codalab.lisn.upsaclay.fr/competitions/18413\#learn\_the\_details}{https://codalab.lisn.upsaclay.fr/competitions/18413\#learn\_the\_details}},
where we win the fourth place on the tasks of classification and segmentation,
demonstrating its effectiveness. The codes will be available at
https://github.com/XiaZunhui/DSSAU-Net.

</details>


### [292] [Advancements in Artificial Intelligence Applications for Cardiovascular Disease Research](https://arxiv.org/abs/2506.03698)
*Yuanlin Mo,Haishan Huang,Bocheng Liang,Weibo Ma*

Main category: cs.CV

TL;DR: AI在心血管医学中的应用通过深度学习提升了诊断效率和准确性，但仍需解决数据验证问题。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在心血管医学中的潜力及其面临的挑战。

Method: 使用深度学习架构（如CNN和GAN）分析医学影像和生理信号。

Result: AI在诊断精度和工作效率上超越人类，但数据验证问题仍需解决。

Conclusion: 未来需开发混合模型和多模态数据集成，以提升临床可靠性。

Abstract: Recent advancements in artificial intelligence (AI) have revolutionized
cardiovascular medicine, particularly through integration with computed
tomography (CT), magnetic resonance imaging (MRI), electrocardiography (ECG)
and ultrasound (US). Deep learning architectures, including convolutional
neural networks and generative adversarial networks, enable automated analysis
of medical imaging and physiological signals, surpassing human capabilities in
diagnostic accuracy and workflow efficiency. However, critical challenges
persist, including the inability to validate input data accuracy, which may
propagate diagnostic errors. This review highlights AI's transformative
potential in precision diagnostics while underscoring the need for robust
validation protocols to ensure clinical reliability. Future directions
emphasize hybrid models integrating multimodal data and adaptive algorithms to
refine personalized cardiovascular care.

</details>


### [293] [OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2506.03706)
*Aditya Gandhamal,Aniruddh Sikdar,Suresh Sundaram*

Main category: cs.CV

TL;DR: OV-COAST提出了一种基于最优传输理论的开集语义分割方法，通过两阶段优化策略显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 提升开集语义分割（OVSS）在域外泛化能力，利用最优传输理论对齐视觉-语言特征。

Method: 采用两阶段优化：第一阶段通过Sinkhorn距离解决最优传输问题；第二阶段用该解指导CAT-Seg模型训练。

Result: 在MESS基准测试中，OV-COAST显著优于CAT-Seg（提升1.72% mIoU）和SAN-B（提升4.9% mIoU）。

Conclusion: OV-COAST通过最优传输理论有效提升了开集语义分割的性能，具有显著优势。

Abstract: Open-vocabulary semantic segmentation (OVSS) entails assigning semantic
labels to each pixel in an image using textual descriptions, typically
leveraging world models such as CLIP. To enhance out-of-domain generalization,
we propose Cost Aggregation with Optimal Transport (OV-COAST) for
open-vocabulary semantic segmentation. To align visual-language features within
the framework of optimal transport theory, we employ cost volume to construct a
cost matrix, which quantifies the distance between two distributions. Our
approach adopts a two-stage optimization strategy: in the first stage, the
optimal transport problem is solved using cost volume via Sinkhorn distance to
obtain an alignment solution; in the second stage, this solution is used to
guide the training of the CAT-Seg model. We evaluate state-of-the-art OVSS
models on the MESS benchmark, where our approach notably improves the
performance of the cost-aggregation model CAT-Seg with ViT-B backbone,
achieving superior results, surpassing CAT-Seg by 1.72 % and SAN-B by 4.9 %
mIoU. The code is available at
https://github.com/adityagandhamal/OV-COAST/}{https://github.com/adityagandhamal/OV-COAST/ .

</details>


### [294] [AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives](https://arxiv.org/abs/2506.03709)
*Aniruddh Sikdar,Aditya Gandhamal,Suresh Sundaram*

Main category: cs.CV

TL;DR: 论文提出了AetherVision-Bench基准，用于评估多角度分割性能，并分析了零样本迁移模型的关键影响因素。


<details>
  <summary>Details</summary>
Motivation: 解决开放词汇语义分割（OVSS）在跨领域泛化中的挑战，提升其在现实应用中的实用性。

Method: 提出AetherVision-Bench基准，评估多角度（空中和地面视角）分割性能，并分析零样本迁移模型的关键因素。

Result: 评估了现有OVSS模型，揭示了影响零样本迁移性能的关键因素。

Conclusion: 该研究为未来研究提供了基准和见解，推动了鲁棒性评估的发展。

Abstract: Open-vocabulary semantic segmentation (OVSS) involves assigning labels to
each pixel in an image based on textual descriptions, leveraging world models
like CLIP. However, they encounter significant challenges in cross-domain
generalization, hindering their practical efficacy in real-world applications.
Embodied AI systems are transforming autonomous navigation for ground vehicles
and drones by enhancing their perception abilities, and in this study, we
present AetherVision-Bench, a benchmark for multi-angle segmentation across
aerial, and ground perspectives, which facilitates an extensive evaluation of
performance across different viewing angles and sensor modalities. We assess
state-of-the-art OVSS models on the proposed benchmark and investigate the key
factors that impact the performance of zero-shot transfer models. Our work
pioneers the creation of a robustness benchmark, offering valuable insights and
establishing a foundation for future research.

</details>


### [295] [OSGNet @ Ego4D Episodic Memory Challenge 2025](https://arxiv.org/abs/2506.03710)
*Yisen Feng,Haoyu Zhang,Qiaohui Chu,Meng Liu,Weili Guan,Yaowei Wang,Liqiang Nie*

Main category: cs.CV

TL;DR: 本文介绍了在CVPR 2025 Ego4D挑战赛中，针对三个以自我为中心的视频定位任务的冠军解决方案，采用早期融合策略提升定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有统一视频定位方法多依赖后期融合策略，效果不佳，需改进。

Method: 采用基于早期融合的视频定位模型处理三个任务。

Result: 在Natural Language Queries、Goal Step和Moment Queries三个赛道中均获得第一名。

Conclusion: 早期融合策略显著提升了视频定位的准确性，方法有效。

Abstract: In this report, we present our champion solutions for the three egocentric
video localization tracks of the Ego4D Episodic Memory Challenge at CVPR 2025.
All tracks require precise localization of the interval within an untrimmed
egocentric video. Previous unified video localization approaches often rely on
late fusion strategies, which tend to yield suboptimal results. To address
this, we adopt an early fusion-based video localization model to tackle all
three tasks, aiming to enhance localization accuracy. Ultimately, our method
achieved first place in the Natural Language Queries, Goal Step, and Moment
Queries tracks, demonstrating its effectiveness. Our code can be found at
https://github.com/Yisen-Feng/OSGNet.

</details>


### [296] [PlückeRF: A Line-based 3D Representation for Few-view Reconstruction](https://arxiv.org/abs/2506.03713)
*Sam Bahrami,Dylan Campbell*

Main category: cs.CV

TL;DR: 本文提出了一种基于PlückeRF表示的多视角3D重建方法，通过有效利用多视角信息提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有的单视角和少视角3D重建方法在利用多视角信息方面仍有改进空间。

Method: 提出PlückeRF表示方法，通过结构化特征增强的线条连接3D表示与输入视图的像素光线，优化信息共享。

Result: 相比传统的三平面表示和现有前馈重建方法，重建质量显著提升。

Conclusion: PlückeRF表示在多视角3D重建中具有优势，为未来研究提供了新方向。

Abstract: Feed-forward 3D reconstruction methods aim to predict the 3D structure of a
scene directly from input images, providing a faster alternative to per-scene
optimization approaches. Significant progress has been made in single-view and
few-view reconstruction using learned priors that infer object shape and
appearance, even for unobserved regions. However, there is substantial
potential to enhance these methods by better leveraging information from
multiple views when available. To address this, we propose a few-view
reconstruction model that more effectively harnesses multi-view information.
Our approach introduces a simple mechanism that connects the 3D representation
with pixel rays from the input views, allowing for preferential sharing of
information between nearby 3D locations and between 3D locations and nearby
pixel rays. We achieve this by defining the 3D representation as a set of
structured, feature-augmented lines; the Pl\"uckeRF representation. Using this
representation, we demonstrate improvements in reconstruction quality over the
equivalent triplane representation and state-of-the-art feedforward
reconstruction methods.

</details>


### [297] [FSHNet: Fully Sparse Hybrid Network for 3D Object Detection](https://arxiv.org/abs/2506.03714)
*Shuai Liu,Mingyue Cui,Boyang Li,Quanmin Liang,Tinghe Hong,Kai Huang,Yunxiao Shan,Kai Huang*

Main category: cs.CV

TL;DR: FSHNet通过SlotFormer块和动态稀疏标签分配策略，解决了稀疏3D检测器中长距离特征提取和中心特征缺失的问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 稀疏3D检测器仅从非空体素提取特征，导致长距离交互能力弱和中心特征缺失，影响了特征提取能力和网络优化。

Method: 提出FSHNet，引入SlotFormer块增强长距离特征提取，采用动态稀疏标签分配策略优化网络，并设计稀疏上采样模块保留细节。

Result: 在Waymo、nuScenes和Argoverse2基准测试中表现出色。

Conclusion: FSHNet有效解决了稀疏3D检测器的关键问题，显著提升了检测性能。

Abstract: Fully sparse 3D detectors have recently gained significant attention due to
their efficiency in long-range detection. However, sparse 3D detectors extract
features only from non-empty voxels, which impairs long-range interactions and
causes the center feature missing. The former weakens the feature extraction
capability, while the latter hinders network optimization. To address these
challenges, we introduce the Fully Sparse Hybrid Network (FSHNet). FSHNet
incorporates a proposed SlotFormer block to enhance the long-range feature
extraction capability of existing sparse encoders. The SlotFormer divides
sparse voxels using a slot partition approach, which, compared to traditional
window partition, provides a larger receptive field. Additionally, we propose a
dynamic sparse label assignment strategy to deeply optimize the network by
providing more high-quality positive samples. To further enhance performance,
we introduce a sparse upsampling module to refine downsampled voxels,
preserving fine-grained details crucial for detecting small objects. Extensive
experiments on the Waymo, nuScenes, and Argoverse2 benchmarks demonstrate the
effectiveness of FSHNet. The code is available at
https://github.com/Say2L/FSHNet.

</details>


### [298] [ComRoPE: Scalable and Robust Rotary Position Embedding Parameterized by Trainable Commuting Angle Matrices](https://arxiv.org/abs/2506.03737)
*Hao Yu,Tangyu Jiang,Shuning Jia,Shannan Yan,Shunning Liu,Haolong Qian,Guanghao Li,Shuting Dong,Huaisong Zhang,Chun Yuan*

Main category: cs.CV

TL;DR: ComRoPE提出了一种可训练的旋转角度矩阵方法，改进了传统的RoPE位置编码，提升了模型的性能和灵活性。


<details>
  <summary>Details</summary>
Motivation: 传统的位置编码方法（如RoPE）存在鲁棒性和灵活性不足的问题，限制了模型的能力。

Method: ComRoPE通过定义可训练的交换角度矩阵，扩展了RoPE的变换空间，并提出了RoPE方程以确保性能一致性。

Result: 在ImageNet-1K数据集上，ComRoPE在训练分辨率和高分辨率下分别比现有方法提升了1.6%和2.9%。

Conclusion: ComRoPE不仅提升了性能，还为未来的位置编码研究提供了新的思路。代码已开源。

Abstract: The Transformer architecture has revolutionized various regions since it was
proposed, and its effectiveness largely depends on the ability to encode
positional information. Traditional position encoding methods exhibit
significant limitations due to lack of robustness and flexibility of position.
Therefore, Rotary Positional Encoding (RoPE) was proposed to alleviate these
issues, which integrates positional information by rotating the embeddings in
the attention mechanism. However, RoPE requires manually defined rotation
matrices with limited transformation space, constraining the model's capacity.
In this work, we propose ComRoPE, which generalizes RoPE by defining it in
terms of trainable commuting angle matrices. Specifically, we demonstrate that
pairwise commutativity of these matrices is essential for RoPE to achieve
scalability and positional robustness. We formally define the RoPE Equation,
which is an essential condition that ensures consistent performance with
position offsets. Based on the theoretical analysis, we present two types of
trainable commuting angle matrices as sufficient solutions to the RoPE
equation, which significantly improve performance, surpassing the current
state-of-the-art method by 1.6% at training resolution and 2.9% at higher
resolution on the ImageNet-1K dataset. Furthermore, our framework shows
versatility in generalizing to existing RoPE formulations and offering new
insights for future positional encoding research. To ensure reproducibility,
the source code and instructions are available at
https://github.com/Longin-Yu/ComRoPE

</details>


### [299] [SAAT: Synergistic Alternating Aggregation Transformer for Image Super-Resolution](https://arxiv.org/abs/2506.03740)
*Jianfeng Wu,Nannan Xu*

Main category: cs.CV

TL;DR: 论文提出了一种新型模型SAAT，通过结合通道和空间注意力机制，提升单图像超分辨率任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的超分辨率方法在计算自注意力时忽略了通道间和空间结构信息，限制了性能提升。

Method: 提出SAAT模型，引入CWSAG和SWSAG模块，分别结合通道注意力和空间注意力与窗口注意力，优化特征提取。

Result: 实验表明SAAT在超分辨率任务中表现优异，性能接近当前最优模型。

Conclusion: SAAT通过协同利用通道和空间注意力，显著提升了超分辨率任务的效果。

Abstract: Single image super-resolution is a well-known downstream task which aims to
restore low-resolution images into high-resolution images. At present, models
based on Transformers have shone brightly in the field of super-resolution due
to their ability to capture long-term dependencies in information. However,
current methods typically compute self-attention in nonoverlapping windows to
save computational costs, and the standard self-attention computation only
focuses on its results, thereby neglecting the useful information across
channels and the rich spatial structural information generated in the
intermediate process. Channel attention and spatial attention have,
respectively, brought significant improvements to various downstream visual
tasks in terms of extracting feature dependency and spatial structure
relationships, but the synergistic relationship between channel and spatial
attention has not been fully explored yet.To address these issues, we propose a
novel model. Synergistic Alternating Aggregation Transformer (SAAT), which can
better utilize the potential information of features. In SAAT, we introduce the
Efficient Channel & Window Synergistic Attention Group (CWSAG) and the Spatial
& Window Synergistic Attention Group (SWSAG). On the one hand, CWSAG combines
efficient channel attention with shifted window attention, enhancing non-local
feature fusion, and producing more visually appealing results. On the other
hand, SWSAG leverages spatial attention to capture rich structured feature
information, thereby enabling SAAT to more effectively extract structural
features.Extensive experimental results and ablation studies demonstrate the
effectiveness of SAAT in the field of super-resolution. SAAT achieves
performance comparable to that of the state-of-the-art (SOTA) under the same
quantity of parameters.

</details>


### [300] [HUMOF: Human Motion Forecasting in Interactive Social Scenes](https://arxiv.org/abs/2506.03753)
*Caiyi Sun,Yujing Sun,Xiao Han,Zemin Yang,Jiawei Liu,Xinge Zhu,Siu Ming Yiu,Yuexin Ma*

Main category: cs.CV

TL;DR: 提出了一种用于复杂交互场景中人体运动预测的分层特征表示方法，结合空间和频率视角，显著提升了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 复杂场景中的人体行为预测因交互信息（如人与人、人与环境）的丰富性而具有挑战性，现有方法难以应对。

Method: 设计了分层交互特征表示，高层特征捕捉整体交互上下文，低层特征关注细节；提出粗到细的交互推理模块，结合空间和频率视角。

Result: 在四个公共数据集上实现了最先进的性能。

Conclusion: 该方法通过分层特征表示和多视角推理，有效提升了复杂场景中人体运动预测的准确性。

Abstract: Complex scenes present significant challenges for predicting human behaviour
due to the abundance of interaction information, such as human-human and
humanenvironment interactions. These factors complicate the analysis and
understanding of human behaviour, thereby increasing the uncertainty in
forecasting human motions. Existing motion prediction methods thus struggle in
these complex scenarios. In this paper, we propose an effective method for
human motion forecasting in interactive scenes. To achieve a comprehensive
representation of interactions, we design a hierarchical interaction feature
representation so that high-level features capture the overall context of the
interactions, while low-level features focus on fine-grained details. Besides,
we propose a coarse-to-fine interaction reasoning module that leverages both
spatial and frequency perspectives to efficiently utilize hierarchical
features, thereby enhancing the accuracy of motion predictions. Our method
achieves state-of-the-art performance across four public datasets. Code will be
released when this paper is published.

</details>


### [301] [CoLa: Chinese Character Decomposition with Compositional Latent Components](https://arxiv.org/abs/2506.03798)
*Fan Shi,Haiyang Yu,Bin Li,Xiangyang Xue*

Main category: cs.CV

TL;DR: 论文提出了一种名为CoLa的深度潜在变量模型，通过学习汉字的组合潜在组件，无需依赖人工定义的分解方案，实现了零样本汉字识别。


<details>
  <summary>Details</summary>
Motivation: 人类能够分解汉字为组合部件并重新组合以识别未见过的汉字，这反映了组合性和学习能力两种认知原则。现有方法依赖人工定义的分解方案，忽略了学习能力，限制了泛化能力。

Method: 提出了一种深度潜在变量模型（CoLa），学习汉字的组合潜在组件，并在潜在空间中通过比较这些组件进行识别和匹配。

Result: 实验表明，CoLa在零样本汉字识别任务中优于现有方法，且学习的组件能直观反映汉字结构。模型还展示了跨数据集的泛化能力。

Conclusion: CoLa通过结合组合性和学习能力，实现了高效泛化和零样本识别，为汉字识别提供了新思路。

Abstract: Humans can decompose Chinese characters into compositional components and
recombine them to recognize unseen characters. This reflects two cognitive
principles: Compositionality, the idea that complex concepts are built on
simpler parts; and Learning-to-learn, the ability to learn strategies for
decomposing and recombining components to form new concepts. These principles
provide inductive biases that support efficient generalization. They are
critical to Chinese character recognition (CCR) in solving the zero-shot
problem, which results from the common long-tail distribution of Chinese
character datasets. Existing methods have made substantial progress in modeling
compositionality via predefined radical or stroke decomposition. However, they
often ignore the learning-to-learn capability, limiting their ability to
generalize beyond human-defined schemes. Inspired by these principles, we
propose a deep latent variable model that learns Compositional Latent
components of Chinese characters (CoLa) without relying on human-defined
decomposition schemes. Recognition and matching can be performed by comparing
compositional latent components in the latent space, enabling zero-shot
character recognition. The experiments illustrate that CoLa outperforms
previous methods in both character the radical zero-shot CCR. Visualization
indicates that the learned components can reflect the structure of characters
in an interpretable way. Moreover, despite being trained on historical
documents, CoLa can analyze components of oracle bone characters, highlighting
its cross-dataset generalization ability.

</details>


### [302] [ConText: Driving In-context Learning for Text Removal and Segmentation](https://arxiv.org/abs/2506.03799)
*Fei Zhang,Pei Zhang,Baosong Yang,Fei Huang,Yanfeng Wang,Ya Zhang*

Main category: cs.CV

TL;DR: 本文首次将视觉上下文学习（V-ICL）范式应用于光学字符识别任务，提出了一种任务链式组合器和上下文感知聚合方法，显著提升了模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有V-ICL通用模型采用直接提示方式，限制了模型的单步推理能力，且视觉异构性影响了同质演示的选择。

Method: 提出任务链式组合器（图像-移除-分割）和上下文感知聚合，增强提示中的中间推理；采用自提示策略解决视觉异构性问题。

Result: 提出的ConText模型在领域内外基准测试中均达到新的最优性能。

Conclusion: 通过任务链式组合和上下文感知聚合，显著提升了视觉上下文学习在字符识别任务中的表现。

Abstract: This paper presents the first study on adapting the visual in-context
learning (V-ICL) paradigm to optical character recognition tasks, specifically
focusing on text removal and segmentation. Most existing V-ICL generalists
employ a reasoning-as-reconstruction approach: they turn to using a
straightforward image-label compositor as the prompt and query input, and then
masking the query label to generate the desired output. This direct prompt
confines the model to a challenging single-step reasoning process. To address
this, we propose a task-chaining compositor in the form of
image-removal-segmentation, providing an enhanced prompt that elicits reasoning
with enriched intermediates. Additionally, we introduce context-aware
aggregation, integrating the chained prompt pattern into the latent query
representation, thereby strengthening the model's in-context reasoning. We also
consider the issue of visual heterogeneity, which complicates the selection of
homogeneous demonstrations in text recognition. Accordingly, this is
effectively addressed through a simple self-prompting strategy, preventing the
model's in-context learnability from devolving into specialist-like,
context-free inference. Collectively, these insights culminate in our ConText
model, which achieves new state-of-the-art across both in- and out-of-domain
benchmarks. The code is available at https://github.com/Ferenas/ConText.

</details>


### [303] [Animal Pose Labeling Using General-Purpose Point Trackers](https://arxiv.org/abs/2506.03868)
*Zhuoyang Pan,Boxiao Pan,Guandao Yang,Adam W. Harley,Leonidas Guibas*

Main category: cs.CV

TL;DR: 提出了一种基于测试时优化的动物姿态标注方法，通过微调预训练模型在稀疏标注帧上，实现高效自动标注。


<details>
  <summary>Details</summary>
Motivation: 现有方法因数据集不足而不可靠，且动物形态多样导致数据收集困难。

Method: 在稀疏标注帧上微调轻量级外观嵌入模型，应用于其余帧进行自动标注。

Result: 方法在合理标注成本下达到最优性能。

Conclusion: 该流程为动物行为自动量化提供了实用工具。

Abstract: Automatically estimating animal poses from videos is important for studying
animal behaviors. Existing methods do not perform reliably since they are
trained on datasets that are not comprehensive enough to capture all necessary
animal behaviors. However, it is very challenging to collect such datasets due
to the large variations in animal morphology. In this paper, we propose an
animal pose labeling pipeline that follows a different strategy, i.e. test time
optimization. Given a video, we fine-tune a lightweight appearance embedding
inside a pre-trained general-purpose point tracker on a sparse set of annotated
frames. These annotations can be obtained from human labelers or off-the-shelf
pose detectors. The fine-tuned model is then applied to the rest of the frames
for automatic labeling. Our method achieves state-of-the-art performance at a
reasonable annotation cost. We believe our pipeline offers a valuable tool for
the automatic quantification of animal behavior. Visit our project webpage at
https://zhuoyang-pan.github.io/animal-labeling.

</details>


### [304] [JointSplat: Probabilistic Joint Flow-Depth Optimization for Sparse-View Gaussian Splatting](https://arxiv.org/abs/2506.03872)
*Yang Xiao,Guoan Xu,Qiang Wu,Wenjing Jia*

Main category: cs.CV

TL;DR: JointSplat提出了一种结合光流和深度的概率优化框架，解决了稀疏视角3D重建中的几何不一致和噪声问题，并在实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 稀疏视角3D重建在低纹理或重复区域存在定位错误和伪影问题，而光流-深度联合估计因缺乏真实光流监督而容易产生局部噪声和全局不一致。

Method: JointSplat通过概率优化机制融合光流和深度信息，并提出多视角深度一致性损失以抑制不确定区域的误导梯度。

Result: 在RealEstate10K和ACID数据集上，JointSplat表现优于现有方法，验证了其高保真稀疏视角3D重建的有效性和鲁棒性。

Conclusion: JointSplat通过联合优化光流和深度，显著提升了稀疏视角3D重建的质量和一致性。

Abstract: Reconstructing 3D scenes from sparse viewpoints is a long-standing challenge
with wide applications. Recent advances in feed-forward 3D Gaussian sparse-view
reconstruction methods provide an efficient solution for real-time novel view
synthesis by leveraging geometric priors learned from large-scale multi-view
datasets and computing 3D Gaussian centers via back-projection. Despite
offering strong geometric cues, both feed-forward multi-view depth estimation
and flow-depth joint estimation face key limitations: the former suffers from
mislocation and artifact issues in low-texture or repetitive regions, while the
latter is prone to local noise and global inconsistency due to unreliable
matches when ground-truth flow supervision is unavailable. To overcome this, we
propose JointSplat, a unified framework that leverages the complementarity
between optical flow and depth via a novel probabilistic optimization
mechanism. Specifically, this pixel-level mechanism scales the information
fusion between depth and flow based on the matching probability of optical flow
during training. Building upon the above mechanism, we further propose a novel
multi-view depth-consistency loss to leverage the reliability of supervision
while suppressing misleading gradients in uncertain areas. Evaluated on
RealEstate10K and ACID, JointSplat consistently outperforms state-of-the-art
(SOTA) methods, demonstrating the effectiveness and robustness of our proposed
probabilistic joint flow-depth optimization approach for high-fidelity
sparse-view 3D reconstruction.

</details>


### [305] [Video, How Do Your Tokens Merge?](https://arxiv.org/abs/2506.03885)
*Sam Pollard,Michael Wray*

Main category: cs.CV

TL;DR: 视频Transformer模型因输入时空扩展需大量计算资源，近期方法通过随机或学习方式合并或丢弃图像模型token。本文首次评估视频token合并方法在复杂时间数据集上的效果，提出无需训练的token合并策略，在三个数据集上验证其效果，实现约2.5倍加速且精度损失小（ViViT平均-0.55%）。


<details>
  <summary>Details</summary>
Motivation: 视频Transformer模型计算资源需求高，现有方法多针对图像模型，视频领域尚未充分探索token合并的效果。

Method: 提出无需训练的token合并策略，在四种视频Transformer模型和三个数据集上进行实验，验证其在粗粒度和细粒度动作识别中的效果。

Result: 实验显示视频token合并可实现约2.5倍加速，同时精度损失较小（ViViT平均-0.55%）。

Conclusion: 视频token合并是一种高效且无需训练的方法，能显著提升计算效率并保持模型精度。

Abstract: Video transformer models require huge amounts of compute resources due to the
spatio-temporal scaling of the input. Tackling this, recent methods have
proposed to drop or merge tokens for image models, whether randomly or via
learned methods. Merging tokens has many benefits: it can be plugged into any
vision transformer, does not require model re-training, and it propagates
information that would otherwise be dropped through the model. Before now,
video token merging has not been evaluated on temporally complex datasets for
video understanding. In this work, we explore training-free token merging for
video to provide comprehensive experiments and find best practices across four
video transformers on three datasets that exhibit coarse and fine-grained
action recognition. Our results showcase the benefits of video token merging
with a speedup of around $2.5$X while maintaining accuracy (avg. $-0.55\%$ for
ViViT). Code available at
https://github.com/sjpollard/video-how-do-your-tokens-merge.

</details>


### [306] [Joint Video Enhancement with Deblurring, Super-Resolution, and Frame Interpolation Network](https://arxiv.org/abs/2506.03892)
*Giyong Choi,HyunWook Park*

Main category: cs.CV

TL;DR: 提出了一种联合视频增强方法DSFN，通过同时解决多个降质因素，直接从低质量视频生成高质量视频。


<details>
  <summary>Details</summary>
Motivation: 传统视频增强方法因未考虑多因素联合降质而效率低下，需改进。

Method: DSFN网络结合联合去模糊与超分辨率模块（JDSR）和三帧插值模块（TFBFI）进行联合增强。

Result: 实验表明DSFN在公共数据集上优于现有序列方法，网络更小且处理更快。

Conclusion: DSFN为多因素视频降质问题提供了高效解决方案。

Abstract: Video quality is often severely degraded by multiple factors rather than a
single factor. These low-quality videos can be restored to high-quality videos
by sequentially performing appropriate video enhancement techniques. However,
the sequential approach was inefficient and sub-optimal because most video
enhancement approaches were designed without taking into account that multiple
factors together degrade video quality. In this paper, we propose a new joint
video enhancement method that mitigates multiple degradation factors
simultaneously by resolving an integrated enhancement problem. Our proposed
network, named DSFN, directly produces a high-resolution, high-frame-rate, and
clear video from a low-resolution, low-frame-rate, and blurry video. In the
DSFN, low-resolution and blurry input frames are enhanced by a joint deblurring
and super-resolution (JDSR) module. Meanwhile, intermediate frames between
input adjacent frames are interpolated by a triple-frame-based frame
interpolation (TFBFI) module. The proper combination of the proposed modules of
DSFN can achieve superior performance on the joint video enhancement task.
Experimental results show that the proposed method outperforms other sequential
state-of-the-art techniques on public datasets with a smaller network size and
faster processing time.

</details>


### [307] [Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection](https://arxiv.org/abs/2506.03918)
*Marcin Kowalczyk,Kamil Jeziorek,Tomasz Kryjak*

Main category: cs.CV

TL;DR: 提出了一种新的噪声注入训练方法，增强神经网络对事件数据噪声的鲁棒性，优于传统过滤方法。


<details>
  <summary>Details</summary>
Motivation: 事件数据常受噪声影响，传统过滤方法可能丢失有用信息，需更鲁棒的解决方案。

Method: 在训练数据中注入可控噪声，使模型学习抗噪声表示，评估了多种网络架构。

Result: 在多个数据集上表现稳定，分类准确率最高，优于传统过滤方法。

Conclusion: 噪声注入训练是事件数据分类中传统过滤方法的可行替代方案。

Abstract: Event-based sensors offer significant advantages over traditional frame-based
cameras, especially in scenarios involving rapid motion or challenging lighting
conditions. However, event data frequently suffers from considerable noise,
negatively impacting the performance and robustness of deep learning models.
Traditionally, this problem has been addressed by applying filtering algorithms
to the event stream, but this may also remove some of relevant data. In this
paper, we propose a novel noise-injection training methodology designed to
enhance the neural networks robustness against varying levels of event noise.
Our approach introduces controlled noise directly into the training data,
enabling models to learn noise-resilient representations. We have conducted
extensive evaluations of the proposed method using multiple benchmark datasets
(N-Caltech101, N-Cars, and Mini N-ImageNet) and various network architectures,
including Convolutional Neural Networks, Vision Transformers, Spiking Neural
Networks, and Graph Convolutional Networks. Experimental results show that our
noise-injection training strategy achieves stable performance over a range of
noise intensities, consistently outperforms event-filtering techniques, and
achieves the highest average classification accuracy, making it a viable
alternative to traditional event-data filtering methods in an object
classification system. Code: https://github.com/vision-agh/DVS_Filtering

</details>


### [308] [Multiple Stochastic Prompt Tuning for Practical Cross-Domain Few Shot Learning](https://arxiv.org/abs/2506.03926)
*Debarshi Brahma,Soma Biswas*

Main category: cs.CV

TL;DR: 提出了一种实用的跨域少样本学习任务（pCDFSL），利用预训练模型CLIP，通过少量标注样本分类未见类别，并解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有跨域少样本学习方法依赖人工设计的训练和测试模式，难以适应真实场景。pCDFSL任务旨在更贴近实际应用需求。

Method: 提出MIST框架，利用多个随机提示处理域和语义偏移，并通过高斯分布建模提示权重以减少过拟合。

Result: 在四个CDFSL基准测试中，MIST框架表现优于现有方法。

Conclusion: MIST框架有效解决了跨域少样本学习中的挑战，具有实际应用潜力。

Abstract: In this work, we propose a practical cross-domain few-shot learning (pCDFSL)
task, where a large-scale pre-trained model like CLIP can be easily deployed on
a target dataset. The goal is to simultaneously classify all unseen classes
under extreme domain shifts, by utilizing only a few labeled samples per class.
The pCDFSL paradigm is source-free and moves beyond artificially created
episodic training and testing regimes followed by existing CDFSL frameworks,
making it more challenging and relevant to real-world applications. Towards
that goal, we propose a novel framework, termed MIST (MultIple STochastic
Prompt tuning), where multiple stochastic prompts are utilized to handle
significant domain and semantic shifts. Specifically, multiple prompts are
learnt for each class, effectively capturing multiple peaks in the input data.
Furthermore, instead of representing the weights of the multiple prompts as
point-estimates, we model them as learnable Gaussian distributions with two
different strategies, encouraging an efficient exploration of the prompt
parameter space, which mitigate overfitting due to the few labeled training
samples. Extensive experiments and comparison with the state-of-the-art methods
on four CDFSL benchmarks adapted to this setting, show the effectiveness of the
proposed framework.

</details>


### [309] [Vision Remember: Alleviating Visual Forgetting in Efficient MLLM with Vision Feature Resample](https://arxiv.org/abs/2506.03928)
*Ze Feng,Jiang-Jiang Liu,Sen Yang,Lingyu Xiao,Xiaofan Li,Wankou Yang,Jingdong Wang*

Main category: cs.CV

TL;DR: 论文提出Vision Remember方法，通过在LLM解码层之间插入模块，重新记忆视觉特征，解决视觉信息丢失问题，提升细粒度任务性能。


<details>
  <summary>Details</summary>
Motivation: 冗余的视觉token占用大量计算资源，传统压缩方法在Vision Projector中会导致视觉信息丢失，尤其是细粒度空间关系任务（如OCR）。

Method: 提出Vision Remember，保留多级视觉特征并通过局部注意力重新采样，增强细粒度信息。

Result: 在多个视觉理解基准测试中验证了方法的有效性，LLaVA-VR（2B参数）优于Tokenpacker-HD-7B和DeepSeek-VL-7B。

Conclusion: Vision Remember在提升性能的同时不牺牲效率，为多模态大语言模型提供了一种高效解决方案。

Abstract: In this work, we study the Efficient Multimodal Large Language Model.
Redundant vision tokens consume a significant amount of computational memory
and resources. Therefore, many previous works compress them in the Vision
Projector to reduce the number of vision tokens. However, simply compressing in
the Vision Projector can lead to the loss of visual information, especially for
tasks that rely on fine-grained spatial relationships, such as OCR and Chart \&
Table Understanding. To address this problem, we propose Vision Remember, which
is inserted between the LLM decoder layers to allow vision tokens to
re-memorize vision features. Specifically, we retain multi-level vision
features and resample them with the vision tokens that have interacted with the
text token. During the resampling process, each vision token only attends to a
local region in vision features, which is referred to as saliency-enhancing
local attention. Saliency-enhancing local attention not only improves
computational efficiency but also captures more fine-grained contextual
information and spatial relationships within the region. Comprehensive
experiments on multiple visual understanding benchmarks validate the
effectiveness of our method when combined with various Efficient Vision
Projectors, showing performance gains without sacrificing efficiency. Based on
Vision Remember, LLaVA-VR with only 2B parameters is also superior to previous
representative MLLMs such as Tokenpacker-HD-7B and DeepSeek-VL-7B.

</details>


### [310] [DiffCAP: Diffusion-based Cumulative Adversarial Purification for Vision Language Models](https://arxiv.org/abs/2506.03933)
*Jia Fu,Yongtao Wu,Yihang Chen,Kunyu Peng,Xiao Zhang,Volkan Cevher,Sepideh Pashami,Anders Holst*

Main category: cs.CV

TL;DR: DiffCAP是一种基于扩散的净化策略，能有效中和视觉语言模型（VLMs）中的对抗性扰动，显著提升模型在对抗环境中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 尽管VLMs在多模态理解中表现优异，但其对扰动的敏感性可能导致错误输出，威胁实际应用中的可靠性。

Method: DiffCAP通过逐步注入高斯噪声直至图像嵌入稳定，再利用预训练扩散模型去噪，恢复干净表示。

Result: 在多种数据集和任务场景下，DiffCAP显著优于现有防御方法，同时减少了超参数调整和去噪时间。

Conclusion: DiffCAP为对抗环境中安全部署VLMs提供了高效且鲁棒的解决方案。

Abstract: Vision Language Models (VLMs) have shown remarkable capabilities in
multimodal understanding, yet their susceptibility to perturbations poses a
significant threat to their reliability in real-world applications. Despite
often being imperceptible to humans, these perturbations can drastically alter
model outputs, leading to erroneous interpretations and decisions. This paper
introduces DiffCAP, a novel diffusion-based purification strategy that can
effectively neutralize adversarial corruptions in VLMs. We observe that adding
minimal noise to an adversarially corrupted image significantly alters its
latent embedding with respect to VLMs. Building on this insight, DiffCAP
cumulatively injects random Gaussian noise into adversarially perturbed input
data. This process continues until the embeddings of two consecutive noisy
images reach a predefined similarity threshold, indicating a potential approach
to neutralize the adversarial effect. Subsequently, a pretrained diffusion
model is employed to denoise the stabilized image, recovering a clean
representation suitable for the VLMs to produce an output. Through extensive
experiments across six datasets with three VLMs under varying attack strengths
in three task scenarios, we show that DiffCAP consistently outperforms existing
defense techniques by a substantial margin. Notably, DiffCAP significantly
reduces both hyperparameter tuning complexity and the required diffusion time,
thereby accelerating the denoising process. Equipped with strong theoretical
and empirical support, DiffCAP provides a robust and practical solution for
securely deploying VLMs in adversarial environments.

</details>


### [311] [Average Calibration Losses for Reliable Uncertainty in Medical Image Segmentation](https://arxiv.org/abs/2506.03942)
*Theodore Barfoot,Luis C. Garcia-Peraza-Herrera,Samet Akcay,Ben Glocker,Tom Vercauteren*

Main category: cs.CV

TL;DR: 提出了一种可微的mL1-ACE损失函数，用于改善医学图像分割的校准性能，实验表明其能显著降低校准误差，同时保持分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络在医学图像分割中过度自信的问题，以提高预测的可靠性和临床实用性。

Method: 提出硬分箱和软分箱的mL1-ACE损失函数，作为辅助损失，并在四个数据集上验证其效果。

Result: mL1-ACE显著降低了校准误差（ACE和MCE），同时保持了较高的Dice系数；软分箱效果更好但可能影响分割性能。

Conclusion: 该方法提高了分割预测的可信度，有助于深度学习在临床中的安全应用。

Abstract: Deep neural networks for medical image segmentation are often overconfident,
compromising both reliability and clinical utility. In this work, we propose
differentiable formulations of marginal L1 Average Calibration Error (mL1-ACE)
as an auxiliary loss that can be computed on a per-image basis. We compare both
hard- and soft-binning approaches to directly improve pixel-wise calibration.
Our experiments on four datasets (ACDC, AMOS, KiTS, BraTS) demonstrate that
incorporating mL1-ACE significantly reduces calibration errors, particularly
Average Calibration Error (ACE) and Maximum Calibration Error (MCE), while
largely maintaining high Dice Similarity Coefficients (DSCs). We find that the
soft-binned variant yields the greatest improvements in calibration, over the
Dice plus cross-entropy loss baseline, but often compromises segmentation
performance, with hard-binned mL1-ACE maintaining segmentation performance,
albeit with weaker calibration improvement. To gain further insight into
calibration performance and its variability across an imaging dataset, we
introduce dataset reliability histograms, an aggregation of per-image
reliability diagrams. The resulting analysis highlights improved alignment
between predicted confidences and true accuracies. Overall, our approach not
only enhances the trustworthiness of segmentation predictions but also shows
potential for safer integration of deep learning methods into clinical
workflows. We share our code here:
https://github.com/cai4cai/Average-Calibration-Losses

</details>


### [312] [MS-YOLO: A Multi-Scale Model for Accurate and Efficient Blood Cell Detection](https://arxiv.org/abs/2506.03972)
*Guohua Wu,Shengqi Chen,Pengchao Deng,Wenting Yu*

Main category: cs.CV

TL;DR: MS-YOLO是一种基于YOLOv11的血液细胞检测模型，通过多尺度扩张残差模块、动态跨路径特征增强模块和轻量自适应权重下采样模块提升检测性能，在CBC和WBCDD数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统手动显微镜方法效率低且准确性不足，现有自动化检测方法成本高且精度不理想，深度学习在重叠细胞和多尺度目标检测中仍面临挑战。

Method: 提出MS-YOLO模型，包含多尺度扩张残差模块（MS-DRM）、动态跨路径特征增强模块（DCFEM）和轻量自适应权重下采样模块（LADS）。

Result: 在CBC基准测试中mAP@50达97.4%，优于现有模型，并在WBCDD数据集上验证了泛化能力。

Conclusion: MS-YOLO具有轻量架构和实时推理效率，满足临床部署需求，为标准化血液病理评估提供技术支持。

Abstract: Complete blood cell detection holds significant value in clinical
diagnostics. Conventional manual microscopy methods suffer from time
inefficiency and diagnostic inaccuracies. Existing automated detection
approaches remain constrained by high deployment costs and suboptimal accuracy.
While deep learning has introduced powerful paradigms to this field, persistent
challenges in detecting overlapping cells and multi-scale objects hinder
practical deployment. This study proposes the multi-scale YOLO (MS-YOLO), a
blood cell detection model based on the YOLOv11 framework, incorporating three
key architectural innovations to enhance detection performance. Specifically,
the multi-scale dilated residual module (MS-DRM) replaces the original C3K2
modules to improve multi-scale discriminability; the dynamic cross-path feature
enhancement module (DCFEM) enables the fusion of hierarchical features from the
backbone with aggregated features from the neck to enhance feature
representations; and the light adaptive-weight downsampling module (LADS)
improves feature downsampling through adaptive spatial weighting while reducing
computational complexity. Experimental results on the CBC benchmark demonstrate
that MS-YOLO achieves precise detection of overlapping cells and multi-scale
objects, particularly small targets such as platelets, achieving an mAP@50 of
97.4% that outperforms existing models. Further validation on the supplementary
WBCDD dataset confirms its robust generalization capability. Additionally, with
a lightweight architecture and real-time inference efficiency, MS-YOLO meets
clinical deployment requirements, providing reliable technical support for
standardized blood pathology assessment.

</details>


### [313] [RAID: A Dataset for Testing the Adversarial Robustness of AI-Generated Image Detectors](https://arxiv.org/abs/2506.03988)
*Hicham Eddoubi,Jonas Ricker,Federico Cocchi,Lorenzo Baraldi,Angelo Sotgiu,Maura Pintor,Marcella Cornia,Lorenzo Baraldi,Asja Fischer,Rita Cucchiara,Battista Biggio*

Main category: cs.CV

TL;DR: 论文提出了一种评估AI生成图像检测器鲁棒性的方法，并发布了包含72k对抗样本的数据集RAID，实验表明现有检测器易受对抗样本欺骗。


<details>
  <summary>Details</summary>
Motivation: AI生成图像质量已高到人类难以区分，检测其真实性成为迫切需求，但现有方法在对抗鲁棒性上评估不足。

Method: 提出RAID数据集，通过攻击七种先进检测器和四种文本生成图像模型，生成多样且高迁移性的对抗样本。

Result: 实验显示对抗样本能高效欺骗未见过的新检测器，表明现有检测器鲁棒性不足。

Conclusion: 当前AI生成图像检测器易受对抗攻击，需开发更鲁棒的方法。数据集和代码已公开。

Abstract: AI-generated images have reached a quality level at which humans are
incapable of reliably distinguishing them from real images. To counteract the
inherent risk of fraud and disinformation, the detection of AI-generated images
is a pressing challenge and an active research topic. While many of the
presented methods claim to achieve high detection accuracy, they are usually
evaluated under idealized conditions. In particular, the adversarial robustness
is often neglected, potentially due to a lack of awareness or the substantial
effort required to conduct a comprehensive robustness analysis. In this work,
we tackle this problem by providing a simpler means to assess the robustness of
AI-generated image detectors. We present RAID (Robust evaluation of
AI-generated image Detectors), a dataset of 72k diverse and highly transferable
adversarial examples. The dataset is created by running attacks against an
ensemble of seven state-of-the-art detectors and images generated by four
different text-to-image models. Extensive experiments show that our methodology
generates adversarial images that transfer with a high success rate to unseen
detectors, which can be used to quickly provide an approximate yet still
reliable estimate of a detector's adversarial robustnessOur findings indicate
that current state-of-the-art AI-generated image detectors can be easily
deceived by adversarial examples, highlighting the critical need for the
development of more robust methods. We release our dataset at
https://huggingface.co/datasets/aimagelab/RAID and evaluation code at
https://github.com/pralab/RAID.

</details>


### [314] [Vocabulary-free few-shot learning for Vision-Language Models](https://arxiv.org/abs/2506.04005)
*Maxime Zanella,Clément Fuchs,Ismail Ben Ayed,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 论文提出了一种无需词汇表的少样本学习方法（SiM），通过相似性映射分类目标实例，摆脱了对预定义类名的依赖，具有高效和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预定义的类名提示，限制了其适用性，尤其是在类名难以获取或指定的场景中。

Method: 提出Similarity Mapping（SiM），仅基于与通用提示（文本或视觉）的相似性分数分类目标实例。

Result: SiM表现优异，计算高效（学习映射通常不到一秒），并能通过链接目标类与通用提示提供可解释性。

Conclusion: SiM为无需词汇表的少样本学习提供了重要基线，未来研究可在此基础上进一步探索。

Abstract: Recent advances in few-shot adaptation for Vision-Language Models (VLMs) have
greatly expanded their ability to generalize across tasks using only a few
labeled examples. However, existing approaches primarily build upon the strong
zero-shot priors of these models by leveraging carefully designed,
task-specific prompts. This dependence on predefined class names can restrict
their applicability, especially in scenarios where exact class names are
unavailable or difficult to specify. To address this limitation, we introduce
vocabulary-free few-shot learning for VLMs, a setting where target class
instances - that is, images - are available but their corresponding names are
not. We propose Similarity Mapping (SiM), a simple yet effective baseline that
classifies target instances solely based on similarity scores with a set of
generic prompts (textual or visual), eliminating the need for carefully
handcrafted prompts. Although conceptually straightforward, SiM demonstrates
strong performance, operates with high computational efficiency (learning the
mapping typically takes less than one second), and provides interpretability by
linking target classes to generic prompts. We believe that our approach could
serve as an important baseline for future research in vocabulary-free few-shot
learning. Code is available at
https://github.com/MaxZanella/vocabulary-free-FSL.

</details>


### [315] [Rex-Thinker: Grounded Object Referring via Chain-of-Thought Reasoning](https://arxiv.org/abs/2506.04034)
*Qing Jiang,Xingyu Chen,Zhaoyang Zeng,Junzhi Yu,Lei Zhang*

Main category: cs.CV

TL;DR: Rex-Thinker将对象引用任务转化为显式的思维链（CoT）推理任务，通过分步验证候选对象是否匹配描述，提升模型的解释性和可信度。


<details>
  <summary>Details</summary>
Motivation: 现有方法将对象引用视为直接的边界框预测任务，缺乏解释性且难以处理无匹配对象的情况。Rex-Thinker旨在通过显式推理解决这些问题。

Method: 提出Rex-Thinker模型，分两步训练：1）监督微调阶段学习结构化推理；2）GRPO强化学习提升准确性和泛化能力。构建HumanRef-CoT数据集支持推理任务。

Result: 实验表明，Rex-Thinker在精度和解释性上优于基线，且能更好地拒绝无匹配对象的输出，泛化能力更强。

Conclusion: Rex-Thinker通过显式推理和分步验证，显著提升了对象引用任务的解释性和可信度。

Abstract: Object referring aims to detect all objects in an image that match a given
natural language description. We argue that a robust object referring model
should be grounded, meaning its predictions should be both explainable and
faithful to the visual content. Specifically, it should satisfy two key
properties: 1) Verifiable, by producing interpretable reasoning that justifies
its predictions and clearly links them to visual evidence; and 2) Trustworthy,
by learning to abstain when no object in the image satisfies the given
expression. However, most methods treat referring as a direct bounding box
prediction task, offering limited interpretability and struggling to reject
expressions with no matching object. In this work, we propose Rex-Thinker, a
model that formulates object referring as an explicit CoT reasoning task. Given
a referring expression, we first identify all candidate object instances
corresponding to the referred object category. Rex-Thinker then performs
step-by-step reasoning over each candidate to assess whether it matches the
given expression, before making a final prediction. To support this paradigm,
we construct a large-scale CoT-style referring dataset named HumanRef-CoT by
prompting GPT-4o on the HumanRef dataset. Each reasoning trace follows a
structured planning, action, and summarization format, enabling the model to
learn decomposed, interpretable reasoning over object candidates. We then train
Rex-Thinker in two stages: a cold-start supervised fine-tuning phase to teach
the model how to perform structured reasoning, followed by GRPO-based RL
learning to improve accuracy and generalization. Experiments show that our
approach outperforms standard baselines in both precision and interpretability
on in-domain evaluation, while also demonstrating improved ability to reject
hallucinated outputs and strong generalization in out-of-domain settings.

</details>


### [316] [Mitigating Hallucinations in Large Vision-Language Models via Entity-Centric Multimodal Preference Optimization](https://arxiv.org/abs/2506.04039)
*Jiulong Wu,Zhengliang Shi,Shuaiqiang Wang,Jizhou Huang,Dawei Yin,Lingyong Yan,Min Cao,Min Zhang*

Main category: cs.CV

TL;DR: 论文提出Entity-centric Multimodal Preference Optimization (EMPO)，通过增强模态对齐减少大视觉语言模型（LVLMs）的幻觉问题，并在实验中显著降低了幻觉率。


<details>
  <summary>Details</summary>
Motivation: 现有偏好对齐方法忽视图像-文本模态对齐，导致对大型语言模型（LLMs）的过度依赖和幻觉问题。

Method: 提出EMPO方法，通过自动构建高质量多模态偏好数据，增强模态对齐。

Result: 在实验中，EMPO显著降低了幻觉率（如Object-HalBench降低85.9%，MM-HalBench降低49.8%）。

Conclusion: EMPO有效解决了LVLMs的幻觉问题，提升了模型的可信度。

Abstract: Large Visual Language Models (LVLMs) have demonstrated impressive
capabilities across multiple tasks. However, their trustworthiness is often
challenged by hallucinations, which can be attributed to the modality
misalignment and the inherent hallucinations of their underlying Large Language
Models (LLMs) backbone. Existing preference alignment methods focus on aligning
model responses with human preferences while neglecting image-text modality
alignment, resulting in over-reliance on LLMs and hallucinations. In this
paper, we propose Entity-centric Multimodal Preference Optimization (EMPO),
which achieves enhanced modality alignment than existing human preference
alignment methods. Besides, to overcome the scarcity of high-quality multimodal
preference data, we utilize open-source instruction datasets to automatically
construct high-quality preference data across three aspects: image,
instruction, and response. Experiments on two human preference datasets and
five multimodal hallucination benchmarks demonstrate the effectiveness of EMPO,
e.g., reducing hallucination rates by 85.9% on Object-HalBench and 49.8% on
MM-HalBench.

</details>


### [317] [EV-Flying: an Event-based Dataset for In-The-Wild Recognition of Flying Objects](https://arxiv.org/abs/2506.04048)
*Gabriele Magrini,Federico Becattini,Giovanni Colombo,Pietro Pala*

Main category: cs.CV

TL;DR: 论文提出了一种基于事件相机的事件流处理方法EV-Flying，用于检测和识别飞行物体，解决了传统RGB方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统RGB方法在检测飞行物体时面临尺度变化、运动模糊和高速运动等挑战，尤其是对昆虫和无人机等小物体。事件相机的高时间分辨率和低延迟特性使其更适合此类任务。

Method: 使用事件相机采集数据，构建EV-Flying数据集，包含鸟类、昆虫和无人机的标注数据。采用基于点云的事件流处理方法，受PointNet启发的轻量级架构。

Result: 提出了一种高效的事件流处理方法，能够分类飞行物体，为实际场景中的空中物体识别提供了新思路。

Conclusion: EV-Flying数据集和方法为飞行物体检测和识别提供了更高效可靠的解决方案，推动了事件相机在相关领域的应用。

Abstract: Monitoring aerial objects is crucial for security, wildlife conservation, and
environmental studies. Traditional RGB-based approaches struggle with
challenges such as scale variations, motion blur, and high-speed object
movements, especially for small flying entities like insects and drones. In
this work, we explore the potential of event-based vision for detecting and
recognizing flying objects, in particular animals that may not follow short and
long-term predictable patters. Event cameras offer high temporal resolution,
low latency, and robustness to motion blur, making them well-suited for this
task. We introduce EV-Flying, an event-based dataset of flying objects,
comprising manually annotated birds, insects and drones with spatio-temporal
bounding boxes and track identities. To effectively process the asynchronous
event streams, we employ a point-based approach leveraging lightweight
architectures inspired by PointNet. Our study investigates the classification
of flying objects using point cloud-based event representations. The proposed
dataset and methodology pave the way for more efficient and reliable aerial
object recognition in real-world scenarios.

</details>


### [318] [Video Deblurring with Deconvolution and Aggregation Networks](https://arxiv.org/abs/2506.04054)
*Giyong Choi,HyunWook Park*

Main category: cs.CV

TL;DR: 论文提出了一种用于视频去模糊的解卷积与聚合网络（DAN），通过三个子网络有效利用相邻帧信息，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频去模糊算法未能充分利用相邻帧信息，导致性能不佳。

Method: DAN包含预处理网络（PPN）、基于对齐的解卷积网络（ABDN）和帧聚合网络（FAN），分别负责预处理、解卷积和聚合。

Result: 实验表明，DAN在公开数据集上定量和定性评估均优于现有方法。

Conclusion: DAN通过合理结合三个子网络，有效利用相邻帧信息，实现了优异的视频去模糊性能。

Abstract: In contrast to single-image deblurring, video deblurring has the advantage
that neighbor frames can be utilized to deblur a target frame. However,
existing video deblurring algorithms often fail to properly employ the neighbor
frames, resulting in sub-optimal performance. In this paper, we propose a
deconvolution and aggregation network (DAN) for video deblurring that utilizes
the information of neighbor frames well. In DAN, both deconvolution and
aggregation strategies are achieved through three sub-networks: the
preprocessing network (PPN) and the alignment-based deconvolution network
(ABDN) for the deconvolution scheme; the frame aggregation network (FAN) for
the aggregation scheme. In the deconvolution part, blurry inputs are first
preprocessed by the PPN with non-local operations. Then, the output frames from
the PPN are deblurred by the ABDN based on the frame alignment. In the FAN,
these deblurred frames from the deconvolution part are combined into a latent
frame according to reliability maps which infer pixel-wise sharpness. The
proper combination of three sub-networks can achieve favorable performance on
video deblurring by using the neighbor frames suitably. In experiments, the
proposed DAN was demonstrated to be superior to existing state-of-the-art
methods through both quantitative and qualitative evaluations on the public
datasets.

</details>


### [319] [Point Cloud Quality Assessment Using the Perceptual Clustering Weighted Graph (PCW-Graph) and Attention Fusion Network](https://arxiv.org/abs/2506.04081)
*Abdelouahed Laazoufi,Mohammed El Hassouni,Hocine Cherifi*

Main category: cs.CV

TL;DR: 无参考点云质量评估（NR-PCQA）在无参考模型的实际应用中至关重要。


<details>
  <summary>Details</summary>
Motivation: 由于实际应用中常缺乏参考模型，需要一种方法来评估3D内容的质量。

Method: 未提及具体方法。

Result: 未提及具体结果。

Conclusion: NR-PCQA在无参考模型的情况下对3D内容质量评估具有重要意义。

Abstract: No-Reference Point Cloud Quality Assessment (NR-PCQA) is critical for
evaluating 3D content in real-world applications where reference models are
unavailable.

</details>


### [320] [GlobalBuildingAtlas: An Open Global and Complete Dataset of Building Polygons, Heights and LoD1 3D Models](https://arxiv.org/abs/2506.04106)
*Xiao Xiang Zhu,Sining Chen,Fahong Zhang,Yilei Shi,Yuanyuan Wang*

Main category: cs.CV

TL;DR: GlobalBuildingAtlas是一个公开数据集，提供全球建筑多边形、高度和LoD1 3D建筑模型，覆盖全面且高质量。


<details>
  <summary>Details</summary>
Motivation: 填补全球范围内高质量、一致的2D和3D建筑数据的空白，支持高分辨率地理空间分析。

Method: 利用机器学习从卫星数据提取建筑多边形和高度，结合质量融合策略优化数据。

Result: 数据集包含27.5亿建筑，高度分辨率达3x3米，LoD1模型覆盖97%建筑高度，误差1.5-8.9米。

Conclusion: GlobalBuildingAtlas为全球建筑现状提供新视角，支持联合国可持续发展目标监测。

Abstract: We introduce GlobalBuildingAtlas, a publicly available dataset providing
global and complete coverage of building polygons, heights and Level of Detail
1 (LoD1) 3D building models. This is the first open dataset to offer high
quality, consistent, and complete building data in 2D and 3D form at the
individual building level on a global scale. Towards this dataset, we developed
machine learning-based pipelines to derive building polygons and heights
(called GBA.Height) from global PlanetScope satellite data, respectively. Also
a quality-based fusion strategy was employed to generate higher-quality
polygons (called GBA.Polygon) based on existing open building polygons,
including our own derived one. With more than 2.75 billion buildings worldwide,
GBA.Polygon surpasses the most comprehensive database to date by more than 1
billion buildings. GBA.Height offers the most detailed and accurate global 3D
building height maps to date, achieving a spatial resolution of 3x3 meters-30
times finer than previous global products (90 m), enabling a high-resolution
and reliable analysis of building volumes at both local and global scales.
Finally, we generated a global LoD1 building model (called GBA.LoD1) from the
resulting GBA.Polygon and GBA.Height. GBA.LoD1 represents the first complete
global LoD1 building models, including 2.68 billion building instances with
predicted heights, i.e., with a height completeness of more than 97%, achieving
RMSEs ranging from 1.5 m to 8.9 m across different continents. With its height
accuracy, comprehensive global coverage and rich spatial details,
GlobalBuildingAltas offers novel insights on the status quo of global
buildings, which unlocks unprecedented geospatial analysis possibilities, as
showcased by a better illustration of where people live and a more
comprehensive monitoring of the progress on the 11th Sustainable Development
Goal of the United Nations.

</details>


### [321] [Multi-view Surface Reconstruction Using Normal and Reflectance Cues](https://arxiv.org/abs/2506.04115)
*Robin Bruneau,Baptiste Brument,Yvain Quéau,Jean Mélou,François Bernard Lauze,Jean-Denis Durou,Lilian Calvet*

Main category: cs.CV

TL;DR: 本文提出了一种结合多视角法线和反射率图的高保真3D表面重建框架，适用于复杂反射材料和稀疏视角场景，并在多个基准数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 在复杂反射材料和稀疏视角条件下，实现高保真3D表面重建仍具挑战性。

Method: 采用像素级的反射率和表面法线联合重参数化，将其表示为模拟光照下的辐射向量，并集成到传统或神经体积渲染框架中。

Result: 在MVPS基准数据集（如DiLiGenT-MV、LUCES-MV和Skoltech3D）上达到最先进性能，尤其在细节重建和复杂可见性条件下表现突出。

Conclusion: 该方法显著提升了3D表面重建的细节保真度和鲁棒性，是Brument等人先前工作的扩展版本，代码和数据已开源。

Abstract: Achieving high-fidelity 3D surface reconstruction while preserving fine
details remains challenging, especially in the presence of materials with
complex reflectance properties and without a dense-view setup. In this paper,
we introduce a versatile framework that incorporates multi-view normal and
optionally reflectance maps into radiance-based surface reconstruction. Our
approach employs a pixel-wise joint re-parametrization of reflectance and
surface normals, representing them as a vector of radiances under simulated,
varying illumination. This formulation enables seamless incorporation into
standard surface reconstruction pipelines, such as traditional multi-view
stereo (MVS) frameworks or modern neural volume rendering (NVR) ones. Combined
with the latter, our approach achieves state-of-the-art performance on
multi-view photometric stereo (MVPS) benchmark datasets, including DiLiGenT-MV,
LUCES-MV and Skoltech3D. In particular, our method excels in reconstructing
fine-grained details and handling challenging visibility conditions. The
present paper is an extended version of the earlier conference paper by Brument
et al. (in Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR), 2024), featuring an accelerated and more robust
algorithm as well as a broader empirical evaluation. The code and data relative
to this article is available at https://github.com/RobinBruneau/RNb-NeuS2.

</details>


### [322] [Contour Errors: An Ego-Centric Metric for Reliable 3D Multi-Object Tracking](https://arxiv.org/abs/2506.04122)
*Sharang Kaul,Mario Berk,Thiemo Gerbich,Abhinav Valada*

Main category: cs.CV

TL;DR: 论文提出了一种新的匹配度量方法Contour Errors（CEs），用于解决3D场景中传统2D匹配指标（如IoU和CPD）的不足，显著提升了多目标跟踪的可靠性。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶等安全关键应用中，可靠的匹配对感知系统的准确性至关重要。传统2D指标在复杂3D场景中表现不佳，因此需要一种更功能相关的匹配度量方法。

Method: 提出Contour Errors（CEs），一种基于自我或目标中心的度量方法，通过比较自我车辆坐标系中的边界框来评估匹配的功能相关性。

Result: 在nuScenes数据集上的实验表明，CEs显著优于传统2D指标，在3D车辆跟踪中，功能失败率（FPs/FNs）在近距离和远距离分别降低了80%和60%。

Conclusion: Contour Errors提供了一种更有效的匹配度量方法，显著提升了多目标跟踪的性能和安全性。

Abstract: Finding reliable matches is essential in multi-object tracking to ensure the
accuracy and reliability of perception systems in safety-critical applications
such as autonomous vehicles. Effective matching mitigates perception errors,
enhancing object identification and tracking for improved performance and
safety. However, traditional metrics such as Intersection over Union (IoU) and
Center Point Distances (CPDs), which are effective in 2D image planes, often
fail to find critical matches in complex 3D scenes. To address this limitation,
we introduce Contour Errors (CEs), an ego or object-centric metric for
identifying matches of interest in tracking scenarios from a functional
perspective. By comparing bounding boxes in the ego vehicle's frame, contour
errors provide a more functionally relevant assessment of object matches.
Extensive experiments on the nuScenes dataset demonstrate that contour errors
improve the reliability of matches over the state-of-the-art 2D IoU and CPD
metrics in tracking-by-detection methods. In 3D car tracking, our results show
that Contour Errors reduce functional failures (FPs/FNs) by 80% at close ranges
and 60% at far ranges compared to IoU in the evaluation stage.

</details>


### [323] [UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation](https://arxiv.org/abs/2506.04134)
*Jinting Wang,Shan Yang,Li Liu*

Main category: cs.CV

TL;DR: UniCUE框架通过直接生成语音，避免了中间文本的误差传播和时间不对齐问题，显著提升了CS视频到语音的转换效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖中间文本进行CS视频到语音转换，导致误差传播和时间不对齐。UniCUE旨在直接生成语音，解决这些问题。

Method: 提出UniCUE框架，包括细粒度语义对齐池、VisioPhonetic适配器和姿态感知视觉处理器，直接生成语音。

Result: 在中文CS数据集上，UniCUE将词错误率降低78.3%，唇语音同步性提升32%。

Conclusion: UniCUE通过直接生成语音和跨任务表示融合，显著提升了CS视频到语音的转换性能。

Abstract: Cued Speech (CS) enhances lipreading through hand coding, providing precise
speech perception support for the hearing-impaired. CS Video-to-Speech
generation (CSV2S) task aims to convert the CS visual expressions (CS videos)
of hearing-impaired individuals into comprehensible speech signals. Direct
generation of speech from CS video (called single CSV2S) yields poor
performance due to insufficient CS data. Current research mostly focuses on CS
Recognition (CSR), which convert video content into linguistic text. Based on
this, one straightforward way of CSV2S is to combine CSR with a Text-to-Speech
system. This combined architecture relies on text as an intermediate medium for
stepwise cross-modal alignment, which may lead to error propagation and
temporal misalignment between speech and video dynamics. To address these
challenges, we propose a novel approach that directly generates speech from CS
videos without relying on intermediate text. Building upon this, we propose
UniCUE, the first unified framework for CSV2S, whose core innovation lies in
the integration of the CSR task that provides fine-grained visual-semantic
information to facilitate speech generation from CS videos. More precisely, (1)
a novel fine-grained semantic alignment pool to ensure precise mapping between
visual features and speech contents; (2) a VisioPhonetic adapter to bridge
cross-task representations, ensuring seamless compatibility between two
distinct tasks (i.e., CSV2S and CSR); (3) a pose-aware visual processor is
introduced to enhance fine-grained spatiotemporal correlations between lip and
hand movements in CS video. Experiments on our new established Chinese CS
dataset (14 cuers1: 8 hearing-impaired and 6 normal-hearing) show that our
UniCUE significantly reduces Word Error Rate by 78.3% and improves lip-speech
synchronization by 32% compared to the single CSV2S.

</details>


### [324] [MMR-V: What's Left Unsaid? A Benchmark for Multimodal Deep Reasoning in Videos](https://arxiv.org/abs/2506.04141)
*Kejian Zhu,Zhuoran Jin,Hongbang Yuan,Jiachun Li,Shangqing Tu,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CV

TL;DR: MMR-V是一个视频多模态深度推理基准，要求模型进行长距离多帧推理，超越直接感知，并具有可靠性和混淆性。实验显示当前模型表现不佳，推理增强策略效果有限。


<details>
  <summary>Details</summary>
Motivation: 现有视频基准主要关注理解任务，缺乏对多帧证据定位和多模态推理能力的测试，因此提出了MMR-V。

Method: MMR-V包含317个视频和1,257个任务，要求模型进行长距离多帧推理，并设计了混淆性策略以减少模型捷径。

Result: 当前模型在多模态推理上表现较差，最佳模型o4-mini准确率仅52.5%，推理增强策略效果有限。

Conclusion: MMR-V可推动多模态推理能力的研究，当前模型的推理能力仍需提升。

Abstract: The sequential structure of videos poses a challenge to the ability of
multimodal large language models (MLLMs) to locate multi-frame evidence and
conduct multimodal reasoning. However, existing video benchmarks mainly focus
on understanding tasks, which only require models to match frames mentioned in
the question (hereafter referred to as "question frame") and perceive a few
adjacent frames. To address this gap, we propose MMR-V: A Benchmark for
Multimodal Deep Reasoning in Videos. The benchmark is characterized by the
following features. (1) Long-range, multi-frame reasoning: Models are required
to infer and analyze evidence frames that may be far from the question frame.
(2) Beyond perception: Questions cannot be answered through direct perception
alone but require reasoning over hidden information. (3) Reliability: All tasks
are manually annotated, referencing extensive real-world user understanding to
align with common perceptions. (4) Confusability: Carefully designed distractor
annotation strategies to reduce model shortcuts. MMR-V consists of 317 videos
and 1,257 tasks. Our experiments reveal that current models still struggle with
multi-modal reasoning; even the best-performing model, o4-mini, achieves only
52.5% accuracy. Additionally, current reasoning enhancement strategies
(Chain-of-Thought and scaling test-time compute) bring limited gains. Further
analysis indicates that the CoT demanded for multi-modal reasoning differs from
it in textual reasoning, which partly explains the limited performance gains.
We hope that MMR-V can inspire further research into enhancing multi-modal
reasoning capabilities.

</details>


### [325] [Person Re-Identification System at Semantic Level based on Pedestrian Attributes Ontology](https://arxiv.org/abs/2506.04143)
*Ngoc Q. Ly,Hieu N. M. Cao,Thi T. Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一种统一的行人再识别系统，包含三个模块（PAO、Local MDCNN、IDS），通过语义信息解决属性不平衡问题，并在Market1501数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 行人再识别在视频监控中至关重要，但现有方法面临数据集规模大、数据不平衡、视角变化等问题，尤其是属性的语义级利用和平衡问题未被充分解决。

Method: 提出统一系统，结合PAO、Local MDCNN和IDS模块，利用属性内组关联和语义信息预筛选候选，无需调整网络架构或数据增强。

Result: 在Market1501数据集上验证了系统的有效性，性能优于现有方法。

Conclusion: 该系统通过模块间的协同作用，有效解决了属性不平衡问题，提升了行人再识别的性能。

Abstract: Person Re-Identification (Re-ID) is a very important task in video
surveillance systems such as tracking people, finding people in public places,
or analysing customer behavior in supermarkets. Although there have been many
works to solve this problem, there are still remaining challenges such as
large-scale datasets, imbalanced data, viewpoint, fine grained data
(attributes), the Local Features are not employed at semantic level in online
stage of Re-ID task, furthermore, the imbalanced data problem of attributes are
not taken into consideration. This paper has proposed a Unified Re-ID system
consisted of three main modules such as Pedestrian Attribute Ontology (PAO),
Local Multi-task DCNN (Local MDCNN), Imbalance Data Solver (IDS). The new main
point of our Re-ID system is the power of mutual support of PAO, Local MDCNN
and IDS to exploit the inner-group correlations of attributes and pre-filter
the mismatch candidates from Gallery set based on semantic information as
Fashion Attributes and Facial Attributes, to solve the imbalanced data of
attributes without adjusting network architecture and data augmentation. We
experimented on the well-known Market1501 dataset. The experimental results
have shown the effectiveness of our Re-ID system and it could achieve the
higher performance on Market1501 dataset in comparison to some state-of-the-art
Re-ID methods.

</details>


### [326] [Image Editing As Programs with Diffusion Models](https://arxiv.org/abs/2506.04158)
*Yujia Hu,Songhua Liu,Zhenxiong Tan,Xingyi Yang,Xinchao Wang*

Main category: cs.CV

TL;DR: IEAP框架通过将复杂编辑指令分解为原子操作，显著提升了扩散模型在结构不一致编辑任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在文本到图像生成中表现优异，但在指令驱动的图像编辑中面临结构不一致编辑的挑战。

Method: 提出IEAP框架，基于DiT架构，将编辑指令分解为原子操作，每个操作由轻量级适配器实现，并通过VLM代理编程。

Result: IEAP在多种编辑任务中显著优于现有方法，尤其在复杂多步指令下表现出更高的准确性和语义保真度。

Conclusion: IEAP通过模块化和序列化编辑操作，为结构不一致的图像编辑提供了高效且通用的解决方案。

Abstract: While diffusion models have achieved remarkable success in text-to-image
generation, they encounter significant challenges with instruction-driven image
editing. Our research highlights a key challenge: these models particularly
struggle with structurally inconsistent edits that involve substantial layout
changes. To mitigate this gap, we introduce Image Editing As Programs (IEAP), a
unified image editing framework built upon the Diffusion Transformer (DiT)
architecture. At its core, IEAP approaches instructional editing through a
reductionist lens, decomposing complex editing instructions into sequences of
atomic operations. Each operation is implemented via a lightweight adapter
sharing the same DiT backbone and is specialized for a specific type of edit.
Programmed by a vision-language model (VLM)-based agent, these operations
collaboratively support arbitrary and structurally inconsistent
transformations. By modularizing and sequencing edits in this way, IEAP
generalizes robustly across a wide range of editing tasks, from simple
adjustments to substantial structural changes. Extensive experiments
demonstrate that IEAP significantly outperforms state-of-the-art methods on
standard benchmarks across various editing scenarios. In these evaluations, our
framework delivers superior accuracy and semantic fidelity, particularly for
complex, multi-step instructions. Codes are available at
https://github.com/YujiaHu1109/IEAP.

</details>


### [327] [FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting](https://arxiv.org/abs/2506.04174)
*Hengyu Liu,Yuehao Wang,Chenxin Li,Ruisi Cai,Kevin Wang,Wuyang Li,Pavlo Molchanov,Peihao Wang,Zhangyang Wang*

Main category: cs.CV

TL;DR: 提出了一种弹性推理方法，用于3D高斯溅射（3DGS），无需微调即可适应不同设备的特定内存需求。


<details>
  <summary>Details</summary>
Motivation: 3DGS在GPU内存需求较高，限制了其在计算资源受限设备上的应用。现有方法通常需要微调且缺乏适应性。

Method: 通过可学习模块选择并变换高斯子集，实现弹性推理，无需额外微调。

Result: 在ZipNeRF、MipNeRF和Tanks&Temples场景中验证了方法的有效性。

Conclusion: 该方法显著提升了3DGS的适应性，适用于不同内存需求的设备。

Abstract: 3D Gaussian splatting (3DGS) has enabled various applications in 3D scene
representation and novel view synthesis due to its efficient rendering
capabilities. However, 3DGS demands relatively significant GPU memory, limiting
its use on devices with restricted computational resources. Previous approaches
have focused on pruning less important Gaussians, effectively compressing 3DGS
but often requiring a fine-tuning stage and lacking adaptability for the
specific memory needs of different devices. In this work, we present an elastic
inference method for 3DGS. Given an input for the desired model size, our
method selects and transforms a subset of Gaussians, achieving substantial
rendering performance without additional fine-tuning. We introduce a tiny
learnable module that controls Gaussian selection based on the input
percentage, along with a transformation module that adjusts the selected
Gaussians to complement the performance of the reduced model. Comprehensive
experiments on ZipNeRF, MipNeRF and Tanks\&Temples scenes demonstrate the
effectiveness of our approach. Code is available at https://flexgs.github.io.

</details>


### [328] [Language-Image Alignment with Fixed Text Encoders](https://arxiv.org/abs/2506.04209)
*Jingfeng Yang,Ziyang Wu,Yue Zhao,Yi Ma*

Main category: cs.CV

TL;DR: 论文提出了一种名为LIFT的简化框架，通过固定预训练的大型语言模型（LLM）作为文本编码器，仅训练图像编码器来实现语言-图像对齐，效果优于CLIP，尤其在组合理解和长标题场景中。


<details>
  <summary>Details</summary>
Motivation: 质疑当前主流的联合训练方法（如CLIP）是否必要，探索预训练的固定LLM是否能作为足够好的文本编码器指导视觉表示学习。

Method: 提出LIFT框架，固定LLM作为文本编码器，仅训练图像编码器，实现语言-图像对齐。

Result: LIFT在组合理解和长标题任务中表现优于CLIP，同时显著提升计算效率。

Conclusion: 研究表明固定LLM文本编码器可以高效指导视觉学习，为语言对齐的视觉表示学习提供了新的设计选择。

Abstract: Currently, the most dominant approach to establishing language-image
alignment is to pre-train text and image encoders jointly through contrastive
learning, such as CLIP and its variants. In this work, we question whether such
a costly joint training is necessary. In particular, we investigate if a
pre-trained fixed large language model (LLM) offers a good enough text encoder
to guide visual representation learning. That is, we propose to learn
Language-Image alignment with a Fixed Text encoder (LIFT) from an LLM by
training only the image encoder. Somewhat surprisingly, through comprehensive
benchmarking and ablation studies, we find that this much simplified framework
LIFT is highly effective and it outperforms CLIP in most scenarios that involve
compositional understanding and long captions, while achieving considerable
gains in computational efficiency. Our work takes a first step towards
systematically exploring how text embeddings from LLMs can guide visual
learning and suggests an alternative design choice for learning
language-aligned visual representations.

</details>


### [329] [Diffusion Domain Teacher: Diffusion Guided Domain Adaptive Object Detector](https://arxiv.org/abs/2506.04211)
*Boyong He,Yuxiang Ji,Zhuoyue Tan,Liaoni Wu*

Main category: cs.CV

TL;DR: 论文提出了一种基于扩散模型的跨域目标检测方法（DDT），通过冻结权重的扩散模型生成伪标签，显著提升了跨域检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决目标检测器因训练数据与真实数据域差异导致的性能下降问题。

Method: 使用冻结权重的扩散模型作为教师模型生成伪标签，指导学生模型在目标域上的监督学习。

Result: 在6个数据集上平均mAP提升21.2%，超越当前SOTA方法5.7%。

Conclusion: DDT方法在跨域目标检测中表现出广泛适用性和高效性。

Abstract: Object detectors often suffer a decrease in performance due to the large
domain gap between the training data (source domain) and real-world data
(target domain). Diffusion-based generative models have shown remarkable
abilities in generating high-quality and diverse images, suggesting their
potential for extracting valuable feature from various domains. To effectively
leverage the cross-domain feature representation of diffusion models, in this
paper, we train a detector with frozen-weight diffusion model on the source
domain, then employ it as a teacher model to generate pseudo labels on the
unlabeled target domain, which are used to guide the supervised learning of the
student model on the target domain. We refer to this approach as Diffusion
Domain Teacher (DDT). By employing this straightforward yet potent framework,
we significantly improve cross-domain object detection performance without
compromising the inference speed. Our method achieves an average mAP
improvement of 21.2% compared to the baseline on 6 datasets from three common
cross-domain detection benchmarks (Cross-Camera, Syn2Real, Real2Artistic},
surpassing the current state-of-the-art (SOTA) methods by an average of 5.7%
mAP. Furthermore, extensive experiments demonstrate that our method
consistently brings improvements even in more powerful and complex models,
highlighting broadly applicable and effective domain adaptation capability of
our DDT. The code is available at
https://github.com/heboyong/Diffusion-Domain-Teacher.

</details>


### [330] [FullDiT2: Efficient In-Context Conditioning for Video Diffusion Transformers](https://arxiv.org/abs/2506.04213)
*Xuanhua He,Quande Liu,Zixuan Ye,Wecai Ye,Qiulin Wang,Xintao Wang,Qifeng Chen,Pengfei Wan,Di Zhang,Kun Gai*

Main category: cs.CV

TL;DR: 论文提出FullDiT2，通过动态令牌选择和选择性上下文缓存机制，解决了视频扩散变换器中效率瓶颈问题，显著降低了计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如FullDiT）在处理多样化控制任务时面临二次计算开销问题，限制了实际应用。

Method: 提出FullDiT2框架，通过动态令牌选择减少序列长度，并设计选择性上下文缓存机制优化条件令牌与视频潜变量的交互。

Result: 实验表明，FullDiT2在六种任务中显著降低计算量，速度提升2-3倍，同时保持或提升生成质量。

Conclusion: FullDiT2为视频生成和编辑任务提供了高效且通用的可控性解决方案。

Abstract: Fine-grained and efficient controllability on video diffusion transformers
has raised increasing desires for the applicability. Recently, In-context
Conditioning emerged as a powerful paradigm for unified conditional video
generation, which enables diverse controls by concatenating varying context
conditioning signals with noisy video latents into a long unified token
sequence and jointly processing them via full-attention, e.g., FullDiT. Despite
their effectiveness, these methods face quadratic computation overhead as task
complexity increases, hindering practical deployment. In this paper, we study
the efficiency bottleneck neglected in original in-context conditioning video
generation framework. We begin with systematic analysis to identify two key
sources of the computation inefficiencies: the inherent redundancy within
context condition tokens and the computational redundancy in context-latent
interactions throughout the diffusion process. Based on these insights, we
propose FullDiT2, an efficient in-context conditioning framework for general
controllability in both video generation and editing tasks, which innovates
from two key perspectives. Firstly, to address the token redundancy, FullDiT2
leverages a dynamic token selection mechanism to adaptively identify important
context tokens, reducing the sequence length for unified full-attention.
Additionally, a selective context caching mechanism is devised to minimize
redundant interactions between condition tokens and video latents. Extensive
experiments on six diverse conditional video editing and generation tasks
demonstrate that FullDiT2 achieves significant computation reduction and 2-3
times speedup in averaged time cost per diffusion step, with minimal
degradation or even higher performance in video generation quality. The project
page is at \href{https://fulldit2.github.io/}{https://fulldit2.github.io/}.

</details>


### [331] [Sounding that Object: Interactive Object-Aware Image to Audio Generation](https://arxiv.org/abs/2506.04214)
*Tingle Li,Baihe Huang,Xiaobin Zhuang,Dongya Jia,Jiawei Chen,Yuping Wang,Zhuo Chen,Gopala Anumanchipalli,Yuxuan Wang*

Main category: cs.CV

TL;DR: 提出了一种交互式对象感知音频生成模型，通过多模态注意力将图像区域与声音关联，支持用户交互式生成对象级声音。


<details>
  <summary>Details</summary>
Motivation: 解决复杂视听场景中多对象和多声源情况下声音生成的准确性挑战。

Method: 结合对象中心学习和条件潜在扩散模型，利用多模态注意力关联图像区域与声音，并通过图像分割实现交互式声音生成。

Result: 定量和定性评估显示模型优于基线，实现了对象与声音的更好对齐。

Conclusion: 模型通过理论验证和实验证明了其有效性，能够准确生成与选定对象对齐的声音。

Abstract: Generating accurate sounds for complex audio-visual scenes is challenging,
especially in the presence of multiple objects and sound sources. In this
paper, we propose an {\em interactive object-aware audio generation} model that
grounds sound generation in user-selected visual objects within images. Our
method integrates object-centric learning into a conditional latent diffusion
model, which learns to associate image regions with their corresponding sounds
through multi-modal attention. At test time, our model employs image
segmentation to allow users to interactively generate sounds at the {\em
object} level. We theoretically validate that our attention mechanism
functionally approximates test-time segmentation masks, ensuring the generated
audio aligns with selected objects. Quantitative and qualitative evaluations
show that our model outperforms baselines, achieving better alignment between
objects and their associated sounds. Project page:
https://tinglok.netlify.app/files/avobject/

</details>


### [332] [UNIC: Unified In-Context Video Editing](https://arxiv.org/abs/2506.04216)
*Zixuan Ye,Xuanhua He,Quande Liu,Qiulin Wang,Xintao Wang,Pengfei Wan,Di Zhang,Kun Gai,Qifeng Chen,Wenhan Luo*

Main category: cs.CV

TL;DR: UNIC框架统一了多种视频编辑任务，通过单一模型实现上下文编辑，无需任务特定适配器。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖任务特定架构或定制化，限制了编辑条件的多样性和任务统一性。

Method: 将输入表示为三种令牌，通过DiT的注意力操作联合建模，引入任务感知RoPE和条件偏置解决挑战。

Result: 在六种视频编辑任务上表现优异，并展示出任务组合能力。

Conclusion: UNIC框架简单有效，统一了多样视频编辑任务，支持灵活任务组合。

Abstract: Recent advances in text-to-video generation have sparked interest in
generative video editing tasks. Previous methods often rely on task-specific
architectures (e.g., additional adapter modules) or dedicated customizations
(e.g., DDIM inversion), which limit the integration of versatile editing
conditions and the unification of various editing tasks. In this paper, we
introduce UNified In-Context Video Editing (UNIC), a simple yet effective
framework that unifies diverse video editing tasks within a single model in an
in-context manner. To achieve this unification, we represent the inputs of
various video editing tasks as three types of tokens: the source video tokens,
the noisy video latent, and the multi-modal conditioning tokens that vary
according to the specific editing task. Based on this formulation, our key
insight is to integrate these three types into a single consecutive token
sequence and jointly model them using the native attention operations of DiT,
thereby eliminating the need for task-specific adapter designs. Nevertheless,
direct task unification under this framework is challenging, leading to severe
token collisions and task confusion due to the varying video lengths and
diverse condition modalities across tasks. To address these, we introduce
task-aware RoPE to facilitate consistent temporal positional encoding, and
condition bias that enables the model to clearly differentiate different
editing tasks. This allows our approach to adaptively perform different video
editing tasks by referring the source video and varying condition tokens "in
context", and support flexible task composition. To validate our method, we
construct a unified video editing benchmark containing six representative video
editing tasks. Results demonstrate that our unified approach achieves superior
performance on each task and exhibits emergent task composition abilities.

</details>


### [333] [Struct2D: A Perception-Guided Framework for Spatial Reasoning in Large Multimodal Models](https://arxiv.org/abs/2506.04220)
*Fangrui Zhu,Hanhui Wang,Yiming Xie,Jing Gu,Tianye Ding,Jianwei Yang,Huaizu Jiang*

Main category: cs.CV

TL;DR: 论文提出Struct2D框架，通过结构化2D输入（如BEV图像和物体标记）提升大模型的空间推理能力，无需依赖3D输入。实验证明其有效性，并构建了200K QA数据集Struct2D-Set，微调后模型在多项任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索大模型仅通过结构化2D输入（而非3D输入）是否具备3D空间推理能力，以简化智能交互的实现。

Method: 提出Struct2D框架，结合BEV图像、物体标记及元数据，通过零样本分析验证模型能力，并构建Struct2D-Set数据集进行微调。

Result: 实验显示，结构化2D输入能显著提升模型的空间推理能力，微调后的模型在3D问答、密集标注等任务中表现优异。

Conclusion: 结构化2D输入可有效连接感知与语言推理，无需3D输入，为未来研究提供了代码和数据集支持。

Abstract: Unlocking spatial reasoning in Large Multimodal Models (LMMs) is crucial for
enabling intelligent interaction with 3D environments. While prior efforts
often rely on explicit 3D inputs or specialized model architectures, we ask:
can LMMs reason about 3D space using only structured 2D representations derived
from perception? We introduce Struct2D, a perception-guided prompting framework
that combines bird's-eye-view (BEV) images with object marks and object-centric
metadata, optionally incorporating egocentric keyframes when needed. Using
Struct2D, we conduct an in-depth zero-shot analysis of closed-source LMMs
(e.g., GPT-o3) and find that they exhibit surprisingly strong spatial reasoning
abilities when provided with structured 2D inputs, effectively handling tasks
such as relative direction estimation and route planning. Building on these
insights, we construct Struct2D-Set, a large-scale instruction tuning dataset
with 200K fine-grained QA pairs across eight spatial reasoning categories,
generated automatically from 3D indoor scenes. We fine-tune an open-source LMM
(Qwen2.5VL) on Struct2D-Set, achieving competitive performance on multiple
benchmarks, including 3D question answering, dense captioning, and object
grounding. Our approach demonstrates that structured 2D inputs can effectively
bridge perception and language reasoning in LMMs-without requiring explicit 3D
representations as input. We will release both our code and dataset to support
future research.

</details>


### [334] [Seeing in the Dark: Benchmarking Egocentric 3D Vision with the Oxford Day-and-Night Dataset](https://arxiv.org/abs/2506.04224)
*Zirui Wang,Wenjing Bian,Xinghui Li,Yifu Tao,Jianeng Wang,Maurice Fallon,Victor Adrian Prisacariu*

Main category: cs.CV

TL;DR: Oxford Day-and-Night是一个大规模的自中心数据集，用于挑战性光照条件下的新视角合成和视觉重定位，填补了现有数据集的不足。


<details>
  <summary>Details</summary>
Motivation: 现有数据集缺乏真实3D几何、广泛光照变化和完整6DoF运动的组合，该数据集旨在解决这一问题。

Method: 利用Meta ARIA眼镜捕获自中心视频，并通过多会话SLAM估计相机位姿、重建3D点云，并对齐不同光照条件下的序列。

Result: 数据集覆盖30公里轨迹和40,000平方米区域，支持新视角合成和重定位两个核心基准测试。

Conclusion: 该数据集为自中心3D视觉研究提供了丰富资源，适用于多样真实环境的模型评估。

Abstract: We introduce Oxford Day-and-Night, a large-scale, egocentric dataset for
novel view synthesis (NVS) and visual relocalisation under challenging lighting
conditions. Existing datasets often lack crucial combinations of features such
as ground-truth 3D geometry, wide-ranging lighting variation, and full 6DoF
motion. Oxford Day-and-Night addresses these gaps by leveraging Meta ARIA
glasses to capture egocentric video and applying multi-session SLAM to estimate
camera poses, reconstruct 3D point clouds, and align sequences captured under
varying lighting conditions, including both day and night. The dataset spans
over 30 $\mathrm{km}$ of recorded trajectories and covers an area of 40,000
$\mathrm{m}^2$, offering a rich foundation for egocentric 3D vision research.
It supports two core benchmarks, NVS and relocalisation, providing a unique
platform for evaluating models in realistic and diverse environments.

</details>


### [335] [Voyager: Long-Range and World-Consistent Video Diffusion for Explorable 3D Scene Generation](https://arxiv.org/abs/2506.04225)
*Tianyu Huang,Wangguandong Zheng,Tengfei Wang,Yuhao Liu,Zhenwei Wang,Junta Wu,Jie Jiang,Hui Li,Rynson W. H. Lau,Wangmeng Zuo,Chunchao Guo*

Main category: cs.CV

TL;DR: Voyager是一种新颖的视频扩散框架，通过单张图像和用户定义的相机路径生成世界一致的3D点云序列，无需传统3D重建流程。


<details>
  <summary>Details</summary>
Motivation: 现实应用（如视频游戏和虚拟现实）需要用户沿自定义相机轨迹探索3D场景，但现有方法在生成长范围、3D一致的场景时仍面临挑战。

Method: Voyager结合三个关键组件：1）世界一致视频扩散，2）长范围世界探索，3）可扩展数据引擎，实现端到端场景生成与重建。

Result: 该方法在视觉质量和几何精度上优于现有方法，具有广泛的应用潜力。

Conclusion: Voyager通过创新的框架设计，解决了3D场景生成的一致性和长范围探索问题，为实际应用提供了高效解决方案。

Abstract: Real-world applications like video gaming and virtual reality often demand
the ability to model 3D scenes that users can explore along custom camera
trajectories. While significant progress has been made in generating 3D objects
from text or images, creating long-range, 3D-consistent, explorable 3D scenes
remains a complex and challenging problem. In this work, we present Voyager, a
novel video diffusion framework that generates world-consistent 3D point-cloud
sequences from a single image with user-defined camera path. Unlike existing
approaches, Voyager achieves end-to-end scene generation and reconstruction
with inherent consistency across frames, eliminating the need for 3D
reconstruction pipelines (e.g., structure-from-motion or multi-view stereo).
Our method integrates three key components: 1) World-Consistent Video
Diffusion: A unified architecture that jointly generates aligned RGB and depth
video sequences, conditioned on existing world observation to ensure global
coherence 2) Long-Range World Exploration: An efficient world cache with point
culling and an auto-regressive inference with smooth video sampling for
iterative scene extension with context-aware consistency, and 3) Scalable Data
Engine: A video reconstruction pipeline that automates camera pose estimation
and metric depth prediction for arbitrary videos, enabling large-scale, diverse
training data curation without manual 3D annotations. Collectively, these
designs result in a clear improvement over existing methods in visual quality
and geometric accuracy, with versatile applications.

</details>


### [336] [LayerFlow: A Unified Model for Layer-aware Video Generation](https://arxiv.org/abs/2506.04228)
*Sihui Ji,Hao Luo,Xi Chen,Yuanpeng Tu,Yiyang Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: LayerFlow是一种统一的分层感知视频生成方法，支持透明前景、干净背景和混合场景的生成，并能分解混合视频或生成背景与前景的互换。


<details>
  <summary>Details</summary>
Motivation: 解决分层视频生成的需求，尤其是在缺乏高质量分层训练视频的情况下。

Method: 基于文本到视频扩散变换器，通过分层嵌入区分不同层的子片段，采用多阶段训练策略，结合低质量视频数据和高质量静态图像。

Result: 实现了平滑的分层视频生成，支持多种变体操作。

Conclusion: LayerFlow为分层视频生成提供了一种高效统一的解决方案，尤其在数据有限的情况下表现优异。

Abstract: We present LayerFlow, a unified solution for layer-aware video generation.
Given per-layer prompts, LayerFlow generates videos for the transparent
foreground, clean background, and blended scene. It also supports versatile
variants like decomposing a blended video or generating the background for the
given foreground and vice versa. Starting from a text-to-video diffusion
transformer, we organize the videos for different layers as sub-clips, and
leverage layer embeddings to distinguish each clip and the corresponding
layer-wise prompts. In this way, we seamlessly support the aforementioned
variants in one unified framework. For the lack of high-quality layer-wise
training videos, we design a multi-stage training strategy to accommodate
static images with high-quality layer annotations. Specifically, we first train
the model with low-quality video data. Then, we tune a motion LoRA to make the
model compatible with static frames. Afterward, we train the content LoRA on
the mixture of image data with high-quality layered images along with
copy-pasted video data. During inference, we remove the motion LoRA thus
generating smooth videos with desired layers.

</details>


### [337] [Dual Branch VideoMamba with Gated Class Token Fusion for Violence Detection](https://arxiv.org/abs/2506.03162)
*Damith Chamalke Senadeera,Xiaoyun Yang,Dimitrios Kollias,Gregory Slabaugh*

Main category: cs.CV

TL;DR: 提出了一种结合双分支设计和状态空间模型（SSM）的高效架构Dual Branch VideoMamba with GCTF，用于视频暴力检测，并在新基准上实现了最优性能。


<details>
  <summary>Details</summary>
Motivation: 随着监控摄像头的快速普及，自动化暴力检测需求增加，但现有方法（如CNN和Transformer）在长期依赖性和计算效率上表现不足。

Method: 采用双分支设计，一支捕捉空间特征，另一支关注时间动态，通过门控机制持续融合；使用SSM作为主干网络。

Result: 在新合并的基准数据集上实现了最优性能，平衡了准确性和计算效率。

Conclusion: SSM在可扩展、实时监控暴力检测中具有潜力。

Abstract: The rapid proliferation of surveillance cameras has increased the demand for
automated violence detection. While CNNs and Transformers have shown success in
extracting spatio-temporal features, they struggle with long-term dependencies
and computational efficiency. We propose Dual Branch VideoMamba with Gated
Class Token Fusion (GCTF), an efficient architecture combining a dual-branch
design and a state-space model (SSM) backbone where one branch captures spatial
features, while the other focuses on temporal dynamics, with continuous fusion
via a gating mechanism. We also present a new benchmark by merging RWF-2000,
RLVS, and VioPeru datasets in video violence detection, ensuring strict
separation between training and testing sets. Our model achieves
state-of-the-art performance on this benchmark offering an optimal balance
between accuracy and computational efficiency, demonstrating the promise of
SSMs for scalable, real-time surveillance violence detection.

</details>


### [338] [Farm-LightSeek: An Edge-centric Multimodal Agricultural IoT Data Analytics Framework with Lightweight LLMs](https://arxiv.org/abs/2506.03168)
*Dawen Jiang,Zhishu Shen,Qiushi Zheng,Tiehua Zhang,Wei Xiang,Jiong Jin*

Main category: cs.CV

TL;DR: Farm-LightSeek是一个基于边缘计算和多模态数据融合的农业物联网框架，利用大语言模型（LLMs）解决智能农业中的实时决策和动态适应问题。


<details>
  <summary>Details</summary>
Motivation: 全球人口增长和气候变化对农业提出挑战，传统农业物联网系统需要数字化转型以高效处理大数据。智能农业依赖AI技术但仍面临专家知识依赖、多模态数据融合困难、动态环境适应性差和边缘实时决策瓶颈等问题。

Method: 提出Farm-LightSeek框架，结合LLMs和边缘计算，通过传感器收集农田多源数据（图像、天气、地理信息），在边缘节点进行跨模态推理和病害检测，实现低延迟管理决策和云端协作模型更新。

Result: 在两个真实数据集上的实验表明，Farm-LightSeek在边缘计算资源限制下仍能可靠完成关键任务。

Conclusion: Farm-LightSeek推动了智能实时农业解决方案的发展，展示了农业物联网与LLMs深度融合的潜力。

Abstract: Amid the challenges posed by global population growth and climate change,
traditional agricultural Internet of Things (IoT) systems is currently
undergoing a significant digital transformation to facilitate efficient big
data processing. While smart agriculture utilizes artificial intelligence (AI)
technologies to enable precise control, it still encounters significant
challenges, including excessive reliance on agricultural expert knowledge,
difficulties in fusing multimodal data, poor adaptability to dynamic
environments, and bottlenecks in real-time decision-making at the edge. Large
language models (LLMs), with their exceptional capabilities in knowledge
acquisition and semantic understanding, provide a promising solution to address
these challenges. To this end, we propose Farm-LightSeek, an edge-centric
multimodal agricultural IoT data analytics framework that integrates LLMs with
edge computing. This framework collects real-time farmland multi-source data
(images, weather, geographic information) via sensors, performs cross-modal
reasoning and disease detection at edge nodes, conducts low-latency management
decisions, and enables cloud collaboration for model updates. The main
innovations of Farm-LightSeek include: (1) an agricultural
"perception-decision-action" closed-loop architecture; (2) cross-modal adaptive
monitoring; and (3)a lightweight LLM deployment strategy balancing performance
and efficiency. Experiments conducted on two real-world datasets demonstrate
that Farm-LightSeek consistently achieves reliable performance in
mission-critical tasks, even under the limitations of edge computing resources.
This work advances intelligent real-time agricultural solutions and highlights
the potential for deeper integration of agricultural IoT with LLMs.

</details>


### [339] [Improvement of human health lifespan with hybrid group pose estimation methods](https://arxiv.org/abs/2506.03169)
*Arindam Chaudhuri*

Main category: cs.CV

TL;DR: 本文提出了一种混合集成群体姿态估计方法，旨在通过结合改进的群体姿态估计和实时姿态估计技术，提升多人姿态检测的准确性和实时性。


<details>
  <summary>Details</summary>
Motivation: 人类姿态估计在健康监测等领域有广泛应用，但现有方法在实时性和遮挡处理上存在不足。本文旨在通过混合集成方法解决这些问题。

Method: 提出了一种混合集成群体姿态估计方法，结合改进的群体姿态估计和实时姿态估计技术，通过特征融合和训练优化提升性能。

Result: 实验表明，该方法在实时姿态估计中表现最佳，对遮挡更鲁棒，并提高了密集回归的准确性。

Conclusion: 该方法在实时应用中具有潜力，能够改善人类健康监测的效果。

Abstract: Human beings rely heavily on estimation of poses in order to access their
body movements. Human pose estimation methods take advantage of computer vision
advances in order to track human body movements in real life applications. This
comes from videos which are recorded through available devices. These
para-digms provide potential to make human movement measurement more accessible
to users. The consumers of pose estimation movements believe that human poses
content tend to supplement available videos. This has increased pose estimation
software usage to estimate human poses. In order to address this problem, we
develop hybrid-ensemble-based group pose estimation method to improve human
health. This proposed hybrid-ensemble-based group pose estimation method aims
to detect multi-person poses using modified group pose estimation and modified
real time pose estimation. This ensemble allows fusion of performance of stated
methods in real time. The input poses from images are fed into individual
meth-ods. The pose transformation method helps to identify relevant features
for en-semble to perform training effectively. After this, customized
pre-trained hybrid ensemble is trained on public benchmarked datasets which is
being evaluated through test datasets. The effectiveness and viability of
proposed method is estab-lished based on comparative analysis of group pose
estimation methods and ex-periments conducted on benchmarked datasets. It
provides best optimized results in real-time pose estimation. It makes pose
estimation method more robust to oc-clusion and improves dense regression
accuracy. These results have affirmed po-tential application of this method in
several real-time situations with improvement in human health life span

</details>


### [340] [PALADIN : Robust Neural Fingerprinting for Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.03170)
*Murthy L,Subarna Tripathi*

Main category: cs.CV

TL;DR: 提出了一种基于循环纠错码的神经指纹技术，用于提高文本到图像扩散模型的归属准确性。


<details>
  <summary>Details</summary>
Motivation: 开源文本到图像生成模型可能被滥用，现有神经指纹技术无法实现100%的归属准确性，导致实际部署受限。

Method: 利用编码理论中的循环纠错码概念，改进神经指纹技术。

Result: 该方法显著提高了归属准确性，但仍未达到完美。

Conclusion: 通过循环纠错码改进的神经指纹技术为文本到图像模型的归属问题提供了更优解决方案。

Abstract: The risk of misusing text-to-image generative models for malicious uses,
especially due to the open-source development of such models, has become a
serious concern. As a risk mitigation strategy, attributing generative models
with neural fingerprinting is emerging as a popular technique. There has been a
plethora of recent work that aim for addressing neural fingerprinting. A
trade-off between the attribution accuracy and generation quality of such
models has been studied extensively. None of the existing methods yet achieved
$100\%$ attribution accuracy. However, any model with less than \emph{perfect}
accuracy is practically non-deployable. In this work, we propose an accurate
method to incorporate neural fingerprinting for text-to-image diffusion models
leveraging the concepts of cyclic error correcting codes from the literature of
coding theory.

</details>


### [341] [EdgeVidSum: Real-Time Personalized Video Summarization at the Edge](https://arxiv.org/abs/2506.03171)
*Ghulam Mujtaba,Eun-Seok Ryu*

Main category: cs.CV

TL;DR: EdgeVidSum是一种轻量级方法，直接在边缘设备上生成长视频的个性化快进摘要，通过本地数据处理保护用户隐私，并利用创新的缩略图技术和高效神经架构实现实时视频摘要。


<details>
  <summary>Details</summary>
Motivation: 解决传统视频摘要方法计算复杂度高、隐私保护不足以及无法在资源受限设备上实时运行的问题。

Method: 使用缩略图容器减少计算复杂度，采用轻量级2D CNN模型从缩略图中识别用户偏好内容，并生成时间戳以创建快进摘要。

Result: 在资源受限设备（如Jetson Nano）上实现实时个性化视频摘要，适用于电影、体育赛事和电视节目等长视频。

Conclusion: EdgeVidSum在计算效率、个性化和隐私保护方面解决了现代视频消费环境中的关键挑战。

Abstract: EdgeVidSum is a lightweight method that generates personalized, fast-forward
summaries of long-form videos directly on edge devices. The proposed approach
enables real-time video summarization while safeguarding user privacy through
local data processing using innovative thumbnail-based techniques and efficient
neural architectures. Unlike conventional methods that process entire videos
frame by frame, the proposed method uses thumbnail containers to significantly
reduce computational complexity without sacrificing semantic relevance. The
framework employs a hierarchical analysis approach, where a lightweight 2D CNN
model identifies user-preferred content from thumbnails and generates
timestamps to create fast-forward summaries. Our interactive demo highlights
the system's ability to create tailored video summaries for long-form videos,
such as movies, sports events, and TV shows, based on individual user
preferences. The entire computation occurs seamlessly on resource-constrained
devices like Jetson Nano, demonstrating how EdgeVidSum addresses the critical
challenges of computational efficiency, personalization, and privacy in modern
video consumption environments.

</details>


### [342] [FOLIAGE: Towards Physical Intelligence World Models Via Unbounded Surface Evolution](https://arxiv.org/abs/2506.03173)
*Xiaoyi Liu,Hao Tang*

Main category: cs.CV

TL;DR: FOLIAGE是一种物理智能驱动的多模态世界模型，用于无界表面增长，通过统一编码器和物理感知预测器生成模态无关的生长嵌入（MAGE），并在SURF-GARDEN平台上验证其性能。


<details>
  <summary>Details</summary>
Motivation: 物理智能对下一代世界模型至关重要，FOLIAGE旨在通过多模态数据预测和塑造表面增长，解决动态环境中的物理建模问题。

Method: FOLIAGE采用统一上下文编码器处理多模态输入，结合物理感知预测器和AGN网络动态建模表面增长，并通过SURF-GARDEN平台生成多样化数据。

Result: FOLIAGE在SURF-BENCH评估中表现优于专用基线，并在动态环境中保持鲁棒性，验证了其物理智能建模能力。

Conclusion: FOLIAGE为物理智能提供了一种基于世界模型的多模态路径，展示了在复杂动态环境中的潜力。

Abstract: Physical intelligence -- anticipating and shaping the world from partial,
multisensory observations -- is critical for next-generation world models. We
propose FOLIAGE, a physics-informed multimodal world model for unbounded
accretive surface growth. In its Action-Perception loop, a unified context
encoder maps images, mesh connectivity, and point clouds to a shared latent
state. A physics-aware predictor, conditioned on physical control actions,
advances this latent state in time to align with the target latent of the
surface, yielding a Modality-Agnostic Growth Embedding (MAGE) that interfaces
with critic heads for downstream objectives. FOLIAGE's Accretive Graph Network
(AGN) captures dynamic connectivity through Age Positional Encoding and
Energy-Gated Message-Passing. Geometry-Correspondence Fusion and Cross-Patch
Masking enhance MAGE's expressiveness, while Hierarchical Pooling balances
global context with local dynamics. We create SURF-GARDEN, a world model
learning platform comprising a Counterfactual Physics Simulator, a Multimodal
Correspondence Extractor, and Evolution Tracing, which generates 7,200 diverse
surface-growth sequences. SURF-BENCH, our physical-intelligence evaluation
suite, evaluates six core tasks -- topology recognition, inverse material
estimation, growth-stage classification, latent roll-out, cross-modal
retrieval, and dense correspondence -- and four stress tests -- sensor dropout,
zero-shot modality transfer, long-horizon prediction, and physics ablation --
to probe resilience. FOLIAGE outperforms specialized baselines while remaining
robust across dynamic environments, establishing a new world-model based,
multimodal pathway to physical intelligence.

</details>


### [343] [Multimodal Foundation Model for Cross-Modal Retrieval and Activity Recognition Tasks](https://arxiv.org/abs/2506.03174)
*Koki Matsuishi,Kosuke Ukita,Tsuyoshi Okita*

Main category: cs.CV

TL;DR: 提出AURA-MFM多模态基础模型，整合第三人称视频、动作捕捉、IMU和文本数据，显著提升行为分析的详细性和多维性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态基础模型（结合第一人称视频和文本）无法全面分析全身活动，需更全面的数据支持。

Method: 整合第三人称视频、动作捕捉、IMU和文本四种模态，采用基于Transformer的IMU编码器提升性能。

Result: 在检索和行为识别任务中表现优异，零样本分类的F1分数（0.6226）和准确率（0.7320）远超现有方法。

Conclusion: AURA-MFM通过多模态整合显著提升行为分析能力，尤其在零样本任务中表现突出。

Abstract: In recent years, the widespread adoption of wearable devices has highlighted
the growing importance of behavior analysis using IMU. While applications span
diverse fields such as healthcare and robotics, recent studies have
increasingly focused on multimodal analysis, in addition to unimodal analysis.
Several studies have proposed multimodal foundation models that incorporate
first-person video and text data; however, these models still fall short in
providing a detailed analysis of full-body human activity. To address this
limitation, we propose Activity Understanding and Representations Alignment -
Multimodal Foundation Model (AURA-MFM), a foundational model integrating four
modalities: third-person video, motion capture, IMU, and text. By incorporating
third-person video and motion capture data, the model enables a detailed and
multidimensional understanding of human activity, which first-person
perspectives alone fail to capture. Additionally, a Transformer-based IMU
encoder is employed to enhance the model's overall performance. Experimental
evaluations on retrieval and activity recognition tasks demonstrate that our
model surpasses existing methods. Notably, in the zero-shot classification for
action recognition, our method achieved significantly higher performance, with
an F1-score of 0.6226 and an accuracy of 0.7320, whereas the existing method
recorded an F1-score of 0.0747 and an accuracy of 0.1961.

</details>


### [344] [Vid-SME: Membership Inference Attacks against Large Video Understanding Models](https://arxiv.org/abs/2506.03179)
*Qi Li,Runpeng Yu,Xinchao Wang*

Main category: cs.CV

TL;DR: Vid-SME是一种针对视频理解大语言模型（VULLMs）的成员推理方法，通过计算Sharma-Mittal熵（SME）差异来识别训练数据中的视频。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在视频理解中的应用引发数据隐私问题，现有方法无法有效扩展到视频领域。

Method: 提出Vid-SME，利用模型输出置信度和自适应参数化计算视频输入的SME，通过自然与时间反转视频帧的SME差异生成成员分数。

Result: 实验表明Vid-SME在多种VULLMs中表现优异。

Conclusion: Vid-SME解决了视频数据成员推理的挑战，为隐私保护提供了有效工具。

Abstract: Multimodal large language models (MLLMs) demonstrate remarkable capabilities
in handling complex multimodal tasks and are increasingly adopted in video
understanding applications. However, their rapid advancement raises serious
data privacy concerns, particularly given the potential inclusion of sensitive
video content, such as personal recordings and surveillance footage, in their
training datasets. Determining improperly used videos during training remains a
critical and unresolved challenge. Despite considerable progress on membership
inference attacks (MIAs) for text and image data in MLLMs, existing methods
fail to generalize effectively to the video domain. These methods suffer from
poor scalability as more frames are sampled and generally achieve negligible
true positive rates at low false positive rates (TPR@Low FPR), mainly due to
their failure to capture the inherent temporal variations of video frames and
to account for model behavior differences as the number of frames varies. To
address these challenges, we introduce Vid-SME, the first membership inference
method tailored for video data used in video understanding LLMs (VULLMs).
Vid-SME leverages the confidence of model output and integrates adaptive
parameterization to compute Sharma-Mittal entropy (SME) for video inputs. By
leveraging the SME difference between natural and temporally-reversed video
frames, Vid-SME derives robust membership scores to determine whether a given
video is part of the model's training set. Experiments on various self-trained
and open-sourced VULLMs demonstrate the strong effectiveness of Vid-SME.

</details>


### [345] [TerraIncognita: A Dynamic Benchmark for Species Discovery Using Frontier Models](https://arxiv.org/abs/2506.03182)
*Shivani Chiranjeevi,Hossein Zaremehrjerdi,Zi K. Deng,Talukder Z. Jubery,Ari Grele,Arti Singh,Asheesh K Singh,Soumik Sarkar,Nirav Merchant,Harold F. Greeney,Baskar Ganapathysubramanian,Chinmay Hegde*

Main category: cs.CV

TL;DR: TerraIncognita是一个动态基准，用于评估多模态模型在从图像数据中识别未知昆虫物种的能力，旨在解决当前昆虫物种发现方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 全球生物多样性快速丧失，尤其是昆虫，当前的手动物种发现方法效率低下且受限于分类学专业知识，阻碍了及时的保护行动。

Method: 通过结合已知物种和稀有物种的专家标注图像，创建了一个基准数据集，评估模型在分类、检测新物种和生成解释方面的能力。

Result: 模型在已知物种的目级别分类中表现优异（F1>90%），但在物种级别表现极差（F1<2%），揭示了从粗到细分类的难度梯度。

Conclusion: TerraIncognita将定期更新，为前沿AI方法提供一个动态的长期评估平台，促进昆虫物种发现的进展。

Abstract: The rapid global loss of biodiversity, particularly among insects, represents
an urgent ecological crisis. Current methods for insect species discovery are
manual, slow, and severely constrained by taxonomic expertise, hindering timely
conservation actions. We introduce TerraIncognita, a dynamic benchmark designed
to evaluate state-of-the-art multimodal models for the challenging problem of
identifying unknown, potentially undescribed insect species from image data.
Our benchmark dataset combines a mix of expertly annotated images of insect
species likely known to frontier AI models, and images of rare and poorly known
species, for which few/no publicly available images exist. These images were
collected from underexplored biodiversity hotspots, realistically mimicking
open-world discovery scenarios faced by ecologists. The benchmark assesses
models' proficiency in hierarchical taxonomic classification, their capability
to detect and abstain from out-of-distribution (OOD) samples representing novel
species, and their ability to generate explanations aligned with expert
taxonomic knowledge. Notably, top-performing models achieve over 90\% F1 at the
Order level on known species, but drop below 2\% at the Species level,
highlighting the sharp difficulty gradient from coarse to fine taxonomic
prediction (Order $\rightarrow$ Family $\rightarrow$ Genus $\rightarrow$
Species). TerraIncognita will be updated regularly, and by committing to
quarterly dataset expansions (of both known and novel species), will provide an
evolving platform for longitudinal benchmarking of frontier AI methods. All
TerraIncognita data, results, and future updates are available
\href{https://baskargroup.github.io/TerraIncognita/}{here}.

</details>


### [346] [Impact of Tuning Parameters in Deep Convolutional Neural Network Using a Crack Image Dataset](https://arxiv.org/abs/2506.03184)
*Mahe Zabin,Ho-Jin Choi,Md. Monirul Islam,Jia Uddin*

Main category: cs.CV

TL;DR: 研究了深度卷积神经网络（DCNN）中不同调参对性能的影响，发现使用maxpooling、adam优化器和tanh激活函数时性能最佳。


<details>
  <summary>Details</summary>
Motivation: 探讨DCNN中调参对分类性能的影响，以优化模型表现。

Method: 使用包含2个卷积层、2个池化层、1个dropout层和1个密集层的DCNN，通过实验评估池化、激活函数和优化器的调参效果。

Result: 实验结果表明，maxpooling、adam优化器和tanh激活函数的组合性能最佳。

Conclusion: 调参对DCNN性能有显著影响，maxpooling、adam和tanh的组合是优化选择。

Abstract: The performance of a classifier depends on the tuning of its parame ters. In
this paper, we have experimented the impact of various tuning parameters on the
performance of a deep convolutional neural network (DCNN). In the ex perimental
evaluation, we have considered a DCNN classifier that consists of 2
convolutional layers (CL), 2 pooling layers (PL), 1 dropout, and a dense layer.
To observe the impact of pooling, activation function, and optimizer tuning pa
rameters, we utilized a crack image dataset having two classes: negative and
pos itive. The experimental results demonstrate that with the maxpooling, the
DCNN demonstrates its better performance for adam optimizer and tanh activation
func tion.

</details>


### [347] [Continual Learning in Vision-Language Models via Aligned Model Merging](https://arxiv.org/abs/2506.03189)
*Ghada Sokar,Gintare Karolina Dziugaite,Anurag Arnab,Ahmet Iscen,Pablo Samuel Castro,Cordelia Schmid*

Main category: cs.CV

TL;DR: 该论文提出了一种基于模型合并的持续学习方法，通过合并新任务参数与旧任务参数，平衡稳定性和可塑性，减少遗忘并提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统的持续学习方法通过顺序微调倾向于可塑性而非稳定性，导致对近期任务的偏见和灾难性遗忘。

Method: 提出模型合并方法，通过合并新任务参数与旧任务参数，并引入对齐机制避免干扰。

Result: 在大型视觉语言模型上验证，有效减少遗忘、增强任务顺序和相似性的鲁棒性，并提升泛化能力。

Conclusion: 模型合并方法在持续学习中实现了稳定性和可塑性的更好平衡，具有实际应用潜力。

Abstract: Continual learning is conventionally tackled through sequential fine-tuning,
a process that, while enabling adaptation, inherently favors plasticity over
the stability needed to retain prior knowledge. While existing approaches
attempt to mitigate catastrophic forgetting, a bias towards recent tasks
persists as they build upon this sequential nature. In this work we present a
new perspective based on model merging to maintain stability while still
retaining plasticity. Rather than just sequentially updating the model weights,
we propose merging newly trained task parameters with previously learned ones,
promoting a better balance. To maximize the effectiveness of the merging
process, we propose a simple mechanism that promotes learning aligned weights
with previous ones, thereby avoiding interference when merging. We evaluate
this approach on large Vision-Language Models (VLMs), and demonstrate its
effectiveness in reducing forgetting, increasing robustness to various task
orders and similarities, and improving generalization.

</details>


### [348] [MINT: Memory-Infused Prompt Tuning at Test-time for CLIP](https://arxiv.org/abs/2506.03190)
*Jiaming Yi,Ruirui Pan,Jishen Yang,Xiulong Yang*

Main category: cs.CV

TL;DR: 提出了一种名为MINT的新框架，通过记忆提示库动态适应测试时的数据分布变化，提升视觉语言预训练模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有测试时适应方法未能充分利用模型内部知识，特别是在动态适应复杂层次视觉语义信息方面存在不足。

Method: MINT引入记忆提示库（MPB），存储可学习的键值提示对，通过测试图像的层次视觉特征检索相关提示对，动态组装关联提示，注入图像编码器。

Result: MINT无需源数据或重新训练，即可实现快速、精确的测试时模型适应。

Conclusion: MINT通过记忆提示库有效提升了视觉语言预训练模型在测试时的泛化能力。

Abstract: Improving the generalization ability of Vision-Language Pre-trained Models
(VLMs) under test-time data distribution shifts remains a critical challenge.
The existing Test-Time Adaptation (TTA) methods fall short in fully leveraging
the model's internal knowledge, particularly in dynamically adapting to complex
and hierarchical visual semantic information. In this paper, we propose
Memory-Infused Prompt Tuning (MINT), a novel framework to address this issue.
Inspired by human associative memory theory, MINT introduces a Memory Prompt
Bank (MPB), which stores learnable key-value prompt pairs that work as a memory
of previously seen samples. During the test time, relevant prompt pairs in the
MPB are retrieved by the hierarchical visual features of test images to
dynamically assemble Associative Prompts. The associative prompts are then
injected into the image encoder for fine-grained, customized visual contextual
guidance. MINT also utilizes learnable text prompts. MINT thus enables rapid,
precise VLM adaptation at test time by leveraging this MPB-acquired memory,
without source data or retraining. The code is available at
https://github.com/Jamieyi2004/MINT.

</details>


### [349] [Multimodal Generative AI with Autoregressive LLMs for Human Motion Understanding and Generation: A Way Forward](https://arxiv.org/abs/2506.03191)
*Muhammad Islam,Tao Huang,Euijoon Ahn,Usman Naseem*

Main category: cs.CV

TL;DR: 本文综述了多模态生成人工智能（GenAI）和自回归大语言模型（LLMs）在人类运动理解与生成中的应用，探讨了新兴方法、架构及其在提升运动合成逼真度和多样性方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索如何通过文本描述指导生成复杂、类人的运动序列，以推动文本到运动生成技术的发展。

Method: 分析了自回归模型、扩散模型、生成对抗网络（GANs）、变分自编码器（VAEs）和基于Transformer的模型，评估其在运动质量、计算效率和适应性方面的优劣。

Result: 文本条件运动生成的最新进展表明，文本输入可以更精确地控制和优化运动输出，LLMs的整合进一步提升了语义对齐和上下文相关性。

Conclusion: 文本到运动的GenAI和LLM架构在医疗、人形机器人、游戏、动画和辅助技术等领域具有变革潜力，但仍需解决生成高效逼真运动的挑战。

Abstract: This paper presents an in-depth survey on the use of multimodal Generative
Artificial Intelligence (GenAI) and autoregressive Large Language Models (LLMs)
for human motion understanding and generation, offering insights into emerging
methods, architectures, and their potential to advance realistic and versatile
motion synthesis. Focusing exclusively on text and motion modalities, this
research investigates how textual descriptions can guide the generation of
complex, human-like motion sequences. The paper explores various generative
approaches, including autoregressive models, diffusion models, Generative
Adversarial Networks (GANs), Variational Autoencoders (VAEs), and
transformer-based models, by analyzing their strengths and limitations in terms
of motion quality, computational efficiency, and adaptability. It highlights
recent advances in text-conditioned motion generation, where textual inputs are
used to control and refine motion outputs with greater precision. The
integration of LLMs further enhances these models by enabling semantic
alignment between instructions and motion, improving coherence and contextual
relevance. This systematic survey underscores the transformative potential of
text-to-motion GenAI and LLM architectures in applications such as healthcare,
humanoids, gaming, animation, and assistive technologies, while addressing
ongoing challenges in generating efficient and realistic human motion.

</details>


### [350] [Human Fall Detection using Transfer Learning-based 3D CNN](https://arxiv.org/abs/2506.03193)
*Ekram Alam,Abu Sufian,Paramartha Dutta,Marco Leo*

Main category: cs.CV

TL;DR: 本文提出了一种基于预训练3D CNN的视觉跌倒检测系统，利用时空特征和SVM分类器实现高效检测。


<details>
  <summary>Details</summary>
Motivation: 老年人意外跌倒是一个重要的健康问题，随着老年人口增加，需要自动化的跌倒检测系统。

Method: 使用预训练的3D CNN提取时空特征，仅训练SVM分类器以减少时间成本，采用分层五折交叉验证。

Result: 在GMDCSA和CAUCAFall数据集上进行了实验，模型表现良好。

Conclusion: 该方法通过预训练模型和高效分类器，为跌倒检测提供了一种有效的解决方案。

Abstract: Unintentional or accidental falls are one of the significant health issues in
senior persons. The population of senior persons is increasing steadily. So,
there is a need for an automated fall detection monitoring system. This paper
introduces a vision-based fall detection system using a pre-trained 3D CNN.
Unlike 2D CNN, 3D CNN extracts not only spatial but also temporal features. The
proposed model leverages the original learned weights of a 3D CNN model
pre-trained on the Sports1M dataset to extract the spatio-temporal features.
Only the SVM classifier was trained, which saves the time required to train the
3D CNN. Stratified shuffle five split cross-validation has been used to split
the dataset into training and testing data. Extracted features from the
proposed 3D CNN model were fed to an SVM classifier to classify the activity as
fall or ADL. Two datasets, GMDCSA and CAUCAFall, were utilized to conduct the
experiment. The source code for this work can be accessed via the following
link: https://github.com/ekramalam/HFD_3DCNN.

</details>


### [351] [HueManity: Probing Fine-Grained Visual Perception in MLLMs](https://arxiv.org/abs/2506.03194)
*Rynaa Grover,Jayant Sravan Tamarapalli,Sahiti Yerramilli,Nilay Pande*

Main category: cs.CV

TL;DR: HueManity是一个评估多模态大语言模型（MLLMs）视觉感知能力的基准测试，结果显示MLLMs在精细视觉任务上表现远低于人类和传统计算机视觉模型。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs在高层次视觉推理上表现优异，但在精细视觉感知任务上存在明显不足，需要评估和改进。

Method: 提出HueManity基准测试，包含83,850张Ishihara风格点阵图像，测试MLLMs的精确模式识别能力。

Result: MLLMs在数字‘简单’任务上最高准确率为33.6%，字母数字‘困难’任务上仅为3%，远低于人类（100%和95.6%）和ResNet50（96.5%和94.5%）。

Conclusion: MLLMs在视觉感知能力上存在显著差距，需进一步研究改进架构和训练范式。

Abstract: Multimodal Large Language Models (MLLMs) excel at high-level visual
reasoning, but their performance on nuanced perceptual tasks remains
surprisingly limited. We present HueManity, a benchmark designed to assess
visual perception in MLLMs. The dataset comprises 83,850 images featuring
two-character alphanumeric strings embedded in Ishihara test style dot
patterns, challenging models on precise pattern recognition. Our evaluation of
nine state-of-the-art MLLMs on HueManity demonstrates a significant performance
deficit compared to human and traditional computer vision baselines. The
best-performing MLLM achieved a 33.6% accuracy on the numeric `easy' task and a
striking 3% on the alphanumeric `hard' task. In contrast, human participants
achieved near-perfect scores (100% and 95.6%), and a fine-tuned ResNet50 model
reached accuracies of 96.5% and 94.5%. These results highlight a critical gap
in the visual capabilities of current MLLMs. Our analysis further explores
potential architectural and training-paradigm factors contributing to this
perceptual gap in MLLMs. We open-source HueManity dataset and code to foster
further research in improving perceptual robustness of MLLMs.

</details>


### [352] [Unlabeled Data Improves Fine-Grained Image Zero-shot Classification with Multimodal LLMs](https://arxiv.org/abs/2506.03195)
*Yunqi Hong,Sohyun An,Andrew Bai,Neil Y. C. Lin,Cho-Jui Hsieh*

Main category: cs.CV

TL;DR: AutoSEP是一个自监督提示学习框架，旨在提升多模态大语言模型（MLLMs）在细粒度图像分类任务中的性能，无需标注数据。


<details>
  <summary>Details</summary>
Motivation: 细粒度图像分类需要关注细微视觉差异，而MLLMs可能忽视这些细节。AutoSEP通过自监督学习生成描述提示，引导MLLMs识别关键特征。

Method: AutoSEP利用未标注数据迭代优化描述提示，基于实例级分类评分函数，无需训练或微调MLLMs。

Result: 在多个细粒度分类数据集上，AutoSEP平均比零样本分类提升13%，优于其他无监督基线5%。

Conclusion: AutoSEP通过自监督提示学习显著提升了MLLMs的细粒度分类能力，展示了无监督优化的有效性。

Abstract: Despite Multimodal Large Language Models (MLLMs) showing promising results on
general zero-shot image classification tasks, fine-grained image classification
remains challenging. It demands precise attention to subtle visual details to
distinguish between visually similar subcategories--details that MLLMs may
easily overlook without explicit guidance. To address this, we introduce
AutoSEP, an iterative self-supervised prompt learning framework designed to
enhance MLLM fine-grained classification capabilities in a fully unsupervised
manner. Our core idea is to leverage unlabeled data to learn a description
prompt that guides MLLMs in identifying crucial discriminative features within
an image, and boosts classification accuracy. We developed an automatic
self-enhancing prompt learning framework called AutoSEP to iteratively improve
the description prompt using unlabeled data, based on instance-level
classification scoring function. AutoSEP only requires black-box access to
MLLMs, eliminating the need for any training or fine-tuning. We evaluate our
approach on multiple fine-grained classification datasets. It consistently
outperforms other unsupervised baselines, demonstrating the effectiveness of
our self-supervised optimization framework. Notably, AutoSEP on average
improves 13 percent over standard zero-shot classification and 5 percent over
the best-performing baselines. Code is available at:
https://github.com/yq-hong/AutoSEP

</details>


### [353] [Infinity Parser: Layout Aware Reinforcement Learning for Scanned Document Parsing](https://arxiv.org/abs/2506.03197)
*Baode Wang,Biao Wu,Weizhen Li,Meng Fang,Yanjie Liang,Zuming Huang,Haozhe Wang,Jun Huang,Ling Chen,Wei Chu,Yuan Qi*

Main category: cs.CV

TL;DR: 论文提出了一种名为layoutRL的端到端强化学习框架，通过优化复合奖励（包括归一化编辑距离、段落计数准确性和阅读顺序保持）来训练模型，使其具有显式的布局感知能力。基于新发布的数据集Infinity-Doc-55K，论文实现了Infinity-Parser，并在OCR、表格和公式提取以及阅读顺序检测任务中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统多阶段文档解析流程存在错误传播和适应性差的问题，限制了文档AI的发展。

Method: 使用强化学习框架layoutRL，结合复合奖励机制，基于Infinity-Doc-55K数据集训练模型。

Result: Infinity-Parser在英文和中文基准测试中均表现优异，超越了专业流程和通用视觉语言模型。

Conclusion: 论文提出的方法显著提升了文档解析的准确性和结构保真度，并公开了代码和数据集以推动文档理解领域的发展。

Abstract: Automated parsing of scanned documents into richly structured,
machine-readable formats remains a critical bottleneck in Document AI, as
traditional multi-stage pipelines suffer from error propagation and limited
adaptability to diverse layouts. We introduce layoutRL, an end-to-end
reinforcement learning framework that trains models to be explicitly
layout-aware by optimizing a composite reward of normalized edit distance,
paragraph count accuracy, and reading order preservation. Leveraging our newly
released dataset, Infinity-Doc-55K, which combines 55K high-fidelity synthetic
scanned document parsing data with expert-filtered real-world documents, we
instantiate layoutRL in a vision-language-model-based parser called
Infinity-Parser. Evaluated on English and Chinese benchmarks for OCR, table and
formula extraction, and reading order detection, Infinity-Parser achieves new
state-of-the-art performance in both accuracy and structural fidelity,
outpacing specialist pipelines and general-purpose vision-language models. We
will publicly release our code and dataset to accelerate progress in robust
document understanding.

</details>


### [354] [FLEX: A Large-Scale Multi-Modal Multi-Action Dataset for Fitness Action Quality Assessment](https://arxiv.org/abs/2506.03198)
*Hao Yin,Lijun Gu,Paritosh Parmar,Lin Xu,Tianxiao Guo,Weiwei Fu,Yang Zhang,Tianyou Zheng*

Main category: cs.CV

TL;DR: 论文提出了FLEX数据集，首个多模态、多动作的大规模数据集，结合表面肌电信号（sEMG）用于动作质量评估（AQA），填补了现有AQA方法和数据集在健身领域的空白。


<details>
  <summary>Details</summary>
Motivation: 随着健康意识的提升和审美体型的追求，健身成为流行趋势，但负重训练存在潜在风险。当前AQA方法和数据集局限于单视角竞技体育场景和RGB模态，缺乏对健身动作的专业评估和指导。

Method: 提出FLEX数据集，包含20种负重动作，由38名不同技能水平的受试者各重复10次，采集多视角RGB视频、3D姿态、sEMG和生理信息。结合知识图谱构建惩罚函数形式的标注规则。

Result: 实验表明，多模态数据、多视角数据和细粒度标注显著提升模型性能。

Conclusion: FLEX推动了AQA方法和数据集向多模态、多动作场景发展，促进了人工智能在健身领域的应用。

Abstract: With the increasing awareness of health and the growing desire for aesthetic
physique, fitness has become a prevailing trend. However, the potential risks
associated with fitness training, especially with weight-loaded fitness
actions, cannot be overlooked. Action Quality Assessment (AQA), a technology
that quantifies the quality of human action and provides feedback, holds the
potential to assist fitness enthusiasts of varying skill levels in achieving
better training outcomes. Nevertheless, current AQA methodologies and datasets
are limited to single-view competitive sports scenarios and RGB modality and
lack professional assessment and guidance of fitness actions. To address this
gap, we propose the FLEX dataset, the first multi-modal, multi-action,
large-scale dataset that incorporates surface electromyography (sEMG) signals
into AQA. FLEX utilizes high-precision MoCap to collect 20 different
weight-loaded actions performed by 38 subjects across 3 different skill levels
for 10 repetitions each, containing 5 different views of the RGB video, 3D
pose, sEMG, and physiological information. Additionally, FLEX incorporates
knowledge graphs into AQA, constructing annotation rules in the form of penalty
functions that map weight-loaded actions, action keysteps, error types, and
feedback. We conducted various baseline methodologies on FLEX, demonstrating
that multimodal data, multiview data, and fine-grained annotations
significantly enhance model performance. FLEX not only advances AQA
methodologies and datasets towards multi-modal and multi-action scenarios but
also fosters the integration of artificial intelligence within the fitness
domain. Dataset and code are available at
https://haoyin116.github.io/FLEX_Dataset.

</details>


### [355] [Channel-adaptive Cross-modal Generative Semantic Communication for Point Cloud Transmission](https://arxiv.org/abs/2506.03211)
*Wanting Yang,Zehui Xiong,Qianqian Yang,Ping Zhang,Merouane Debbah,Rahim Tafazolli*

Main category: cs.CV

TL;DR: GenSeC-PC是一种新型的跨模态生成语义通信方法，用于高效传输点云数据，结合图像和点云的语义编码，实现高压缩效率和优越的重建性能。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶和扩展现实的快速发展，点云的高效传输变得尤为重要。现有方法在噪声或不完整源数据下的可靠重建和实时通信方面存在不足。

Method: 采用跨模态语义编码器融合图像和点云，基于PointDif的解码器，设计通道自适应的联合语义-信道编码架构，并利用修正的去噪扩散隐式模型加速解码。

Result: 仿真结果表明，该方法在低信噪比、带宽限制等多样化条件下表现出鲁棒性，支持完全模拟传输，显著提升压缩效率。

Conclusion: GenSeC-PC通过生成先验和跨模态设计，实现了高效、鲁棒的点云传输，为实时通信提供了可行方案。

Abstract: With the rapid development of autonomous driving and extended reality,
efficient transmission of point clouds (PCs) has become increasingly important.
In this context, we propose a novel channel-adaptive cross-modal generative
semantic communication (SemCom) for PC transmission, called GenSeC-PC.
GenSeC-PC employs a semantic encoder that fuses images and point clouds, where
images serve as non-transmitted side information. Meanwhile, the decoder is
built upon the backbone of PointDif. Such a cross-modal design not only ensures
high compression efficiency but also delivers superior reconstruction
performance compared to PointDif. Moreover, to ensure robust transmission and
reduce system complexity, we design a streamlined and asymmetric
channel-adaptive joint semantic-channel coding architecture, where only the
encoder needs the feedback of average signal-to-noise ratio (SNR) and available
bandwidth. In addition, rectified denoising diffusion implicit models is
employed to accelerate the decoding process to the millisecond level, enabling
real-time PC communication. Unlike existing methods, GenSeC-PC leverages
generative priors to ensure reliable reconstruction even from noisy or
incomplete source PCs. More importantly, it supports fully analog transmission,
improving compression efficiency by eliminating the need for error-free side
information transmission common in prior SemCom approaches. Simulation results
confirm the effectiveness of cross-modal semantic extraction and dual-metric
guided fine-tuning, highlighting the framework's robustness across diverse
conditions, including low SNR, bandwidth limitations, varying numbers of 2D
images, and previously unseen objects.

</details>


### [356] [ConMamba: Contrastive Vision Mamba for Plant Disease Detection](https://arxiv.org/abs/2506.03213)
*Abdullah Al Mamun,Miaohua Zhang,David Ahmedt-Aristizabal,Zeeshan Hayder,Mohammad Awrangjeb*

Main category: cs.CV

TL;DR: ConMamba是一种新型自监督学习框架，专为植物病害检测设计，通过双向状态空间模型和动态对比损失优化性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法依赖大量标注数据且计算成本高，自监督学习虽能利用未标注数据，但现有方法难以捕捉长距离依赖关系且特征对齐效果不佳。

Method: 提出ConMamba框架，结合Vision Mamba Encoder（双向状态空间模型）和动态权重调整的双层对比损失。

Result: 在三个基准数据集上显著优于现有方法。

Conclusion: ConMamba为植物病害检测提供了高效且鲁棒的解决方案。

Abstract: Plant Disease Detection (PDD) is a key aspect of precision agriculture.
However, existing deep learning methods often rely on extensively annotated
datasets, which are time-consuming and costly to generate. Self-supervised
Learning (SSL) offers a promising alternative by exploiting the abundance of
unlabeled data. However, most existing SSL approaches suffer from high
computational costs due to convolutional neural networks or transformer-based
architectures. Additionally, they struggle to capture long-range dependencies
in visual representation and rely on static loss functions that fail to align
local and global features effectively. To address these challenges, we propose
ConMamba, a novel SSL framework specially designed for PDD. ConMamba integrates
the Vision Mamba Encoder (VME), which employs a bidirectional State Space Model
(SSM) to capture long-range dependencies efficiently. Furthermore, we introduce
a dual-level contrastive loss with dynamic weight adjustment to optimize
local-global feature alignment. Experimental results on three benchmark
datasets demonstrate that ConMamba significantly outperforms state-of-the-art
methods across multiple evaluation metrics. This provides an efficient and
robust solution for PDD.

</details>


### [357] [OpenCarbon: A Contrastive Learning-based Cross-Modality Neural Approach for High-Resolution Carbon Emission Prediction Using Open Data](https://arxiv.org/abs/2506.03224)
*Jinwei Zeng,Yu Liu,Guozhen Zhang,Jingtao Ding,Yuming Lin,Jian Yuan,Yong Li*

Main category: cs.CV

TL;DR: 论文提出了一种基于开放数据（卫星图像和POI数据）的高分辨率碳排放预测模型OpenCarbon，通过跨模态信息提取和邻域聚合模块解决功能性和空间相关性挑战，实验显示性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统碳排放核算方法数据收集成本高，而开放数据和先进学习技术为高分辨率碳排放估算提供了新思路。

Method: 结合卫星图像和POI数据，设计跨模态信息提取与融合模块及邻域聚合模块，解决功能性和空间相关性挑战。

Result: 模型在R2指标上性能提升26.6%，泛化测试和案例研究验证了其有效性。

Conclusion: OpenCarbon能有效捕捉城市功能与碳排放的关系，为高效碳治理和减排规划提供支持。

Abstract: Accurately estimating high-resolution carbon emissions is crucial for
effective emission governance and mitigation planning. While conventional
methods for precise carbon accounting are hindered by substantial data
collection efforts, the rise of open data and advanced learning techniques
offers a promising solution. Once an open data-based prediction model is
developed and trained, it can easily infer emissions for new areas based on
available open data. To address this, we incorporate two modalities of open
data, satellite images and point-of-interest (POI) data, to predict
high-resolution urban carbon emissions, with satellite images providing
macroscopic and static and POI data offering fine-grained and relatively
dynamic functionality information. However, estimating high-resolution carbon
emissions presents two significant challenges: the intertwined and implicit
effects of various functionalities on carbon emissions, and the complex spatial
contiguity correlations that give rise to the agglomeration effect. Our model,
OpenCarbon, features two major designs that target the challenges: a
cross-modality information extraction and fusion module to extract
complementary functionality information from two modules and model their
interactions, and a neighborhood-informed aggregation module to capture the
spatial contiguity correlations. Extensive experiments demonstrate our model's
superiority, with a significant performance gain of 26.6\% on R2. Further
generalizability tests and case studies also show OpenCarbon's capacity to
capture the intrinsic relation between urban functionalities and carbon
emissions, validating its potential to empower efficient carbon governance and
targeted carbon mitigation planning. Codes and data are available:
https://github.com/JinweiZzz/OpenCarbon.

</details>


### [358] [Pre-trained Vision-Language Models Assisted Noisy Partial Label Learning](https://arxiv.org/abs/2506.03229)
*Qian-Wei Wang,Yuqiu Xie,Letian Zhang,Zimo Liu,Shu-Tao Xia*

Main category: cs.CV

TL;DR: 本文提出了一种名为Co-Reg的创新方法，用于从预训练视觉语言模型（VLMs）生成的噪声部分标签中学习，通过协同一致性正则化提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 预训练VLMs（如CLIP、LLaVa和GPT-4V）可以替代耗时的手动标注，但其生成的噪声标签具有实例依赖性，增加了学习难度。

Method: 通过同时训练两个神经网络，利用‘协同伪标签’机制净化训练标签，并在标签空间和特征表示空间施加一致性正则化约束。

Result: 实验验证了该方法在不同去噪和消歧算法、标注方式及预训练模型应用方案中的有效性。

Conclusion: 该方法展示了将弱监督学习技术融入预训练模型知识蒸馏过程的广阔前景。

Abstract: In the context of noisy partial label learning (NPLL), each training sample
is associated with a set of candidate labels annotated by multiple noisy
annotators. With the emergence of high-performance pre-trained vision-language
models (VLMs) such as CLIP, LLaVa and GPT-4V, the direction of using these
models to replace time-consuming manual annotation workflows and achieve
"manual-annotation-free" training for downstream tasks has become a highly
promising research avenue. This paper focuses on learning from noisy partial
labels annotated by pre-trained VLMs and proposes an innovative collaborative
consistency regularization (Co-Reg) method. Unlike the symmetric noise
primarily addressed in traditional noisy label learning, the noise generated by
pre-trained models is instance-dependent, embodying the underlying patterns of
the pre-trained models themselves, which significantly increases the learning
difficulty for the model. To address this, we simultaneously train two neural
networks that implement collaborative purification of training labels through a
"Co-Pseudo-Labeling" mechanism, while enforcing consistency regularization
constraints in both the label space and feature representation space. Our
method can also leverage few-shot manually annotated valid labels to further
enhance its performances. Comparative experiments with different denoising and
disambiguation algorithms, annotation manners, and pre-trained model
application schemes fully validate the effectiveness of the proposed method,
while revealing the broad prospects of integrating weakly-supervised learning
techniques into the knowledge distillation process of pre-trained models.

</details>


### [359] [Chipmunk: Training-Free Acceleration of Diffusion Transformers with Dynamic Column-Sparse Deltas](https://arxiv.org/abs/2506.03275)
*Austin Silveria,Soham V. Govande,Daniel Y. Fu*

Main category: cs.CV

TL;DR: 论文提出Chipmunk方法，通过动态稀疏化减少DiT推理时的计算冗余，显著提升速度且不影响生成质量。


<details>
  <summary>Details</summary>
Motivation: DiT在图像和视频生成中表现出色，但推理计算成本高。研究发现DiT的潜在噪声向量变化缓慢，表明计算存在冗余。

Method: Chipmunk利用动态稀疏化，仅重新计算变化最快的中间激活值，同时缓存其余部分，并通过列稀疏核和计算重叠优化系统性能。

Result: Chipmunk在HunyuanVideo和FLUX.1-dev上分别实现2.16x和1.41x加速，叠加全步缓存后加速效果更显著。

Conclusion: Chipmunk有效减少DiT推理冗余，显著提升速度且保持生成质量，适用于多种模型。

Abstract: Diffusion Transformers (DiTs) have achieved state-of-the-art performance in
high-quality image and video generation but incur substantial compute cost at
inference. A common observation is that DiT latent noise vectors change slowly
across inference steps, which suggests that the DiT compute may be redundant
across steps. In this paper, we aim to speed up inference by reducing this
redundancy, without additional training. We first study how activations change
between steps in two state-of-the-art open-source DiTs. We find that just 5-25%
of the values in attention and MLP explain 70-90% of the change in activations
across steps. This finding motivates our approach, Chipmunk, which uses dynamic
sparsity at inference time to recompute only the fastest-changing intermediate
activations, while caching the rest. Dynamic sparsity introduces two systems
challenges: (1) sparse attention and MLP operations tend to underutilize GPU
tensor cores; and (2) computing dynamic sparsity patterns at runtime and
caching activations both introduce overhead. To address these challenges,
Chipmunk first uses a voxel-based reordering of input tokens to introduce
column-wise sparsity. We implement column-sparse kernels utilizing efficient
sparse gathers from global to shared GPU memory, achieving a 9.3x speedup at
93% sparsity compared to highly-optimized dense baselines. Second, Chipmunk
overlaps the computation of sparsity patterns and cache updates with other
parts of the computation (e.g., second layer of the MLP) to hide the extra
latency. Chipmunk achieves up to 2.16x speedup on HunyuanVideo and 1.41x on
FLUX.1-dev without compromising generation quality. Furthermore, we show that
Chipmunk can be stacked on top of full step caching, achieving a 3.72x speedup
on HunyuanVideo, a 2.67x speedup on WAN2.1, and a 2.25x speedup on FLUX.1-dev
with minimal quality impact.

</details>


### [360] [Learning Optical Flow Field via Neural Ordinary Differential Equation](https://arxiv.org/abs/2506.03290)
*Leyla Mirvakhabova,Hong Cai,Jisoo Jeong,Hanno Ackermann,Farhad Zanjani,Fatih Porikli*

Main category: cs.CV

TL;DR: 论文提出了一种基于神经ODE的光流估计方法，动态调整计算步骤，优于固定步骤的基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有光流估计方法使用固定步骤的神经网络进行迭代优化，可能导致性能不佳，缺乏对输入数据的适应性。

Method: 采用神经ODE模型预测光流导数，动态调整计算步骤，通过特定架构和超参数实现与现有方法相同的更新。

Result: 在光流基准测试中，该方法显著优于基线和现有模型，且仅需单次优化步骤。

Conclusion: 神经ODE模型为光流估计提供了更灵活和高效的方法，具有显著性能提升。

Abstract: Recent works on optical flow estimation use neural networks to predict the
flow field that maps positions of one image to positions of the other. These
networks consist of a feature extractor, a correlation volume, and finally
several refinement steps. These refinement steps mimic the iterative
refinements performed by classical optimization algorithms and are usually
implemented by neural layers (e.g., GRU) which are recurrently executed for a
fixed and pre-determined number of steps. However, relying on a fixed number of
steps may result in suboptimal performance because it is not tailored to the
input data. In this paper, we introduce a novel approach for predicting the
derivative of the flow using a continuous model, namely neural ordinary
differential equations (ODE). One key advantage of this approach is its
capacity to model an equilibrium process, dynamically adjusting the number of
compute steps based on the data at hand. By following a particular neural
architecture, ODE solver, and associated hyperparameters, our proposed model
can replicate the exact same updates as recurrent cells used in existing works,
offering greater generality. Through extensive experimental analysis on optical
flow benchmarks, we demonstrate that our approach achieves an impressive
improvement over baseline and existing models, all while requiring only a
single refinement step.

</details>


### [361] [SportMamba: Adaptive Non-Linear Multi-Object Tracking with State Space Models for Team Sports](https://arxiv.org/abs/2506.03335)
*Dheeraj Khanna,Jerrin Bright,Yuhao Chen,John S. Zelek*

Main category: cs.CV

TL;DR: SportMamba是一种针对动态团队运动的多目标跟踪技术，通过引入mamba-attention机制和高度自适应空间关联度量，解决了快速运动和遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 团队运动中的多目标跟踪因快速运动和频繁遮挡而具有挑战性，现有方法依赖检测和外观跟踪，难以处理复杂场景。

Method: 提出mamba-attention机制建模非线性运动，引入高度自适应空间关联度量减少遮挡导致的ID切换，扩展检测搜索空间。

Result: 在SportsMOT数据集上表现优异，并在VIP-HTD冰球数据集上展示了泛化能力。

Conclusion: SportMamba在复杂运动场景中实现了先进的跟踪性能，并具备良好的泛化能力。

Abstract: Multi-object tracking (MOT) in team sports is particularly challenging due to
the fast-paced motion and frequent occlusions resulting in motion blur and
identity switches, respectively. Predicting player positions in such scenarios
is particularly difficult due to the observed highly non-linear motion
patterns. Current methods are heavily reliant on object detection and
appearance-based tracking, which struggle to perform in complex team sports
scenarios, where appearance cues are ambiguous and motion patterns do not
necessarily follow a linear pattern. To address these challenges, we introduce
SportMamba, an adaptive hybrid MOT technique specifically designed for tracking
in dynamic team sports. The technical contribution of SportMamba is twofold.
First, we introduce a mamba-attention mechanism that models non-linear motion
by implicitly focusing on relevant embedding dependencies. Second, we propose a
height-adaptive spatial association metric to reduce ID switches caused by
partial occlusions by accounting for scale variations due to depth changes.
Additionally, we extend the detection search space with adaptive buffers to
improve associations in fast-motion scenarios. Our proposed technique,
SportMamba, demonstrates state-of-the-art performance on various metrics in the
SportsMOT dataset, which is characterized by complex motion and severe
occlusion. Furthermore, we demonstrate its generalization capability through
zero-shot transfer to VIP-HTD, an ice hockey dataset.

</details>


### [362] [Seeing the Arrow of Time in Large Multimodal Models](https://arxiv.org/abs/2506.03340)
*Zihui Xue,Mi Luo,Kristen Grauman*

Main category: cs.CV

TL;DR: 论文提出ArrowRL，一种基于强化学习的训练策略，通过逆向奖励提升大型多模态模型（LMMs）对时间方向性的感知能力，并在新基准AoTBench上验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有LMMs在视频理解中难以感知和利用时间方向性，阻碍了更深层次的时间理解。

Method: 提出ArrowRL，一种基于强化学习的训练策略，通过逆向奖励机制鼓励模型对正向和反向视频帧产生不同的解释。

Result: ArrowRL显著提升了时间感知能力，在AoTBench和标准视频问答（VQA）基准上分别实现了超过20%和10%的准确率提升。

Conclusion: ArrowRL的有效性验证了在LMMs中专门理解时间方向性的重要性。

Abstract: The Arrow of Time (AoT)-time's irreversible flow shaping physical events-is
fundamental to video comprehension, yet remains a significant challenge for
modern large multimodal models (LMMs). Current LMMs struggle to perceive and
utilize temporal directionality in video when responding to language queries,
obstructing deeper temporal understanding. We tackle this deficiency by first
providing a critical analysis of existing benchmarks and models. We then
introduce ArrowRL, a reinforcement learning (RL)-based training strategy with
an innovative reverse reward that instills AoT awareness by encouraging
divergent video interpretations between forward and reversed visual frames. For
rigorous evaluation, we additionally develop AoTBench, a new multi-faceted
benchmark probing temporally challenging questions. Experiments show ArrowRL
greatly advances temporal perception: it not only achieves substantial
improvements on our challenging AoTBench but also demonstrably boosts
performance on standard video question answering (VQA) benchmarks (with peak
accuracy gains reaching over 20% and 10% respectively). This validates
ArrowRL's effectiveness and highlights the critical need for dedicated AoT
understanding in LMMs.

</details>


### [363] [Semiconductor SEM Image Defect Classification Using Supervised and Semi-Supervised Learning with Vision Transformers](https://arxiv.org/abs/2506.03345)
*Chien-Fu,Huang,Katherine Sieg,Leonid Karlinksy,Nash Flores,Rebekah Sheraw,Xin Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种基于视觉变换器（ViT）的自动缺陷分类方法，用于半导体晶圆缺陷的扫描电子显微镜图像分类，实现了超过90%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 半导体工艺中缺陷控制对提高产量、降低成本和预防关键组件故障至关重要，但传统人工分类方法存在时间、人力和偏见限制。

Method: 采用视觉变换器（ViT）神经网络，结合DinoV2的迁移学习和半监督学习，对7400多张晶圆缺陷图像进行分类。

Result: 在每类缺陷仅需少于15张图像的情况下，分类准确率超过90%。

Conclusion: 该方法展示了快速、灵活且平台无关的自动缺陷分类工具的潜力。

Abstract: Controlling defects in semiconductor processes is important for maintaining
yield, improving production cost, and preventing time-dependent critical
component failures. Electron beam-based imaging has been used as a tool to
survey wafers in the line and inspect for defects. However, manual
classification of images for these nano-scale defects is limited by time, labor
constraints, and human biases. In recent years, deep learning computer vision
algorithms have shown to be effective solutions for image-based inspection
applications in industry. This work proposes application of vision transformer
(ViT) neural networks for automatic defect classification (ADC) of scanning
electron microscope (SEM) images of wafer defects. We evaluated our proposed
methods on 300mm wafer semiconductor defect data from our fab in IBM Albany. We
studied 11 defect types from over 7400 total images and investigated the
potential of transfer learning of DinoV2 and semi-supervised learning for
improved classification accuracy and efficient computation. We were able to
achieve classification accuracies of over 90% with less than 15 images per
defect class. Our work demonstrates the potential to apply the proposed
framework for a platform agnostic in-house classification tool with faster
turnaround time and flexibility.

</details>


### [364] [Toward Reliable VLM: A Fine-Grained Benchmark and Framework for Exposure, Bias, and Inference in Korean Street Views](https://arxiv.org/abs/2506.03371)
*Xiaonan Wang,Bo Shao,Hansaem Kim*

Main category: cs.CV

TL;DR: 该论文介绍了KoreaGEO Bench，一个针对韩国街景的细粒度多模态地理定位基准数据集，旨在解决现有基准的局限性，并评估视觉语言模型在隐私风险下的表现。


<details>
  <summary>Details</summary>
Motivation: 当前的地理定位基准存在粗粒度、语言偏见和缺乏多模态及隐私评估的问题，因此需要更精细和全面的基准来评估模型。

Method: 构建了包含1,080张高分辨率图像的KoreaGEO Bench数据集，涵盖四种城市集群和九种地点类型，并引入多模态输入和两种韩语字幕。采用三路径评估协议测试十种主流视觉语言模型。

Result: 结果显示不同输入模态对定位精度有显著影响，并揭示了模型对核心城市的结构性预测偏见。

Conclusion: KoreaGEO Bench为地理定位任务提供了更全面的评估工具，揭示了模型的局限性及其在隐私风险下的表现。

Abstract: Recent advances in vision-language models (VLMs) have enabled accurate
image-based geolocation, raising serious concerns about location privacy risks
in everyday social media posts. However, current benchmarks remain
coarse-grained, linguistically biased, and lack multimodal and privacy-aware
evaluations. To address these gaps, we present KoreaGEO Bench, the first
fine-grained, multimodal geolocation benchmark for Korean street views. Our
dataset comprises 1,080 high-resolution images sampled across four urban
clusters and nine place types, enriched with multi-contextual annotations and
two styles of Korean captions simulating real-world privacy exposure. We
introduce a three-path evaluation protocol to assess ten mainstream VLMs under
varying input modalities and analyze their accuracy, spatial bias, and
reasoning behavior. Results reveal modality-driven shifts in localization
precision and highlight structural prediction biases toward core cities.

</details>


### [365] [A Foundation Model for Spatial Proteomics](https://arxiv.org/abs/2506.03373)
*Muhammad Shaban,Yuzhou Chang,Huaying Qiu,Yao Yu Yeo,Andrew H. Song,Guillaume Jaume,Yuchen Wang,Luca L. Weishaupt,Tong Ding,Anurag Vaidya,Abdallah Lamane,Daniel Shao,Mohammed Zidane,Yunhao Bai,Paige McCallum,Shuli Luo,Wenrui Wu,Yang Wang,Precious Cramer,Chi Ngai Chan,Pierre Stephan,Johanna Schaffenrath,Jia Le Lee,Hendrik A. Michel,Caiwei Tian,Cristina Almagro-Perez,Sophia J. Wagner,Sharifa Sahai,Ming Y. Lu,Richard J. Chen,Andrew Zhang,Mark Edward M. Gonzales,Ahmad Makky,Jia-Ying Joey Lee,Hao Cheng,Nourhan El Ahmar,Sayed Matar,Maximilian Haist,Darci Phillips,Yuqi Tan,Garry P. Nolan,W. Richard Burack,Jacob D. Estes,Jonathan T. C. Liu,Toni K Choueiri,Neeraj Agarwal,Marc Barry,Scott J. Rodig,Long Phi Le,Georg Gerber,Christian M. Schürch,Fabian J. Theis,Youn H Kim,Joe Yeong,Sabina Signoretti,Brooke E. Howitt,Lit-Hsin Loo,Qin Ma,Sizun Jiang,Faisal Mahmood*

Main category: cs.CV

TL;DR: KRONOS是一个为空间蛋白质组学设计的基础模型，通过自监督学习处理多通道、高维度的图像数据，支持多种下游任务，并在多个任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 空间蛋白质组学在单细胞分辨率下映射蛋白质，但现有基础模型对其影响有限，因此需要专门设计的模型。

Method: KRONOS通过自监督学习在47百万图像块上训练，覆盖175种蛋白质标记、16种组织类型和8种成像平台，并引入架构改进处理高维数据。

Result: KRONOS在11个独立队列中表现出色，支持细胞表型分析、区域分类和患者分层等任务，并实现高效数据利用。

Conclusion: KRONOS是一个灵活且可扩展的空间蛋白质组学工具，支持跨机构比较和图像反向搜索。

Abstract: Foundation models have begun to transform image analysis by acting as
pretrained generalist backbones that can be adapted to many tasks even when
post-training data are limited, yet their impact on spatial proteomics, imaging
that maps proteins at single-cell resolution, remains limited. Here, we
introduce KRONOS, a foundation model built for spatial proteomics. KRONOS was
trained in a self-supervised manner on over 47 million image patches covering
175 protein markers, 16 tissue types, and 8 fluorescence-based imaging
platforms. We introduce key architectural adaptations to address the
high-dimensional, multi-channel, and heterogeneous nature of multiplex imaging.
We demonstrate that KRONOS learns biologically meaningful representations
across multiple scales, ranging from cellular and microenvironment to tissue
levels, enabling it to address diverse downstream tasks, including cell
phenotyping, region classification, and patient stratification. Evaluated
across 11 independent cohorts, KRONOS achieves state-of-the-art performance
across cell phenotyping, treatment response prediction, and retrieval tasks,
and is highly data-efficient. KRONOS also introduces the paradigm of
segmentation-free patch-level processing for efficient and scalable spatial
proteomics analysis, allowing cross-institutional comparisons, and as an image
reverse search engine for spatial patterns. Together, these results position
KRONOS as a flexible and scalable tool for spatial proteomics. The model is
publicly accessible at https://github.com/mahmoodlab/KRONOS.

</details>


### [366] [Cross-Modal Urban Sensing: Evaluating Sound-Vision Alignment Across Street-Level and Aerial Imagery](https://arxiv.org/abs/2506.03388)
*Pengyu Chen,Xiao Huang,Teng Fei,Sicheng Wang*

Main category: cs.CV

TL;DR: 研究探讨了城市声音与视觉场景的关联，通过多模态方法比较了不同视觉表示策略在捕捉声音语义上的效果，发现街景嵌入与声音更匹配，而遥感分割在生态分类上更有效。


<details>
  <summary>Details</summary>
Motivation: 探索城市环境声音与视觉场景的对应关系，以填补大规模地理分析中声音数据的潜力。

Method: 采用多模态方法，结合地理标记的声音记录、街景和遥感图像，使用AST、CLIP、RemoteCLIP等模型提取特征并评估跨模态相似性。

Result: 街景嵌入与声音语义更一致，遥感分割在生态分类（BGA框架）上表现更优。

Conclusion: 嵌入模型提供更好的语义对齐，分割方法则更利于解释视觉结构与声学生态的联系，为多模态城市感知提供了新视角。

Abstract: Environmental soundscapes convey substantial ecological and social
information regarding urban environments; however, their potential remains
largely untapped in large-scale geographic analysis. In this study, we
investigate the extent to which urban sounds correspond with visual scenes by
comparing various visual representation strategies in capturing acoustic
semantics. We employ a multimodal approach that integrates geo-referenced sound
recordings with both street-level and remote sensing imagery across three major
global cities: London, New York, and Tokyo. Utilizing the AST model for audio,
along with CLIP and RemoteCLIP for imagery, as well as CLIPSeg and Seg-Earth OV
for semantic segmentation, we extract embeddings and class-level features to
evaluate cross-modal similarity. The results indicate that street view
embeddings demonstrate stronger alignment with environmental sounds compared to
segmentation outputs, whereas remote sensing segmentation is more effective in
interpreting ecological categories through a Biophony--Geophony--Anthrophony
(BGA) framework. These findings imply that embedding-based models offer
superior semantic alignment, while segmentation-based methods provide
interpretable links between visual structure and acoustic ecology. This work
advances the burgeoning field of multimodal urban sensing by offering novel
perspectives for incorporating sound into geospatial analysis.

</details>


### [367] [Temporal Vegetation Index-Based Unsupervised Crop Stress Detection via Eigenvector-Guided Contrastive Learning](https://arxiv.org/abs/2506.03394)
*Shafqaat Ahmad*

Main category: cs.CV

TL;DR: EigenCL是一种无监督对比学习框架，用于早期作物胁迫检测，无需标记数据，基于NDRE时间动态和生物特征分解。


<details>
  <summary>Details</summary>
Motivation: 传统NDRE方法在胁迫症状显现后才能检测或需要标记数据，限制了可扩展性。EigenCL旨在提供一种无标签、可扩展的早期胁迫检测方法。

Method: 利用Sentinel-2 NDRE图像构建时间序列，通过RBF相似矩阵和特征分解提取主特征向量，定义胁迫感知相似性进行对比学习。

Result: 学习到的嵌入形成生理学上有意义的聚类，实现76%的早期胁迫检测（提前12天），下游分类准确率达95%（k-NN）和91%（逻辑回归）。

Conclusion: EigenCL是一种无需标记、可扩展的早期胁迫检测方法，适用于数据稀缺的农业环境，具有实际部署潜力。

Abstract: Early detection of crop stress is vital for minimizing yield loss and
enabling timely intervention in precision agriculture. Traditional approaches
using NDRE often detect stress only after visible symptoms appear or require
labeled datasets, limiting scalability. This study introduces EigenCL, a novel
unsupervised contrastive learning framework guided by temporal NDRE dynamics
and biologically grounded eigen decomposition. Using over 10,000 Sentinel-2
NDRE image patches from drought-affected Iowa cornfields, we constructed
five-point NDRE time series per patch and derived an RBF similarity matrix. The
principal eigenvector explaining 76% of the variance and strongly correlated (r
= 0.95) with raw NDRE values was used to define stress-aware similarity for
contrastive embedding learning. Unlike existing methods that rely on visual
augmentations, EigenCL pulls embeddings together based on biologically similar
stress trajectories and pushes apart divergent ones. The learned embeddings
formed physiologically meaningful clusters, achieving superior clustering
metrics (Silhouette: 0.748, DBI: 0.35) and enabling 76% early stress detection
up to 12 days before conventional NDRE thresholds. Downstream classification
yielded 95% k-NN and 91% logistic regression accuracy. Validation on an
independent 2023 Nebraska dataset confirmed generalizability without
retraining. EigenCL offers a label-free, scalable approach for early stress
detection that aligns with underlying plant physiology and is suitable for
real-world deployment in data-scarce agricultural environments.

</details>


### [368] [ViT-Split: Unleashing the Power of Vision Foundation Models via Efficient Splitting Heads](https://arxiv.org/abs/2506.03433)
*Yifan Li,Xin Li,Tianqin Li,Wenbin He,Yu Kong,Liu Ren*

Main category: cs.CV

TL;DR: ViT-Split是一种新的视觉基础模型（VFM）适配方法，通过分离VFM的提取器和适配器组件，解决了现有方法中的梯度传播和参数调优问题，显著提升了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有VFM适配器存在早期梯度传播和全组件调优的不足，且未能充分利用VFM的先验知识。

Method: 提出ViT-Split方法，将VFM分为提取器和适配器两部分，并引入任务头和先验头，避免早期梯度传播并减少调优参数。

Result: 在多个任务（如分割、检测、深度估计和视觉问答）上验证了ViT-Split的高效性，训练时间减少4倍，性能优于其他适配器。

Conclusion: ViT-Split通过优化VFM的适配方式，显著提升了效率和性能，为下游任务提供了更优的解决方案。

Abstract: Vision foundation models (VFMs) have demonstrated remarkable performance
across a wide range of downstream tasks. While several VFM adapters have shown
promising results by leveraging the prior knowledge of VFMs, we identify two
inefficiencies in these approaches. First, the interaction between
convolutional neural network (CNN) and VFM backbone triggers early layer
gradient backpropagation. Second, existing methods require tuning all
components, adding complexity. Besides, these adapters alter VFM features,
underutilizing the prior knowledge. To tackle these challenges, we propose a
new approach called ViT-Split, based on a key observation: the layers of
several VFMs, like DINOv2, can be divided into two distinct components: an
extractor for learning low-level features and an adapter for learning
task-specific features. Leveraging this insight, we eliminate the CNN branch
and introduce two heads, task head and prior head, to the frozen VFM. The task
head is designed to learn task-specific features, mitigating the early gradient
propagation issue. The prior head is used to leverage the multi-scale prior
features from the frozen VFM, reducing tuning parameters and overfitting.
Extensive experiments on various tasks (e.g., segmentation, detection, depth
estimation, and visual question answering) validate the effectiveness and
efficiency of ViT-Split. Specifically, ViT-Split reduces training time up to
$4\times$ while achieving comparable or even better results on ADE20K, compared
to other VFM adapters.

</details>


### [369] [Geometric Visual Fusion Graph Neural Networks for Multi-Person Human-Object Interaction Recognition in Videos](https://arxiv.org/abs/2506.03440)
*Tanqiu Qiao,Ruochen Li,Frederick W. B. Li,Yoshiki Kubotani,Shigeo Morishima,Hubert P. H. Shum*

Main category: cs.CV

TL;DR: 论文提出了一种名为GeoVis-GNN的几何视觉融合图神经网络，通过双注意力特征融合和相互依赖的实体图学习，从实体特定表示逐步构建高层次交互理解。同时，引入了MPHOI-120数据集以解决复杂动态交互问题。


<details>
  <summary>Details</summary>
Motivation: 人类-物体交互（HOI）识别需要结合视觉和几何特征，但如何在不损害各自独特性的情况下有效融合多模态特征仍具挑战性。

Method: 采用自下而上的方法，提出GeoVis-GNN，结合双注意力特征融合和相互依赖的实体图学习。

Result: 在多种HOI场景中（如双人交互、单人活动等）实现了最先进的性能。

Conclusion: GeoVis-GNN通过有效融合多模态特征，显著提升了HOI识别的性能，MPHOI-120数据集为复杂交互研究提供了支持。

Abstract: Human-Object Interaction (HOI) recognition in videos requires understanding
both visual patterns and geometric relationships as they evolve over time.
Visual and geometric features offer complementary strengths. Visual features
capture appearance context, while geometric features provide structural
patterns. Effectively fusing these multimodal features without compromising
their unique characteristics remains challenging. We observe that establishing
robust, entity-specific representations before modeling interactions helps
preserve the strengths of each modality. Therefore, we hypothesize that a
bottom-up approach is crucial for effective multimodal fusion. Following this
insight, we propose the Geometric Visual Fusion Graph Neural Network
(GeoVis-GNN), which uses dual-attention feature fusion combined with
interdependent entity graph learning. It progressively builds from
entity-specific representations toward high-level interaction understanding. To
advance HOI recognition to real-world scenarios, we introduce the Concurrent
Partial Interaction Dataset (MPHOI-120). It captures dynamic multi-person
interactions involving concurrent actions and partial engagement. This dataset
helps address challenges like complex human-object dynamics and mutual
occlusions. Extensive experiments demonstrate the effectiveness of our method
across various HOI scenarios. These scenarios include two-person interactions,
single-person activities, bimanual manipulations, and complex concurrent
partial interactions. Our method achieves state-of-the-art performance.

</details>


### [370] [RefEdit: A Benchmark and Method for Improving Instruction-based Image Editing Model on Referring Expressions](https://arxiv.org/abs/2506.03448)
*Bimsara Pathiraja,Maitreya Patel,Shivam Singh,Yezhou Yang,Chitta Baral*

Main category: cs.CV

TL;DR: 论文提出RefEdit模型，通过合成数据训练，显著提升了多实体复杂场景的图像编辑能力，优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单对象编辑表现良好，但在多实体复杂场景中表现不佳，亟需改进。

Method: 引入RefEdit-Bench基准，提出RefEdit模型，基于合成数据训练，仅需20,000编辑三元组。

Result: RefEdit在多实体编辑任务中表现优异，超越基于Flux/SD3的基线方法，并在传统基准上达到SOTA。

Conclusion: RefEdit通过高效数据训练，显著提升复杂场景编辑能力，为开源社区提供可复现资源。

Abstract: Despite recent advances in inversion and instruction-based image editing,
existing approaches primarily excel at editing single, prominent objects but
significantly struggle when applied to complex scenes containing multiple
entities. To quantify this gap, we first introduce RefEdit-Bench, a rigorous
real-world benchmark rooted in RefCOCO, where even baselines trained on
millions of samples perform poorly. To overcome this limitation, we introduce
RefEdit -- an instruction-based editing model trained on our scalable synthetic
data generation pipeline. Our RefEdit, trained on only 20,000 editing triplets,
outperforms the Flux/SD3 model-based baselines trained on millions of data.
Extensive evaluations across various benchmarks demonstrate that our model not
only excels in referring expression tasks but also enhances performance on
traditional benchmarks, achieving state-of-the-art results comparable to
closed-source methods. We release data \& checkpoint for reproducibility.

</details>


### [371] [The effects of using created synthetic images in computer vision training](https://arxiv.org/abs/2506.03449)
*John W. Smutny*

Main category: cs.CV

TL;DR: 研究利用Unreal Engine 4生成合成图像补充数据集，提升计算机视觉模型的训练效果，尤其在数据稀缺场景下表现显著。


<details>
  <summary>Details</summary>
Motivation: 解决真实图像数据获取成本高、质量不可控的问题，探索合成图像在计算机视觉模型中的潜力。

Method: 使用UE4生成合成图像，测试其在两种分类任务（猫狗分类和焊接缺陷检测）中对VGG16和MobileNetV3-small模型性能的影响，并引入预训练模型评估合成图像质量。

Result: 合成图像补充60%以上时，测试-训练准确率差距缩小至1-2%；合成图像为主时，仅需10%真实图像即可达到传统方法50-70%的效果。

Conclusion: 合成图像可显著减少对真实数据的依赖，为数据稀缺项目提供高效解决方案。

Abstract: This paper investigates how rendering engines, like Unreal Engine 4 (UE), can
be used to create synthetic images to supplement datasets for deep computer
vision (CV) models in image abundant and image limited use cases. Using
rendered synthetic images from UE can provide developers and businesses with a
method of accessing nearly unlimited, reproducible, agile, and cheap training
sets for their customers and applications without the threat of poisoned images
from the internet or the cost of collecting them. The validity of these
generated images are examined by testing the change in model test accuracy in
two different sized CV models across two binary classification cases (Cat vs
Dog and Weld Defect Detection). In addition, this paper provides an
implementation of how to measure the quality of synthetic images by using
pre-trained CV models as auditors. Results imply that for large (VGG16) and
small (MobileNetV3-small) parameter deep CV models, adding >60% additional
synthetic images to a real image dataset during model training can narrow the
test-training accuracy gap to ~1-2% without a conclusive effect on test
accuracy compared to using real world images alone. Likewise, adding <10%
additional real training images to synthetic only training sets decreased the
classification error rate in half, then decreasing further when adding more
real training images. For these cases tested, using synthetic images from
rendering engines allow researchers to only use 10% of their real images during
training, compared to the traditional 50-70%. This research serves as an
example of how to create synthetic images, guidelines on how to use the images,
potential restrictions and possible performance improvements for data-scarce
projects.

</details>


### [372] [RoNFA: Robust Neural Field-based Approach for Few-Shot Image Classification with Noisy Labels](https://arxiv.org/abs/2506.03461)
*Nan Xiang,Lifeng Xing,Dequan Jin*

Main category: cs.CV

TL;DR: 提出了一种鲁棒的神经场方法（RoNFA），用于带有噪声标签的小样本学习，显著提升了分类准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 小样本学习中标签稀缺且易出错，需提升模型对标签噪声的鲁棒性。

Method: RoNFA通过两个神经场分别表示特征和类别，利用软聚类生成类别代表神经元，并通过自适应感受野调整提升预测准确性。

Result: 在真实数据集上，RoNFA显著优于现有方法，甚至在噪声标签下的准确率超过干净标签下的先进方法。

Conclusion: RoNFA在小样本学习中表现出卓越的鲁棒性和分类能力，适用于实际噪声标签场景。

Abstract: In few-shot learning (FSL), the labeled samples are scarce. Thus, label
errors can significantly reduce classification accuracy. Since label errors are
inevitable in realistic learning tasks, improving the robustness of the model
in the presence of label errors is critical. This paper proposes a new robust
neural field-based image approach (RoNFA) for few-shot image classification
with noisy labels. RoNFA consists of two neural fields for feature and category
representation. They correspond to the feature space and category set. Each
neuron in the field for category representation (FCR) has a receptive field
(RF) on the field for feature representation (FFR) centered at the
representative neuron for its category generated by soft clustering. In the
prediction stage, the range of these receptive fields adapts according to the
neuronal activation in FCR to ensure prediction accuracy. These learning
strategies provide the proposed model with excellent few-shot learning
capability and strong robustness against label noises. The experimental results
on real-world FSL datasets with three different types of label noise
demonstrate that the proposed method significantly outperforms state-of-the-art
FSL methods. Its accuracy obtained in the presence of noisy labels even
surpasses the results obtained by state-of-the-art FSL methods trained on clean
support sets, indicating its strong robustness against noisy labels.

</details>


### [373] [MamFusion: Multi-Mamba with Temporal Fusion for Partially Relevant Video Retrieval](https://arxiv.org/abs/2506.03473)
*Xinru Ying,Jiaqi Mo,Jingyang Lin,Canghong Jin,Fangfang Wang,Lina Wei*

Main category: cs.CV

TL;DR: 该论文提出了一种名为MamFusion的多Mamba模块框架，用于解决部分相关视频检索（PRVR）任务中的长序列视频内容理解问题，通过时间融合技术提升检索效果。


<details>
  <summary>Details</summary>
Motivation: 部分相关视频检索（PRVR）是一个具有挑战性的任务，需要解决长序列视频内容中的信息冗余问题。

Method: 利用Mamba模块的长时状态空间建模能力和线性可扩展性，设计了多Mamba模块的时间融合框架（MamFusion），并引入了Temporal T-to-V和V-to-T Fusion来显式建模文本查询与视频片段的时间关系。

Result: 在大规模数据集上的实验表明，MamFusion在检索效果上达到了最先进的性能。

Conclusion: MamFusion通过有效捕捉长时视频内容的状态相关性并将其融入文本-视频相关性理解，显著提升了PRVR任务的检索性能。

Abstract: Partially Relevant Video Retrieval (PRVR) is a challenging task in the domain
of multimedia retrieval. It is designed to identify and retrieve untrimmed
videos that are partially relevant to the provided query. In this work, we
investigate long-sequence video content understanding to address information
redundancy issues. Leveraging the outstanding long-term state space modeling
capability and linear scalability of the Mamba module, we introduce a
multi-Mamba module with temporal fusion framework (MamFusion) tailored for PRVR
task. This framework effectively captures the state-relatedness in long-term
video content and seamlessly integrates it into text-video relevance
understanding, thereby enhancing the retrieval process. Specifically, we
introduce Temporal T-to-V Fusion and Temporal V-to-T Fusion to explicitly model
temporal relationships between text queries and video moments, improving
contextual awareness and retrieval accuracy. Extensive experiments conducted on
large-scale datasets demonstrate that MamFusion achieves state-of-the-art
performance in retrieval effectiveness. Code is available at the link:
https://github.com/Vision-Multimodal-Lab-HZCU/MamFusion.

</details>


### [374] [Heterogeneous Skeleton-Based Action Representation Learning](https://arxiv.org/abs/2506.03481)
*Hongsong Wang,Xiaoyan Ma,Jidong Kuang,Jie Gui*

Main category: cs.CV

TL;DR: 该论文提出了一种处理异构骨架数据的框架，用于基于骨架的人体动作识别，通过异构骨架处理和统一表示学习两部分解决骨架数据的异质性问题。


<details>
  <summary>Details</summary>
Motivation: 由于骨架数据来源不同，其关节维度和拓扑结构存在异质性，而现有方法仅针对同质骨架设计模型，忽略了这一问题。

Method: 框架包括异构骨架处理（通过辅助网络将二维骨架转为三维，并构建统一骨架）和统一表示学习（使用共享主干网络处理不同骨架）。还设计了语义运动编码以利用骨架语义信息。

Result: 在NTU-60、NTU-120和PKU-MMD II数据集上的实验验证了方法的有效性，适用于不同人形结构的机器人动作识别。

Conclusion: 该方法能有效处理异构骨架数据，提升动作识别性能，具有广泛的应用潜力。

Abstract: Skeleton-based human action recognition has received widespread attention in
recent years due to its diverse range of application scenarios. Due to the
different sources of human skeletons, skeleton data naturally exhibit
heterogeneity. The previous works, however, overlook the heterogeneity of human
skeletons and solely construct models tailored for homogeneous skeletons. This
work addresses the challenge of heterogeneous skeleton-based action
representation learning, specifically focusing on processing skeleton data that
varies in joint dimensions and topological structures. The proposed framework
comprises two primary components: heterogeneous skeleton processing and unified
representation learning. The former first converts two-dimensional skeleton
data into three-dimensional skeleton via an auxiliary network, and then
constructs a prompted unified skeleton using skeleton-specific prompts. We also
design an additional modality named semantic motion encoding to harness the
semantic information within skeletons. The latter module learns a unified
action representation using a shared backbone network that processes different
heterogeneous skeletons. Extensive experiments on the NTU-60, NTU-120, and
PKU-MMD II datasets demonstrate the effectiveness of our method in various
tasks of action understanding. Our approach can be applied to action
recognition in robots with different humanoid structures.

</details>


### [375] [CHIME: Conditional Hallucination and Integrated Multi-scale Enhancement for Time Series Diffusion Model](https://arxiv.org/abs/2506.03502)
*Yuxuan Chen,Haipeng Xie*

Main category: cs.CV

TL;DR: CHIME是一个用于时间序列扩散模型的条件幻觉和多尺度增强框架，解决了多尺度特征对齐和生成能力的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究在时间序列任务中应用扩散模型时，面临多尺度特征对齐和跨实体、长时间尺度生成能力的挑战。

Method: CHIME通过多尺度分解和自适应集成捕获时间序列特征，并引入特征幻觉模块实现跨类别特征迁移。

Result: 在公开数据集上，CHIME实现了最先进的性能，并在少样本场景中表现出优秀的生成泛化能力。

Conclusion: CHIME框架在时间序列生成任务中表现出色，具有广泛的应用潜力。

Abstract: The denoising diffusion probabilistic model has become a mainstream
generative model, achieving significant success in various computer vision
tasks. Recently, there has been initial exploration of applying diffusion
models to time series tasks. However, existing studies still face challenges in
multi-scale feature alignment and generative capabilities across different
entities and long-time scales. In this paper, we propose CHIME, a conditional
hallucination and integrated multi-scale enhancement framework for time series
diffusion models. By employing multi-scale decomposition and adaptive
integration, CHIME captures the decomposed features of time series, achieving
in-domain distribution alignment between generated and original samples. In
addition, we introduce a feature hallucination module in the conditional
denoising process, enabling the transfer of temporal features through the
training of category-independent transformation layers. Experimental results on
publicly available real-world datasets demonstrate that CHIME achieves
state-of-the-art performance and exhibits excellent generative generalization
capabilities in few-shot scenarios.

</details>


### [376] [EDCFlow: Exploring Temporally Dense Difference Maps for Event-based Optical Flow Estimation](https://arxiv.org/abs/2506.03512)
*Daikun Liu,Lei Cheng,Teng Wang,changyin Sun*

Main category: cs.CV

TL;DR: EDCFlow是一种轻量级事件光流网络，通过结合时间密集特征差异和成本体积，实现高分辨率光流估计，具有高效计算和优越泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于事件的光流估计方法在计算冗余和分辨率扩展性上存在局限，EDCFlow旨在解决这些问题。

Method: 开发了基于注意力的多尺度时间特征差异层，高效捕捉高分辨率运动模式，并自适应融合高低分辨率运动特征。

Result: EDCFlow在性能和复杂度上优于现有方法，泛化能力更强。

Conclusion: EDCFlow可作为RAFT类方法的即插即用模块，提升光流细节，适用于高分辨率场景。

Abstract: Recent learning-based methods for event-based optical flow estimation utilize
cost volumes for pixel matching but suffer from redundant computations and
limited scalability to higher resolutions for flow refinement. In this work, we
take advantage of the complementarity between temporally dense feature
differences of adjacent event frames and cost volume and present a lightweight
event-based optical flow network (EDCFlow) to achieve high-quality flow
estimation at a higher resolution. Specifically, an attention-based multi-scale
temporal feature difference layer is developed to capture diverse motion
patterns at high resolution in a computation-efficient manner. An adaptive
fusion of high-resolution difference motion features and low-resolution
correlation motion features is performed to enhance motion representation and
model generalization. Notably, EDCFlow can serve as a plug-and-play refinement
module for RAFT-like event-based methods to enhance flow details. Extensive
experiments demonstrate that EDCFlow achieves better performance with lower
complexity compared to existing methods, offering superior generalization.

</details>


### [377] [DenseDPO: Fine-Grained Temporal Preference Optimization for Video Diffusion Models](https://arxiv.org/abs/2506.03517)
*Ziyi Wu,Anil Kag,Ivan Skorokhodov,Willi Menapace,Ashkan Mirzaei,Igor Gilitschenski,Sergey Tulyakov,Aliaksandr Siarohin*

Main category: cs.CV

TL;DR: DenseDPO改进DPO方法，通过生成对齐的视频对和分段标注偏好，减少运动偏差并提高标注效率，同时支持自动标注。


<details>
  <summary>Details</summary>
Motivation: DPO方法在视频生成中存在运动偏差和标注效率低的问题，DenseDPO旨在解决这些问题。

Method: 1. 通过去噪生成对齐的视频对；2. 分段标注偏好；3. 利用VLMs自动标注。

Result: DenseDPO在减少数据量的情况下显著提升运动生成质量，同时保持其他性能指标。

Conclusion: DenseDPO有效解决了DPO的局限性，并展示了自动标注的潜力。

Abstract: Direct Preference Optimization (DPO) has recently been applied as a
post-training technique for text-to-video diffusion models. To obtain training
data, annotators are asked to provide preferences between two videos generated
from independent noise. However, this approach prohibits fine-grained
comparisons, and we point out that it biases the annotators towards low-motion
clips as they often contain fewer visual artifacts. In this work, we introduce
DenseDPO, a method that addresses these shortcomings by making three
contributions. First, we create each video pair for DPO by denoising corrupted
copies of a ground truth video. This results in aligned pairs with similar
motion structures while differing in local details, effectively neutralizing
the motion bias. Second, we leverage the resulting temporal alignment to label
preferences on short segments rather than entire clips, yielding a denser and
more precise learning signal. With only one-third of the labeled data, DenseDPO
greatly improves motion generation over vanilla DPO, while matching it in text
alignment, visual quality, and temporal consistency. Finally, we show that
DenseDPO unlocks automatic preference annotation using off-the-shelf Vision
Language Models (VLMs): GPT accurately predicts segment-level preferences
similar to task-specifically fine-tuned video reward models, and DenseDPO
trained on these labels achieves performance close to using human labels.

</details>


### [378] [Target Semantics Clustering via Text Representations for Robust Universal Domain Adaptation](https://arxiv.org/abs/2506.03521)
*Weinan He,Zilei Wang,Yixin Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种基于视觉语言模型的方法TASC，通过文本表示空间搜索语义中心，解决了通用域自适应（UniDA）中的复杂对齐问题，并提出了UniMS评分函数检测开放集样本。


<details>
  <summary>Details</summary>
Motivation: 通用域自适应（UniDA）面临域偏移和未知类别偏移的挑战，现有方法在连续图像表示空间中获取语义中心导致复杂且不鲁棒的对齐算法。

Method: 基于视觉语言模型，在离散文本表示空间中搜索语义中心，提出TASC方法（两阶段：贪婪搜索文本嵌入和梯度下降优化编码器）和UniMS评分函数。

Result: 在四个基准测试中验证了方法的有效性和鲁棒性，取得了最先进的性能。

Conclusion: 通过文本表示空间搜索语义中心简化了对齐算法，提升了通用域自适应的性能。

Abstract: Universal Domain Adaptation (UniDA) focuses on transferring source domain
knowledge to the target domain under both domain shift and unknown category
shift. Its main challenge lies in identifying common class samples and aligning
them. Current methods typically obtain target domain semantics centers from an
unconstrained continuous image representation space. Due to domain shift and
the unknown number of clusters, these centers often result in complex and less
robust alignment algorithm. In this paper, based on vision-language models, we
search for semantic centers in a semantically meaningful and discrete text
representation space. The constrained space ensures almost no domain bias and
appropriate semantic granularity for these centers, enabling a simple and
robust adaptation algorithm. Specifically, we propose TArget Semantics
Clustering (TASC) via Text Representations, which leverages information
maximization as a unified objective and involves two stages. First, with the
frozen encoders, a greedy search-based framework is used to search for an
optimal set of text embeddings to represent target semantics. Second, with the
search results fixed, encoders are refined based on gradient descent,
simultaneously achieving robust domain alignment and private class clustering.
Additionally, we propose Universal Maximum Similarity (UniMS), a scoring
function tailored for detecting open-set samples in UniDA. Experimentally, we
evaluate the universality of UniDA algorithms under four category shift
scenarios. Extensive experiments on four benchmarks demonstrate the
effectiveness and robustness of our method, which has achieved state-of-the-art
performance.

</details>


### [379] [Video-Skill-CoT: Skill-based Chain-of-Thoughts for Domain-Adaptive Video Reasoning](https://arxiv.org/abs/2506.03525)
*Daeun Lee,Jaehong Yoon,Jaemin Cho,Mohit Bansal*

Main category: cs.CV

TL;DR: Video-SKoT框架通过技能感知的CoT监督，提升了领域自适应视频推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以适应不同视频内容中的领域特定技能（如事件检测、空间关系理解、情感理解）。

Method: 1. 构建基于技能的CoT标注；2. 引入技能特定的专家学习框架。

Result: 在三个视频理解基准测试中，Video-SKoT表现优于基线方法。

Conclusion: Video-SKoT通过技能感知的CoT监督和专家学习，显著提升了视频推理能力。

Abstract: Recent advances in Chain-of-Thought (CoT) reasoning have improved complex
video understanding, but existing methods often struggle to adapt to
domain-specific skills (e.g., event detection, spatial relation understanding,
emotion understanding) over various video content. To address this, we propose
Video-Skill-CoT (a.k.a. Video-SKoT), a framework that automatically constructs
and leverages skill-aware CoT supervisions for domain-adaptive video reasoning.
First, we construct skill-based CoT annotations: we extract domain-relevant
reasoning skills from training questions, cluster them into a shared skill
taxonomy, and create detailed multi-step CoT rationale tailored to each
video-question pair for training. Second, we introduce a skill-specific expert
learning framework. Each expert module specializes in a subset of reasoning
skills and is trained with lightweight adapters using the collected CoT
supervision. We demonstrate the effectiveness of the proposed approach on three
video understanding benchmarks, where Video-SKoT consistently outperforms
strong baselines. We also provide in-depth analyses on comparing different CoT
annotation pipelines and learned skills over multiple video domains.

</details>


### [380] [Robust Neural Rendering in the Wild with Asymmetric Dual 3D Gaussian Splatting](https://arxiv.org/abs/2506.03538)
*Chengqi Li,Zhihao Shi,Yangdi Lu,Wenbo He,Xiangyu Xu*

Main category: cs.CV

TL;DR: 提出了一种名为Asymmetric Dual 3DGS的新框架，通过并行训练两个3D高斯模型并引入一致性约束，减少重建中的视觉伪影，同时通过动态EMA代理提高效率。


<details>
  <summary>Details</summary>
Motivation: 解决野外图像3D重建中因光照不一致和瞬态干扰导致的低质量训练数据问题，现有方法难以生成稳定且一致的重建结果。

Method: 并行训练两个3D高斯模型，施加一致性约束；引入互补掩码策略防止模型陷入相似错误模式；使用动态EMA代理提高训练效率。

Result: 在真实数据集上表现优于现有方法，同时保持高效性。

Conclusion: Asymmetric Dual 3DGS能有效减少伪影并提升重建质量，代码和模型将开源。

Abstract: 3D reconstruction from in-the-wild images remains a challenging task due to
inconsistent lighting conditions and transient distractors. Existing methods
typically rely on heuristic strategies to handle the low-quality training data,
which often struggle to produce stable and consistent reconstructions,
frequently resulting in visual artifacts. In this work, we propose Asymmetric
Dual 3DGS, a novel framework that leverages the stochastic nature of these
artifacts: they tend to vary across different training runs due to minor
randomness. Specifically, our method trains two 3D Gaussian Splatting (3DGS)
models in parallel, enforcing a consistency constraint that encourages
convergence on reliable scene geometry while suppressing inconsistent
artifacts. To prevent the two models from collapsing into similar failure modes
due to confirmation bias, we introduce a divergent masking strategy that
applies two complementary masks: a multi-cue adaptive mask and a
self-supervised soft mask, which leads to an asymmetric training process of the
two models, reducing shared error modes. In addition, to improve the efficiency
of model training, we introduce a lightweight variant called Dynamic EMA Proxy,
which replaces one of the two models with a dynamically updated Exponential
Moving Average (EMA) proxy, and employs an alternating masking strategy to
preserve divergence. Extensive experiments on challenging real-world datasets
demonstrate that our method consistently outperforms existing approaches while
achieving high efficiency. Codes and trained models will be released.

</details>


### [381] [WIFE-Fusion:Wavelet-aware Intra-inter Frequency Enhancement for Multi-model Image Fusion](https://arxiv.org/abs/2506.03555)
*Tianpei Zhang,Jufeng Zhao,Yiming Zhu,Guangmang Cui*

Main category: cs.CV

TL;DR: 提出了一种基于频域交互的多模态图像融合框架WIFE-Fusion，通过频域自注意力机制和交互增强特征提取与融合。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视频域特征探索和交互关系，限制了多模态图像融合的效果。

Method: 提出Intra-Frequency Self-Attention (IFSA)和Inter-Frequency Interaction (IFI)，分别利用自注意力机制和频域组件交互增强特征提取与融合。

Result: 在五个数据集上的实验表明，WIFE-Fusion优于现有专业和统一融合方法。

Conclusion: WIFE-Fusion通过频域交互实现了更精确的特征提取与融合，显著提升了多模态图像融合效果。

Abstract: Multimodal image fusion effectively aggregates information from diverse
modalities, with fused images playing a crucial role in vision systems.
However, existing methods often neglect frequency-domain feature exploration
and interactive relationships. In this paper, we propose wavelet-aware
Intra-inter Frequency Enhancement Fusion (WIFE-Fusion), a multimodal image
fusion framework based on frequency-domain components interactions. Its core
innovations include: Intra-Frequency Self-Attention (IFSA) that leverages
inherent cross-modal correlations and complementarity through interactive
self-attention mechanisms to extract enriched frequency-domain features, and
Inter-Frequency Interaction (IFI) that enhances enriched features and filters
latent features via combinatorial interactions between heterogeneous
frequency-domain components across modalities. These processes achieve precise
source feature extraction and unified modeling of feature
extraction-aggregation. Extensive experiments on five datasets across three
multimodal fusion tasks demonstrate WIFE-Fusion's superiority over current
specialized and unified fusion methods. Our code is available at
https://github.com/Lmmh058/WIFE-Fusion.

</details>


### [382] [DiagNet: Detecting Objects using Diagonal Constraints on Adjacency Matrix of Graph Neural Network](https://arxiv.org/abs/2506.03571)
*Chong Hyun Lee,Kibae Lee*

Main category: cs.CV

TL;DR: DaigNet是一种新的目标检测方法，通过图卷积网络（GCN）邻接矩阵的对角约束检测目标边界框，无需设计锚框。实验表明其性能优于多个YOLO版本。


<details>
  <summary>Details</summary>
Motivation: 传统目标检测方法需要设计锚框，DaigNet旨在消除这一需求，简化检测流程。

Method: 提出两种基于硬约束和软约束的对角化算法，以及两种损失函数（对角约束和互补约束），并采用YOLO模型的检测头。

Result: 在Pascal VOC上mAP50比YOLOv1高7.5%，在MS COCO上比YOLOv3u、YOLOv5u和YOLOv8分别高5.1%、3.7%和2.9%。

Conclusion: DaigNet通过GCN对角约束有效提升目标检测性能，简化了传统方法的设计复杂度。

Abstract: We propose DaigNet, a new approach to object detection with which we can
detect an object bounding box using diagonal constraints on adjacency matrix of
a graph convolutional network (GCN). We propose two diagonalization algorithms
based on hard and soft constraints on adjacency matrix and two loss functions
using diagonal constraint and complementary constraint. The DaigNet eliminates
the need for designing a set of anchor boxes commonly used. To prove
feasibility of our novel detector, we adopt detection head in YOLO models.
Experiments show that the DiagNet achieves 7.5% higher mAP50 on Pascal VOC than
YOLOv1. The DiagNet also shows 5.1% higher mAP on MS COCO than YOLOv3u, 3.7%
higher mAP than YOLOv5u, and 2.9% higher mAP than YOLOv8.

</details>


### [383] [ViTSGMM: A Robust Semi-Supervised Image Recognition Network Using Sparse Labels](https://arxiv.org/abs/2506.03582)
*Rui Yann,Xianglei Xing*

Main category: cs.CV

TL;DR: ViTSGMM是一种高效的半监督学习图像识别网络，通过优化特征表示与目标类之间的互信息，构建分层混合密度分类决策机制，显著提升了在有限标注数据下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖复杂训练技术和架构，但在极有限标注数据下泛化能力不足。

Method: 构建分层混合密度分类决策机制，优化互信息并压缩冗余信息，保留关键判别成分。

Result: 在STL-10和CIFAR-10/100数据集上，使用极少标注样本即达到最先进性能，并发现并解决了STL-10数据集中的数据泄漏问题。

Conclusion: ViTSGMM在高效性和性能上均优于现有方法，同时揭示了数据集中的潜在问题，提升了实验可靠性。

Abstract: We present ViTSGMM, an image recognition network that leverages
semi-supervised learning in a highly efficient manner. Existing works often
rely on complex training techniques and architectures, while their
generalization ability when dealing with extremely limited labeled data remains
to be improved. To address these limitations, we construct a hierarchical
mixture density classification decision mechanism by optimizing mutual
information between feature representations and target classes, compressing
redundant information while retaining crucial discriminative components.
Experimental results demonstrate that our method achieves state-of-the-art
performance on STL-10 and CIFAR-10/100 datasets when using negligible labeled
samples. Notably, this paper also reveals a long-overlooked data leakage issue
in the STL-10 dataset for semi-supervised learning tasks and removes duplicates
to ensure the reliability of experimental results. Code available at
https://github.com/Shu1L0n9/ViTSGMM.

</details>


### [384] [A Large-Scale Referring Remote Sensing Image Segmentation Dataset and Benchmark](https://arxiv.org/abs/2506.03583)
*Zhigang Yang,Huiguang Yao,Linmao Tian,Xuezhi Zhao,Qiang Li,Qi Wang*

Main category: cs.CV

TL;DR: 论文介绍了NWPU-Refer数据集和MRSNet框架，用于解决遥感图像分割任务中的数据集和模型限制。


<details>
  <summary>Details</summary>
Motivation: 现有遥感图像分割数据集在分辨率、场景多样性和类别覆盖上存在不足，限制了模型的泛化能力。

Method: 提出了NWPU-Refer数据集和MRSNet框架，后者包含IFIM和HFIM模块以优化特征提取和融合。

Result: MRSNet在NWPU-Refer数据集上表现优异，达到最先进水平。

Conclusion: NWPU-Refer和MRSNet为遥感图像分割领域提供了重要的资源和解决方案。

Abstract: Referring Remote Sensing Image Segmentation is a complex and challenging task
that integrates the paradigms of computer vision and natural language
processing. Existing datasets for RRSIS suffer from critical limitations in
resolution, scene diversity, and category coverage, which hinders the
generalization and real-world applicability of refer segmentation models. To
facilitate the development of this field, we introduce NWPU-Refer, the largest
and most diverse RRSIS dataset to date, comprising 15,003 high-resolution
images (1024-2048px) spanning 30+ countries with 49,745 annotated targets
supporting single-object, multi-object, and non-object segmentation scenarios.
Additionally, we propose the Multi-scale Referring Segmentation Network
(MRSNet), a novel framework tailored for the unique demands of RRSIS. MRSNet
introduces two key innovations: (1) an Intra-scale Feature Interaction Module
(IFIM) that captures fine-grained details within each encoder stage, and (2) a
Hierarchical Feature Interaction Module (HFIM) to enable seamless cross-scale
feature fusion, preserving spatial integrity while enhancing discriminative
power. Extensive experiments conducte on the proposed NWPU-Refer dataset
demonstrate that MRSNet achieves state-of-the-art performance across multiple
evaluation metrics, validating its effectiveness. The dataset and code are
publicly available at https://github.com/CVer-Yang/NWPU-Refer.

</details>


### [385] [BiMa: Towards Biases Mitigation for Text-Video Retrieval via Scene Element Guidance](https://arxiv.org/abs/2506.03589)
*Huy Le,Nhat Chung,Tung Kieu,Anh Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: BiMa框架通过视觉和文本去偏方法提升文本-视频检索性能。


<details>
  <summary>Details</summary>
Motivation: 解决文本-视频检索系统中因数据集视觉-语言偏差导致的关键细节忽略问题。

Method: 生成视频场景元素并融入视频嵌入以去偏视觉表示；分离文本特征为内容和偏差部分以去偏文本表示。

Result: 在五大TVR基准测试中表现优异，并在分布外检索任务中验证了去偏能力。

Conclusion: BiMa能有效减少视觉和文本偏差，提升检索性能。

Abstract: Text-video retrieval (TVR) systems often suffer from visual-linguistic biases
present in datasets, which cause pre-trained vision-language models to overlook
key details. To address this, we propose BiMa, a novel framework designed to
mitigate biases in both visual and textual representations. Our approach begins
by generating scene elements that characterize each video by identifying
relevant entities/objects and activities. For visual debiasing, we integrate
these scene elements into the video embeddings, enhancing them to emphasize
fine-grained and salient details. For textual debiasing, we introduce a
mechanism to disentangle text features into content and bias components,
enabling the model to focus on meaningful content while separately handling
biased information. Extensive experiments and ablation studies across five
major TVR benchmarks (i.e., MSR-VTT, MSVD, LSMDC, ActivityNet, and DiDeMo)
demonstrate the competitive performance of BiMa. Additionally, the model's bias
mitigation capability is consistently validated by its strong results on
out-of-distribution retrieval tasks.

</details>


### [386] [Resolving Task Objective Conflicts in Unified Multimodal Understanding and Generation via Task-Aware Mixture-of-Experts](https://arxiv.org/abs/2506.03591)
*Jiaxing Zhang,Xinyi Zeng,Hao Tang*

Main category: cs.CV

TL;DR: 论文提出了一种名为UTAMoE的新方法，通过解耦自回归（AR）模型的内部组件来解决多模态大语言模型（MLLMs）中任务目标冲突的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于自回归变换器的多模态大语言模型在理解和生成任务之间存在目标冲突，导致性能不佳，而现有解决方案未能从根本上解决这一问题。

Method: 设计了UTAMoE框架，通过任务感知的混合专家（MoE）层解耦AR模块，并采用两阶段训练策略增强任务区分与协调。

Result: 在多模态基准测试中，UTAMoE有效缓解了任务目标冲突，取得了最优性能。

Conclusion: UTAMoE通过解耦和任务感知优化，显著提升了多模态大语言模型的性能。

Abstract: Unified multimodal large language models (MLLMs) based on end-to-end
autoregressive (AR) transformers effectively integrate both understanding and
generation tasks within a single framework. However, intrinsic Task Objective
Conflicts between high-level semantic abstraction in understanding and
fine-grained detail preservation in generation pose significant challenges,
often leading to suboptimal trade-offs and task interference. Existing
solutions, such as decoupling shared visual encoders, fall short of
fundamentally resolving these conflicts due to inherent AR architecture. In
this paper, we propose a novel approach that decouples internal components of
AR to resolve task objective conflicts. Specifically, we design UTAMoE, a
Unified Task-Aware Mixture-of-Experts (MoE) framework that decouples internal
AR modules via a Task-Aware MoE Layer to create task-specific optimization
subpaths. To enhance task differentiation while maintaining overall
coordination, we introduce a novel Two-Stage Training Strategy. Extensive
experiments on multimodal benchmarks demonstrate that UTAMoE mitigates task
objective conflicts, achieving state-of-the-art performance across various
tasks. Visualizations and ablation studies further validate the effectiveness
of our approach.

</details>


### [387] [ControlThinker: Unveiling Latent Semantics for Controllable Image Generation through Visual Reasoning](https://arxiv.org/abs/2506.03596)
*Feng Han,Yang Jiao,Shaoxiang Chen,Junhao Xu,Jingjing Chen,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: ControlThinker提出了一种新颖的框架，通过增强文本提示的语义理解，改善了可控图像生成中的语义差距问题。


<details>
  <summary>Details</summary>
Motivation: 当前方法在稀疏语义的文本提示与目标图像之间存在语义差距，且过度依赖低层次控制信号。

Method: 采用“理解后生成”范式，利用MLLM挖掘控制图像的潜在语义以丰富文本提示，并通过ORM选择最优推理轨迹。

Result: 实验表明，ControlThinker显著减少了语义差距，提升了生成图像的视觉质量和语义一致性。

Conclusion: ControlThinker通过增强语义理解和优化推理轨迹，有效解决了可控图像生成中的关键问题。

Abstract: The field of controllable image generation has seen significant advancements,
with various architectures improving generation layout consistency with control
signals. However, contemporary methods still face challenges in bridging the
semantic gap between input text prompts with sparse semantics and the target
images, often over-relying on low-level control signals to infer regional
details. To address this challenge, we propose ControlThinker, a novel
framework that employs a "comprehend-then-generate" paradigm. Firstly, by
incentivizing the visual reasoning capability of a MLLM, latent semantics from
control images are mined to enrich text prompts. This enriched semantic
understanding then seamlessly aids in image generation without the need for
additional complex modifications. To further tackle the uncertainty arising
from the ambiguity of control images, we encourage broader exploration of
reasoning trajectories and select the optimal one using a metric-based output
reward model (ORM). Extensive experimental results demonstrate that
ControlThinker effectively mitigates the semantic gap between raw text prompts
and target images, resulting in improved visual quality and semantic
consistency across a wide range of benchmarks. The code and models are
available at https://github.com/Maplebb/ControlThinker.

</details>


### [388] [Generating 6DoF Object Manipulation Trajectories from Action Description in Egocentric Vision](https://arxiv.org/abs/2506.03605)
*Tomoya Yoshida,Shuhei Kurita,Taichi Nishimura,Shinsuke Mori*

Main category: cs.CV

TL;DR: 论文提出了一种利用大规模视频数据集提取多样化操作轨迹的框架，并基于视觉和点云语言模型生成轨迹，验证了在6DoF操作轨迹生成任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 开发交互式机器人需要学习工具或物体的多样化操作，但大规模收集详细操作演示数据几乎不可行。

Method: 利用Exo-Ego4D的大规模视频数据集提取操作轨迹，结合文本动作描述，开发基于视觉和点云的语言模型生成轨迹。

Result: 在HOT3D数据集上验证了模型能成功生成有效的物体操作轨迹。

Conclusion: 该框架为从动作描述生成6DoF操作轨迹的任务提供了训练数据集和基线模型。

Abstract: Learning to use tools or objects in common scenes, particularly handling them
in various ways as instructed, is a key challenge for developing interactive
robots. Training models to generate such manipulation trajectories requires a
large and diverse collection of detailed manipulation demonstrations for
various objects, which is nearly unfeasible to gather at scale. In this paper,
we propose a framework that leverages large-scale ego- and exo-centric video
datasets -- constructed globally with substantial effort -- of Exo-Ego4D to
extract diverse manipulation trajectories at scale. From these extracted
trajectories with the associated textual action description, we develop
trajectory generation models based on visual and point cloud-based language
models. In the recently proposed egocentric vision-based in-a-quality
trajectory dataset of HOT3D, we confirmed that our models successfully generate
valid object trajectories, establishing a training dataset and baseline models
for the novel task of generating 6DoF manipulation trajectories from action
descriptions in egocentric vision.

</details>


### [389] [Analyzing Transformer Models and Knowledge Distillation Approaches for Image Captioning on Edge AI](https://arxiv.org/abs/2506.03607)
*Wing Man Casca Kwok,Yip Chiu Tung,Kunal Bhagchandani*

Main category: cs.CV

TL;DR: 本文研究了在边缘计算设备上部署基于Transformer的图像描述模型，通过知识蒸馏技术优化模型，实现在资源受限设备上的高效推理。


<details>
  <summary>Details</summary>
Motivation: 工业自动化和物联网应用中，边缘设备需要实时AI决策能力，但传统深度学习模型因计算资源限制难以满足需求。

Method: 评估资源高效的Transformer模型，并应用知识蒸馏技术优化模型。

Result: 实验表明，优化后的模型在资源受限设备上能加速推理并保持性能。

Conclusion: 通过知识蒸馏和模型优化，Transformer模型可在边缘设备上高效运行，提升机器感知能力。

Abstract: Edge computing decentralizes processing power to network edge, enabling
real-time AI-driven decision-making in IoT applications. In industrial
automation such as robotics and rugged edge AI, real-time perception and
intelligence are critical for autonomous operations. Deploying
transformer-based image captioning models at the edge can enhance machine
perception, improve scene understanding for autonomous robots, and aid in
industrial inspection.
  However, these edge or IoT devices are often constrained in computational
resources for physical agility, yet they have strict response time
requirements. Traditional deep learning models can be too large and
computationally demanding for these devices. In this research, we present
findings of transformer-based models for image captioning that operate
effectively on edge devices. By evaluating resource-effective transformer
models and applying knowledge distillation techniques, we demonstrate inference
can be accelerated on resource-constrained devices while maintaining model
performance using these techniques.

</details>


### [390] [PDSE: A Multiple Lesion Detector for CT Images using PANet and Deformable Squeeze-and-Excitation Block](https://arxiv.org/abs/2506.03608)
*Di Fan,Heng Yu,Zhiyuan Xu*

Main category: cs.CV

TL;DR: PDSE是一种改进的一阶段病变检测框架，通过优化Retinanet并结合低层特征图、自适应SE块和通道特征图注意力，显著提升了CT图像中病变检测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: CT扫描中病变的多样性和复杂性使得检测任务具有挑战性，需要更高效的算法来定位不同大小和位置的病变。

Method: 通过改进Retinanet，引入低层特征图增强路径聚合流，结合自适应SE块和通道特征图注意力机制。

Result: 在DeepLesion基准测试中，mAP超过0.20，显著提升了小目标和多尺度目标的检测性能。

Conclusion: PDSE框架在CT病变检测中表现出色，达到了新的最先进水平。

Abstract: Detecting lesions in Computed Tomography (CT) scans is a challenging task in
medical image processing due to the diverse types, sizes, and locations of
lesions. Recently, various one-stage and two-stage framework networks have been
developed to focus on lesion localization. We introduce a one-stage lesion
detection framework, PDSE, by redesigning Retinanet to achieve higher accuracy
and efficiency for detecting lesions in multimodal CT images. Specifically, we
enhance the path aggregation flow by incorporating a low-level feature map.
Additionally, to improve model representation, we utilize the adaptive
Squeeze-and-Excitation (SE) block and integrate channel feature map attention.
This approach has resulted in achieving new state-of-the-art performance. Our
method significantly improves the detection of small and multiscaled objects.
When evaluated against other advanced algorithms on the public DeepLesion
benchmark, our algorithm achieved an mAP of over 0.20.

</details>


### [391] [VLMs Can Aggregate Scattered Training Patches](https://arxiv.org/abs/2506.03614)
*Zhanhui Zhou,Lingjie Chen,Chao Yang,Chaochao Lu*

Main category: cs.CV

TL;DR: 论文研究了视觉语言模型（VLMs）中通过视觉拼接绕过数据过滤的风险，展示了如何通过分散有害图像的碎片来重建有害内容。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过过滤训练数据中的危险样本来降低风险，但攻击者可能将有害图像拆分为看似无害的碎片，分散在多个样本中，从而绕过过滤。

Method: 通过将图像和唯一ID对拆分为不同粒度的碎片进行微调，验证VLMs的视觉拼接能力，并模拟对抗性数据中毒场景。

Result: 实验证明VLMs能够通过视觉拼接从碎片中重建完整信息，导致有害内容绕过过滤并在推理时生成。

Conclusion: 视觉拼接能力为VLMs带来安全隐患，需进一步研究防御方法。

Abstract: One way to mitigate risks in vision-language models (VLMs) is to remove
dangerous samples in their training data. However, such data moderation can be
easily bypassed when harmful images are split into small, benign-looking
patches, scattered across many training samples. VLMs may then learn to piece
these fragments together during training and generate harmful responses at
inference, either from full images or text references. For instance, if trained
on image patches from a bloody scene paired with the descriptions "safe," VLMs
may later describe, the full image or a text reference to the scene, as "safe."
We define the core ability of VLMs enabling this attack as $\textit{visual
stitching}$ -- the ability to integrate visual information spread across
multiple training samples that share the same textual descriptions. In our
work, we first demonstrate visual stitching abilities in common open-source
VLMs on three datasets where each image is labeled with a unique synthetic ID:
we split each $(\texttt{image}, \texttt{ID})$ pair into $\{(\texttt{patch},
\texttt{ID})\}$ pairs at different granularity for finetuning, and we find that
tuned models can verbalize the correct IDs from full images or text reference.
Building on this, we simulate the adversarial data poisoning scenario mentioned
above by using patches from dangerous images and replacing IDs with text
descriptions like ``safe'' or ``unsafe'', demonstrating how harmful content can
evade moderation in patches and later be reconstructed through visual
stitching, posing serious VLM safety risks. Code is available at
https://github.com/ZHZisZZ/visual-stitching.

</details>


### [392] [Isharah: A Large-Scale Multi-Scene Dataset for Continuous Sign Language Recognition](https://arxiv.org/abs/2506.03615)
*Sarah Alyami,Hamzah Luqman,Sadam Al-Azani,Maad Alowaifeer,Yazeed Alharbi,Yaser Alonaizan*

Main category: cs.CV

TL;DR: Isharah是一个大型多场景连续手语识别（CSLR）数据集，首次在非受控环境中通过智能手机摄像头收集，包含30,000个视频片段，支持CSLR和手语翻译（SLT）系统的开发。


<details>
  <summary>Details</summary>
Motivation: 现有CSLR数据集多为受控环境收集，限制了其在真实场景中的鲁棒性。Isharah旨在填补这一空白，提供更具多样性和复杂性的数据。

Method: 通过18名聋人和专业手语者的智能手机摄像头收集30,000个视频片段，涵盖多种录制设置、距离、角度和分辨率，并提供词汇级标注。

Result: Isharah是首个大规模非受控环境CSLR数据集，支持多种手语理解任务，包括独立手语者和未见句子的CSLR，以及基于词汇和无词汇的SLT。

Conclusion: Isharah为真实场景下的手语理解提供了丰富资源，推动了CSLR和SLT系统的发展。

Abstract: Current benchmarks for sign language recognition (SLR) focus mainly on
isolated SLR, while there are limited datasets for continuous SLR (CSLR), which
recognizes sequences of signs in a video. Additionally, existing CSLR datasets
are collected in controlled settings, which restricts their effectiveness in
building robust real-world CSLR systems. To address these limitations, we
present Isharah, a large multi-scene dataset for CSLR. It is the first dataset
of its type and size that has been collected in an unconstrained environment
using signers' smartphone cameras. This setup resulted in high variations of
recording settings, camera distances, angles, and resolutions. This variation
helps with developing sign language understanding models capable of handling
the variability and complexity of real-world scenarios. The dataset consists of
30,000 video clips performed by 18 deaf and professional signers. Additionally,
the dataset is linguistically rich as it provides a gloss-level annotation for
all dataset's videos, making it useful for developing CSLR and sign language
translation (SLT) systems. This paper also introduces multiple sign language
understanding benchmarks, including signer-independent and unseen-sentence
CSLR, along with gloss-based and gloss-free SLT. The Isharah dataset is
available on https://snalyami.github.io/Isharah_CSLR/.

</details>


### [393] [Negative-Guided Subject Fidelity Optimization for Zero-Shot Subject-Driven Generation](https://arxiv.org/abs/2506.03621)
*Chaehun Shin,Jooyoung Choi,Johan Barthelemy,Jungbeom Lee,Sungroh Yoon*

Main category: cs.CV

TL;DR: SFO是一种新的比较学习框架，通过引入合成负样本和成对比较，提升零样本主题驱动生成的主题保真度。


<details>
  <summary>Details</summary>
Motivation: 现有监督微调方法仅依赖正样本，且使用预训练阶段的扩散损失，限制了主题保真度的提升。

Method: 提出Condition-Degradation Negative Sampling (CDNS)自动生成负样本，并通过重新加权扩散时间步长，优化中间步骤的微调。

Result: 实验表明，SFO在主题保真度和文本对齐方面显著优于基线方法。

Conclusion: SFO通过比较学习和CDNS，有效提升了主题驱动生成的性能。

Abstract: We present Subject Fidelity Optimization (SFO), a novel comparative learning
framework for zero-shot subject-driven generation that enhances subject
fidelity. Beyond supervised fine-tuning methods that rely only on positive
targets and use the diffusion loss as in the pre-training stage, SFO introduces
synthetic negative targets and explicitly guides the model to favor positives
over negatives through pairwise comparison. For negative targets, we propose
Condition-Degradation Negative Sampling (CDNS), which automatically generates
distinctive and informative negatives by intentionally degrading visual and
textual cues without expensive human annotations. Moreover, we reweight the
diffusion timesteps to focus finetuning on intermediate steps where subject
details emerge. Extensive experiments demonstrate that SFO with CDNS
significantly outperforms baselines in terms of both subject fidelity and text
alignment on a subject-driven generation benchmark. Project page:
https://subjectfidelityoptimization.github.io/

</details>


### [394] [FingerVeinSyn-5M: A Million-Scale Dataset and Benchmark for Finger Vein Recognition](https://arxiv.org/abs/2506.03635)
*Yinfan Wang,Jie Gui,Baosheng Yu,Qi Li,Zhenan Sun,Juho Kannala,Guoying Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种合成手指静脉图像生成器FVeinSyn，并创建了大规模数据集FingerVeinSyn-5M，显著提升了深度学习模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有手指静脉识别数据集规模小，限制了深度学习方法的进展，需要更大规模的数据集。

Method: 使用FVeinSyn生成器合成多样化的手指静脉图像，构建了包含500万样本的FingerVeinSyn-5M数据集。

Result: 在多个基准测试中，预训练模型性能平均提升53.91%。

Conclusion: FingerVeinSyn-5M为手指静脉识别领域提供了首个大规模、全注释数据集，显著推动了该领域的研究。

Abstract: A major challenge in finger vein recognition is the lack of large-scale
public datasets. Existing datasets contain few identities and limited samples
per finger, restricting the advancement of deep learning-based methods. To
address this, we introduce FVeinSyn, a synthetic generator capable of producing
diverse finger vein patterns with rich intra-class variations. Using FVeinSyn,
we created FingerVeinSyn-5M -- the largest available finger vein dataset --
containing 5 million samples from 50,000 unique fingers, each with 100
variations including shift, rotation, scale, roll, varying exposure levels,
skin scattering blur, optical blur, and motion blur. FingerVeinSyn-5M is also
the first to offer fully annotated finger vein images, supporting deep learning
applications in this field. Models pretrained on FingerVeinSyn-5M and
fine-tuned with minimal real data achieve an average 53.91\% performance gain
across multiple benchmarks. The dataset is publicly available at:
https://github.com/EvanWang98/FingerVeinSyn-5M.

</details>


### [395] [Spatial Understanding from Videos: Structured Prompts Meet Simulation Data](https://arxiv.org/abs/2506.03642)
*Haoyu Zhang,Meng Liu,Zaijing Li,Haokun Wen,Weili Guan,Yaowei Wang,Liqiang Nie*

Main category: cs.CV

TL;DR: 论文提出了一种增强预训练视觉语言模型（VLMs）3D空间推理能力的统一框架，结合结构化提示策略和自动化构建的数据集。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D空间推理中存在空间不确定性和数据稀缺问题，限制了预训练VLMs的能力。

Method: 提出SpatialMind（结构化提示策略）和ScanForgeQA（自动化构建的问答数据集），无需修改模型架构。

Result: 在多个基准测试中验证了提示和微调策略的有效性。

Conclusion: 该框架为视觉空间理解的未来研究提供了启发。

Abstract: Visual-spatial understanding, the ability to infer object relationships and
layouts from visual input, is fundamental to downstream tasks such as robotic
navigation and embodied interaction. However, existing methods face spatial
uncertainty and data scarcity, limiting the 3D spatial reasoning capability of
pre-trained vision-language models (VLMs). To address these challenges, we
present a unified framework for enhancing 3D spatial reasoning in pre-trained
VLMs without modifying their architecture. This framework combines SpatialMind,
a structured prompting strategy that decomposes complex scenes and questions
into interpretable reasoning steps, with ScanForgeQA, a scalable
question-answering dataset built from diverse 3D simulation scenes through an
automated construction process designed for fine-tuning. Extensive experiments
across multiple benchmarks demonstrate the individual and combined
effectiveness of our prompting and fine-tuning strategies, and yield insights
that may inspire future research on visual-spatial understanding.

</details>


### [396] [Images are Worth Variable Length of Representations](https://arxiv.org/abs/2506.03643)
*Lingjun Mao,Rodolfo Corona,Xin Liang,Wenhao Yan,Zineng Tang*

Main category: cs.CV

TL;DR: DOVE是一种动态视觉编码器，根据图像信息量动态生成可变数量的视觉标记，显著减少平均标记数并保持高质量重建。


<details>
  <summary>Details</summary>
Motivation: 现有视觉编码器将图像映射为固定长度的标记序列，忽略了不同图像信息量的差异，导致效率低下。

Method: 提出DOVE动态视觉编码器，通过生成可变数量的视觉标记来重建图像，并扩展为查询条件化标记化。

Result: DOVE在保持高重建质量的同时显著减少标记数量，在线性探测和多模态任务中优于现有方法。

Conclusion: DOVE通过动态标记化和查询条件化，实现了更高效和有针对性的语义提取。

Abstract: Most existing vision encoders map images into a fixed-length sequence of
tokens, overlooking the fact that different images contain varying amounts of
information. For example, a visually complex image (e.g., a cluttered room)
inherently carries more information and thus deserves more tokens than a simple
image (e.g., a blank wall). To address this inefficiency, we propose DOVE, a
dynamic vision encoder that produces a variable number of visual tokens (i.e.,
continuous representation vectors) to reconstruct each image. Our results show
that DOVE significantly reduces the average number of tokens while maintaining
high reconstruction quality. In several linear probing and downstream
multimodal tasks, it outperforms existing autoencoder-based tokenization
methods when using far fewer tokens, capturing more expressive semantic
features compared to fixed-length encoding. We further extend DOVE with
query-conditioned tokenization. By guiding the model to focus on query-relevant
regions, it achieves more efficient and targeted semantic extraction. Our code
and checkpoints are available at https://dove-encoder.github.io/dove-encoder.

</details>


### [397] [YOND: Practical Blind Raw Image Denoising Free from Camera-Specific Data Dependency](https://arxiv.org/abs/2506.03645)
*Hansen Feng,Lizhi Wang,Yiqi Huang,Tong Li,Lin Zhu,Hua Huang*

Main category: cs.CV

TL;DR: YOND是一种新型盲原始图像去噪方法，通过合成数据训练，能泛化到未知相机数据，包含三个关键模块：CNE、EM-VST和SNR-Net。


<details>
  <summary>Details</summary>
Motivation: 现有学习型方法依赖相机特定数据，导致在未知相机数据上性能下降，YOND旨在解决这一问题。

Method: 提出三个模块：CNE用于噪声参数估计，EM-VST消除相机依赖，SNR-Net实现可控去噪。

Result: 在未知相机数据上表现优异，具有灵活性和实用性。

Conclusion: YOND通过合成数据训练，实现了对未知相机数据的鲁棒去噪，具有广泛应用潜力。

Abstract: The rapid advancement of photography has created a growing demand for a
practical blind raw image denoising method. Recently, learning-based methods
have become mainstream due to their excellent performance. However, most
existing learning-based methods suffer from camera-specific data dependency,
resulting in performance drops when applied to data from unknown cameras. To
address this challenge, we introduce a novel blind raw image denoising method
named YOND, which represents You Only Need a Denoiser. Trained solely on
synthetic data, YOND can generalize robustly to noisy raw images captured by
diverse unknown cameras. Specifically, we propose three key modules to
guarantee the practicality of YOND: coarse-to-fine noise estimation (CNE),
expectation-matched variance-stabilizing transform (EM-VST), and SNR-guided
denoiser (SNR-Net). Firstly, we propose CNE to identify the camera noise
characteristic, refining the estimated noise parameters based on the coarse
denoised image. Secondly, we propose EM-VST to eliminate camera-specific data
dependency, correcting the bias expectation of VST according to the noisy
image. Finally, we propose SNR-Net to offer controllable raw image denoising,
supporting adaptive adjustments and manual fine-tuning. Extensive experiments
on unknown cameras, along with flexible solutions for challenging cases,
demonstrate the superior practicality of our method. The source code will be
publicly available at the
\href{https://fenghansen.github.io/publication/YOND}{project homepage}.

</details>


### [398] [EmoArt: A Multidimensional Dataset for Emotion-Aware Artistic Generation](https://arxiv.org/abs/2506.03652)
*Cheng Zhang,Hongxia xie,Bin Wen,Songhan Zuo,Ruoxuan Zhang,Wen-huang Cheng*

Main category: cs.CV

TL;DR: 论文介绍了EmoArt数据集，用于解决文本到图像生成中情感表达不足的问题，并评估了现有模型的情感对齐能力。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成模型在情感表达和抽象艺术图像生成方面存在不足，主要原因是缺乏大规模、细粒度的情感数据集。

Method: 提出了EmoArt数据集，包含132,664件艺术品，涵盖56种绘画风格，每件作品标注了场景描述、视觉属性、情感标签等。

Result: 通过EmoArt数据集，系统评估了流行文本到图像扩散模型的情感对齐能力。

Conclusion: EmoArt数据集为情感驱动的图像合成提供了重要数据和基准，推动了情感计算、多模态学习和计算艺术的发展。

Abstract: With the rapid advancement of diffusion models, text-to-image generation has
achieved significant progress in image resolution, detail fidelity, and
semantic alignment, particularly with models like Stable Diffusion 3.5, Stable
Diffusion XL, and FLUX 1. However, generating emotionally expressive and
abstract artistic images remains a major challenge, largely due to the lack of
large-scale, fine-grained emotional datasets. To address this gap, we present
the EmoArt Dataset -- one of the most comprehensive emotion-annotated art
datasets to date. It contains 132,664 artworks across 56 painting styles (e.g.,
Impressionism, Expressionism, Abstract Art), offering rich stylistic and
cultural diversity. Each image includes structured annotations: objective scene
descriptions, five key visual attributes (brushwork, composition, color, line,
light), binary arousal-valence labels, twelve emotion categories, and potential
art therapy effects. Using EmoArt, we systematically evaluate popular
text-to-image diffusion models for their ability to generate emotionally
aligned images from text. Our work provides essential data and benchmarks for
emotion-driven image synthesis and aims to advance fields such as affective
computing, multimodal learning, and computational art, enabling applications in
art therapy and creative design. The dataset and more details can be accessed
via our project website.

</details>


### [399] [MambaNeXt-YOLO: A Hybrid State Space Model for Real-time Object Detection](https://arxiv.org/abs/2506.03654)
*Xiaochun Lei,Siqi Wu,Weilin Wu,Zetao Jiang*

Main category: cs.CV

TL;DR: MambaNeXt-YOLO是一种新型实时目标检测框架，结合CNN与Mamba模型，平衡准确性与效率，适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 实时目标检测在计算资源有限的情况下具有挑战性，Transformer架构虽能建模全局上下文但计算复杂度高，需要更高效的替代方案。

Method: 提出MambaNeXt-YOLO框架，包括混合设计的MambaNeXt Block、多分支非对称融合金字塔网络（MAFPN），并优化边缘部署效率。

Result: 在PASCAL VOC数据集上达到66.6% mAP和31.9 FPS，无需预训练，支持NVIDIA Jetson Xavier NX等边缘设备。

Conclusion: MambaNeXt-YOLO通过结合CNN与Mamba模型，有效平衡了目标检测的准确性与效率，适用于实时和边缘计算场景。

Abstract: Real-time object detection is a fundamental but challenging task in computer
vision, particularly when computational resources are limited. Although
YOLO-series models have set strong benchmarks by balancing speed and accuracy,
the increasing need for richer global context modeling has led to the use of
Transformer-based architectures. Nevertheless, Transformers have high
computational complexity because of their self-attention mechanism, which
limits their practicality for real-time and edge deployments. To overcome these
challenges, recent developments in linear state space models, such as Mamba,
provide a promising alternative by enabling efficient sequence modeling with
linear complexity. Building on this insight, we propose MambaNeXt-YOLO, a novel
object detection framework that balances accuracy and efficiency through three
key contributions: (1) MambaNeXt Block: a hybrid design that integrates CNNs
with Mamba to effectively capture both local features and long-range
dependencies; (2) Multi-branch Asymmetric Fusion Pyramid Network (MAFPN): an
enhanced feature pyramid architecture that improves multi-scale object
detection across various object sizes; and (3) Edge-focused Efficiency: our
method achieved 66.6\% mAP at 31.9 FPS on the PASCAL VOC dataset without any
pre-training and supports deployment on edge devices such as the NVIDIA Jetson
Xavier NX and Orin NX.

</details>


### [400] [INP-Former++: Advancing Universal Anomaly Detection via Intrinsic Normal Prototypes and Residual Learning](https://arxiv.org/abs/2506.03660)
*Wei Luo,Haiming Yao,Yunkang Cao,Qiyu Chen,Ang Gao,Weiming Shen,Weihang Zhang,Wenyong Yu*

Main category: cs.CV

TL;DR: INP-Former是一种新颖的异常检测方法，通过从测试图像中提取内在正常原型（INPs），避免了传统方法依赖外部正常参考的限制，显著提升了检测精度。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法依赖训练集中的正常参考图像，但由于外观和位置变化，这些参考与测试图像的对齐困难，限制了检测精度。作者观察到异常通常表现为局部变化，测试图像中仍包含有价值的正常信息，因此提出直接从测试图像中提取INPs。

Method: 提出INP-Former，包括INP提取器（线性组合正常令牌表示INPs）、INP一致性损失（确保INPs能忠实表示测试图像中的正常信息）、INP引导的解码器（重构正常令牌，重建误差作为异常分数）以及软挖掘损失（优先优化难样本）。

Result: INP-Former在单类、多类和少样本异常检测任务中达到最先进性能，并在MVTec-AD、VisA和Real-IAD数据集上验证了其通用性。此外，INP-Former++通过引入残差学习和软INP一致性损失进一步提升了性能。

Conclusion: INP-Former通过直接从测试图像中提取正常信息，提供了一种通用且高效的异常检测解决方案，并在多种设置下显著优于现有方法。

Abstract: Anomaly detection (AD) is essential for industrial inspection and medical
diagnosis, yet existing methods typically rely on ``comparing'' test images to
normal references from a training set. However, variations in appearance and
positioning often complicate the alignment of these references with the test
image, limiting detection accuracy. We observe that most anomalies manifest as
local variations, meaning that even within anomalous images, valuable normal
information remains. We argue that this information is useful and may be more
aligned with the anomalies since both the anomalies and the normal information
originate from the same image. Therefore, rather than relying on external
normality from the training set, we propose INP-Former, a novel method that
extracts Intrinsic Normal Prototypes (INPs) directly from the test image.
Specifically, we introduce the INP Extractor, which linearly combines normal
tokens to represent INPs. We further propose an INP Coherence Loss to ensure
INPs can faithfully represent normality for the testing image. These INPs then
guide the INP-guided Decoder to reconstruct only normal tokens, with
reconstruction errors serving as anomaly scores. Additionally, we propose a
Soft Mining Loss to prioritize hard-to-optimize samples during training.
INP-Former achieves state-of-the-art performance in single-class, multi-class,
and few-shot AD tasks across MVTec-AD, VisA, and Real-IAD, positioning it as a
versatile and universal solution for AD. Remarkably, INP-Former also
demonstrates some zero-shot AD capability. Furthermore, we propose a soft
version of the INP Coherence Loss and enhance INP-Former by incorporating
residual learning, leading to the development of INP-Former++. The proposed
method significantly improves detection performance across single-class,
multi-class, semi-supervised, few-shot, and zero-shot settings.

</details>


### [401] [Zero-Shot Temporal Interaction Localization for Egocentric Videos](https://arxiv.org/abs/2506.03662)
*Erhang Zhang,Junyi Ma,Yin-Dong Zheng,Yixuan Zhou,Hesheng Wang*

Main category: cs.CV

TL;DR: EgoLoc是一种新型的零样本时序交互定位方法，用于在自我中心视频中定位人-物交互的抓取动作时间。通过自适应采样策略和视觉-动态反馈，显著提升了定位精度和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖标注数据导致领域偏差和低效部署，且零样本方法因粗粒度估计和开环流程性能受限。

Method: 引入自适应采样策略生成视觉提示，结合2D和3D观测，通过3D手部速度采样高质量初始猜测，并利用闭环反馈优化结果。

Result: 在公开数据集和新基准测试中，EgoLoc优于现有基线方法。

Conclusion: EgoLoc为自我中心视频的时序交互定位提供了高效准确的解决方案，代码和数据将开源。

Abstract: Locating human-object interaction (HOI) actions within video serves as the
foundation for multiple downstream tasks, such as human behavior analysis and
human-robot skill transfer. Current temporal action localization methods
typically rely on annotated action and object categories of interactions for
optimization, which leads to domain bias and low deployment efficiency.
Although some recent works have achieved zero-shot temporal action localization
(ZS-TAL) with large vision-language models (VLMs), their coarse-grained
estimations and open-loop pipelines hinder further performance improvements for
temporal interaction localization (TIL). To address these issues, we propose a
novel zero-shot TIL approach dubbed EgoLoc to locate the timings of grasp
actions for human-object interaction in egocentric videos. EgoLoc introduces a
self-adaptive sampling strategy to generate reasonable visual prompts for VLM
reasoning. By absorbing both 2D and 3D observations, it directly samples
high-quality initial guesses around the possible contact/separation timestamps
of HOI according to 3D hand velocities, leading to high inference accuracy and
efficiency. In addition, EgoLoc generates closed-loop feedback from visual and
dynamic cues to further refine the localization results. Comprehensive
experiments on the publicly available dataset and our newly proposed benchmark
demonstrate that EgoLoc achieves better temporal interaction localization for
egocentric videos compared to state-of-the-art baselines. We will release our
code and relevant data as open-source at https://github.com/IRMVLab/EgoLoc.

</details>


### [402] [Intersectional Bias in Pre-Trained Image Recognition Models](https://arxiv.org/abs/2506.03664)
*Valerie Krug,Sebastian Stober*

Main category: cs.CV

TL;DR: 研究探讨了ImageNet分类器在面部图像中对年龄、种族和性别等敏感变量的偏见表现，发现模型能显著区分年龄，对种族和性别的区分较弱。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型常基于预训练模型加速训练，但可能延续编码的偏见，因此研究ImageNet分类器在面部图像中的偏见表现。

Method: 使用线性分类器探针和地形图可视化激活，分析ImageNet分类器对年龄、种族和性别的区分能力。

Result: 模型能显著区分年龄，对种族和性别的区分较弱，尤其是在中年群体中。

Conclusion: ImageNet分类器在面部图像中存在偏见，需进一步研究以减少偏见影响。

Abstract: Deep Learning models have achieved remarkable success. Training them is often
accelerated by building on top of pre-trained models which poses the risk of
perpetuating encoded biases. Here, we investigate biases in the representations
of commonly used ImageNet classifiers for facial images while considering
intersections of sensitive variables age, race and gender. To assess the
biases, we use linear classifier probes and visualize activations as
topographic maps. We find that representations in ImageNet classifiers
particularly allow differentiation between ages. Less strongly pronounced, the
models appear to associate certain ethnicities and distinguish genders in
middle-aged groups.

</details>


### [403] [Accelerating SfM-based Pose Estimation with Dominating Set](https://arxiv.org/abs/2506.03667)
*Joji Joseph,Bharadwaj Amrutur,Shalabh Bhatnagar*

Main category: cs.CV

TL;DR: 提出了一种基于图论支配集的预处理技术，显著提升了SfM位姿估计的速度，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 为了满足增强现实（AR）、虚拟现实（VR）和机器人等实时应用中对快速位姿估计的需求。

Method: 利用图论中的支配集概念预处理SfM模型，优化位姿估计过程。

Result: 处理速度提升1.5至14.48倍，参考图像和点云大小分别减少17-23倍和2.27-4倍。

Conclusion: 该方法为实时3D位姿估计提供了高效且准确的解决方案。

Abstract: This paper introduces a preprocessing technique to speed up
Structure-from-Motion (SfM) based pose estimation, which is critical for
real-time applications like augmented reality (AR), virtual reality (VR), and
robotics. Our method leverages the concept of a dominating set from graph
theory to preprocess SfM models, significantly enhancing the speed of the pose
estimation process without losing significant accuracy. Using the OnePose
dataset, we evaluated our method across various SfM-based pose estimation
techniques. The results demonstrate substantial improvements in processing
speed, ranging from 1.5 to 14.48 times, and a reduction in reference images and
point cloud size by factors of 17-23 and 2.27-4, respectively. This work offers
a promising solution for efficient and accurate 3D pose estimation, balancing
speed and accuracy in real-time applications.

</details>


### [404] [BiXFormer: A Robust Framework for Maximizing Modality Effectiveness in Multi-Modal Semantic Segmentation](https://arxiv.org/abs/2506.03675)
*Jialei Chen,Xu Zheng,Danda Pani Paudel,Luc Van Gool,Hiroshi Murase,Daisuke Deguchi*

Main category: cs.CV

TL;DR: 论文提出BiXFormer，通过统一模态匹配（UMM）和跨模态对齐（CMA）优化多模态语义分割，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态融合中限制了各模态的优势发挥，且对非RGB模态关注不足。

Method: BiXFormer将多模态输入分为RGB和非RGB模态，分别处理；提出UMM（包括MAM和CM）和CMA，最大化模态效果并处理缺失模态。

Result: 实验显示，mIoU提升+2.75%和+22.74%。

Conclusion: BiXFormer有效提升多模态语义分割性能，尤其擅长处理缺失模态。

Abstract: Utilizing multi-modal data enhances scene understanding by providing
complementary semantic and geometric information. Existing methods fuse
features or distill knowledge from multiple modalities into a unified
representation, improving robustness but restricting each modality's ability to
fully leverage its strengths in different situations. We reformulate
multi-modal semantic segmentation as a mask-level classification task and
propose BiXFormer, which integrates Unified Modality Matching (UMM) and Cross
Modality Alignment (CMA) to maximize modality effectiveness and handle missing
modalities. Specifically, BiXFormer first categorizes multi-modal inputs into
RGB and X, where X represents any non-RGB modalities, e.g., depth, allowing
separate processing for each. This design leverages the well-established
pretraining for RGB, while addressing the relative lack of attention to X
modalities. Then, we propose UMM, which includes Modality Agnostic Matching
(MAM) and Complementary Matching (CM). MAM assigns labels to features from all
modalities without considering modality differences, leveraging each modality's
strengths. CM then reassigns unmatched labels to remaining unassigned features
within their respective modalities, ensuring that each available modality
contributes to the final prediction and mitigating the impact of missing
modalities. Moreover, to further facilitate UMM, we introduce CMA, which
enhances the weaker queries assigned in CM by aligning them with optimally
matched queries from MAM. Experiments on both synthetic and real-world
multi-modal benchmarks demonstrate the effectiveness of our method, achieving
significant improvements in mIoU of +2.75% and +22.74% over the prior arts.

</details>


### [405] [How PARTs assemble into wholes: Learning the relative composition of images](https://arxiv.org/abs/2506.03682)
*Melika Ayoughi,Samira Abnar,Chen Huang,Chris Sandino,Sayeri Lala,Eeshan Gunesh Dhekane,Dan Busbridge,Shuangfei Zhai,Vimal Thilak,Josh Susskind,Pascal Mettes,Paul Groth,Hanlin Goh*

Main category: cs.CV

TL;DR: PART是一种自监督学习方法，通过连续相对变换学习图像部分的相对组合，克服了网格方法的局限性，在空间理解任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有网格方法无法捕捉真实世界物体组合的连续性和流动性，限制了自监督学习的表现。

Method: PART利用非网格补丁之间的连续相对变换，建模图像部分的相对关系，实现更灵活的结构学习。

Result: 在对象检测和时间序列预测等任务中，PART优于网格方法（如MAE和DropPos），并在全局分类任务中保持竞争力。

Conclusion: PART突破了网格限制，为跨多样数据类型的通用自监督预训练开辟了新方向，具有广泛的应用潜力。

Abstract: The composition of objects and their parts, along with object-object
positional relationships, provides a rich source of information for
representation learning. Hence, spatial-aware pretext tasks have been actively
explored in self-supervised learning. Existing works commonly start from a grid
structure, where the goal of the pretext task involves predicting the absolute
position index of patches within a fixed grid. However, grid-based approaches
fall short of capturing the fluid and continuous nature of real-world object
compositions. We introduce PART, a self-supervised learning approach that
leverages continuous relative transformations between off-grid patches to
overcome these limitations. By modeling how parts relate to each other in a
continuous space, PART learns the relative composition of images-an off-grid
structural relative positioning process that generalizes beyond occlusions and
deformations. In tasks requiring precise spatial understanding such as object
detection and time series prediction, PART outperforms strong grid-based
methods like MAE and DropPos, while also maintaining competitive performance on
global classification tasks with minimal hyperparameter tuning. By breaking
free from grid constraints, PART opens up an exciting new trajectory for
universal self-supervised pretraining across diverse datatypes-from natural
images to EEG signals-with promising potential in video, medical imaging, and
audio.

</details>


### [406] [PRJ: Perception-Retrieval-Judgement for Generated Images](https://arxiv.org/abs/2506.03683)
*Qiang Fu,Zonglei Jing,Zonghao Ying,Xiaoqian Li*

Main category: cs.CV

TL;DR: 论文提出了一种名为PRJ的三阶段框架，用于检测AI生成视觉内容中的有害内容，解决了现有系统在上下文理解和动态毒性评估上的不足。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的快速发展带来了视觉内容安全性的问题，现有系统缺乏上下文理解和动态毒性评估能力，亟需改进。

Method: PRJ框架分为三个阶段：感知（将图像转化为语言描述）、检索（获取相关知识）和判断（基于规则评估毒性），并引入了动态评分机制。

Result: 实验表明，PRJ在检测准确性和鲁棒性上优于现有安全检测系统，并能支持结构化类别级毒性解释。

Conclusion: PRJ框架通过语言中心的结构和动态评分机制，显著提升了有害内容检测的能力和可解释性。

Abstract: The rapid progress of generative AI has enabled remarkable creative
capabilities, yet it also raises urgent concerns regarding the safety of
AI-generated visual content in real-world applications such as content
moderation, platform governance, and digital media regulation. This includes
unsafe material such as sexually explicit images, violent scenes, hate symbols,
propaganda, and unauthorized imitations of copyrighted artworks. Existing image
safety systems often rely on rigid category filters and produce binary outputs,
lacking the capacity to interpret context or reason about nuanced,
adversarially induced forms of harm. In addition, standard evaluation metrics
(e.g., attack success rate) fail to capture the semantic severity and dynamic
progression of toxicity. To address these limitations, we propose
Perception-Retrieval-Judgement (PRJ), a cognitively inspired framework that
models toxicity detection as a structured reasoning process. PRJ follows a
three-stage design: it first transforms an image into descriptive language
(perception), then retrieves external knowledge related to harm categories and
traits (retrieval), and finally evaluates toxicity based on legal or normative
rules (judgement). This language-centric structure enables the system to detect
both explicit and implicit harms with improved interpretability and categorical
granularity. In addition, we introduce a dynamic scoring mechanism based on a
contextual toxicity risk matrix to quantify harmfulness across different
semantic dimensions. Experiments show that PRJ surpasses existing safety
checkers in detection accuracy and robustness while uniquely supporting
structured category-level toxicity interpretation.

</details>


### [407] [DSSAU-Net:U-Shaped Hybrid Network for Pubic Symphysis and Fetal Head Segmentation](https://arxiv.org/abs/2506.03684)
*Zunhui Xia,Hongxing Li,Libin Lan*

Main category: cs.CV

TL;DR: 提出了一种名为DSSAU-Net的稀疏自注意力网络架构，用于胎儿头部和耻骨联合的精确分割，以提高分娩过程中超声辅助诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统分娩过程中的侵入性阴道检查方法主观且不准确，超声辅助诊断通过胎儿头部和耻骨联合的分割提供客观评估，但需要高效且精确的分割方法。

Method: 设计了DSSAU-Net网络，采用双稀疏选择注意力块（DSSA）构建对称U形编码器-解码器架构，结合多尺度特征融合和跳跃连接以减少计算复杂度并提升特征提取能力。

Result: 在MICCAI IUGC 2024竞赛的测试集上验证了DSSAU-Net的性能，获得了分类和分割任务的第四名，证明了其有效性。

Conclusion: DSSAU-Net在胎儿头部和耻骨联合分割任务中表现出色，为超声辅助分娩诊断提供了高效且精确的解决方案。

Abstract: In the childbirth process, traditional methods involve invasive vaginal
examinations, but research has shown that these methods are both subjective and
inaccurate. Ultrasound-assisted diagnosis offers an objective yet effective way
to assess fetal head position via two key parameters: Angle of Progression
(AoP) and Head-Symphysis Distance (HSD), calculated by segmenting the fetal
head (FH) and pubic symphysis (PS), which aids clinicians in ensuring a smooth
delivery process. Therefore, accurate segmentation of FH and PS is crucial. In
this work, we propose a sparse self-attention network architecture with good
performance and high computational efficiency, named DSSAU-Net, for the
segmentation of FH and PS. Specifically, we stack varying numbers of Dual
Sparse Selection Attention (DSSA) blocks at each stage to form a symmetric
U-shaped encoder-decoder network architecture. For a given query, DSSA is
designed to explicitly perform one sparse token selection at both the region
and pixel levels, respectively, which is beneficial for further reducing
computational complexity while extracting the most relevant features. To
compensate for the information loss during the upsampling process, skip
connections with convolutions are designed. Additionally, multiscale feature
fusion is employed to enrich the model's global and local information. The
performance of DSSAU-Net has been validated using the Intrapartum Ultrasound
Grand Challenge (IUGC) 2024 \textit{test set} provided by the organizer in the
MICCAI IUGC 2024
competition\footnote{\href{https://codalab.lisn.upsaclay.fr/competitions/18413\#learn\_the\_details}{https://codalab.lisn.upsaclay.fr/competitions/18413\#learn\_the\_details}},
where we win the fourth place on the tasks of classification and segmentation,
demonstrating its effectiveness. The codes will be available at
https://github.com/XiaZunhui/DSSAU-Net.

</details>


### [408] [Advancements in Artificial Intelligence Applications for Cardiovascular Disease Research](https://arxiv.org/abs/2506.03698)
*Yuanlin Mo,Haishan Huang,Bocheng Liang,Weibo Ma*

Main category: cs.CV

TL;DR: AI在心血管医学中的应用通过深度学习提升了诊断效率和准确性，但仍需解决数据验证问题。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在心血管医学中的潜力及其面临的挑战。

Method: 采用深度学习架构（如卷积神经网络和生成对抗网络）分析医学影像和生理信号。

Result: AI在诊断准确性和效率上超越人类，但输入数据验证问题仍需解决。

Conclusion: 未来需开发混合模型和自适应算法，以提升个性化心血管护理的可靠性。

Abstract: Recent advancements in artificial intelligence (AI) have revolutionized
cardiovascular medicine, particularly through integration with computed
tomography (CT), magnetic resonance imaging (MRI), electrocardiography (ECG)
and ultrasound (US). Deep learning architectures, including convolutional
neural networks and generative adversarial networks, enable automated analysis
of medical imaging and physiological signals, surpassing human capabilities in
diagnostic accuracy and workflow efficiency. However, critical challenges
persist, including the inability to validate input data accuracy, which may
propagate diagnostic errors. This review highlights AI's transformative
potential in precision diagnostics while underscoring the need for robust
validation protocols to ensure clinical reliability. Future directions
emphasize hybrid models integrating multimodal data and adaptive algorithms to
refine personalized cardiovascular care.

</details>


### [409] [OV-COAST: Cost Aggregation with Optimal Transport for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2506.03706)
*Aditya Gandhamal,Aniruddh Sikdar,Suresh Sundaram*

Main category: cs.CV

TL;DR: OV-COAST提出了一种基于最优传输理论的开集语义分割方法，通过两阶段优化策略显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 提升开集语义分割的跨域泛化能力。

Method: 使用成本体积构建成本矩阵，通过Sinkhorn距离求解最优传输问题，并指导CAT-Seg模型训练。

Result: 在MESS基准测试中，OV-COAST显著优于CAT-Seg和SAN-B，分别提升1.72%和4.9% mIoU。

Conclusion: OV-COAST通过最优传输理论有效提升了开集语义分割的性能。

Abstract: Open-vocabulary semantic segmentation (OVSS) entails assigning semantic
labels to each pixel in an image using textual descriptions, typically
leveraging world models such as CLIP. To enhance out-of-domain generalization,
we propose Cost Aggregation with Optimal Transport (OV-COAST) for
open-vocabulary semantic segmentation. To align visual-language features within
the framework of optimal transport theory, we employ cost volume to construct a
cost matrix, which quantifies the distance between two distributions. Our
approach adopts a two-stage optimization strategy: in the first stage, the
optimal transport problem is solved using cost volume via Sinkhorn distance to
obtain an alignment solution; in the second stage, this solution is used to
guide the training of the CAT-Seg model. We evaluate state-of-the-art OVSS
models on the MESS benchmark, where our approach notably improves the
performance of the cost-aggregation model CAT-Seg with ViT-B backbone,
achieving superior results, surpassing CAT-Seg by 1.72 % and SAN-B by 4.9 %
mIoU. The code is available at
https://github.com/adityagandhamal/OV-COAST/}{https://github.com/adityagandhamal/OV-COAST/ .

</details>


### [410] [AetherVision-Bench: An Open-Vocabulary RGB-Infrared Benchmark for Multi-Angle Segmentation across Aerial and Ground Perspectives](https://arxiv.org/abs/2506.03709)
*Aniruddh Sikdar,Aditya Gandhamal,Suresh Sundaram*

Main category: cs.CV

TL;DR: 本文提出了AetherVision-Bench，一个用于多角度分割的基准测试，旨在评估开放词汇语义分割（OVSS）模型在不同视角和传感器模态下的性能。


<details>
  <summary>Details</summary>
Motivation: 开放词汇语义分割（OVSS）在跨领域泛化方面面临挑战，限制了其在实际应用中的效果。本文旨在通过多角度分割基准测试，提升OVSS模型的性能评估和零样本迁移能力。

Method: 提出了AetherVision-Bench基准测试，用于评估OVSS模型在多角度（空中和地面视角）和不同传感器模态下的性能。

Result: 评估了现有OVSS模型在基准测试上的表现，并分析了影响零样本迁移模型性能的关键因素。

Conclusion: 本文为OVSS模型的鲁棒性评估提供了新基准，为未来研究奠定了基础。

Abstract: Open-vocabulary semantic segmentation (OVSS) involves assigning labels to
each pixel in an image based on textual descriptions, leveraging world models
like CLIP. However, they encounter significant challenges in cross-domain
generalization, hindering their practical efficacy in real-world applications.
Embodied AI systems are transforming autonomous navigation for ground vehicles
and drones by enhancing their perception abilities, and in this study, we
present AetherVision-Bench, a benchmark for multi-angle segmentation across
aerial, and ground perspectives, which facilitates an extensive evaluation of
performance across different viewing angles and sensor modalities. We assess
state-of-the-art OVSS models on the proposed benchmark and investigate the key
factors that impact the performance of zero-shot transfer models. Our work
pioneers the creation of a robustness benchmark, offering valuable insights and
establishing a foundation for future research.

</details>


### [411] [OSGNet @ Ego4D Episodic Memory Challenge 2025](https://arxiv.org/abs/2506.03710)
*Yisen Feng,Haoyu Zhang,Qiaohui Chu,Meng Liu,Weili Guan,Yaowei Wang,Liqiang Nie*

Main category: cs.CV

TL;DR: 本文介绍了在CVPR 2025 Ego4D挑战赛中三个视频定位任务的冠军解决方案，通过早期融合模型提升定位精度。


<details>
  <summary>Details</summary>
Motivation: 解决传统后期融合策略在视频定位任务中的性能不足问题。

Method: 采用早期融合的视频定位模型处理三个任务。

Result: 在Natural Language Queries、Goal Step和Moment Queries三个赛道中均获得第一名。

Conclusion: 早期融合模型显著提升了视频定位的准确性。

Abstract: In this report, we present our champion solutions for the three egocentric
video localization tracks of the Ego4D Episodic Memory Challenge at CVPR 2025.
All tracks require precise localization of the interval within an untrimmed
egocentric video. Previous unified video localization approaches often rely on
late fusion strategies, which tend to yield suboptimal results. To address
this, we adopt an early fusion-based video localization model to tackle all
three tasks, aiming to enhance localization accuracy. Ultimately, our method
achieved first place in the Natural Language Queries, Goal Step, and Moment
Queries tracks, demonstrating its effectiveness. Our code can be found at
https://github.com/Yisen-Feng/OSGNet.

</details>


### [412] [PlückeRF: A Line-based 3D Representation for Few-view Reconstruction](https://arxiv.org/abs/2506.03713)
*Sam Bahrami,Dylan Campbell*

Main category: cs.CV

TL;DR: 本文提出了一种基于多视图信息的3D重建模型，通过改进信息共享机制，提升了重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有的单视图和少视图3D重建方法在利用多视图信息方面仍有改进空间。

Method: 提出了一种基于PlückerRF表示的3D重建模型，通过结构化特征增强的线条连接3D表示与输入视图的像素光线。

Result: 实验表明，该方法在重建质量上优于现有的三平面表示和前沿的feedforward重建方法。

Conclusion: 通过更有效地利用多视图信息，该方法显著提升了3D重建的效果。

Abstract: Feed-forward 3D reconstruction methods aim to predict the 3D structure of a
scene directly from input images, providing a faster alternative to per-scene
optimization approaches. Significant progress has been made in single-view and
few-view reconstruction using learned priors that infer object shape and
appearance, even for unobserved regions. However, there is substantial
potential to enhance these methods by better leveraging information from
multiple views when available. To address this, we propose a few-view
reconstruction model that more effectively harnesses multi-view information.
Our approach introduces a simple mechanism that connects the 3D representation
with pixel rays from the input views, allowing for preferential sharing of
information between nearby 3D locations and between 3D locations and nearby
pixel rays. We achieve this by defining the 3D representation as a set of
structured, feature-augmented lines; the Pl\"uckeRF representation. Using this
representation, we demonstrate improvements in reconstruction quality over the
equivalent triplane representation and state-of-the-art feedforward
reconstruction methods.

</details>


### [413] [FSHNet: Fully Sparse Hybrid Network for 3D Object Detection](https://arxiv.org/abs/2506.03714)
*Shuai Liu,Mingyue Cui,Boyang Li,Quanmin Liang,Tinghe Hong,Kai Huang,Yunxiao Shan,Kai Huang*

Main category: cs.CV

TL;DR: FSHNet提出了一种全稀疏混合网络，通过SlotFormer块增强长程特征提取能力，动态稀疏标签分配策略优化网络，稀疏上采样模块保留细节，显著提升了3D检测性能。


<details>
  <summary>Details</summary>
Motivation: 稀疏3D检测器仅从非空体素提取特征，导致长程交互能力弱和中心特征缺失，限制了特征提取和网络优化。

Method: 引入SlotFormer块增强稀疏编码器的长程特征提取能力，采用动态稀疏标签分配策略优化网络，提出稀疏上采样模块保留细节。

Result: 在Waymo、nuScenes和Argoverse2基准测试中表现优异。

Conclusion: FSHNet通过改进特征提取和优化策略，显著提升了全稀疏3D检测器的性能。

Abstract: Fully sparse 3D detectors have recently gained significant attention due to
their efficiency in long-range detection. However, sparse 3D detectors extract
features only from non-empty voxels, which impairs long-range interactions and
causes the center feature missing. The former weakens the feature extraction
capability, while the latter hinders network optimization. To address these
challenges, we introduce the Fully Sparse Hybrid Network (FSHNet). FSHNet
incorporates a proposed SlotFormer block to enhance the long-range feature
extraction capability of existing sparse encoders. The SlotFormer divides
sparse voxels using a slot partition approach, which, compared to traditional
window partition, provides a larger receptive field. Additionally, we propose a
dynamic sparse label assignment strategy to deeply optimize the network by
providing more high-quality positive samples. To further enhance performance,
we introduce a sparse upsampling module to refine downsampled voxels,
preserving fine-grained details crucial for detecting small objects. Extensive
experiments on the Waymo, nuScenes, and Argoverse2 benchmarks demonstrate the
effectiveness of FSHNet. The code is available at
https://github.com/Say2L/FSHNet.

</details>


### [414] [ComRoPE: Scalable and Robust Rotary Position Embedding Parameterized by Trainable Commuting Angle Matrices](https://arxiv.org/abs/2506.03737)
*Hao Yu,Tangyu Jiang,Shuning Jia,Shannan Yan,Shunning Liu,Haolong Qian,Guanghao Li,Shuting Dong,Huaisong Zhang,Chun Yuan*

Main category: cs.CV

TL;DR: ComRoPE提出了一种可训练的旋转角度矩阵方法，改进了RoPE的位置编码能力，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统位置编码方法缺乏鲁棒性和灵活性，RoPE虽有所改进，但其手动定义的旋转矩阵限制了模型能力。

Method: 通过定义可训练的交换角度矩阵，满足RoPE方程的条件，提升位置编码的鲁棒性和扩展性。

Result: 在ImageNet-1K数据集上，训练分辨率和高分辨率下分别提升1.6%和2.9%。

Conclusion: ComRoPE不仅性能优越，还能推广到现有RoPE方法，为未来位置编码研究提供新思路。

Abstract: The Transformer architecture has revolutionized various regions since it was
proposed, and its effectiveness largely depends on the ability to encode
positional information. Traditional position encoding methods exhibit
significant limitations due to lack of robustness and flexibility of position.
Therefore, Rotary Positional Encoding (RoPE) was proposed to alleviate these
issues, which integrates positional information by rotating the embeddings in
the attention mechanism. However, RoPE requires manually defined rotation
matrices with limited transformation space, constraining the model's capacity.
In this work, we propose ComRoPE, which generalizes RoPE by defining it in
terms of trainable commuting angle matrices. Specifically, we demonstrate that
pairwise commutativity of these matrices is essential for RoPE to achieve
scalability and positional robustness. We formally define the RoPE Equation,
which is an essential condition that ensures consistent performance with
position offsets. Based on the theoretical analysis, we present two types of
trainable commuting angle matrices as sufficient solutions to the RoPE
equation, which significantly improve performance, surpassing the current
state-of-the-art method by 1.6% at training resolution and 2.9% at higher
resolution on the ImageNet-1K dataset. Furthermore, our framework shows
versatility in generalizing to existing RoPE formulations and offering new
insights for future positional encoding research. To ensure reproducibility,
the source code and instructions are available at
https://github.com/Longin-Yu/ComRoPE

</details>


### [415] [SAAT: Synergistic Alternating Aggregation Transformer for Image Super-Resolution](https://arxiv.org/abs/2506.03740)
*Jianfeng Wu,Nannan Xu*

Main category: cs.CV

TL;DR: 论文提出了一种新型模型SAAT，通过结合通道和空间注意力机制，优化了单图像超分辨率任务中的特征提取和结构信息利用。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的超分辨率方法在计算自注意力时忽略了跨通道信息和中间过程的空间结构信息，且未充分探索通道与空间注意力的协同关系。

Method: 提出了SAAT模型，包含CWSAG（高效通道与窗口协同注意力组）和SWSAG（空间与窗口协同注意力组），分别增强非局部特征融合和结构化特征提取。

Result: 实验表明SAAT在超分辨率任务中表现优异，性能与现有最优方法相当。

Conclusion: SAAT通过协同注意力机制有效提升了超分辨率任务的特征利用和结构提取能力。

Abstract: Single image super-resolution is a well-known downstream task which aims to
restore low-resolution images into high-resolution images. At present, models
based on Transformers have shone brightly in the field of super-resolution due
to their ability to capture long-term dependencies in information. However,
current methods typically compute self-attention in nonoverlapping windows to
save computational costs, and the standard self-attention computation only
focuses on its results, thereby neglecting the useful information across
channels and the rich spatial structural information generated in the
intermediate process. Channel attention and spatial attention have,
respectively, brought significant improvements to various downstream visual
tasks in terms of extracting feature dependency and spatial structure
relationships, but the synergistic relationship between channel and spatial
attention has not been fully explored yet.To address these issues, we propose a
novel model. Synergistic Alternating Aggregation Transformer (SAAT), which can
better utilize the potential information of features. In SAAT, we introduce the
Efficient Channel & Window Synergistic Attention Group (CWSAG) and the Spatial
& Window Synergistic Attention Group (SWSAG). On the one hand, CWSAG combines
efficient channel attention with shifted window attention, enhancing non-local
feature fusion, and producing more visually appealing results. On the other
hand, SWSAG leverages spatial attention to capture rich structured feature
information, thereby enabling SAAT to more effectively extract structural
features.Extensive experimental results and ablation studies demonstrate the
effectiveness of SAAT in the field of super-resolution. SAAT achieves
performance comparable to that of the state-of-the-art (SOTA) under the same
quantity of parameters.

</details>


### [416] [HUMOF: Human Motion Forecasting in Interactive Social Scenes](https://arxiv.org/abs/2506.03753)
*Caiyi Sun,Yujing Sun,Xiao Han,Zemin Yang,Jiawei Liu,Xinge Zhu,Siu Ming Yiu,Yuexin Ma*

Main category: cs.CV

TL;DR: 提出了一种用于交互场景中人体运动预测的分层特征表示方法，通过空间和频率视角的粗到细推理模块提升预测准确性。


<details>
  <summary>Details</summary>
Motivation: 复杂场景中的人体行为预测因交互信息（如人与人、人与环境）的丰富性而具有挑战性，现有方法难以应对。

Method: 设计分层交互特征表示（高层特征捕捉整体上下文，低层特征关注细节），并提出基于空间和频率视角的粗到细推理模块。

Result: 在四个公共数据集上实现了最先进的性能。

Conclusion: 该方法通过分层特征表示和推理模块有效提升了复杂场景中人体运动预测的准确性。

Abstract: Complex scenes present significant challenges for predicting human behaviour
due to the abundance of interaction information, such as human-human and
humanenvironment interactions. These factors complicate the analysis and
understanding of human behaviour, thereby increasing the uncertainty in
forecasting human motions. Existing motion prediction methods thus struggle in
these complex scenarios. In this paper, we propose an effective method for
human motion forecasting in interactive scenes. To achieve a comprehensive
representation of interactions, we design a hierarchical interaction feature
representation so that high-level features capture the overall context of the
interactions, while low-level features focus on fine-grained details. Besides,
we propose a coarse-to-fine interaction reasoning module that leverages both
spatial and frequency perspectives to efficiently utilize hierarchical
features, thereby enhancing the accuracy of motion predictions. Our method
achieves state-of-the-art performance across four public datasets. Code will be
released when this paper is published.

</details>


### [417] [CoLa: Chinese Character Decomposition with Compositional Latent Components](https://arxiv.org/abs/2506.03798)
*Fan Shi,Haiyang Yu,Bin Li,Xiangyang Xue*

Main category: cs.CV

TL;DR: 论文提出了一种名为CoLa的深度潜在变量模型，通过学习汉字的组合潜在成分，无需依赖人工定义的分解方案，实现了零样本汉字识别。


<details>
  <summary>Details</summary>
Motivation: 人类能够通过分解和重组汉字的组成成分来识别未见过的汉字，这反映了组合性和学习能力两种认知原则。现有方法多依赖人工定义的分解方案，缺乏学习能力，限制了泛化能力。

Method: 提出CoLa模型，通过学习汉字的组合潜在成分，在潜在空间中进行识别和匹配，实现零样本识别。

Result: 实验表明，CoLa在零样本汉字识别任务中优于现有方法，且学习到的成分能直观反映汉字结构。模型还展示了跨数据集的泛化能力。

Conclusion: CoLa通过结合组合性和学习能力，为汉字识别提供了更高效的泛化方法，尤其在零样本场景下表现优异。

Abstract: Humans can decompose Chinese characters into compositional components and
recombine them to recognize unseen characters. This reflects two cognitive
principles: Compositionality, the idea that complex concepts are built on
simpler parts; and Learning-to-learn, the ability to learn strategies for
decomposing and recombining components to form new concepts. These principles
provide inductive biases that support efficient generalization. They are
critical to Chinese character recognition (CCR) in solving the zero-shot
problem, which results from the common long-tail distribution of Chinese
character datasets. Existing methods have made substantial progress in modeling
compositionality via predefined radical or stroke decomposition. However, they
often ignore the learning-to-learn capability, limiting their ability to
generalize beyond human-defined schemes. Inspired by these principles, we
propose a deep latent variable model that learns Compositional Latent
components of Chinese characters (CoLa) without relying on human-defined
decomposition schemes. Recognition and matching can be performed by comparing
compositional latent components in the latent space, enabling zero-shot
character recognition. The experiments illustrate that CoLa outperforms
previous methods in both character the radical zero-shot CCR. Visualization
indicates that the learned components can reflect the structure of characters
in an interpretable way. Moreover, despite being trained on historical
documents, CoLa can analyze components of oracle bone characters, highlighting
its cross-dataset generalization ability.

</details>


### [418] [ConText: Driving In-context Learning for Text Removal and Segmentation](https://arxiv.org/abs/2506.03799)
*Fei Zhang,Pei Zhang,Baosong Yang,Fei Huang,Yanfeng Wang,Ya Zhang*

Main category: cs.CV

TL;DR: 该论文首次将视觉上下文学习（V-ICL）范式应用于光学字符识别任务，提出任务链式组合器和上下文感知聚合方法，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有V-ICL方法采用直接提示方式，限制了模型的推理能力，且视觉异质性导致演示选择困难。

Method: 提出任务链式组合器（图像-去除-分割）和上下文感知聚合，并引入自提示策略解决视觉异质性问题。

Result: ConText模型在领域内外基准测试中均达到最新最优性能。

Conclusion: 通过任务链式设计和上下文感知聚合，显著提升了视觉上下文学习在字符识别任务中的表现。

Abstract: This paper presents the first study on adapting the visual in-context
learning (V-ICL) paradigm to optical character recognition tasks, specifically
focusing on text removal and segmentation. Most existing V-ICL generalists
employ a reasoning-as-reconstruction approach: they turn to using a
straightforward image-label compositor as the prompt and query input, and then
masking the query label to generate the desired output. This direct prompt
confines the model to a challenging single-step reasoning process. To address
this, we propose a task-chaining compositor in the form of
image-removal-segmentation, providing an enhanced prompt that elicits reasoning
with enriched intermediates. Additionally, we introduce context-aware
aggregation, integrating the chained prompt pattern into the latent query
representation, thereby strengthening the model's in-context reasoning. We also
consider the issue of visual heterogeneity, which complicates the selection of
homogeneous demonstrations in text recognition. Accordingly, this is
effectively addressed through a simple self-prompting strategy, preventing the
model's in-context learnability from devolving into specialist-like,
context-free inference. Collectively, these insights culminate in our ConText
model, which achieves new state-of-the-art across both in- and out-of-domain
benchmarks. The code is available at https://github.com/Ferenas/ConText.

</details>


### [419] [Animal Pose Labeling Using General-Purpose Point Trackers](https://arxiv.org/abs/2506.03868)
*Zhuoyang Pan,Boxiao Pan,Guandao Yang,Adam W. Harley,Leonidas Guibas*

Main category: cs.CV

TL;DR: 提出了一种基于测试时优化的动物姿态标注方法，通过微调预训练模型在稀疏标注帧上，实现高效自动标注。


<details>
  <summary>Details</summary>
Motivation: 现有方法因训练数据不足难以可靠估计动物姿态，而收集全面数据集又因动物形态多样性极具挑战。

Method: 在稀疏标注帧上微调轻量级外观嵌入的预训练通用点跟踪器，用于自动标注剩余帧。

Result: 方法以合理标注成本达到最先进性能。

Conclusion: 该流程为动物行为自动量化提供了有价值的工具。

Abstract: Automatically estimating animal poses from videos is important for studying
animal behaviors. Existing methods do not perform reliably since they are
trained on datasets that are not comprehensive enough to capture all necessary
animal behaviors. However, it is very challenging to collect such datasets due
to the large variations in animal morphology. In this paper, we propose an
animal pose labeling pipeline that follows a different strategy, i.e. test time
optimization. Given a video, we fine-tune a lightweight appearance embedding
inside a pre-trained general-purpose point tracker on a sparse set of annotated
frames. These annotations can be obtained from human labelers or off-the-shelf
pose detectors. The fine-tuned model is then applied to the rest of the frames
for automatic labeling. Our method achieves state-of-the-art performance at a
reasonable annotation cost. We believe our pipeline offers a valuable tool for
the automatic quantification of animal behavior. Visit our project webpage at
https://zhuoyang-pan.github.io/animal-labeling.

</details>


### [420] [JointSplat: Probabilistic Joint Flow-Depth Optimization for Sparse-View Gaussian Splatting](https://arxiv.org/abs/2506.03872)
*Yang Xiao,Guoan Xu,Qiang Wu,Wenjing Jia*

Main category: cs.CV

TL;DR: JointSplat是一个统一框架，通过概率优化机制结合光流和深度信息，解决了稀疏视角3D重建中的定位和一致性难题。


<details>
  <summary>Details</summary>
Motivation: 稀疏视角3D重建存在低纹理区域定位不准和全局不一致性问题，需要一种结合光流和深度互补性的方法。

Method: 提出JointSplat框架，通过概率优化机制动态融合光流和深度信息，并引入多视角深度一致性损失。

Result: 在RealEstate10K和ACID数据集上，JointSplat优于现有方法，证明了其高保真稀疏视角重建的有效性。

Conclusion: JointSplat通过概率联合优化光流和深度，显著提升了稀疏视角3D重建的质量和鲁棒性。

Abstract: Reconstructing 3D scenes from sparse viewpoints is a long-standing challenge
with wide applications. Recent advances in feed-forward 3D Gaussian sparse-view
reconstruction methods provide an efficient solution for real-time novel view
synthesis by leveraging geometric priors learned from large-scale multi-view
datasets and computing 3D Gaussian centers via back-projection. Despite
offering strong geometric cues, both feed-forward multi-view depth estimation
and flow-depth joint estimation face key limitations: the former suffers from
mislocation and artifact issues in low-texture or repetitive regions, while the
latter is prone to local noise and global inconsistency due to unreliable
matches when ground-truth flow supervision is unavailable. To overcome this, we
propose JointSplat, a unified framework that leverages the complementarity
between optical flow and depth via a novel probabilistic optimization
mechanism. Specifically, this pixel-level mechanism scales the information
fusion between depth and flow based on the matching probability of optical flow
during training. Building upon the above mechanism, we further propose a novel
multi-view depth-consistency loss to leverage the reliability of supervision
while suppressing misleading gradients in uncertain areas. Evaluated on
RealEstate10K and ACID, JointSplat consistently outperforms state-of-the-art
(SOTA) methods, demonstrating the effectiveness and robustness of our proposed
probabilistic joint flow-depth optimization approach for high-fidelity
sparse-view 3D reconstruction.

</details>


### [421] [Video, How Do Your Tokens Merge?](https://arxiv.org/abs/2506.03885)
*Sam Pollard,Michael Wray*

Main category: cs.CV

TL;DR: 该论文探讨了无需重新训练的视频Transformer模型中的token合并方法，在保持精度的同时显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: 视频Transformer模型因输入数据的时空扩展而需要大量计算资源，现有方法多针对图像模型，视频领域的token合并尚未在复杂时间数据集上验证。

Method: 研究了四种视频Transformer模型在三个数据集上的训练无关token合并方法，涵盖粗粒度和细粒度动作识别。

Result: 实验显示token合并可带来约2.5倍的速度提升，同时精度损失极小（ViViT平均仅下降0.55%）。

Conclusion: 视频token合并是一种高效且通用的方法，可显著提升计算效率而无需模型重新训练。

Abstract: Video transformer models require huge amounts of compute resources due to the
spatio-temporal scaling of the input. Tackling this, recent methods have
proposed to drop or merge tokens for image models, whether randomly or via
learned methods. Merging tokens has many benefits: it can be plugged into any
vision transformer, does not require model re-training, and it propagates
information that would otherwise be dropped through the model. Before now,
video token merging has not been evaluated on temporally complex datasets for
video understanding. In this work, we explore training-free token merging for
video to provide comprehensive experiments and find best practices across four
video transformers on three datasets that exhibit coarse and fine-grained
action recognition. Our results showcase the benefits of video token merging
with a speedup of around $2.5$X while maintaining accuracy (avg. $-0.55\%$ for
ViViT). Code available at
https://github.com/sjpollard/video-how-do-your-tokens-merge.

</details>


### [422] [Joint Video Enhancement with Deblurring, Super-Resolution, and Frame Interpolation Network](https://arxiv.org/abs/2506.03892)
*Giyong Choi,HyunWook Park*

Main category: cs.CV

TL;DR: 提出了一种联合视频增强方法DSFN，同时解决多种视频降质问题，优于现有序列方法。


<details>
  <summary>Details</summary>
Motivation: 视频质量通常受多种因素共同影响，现有序列增强方法效率低下且非最优。

Method: DSFN网络通过联合去模糊和超分辨率模块（JDSR）及三帧插值模块（TFBFI）直接生成高质量视频。

Result: 在公共数据集上表现优于现有技术，网络更小且处理更快。

Conclusion: DSFN为联合视频增强任务提供了一种高效且性能优越的解决方案。

Abstract: Video quality is often severely degraded by multiple factors rather than a
single factor. These low-quality videos can be restored to high-quality videos
by sequentially performing appropriate video enhancement techniques. However,
the sequential approach was inefficient and sub-optimal because most video
enhancement approaches were designed without taking into account that multiple
factors together degrade video quality. In this paper, we propose a new joint
video enhancement method that mitigates multiple degradation factors
simultaneously by resolving an integrated enhancement problem. Our proposed
network, named DSFN, directly produces a high-resolution, high-frame-rate, and
clear video from a low-resolution, low-frame-rate, and blurry video. In the
DSFN, low-resolution and blurry input frames are enhanced by a joint deblurring
and super-resolution (JDSR) module. Meanwhile, intermediate frames between
input adjacent frames are interpolated by a triple-frame-based frame
interpolation (TFBFI) module. The proper combination of the proposed modules of
DSFN can achieve superior performance on the joint video enhancement task.
Experimental results show that the proposed method outperforms other sequential
state-of-the-art techniques on public datasets with a smaller network size and
faster processing time.

</details>


### [423] [Learning from Noise: Enhancing DNNs for Event-Based Vision through Controlled Noise Injection](https://arxiv.org/abs/2506.03918)
*Marcin Kowalczyk,Kamil Jeziorek,Tomasz Kryjak*

Main category: cs.CV

TL;DR: 提出了一种噪声注入训练方法，增强神经网络对事件噪声的鲁棒性，优于传统事件过滤技术。


<details>
  <summary>Details</summary>
Motivation: 事件数据常受噪声影响，传统过滤方法可能丢失有用信息。

Method: 在训练数据中引入可控噪声，使模型学习抗噪声表示。

Result: 在多个数据集和网络架构上表现稳定，分类准确率最高。

Conclusion: 噪声注入训练是事件数据分类系统的可行替代方案。

Abstract: Event-based sensors offer significant advantages over traditional frame-based
cameras, especially in scenarios involving rapid motion or challenging lighting
conditions. However, event data frequently suffers from considerable noise,
negatively impacting the performance and robustness of deep learning models.
Traditionally, this problem has been addressed by applying filtering algorithms
to the event stream, but this may also remove some of relevant data. In this
paper, we propose a novel noise-injection training methodology designed to
enhance the neural networks robustness against varying levels of event noise.
Our approach introduces controlled noise directly into the training data,
enabling models to learn noise-resilient representations. We have conducted
extensive evaluations of the proposed method using multiple benchmark datasets
(N-Caltech101, N-Cars, and Mini N-ImageNet) and various network architectures,
including Convolutional Neural Networks, Vision Transformers, Spiking Neural
Networks, and Graph Convolutional Networks. Experimental results show that our
noise-injection training strategy achieves stable performance over a range of
noise intensities, consistently outperforms event-filtering techniques, and
achieves the highest average classification accuracy, making it a viable
alternative to traditional event-data filtering methods in an object
classification system. Code: https://github.com/vision-agh/DVS_Filtering

</details>


### [424] [Multiple Stochastic Prompt Tuning for Practical Cross-Domain Few Shot Learning](https://arxiv.org/abs/2506.03926)
*Debarshi Brahma,Soma Biswas*

Main category: cs.CV

TL;DR: 提出了一种实用的跨域少样本学习任务（pCDFSL），利用预训练模型CLIP处理极端域偏移下的未见类分类，仅需少量标注样本。


<details>
  <summary>Details</summary>
Motivation: 现有CDFSL框架依赖人工设计的训练和测试机制，pCDFSL更贴近实际应用需求。

Method: 提出MIST框架，通过多个随机提示调优处理域和语义偏移，采用高斯分布建模提示权重以避免过拟合。

Result: 在四个CDFSL基准测试中表现优于现有方法。

Conclusion: MIST框架有效解决了pCDFSL任务中的挑战，具有实际应用潜力。

Abstract: In this work, we propose a practical cross-domain few-shot learning (pCDFSL)
task, where a large-scale pre-trained model like CLIP can be easily deployed on
a target dataset. The goal is to simultaneously classify all unseen classes
under extreme domain shifts, by utilizing only a few labeled samples per class.
The pCDFSL paradigm is source-free and moves beyond artificially created
episodic training and testing regimes followed by existing CDFSL frameworks,
making it more challenging and relevant to real-world applications. Towards
that goal, we propose a novel framework, termed MIST (MultIple STochastic
Prompt tuning), where multiple stochastic prompts are utilized to handle
significant domain and semantic shifts. Specifically, multiple prompts are
learnt for each class, effectively capturing multiple peaks in the input data.
Furthermore, instead of representing the weights of the multiple prompts as
point-estimates, we model them as learnable Gaussian distributions with two
different strategies, encouraging an efficient exploration of the prompt
parameter space, which mitigate overfitting due to the few labeled training
samples. Extensive experiments and comparison with the state-of-the-art methods
on four CDFSL benchmarks adapted to this setting, show the effectiveness of the
proposed framework.

</details>


### [425] [Vision Remember: Alleviating Visual Forgetting in Efficient MLLM with Vision Feature Resample](https://arxiv.org/abs/2506.03928)
*Ze Feng,Jiang-Jiang Liu,Sen Yang,Lingyu Xiao,Xiaofan Li,Wankou Yang,Jingdong Wang*

Main category: cs.CV

TL;DR: 提出Vision Remember方法，通过在LLM解码层间插入模块，保留多级视觉特征并重新采样，以解决视觉信息丢失问题，提升细粒度空间关系任务的性能。


<details>
  <summary>Details</summary>
Motivation: 冗余视觉标记占用大量计算资源，现有方法在Vision Projector中压缩视觉标记会导致视觉信息丢失，尤其是对细粒度空间关系任务（如OCR和图表理解）影响显著。

Method: 提出Vision Remember模块，保留多级视觉特征并通过局部注意力机制重新采样，增强视觉标记的细粒度上下文信息和空间关系。

Result: 在多个视觉理解基准测试中验证了方法的有效性，结合不同Efficient Vision Projectors时性能提升且效率不降。LLaVA-VR（仅2B参数）优于Tokenpacker-HD-7B和DeepSeek-VL-7B等模型。

Conclusion: Vision Remember通过局部注意力机制有效保留视觉信息，提升模型性能，尤其在细粒度任务中表现优异，同时保持计算效率。

Abstract: In this work, we study the Efficient Multimodal Large Language Model.
Redundant vision tokens consume a significant amount of computational memory
and resources. Therefore, many previous works compress them in the Vision
Projector to reduce the number of vision tokens. However, simply compressing in
the Vision Projector can lead to the loss of visual information, especially for
tasks that rely on fine-grained spatial relationships, such as OCR and Chart \&
Table Understanding. To address this problem, we propose Vision Remember, which
is inserted between the LLM decoder layers to allow vision tokens to
re-memorize vision features. Specifically, we retain multi-level vision
features and resample them with the vision tokens that have interacted with the
text token. During the resampling process, each vision token only attends to a
local region in vision features, which is referred to as saliency-enhancing
local attention. Saliency-enhancing local attention not only improves
computational efficiency but also captures more fine-grained contextual
information and spatial relationships within the region. Comprehensive
experiments on multiple visual understanding benchmarks validate the
effectiveness of our method when combined with various Efficient Vision
Projectors, showing performance gains without sacrificing efficiency. Based on
Vision Remember, LLaVA-VR with only 2B parameters is also superior to previous
representative MLLMs such as Tokenpacker-HD-7B and DeepSeek-VL-7B.

</details>


### [426] [DiffCAP: Diffusion-based Cumulative Adversarial Purification for Vision Language Models](https://arxiv.org/abs/2506.03933)
*Jia Fu,Yongtao Wu,Yihang Chen,Kunyu Peng,Xiao Zhang,Volkan Cevher,Sepideh Pashami,Anders Holst*

Main category: cs.CV

TL;DR: DiffCAP是一种基于扩散的净化策略，能有效中和视觉语言模型（VLMs）中的对抗性扰动，显著提升模型在对抗环境中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 尽管VLMs在多模态理解中表现出色，但其对扰动的敏感性可能导致错误输出，威胁实际应用的可靠性。

Method: DiffCAP通过逐步注入高斯噪声中和对抗性扰动，直至连续噪声图像的嵌入达到相似阈值，随后使用预训练扩散模型去噪。

Result: 在多种数据集、模型和攻击强度下，DiffCAP显著优于现有防御技术，同时减少超参数调整和去噪时间。

Conclusion: DiffCAP为对抗环境中安全部署VLMs提供了高效且实用的解决方案。

Abstract: Vision Language Models (VLMs) have shown remarkable capabilities in
multimodal understanding, yet their susceptibility to perturbations poses a
significant threat to their reliability in real-world applications. Despite
often being imperceptible to humans, these perturbations can drastically alter
model outputs, leading to erroneous interpretations and decisions. This paper
introduces DiffCAP, a novel diffusion-based purification strategy that can
effectively neutralize adversarial corruptions in VLMs. We observe that adding
minimal noise to an adversarially corrupted image significantly alters its
latent embedding with respect to VLMs. Building on this insight, DiffCAP
cumulatively injects random Gaussian noise into adversarially perturbed input
data. This process continues until the embeddings of two consecutive noisy
images reach a predefined similarity threshold, indicating a potential approach
to neutralize the adversarial effect. Subsequently, a pretrained diffusion
model is employed to denoise the stabilized image, recovering a clean
representation suitable for the VLMs to produce an output. Through extensive
experiments across six datasets with three VLMs under varying attack strengths
in three task scenarios, we show that DiffCAP consistently outperforms existing
defense techniques by a substantial margin. Notably, DiffCAP significantly
reduces both hyperparameter tuning complexity and the required diffusion time,
thereby accelerating the denoising process. Equipped with strong theoretical
and empirical support, DiffCAP provides a robust and practical solution for
securely deploying VLMs in adversarial environments.

</details>


### [427] [Average Calibration Losses for Reliable Uncertainty in Medical Image Segmentation](https://arxiv.org/abs/2506.03942)
*Theodore Barfoot,Luis C. Garcia-Peraza-Herrera,Samet Akcay,Ben Glocker,Tom Vercauteren*

Main category: cs.CV

TL;DR: 提出了一种可微分的mL1-ACE损失函数，用于改善医学图像分割模型的校准性能，实验表明其显著降低了校准误差。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割模型通常过于自信，影响可靠性和临床实用性，需要改进校准性能。

Method: 提出硬分箱和软分箱的mL1-ACE损失函数，作为辅助损失，并在四个数据集上验证其效果。

Result: 软分箱mL1-ACE显著改善校准性能，但可能影响分割性能；硬分箱则保持分割性能但校准改进较弱。

Conclusion: 该方法提高了分割预测的可信度，有助于深度学习在临床中的安全应用。

Abstract: Deep neural networks for medical image segmentation are often overconfident,
compromising both reliability and clinical utility. In this work, we propose
differentiable formulations of marginal L1 Average Calibration Error (mL1-ACE)
as an auxiliary loss that can be computed on a per-image basis. We compare both
hard- and soft-binning approaches to directly improve pixel-wise calibration.
Our experiments on four datasets (ACDC, AMOS, KiTS, BraTS) demonstrate that
incorporating mL1-ACE significantly reduces calibration errors, particularly
Average Calibration Error (ACE) and Maximum Calibration Error (MCE), while
largely maintaining high Dice Similarity Coefficients (DSCs). We find that the
soft-binned variant yields the greatest improvements in calibration, over the
Dice plus cross-entropy loss baseline, but often compromises segmentation
performance, with hard-binned mL1-ACE maintaining segmentation performance,
albeit with weaker calibration improvement. To gain further insight into
calibration performance and its variability across an imaging dataset, we
introduce dataset reliability histograms, an aggregation of per-image
reliability diagrams. The resulting analysis highlights improved alignment
between predicted confidences and true accuracies. Overall, our approach not
only enhances the trustworthiness of segmentation predictions but also shows
potential for safer integration of deep learning methods into clinical
workflows. We share our code here:
https://github.com/cai4cai/Average-Calibration-Losses

</details>


### [428] [MS-YOLO: A Multi-Scale Model for Accurate and Efficient Blood Cell Detection](https://arxiv.org/abs/2506.03972)
*Guohua Wu,Shengqi Chen,Pengchao Deng,Wenting Yu*

Main category: cs.CV

TL;DR: MS-YOLO是一种基于YOLOv11的血细胞检测模型，通过多尺度扩展残差模块、动态跨路径特征增强模块和轻量自适应权重下采样模块提升检测性能，在CBC基准测试中达到97.4%的mAP@50，优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 传统手动显微镜方法效率低且准确性不足，现有自动化检测方法成本高且精度不理想，深度学习在重叠细胞和多尺度目标检测方面仍面临挑战。

Method: 提出MS-YOLO模型，包含多尺度扩展残差模块（MS-DRM）、动态跨路径特征增强模块（DCFEM）和轻量自适应权重下采样模块（LADS）。

Result: 在CBC基准测试中达到97.4%的mAP@50，尤其在血小板等小目标检测上表现优异，并在WBCDD数据集上验证了泛化能力。

Conclusion: MS-YOLO具有轻量级架构和实时推理效率，满足临床部署需求，为标准化血液病理评估提供可靠技术支持。

Abstract: Complete blood cell detection holds significant value in clinical
diagnostics. Conventional manual microscopy methods suffer from time
inefficiency and diagnostic inaccuracies. Existing automated detection
approaches remain constrained by high deployment costs and suboptimal accuracy.
While deep learning has introduced powerful paradigms to this field, persistent
challenges in detecting overlapping cells and multi-scale objects hinder
practical deployment. This study proposes the multi-scale YOLO (MS-YOLO), a
blood cell detection model based on the YOLOv11 framework, incorporating three
key architectural innovations to enhance detection performance. Specifically,
the multi-scale dilated residual module (MS-DRM) replaces the original C3K2
modules to improve multi-scale discriminability; the dynamic cross-path feature
enhancement module (DCFEM) enables the fusion of hierarchical features from the
backbone with aggregated features from the neck to enhance feature
representations; and the light adaptive-weight downsampling module (LADS)
improves feature downsampling through adaptive spatial weighting while reducing
computational complexity. Experimental results on the CBC benchmark demonstrate
that MS-YOLO achieves precise detection of overlapping cells and multi-scale
objects, particularly small targets such as platelets, achieving an mAP@50 of
97.4% that outperforms existing models. Further validation on the supplementary
WBCDD dataset confirms its robust generalization capability. Additionally, with
a lightweight architecture and real-time inference efficiency, MS-YOLO meets
clinical deployment requirements, providing reliable technical support for
standardized blood pathology assessment.

</details>


### [429] [RAID: A Dataset for Testing the Adversarial Robustness of AI-Generated Image Detectors](https://arxiv.org/abs/2506.03988)
*Hicham Eddoubi,Jonas Ricker,Federico Cocchi,Lorenzo Baraldi,Angelo Sotgiu,Maura Pintor,Marcella Cornia,Lorenzo Baraldi,Asja Fischer,Rita Cucchiara,Battista Biggio*

Main category: cs.CV

TL;DR: 论文提出RAID数据集，用于评估AI生成图像检测器的对抗鲁棒性，发现现有检测器易受对抗样本欺骗。


<details>
  <summary>Details</summary>
Motivation: AI生成图像质量高，人类难以区分，需检测其真实性以防止欺诈和虚假信息。现有检测方法在理想条件下表现良好，但对抗鲁棒性常被忽视。

Method: 提出RAID数据集，包含72k多样且高迁移性的对抗样本，通过攻击七种先进检测器和四种文本生成图像模型生成。

Result: 实验表明，RAID生成的对抗样本能高成功率迁移到未见检测器，揭示当前检测器易受欺骗。

Conclusion: 需开发更鲁棒的检测方法，RAID数据集和代码已公开。

Abstract: AI-generated images have reached a quality level at which humans are
incapable of reliably distinguishing them from real images. To counteract the
inherent risk of fraud and disinformation, the detection of AI-generated images
is a pressing challenge and an active research topic. While many of the
presented methods claim to achieve high detection accuracy, they are usually
evaluated under idealized conditions. In particular, the adversarial robustness
is often neglected, potentially due to a lack of awareness or the substantial
effort required to conduct a comprehensive robustness analysis. In this work,
we tackle this problem by providing a simpler means to assess the robustness of
AI-generated image detectors. We present RAID (Robust evaluation of
AI-generated image Detectors), a dataset of 72k diverse and highly transferable
adversarial examples. The dataset is created by running attacks against an
ensemble of seven state-of-the-art detectors and images generated by four
different text-to-image models. Extensive experiments show that our methodology
generates adversarial images that transfer with a high success rate to unseen
detectors, which can be used to quickly provide an approximate yet still
reliable estimate of a detector's adversarial robustnessOur findings indicate
that current state-of-the-art AI-generated image detectors can be easily
deceived by adversarial examples, highlighting the critical need for the
development of more robust methods. We release our dataset at
https://huggingface.co/datasets/aimagelab/RAID and evaluation code at
https://github.com/pralab/RAID.

</details>


### [430] [Vocabulary-free few-shot learning for Vision-Language Models](https://arxiv.org/abs/2506.04005)
*Maxime Zanella,Clément Fuchs,Ismail Ben Ayed,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 论文提出了一种无需词汇表的少样本学习方法SiM，通过相似性映射分类目标实例，无需依赖预定义的类别名称。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预定义的类别名称，限制了其适用性，尤其是在类别名称难以获取或指定的场景中。

Method: 提出Similarity Mapping (SiM)，仅基于与通用提示（文本或视觉）的相似性分数分类目标实例。

Result: SiM表现优异，计算效率高（学习映射通常不到一秒），并具有可解释性。

Conclusion: SiM为无需词汇表的少样本学习提供了重要基线，未来研究可在此基础上展开。

Abstract: Recent advances in few-shot adaptation for Vision-Language Models (VLMs) have
greatly expanded their ability to generalize across tasks using only a few
labeled examples. However, existing approaches primarily build upon the strong
zero-shot priors of these models by leveraging carefully designed,
task-specific prompts. This dependence on predefined class names can restrict
their applicability, especially in scenarios where exact class names are
unavailable or difficult to specify. To address this limitation, we introduce
vocabulary-free few-shot learning for VLMs, a setting where target class
instances - that is, images - are available but their corresponding names are
not. We propose Similarity Mapping (SiM), a simple yet effective baseline that
classifies target instances solely based on similarity scores with a set of
generic prompts (textual or visual), eliminating the need for carefully
handcrafted prompts. Although conceptually straightforward, SiM demonstrates
strong performance, operates with high computational efficiency (learning the
mapping typically takes less than one second), and provides interpretability by
linking target classes to generic prompts. We believe that our approach could
serve as an important baseline for future research in vocabulary-free few-shot
learning. Code is available at
https://github.com/MaxZanella/vocabulary-free-FSL.

</details>


### [431] [Rex-Thinker: Grounded Object Referring via Chain-of-Thought Reasoning](https://arxiv.org/abs/2506.04034)
*Qing Jiang,Xingyu Chen,Zhaoyang Zeng,Junzhi Yu,Lei Zhang*

Main category: cs.CV

TL;DR: Rex-Thinker将对象引用任务转化为显式的思维链推理任务，通过分步验证候选对象是否匹配描述，提升模型的解释性和可信度。


<details>
  <summary>Details</summary>
Motivation: 现有方法将对象引用视为直接预测边界框的任务，缺乏解释性且难以拒绝无匹配对象的描述。Rex-Thinker旨在通过显式推理解决这些问题。

Method: 模型分两步：1) 识别候选对象；2) 对每个候选对象进行分步推理验证。训练分为监督微调和GRPO强化学习两阶段。

Result: Rex-Thinker在精度和解释性上优于基线模型，并能更好地拒绝无效输出，在跨域场景中表现更强。

Conclusion: 通过思维链推理和结构化训练，Rex-Thinker显著提升了对象引用任务的解释性和鲁棒性。

Abstract: Object referring aims to detect all objects in an image that match a given
natural language description. We argue that a robust object referring model
should be grounded, meaning its predictions should be both explainable and
faithful to the visual content. Specifically, it should satisfy two key
properties: 1) Verifiable, by producing interpretable reasoning that justifies
its predictions and clearly links them to visual evidence; and 2) Trustworthy,
by learning to abstain when no object in the image satisfies the given
expression. However, most methods treat referring as a direct bounding box
prediction task, offering limited interpretability and struggling to reject
expressions with no matching object. In this work, we propose Rex-Thinker, a
model that formulates object referring as an explicit CoT reasoning task. Given
a referring expression, we first identify all candidate object instances
corresponding to the referred object category. Rex-Thinker then performs
step-by-step reasoning over each candidate to assess whether it matches the
given expression, before making a final prediction. To support this paradigm,
we construct a large-scale CoT-style referring dataset named HumanRef-CoT by
prompting GPT-4o on the HumanRef dataset. Each reasoning trace follows a
structured planning, action, and summarization format, enabling the model to
learn decomposed, interpretable reasoning over object candidates. We then train
Rex-Thinker in two stages: a cold-start supervised fine-tuning phase to teach
the model how to perform structured reasoning, followed by GRPO-based RL
learning to improve accuracy and generalization. Experiments show that our
approach outperforms standard baselines in both precision and interpretability
on in-domain evaluation, while also demonstrating improved ability to reject
hallucinated outputs and strong generalization in out-of-domain settings.

</details>


### [432] [Mitigating Hallucinations in Large Vision-Language Models via Entity-Centric Multimodal Preference Optimization](https://arxiv.org/abs/2506.04039)
*Jiulong Wu,Zhengliang Shi,Shuaiqiang Wang,Jizhou Huang,Dawei Yin,Lingyong Yan,Min Cao,Min Zhang*

Main category: cs.CV

TL;DR: 论文提出EMPO方法，通过实体中心的多模态偏好优化，显著减少大型视觉语言模型的幻觉问题，并在实验中取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在多任务中表现出色，但其可信度常因幻觉问题受到质疑，现有方法忽视图像-文本模态对齐，导致过度依赖语言模型和幻觉。

Method: 提出Entity-centric Multimodal Preference Optimization (EMPO)，通过自动构建高质量多模态偏好数据（图像、指令、响应），增强模态对齐。

Result: 在多个基准测试中表现优异，如Object-HalBench和MM-HalBench的幻觉率分别降低85.9%和49.8%。

Conclusion: EMPO通过优化多模态偏好对齐，有效减少幻觉问题，提升了LVLMs的可信度。

Abstract: Large Visual Language Models (LVLMs) have demonstrated impressive
capabilities across multiple tasks. However, their trustworthiness is often
challenged by hallucinations, which can be attributed to the modality
misalignment and the inherent hallucinations of their underlying Large Language
Models (LLMs) backbone. Existing preference alignment methods focus on aligning
model responses with human preferences while neglecting image-text modality
alignment, resulting in over-reliance on LLMs and hallucinations. In this
paper, we propose Entity-centric Multimodal Preference Optimization (EMPO),
which achieves enhanced modality alignment than existing human preference
alignment methods. Besides, to overcome the scarcity of high-quality multimodal
preference data, we utilize open-source instruction datasets to automatically
construct high-quality preference data across three aspects: image,
instruction, and response. Experiments on two human preference datasets and
five multimodal hallucination benchmarks demonstrate the effectiveness of EMPO,
e.g., reducing hallucination rates by 85.9% on Object-HalBench and 49.8% on
MM-HalBench.

</details>


### [433] [EV-Flying: an Event-based Dataset for In-The-Wild Recognition of Flying Objects](https://arxiv.org/abs/2506.04048)
*Gabriele Magrini,Federico Becattini,Giovanni Colombo,Pietro Pala*

Main category: cs.CV

TL;DR: 论文提出了一种基于事件相机的飞行物体监测方法EV-Flying，解决了传统RGB方法在尺度变化、运动模糊和高速运动中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统RGB方法在监测小飞行物体（如昆虫和无人机）时面临尺度变化、运动模糊和高速运动的挑战，事件相机因其高时间分辨率和低延迟成为更优选择。

Method: 提出EV-Flying数据集，包含标注的鸟类、昆虫和无人机数据，采用基于点云的轻量级架构（类似PointNet）处理异步事件流。

Result: 研究了基于点云事件表示的飞行物体分类，为实际场景中的高效可靠识别提供了基础。

Conclusion: EV-Flying数据集和方法为飞行物体识别提供了更高效可靠的解决方案。

Abstract: Monitoring aerial objects is crucial for security, wildlife conservation, and
environmental studies. Traditional RGB-based approaches struggle with
challenges such as scale variations, motion blur, and high-speed object
movements, especially for small flying entities like insects and drones. In
this work, we explore the potential of event-based vision for detecting and
recognizing flying objects, in particular animals that may not follow short and
long-term predictable patters. Event cameras offer high temporal resolution,
low latency, and robustness to motion blur, making them well-suited for this
task. We introduce EV-Flying, an event-based dataset of flying objects,
comprising manually annotated birds, insects and drones with spatio-temporal
bounding boxes and track identities. To effectively process the asynchronous
event streams, we employ a point-based approach leveraging lightweight
architectures inspired by PointNet. Our study investigates the classification
of flying objects using point cloud-based event representations. The proposed
dataset and methodology pave the way for more efficient and reliable aerial
object recognition in real-world scenarios.

</details>


### [434] [Video Deblurring with Deconvolution and Aggregation Networks](https://arxiv.org/abs/2506.04054)
*Giyong Choi,HyunWook Park*

Main category: cs.CV

TL;DR: 本文提出了一种用于视频去模糊的解卷积与聚合网络（DAN），通过三个子网络有效利用相邻帧信息，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频去模糊算法未能充分利用相邻帧信息，导致性能不佳。

Method: DAN包含预处理网络（PPN）、基于对齐的解卷积网络（ABDN）和帧聚合网络（FAN），分别负责预处理、解卷积和聚合。

Result: 实验表明，DAN在公开数据集上定量和定性评估均优于现有方法。

Conclusion: DAN通过合理结合三个子网络，有效利用相邻帧信息，实现了优越的视频去模糊性能。

Abstract: In contrast to single-image deblurring, video deblurring has the advantage
that neighbor frames can be utilized to deblur a target frame. However,
existing video deblurring algorithms often fail to properly employ the neighbor
frames, resulting in sub-optimal performance. In this paper, we propose a
deconvolution and aggregation network (DAN) for video deblurring that utilizes
the information of neighbor frames well. In DAN, both deconvolution and
aggregation strategies are achieved through three sub-networks: the
preprocessing network (PPN) and the alignment-based deconvolution network
(ABDN) for the deconvolution scheme; the frame aggregation network (FAN) for
the aggregation scheme. In the deconvolution part, blurry inputs are first
preprocessed by the PPN with non-local operations. Then, the output frames from
the PPN are deblurred by the ABDN based on the frame alignment. In the FAN,
these deblurred frames from the deconvolution part are combined into a latent
frame according to reliability maps which infer pixel-wise sharpness. The
proper combination of three sub-networks can achieve favorable performance on
video deblurring by using the neighbor frames suitably. In experiments, the
proposed DAN was demonstrated to be superior to existing state-of-the-art
methods through both quantitative and qualitative evaluations on the public
datasets.

</details>


### [435] [Point Cloud Quality Assessment Using the Perceptual Clustering Weighted Graph (PCW-Graph) and Attention Fusion Network](https://arxiv.org/abs/2506.04081)
*Abdelouahed Laazoufi,Mohammed El Hassouni,Hocine Cherifi*

Main category: cs.CV

TL;DR: 无参考点云质量评估（NR-PCQA）在无参考模型的实际应用中至关重要。


<details>
  <summary>Details</summary>
Motivation: 由于实际应用中常常缺乏参考模型，需要一种方法来评估3D内容的质量。

Method: 未明确提及具体方法，但研究重点是NR-PCQA技术。

Result: 未明确提及具体结果，但强调了NR-PCQA的重要性。

Conclusion: NR-PCQA在无参考模型的实际应用中具有重要价值。

Abstract: No-Reference Point Cloud Quality Assessment (NR-PCQA) is critical for
evaluating 3D content in real-world applications where reference models are
unavailable.

</details>


### [436] [GlobalBuildingAtlas: An Open Global and Complete Dataset of Building Polygons, Heights and LoD1 3D Models](https://arxiv.org/abs/2506.04106)
*Xiao Xiang Zhu,Sining Chen,Fahong Zhang,Yilei Shi,Yuanyuan Wang*

Main category: cs.CV

TL;DR: GlobalBuildingAtlas是全球首个公开的、覆盖全球的建筑物多边形、高度和LoD1 3D模型数据集，包含超过27.5亿建筑物，提供高分辨率和精确的地理空间分析。


<details>
  <summary>Details</summary>
Motivation: 填补全球范围内高质量、一致性和完整性建筑物数据的空白，支持高分辨率的本地和全球分析。

Method: 开发基于机器学习的流程从卫星数据中提取建筑物多边形和高度，并通过质量融合策略优化数据。

Result: 生成全球最全面的2D和3D建筑物数据集，包括GBA.Polygon、GBA.Height和GBA.LoD1，高度精度达1.5-8.9米RMSE。

Conclusion: GlobalBuildingAtlas为全球建筑物现状提供新见解，支持可持续发展和地理空间分析。

Abstract: We introduce GlobalBuildingAtlas, a publicly available dataset providing
global and complete coverage of building polygons, heights and Level of Detail
1 (LoD1) 3D building models. This is the first open dataset to offer high
quality, consistent, and complete building data in 2D and 3D form at the
individual building level on a global scale. Towards this dataset, we developed
machine learning-based pipelines to derive building polygons and heights
(called GBA.Height) from global PlanetScope satellite data, respectively. Also
a quality-based fusion strategy was employed to generate higher-quality
polygons (called GBA.Polygon) based on existing open building polygons,
including our own derived one. With more than 2.75 billion buildings worldwide,
GBA.Polygon surpasses the most comprehensive database to date by more than 1
billion buildings. GBA.Height offers the most detailed and accurate global 3D
building height maps to date, achieving a spatial resolution of 3x3 meters-30
times finer than previous global products (90 m), enabling a high-resolution
and reliable analysis of building volumes at both local and global scales.
Finally, we generated a global LoD1 building model (called GBA.LoD1) from the
resulting GBA.Polygon and GBA.Height. GBA.LoD1 represents the first complete
global LoD1 building models, including 2.68 billion building instances with
predicted heights, i.e., with a height completeness of more than 97%, achieving
RMSEs ranging from 1.5 m to 8.9 m across different continents. With its height
accuracy, comprehensive global coverage and rich spatial details,
GlobalBuildingAltas offers novel insights on the status quo of global
buildings, which unlocks unprecedented geospatial analysis possibilities, as
showcased by a better illustration of where people live and a more
comprehensive monitoring of the progress on the 11th Sustainable Development
Goal of the United Nations.

</details>


### [437] [Multi-view Surface Reconstruction Using Normal and Reflectance Cues](https://arxiv.org/abs/2506.04115)
*Robin Bruneau,Baptiste Brument,Yvain Quéau,Jean Mélou,François Bernard Lauze,Jean-Denis Durou,Lilian Calvet*

Main category: cs.CV

TL;DR: 提出了一种结合多视角法线和反射率图的框架，用于高保真3D表面重建，尤其在复杂反射材料和稀疏视角下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决复杂反射材料和稀疏视角下高保真3D表面重建的挑战。

Method: 采用像素级联合重参数化反射率和表面法线，将其表示为模拟变化光照下的辐射向量，并与传统或神经体积渲染框架结合。

Result: 在多视角光度立体基准数据集（如DiLiGenT-MV、LUCES-MV和Skoltech3D）上达到最先进性能，尤其擅长细节重建和复杂可见性处理。

Conclusion: 该方法在复杂场景下表现优异，是早期会议论文的扩展版本，算法更快速、鲁棒，并提供了更广泛的实验评估。

Abstract: Achieving high-fidelity 3D surface reconstruction while preserving fine
details remains challenging, especially in the presence of materials with
complex reflectance properties and without a dense-view setup. In this paper,
we introduce a versatile framework that incorporates multi-view normal and
optionally reflectance maps into radiance-based surface reconstruction. Our
approach employs a pixel-wise joint re-parametrization of reflectance and
surface normals, representing them as a vector of radiances under simulated,
varying illumination. This formulation enables seamless incorporation into
standard surface reconstruction pipelines, such as traditional multi-view
stereo (MVS) frameworks or modern neural volume rendering (NVR) ones. Combined
with the latter, our approach achieves state-of-the-art performance on
multi-view photometric stereo (MVPS) benchmark datasets, including DiLiGenT-MV,
LUCES-MV and Skoltech3D. In particular, our method excels in reconstructing
fine-grained details and handling challenging visibility conditions. The
present paper is an extended version of the earlier conference paper by Brument
et al. (in Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition (CVPR), 2024), featuring an accelerated and more robust
algorithm as well as a broader empirical evaluation. The code and data relative
to this article is available at https://github.com/RobinBruneau/RNb-NeuS2.

</details>


### [438] [Contour Errors: An Ego-Centric Metric for Reliable 3D Multi-Object Tracking](https://arxiv.org/abs/2506.04122)
*Sharang Kaul,Mario Berk,Thiemo Gerbich,Abhinav Valada*

Main category: cs.CV

TL;DR: 提出了一种名为Contour Errors（CEs）的新指标，用于在3D场景中更可靠地匹配目标，相比传统2D指标（如IoU和CPD），显著减少了功能失败率。


<details>
  <summary>Details</summary>
Motivation: 在安全关键应用（如自动驾驶）中，可靠的目标匹配对感知系统的准确性和可靠性至关重要，但传统2D指标在复杂3D场景中表现不佳。

Method: 引入Contour Errors（CEs），通过比较自车坐标系中的边界框，从功能角度评估目标匹配。

Result: 在nuScenes数据集上的实验表明，CEs在3D车辆跟踪中比IoU和CPD更可靠，近距离功能失败率降低80%，远距离降低60%。

Conclusion: Contour Errors是一种更有效的3D目标匹配指标，显著提升了感知系统的性能和安全性。

Abstract: Finding reliable matches is essential in multi-object tracking to ensure the
accuracy and reliability of perception systems in safety-critical applications
such as autonomous vehicles. Effective matching mitigates perception errors,
enhancing object identification and tracking for improved performance and
safety. However, traditional metrics such as Intersection over Union (IoU) and
Center Point Distances (CPDs), which are effective in 2D image planes, often
fail to find critical matches in complex 3D scenes. To address this limitation,
we introduce Contour Errors (CEs), an ego or object-centric metric for
identifying matches of interest in tracking scenarios from a functional
perspective. By comparing bounding boxes in the ego vehicle's frame, contour
errors provide a more functionally relevant assessment of object matches.
Extensive experiments on the nuScenes dataset demonstrate that contour errors
improve the reliability of matches over the state-of-the-art 2D IoU and CPD
metrics in tracking-by-detection methods. In 3D car tracking, our results show
that Contour Errors reduce functional failures (FPs/FNs) by 80% at close ranges
and 60% at far ranges compared to IoU in the evaluation stage.

</details>


### [439] [UniCUE: Unified Recognition and Generation Framework for Chinese Cued Speech Video-to-Speech Generation](https://arxiv.org/abs/2506.04134)
*Jinting Wang,Shan Yang,Li Liu*

Main category: cs.CV

TL;DR: 论文提出UniCUE框架，直接通过CS视频生成语音，避免中间文本转换的误差传播和时间不对齐问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有CSV2S方法依赖中间文本转换，导致误差传播和时间不对齐，需直接生成语音以解决这些问题。

Method: 提出UniCUE框架，整合CSR任务，引入细粒度语义对齐池、VisioPhonetic适配器和姿态感知视觉处理器。

Result: 在中文CS数据集上，UniCUE将词错误率降低78.3%，唇语同步性提升32%。

Conclusion: UniCUE通过直接生成语音和跨任务整合，显著提升了CSV2S的性能和同步性。

Abstract: Cued Speech (CS) enhances lipreading through hand coding, providing precise
speech perception support for the hearing-impaired. CS Video-to-Speech
generation (CSV2S) task aims to convert the CS visual expressions (CS videos)
of hearing-impaired individuals into comprehensible speech signals. Direct
generation of speech from CS video (called single CSV2S) yields poor
performance due to insufficient CS data. Current research mostly focuses on CS
Recognition (CSR), which convert video content into linguistic text. Based on
this, one straightforward way of CSV2S is to combine CSR with a Text-to-Speech
system. This combined architecture relies on text as an intermediate medium for
stepwise cross-modal alignment, which may lead to error propagation and
temporal misalignment between speech and video dynamics. To address these
challenges, we propose a novel approach that directly generates speech from CS
videos without relying on intermediate text. Building upon this, we propose
UniCUE, the first unified framework for CSV2S, whose core innovation lies in
the integration of the CSR task that provides fine-grained visual-semantic
information to facilitate speech generation from CS videos. More precisely, (1)
a novel fine-grained semantic alignment pool to ensure precise mapping between
visual features and speech contents; (2) a VisioPhonetic adapter to bridge
cross-task representations, ensuring seamless compatibility between two
distinct tasks (i.e., CSV2S and CSR); (3) a pose-aware visual processor is
introduced to enhance fine-grained spatiotemporal correlations between lip and
hand movements in CS video. Experiments on our new established Chinese CS
dataset (14 cuers1: 8 hearing-impaired and 6 normal-hearing) show that our
UniCUE significantly reduces Word Error Rate by 78.3% and improves lip-speech
synchronization by 32% compared to the single CSV2S.

</details>


### [440] [MMR-V: What's Left Unsaid? A Benchmark for Multimodal Deep Reasoning in Videos](https://arxiv.org/abs/2506.04141)
*Kejian Zhu,Zhuoran Jin,Hongbang Yuan,Jiachun Li,Shangqing Tu,Pengfei Cao,Yubo Chen,Kang Liu,Jun Zhao*

Main category: cs.CV

TL;DR: 论文提出了MMR-V基准测试，用于评估多模态大语言模型在视频中的多帧证据定位和推理能力，发现现有模型表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有视频基准测试主要关注理解任务，缺乏对多帧长距离推理和隐藏信息推理的评估，因此需要新的基准测试。

Method: 提出MMR-V基准测试，包含长距离多帧推理、超越感知的推理、人工标注任务和干扰项设计。

Result: 实验显示当前模型在多模态推理上表现不佳，最佳模型准确率仅52.5%，且现有推理增强策略效果有限。

Conclusion: MMR-V可推动多模态推理能力的研究，并揭示多模态推理与文本推理的差异。

Abstract: The sequential structure of videos poses a challenge to the ability of
multimodal large language models (MLLMs) to locate multi-frame evidence and
conduct multimodal reasoning. However, existing video benchmarks mainly focus
on understanding tasks, which only require models to match frames mentioned in
the question (hereafter referred to as "question frame") and perceive a few
adjacent frames. To address this gap, we propose MMR-V: A Benchmark for
Multimodal Deep Reasoning in Videos. The benchmark is characterized by the
following features. (1) Long-range, multi-frame reasoning: Models are required
to infer and analyze evidence frames that may be far from the question frame.
(2) Beyond perception: Questions cannot be answered through direct perception
alone but require reasoning over hidden information. (3) Reliability: All tasks
are manually annotated, referencing extensive real-world user understanding to
align with common perceptions. (4) Confusability: Carefully designed distractor
annotation strategies to reduce model shortcuts. MMR-V consists of 317 videos
and 1,257 tasks. Our experiments reveal that current models still struggle with
multi-modal reasoning; even the best-performing model, o4-mini, achieves only
52.5% accuracy. Additionally, current reasoning enhancement strategies
(Chain-of-Thought and scaling test-time compute) bring limited gains. Further
analysis indicates that the CoT demanded for multi-modal reasoning differs from
it in textual reasoning, which partly explains the limited performance gains.
We hope that MMR-V can inspire further research into enhancing multi-modal
reasoning capabilities.

</details>


### [441] [Person Re-Identification System at Semantic Level based on Pedestrian Attributes Ontology](https://arxiv.org/abs/2506.04143)
*Ngoc Q. Ly,Hieu N. M. Cao,Thi T. Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一种统一的Re-ID系统，结合PAO、Local MDCNN和IDS模块，通过语义信息解决属性不平衡问题，并在Market1501数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决Re-ID任务中的大规模数据集、不平衡数据、视角和细粒度属性等挑战，特别是语义级局部特征和属性不平衡问题。

Method: 提出三个模块：PAO（行人属性本体）、Local MDCNN（局部多任务DCNN）和IDS（不平衡数据求解器），通过语义信息预过滤候选集并解决属性不平衡问题。

Result: 在Market1501数据集上表现优于现有方法。

Conclusion: 提出的统一Re-ID系统有效解决了属性不平衡问题，并提升了性能。

Abstract: Person Re-Identification (Re-ID) is a very important task in video
surveillance systems such as tracking people, finding people in public places,
or analysing customer behavior in supermarkets. Although there have been many
works to solve this problem, there are still remaining challenges such as
large-scale datasets, imbalanced data, viewpoint, fine grained data
(attributes), the Local Features are not employed at semantic level in online
stage of Re-ID task, furthermore, the imbalanced data problem of attributes are
not taken into consideration. This paper has proposed a Unified Re-ID system
consisted of three main modules such as Pedestrian Attribute Ontology (PAO),
Local Multi-task DCNN (Local MDCNN), Imbalance Data Solver (IDS). The new main
point of our Re-ID system is the power of mutual support of PAO, Local MDCNN
and IDS to exploit the inner-group correlations of attributes and pre-filter
the mismatch candidates from Gallery set based on semantic information as
Fashion Attributes and Facial Attributes, to solve the imbalanced data of
attributes without adjusting network architecture and data augmentation. We
experimented on the well-known Market1501 dataset. The experimental results
have shown the effectiveness of our Re-ID system and it could achieve the
higher performance on Market1501 dataset in comparison to some state-of-the-art
Re-ID methods.

</details>


### [442] [Image Editing As Programs with Diffusion Models](https://arxiv.org/abs/2506.04158)
*Yujia Hu,Songhua Liu,Zhenxiong Tan,Xingyi Yang,Xinchao Wang*

Main category: cs.CV

TL;DR: IEAP框架通过将复杂编辑指令分解为原子操作序列，基于Diffusion Transformer架构，显著提升了指令驱动图像编辑的性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在文本到图像生成中表现优异，但在指令驱动的图像编辑中面临结构不一致性挑战，IEAP旨在解决这一问题。

Method: IEAP采用模块化方法，将编辑指令分解为原子操作，每个操作由轻量级适配器实现，并通过VLM代理编程。

Result: 实验表明，IEAP在多种编辑场景下显著优于现有方法，尤其在复杂多步指令中表现出更高的准确性和语义保真度。

Conclusion: IEAP通过模块化和序列化编辑操作，实现了对复杂指令的鲁棒处理，为图像编辑提供了高效解决方案。

Abstract: While diffusion models have achieved remarkable success in text-to-image
generation, they encounter significant challenges with instruction-driven image
editing. Our research highlights a key challenge: these models particularly
struggle with structurally inconsistent edits that involve substantial layout
changes. To mitigate this gap, we introduce Image Editing As Programs (IEAP), a
unified image editing framework built upon the Diffusion Transformer (DiT)
architecture. At its core, IEAP approaches instructional editing through a
reductionist lens, decomposing complex editing instructions into sequences of
atomic operations. Each operation is implemented via a lightweight adapter
sharing the same DiT backbone and is specialized for a specific type of edit.
Programmed by a vision-language model (VLM)-based agent, these operations
collaboratively support arbitrary and structurally inconsistent
transformations. By modularizing and sequencing edits in this way, IEAP
generalizes robustly across a wide range of editing tasks, from simple
adjustments to substantial structural changes. Extensive experiments
demonstrate that IEAP significantly outperforms state-of-the-art methods on
standard benchmarks across various editing scenarios. In these evaluations, our
framework delivers superior accuracy and semantic fidelity, particularly for
complex, multi-step instructions. Codes are available at
https://github.com/YujiaHu1109/IEAP.

</details>


### [443] [FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting](https://arxiv.org/abs/2506.04174)
*Hengyu Liu,Yuehao Wang,Chenxin Li,Ruisi Cai,Kevin Wang,Wuyang Li,Pavlo Molchanov,Peihao Wang,Zhangyang Wang*

Main category: cs.CV

TL;DR: 提出了一种弹性推理方法，通过选择并变换高斯子集，无需微调即可适应不同设备的显存需求。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅（3DGS）在3D场景表示和新视角合成中应用广泛，但其高GPU内存需求限制了在资源受限设备上的使用。现有方法需微调且缺乏灵活性。

Method: 引入小型可学习模块控制高斯选择，并通过变换模块调整所选高斯以提升性能。

Result: 在ZipNeRF、MipNeRF和Tanks&Temples场景上的实验验证了方法的有效性。

Conclusion: 该方法实现了无需微调的高效渲染，适应性强，代码已开源。

Abstract: 3D Gaussian splatting (3DGS) has enabled various applications in 3D scene
representation and novel view synthesis due to its efficient rendering
capabilities. However, 3DGS demands relatively significant GPU memory, limiting
its use on devices with restricted computational resources. Previous approaches
have focused on pruning less important Gaussians, effectively compressing 3DGS
but often requiring a fine-tuning stage and lacking adaptability for the
specific memory needs of different devices. In this work, we present an elastic
inference method for 3DGS. Given an input for the desired model size, our
method selects and transforms a subset of Gaussians, achieving substantial
rendering performance without additional fine-tuning. We introduce a tiny
learnable module that controls Gaussian selection based on the input
percentage, along with a transformation module that adjusts the selected
Gaussians to complement the performance of the reduced model. Comprehensive
experiments on ZipNeRF, MipNeRF and Tanks\&Temples scenes demonstrate the
effectiveness of our approach. Code is available at https://flexgs.github.io.

</details>


### [444] [Language-Image Alignment with Fixed Text Encoders](https://arxiv.org/abs/2506.04209)
*Jingfeng Yang,Ziyang Wu,Yue Zhao,Yi Ma*

Main category: cs.CV

TL;DR: 本文提出了一种简化框架LIFT，通过固定预训练的大型语言模型（LLM）作为文本编码器，仅训练图像编码器，实现了高效的语言-图像对齐。LIFT在组合理解和长标题任务中优于CLIP，并显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: 质疑当前主流的联合训练方法（如CLIP）是否必要，探索预训练的固定LLM是否能作为足够好的文本编码器指导视觉表示学习。

Method: 提出LIFT框架，固定LLM作为文本编码器，仅训练图像编码器，实现语言-图像对齐。

Result: LIFT在组合理解和长标题任务中表现优于CLIP，同时显著提升计算效率。

Conclusion: LIFT为探索LLM文本嵌入如何指导视觉学习提供了初步方向，并提出了学习语言对齐视觉表示的新设计选择。

Abstract: Currently, the most dominant approach to establishing language-image
alignment is to pre-train text and image encoders jointly through contrastive
learning, such as CLIP and its variants. In this work, we question whether such
a costly joint training is necessary. In particular, we investigate if a
pre-trained fixed large language model (LLM) offers a good enough text encoder
to guide visual representation learning. That is, we propose to learn
Language-Image alignment with a Fixed Text encoder (LIFT) from an LLM by
training only the image encoder. Somewhat surprisingly, through comprehensive
benchmarking and ablation studies, we find that this much simplified framework
LIFT is highly effective and it outperforms CLIP in most scenarios that involve
compositional understanding and long captions, while achieving considerable
gains in computational efficiency. Our work takes a first step towards
systematically exploring how text embeddings from LLMs can guide visual
learning and suggests an alternative design choice for learning
language-aligned visual representations.

</details>


### [445] [Diffusion Domain Teacher: Diffusion Guided Domain Adaptive Object Detector](https://arxiv.org/abs/2506.04211)
*Boyong He,Yuxiang Ji,Zhuoyue Tan,Liaoni Wu*

Main category: cs.CV

TL;DR: 论文提出了一种基于扩散模型的跨域目标检测方法（DDT），通过冻结权重的扩散模型生成伪标签，显著提升了跨域检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决目标检测器在训练数据与真实数据域间性能下降的问题，利用扩散模型的跨域特征表示能力。

Method: 训练冻结权重的扩散模型作为教师模型，生成目标域伪标签，指导学生模型学习。

Result: 在6个数据集上平均mAP提升21.2%，超越现有SOTA方法5.7%。

Conclusion: DDT框架简单有效，适用于复杂模型，展示了强大的域适应能力。

Abstract: Object detectors often suffer a decrease in performance due to the large
domain gap between the training data (source domain) and real-world data
(target domain). Diffusion-based generative models have shown remarkable
abilities in generating high-quality and diverse images, suggesting their
potential for extracting valuable feature from various domains. To effectively
leverage the cross-domain feature representation of diffusion models, in this
paper, we train a detector with frozen-weight diffusion model on the source
domain, then employ it as a teacher model to generate pseudo labels on the
unlabeled target domain, which are used to guide the supervised learning of the
student model on the target domain. We refer to this approach as Diffusion
Domain Teacher (DDT). By employing this straightforward yet potent framework,
we significantly improve cross-domain object detection performance without
compromising the inference speed. Our method achieves an average mAP
improvement of 21.2% compared to the baseline on 6 datasets from three common
cross-domain detection benchmarks (Cross-Camera, Syn2Real, Real2Artistic},
surpassing the current state-of-the-art (SOTA) methods by an average of 5.7%
mAP. Furthermore, extensive experiments demonstrate that our method
consistently brings improvements even in more powerful and complex models,
highlighting broadly applicable and effective domain adaptation capability of
our DDT. The code is available at
https://github.com/heboyong/Diffusion-Domain-Teacher.

</details>


### [446] [FullDiT2: Efficient In-Context Conditioning for Video Diffusion Transformers](https://arxiv.org/abs/2506.04213)
*Xuanhua He,Quande Liu,Zixuan Ye,Wecai Ye,Qiulin Wang,Xintao Wang,Qifeng Chen,Pengfei Wan,Di Zhang,Kun Gai*

Main category: cs.CV

TL;DR: FullDiT2提出了一种高效的上下文条件框架，通过动态令牌选择和选择性上下文缓存机制，显著减少了计算冗余，提升了视频生成和编辑任务的效率。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文条件视频生成方法（如FullDiT）存在二次计算开销问题，限制了实际应用。本文旨在解决这一效率瓶颈。

Method: FullDiT2通过动态令牌选择机制减少令牌冗余，并设计选择性上下文缓存机制优化上下文与潜在视频的交互。

Result: 实验表明，FullDiT2在六种任务中实现了计算量显著减少和2-3倍的加速，同时保持了视频生成质量。

Conclusion: FullDiT2为视频生成和编辑任务提供了一种高效且通用的可控性框架。

Abstract: Fine-grained and efficient controllability on video diffusion transformers
has raised increasing desires for the applicability. Recently, In-context
Conditioning emerged as a powerful paradigm for unified conditional video
generation, which enables diverse controls by concatenating varying context
conditioning signals with noisy video latents into a long unified token
sequence and jointly processing them via full-attention, e.g., FullDiT. Despite
their effectiveness, these methods face quadratic computation overhead as task
complexity increases, hindering practical deployment. In this paper, we study
the efficiency bottleneck neglected in original in-context conditioning video
generation framework. We begin with systematic analysis to identify two key
sources of the computation inefficiencies: the inherent redundancy within
context condition tokens and the computational redundancy in context-latent
interactions throughout the diffusion process. Based on these insights, we
propose FullDiT2, an efficient in-context conditioning framework for general
controllability in both video generation and editing tasks, which innovates
from two key perspectives. Firstly, to address the token redundancy, FullDiT2
leverages a dynamic token selection mechanism to adaptively identify important
context tokens, reducing the sequence length for unified full-attention.
Additionally, a selective context caching mechanism is devised to minimize
redundant interactions between condition tokens and video latents. Extensive
experiments on six diverse conditional video editing and generation tasks
demonstrate that FullDiT2 achieves significant computation reduction and 2-3
times speedup in averaged time cost per diffusion step, with minimal
degradation or even higher performance in video generation quality. The project
page is at \href{https://fulldit2.github.io/}{https://fulldit2.github.io/}.

</details>


### [447] [Sounding that Object: Interactive Object-Aware Image to Audio Generation](https://arxiv.org/abs/2506.04214)
*Tingle Li,Baihe Huang,Xiaobin Zhuang,Dongya Jia,Jiawei Chen,Yuping Wang,Zhuo Chen,Gopala Anumanchipalli,Yuxuan Wang*

Main category: cs.CV

TL;DR: 提出了一种交互式对象感知音频生成模型，通过多模态注意力将图像区域与声音关联，用户可选择对象生成声音。


<details>
  <summary>Details</summary>
Motivation: 复杂视听场景中生成准确声音具有挑战性，尤其是在多对象和多声源的情况下。

Method: 结合对象中心学习和条件潜在扩散模型，通过多模态注意力关联图像区域与声音，测试时利用图像分割实现交互式对象级声音生成。

Result: 定量和定性评估表明，模型优于基线方法，实现了对象与声音的更好对齐。

Conclusion: 模型通过理论验证和实验证明了其有效性，能够根据用户选择的对象生成准确的声音。

Abstract: Generating accurate sounds for complex audio-visual scenes is challenging,
especially in the presence of multiple objects and sound sources. In this
paper, we propose an {\em interactive object-aware audio generation} model that
grounds sound generation in user-selected visual objects within images. Our
method integrates object-centric learning into a conditional latent diffusion
model, which learns to associate image regions with their corresponding sounds
through multi-modal attention. At test time, our model employs image
segmentation to allow users to interactively generate sounds at the {\em
object} level. We theoretically validate that our attention mechanism
functionally approximates test-time segmentation masks, ensuring the generated
audio aligns with selected objects. Quantitative and qualitative evaluations
show that our model outperforms baselines, achieving better alignment between
objects and their associated sounds. Project page:
https://tinglok.netlify.app/files/avobject/

</details>


### [448] [UNIC: Unified In-Context Video Editing](https://arxiv.org/abs/2506.04216)
*Zixuan Ye,Xuanhua He,Quande Liu,Qiulin Wang,Xintao Wang,Pengfei Wan,Di Zhang,Kun Gai,Qifeng Chen,Wenhan Luo*

Main category: cs.CV

TL;DR: UNIC是一个统一的视频编辑框架，通过将不同任务的输入表示为三种令牌类型，并利用DiT的注意力机制实现任务统一，避免了特定任务适配器的需求。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖任务特定架构或定制化设计，限制了编辑条件的多样性和任务的统一性。

Method: 将输入表示为源视频令牌、噪声视频潜在令牌和多模态条件令牌，通过任务感知RoPE和条件偏置解决任务混淆问题。

Result: 在六个代表性视频编辑任务上表现优异，并展现出任务组合能力。

Conclusion: UNIC通过统一框架实现了多样视频编辑任务的高效处理，具有灵活性和扩展性。

Abstract: Recent advances in text-to-video generation have sparked interest in
generative video editing tasks. Previous methods often rely on task-specific
architectures (e.g., additional adapter modules) or dedicated customizations
(e.g., DDIM inversion), which limit the integration of versatile editing
conditions and the unification of various editing tasks. In this paper, we
introduce UNified In-Context Video Editing (UNIC), a simple yet effective
framework that unifies diverse video editing tasks within a single model in an
in-context manner. To achieve this unification, we represent the inputs of
various video editing tasks as three types of tokens: the source video tokens,
the noisy video latent, and the multi-modal conditioning tokens that vary
according to the specific editing task. Based on this formulation, our key
insight is to integrate these three types into a single consecutive token
sequence and jointly model them using the native attention operations of DiT,
thereby eliminating the need for task-specific adapter designs. Nevertheless,
direct task unification under this framework is challenging, leading to severe
token collisions and task confusion due to the varying video lengths and
diverse condition modalities across tasks. To address these, we introduce
task-aware RoPE to facilitate consistent temporal positional encoding, and
condition bias that enables the model to clearly differentiate different
editing tasks. This allows our approach to adaptively perform different video
editing tasks by referring the source video and varying condition tokens "in
context", and support flexible task composition. To validate our method, we
construct a unified video editing benchmark containing six representative video
editing tasks. Results demonstrate that our unified approach achieves superior
performance on each task and exhibits emergent task composition abilities.

</details>


### [449] [Struct2D: A Perception-Guided Framework for Spatial Reasoning in Large Multimodal Models](https://arxiv.org/abs/2506.04220)
*Fangrui Zhu,Hanhui Wang,Yiming Xie,Jing Gu,Tianye Ding,Jianwei Yang,Huaizu Jiang*

Main category: cs.CV

TL;DR: Struct2D框架通过结构化2D输入（如BEV图像和对象标记）提升LMMs的空间推理能力，无需3D输入。实验表明LMMs在零样本任务中表现优异，并通过Struct2D-Set数据集微调后，在多个基准测试中取得竞争力。


<details>
  <summary>Details</summary>
Motivation: 探索LMMs是否仅通过结构化2D输入（而非3D输入）实现空间推理，以简化智能交互的实现。

Method: 提出Struct2D框架，结合BEV图像、对象标记和元数据，生成Struct2D-Set数据集（200K QA对），并微调开源LMM。

Result: LMMs在零样本任务中表现优异，微调后的模型在3D问答、密集描述和对象定位等任务中具有竞争力。

Conclusion: 结构化2D输入能有效连接感知与语言推理，无需3D输入，为未来研究提供代码和数据集支持。

Abstract: Unlocking spatial reasoning in Large Multimodal Models (LMMs) is crucial for
enabling intelligent interaction with 3D environments. While prior efforts
often rely on explicit 3D inputs or specialized model architectures, we ask:
can LMMs reason about 3D space using only structured 2D representations derived
from perception? We introduce Struct2D, a perception-guided prompting framework
that combines bird's-eye-view (BEV) images with object marks and object-centric
metadata, optionally incorporating egocentric keyframes when needed. Using
Struct2D, we conduct an in-depth zero-shot analysis of closed-source LMMs
(e.g., GPT-o3) and find that they exhibit surprisingly strong spatial reasoning
abilities when provided with structured 2D inputs, effectively handling tasks
such as relative direction estimation and route planning. Building on these
insights, we construct Struct2D-Set, a large-scale instruction tuning dataset
with 200K fine-grained QA pairs across eight spatial reasoning categories,
generated automatically from 3D indoor scenes. We fine-tune an open-source LMM
(Qwen2.5VL) on Struct2D-Set, achieving competitive performance on multiple
benchmarks, including 3D question answering, dense captioning, and object
grounding. Our approach demonstrates that structured 2D inputs can effectively
bridge perception and language reasoning in LMMs-without requiring explicit 3D
representations as input. We will release both our code and dataset to support
future research.

</details>


### [450] [Seeing in the Dark: Benchmarking Egocentric 3D Vision with the Oxford Day-and-Night Dataset](https://arxiv.org/abs/2506.04224)
*Zirui Wang,Wenjing Bian,Xinghui Li,Yifu Tao,Jianeng Wang,Maurice Fallon,Victor Adrian Prisacariu*

Main category: cs.CV

TL;DR: 牛津Day-and-Night数据集是一个大规模、以自我为中心的视觉数据集，用于挑战性光照条件下的新视角合成和视觉重定位。


<details>
  <summary>Details</summary>
Motivation: 现有数据集通常缺乏关键特征组合，如真实3D几何、广泛的光照变化和完整的6DoF运动。

Method: 利用Meta ARIA眼镜捕获自我中心视频，并应用多会话SLAM估计相机姿态、重建3D点云，并对齐不同光照条件下的序列。

Result: 数据集覆盖30公里轨迹和40,000平方米区域，支持新视角合成和重定位两个核心基准。

Conclusion: 该数据集为在真实多样环境中评估模型提供了独特平台。

Abstract: We introduce Oxford Day-and-Night, a large-scale, egocentric dataset for
novel view synthesis (NVS) and visual relocalisation under challenging lighting
conditions. Existing datasets often lack crucial combinations of features such
as ground-truth 3D geometry, wide-ranging lighting variation, and full 6DoF
motion. Oxford Day-and-Night addresses these gaps by leveraging Meta ARIA
glasses to capture egocentric video and applying multi-session SLAM to estimate
camera poses, reconstruct 3D point clouds, and align sequences captured under
varying lighting conditions, including both day and night. The dataset spans
over 30 $\mathrm{km}$ of recorded trajectories and covers an area of 40,000
$\mathrm{m}^2$, offering a rich foundation for egocentric 3D vision research.
It supports two core benchmarks, NVS and relocalisation, providing a unique
platform for evaluating models in realistic and diverse environments.

</details>


### [451] [Voyager: Long-Range and World-Consistent Video Diffusion for Explorable 3D Scene Generation](https://arxiv.org/abs/2506.04225)
*Tianyu Huang,Wangguandong Zheng,Tengfei Wang,Yuhao Liu,Zhenwei Wang,Junta Wu,Jie Jiang,Hui Li,Rynson W. H. Lau,Wangmeng Zuo,Chunchao Guo*

Main category: cs.CV

TL;DR: Voyager是一种新颖的视频扩散框架，通过单张图像和用户定义的相机路径生成世界一致的3D点云序列，避免了传统3D重建流程的需求。


<details>
  <summary>Details</summary>
Motivation: 现实应用（如视频游戏和虚拟现实）需要能够建模可沿自定义相机轨迹探索的3D场景，但现有方法在生成长范围、3D一致的场景方面仍面临挑战。

Method: Voyager结合了三个关键组件：1）世界一致的视频扩散，生成对齐的RGB和深度视频序列；2）长范围世界探索，通过点剔除和自回归推理实现场景扩展；3）可扩展数据引擎，自动化相机姿态估计和深度预测。

Result: 该方法在视觉质量和几何精度上优于现有方法，具有广泛的应用潜力。

Conclusion: Voyager通过端到端的场景生成和重建，解决了长范围3D场景生成的一致性问题，为相关领域提供了新的解决方案。

Abstract: Real-world applications like video gaming and virtual reality often demand
the ability to model 3D scenes that users can explore along custom camera
trajectories. While significant progress has been made in generating 3D objects
from text or images, creating long-range, 3D-consistent, explorable 3D scenes
remains a complex and challenging problem. In this work, we present Voyager, a
novel video diffusion framework that generates world-consistent 3D point-cloud
sequences from a single image with user-defined camera path. Unlike existing
approaches, Voyager achieves end-to-end scene generation and reconstruction
with inherent consistency across frames, eliminating the need for 3D
reconstruction pipelines (e.g., structure-from-motion or multi-view stereo).
Our method integrates three key components: 1) World-Consistent Video
Diffusion: A unified architecture that jointly generates aligned RGB and depth
video sequences, conditioned on existing world observation to ensure global
coherence 2) Long-Range World Exploration: An efficient world cache with point
culling and an auto-regressive inference with smooth video sampling for
iterative scene extension with context-aware consistency, and 3) Scalable Data
Engine: A video reconstruction pipeline that automates camera pose estimation
and metric depth prediction for arbitrary videos, enabling large-scale, diverse
training data curation without manual 3D annotations. Collectively, these
designs result in a clear improvement over existing methods in visual quality
and geometric accuracy, with versatile applications.

</details>


### [452] [LayerFlow: A Unified Model for Layer-aware Video Generation](https://arxiv.org/abs/2506.04228)
*Sihui Ji,Hao Luo,Xi Chen,Yuanpeng Tu,Yiyang Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: LayerFlow是一个统一的层感知视频生成解决方案，支持透明前景、干净背景和混合场景的生成，并能分解混合视频或为给定前景生成背景。


<details>
  <summary>Details</summary>
Motivation: 解决高质量分层视频生成的需求，同时支持多种变体任务。

Method: 基于文本到视频扩散变换器，通过分层嵌入区分不同层的子片段，并采用多阶段训练策略以适应静态图像数据。

Result: 能够生成平滑的分层视频，支持多种变体任务。

Conclusion: LayerFlow提供了一个统一的框架，有效解决了分层视频生成的挑战。

Abstract: We present LayerFlow, a unified solution for layer-aware video generation.
Given per-layer prompts, LayerFlow generates videos for the transparent
foreground, clean background, and blended scene. It also supports versatile
variants like decomposing a blended video or generating the background for the
given foreground and vice versa. Starting from a text-to-video diffusion
transformer, we organize the videos for different layers as sub-clips, and
leverage layer embeddings to distinguish each clip and the corresponding
layer-wise prompts. In this way, we seamlessly support the aforementioned
variants in one unified framework. For the lack of high-quality layer-wise
training videos, we design a multi-stage training strategy to accommodate
static images with high-quality layer annotations. Specifically, we first train
the model with low-quality video data. Then, we tune a motion LoRA to make the
model compatible with static frames. Afterward, we train the content LoRA on
the mixture of image data with high-quality layered images along with
copy-pasted video data. During inference, we remove the motion LoRA thus
generating smooth videos with desired layers.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [453] [Parallel CPU-GPU Execution for LLM Inference on Constrained GPUs](https://arxiv.org/abs/2506.03296)
*Jiakun Fan,Yanglin Zhang,Xiangchen Li,Dimitrios S. Nikolopoulos*

Main category: cs.DC

TL;DR: APEX是一种新型调度策略，通过动态分配CPU和GPU任务，优化混合LLM推理中的并行性，显著提升内存受限硬件上的推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有调度器在混合GPU-CPU执行中无法有效重叠CPU卸载任务与GPU执行，导致解码阶段性能瓶颈，尤其影响实时应用。

Method: APEX采用基于性能分析的动态调度策略，预测CPU和GPU子任务执行时间以最大化并行性，同时避免调度开销。

Result: 在T4和A10 GPU上，APEX比纯GPU调度器提升吞吐量84%-96%和11%-89%，比现有混合调度器在长输出场景下提升49%和37%。

Conclusion: APEX显著提升了混合LLM推理效率，为异构AI系统调度提供了蓝图，填补了实时LLM应用的效率缺口。

Abstract: Deploying large language models (LLMs) for online inference is often
constrained by limited GPU memory, particularly due to the growing KV cache
during auto-regressive decoding. Hybrid GPU-CPU execution has emerged as a
promising solution by offloading KV cache management and parts of attention
computation to the CPU. However, a key bottleneck remains: existing schedulers
fail to effectively overlap CPU-offloaded tasks with GPU execution during the
latency-critical, bandwidth-bound decode phase. This particularly penalizes
real-time, decode-heavy applications (e.g., chat, Chain-of-Thought reasoning)
which are currently underserved by existing systems, especially under memory
pressure typical of edge or low-cost deployments.
  We present APEX, a novel, profiling-informed scheduling strategy that
maximizes CPU-GPU parallelism during hybrid LLM inference. Unlike systems
relying on static rules or purely heuristic approaches, APEX dynamically
dispatches compute across heterogeneous resources by predicting execution times
of CPU and GPU subtasks to maximize overlap while avoiding scheduling
overheads.We evaluate APEX on diverse workloads and GPU architectures (NVIDIA
T4, A10), using LLaMa-2-7B and LLaMa-3.1-8B models. Compared to GPU-only
schedulers like VLLM, APEX improves throughput by 84% - 96% on T4 and 11% - 89%
on A10 GPUs, while preserving latency. Against the best existing hybrid
schedulers, it delivers up to 49% (T4) and 37% (A10) higher throughput in
long-output settings.APEX significantly advances hybrid LLM inference
efficiency on such memory-constrained hardware and provides a blueprint for
scheduling in heterogeneous AI systems, filling a critical gap for efficient
real-time LLM applications.

</details>


### [454] [The Cloud Next Door: Investigating the Environmental and Socioeconomic Strain of Datacenters on Local Communities](https://arxiv.org/abs/2506.03367)
*Wacuka Ngata,Noman Bashir,Michelle Westerlaken,Laurent Liote,Yasra Chandio,Elsa Olivetti*

Main category: cs.DC

TL;DR: 该论文探讨了数据中心扩张对当地社区的社会环境影响，通过混合方法研究揭示了健康、水资源、噪音污染等问题，并呼吁更公平的决策。


<details>
  <summary>Details</summary>
Motivation: 数据中心是现代数字基础设施的核心，但其扩张对当地社区的社会环境影响（如健康、水资源、噪音污染等）被忽视，研究旨在揭示这些问题。

Method: 采用混合方法研究，结合定量数据和定性分析，聚焦弗吉尼亚北部的“数据中心谷”。

Result: 研究发现数据中心增长重塑了当地环境和日常生活，并揭示了权力动态如何决定受益者和成本承担者。

Conclusion: 研究呼吁提高对这些影响的关注，推动更公平和明智的数字基础设施决策。

Abstract: Datacenters have become the backbone of modern digital infrastructure,
powering the rapid rise of artificial intelligence and promising economic
growth and technological progress. However, this expansion has brought growing
tensions in the local communities where datacenters are already situated or
being proposed. While the mainstream discourse often focuses on energy usage
and carbon footprint of the computing sector at a global scale, the local
socio-environmental consequences -- such as health impacts, water usage, noise
pollution, infrastructural strain, and economic burden -- remain largely
underexplored and poorly addressed. In this work, we surface these
community-level consequences through a mixed-methods study that combines
quantitative data with qualitative insights. Focusing on Northern Virginia's
``Data Center Valley,'' we highlight how datacenter growth reshapes local
environments and everyday life, and examine the power dynamics that determine
who benefits and who bears the costs. Our goal is to bring visibility to these
impacts and prompt more equitable and informed decisions about the future of
digital infrastructure.

</details>


### [455] [LRScheduler: A Layer-aware and Resource-adaptive Container Scheduler in Edge Computing](https://arxiv.org/abs/2506.03694)
*Zhiqing Tang,Wentao Peng,Jianxiong Guo,Jiong Lou,Hanshuai Cui,Tian Wang,Yuan Wu,Weijia Jia*

Main category: cs.DC

TL;DR: 论文提出了一种轻量级容器调度器LRScheduler，用于边缘计算中优化容器部署成本和启动时间。


<details>
  <summary>Details</summary>
Motivation: 现有研究对容器镜像层共享调度的理论探讨较多，但缺乏实际实现，边缘计算中带宽有限，需减少部署成本。

Method: 设计并实现基于容器镜像层信息的节点评分和调度机制，动态加权资源自适应机制以增强负载均衡。

Result: 测试表明，LRScheduler能有效降低容器部署成本，优于默认调度器。

Conclusion: LRScheduler在边缘计算中实现了高效的容器调度和资源利用。

Abstract: Lightweight containers provide an efficient approach for deploying
computation-intensive applications in network edge. The layered storage
structure of container images can further reduce the deployment cost and
container startup time. Existing researches discuss layer sharing scheduling
theoretically but with little attention paid to the practical implementation.
To fill in this gap, we propose and implement a Layer-aware and
Resource-adaptive container Scheduler (LRScheduler) in edge computing.
Specifically, we first utilize container image layer information to design and
implement a node scoring and container scheduling mechanism. This mechanism can
effectively reduce the download cost when deploying containers, which is very
important in edge computing with limited bandwidth. Then, we design a
dynamically weighted and resource-adaptive mechanism to enhance load balancing
in edge clusters, increasing layer sharing scores when resource load is low to
use idle resources effectively. Our scheduler is built on the scheduling
framework of Kubernetes, enabling full process automation from task information
acquisition to container dep=loyment. Testing on a real system has shown that
our design can effectively reduce the container deployment cost as compared
with the default scheduler.

</details>


### [456] [SLURM Heterogeneous Jobs for Hybrid Classical-Quantum Workflows](https://arxiv.org/abs/2506.03846)
*Aniello Esposito,Utz-Uwe Haus*

Main category: cs.DC

TL;DR: 提出了一种基于超级计算机标准工具的高效混合经典-量子工作流调度方法，用户需适度干预以减少量子资源闲置时间和整体工作流执行时间。


<details>
  <summary>Details</summary>
Motivation: 解决混合经典-量子工作流中量子资源闲置和整体执行时间过长的问题。

Method: 将整体工作流拆分为基本构建块并确保数据流，利用超级计算机标准工具进行调度。

Result: 显著减少量子资源闲置时间和工作流整体执行时间。

Conclusion: 该方法简单有效，适用于混合经典-量子工作流的调度优化。

Abstract: A method for efficient scheduling of hybrid classical-quantum workflows is
presented, based on standard tools available on common supercomputer systems.
Moderate interventions by the user are required, such as splitting a monolithic
workflow in to basic building blocks and ensuring the data flow. This bares the
potential to significantly reduce idle time of the quantum resource as well as
overall wall time of co-scheduled workflows. Relevant pseudo-code samples and
scripts are provided to demonstrate the simplicity and working principles of
the method.

</details>


### [457] [Analysis of Server Throughput For Managed Big Data Analytics Frameworks](https://arxiv.org/abs/2506.03854)
*Emmanouil Anagnostakis,Polyvios Pratikakis*

Main category: cs.DC

TL;DR: 论文分析了大数据框架中内存管理和GC开销问题，提出通过TeraHeap减少GC和序列化/反序列化开销，以提高服务器吞吐量。


<details>
  <summary>Details</summary>
Motivation: 大数据框架（如Spark和Giraph）因内存压力和GC开销导致CPU利用率低，现有解决方案（如增加内存或对象卸载）存在资源浪费或性能瓶颈。

Method: 使用TeraHeap将对象从Java堆（H1）迁移到快速存储设备上的二级堆（H2），减少GC开销并消除序列化/反序列化。实验通过调整DRAM分配策略（H1与Page Cache的比例）和不同内存配置评估性能。

Result: 实验表明，TeraHeap能有效减少GC和序列化/反序列化开销，提高服务器吞吐量，尤其是在内存受限的场景下。

Conclusion: 通过优化内存管理和减少GC开销，TeraHeap能显著提升大数据框架的CPU利用率和服务器吞吐量。

Abstract: Managed big data frameworks, such as Apache Spark and Giraph demand a large
amount of memory per core to process massive volume datasets effectively. The
memory pressure that arises from the big data processing leads to high garbage
collection (GC) overhead. Big data analytics frameworks attempt to remove this
overhead by offloading objects to storage devices. At the same time,
infrastructure providers, trying to address the same problem, attribute more
memory to increase memory per instance leaving cores underutilized. For
frameworks, trying to avoid GC through offloading to storage devices leads to
high Serialization/Deserialization (S/D) overhead. For infrastructure, the
result is that resource usage is decreased. These limitations prevent managed
big data frameworks from effectively utilizing the CPU thus leading to low
server throughput.
  We conduct a methodological analysis of server throughput for managed big
data analytics frameworks. More specifically, we examine, whether reducing GC
and S/D can help increase the effective CPU utilization of the server. We use a
system called TeraHeap that moves objects from the Java managed heap (H1) to a
secondary heap over a fast storage device (H2) to reduce the GC overhead and
eliminate S/D over data. We focus on analyzing the system's performance under
the co-location of multiple memory-bound instances to utilize all available
DRAM and study server throughput. Our detailed methodology includes choosing
the DRAM budget for each instance and how to distribute this budget among H1
and Page Cache (PC). We try two different distributions for the DRAM budget,
one with more H1 and one with more PC to study the needs of both approaches. We
evaluate both techniques under 3 different memory-per-core scenarios using
Spark and Giraph with native JVM or JVM with TeraHeap. We do this to check
throughput changes when memory capacity increases.

</details>


### [458] [An Efficient Candidate-Free R-S Set Similarity Join Algorithm with the Filter-and-Verification Tree and MapReduce](https://arxiv.org/abs/2506.03893)
*Yuhong Feng,Fangcao Jian,Yixuan Cao,Xiaobin Jian,Jia Wang,Haiyue Feng,Chunyan Miao*

Main category: cs.DC

TL;DR: 论文提出了一种候选集自由的两阶段R-S连接算法（CF-RS-Join），通过过滤-验证树（FVT）及其线性变体（LFVT）将过滤和验证合并为单阶段处理，显著减少了I/O和验证开销。


<details>
  <summary>Details</summary>
Motivation: 现有R-S连接算法在并行和分布式框架下仍存在候选集过多的问题，导致性能下降。

Method: 提出CF-RS-Join/FVT和CF-RS-Join/LFVT算法，分别利用FVT和LFVT结构压缩数据并实现单阶段处理；进一步扩展为MapReduce版本MR-CF-RS-Join/FVT和MR-CF-RS-Join/LFVT。

Result: 实验表明，MR-CF-RS-Join/LFVT在7个真实数据集上表现最佳，优于现有算法。

Conclusion: CF-RS-Join算法通过消除候选集生成和优化数据结构，显著提升了R-S连接的性能和可扩展性。

Abstract: Given two different collections of sets, the exact set similarity R-S Join
finds all set pairs with similarity no less than a given threshold, which has
widespread applications. While existing algorithms accelerate large-scale R-S
Joins using a two-stage filter-and-verification framework along with the
parallel and distributed MapReduce framework, they suffer from excessive
candidate set pairs, leading to significant I/O, data transfer, and
verification overhead, and ultimately degrading the performance. This paper
proposes novel candidate-free R-S Join (CF-RS-Join) algorithms that integrate
filtering and verification into a single stage through filter-and-verification
trees (FVTs) and their linear variants (LFVTs). First, CF-RS-Join with FVT
(CF-RS-Join/FVT) is proposed to leverage an innovative FVT structure that
compresses elements and associated sets in memory, enabling single-stage
processing that eliminates the candidate set generation, fast lookups, and
reduced database scans. Correctness proofs are provided. Second, CF-RS-Join
with LFVT (CF-RS-Join/LFVT) is proposed to exploit a more compact Linear FVT,
which compresses non-branching paths into single nodes and stores them in
linear arrays for optimized traversal. Third, MR-CF-RS-Join/FVT and
MR-CF-RS-Join/LFVT have been proposed to extend our approaches using MapReduce
for parallel processing. Empirical studies on 7 real-world datasets have been
conducted to evaluate the performance of the proposed algorithms against
selected existing algorithms in terms of execution time, scalability, memory
usage, and disk usage. Experimental results demonstrate that our algorithm
using MapReduce, i.e., MR-CF-RS-Join/LFVT, achieves the best performance.

</details>


### [459] [Energy-Aware Workflow Execution: An Overview of Techniques for Saving Energy and Emissions in Scientific Compute Clusters](https://arxiv.org/abs/2506.04062)
*Lauritz Thamsen,Yehia Elkhatib,Paul Harvey,Syed Waqar Nabi,Jeremy Singer,Wim Vanderbauwhede*

Main category: cs.DC

TL;DR: 论文探讨了科学工作流系统的环境足迹问题，提出了减少能耗和碳排放的技术方法。


<details>
  <summary>Details</summary>
Motivation: 科学工作流系统因大规模数据分析需求而广泛使用，但其高能耗和碳排放对环境造成显著影响，亟需解决。

Method: 通过分析三个真实科学工作流的碳排放，提出多种节能技术，如高效异构架构、代码优化、处理器调频、负载整合和高效调度。

Result: 研究表明，这些技术能有效降低工作流任务的能耗和碳排放。

Conclusion: 通过优化技术手段，科学工作流系统可以显著减少环境足迹，助力碳减排目标。

Abstract: Scientific research in many fields routinely requires the analysis of large
datasets, and scientists often employ workflow systems to leverage clusters of
computers for their data analysis. However, due to their size and scale, these
workflow applications can have a considerable environmental footprint in terms
of compute resource use, energy consumption, and carbon emissions. Mitigating
this is critical in light of climate change and the urgent need to reduce
carbon emissions.
  In this chapter, we exemplify the problem by estimating the carbon footprint
of three real-world scientific workflows from different scientific domains. We
then describe techniques for reducing the energy consumption and, thereby,
carbon footprint of individual workflow tasks and entire workflow applications,
such as using energy-efficient heterogeneous architectures, generating
optimised code, scaling processor voltages and frequencies, consolidating
workloads on shared cluster nodes, and scheduling workloads for optimised
energy efficiency.

</details>


### [460] [Carbon-Aware Temporal Data Transfer Scheduling Across Cloud Datacenters](https://arxiv.org/abs/2506.04117)
*Elvis Rodrigues,Jacob Goldverg,Tevfik Kosar*

Main category: cs.DC

TL;DR: LinTS是一种新型碳感知时间数据传输调度框架，显著降低云数据中心间数据传输的碳排放。


<details>
  <summary>Details</summary>
Motivation: 云数据中心间通信产生大量碳排放，环境影响已成为紧迫问题。

Method: LinTS通过生成竞争性传输调度和扩展决策，优于常见启发式算法。

Result: LinTS可将碳排放降低最多66%（与最差情况相比）和15%（与其他解决方案相比），同时满足所有截止时间约束。

Conclusion: LinTS是一种高效且环保的云数据中心间数据传输调度解决方案。

Abstract: Inter-datacenter communication is a significant part of cloud operations and
produces a substantial amount of carbon emissions for cloud data centers, where
the environmental impact has already been a pressing issue. In this paper, we
present a novel carbon-aware temporal data transfer scheduling framework,
called LinTS, which promises to significantly reduce the carbon emission of
data transfers between cloud data centers. LinTS produces a competitive
transfer schedule and makes scaling decisions, outperforming common heuristic
algorithms. LinTS can lower carbon emissions during inter-datacenter transfers
by up to 66% compared to the worst case and up to 15% compared to other
solutions while preserving all deadline constraints.

</details>


### [461] [Cascadia: A Cascade Serving System for Large Language Models](https://arxiv.org/abs/2506.04203)
*Youhe Jiang,Fangcheng Fu,Wanru Zhao,Stephan Rabanser,Nicholas D. Lane,Binhang Yuan*

Main category: cs.DC

TL;DR: Cascadia是一个新型级联服务框架，通过双层优化方法调度请求路由和部署模型级联，显著提升LLM服务的响应速度和吞吐量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在响应速度和质量之间存在权衡，现有框架难以高效处理资源需求、工作负载异构性及系统部署与路由策略的协同优化。

Method: Cascadia采用双层优化：内层通过混合整数线性程序选择资源分配和并行策略；外层使用加权Tchebycheff算法协同优化路由策略和系统部署。

Result: 在多样化工作负载和模型级联（如DeepSeek和Llama系列）上，Cascadia显著优于单模型部署和现有基线，平均提升2.3倍延迟SLO和2.4倍吞吐量。

Conclusion: Cascadia为LLM服务提供了一种高效、质量保持的级联调度和部署解决方案。

Abstract: Recent advances in large language models (LLMs) have intensified the need to
deliver both rapid responses and high-quality answers. More powerful models
yield better results but incur higher inference latency, whereas smaller models
are faster yet less capable. Recent work proposes balancing this
latency-quality trade-off using model cascades, which route simpler queries to
smaller models and more complex ones to larger models. However, enabling
efficient cascade serving remains challenging. Current frameworks lack
effective mechanisms for handling (i) the huge and varying resource demands of
different LLMs, (ii) the inherent heterogeneity of LLM workloads, and (iii) the
co-optimization of system deployment and routing strategy. Motivated by these
observations, we introduce Cascadia, a novel cascade serving framework designed
explicitly to schedule request routing and deploy model cascades for fast,
quality-preserving LLM serving. Cascadia employs a bi-level optimization
method: at the inner level, it uses a mixed-integer linear program to select
resource allocations and parallelism strategies based on LLM information and
workload characteristics; at the outer level, it applies a weighted Tchebycheff
algorithm to iteratively co-optimize the routing strategy and the system
deployment produced by the inner level. Our extensive evaluation on diverse
workload traces and different model cascades (DeepSeek and the Llama series)
demonstrates that Cascadia significantly outperforms both single-model
deployments and the state-of-the-art cascade serving baseline, achieving up to
4x (2.3x on average) tighter latency SLOs and up to 5x (2.4x on average) higher
throughput while maintaining target answer quality.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [462] [Adaptive and Robust Image Processing on CubeSats](https://arxiv.org/abs/2506.03152)
*Robert Bayer,Julian Priest,Daniel Kjellberg,Jeppe Lindhard,Nikolaj Sørenesen,Nicolaj Valsted,Ívar Óli,Pınar Tözün*

Main category: eess.IV

TL;DR: 论文提出了DIPP和DISH两个系统，分别解决CubeSat上图像处理管道的灵活性和资源受限问题。DIPP是模块化框架，支持动态更新；DISH是专用语言，优化资源使用。实验证明两者高效且低开销。


<details>
  <summary>Details</summary>
Motivation: CubeSat资源受限且部署后难以调整，需灵活且高效的图像处理方案。

Method: DIPP提供模块化管道框架，DISH设计专用语言和运行时系统。

Result: DIPP减少更新开销且稳健；DISH内存需求低于Lua，表达能力相当。

Conclusion: DIPP和DISH为CubeSat提供了高效、灵活的图像处理解决方案。

Abstract: CubeSats offer a low-cost platform for space research, particularly for Earth
observation. However, their resource-constrained nature and being in space,
challenge the flexibility and complexity of the deployed image processing
pipelines and their orchestration. This paper introduces two novel systems,
DIPP and DISH, to address these challenges. DIPP is a modular and configurable
image processing pipeline framework that allows for adaptability to changing
mission goals even after deployment, while preserving robustness. DISH is a
domain-specific language (DSL) and runtime system designed to schedule complex
imaging workloads on low-power and memory-constrained processors.
  Our experiments demonstrate that DIPP's decomposition of the processing
pipelines adds negligible overhead, while significantly reducing the network
requirements of updating pipelines and being robust against erroneous module
uploads. Furthermore, we compare DISH to Lua, a general purpose scripting
language, and demonstrate its comparable expressiveness and lower memory
requirement.

</details>


### [463] [Super-temporal-resolution Photoacoustic Imaging with Dynamic Reconstruction through Implicit Neural Representation in Sparse-view](https://arxiv.org/abs/2506.03175)
*Youshen Xiao,Yiling Shi,Ruixi Sun,Hongjiang Wei,Fei Gao,Yuyao Zhang*

Main category: eess.IV

TL;DR: 提出了一种基于隐式神经表示（INR）的动态光声成像重建方法，用于稀疏数据下的高质量成像和提升时间分辨率。


<details>
  <summary>Details</summary>
Motivation: 传统光声成像方法在稀疏数据下产生严重伪影，且未考虑动态成像中的帧间关系，同时时间分辨率受限于激光技术。

Method: 利用INR将动态光声图像表示为隐式函数，并通过神经网络学习稀疏传感器数据，结合低秩和稀疏性正则化。

Result: 在两种稀疏条件下优于传统方法，有效抑制伪影并保证图像质量。

Conclusion: INR方法为稀疏数据下的动态光声成像提供了高质量重建和更高时间分辨率的解决方案。

Abstract: Dynamic Photoacoustic Computed Tomography (PACT) is an important imaging
technique for monitoring physiological processes, capable of providing
high-contrast images of optical absorption at much greater depths than
traditional optical imaging methods. However, practical instrumentation and
geometric constraints limit the number of acoustic sensors available around the
imaging target, leading to sparsity in sensor data. Traditional photoacoustic
(PA) image reconstruction methods, when directly applied to sparse PA data,
produce severe artifacts. Additionally, these traditional methods do not
consider the inter-frame relationships in dynamic imaging. Temporal resolution
is crucial for dynamic photoacoustic imaging, which is fundamentally limited by
the low repetition rate (e.g., 20 Hz) and high cost of high-power laser
technology. Recently, Implicit Neural Representation (INR) has emerged as a
powerful deep learning tool for solving inverse problems with sparse data, by
characterizing signal properties as continuous functions of their coordinates
in an unsupervised manner. In this work, we propose an INR-based method to
improve dynamic photoacoustic image reconstruction from sparse-views and
enhance temporal resolution, using only spatiotemporal coordinates as input.
Specifically, the proposed INR represents dynamic photoacoustic images as
implicit functions and encodes them into a neural network. The weights of the
network are learned solely from the acquired sparse sensor data, without the
need for external training datasets or prior images. Benefiting from the strong
implicit continuity regularization provided by INR, as well as explicit
regularization for low-rank and sparsity, our proposed method outperforms
traditional reconstruction methods under two different sparsity conditions,
effectively suppressing artifacts and ensuring image quality.

</details>


### [464] [Deep Learning-Based Breast Cancer Detection in Mammography: A Multi-Center Validation Study in Thai Population](https://arxiv.org/abs/2506.03177)
*Isarun Chamveha,Supphanut Chaiyungyuen,Sasinun Worakriangkrai,Nattawadee Prasawang,Warasinee Chaisangmongkon,Pornpim Korpraphong,Voraparee Suvannarerg,Shanigarn Thiravit,Chalermdej Kannawat,Kewalin Rungsinaporn,Suwara Issaragrisil,Payia Chadbunchachai,Pattiya Gatechumpol,Chawiporn Muktabhant,Patarachai Sereerat*

Main category: eess.IV

TL;DR: 该研究提出了一种基于改进的EfficientNetV2架构和增强注意力机制的深度学习系统，用于乳腺X光检查中的乳腺癌检测，并在多个数据集上验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 提高乳腺癌筛查的准确性和效率，通过深度学习辅助放射科医生进行乳腺X光检查的解读。

Method: 使用改进的EfficientNetV2架构和增强注意力机制，训练数据来自泰国一家大型医疗中心的乳腺X光片，并在三个不同数据集上验证模型性能。

Result: 模型在癌症检测上的AUROC分别为0.89、0.96和0.94；在病灶定位和临床验证中表现出色，与放射科医生的分类和定位一致性高。

Conclusion: 该系统在乳腺X光检查解读中表现出高效性和临床接受度，有望提升乳腺癌筛查的工作流程。

Abstract: This study presents a deep learning system for breast cancer detection in
mammography, developed using a modified EfficientNetV2 architecture with
enhanced attention mechanisms. The model was trained on mammograms from a major
Thai medical center and validated on three distinct datasets: an in-domain test
set (9,421 cases), a biopsy-confirmed set (883 cases), and an out-of-domain
generalizability set (761 cases) collected from two different hospitals. For
cancer detection, the model achieved AUROCs of 0.89, 0.96, and 0.94 on the
respective datasets. The system's lesion localization capability, evaluated
using metrics including Lesion Localization Fraction (LLF) and Non-Lesion
Localization Fraction (NLF), demonstrated robust performance in identifying
suspicious regions. Clinical validation through concordance tests showed strong
agreement with radiologists: 83.5% classification and 84.0% localization
concordance for biopsy-confirmed cases, and 78.1% classification and 79.6%
localization concordance for out-of-domain cases. Expert radiologists'
acceptance rate also averaged 96.7% for biopsy-confirmed cases, and 89.3% for
out-of-domain cases. The system achieved a System Usability Scale score of
74.17 for source hospital, and 69.20 for validation hospitals, indicating good
clinical acceptance. These results demonstrate the model's effectiveness in
assisting mammogram interpretation, with the potential to enhance breast cancer
screening workflows in clinical practice.

</details>


### [465] [LLaMA-XR: A Novel Framework for Radiology Report Generation using LLaMA and QLoRA Fine Tuning](https://arxiv.org/abs/2506.03178)
*Md. Zihad Bin Jahangir,Muhammad Ashad Kabir,Sumaiya Akter,Israt Jahan,Minh Chau*

Main category: eess.IV

TL;DR: LLaMA-XR是一种结合LLaMA 3.1和DenseNet-121图像嵌入的新型框架，通过QLoRA微调提升放射报告生成的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 减少放射科医生的工作量并提高诊断准确性，但现有模型在保持准确性和上下文相关性方面存在挑战。

Method: 整合LLaMA 3.1与DenseNet-121图像嵌入，采用QLoRA微调和优化策略提升参数利用率和计算效率。

Result: 在IU X-ray数据集上，LLaMA-XR的ROUGE-L得分为0.433，METEOR得分为0.336，优于现有方法。

Conclusion: LLaMA-XR是一种高效且准确的AI系统，具有临床实用性和可靠性。

Abstract: Automated radiology report generation holds significant potential to reduce
radiologists' workload and enhance diagnostic accuracy. However, generating
precise and clinically meaningful reports from chest radiographs remains
challenging due to the complexity of medical language and the need for
contextual understanding. Existing models often struggle with maintaining both
accuracy and contextual relevance. In this paper, we present LLaMA-XR, a novel
framework that integrates LLaMA 3.1 with DenseNet-121-based image embeddings
and Quantized Low-Rank Adaptation (QLoRA) fine-tuning. LLaMA-XR achieves
improved coherence and clinical accuracy while maintaining computational
efficiency. This efficiency is driven by an optimization strategy that enhances
parameter utilization and reduces memory overhead, enabling faster report
generation with lower computational resource demands. Extensive experiments
conducted on the IU X-ray benchmark dataset demonstrate that LLaMA-XR
outperforms a range of state-of-the-art methods. Our model achieves a ROUGE-L
score of 0.433 and a METEOR score of 0.336, establishing new performance
benchmarks in the domain. These results underscore LLaMA-XR's potential as an
effective and efficient AI system for automated radiology reporting, offering
enhanced clinical utility and reliability.

</details>


### [466] [Dc-EEMF: Pushing depth-of-field limit of photoacoustic microscopy via decision-level constrained learning](https://arxiv.org/abs/2506.03181)
*Wangting Zhou,Jiangshan He,Tong Cai,Lin Wang,Zhen Yuan,Xunbin Wei,Xueli Chen*

Main category: eess.IV

TL;DR: 提出了一种基于决策级约束的端到端多焦点图像融合方法（Dc-EEMF），用于突破光声显微镜（PAM）的景深限制。


<details>
  <summary>Details</summary>
Motivation: 传统光学分辨率光声显微镜（OR-PAM）因高斯光束的有限景深（DoF）而无法在深度方向解析足够细节，限制了其在生物医学研究中的应用。

Method: 采用轻量级Siamese网络，结合抗伪影的通道空间频率特征融合规则，并设计了基于U-Net的感知损失函数，实现端到端融合。

Result: 实验和数值分析表明，该方法在保持横向分辨率的同时，实现了PAM图像的优异融合效果。

Conclusion: Dc-EEMF驱动的PAM有望成为需要扩展景深的临床和临床前研究的实用工具。

Abstract: Photoacoustic microscopy holds the potential to measure biomarkers'
structural and functional status without labels, which significantly aids in
comprehending pathophysiological conditions in biomedical research. However,
conventional optical-resolution photoacoustic microscopy (OR-PAM) is hindered
by a limited depth-of-field (DoF) due to the narrow depth range focused on a
Gaussian beam. Consequently, it fails to resolve sufficient details in the
depth direction. Herein, we propose a decision-level constrained end-to-end
multi-focus image fusion (Dc-EEMF) to push DoF limit of PAM. The DC-EEMF method
is a lightweight siamese network that incorporates an artifact-resistant
channel-wise spatial frequency as its feature fusion rule. The meticulously
crafted U-Net-based perceptual loss function for decision-level focus
properties in end-to-end fusion seamlessly integrates the complementary
advantages of spatial domain and transform domain methods within Dc-EEMF. This
approach can be trained end-to-end without necessitating post-processing
procedures. Experimental results and numerical analyses collectively
demonstrate our method's robust performance, achieving an impressive fusion
result for PAM images without a substantial sacrifice in lateral resolution.
The utilization of Dc-EEMF-powered PAM has the potential to serve as a
practical tool in preclinical and clinical studies requiring extended DoF for
various applications.

</details>


### [467] [Edge Computing for Physics-Driven AI in Computational MRI: A Feasibility Study](https://arxiv.org/abs/2506.03183)
*Yaşar Utku Alçalar,Yu Cao,Mehmet Akçakaya*

Main category: eess.IV

TL;DR: 论文提出了一种针对FPGA边缘计算优化的PD-AI MRI重建方法，通过8位复数数据量化和消除冗余FFT/IFFT操作，提高了计算效率，同时保持了重建质量。


<details>
  <summary>Details</summary>
Motivation: 高分辨率MRI扫描产生大量数据，导致传输、存储和实时处理挑战，尤其是在功能MRI中。边缘计算结合FPGA为解决这些问题提供了可能，但需要优化PD-AI模型以提高硬件效率。

Method: 提出了一种针对FPGA优化的PD-AI计算方法，采用8位复数数据量化并消除冗余FFT/IFFT操作。

Result: 该方法在计算效率上有所提升，重建质量与传统PD-AI方法相当，且优于标准临床方法。

Conclusion: 该方法为资源受限设备上的高分辨率MRI重建提供了可能，展示了实际部署的潜力。

Abstract: Physics-driven artificial intelligence (PD-AI) reconstruction methods have
emerged as the state-of-the-art for accelerating MRI scans, enabling higher
spatial and temporal resolutions. However, the high resolution of these scans
generates massive data volumes, leading to challenges in transmission, storage,
and real-time processing. This is particularly pronounced in functional MRI,
where hundreds of volumetric acquisitions further exacerbate these demands.
Edge computing with FPGAs presents a promising solution for enabling PD-AI
reconstruction near the MRI sensors, reducing data transfer and storage
bottlenecks. However, this requires optimization of PD-AI models for hardware
efficiency through quantization and bypassing traditional FFT-based approaches,
which can be a limitation due to their computational demands. In this work, we
propose a novel PD-AI computational MRI approach optimized for FPGA-based edge
computing devices, leveraging 8-bit complex data quantization and eliminating
redundant FFT/IFFT operations. Our results show that this strategy improves
computational efficiency while maintaining reconstruction quality comparable to
conventional PD-AI methods, and outperforms standard clinical methods. Our
approach presents an opportunity for high-resolution MRI reconstruction on
resource-constrained devices, highlighting its potential for real-world
deployment.

</details>


### [468] [DLiPath: A Benchmark for the Comprehensive Assessment of Donor Liver Based on Histopathological Image Dataset](https://arxiv.org/abs/2506.03185)
*Liangrui Pan,Xingchen Li,Zhongyi Chen,Ling Chu,Shaoliang Peng*

Main category: eess.IV

TL;DR: DLiPath是首个基于组织病理学图像数据集的供体肝脏评估基准，通过多实例学习模型实现高精度评估，减少人工评估的变异性。


<details>
  <summary>Details</summary>
Motivation: 供体肝脏活检的快速准确评估对移植决策至关重要，但人工评估存在显著的观察者间和观察者内变异性。

Method: 收集并公开了304名供体肝脏患者的636张全切片图像，标注关键病理特征，并基于此数据集评估了九种多实例学习模型。

Result: 多个多实例学习模型在DLiPath数据集上实现了高精度评估，为未来自动化研究提供了方向。

Conclusion: DLiPath为供体肝脏的智能评估提供了基准，展示了多实例学习模型在此领域的潜力。

Abstract: Pathologists comprehensive evaluation of donor liver biopsies provides
crucial information for accepting or discarding potential grafts. However,
rapidly and accurately obtaining these assessments intraoperatively poses a
significant challenge for pathologists. Features in donor liver biopsies, such
as portal tract fibrosis, total steatosis, macrovesicular steatosis, and
hepatocellular ballooning are correlated with transplant outcomes, yet
quantifying these indicators suffers from substantial inter- and intra-observer
variability. To address this, we introduce DLiPath, the first benchmark for
comprehensive donor liver assessment based on a histopathology image dataset.
We collected and publicly released 636 whole slide images from 304 donor liver
patients at the Department of Pathology, the Third Xiangya Hospital, with
expert annotations for key pathological features (including cholestasis, portal
tract fibrosis, portal inflammation, total steatosis, macrovesicular steatosis,
and hepatocellular ballooning). We selected nine state-of-the-art
multiple-instance learning (MIL) models based on the DLiPath dataset as
baselines for extensive comparative analysis. The experimental results
demonstrate that several MIL models achieve high accuracy across donor liver
assessment indicators on DLiPath, charting a clear course for future automated
and intelligent donor liver assessment research. Data and code are available at
https://github.com/panliangrui/ACM_MM_2025.

</details>


### [469] [Lightweight Convolutional Neural Networks for Retinal Disease Classification](https://arxiv.org/abs/2506.03186)
*Duaa Kareem Qasim,Sabah Abdulazeez Jebur,Lafta Raheem Ali,Abdul Jalil M. Khalaf,Abir Jaafar Hussain*

Main category: eess.IV

TL;DR: 该论文使用MobileNet和NASNetMobile两种轻量级CNN架构，对正常、糖尿病视网膜病变（DR）和黄斑裂孔（MH）的视网膜图像进行分类，MobileNetV2达到90.8%的准确率。


<details>
  <summary>Details</summary>
Motivation: 早期检测DR和MH对预防视力损害至关重要，但传统方法效率低。

Method: 使用MobileNet和NASNetMobile模型，在RFMiD数据集上训练，采用预处理、迁移学习和数据增强技术。

Result: MobileNetV2表现最佳，准确率90.8%，NASNetMobile为89.5%。

Conclusion: CNN在视网膜疾病分类中高效，为AI辅助眼科诊断奠定基础。

Abstract: Retinal diseases such as Diabetic Retinopathy (DR) and Macular Hole (MH)
significantly impact vision and affect millions worldwide. Early detection is
crucial, as DR, a complication of diabetes, damages retinal blood vessels,
potentially leading to blindness, while MH disrupts central vision, affecting
tasks like reading and facial recognition. This paper employed two lightweight
and efficient Convolution Neural Network architectures, MobileNet and
NASNetMobile, for the classification of Normal, DR, and MH retinal images. The
models were trained on the RFMiD dataset, consisting of 3,200 fundus images,
after undergoing preprocessing steps such as resizing, normalization, and
augmentation. To address data scarcity, this study leveraged transfer learning
and data augmentation techniques, enhancing model generalization and
performance. The experimental results demonstrate that MobileNetV2 achieved the
highest accuracy of 90.8%, outperforming NASNetMobile, which achieved 89.5%
accuracy. These findings highlight the effectiveness of CNNs in retinal disease
classification, providing a foundation for AI-assisted ophthalmic diagnosis and
early intervention.

</details>


### [470] [Multi-Analyte, Swab-based Automated Wound Monitor with AI](https://arxiv.org/abs/2506.03188)
*Madhu Babu Sikha,Lalith Appari,Gurudatt Nanjanagudu Ganesh,Amay Bandodkar,Imon Banerjee*

Main category: eess.IV

TL;DR: 开发了一种低成本的多分析物3D打印检测装置和iOS应用，用于早期识别糖尿病足溃疡（DFUs），并通过计算机视觉技术自动分析伤口严重程度。


<details>
  <summary>Details</summary>
Motivation: 糖尿病足溃疡（DFUs）是一种慢性伤口，早期识别非愈合性DFUs可以显著降低治疗成本并减少截肢风险。

Method: 采用3D打印的多分析物检测装置和iOS应用，通过计算机视觉技术比较伤口暴露前后的图像密度变化，自动评估伤口严重程度。

Result: 开发了一种集成传感器和iOS应用，能够实时监测伤口状况、跟踪愈合进展，并提供可操作的见解。

Conclusion: 该技术为医疗专业人员提供了一种低成本、高效的早期诊断工具，有助于改善DFUs的治疗效果。

Abstract: Diabetic foot ulcers (DFUs), a class of chronic wounds, affect ~750,000
individuals every year in the US alone and identifying non-healing DFUs that
develop to chronic wounds early can drastically reduce treatment costs and
minimize risks of amputation. There is therefore a pressing need for diagnostic
tools that can detect non-healing DFUs early. We develop a low cost,
multi-analyte 3D printed assays seamlessly integrated on swabs that can
identify non-healing DFUs and a Wound Sensor iOS App - an innovative mobile
application developed for the controlled acquisition and automated analysis of
wound sensor data. By comparing both the original base image (before exposure
to the wound) and the wound-exposed image, we developed automated computer
vision techniques to compare density changes between the two assay images,
which allow us to automatically determine the severity of the wound. The iOS
app ensures accurate data collection and presents actionable insights, despite
challenges such as variations in camera configurations and ambient conditions.
The proposed integrated sensor and iOS app will allow healthcare professionals
to monitor wound conditions real-time, track healing progress, and assess
critical parameters related to wound care.

</details>


### [471] [Encoding of Demographic and Anatomical Information in Chest X-Ray-based Severe Left Ventricular Hypertrophy Classifiers](https://arxiv.org/abs/2506.03192)
*Basudha Pal,Rama Chellappa,Muhammad Umair*

Main category: eess.IV

TL;DR: 提出一种基于胸部X光片的直接分类框架，用于预测严重左心室肥厚，无需依赖解剖测量或人口统计输入，效果显著且模型可解释性强。


<details>
  <summary>Details</summary>
Motivation: 尽管超声心动图和MRI是评估心脏结构的临床标准，但其成本高且可及性有限，因此需要一种更经济、更易获取的替代方法。

Method: 采用直接分类框架，利用胸部X光片预测严重左心室肥厚，并使用互信息神经估计量化特征表达能力。

Result: 模型在AUROC和AUPRC指标上表现优异，同时揭示了具有临床意义的属性编码。

Conclusion: 该方法为心脏疾病的低成本、高效筛查提供了新思路，且模型具有透明性和可解释性。

Abstract: While echocardiography and MRI are clinical standards for evaluating cardiac
structure, their use is limited by cost and accessibility.We introduce a direct
classification framework that predicts severe left ventricular hypertrophy from
chest X-rays, without relying on anatomical measurements or demographic inputs.
Our approach achieves high AUROC and AUPRC, and employs Mutual Information
Neural Estimation to quantify feature expressivity. This reveals clinically
meaningful attribute encoding and supports transparent model interpretation.

</details>


### [472] [A combined Machine Learning and Finite Element Modelling tool for the surgical planning of craniosynostosis correction](https://arxiv.org/abs/2506.03202)
*Itxasne Antúnez Sáenz,Ane Alberdi Aramendi,David Dunaway,Juling Ong,Lara Deliège,Amparo Sáenz,Anita Ahmadi Birjandi,Noor UI Owase Jeelani,Silvia Schievano,Alessandro Borghi*

Main category: eess.IV

TL;DR: 研究开发了一种基于机器学习的实时预测工具，用于颅缝早闭手术结果，减少CT扫描需求。


<details>
  <summary>Details</summary>
Motivation: 目前颅缝早闭手术结果难以预测，依赖医生经验和有限工具，需减少辐射暴露并提高效率。

Method: 基于3D照片创建个性化合成颅骨，结合人群平均数据，使用机器学习模型预测手术结果。

Result: 多输出支持向量回归模型R2达0.95，MSE和MAE低于0.13。

Conclusion: 该工具可优化手术参数，未来有望模拟多种手术场景并提升颅骨指数。

Abstract: Craniosynostosis is a medical condition that affects the growth of babies'
heads, caused by an early fusion of cranial sutures. In recent decades,
surgical treatments for craniosynostosis have significantly improved, leading
to reduced invasiveness, faster recovery, and less blood loss. At Great Ormond
Street Hospital (GOSH), the main surgical treatment for patients diagnosed with
sagittal craniosynostosis (SC) is spring assisted cranioplasty (SAC). This
procedure involves a 15x15 mm2 osteotomy, where two springs are inserted to
induce distraction. Despite the numerous advantages of this surgical technique
for patients, the outcome remains unpredictable due to the lack of efficient
preoperative planning tools. The surgeon's experience and the baby's age are
currently relied upon to determine the osteotomy location and spring selection.
Previous tools for predicting the surgical outcome of SC relied on finite
element modeling (FEM), which involved computed tomography (CT) imaging and
required engineering expertise and lengthy calculations. The main goal of this
research is to develop a real-time prediction tool for the surgical outcome of
patients, eliminating the need for CT scans to minimise radiation exposure
during preoperative planning. The proposed methodology involves creating
personalised synthetic skulls based on three-dimensional (3D) photographs,
incorporating population average values of suture location, skull thickness,
and soft tissue properties. A machine learning (ML) surrogate model is employed
to achieve the desired surgical outcome. The resulting multi-output support
vector regressor model achieves a R2 metric of 0.95 and MSE and MAE below 0.13.
Furthermore, in the future, this model could not only simulate various surgical
scenarios but also provide optimal parameters for achieving a maximum cranial
index (CI).

</details>


### [473] [A Survey of Deep Learning Video Super-Resolution](https://arxiv.org/abs/2506.03216)
*Arbind Agrahari Baniya,Tsz-Kwan Lee,Peter Eklund,Sunil Aryal*

Main category: eess.IV

TL;DR: 本文对基于深度学习的视频超分辨率（VSR）模型进行了全面综述，分析了其组件、方法及挑战，并提出了多级分类法以指导未来研究。


<details>
  <summary>Details</summary>
Motivation: 由于VSR在多个领域具有潜在影响力，且现有方法的使用和决策缺乏充分解释，需对VSR研究中的深度学习方法和组件进行系统分析，以支持针对特定需求的模型开发。

Method: 通过综述和系统分类现有VSR模型，分析其关键组件和技术，并建立多级分类法。

Result: 识别了VSR领域的趋势、需求与挑战，并提出了首个基于深度学习的VSR模型分类法。

Conclusion: 本研究为VSR实践提供了系统化的指导，有助于推动该领域的成熟和实际应用。

Abstract: Video super-resolution (VSR) is a prominent research topic in low-level
computer vision, where deep learning technologies have played a significant
role. The rapid progress in deep learning and its applications in VSR has led
to a proliferation of tools and techniques in the literature. However, the
usage of these methods is often not adequately explained, and decisions are
primarily driven by quantitative improvements. Given the significance of VSR's
potential influence across multiple domains, it is imperative to conduct a
comprehensive analysis of the elements and deep learning methodologies employed
in VSR research. This methodical analysis will facilitate the informed
development of models tailored to specific application needs. In this paper, we
present an overarching overview of deep learning-based video super-resolution
models, investigating each component and discussing its implications.
Furthermore, we provide a synopsis of key components and technologies employed
by state-of-the-art and earlier VSR models. By elucidating the underlying
methodologies and categorising them systematically, we identified trends,
requirements, and challenges in the domain. As a first-of-its-kind survey of
deep learning-based VSR models, this work also establishes a multi-level
taxonomy to guide current and future VSR research, enhancing the maturation and
interpretation of VSR practices for various practical applications.

</details>


### [474] [petBrain: A New Pipeline for Amyloid, Tau Tangles and Neurodegeneration Quantification Using PET and MRI](https://arxiv.org/abs/2506.03217)
*Pierrick Coupé,Boris Mansencal,Floréal Morandat,Sergio Morell-Ortega,Nicolas Villain,Jose V. Manjón,Vincent Planche*

Main category: eess.IV

TL;DR: petBrain是一个基于深度学习的端到端处理管道，用于标准化阿尔茨海默病生物标志物分析，支持淀粉样蛋白-PET、tau-PET和结构MRI。


<details>
  <summary>Details</summary>
Motivation: 现有管道在处理时间、示踪剂类型多样性和多模态整合方面存在局限性，需要更高效的解决方案。

Method: 开发了petBrain，利用深度学习分割、标准化生物标志物量化和同时估计A/T2/N生物标志物，实现为无需本地基础设施的Web平台。

Result: petBrain提供快速可靠的生物标志物量化，结果与现有管道相当，并与ADNI数据库数据及临床指标一致。

Conclusion: petBrain是一个强大且开放的平台，有助于标准化AD生物标志物分析，推动临床研究应用。

Abstract: INTRODUCTION: Quantification of amyloid plaques (A), neurofibrillary tangles
(T2), and neurodegeneration (N) using PET and MRI is critical for Alzheimer's
disease (AD) diagnosis and prognosis. Existing pipelines face limitations
regarding processing time, variability in tracer types, and challenges in
multimodal integration.
  METHODS: We developed petBrain, a novel end-to-end processing pipeline for
amyloid-PET, tau-PET, and structural MRI. It leverages deep learning-based
segmentation, standardized biomarker quantification (Centiloid, CenTauR,
HAVAs), and simultaneous estimation of A, T2, and N biomarkers. The pipeline is
implemented as a web-based platform, requiring no local computational
infrastructure or specialized software knowledge.
  RESULTS: petBrain provides reliable and rapid biomarker quantification, with
results comparable to existing pipelines for A and T2. It shows strong
concordance with data processed in ADNI databases. The staging and
quantification of A/T2/N by petBrain demonstrated good agreement with
CSF/plasma biomarkers, clinical status, and cognitive performance.
  DISCUSSION: petBrain represents a powerful and openly accessible platform for
standardized AD biomarker analysis, facilitating applications in clinical
research.

</details>


### [475] [Rethinking Whole-Body CT Image Interpretation: An Abnormality-Centric Approach](https://arxiv.org/abs/2506.03238)
*Ziheng Zhao,Lisong Dai,Ya Zhang,Yanfeng Wang,Weidi Xie*

Main category: eess.IV

TL;DR: 该论文提出了一种自动化CT图像解释方法，包括分类系统、数据集、模型开发和基准测试，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决临床放射学中多平面和全身CT图像的异常定位和描述的自动化挑战。

Method: 提出分类系统、构建数据集、开发OminiAbnorm-CT模型，并建立临床基准测试。

Result: OminiAbnorm-CT在所有任务和指标上显著优于现有方法。

Conclusion: 该方法为自动化CT图像解释提供了有效解决方案，具有临床应用潜力。

Abstract: Automated interpretation of CT images-particularly localizing and describing
abnormal findings across multi-plane and whole-body scans-remains a significant
challenge in clinical radiology. This work aims to address this challenge
through four key contributions: (i) On taxonomy, we collaborate with senior
radiologists to propose a comprehensive hierarchical classification system,
with 404 representative abnormal findings across all body regions; (ii) On
data, we contribute a dataset containing over 14.5K CT images from multiple
planes and all human body regions, and meticulously provide grounding
annotations for over 19K abnormalities, each linked to the detailed description
and cast into the taxonomy; (iii) On model development, we propose
OminiAbnorm-CT, which can automatically ground and describe abnormal findings
on multi-plane and whole-body CT images based on text queries, while also
allowing flexible interaction through visual prompts; (iv) On benchmarks, we
establish three representative evaluation tasks based on real clinical
scenarios. Through extensive experiments, we show that OminiAbnorm-CT can
significantly outperform existing methods on all the tasks and metrics.

</details>


### [476] [Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images](https://arxiv.org/abs/2506.03420)
*Muhammad Zubair Hasan,Fahmida Yasmin Rifat*

Main category: eess.IV

TL;DR: 提出了一种结合机器学习和深度学习的混合方法，用于分类恶性与良性皮肤病变，使用SLICE-3D数据集，通过特征融合和合成数据增强，取得了最高的部分AUC性能。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌是全球范围内高发且致命的疾病，早期检测对患者预后至关重要。

Method: 结合视觉变换器（EVA02）和卷积ViT混合模型（EdgeNeXtSAC）提取特征，采用分割辅助分类管道，并通过梯度提升决策树（GBDT）融合预测结果。使用合成数据增强和诊断信息重新标记策略解决类别不平衡。

Result: 在部分AUC（pAUC）高于80%真阳性率（TPR）的评估指标下，取得了0.1755的最高pAUC值。

Conclusion: 混合可解释AI系统在远程医疗和资源有限环境中具有皮肤癌分诊的潜力。

Abstract: Skin cancer is among the most prevalent and life-threatening diseases
worldwide, with early detection being critical to patient outcomes. This work
presents a hybrid machine and deep learning-based approach for classifying
malignant and benign skin lesions using the SLICE-3D dataset from ISIC 2024,
which comprises 401,059 cropped lesion images extracted from 3D Total Body
Photography (TBP), emulating non-dermoscopic, smartphone-like conditions. Our
method combines vision transformers (EVA02) and our designed convolutional ViT
hybrid (EdgeNeXtSAC) to extract robust features, employing a
segmentation-assisted classification pipeline to enhance lesion localization.
Predictions from these models are fused with a gradient-boosted decision tree
(GBDT) ensemble enriched by engineered features and patient-specific relational
metrics. To address class imbalance and improve generalization, we augment
malignant cases with Stable Diffusion-generated synthetic lesions and apply a
diagnosis-informed relabeling strategy to harmonize external datasets into a
3-class format. Using partial AUC (pAUC) above 80 percent true positive rate
(TPR) as the evaluation metric, our approach achieves a pAUC of 0.1755 -- the
highest among all configurations. These results underscore the potential of
hybrid, interpretable AI systems for skin cancer triage in telemedicine and
resource-constrained settings.

</details>


### [477] [Identifying Alzheimer's Disease Prediction Strategies of Convolutional Neural Network Classifiers using R2* Maps and Spectral Clustering](https://arxiv.org/abs/2506.03890)
*Christian Tinauer,Maximilian Sackl,Stefan Ropele,Christian Langkammer*

Main category: eess.IV

TL;DR: 研究使用LRP和谱聚类分析深度学习模型在AD分类中的决策策略，发现预处理和训练选择对模型策略有显著影响。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在AD分类中表现优异但缺乏可解释性，需分析其决策策略以避免潜在偏见。

Method: 使用3D卷积神经网络和R2*图，通过LRP生成热力图，并用谱聚类和t-SNE可视化分析决策模式。

Result: 谱聚类揭示了明显的决策模式，基于热力图的模型在AD和NC间区分最清晰。

Conclusion: 预处理和训练选择对模型策略影响显著，谱聚类为医学AI的可解释性提供了有效方法。

Abstract: Deep learning models have shown strong performance in classifying Alzheimer's
disease (AD) from R2* maps, but their decision-making remains opaque, raising
concerns about interpretability. Previous studies suggest biases in model
decisions, necessitating further analysis. This study uses Layer-wise Relevance
Propagation (LRP) and spectral clustering to explore classifier decision
strategies across preprocessing and training configurations using R2* maps. We
trained a 3D convolutional neural network on R2* maps, generating relevance
heatmaps via LRP and applied spectral clustering to identify dominant patterns.
t-Stochastic Neighbor Embedding (t-SNE) visualization was used to assess
clustering structure. Spectral clustering revealed distinct decision patterns,
with the relevance-guided model showing the clearest separation between AD and
normal control (NC) cases. The t-SNE visualization confirmed that this model
aligned heatmap groupings with the underlying subject groups. Our findings
highlight the significant impact of preprocessing and training choices on deep
learning models trained on R2* maps, even with similar performance metrics.
Spectral clustering offers a structured method to identify classification
strategy differences, emphasizing the importance of explainability in medical
AI.

</details>


### [478] [Conformal coronary calcification volume estimation with conditional coverage via histogram clustering](https://arxiv.org/abs/2506.04030)
*Olivier Jaubert,Salman Mohammadi,Keith A. Goatman,Shadia S. Mikhael,Conor Bradley,Rebecca Hughes,Richard Good,John H. Hipwell,Sonia Dahdouh*

Main category: eess.IV

TL;DR: 提出了一种基于聚类的条件共形预测框架，用于从训练好的分割网络中提供校准覆盖的分数区间，无需重新训练。该方法在3D UNet模型上表现优于传统共形预测。


<details>
  <summary>Details</summary>
Motivation: 通过CT扫描偶然检测和量化冠状动脉钙化可能带来早期临床干预，但过度报告可能对患者健康和医疗系统造成负担。因此，需要谨慎处理自动报告钙化分数的问题。

Method: 提出了一种基于聚类的条件共形预测框架，用于校准预测区间，适用于确定性、MCDropout和深度集成3D UNet模型。

Result: 该方法在覆盖率和分流指标上优于传统共形预测，能够提供有意义的钙化分数预测区间。

Conclusion: 该方法有助于根据风险类别预测的置信度对患者进行分流，为临床决策提供支持。

Abstract: Incidental detection and quantification of coronary calcium in CT scans could
lead to the early introduction of lifesaving clinical interventions. However,
over-reporting could negatively affect patient wellbeing and unnecessarily
burden the medical system. Therefore, careful considerations should be taken
when automatically reporting coronary calcium scores. A cluster-based
conditional conformal prediction framework is proposed to provide score
intervals with calibrated coverage from trained segmentation networks without
retraining. The proposed method was tuned and used to calibrate predictive
intervals for 3D UNet models (deterministic, MCDropout and deep ensemble)
reaching similar coverage with better triage metrics compared to conventional
conformal prediction. Meaningful predictive intervals of calcium scores could
help triage patients according to the confidence of their risk category
prediction.

</details>


### [479] [Towards generating more interpretable counterfactuals via concept vectors: a preliminary study on chest X-rays](https://arxiv.org/abs/2506.04058)
*Bulat Maksudov,Kathleen Curran,Alessandra Mileo*

Main category: eess.IV

TL;DR: 该研究提出了一种将临床概念映射到生成模型潜在空间的方法，通过概念激活向量（CAVs）实现无需显式标签训练的临床特征解释。


<details>
  <summary>Details</summary>
Motivation: 确保医学影像模型与临床知识对齐并具有可解释性是部署模型的关键步骤。

Method: 使用简单的重建自编码器，将用户定义的概念与图像级特征关联，提取稳定概念并生成视觉解释。

Result: 在胸部X光片中，该方法对大型病理（如心脏肥大）表现良好，但对小型病理因重建限制效果有限。

Conclusion: 尽管未超越基线方法，但提供了一种与临床知识对齐的可解释概念解释路径。

Abstract: An essential step in deploying medical imaging models is ensuring alignment
with clinical knowledge and interpretability. We focus on mapping clinical
concepts into the latent space of generative models to identify Concept
Activation Vectors (CAVs). Using a simple reconstruction autoencoder, we link
user-defined concepts to image-level features without explicit label training.
The extracted concepts are stable across datasets, enabling visual explanations
that highlight clinically relevant features. By traversing latent space along
concept directions, we produce counterfactuals that exaggerate or reduce
specific clinical features. Preliminary results on chest X-rays show promise
for large pathologies like cardiomegaly, while smaller pathologies remain
challenging due to reconstruction limits. Although not outperforming baselines,
this approach offers a path toward interpretable, concept-based explanations
aligned with clinical knowledge.

</details>


### [480] [A Diffusion-Driven Temporal Super-Resolution and Spatial Consistency Enhancement Framework for 4D MRI imaging](https://arxiv.org/abs/2506.04116)
*Xuanru Zhou,Jiarun Liu,Shoujun Yu,Hao Yang,Cheng Li,Tao Tan,Shanshan Wang*

Main category: eess.IV

TL;DR: TSSC-Net是一种新型框架，用于在4D MRI中生成中间帧，提高时间分辨率并保持空间一致性，适用于快速运动场景。


<details>
  <summary>Details</summary>
Motivation: 传统方法在快速、大幅运动时难以处理大变形，导致配准错误和伪影，需要一种新方法提高时空分辨率。

Method: 采用基于扩散的时间超分辨率网络生成中间帧，并结合三向Mamba模块利用长程上下文信息解决空间不一致问题。

Result: 在ACDC心脏MRI和动态4D膝关节数据集上验证，TSSC-Net能生成高分辨率动态MRI，保持结构保真和空间一致性。

Conclusion: TSSC-Net有效解决了快速运动下4D MRI的时空分辨率问题，具有实际应用潜力。

Abstract: In medical imaging, 4D MRI enables dynamic 3D visualization, yet the
trade-off between spatial and temporal resolution requires prolonged scan time
that can compromise temporal fidelity--especially during rapid, large-amplitude
motion. Traditional approaches typically rely on registration-based
interpolation to generate intermediate frames. However, these methods struggle
with large deformations, resulting in misregistration, artifacts, and
diminished spatial consistency. To address these challenges, we propose
TSSC-Net, a novel framework that generates intermediate frames while preserving
spatial consistency. To improve temporal fidelity under fast motion, our
diffusion-based temporal super-resolution network generates intermediate frames
using the start and end frames as key references, achieving 6x temporal
super-resolution in a single inference step. Additionally, we introduce a novel
tri-directional Mamba-based module that leverages long-range contextual
information to effectively resolve spatial inconsistencies arising from
cross-slice misalignment, thereby enhancing volumetric coherence and correcting
cross-slice errors. Extensive experiments were performed on the public ACDC
cardiac MRI dataset and a real-world dynamic 4D knee joint dataset. The results
demonstrate that TSSC-Net can generate high-resolution dynamic MRI from
fast-motion data while preserving structural fidelity and spatial consistency.

</details>


### [481] [A Comprehensive Study on Medical Image Segmentation using Deep Neural Networks](https://arxiv.org/abs/2506.04121)
*Loan Dao,Ngoc Quoc Ly*

Main category: eess.IV

TL;DR: 本文综述了基于深度神经网络（DNN）的医学图像分割（MIS）的研究进展，重点探讨了DIKIW框架下的最新解决方案，并强调了可解释人工智能（XAI）在提升透明度和伦理需求中的重要性。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割在疾病诊断和早期检测中具有重要作用，尤其是通过及时诊断提高癌症患者的生存率。XAI和早期预测被视为从“智能”到“智慧”的重要步骤。

Method: 研究基于DIKIW框架评估智能视觉系统，并探讨了DNN在MIS中的应用及XAI的作用。

Result: 论文总结了MIS领域的最新进展，并提出了提升DNN-based MIS效率的潜在解决方案。

Conclusion: MIS在医学领域具有广阔前景，XAI和早期预测是关键发展方向，但仍需解决现有挑战以实现更高效的应用。

Abstract: Over the past decade, Medical Image Segmentation (MIS) using Deep Neural
Networks (DNNs) has achieved significant performance improvements and holds
great promise for future developments. This paper presents a comprehensive
study on MIS based on DNNs. Intelligent Vision Systems are often evaluated
based on their output levels, such as Data, Information, Knowledge,
Intelligence, and Wisdom (DIKIW),and the state-of-the-art solutions in MIS at
these levels are the focus of research. Additionally, Explainable Artificial
Intelligence (XAI) has become an important research direction, as it aims to
uncover the "black box" nature of previous DNN architectures to meet the
requirements of transparency and ethics. The study emphasizes the importance of
MIS in disease diagnosis and early detection, particularly for increasing the
survival rate of cancer patients through timely diagnosis. XAI and early
prediction are considered two important steps in the journey from
"intelligence" to "wisdom." Additionally, the paper addresses existing
challenges and proposes potential solutions to enhance the efficiency of
implementing DNN-based MIS.

</details>


### [482] [Recent Advances in Medical Image Classification](https://arxiv.org/abs/2506.04129)
*Loan Dao,Ngoc Quoc Ly*

Main category: eess.IV

TL;DR: 论文综述了医学图像分类的最新进展，重点介绍了基于深度学习模型和视觉语言模型的解决方案，并探讨了如何解决标记数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 医学图像分类对诊断和治疗至关重要，人工智能的进步为其提供了新的解决方案。

Method: 论文从基础、特定和应用三个层面回顾了解决方案，包括卷积神经网络、视觉变换器和视觉语言模型等深度学习方法。

Result: 这些方法有效解决了标记数据不足的问题，并通过可解释人工智能提升了预测结果的解释性。

Conclusion: 论文总结了当前医学图像分类的技术进展，并强调了可解释人工智能的重要性。

Abstract: Medical image classification is crucial for diagnosis and treatment,
benefiting significantly from advancements in artificial intelligence. The
paper reviews recent progress in the field, focusing on three levels of
solutions: basic, specific, and applied. It highlights advances in traditional
methods using deep learning models like Convolutional Neural Networks and
Vision Transformers, as well as state-of-the-art approaches with Vision
Language Models. These models tackle the issue of limited labeled data, and
enhance and explain predictive results through Explainable Artificial
Intelligence.

</details>


### [483] [Adaptive and Robust Image Processing on CubeSats](https://arxiv.org/abs/2506.03152)
*Robert Bayer,Julian Priest,Daniel Kjellberg,Jeppe Lindhard,Nikolaj Sørenesen,Nicolaj Valsted,Ívar Óli,Pınar Tözün*

Main category: eess.IV

TL;DR: 本文提出了DIPP和DISH两个系统，用于解决CubeSats在资源受限环境下图像处理流水线的灵活性和复杂性问题。DIPP是一个模块化框架，支持部署后调整任务目标；DISH是一种领域特定语言，用于调度低功耗处理器上的复杂任务。实验表明DIPP开销低且稳健，DISH比Lua更节省内存。


<details>
  <summary>Details</summary>
Motivation: CubeSats的低成本特性使其成为空间研究的理想平台，但其资源受限的特性限制了图像处理流水线的灵活性和复杂性。

Method: 提出DIPP（模块化图像处理流水线框架）和DISH（领域特定语言及运行时系统），分别解决流水线适应性和任务调度问题。

Result: DIPP在分解流水线时开销可忽略，且更新需求低；DISH与Lua相比内存需求更低，表达能力相当。

Conclusion: DIPP和DISH为CubeSats提供了高效、灵活的图像处理解决方案，适用于资源受限环境。

Abstract: CubeSats offer a low-cost platform for space research, particularly for Earth
observation. However, their resource-constrained nature and being in space,
challenge the flexibility and complexity of the deployed image processing
pipelines and their orchestration. This paper introduces two novel systems,
DIPP and DISH, to address these challenges. DIPP is a modular and configurable
image processing pipeline framework that allows for adaptability to changing
mission goals even after deployment, while preserving robustness. DISH is a
domain-specific language (DSL) and runtime system designed to schedule complex
imaging workloads on low-power and memory-constrained processors.
  Our experiments demonstrate that DIPP's decomposition of the processing
pipelines adds negligible overhead, while significantly reducing the network
requirements of updating pipelines and being robust against erroneous module
uploads. Furthermore, we compare DISH to Lua, a general purpose scripting
language, and demonstrate its comparable expressiveness and lower memory
requirement.

</details>


### [484] [Super-temporal-resolution Photoacoustic Imaging with Dynamic Reconstruction through Implicit Neural Representation in Sparse-view](https://arxiv.org/abs/2506.03175)
*Youshen Xiao,Yiling Shi,Ruixi Sun,Hongjiang Wei,Fei Gao,Yuyao Zhang*

Main category: eess.IV

TL;DR: 提出了一种基于隐式神经表示（INR）的方法，用于从稀疏视角数据中改进动态光声图像重建并提升时间分辨率。


<details>
  <summary>Details</summary>
Motivation: 传统光声图像重建方法在稀疏数据下产生严重伪影，且未考虑动态成像中的帧间关系。时间分辨率受限于激光技术的低重复率和高成本。

Method: 利用INR将动态光声图像表示为隐式函数，并通过神经网络编码，仅从稀疏传感器数据学习网络权重，无需外部训练数据或先验图像。结合低秩和稀疏性正则化。

Result: 在两种稀疏条件下优于传统重建方法，有效抑制伪影并确保图像质量。

Conclusion: INR方法为动态光声成像提供了一种高效的重建方案，解决了稀疏数据和时间分辨率的挑战。

Abstract: Dynamic Photoacoustic Computed Tomography (PACT) is an important imaging
technique for monitoring physiological processes, capable of providing
high-contrast images of optical absorption at much greater depths than
traditional optical imaging methods. However, practical instrumentation and
geometric constraints limit the number of acoustic sensors available around the
imaging target, leading to sparsity in sensor data. Traditional photoacoustic
(PA) image reconstruction methods, when directly applied to sparse PA data,
produce severe artifacts. Additionally, these traditional methods do not
consider the inter-frame relationships in dynamic imaging. Temporal resolution
is crucial for dynamic photoacoustic imaging, which is fundamentally limited by
the low repetition rate (e.g., 20 Hz) and high cost of high-power laser
technology. Recently, Implicit Neural Representation (INR) has emerged as a
powerful deep learning tool for solving inverse problems with sparse data, by
characterizing signal properties as continuous functions of their coordinates
in an unsupervised manner. In this work, we propose an INR-based method to
improve dynamic photoacoustic image reconstruction from sparse-views and
enhance temporal resolution, using only spatiotemporal coordinates as input.
Specifically, the proposed INR represents dynamic photoacoustic images as
implicit functions and encodes them into a neural network. The weights of the
network are learned solely from the acquired sparse sensor data, without the
need for external training datasets or prior images. Benefiting from the strong
implicit continuity regularization provided by INR, as well as explicit
regularization for low-rank and sparsity, our proposed method outperforms
traditional reconstruction methods under two different sparsity conditions,
effectively suppressing artifacts and ensuring image quality.

</details>


### [485] [Deep Learning-Based Breast Cancer Detection in Mammography: A Multi-Center Validation Study in Thai Population](https://arxiv.org/abs/2506.03177)
*Isarun Chamveha,Supphanut Chaiyungyuen,Sasinun Worakriangkrai,Nattawadee Prasawang,Warasinee Chaisangmongkon,Pornpim Korpraphong,Voraparee Suvannarerg,Shanigarn Thiravit,Chalermdej Kannawat,Kewalin Rungsinaporn,Suwara Issaragrisil,Payia Chadbunchachai,Pattiya Gatechumpol,Chawiporn Muktabhant,Patarachai Sereerat*

Main category: eess.IV

TL;DR: 该研究提出了一种基于改进的EfficientNetV2架构和增强注意力机制的深度学习系统，用于乳腺X光检查中的乳腺癌检测，并在多个数据集上验证了其高性能和临床适用性。


<details>
  <summary>Details</summary>
Motivation: 开发一种高效的深度学习系统，以辅助乳腺X光检查中的乳腺癌检测，提高筛查准确性和临床工作效率。

Method: 使用改进的EfficientNetV2架构和增强的注意力机制，模型在泰国一家主要医疗中心的乳腺X光数据上进行训练，并在三个不同的数据集上进行验证。

Result: 模型在癌症检测中表现出色，AUROC分别为0.89、0.96和0.94；在病灶定位和临床验证中与放射科医生达成高度一致，专家接受率高达96.7%和89.3%。

Conclusion: 该系统在乳腺X光检查中表现出高效性和临床适用性，有望提升乳腺癌筛查的工作流程。

Abstract: This study presents a deep learning system for breast cancer detection in
mammography, developed using a modified EfficientNetV2 architecture with
enhanced attention mechanisms. The model was trained on mammograms from a major
Thai medical center and validated on three distinct datasets: an in-domain test
set (9,421 cases), a biopsy-confirmed set (883 cases), and an out-of-domain
generalizability set (761 cases) collected from two different hospitals. For
cancer detection, the model achieved AUROCs of 0.89, 0.96, and 0.94 on the
respective datasets. The system's lesion localization capability, evaluated
using metrics including Lesion Localization Fraction (LLF) and Non-Lesion
Localization Fraction (NLF), demonstrated robust performance in identifying
suspicious regions. Clinical validation through concordance tests showed strong
agreement with radiologists: 83.5% classification and 84.0% localization
concordance for biopsy-confirmed cases, and 78.1% classification and 79.6%
localization concordance for out-of-domain cases. Expert radiologists'
acceptance rate also averaged 96.7% for biopsy-confirmed cases, and 89.3% for
out-of-domain cases. The system achieved a System Usability Scale score of
74.17 for source hospital, and 69.20 for validation hospitals, indicating good
clinical acceptance. These results demonstrate the model's effectiveness in
assisting mammogram interpretation, with the potential to enhance breast cancer
screening workflows in clinical practice.

</details>


### [486] [LLaMA-XR: A Novel Framework for Radiology Report Generation using LLaMA and QLoRA Fine Tuning](https://arxiv.org/abs/2506.03178)
*Md. Zihad Bin Jahangir,Muhammad Ashad Kabir,Sumaiya Akter,Israt Jahan,Minh Chau*

Main category: eess.IV

TL;DR: LLaMA-XR是一种结合LLaMA 3.1和DenseNet-121图像嵌入的新型框架，通过QLoRA微调提升放射报告生成的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有模型在生成精确且临床相关的放射报告时面临的挑战。

Method: 整合LLaMA 3.1与DenseNet-121图像嵌入，采用QLoRA微调优化参数利用和内存开销。

Result: 在IU X-ray数据集上，ROUGE-L得分0.433，METEOR得分0.336，优于现有方法。

Conclusion: LLaMA-XR展示了高效且可靠的自动化放射报告生成潜力。

Abstract: Automated radiology report generation holds significant potential to reduce
radiologists' workload and enhance diagnostic accuracy. However, generating
precise and clinically meaningful reports from chest radiographs remains
challenging due to the complexity of medical language and the need for
contextual understanding. Existing models often struggle with maintaining both
accuracy and contextual relevance. In this paper, we present LLaMA-XR, a novel
framework that integrates LLaMA 3.1 with DenseNet-121-based image embeddings
and Quantized Low-Rank Adaptation (QLoRA) fine-tuning. LLaMA-XR achieves
improved coherence and clinical accuracy while maintaining computational
efficiency. This efficiency is driven by an optimization strategy that enhances
parameter utilization and reduces memory overhead, enabling faster report
generation with lower computational resource demands. Extensive experiments
conducted on the IU X-ray benchmark dataset demonstrate that LLaMA-XR
outperforms a range of state-of-the-art methods. Our model achieves a ROUGE-L
score of 0.433 and a METEOR score of 0.336, establishing new performance
benchmarks in the domain. These results underscore LLaMA-XR's potential as an
effective and efficient AI system for automated radiology reporting, offering
enhanced clinical utility and reliability.

</details>


### [487] [Dc-EEMF: Pushing depth-of-field limit of photoacoustic microscopy via decision-level constrained learning](https://arxiv.org/abs/2506.03181)
*Wangting Zhou,Jiangshan He,Tong Cai,Lin Wang,Zhen Yuan,Xunbin Wei,Xueli Chen*

Main category: eess.IV

TL;DR: 提出了一种轻量级孪生网络Dc-EEMF，用于扩展光学分辨率光声显微镜（OR-PAM）的景深（DoF），通过端到端多焦点图像融合提升成像质量。


<details>
  <summary>Details</summary>
Motivation: 传统OR-PAM因高斯光束的有限景深无法在深度方向解析足够细节，限制了其在生物医学研究中的应用。

Method: 采用决策级约束的端到端多焦点图像融合（Dc-EEMF），结合抗伪影的通道空间频率特征融合规则和U-Net感知损失函数。

Result: 实验和数值分析表明，Dc-EEMF在不显著牺牲横向分辨率的情况下实现了高质量的PAM图像融合。

Conclusion: Dc-EEMF有望成为临床和临床前研究中扩展景深的实用工具。

Abstract: Photoacoustic microscopy holds the potential to measure biomarkers'
structural and functional status without labels, which significantly aids in
comprehending pathophysiological conditions in biomedical research. However,
conventional optical-resolution photoacoustic microscopy (OR-PAM) is hindered
by a limited depth-of-field (DoF) due to the narrow depth range focused on a
Gaussian beam. Consequently, it fails to resolve sufficient details in the
depth direction. Herein, we propose a decision-level constrained end-to-end
multi-focus image fusion (Dc-EEMF) to push DoF limit of PAM. The DC-EEMF method
is a lightweight siamese network that incorporates an artifact-resistant
channel-wise spatial frequency as its feature fusion rule. The meticulously
crafted U-Net-based perceptual loss function for decision-level focus
properties in end-to-end fusion seamlessly integrates the complementary
advantages of spatial domain and transform domain methods within Dc-EEMF. This
approach can be trained end-to-end without necessitating post-processing
procedures. Experimental results and numerical analyses collectively
demonstrate our method's robust performance, achieving an impressive fusion
result for PAM images without a substantial sacrifice in lateral resolution.
The utilization of Dc-EEMF-powered PAM has the potential to serve as a
practical tool in preclinical and clinical studies requiring extended DoF for
various applications.

</details>


### [488] [Edge Computing for Physics-Driven AI in Computational MRI: A Feasibility Study](https://arxiv.org/abs/2506.03183)
*Yaşar Utku Alçalar,Yu Cao,Mehmet Akçakaya*

Main category: eess.IV

TL;DR: 提出了一种针对FPGA边缘计算优化的PD-AI MRI重建方法，通过8位复数数据量化和消除冗余FFT/IFFT操作，提高了计算效率，同时保持了重建质量。


<details>
  <summary>Details</summary>
Motivation: 高分辨率MRI扫描产生大量数据，导致传输、存储和实时处理挑战，尤其是在功能MRI中。边缘计算结合FPGA提供了一种解决方案，但需要优化PD-AI模型以适应硬件效率。

Method: 采用8位复数数据量化并消除冗余FFT/IFFT操作，优化PD-AI模型以适应FPGA边缘计算设备。

Result: 该方法在计算效率上有所提升，重建质量与常规PD-AI方法相当，且优于标准临床方法。

Conclusion: 该方法为资源受限设备上的高分辨率MRI重建提供了可能，具有实际部署潜力。

Abstract: Physics-driven artificial intelligence (PD-AI) reconstruction methods have
emerged as the state-of-the-art for accelerating MRI scans, enabling higher
spatial and temporal resolutions. However, the high resolution of these scans
generates massive data volumes, leading to challenges in transmission, storage,
and real-time processing. This is particularly pronounced in functional MRI,
where hundreds of volumetric acquisitions further exacerbate these demands.
Edge computing with FPGAs presents a promising solution for enabling PD-AI
reconstruction near the MRI sensors, reducing data transfer and storage
bottlenecks. However, this requires optimization of PD-AI models for hardware
efficiency through quantization and bypassing traditional FFT-based approaches,
which can be a limitation due to their computational demands. In this work, we
propose a novel PD-AI computational MRI approach optimized for FPGA-based edge
computing devices, leveraging 8-bit complex data quantization and eliminating
redundant FFT/IFFT operations. Our results show that this strategy improves
computational efficiency while maintaining reconstruction quality comparable to
conventional PD-AI methods, and outperforms standard clinical methods. Our
approach presents an opportunity for high-resolution MRI reconstruction on
resource-constrained devices, highlighting its potential for real-world
deployment.

</details>


### [489] [DLiPath: A Benchmark for the Comprehensive Assessment of Donor Liver Based on Histopathological Image Dataset](https://arxiv.org/abs/2506.03185)
*Liangrui Pan,Xingchen Li,Zhongyi Chen,Ling Chu,Shaoliang Peng*

Main category: eess.IV

TL;DR: DLiPath是一个基于组织病理学图像数据集的供体肝脏评估基准，旨在解决供体肝脏活检评估中的快速准确性问题，并减少观察者间和观察者内的变异性。


<details>
  <summary>Details</summary>
Motivation: 供体肝脏活检的快速准确评估对移植决策至关重要，但现有方法存在观察者变异性问题。

Method: 收集并公开了304名供体肝脏患者的636张全切片图像，标注关键病理特征，并基于此数据集评估了九种多实例学习模型。

Result: 实验表明，多种多实例学习模型在DLiPath数据集上实现了高准确性。

Conclusion: DLiPath为未来自动化和智能化的供体肝脏评估研究提供了明确方向。

Abstract: Pathologists comprehensive evaluation of donor liver biopsies provides
crucial information for accepting or discarding potential grafts. However,
rapidly and accurately obtaining these assessments intraoperatively poses a
significant challenge for pathologists. Features in donor liver biopsies, such
as portal tract fibrosis, total steatosis, macrovesicular steatosis, and
hepatocellular ballooning are correlated with transplant outcomes, yet
quantifying these indicators suffers from substantial inter- and intra-observer
variability. To address this, we introduce DLiPath, the first benchmark for
comprehensive donor liver assessment based on a histopathology image dataset.
We collected and publicly released 636 whole slide images from 304 donor liver
patients at the Department of Pathology, the Third Xiangya Hospital, with
expert annotations for key pathological features (including cholestasis, portal
tract fibrosis, portal inflammation, total steatosis, macrovesicular steatosis,
and hepatocellular ballooning). We selected nine state-of-the-art
multiple-instance learning (MIL) models based on the DLiPath dataset as
baselines for extensive comparative analysis. The experimental results
demonstrate that several MIL models achieve high accuracy across donor liver
assessment indicators on DLiPath, charting a clear course for future automated
and intelligent donor liver assessment research. Data and code are available at
https://github.com/panliangrui/ACM_MM_2025.

</details>


### [490] [Lightweight Convolutional Neural Networks for Retinal Disease Classification](https://arxiv.org/abs/2506.03186)
*Duaa Kareem Qasim,Sabah Abdulazeez Jebur,Lafta Raheem Ali,Abdul Jalil M. Khalaf,Abir Jaafar Hussain*

Main category: eess.IV

TL;DR: 论文提出使用轻量级CNN架构MobileNet和NASNetMobile对糖尿病视网膜病变（DR）和黄斑裂孔（MH）进行分类，MobileNetV2表现最佳，准确率达90.8%。


<details>
  <summary>Details</summary>
Motivation: DR和MH严重影响视力，早期检测至关重要。AI辅助诊断可帮助实现早期干预。

Method: 使用MobileNet和NASNetMobile架构，基于RFMiD数据集（3,200张眼底图像），通过预处理、迁移学习和数据增强提升模型性能。

Result: MobileNetV2准确率90.8%，优于NASNetMobile的89.5%。

Conclusion: CNN在视网膜疾病分类中表现优异，为AI辅助眼科诊断提供了基础。

Abstract: Retinal diseases such as Diabetic Retinopathy (DR) and Macular Hole (MH)
significantly impact vision and affect millions worldwide. Early detection is
crucial, as DR, a complication of diabetes, damages retinal blood vessels,
potentially leading to blindness, while MH disrupts central vision, affecting
tasks like reading and facial recognition. This paper employed two lightweight
and efficient Convolution Neural Network architectures, MobileNet and
NASNetMobile, for the classification of Normal, DR, and MH retinal images. The
models were trained on the RFMiD dataset, consisting of 3,200 fundus images,
after undergoing preprocessing steps such as resizing, normalization, and
augmentation. To address data scarcity, this study leveraged transfer learning
and data augmentation techniques, enhancing model generalization and
performance. The experimental results demonstrate that MobileNetV2 achieved the
highest accuracy of 90.8%, outperforming NASNetMobile, which achieved 89.5%
accuracy. These findings highlight the effectiveness of CNNs in retinal disease
classification, providing a foundation for AI-assisted ophthalmic diagnosis and
early intervention.

</details>


### [491] [Multi-Analyte, Swab-based Automated Wound Monitor with AI](https://arxiv.org/abs/2506.03188)
*Madhu Babu Sikha,Lalith Appari,Gurudatt Nanjanagudu Ganesh,Amay Bandodkar,Imon Banerjee*

Main category: eess.IV

TL;DR: 开发了一种低成本、多分析物的3D打印检测装置和iOS应用，用于早期识别糖尿病足溃疡（DFUs）并实时监测伤口状况。


<details>
  <summary>Details</summary>
Motivation: 糖尿病足溃疡（DFUs）每年影响大量患者，早期识别非愈合性DFUs可显著降低治疗成本和截肢风险，亟需早期诊断工具。

Method: 通过3D打印的多分析物检测装置和iOS应用，利用计算机视觉技术比较伤口暴露前后的图像密度变化，自动评估伤口严重程度。

Result: 开发的iOS应用能准确收集数据并提供可操作的见解，克服了相机配置和环境变化的挑战。

Conclusion: 集成的传感器和iOS应用可帮助医护人员实时监测伤口状况、跟踪愈合进度并评估关键护理参数。

Abstract: Diabetic foot ulcers (DFUs), a class of chronic wounds, affect ~750,000
individuals every year in the US alone and identifying non-healing DFUs that
develop to chronic wounds early can drastically reduce treatment costs and
minimize risks of amputation. There is therefore a pressing need for diagnostic
tools that can detect non-healing DFUs early. We develop a low cost,
multi-analyte 3D printed assays seamlessly integrated on swabs that can
identify non-healing DFUs and a Wound Sensor iOS App - an innovative mobile
application developed for the controlled acquisition and automated analysis of
wound sensor data. By comparing both the original base image (before exposure
to the wound) and the wound-exposed image, we developed automated computer
vision techniques to compare density changes between the two assay images,
which allow us to automatically determine the severity of the wound. The iOS
app ensures accurate data collection and presents actionable insights, despite
challenges such as variations in camera configurations and ambient conditions.
The proposed integrated sensor and iOS app will allow healthcare professionals
to monitor wound conditions real-time, track healing progress, and assess
critical parameters related to wound care.

</details>


### [492] [Encoding of Demographic and Anatomical Information in Chest X-Ray-based Severe Left Ventricular Hypertrophy Classifiers](https://arxiv.org/abs/2506.03192)
*Basudha Pal,Rama Chellappa,Muhammad Umair*

Main category: eess.IV

TL;DR: 提出了一种直接从胸部X光片预测严重左心室肥厚的分类框架，无需依赖解剖测量或人口统计学输入，性能优越且支持透明模型解释。


<details>
  <summary>Details</summary>
Motivation: 超声心动图和MRI是评估心脏结构的临床标准，但成本高且可及性有限，因此需要一种更经济、更易获取的替代方法。

Method: 采用直接分类框架，利用互信息神经估计量化特征表达性，无需解剖测量或人口统计学输入。

Result: 模型在AUROC和AUPRC上表现优异，揭示了具有临床意义的属性编码。

Conclusion: 该方法为心脏结构评估提供了一种低成本、高可及性的替代方案，同时支持透明模型解释。

Abstract: While echocardiography and MRI are clinical standards for evaluating cardiac
structure, their use is limited by cost and accessibility.We introduce a direct
classification framework that predicts severe left ventricular hypertrophy from
chest X-rays, without relying on anatomical measurements or demographic inputs.
Our approach achieves high AUROC and AUPRC, and employs Mutual Information
Neural Estimation to quantify feature expressivity. This reveals clinically
meaningful attribute encoding and supports transparent model interpretation.

</details>


### [493] [A combined Machine Learning and Finite Element Modelling tool for the surgical planning of craniosynostosis correction](https://arxiv.org/abs/2506.03202)
*Itxasne Antúnez Sáenz,Ane Alberdi Aramendi,David Dunaway,Juling Ong,Lara Deliège,Amparo Sáenz,Anita Ahmadi Birjandi,Noor UI Owase Jeelani,Silvia Schievano,Alessandro Borghi*

Main category: eess.IV

TL;DR: 该研究旨在开发一种实时预测工具，用于颅缝早闭症手术结果，避免CT扫描以减少辐射暴露。通过3D照片生成个性化合成头骨，并利用机器学习模型预测手术效果。


<details>
  <summary>Details</summary>
Motivation: 目前颅缝早闭症手术结果难以预测，依赖医生经验和患儿年龄，且现有工具（如有限元建模）需要CT扫描和复杂计算。研究目标是开发无需CT的实时预测工具。

Method: 基于3D照片生成个性化合成头骨，结合人群平均数据（如缝线位置、颅骨厚度等），使用机器学习代理模型（多输出支持向量回归）预测手术结果。

Result: 模型R2为0.95，MSE和MAE低于0.13，效果显著。未来还可模拟不同手术场景并提供最优参数。

Conclusion: 该方法成功实现了无需CT的实时手术结果预测，为颅缝早闭症手术规划提供了高效工具，未来可进一步优化手术参数。

Abstract: Craniosynostosis is a medical condition that affects the growth of babies'
heads, caused by an early fusion of cranial sutures. In recent decades,
surgical treatments for craniosynostosis have significantly improved, leading
to reduced invasiveness, faster recovery, and less blood loss. At Great Ormond
Street Hospital (GOSH), the main surgical treatment for patients diagnosed with
sagittal craniosynostosis (SC) is spring assisted cranioplasty (SAC). This
procedure involves a 15x15 mm2 osteotomy, where two springs are inserted to
induce distraction. Despite the numerous advantages of this surgical technique
for patients, the outcome remains unpredictable due to the lack of efficient
preoperative planning tools. The surgeon's experience and the baby's age are
currently relied upon to determine the osteotomy location and spring selection.
Previous tools for predicting the surgical outcome of SC relied on finite
element modeling (FEM), which involved computed tomography (CT) imaging and
required engineering expertise and lengthy calculations. The main goal of this
research is to develop a real-time prediction tool for the surgical outcome of
patients, eliminating the need for CT scans to minimise radiation exposure
during preoperative planning. The proposed methodology involves creating
personalised synthetic skulls based on three-dimensional (3D) photographs,
incorporating population average values of suture location, skull thickness,
and soft tissue properties. A machine learning (ML) surrogate model is employed
to achieve the desired surgical outcome. The resulting multi-output support
vector regressor model achieves a R2 metric of 0.95 and MSE and MAE below 0.13.
Furthermore, in the future, this model could not only simulate various surgical
scenarios but also provide optimal parameters for achieving a maximum cranial
index (CI).

</details>


### [494] [A Survey of Deep Learning Video Super-Resolution](https://arxiv.org/abs/2506.03216)
*Arbind Agrahari Baniya,Tsz-Kwan Lee,Peter Eklund,Sunil Aryal*

Main category: eess.IV

TL;DR: 本文对基于深度学习的视频超分辨率（VSR）模型进行了全面综述，分析了各组件及其影响，并提出了多级分类法以指导未来研究。


<details>
  <summary>Details</summary>
Motivation: 由于VSR在多个领域具有潜在影响，但现有方法的使用和决策缺乏充分解释，因此需要对VSR研究中的深度学习方法和组件进行系统分析。

Method: 通过综述现有VSR模型，分析其关键组件和技术，并系统分类，以识别趋势、需求和挑战。

Result: 提出了首个基于深度学习的VSR模型综述，建立了多级分类法，为当前和未来研究提供指导。

Conclusion: 本研究促进了VSR实践的成熟和解释，为特定应用需求提供了模型开发的依据。

Abstract: Video super-resolution (VSR) is a prominent research topic in low-level
computer vision, where deep learning technologies have played a significant
role. The rapid progress in deep learning and its applications in VSR has led
to a proliferation of tools and techniques in the literature. However, the
usage of these methods is often not adequately explained, and decisions are
primarily driven by quantitative improvements. Given the significance of VSR's
potential influence across multiple domains, it is imperative to conduct a
comprehensive analysis of the elements and deep learning methodologies employed
in VSR research. This methodical analysis will facilitate the informed
development of models tailored to specific application needs. In this paper, we
present an overarching overview of deep learning-based video super-resolution
models, investigating each component and discussing its implications.
Furthermore, we provide a synopsis of key components and technologies employed
by state-of-the-art and earlier VSR models. By elucidating the underlying
methodologies and categorising them systematically, we identified trends,
requirements, and challenges in the domain. As a first-of-its-kind survey of
deep learning-based VSR models, this work also establishes a multi-level
taxonomy to guide current and future VSR research, enhancing the maturation and
interpretation of VSR practices for various practical applications.

</details>


### [495] [petBrain: A New Pipeline for Amyloid, Tau Tangles and Neurodegeneration Quantification Using PET and MRI](https://arxiv.org/abs/2506.03217)
*Pierrick Coupé,Boris Mansencal,Floréal Morandat,Sergio Morell-Ortega,Nicolas Villain,Jose V. Manjón,Vincent Planche*

Main category: eess.IV

TL;DR: petBrain是一种新型的端到端处理管道，用于淀粉样蛋白-PET、tau-PET和结构MRI，提供快速、可靠的生物标志物量化，适用于阿尔茨海默病研究。


<details>
  <summary>Details</summary>
Motivation: 现有管道在处理时间、示踪剂类型变异性和多模态集成方面存在局限性，需要一种更高效、标准化的解决方案。

Method: 利用深度学习分割、标准化生物标志物量化（如Centiloid、CenTauR、HAVAs）和同时估计A、T2、N生物标志物，实现为基于网络的平台。

Result: petBrain提供可靠的生物标志物量化，与现有管道结果相当，且与ADNI数据库数据一致，其A/T2/N分期与CSF/血浆生物标志物、临床状态和认知表现吻合良好。

Conclusion: petBrain是一个强大且开放的平台，适用于标准化AD生物标志物分析，推动临床研究应用。

Abstract: INTRODUCTION: Quantification of amyloid plaques (A), neurofibrillary tangles
(T2), and neurodegeneration (N) using PET and MRI is critical for Alzheimer's
disease (AD) diagnosis and prognosis. Existing pipelines face limitations
regarding processing time, variability in tracer types, and challenges in
multimodal integration.
  METHODS: We developed petBrain, a novel end-to-end processing pipeline for
amyloid-PET, tau-PET, and structural MRI. It leverages deep learning-based
segmentation, standardized biomarker quantification (Centiloid, CenTauR,
HAVAs), and simultaneous estimation of A, T2, and N biomarkers. The pipeline is
implemented as a web-based platform, requiring no local computational
infrastructure or specialized software knowledge.
  RESULTS: petBrain provides reliable and rapid biomarker quantification, with
results comparable to existing pipelines for A and T2. It shows strong
concordance with data processed in ADNI databases. The staging and
quantification of A/T2/N by petBrain demonstrated good agreement with
CSF/plasma biomarkers, clinical status, and cognitive performance.
  DISCUSSION: petBrain represents a powerful and openly accessible platform for
standardized AD biomarker analysis, facilitating applications in clinical
research.

</details>


### [496] [Rethinking Whole-Body CT Image Interpretation: An Abnormality-Centric Approach](https://arxiv.org/abs/2506.03238)
*Ziheng Zhao,Lisong Dai,Ya Zhang,Yanfeng Wang,Weidi Xie*

Main category: eess.IV

TL;DR: 该论文提出了一种自动化解释CT图像的方法，通过分类系统、数据集、模型开发和基准测试四个关键贡献，显著提升了异常检测和描述的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决临床放射学中多平面和全身CT图像异常定位和描述的自动化解释挑战。

Method: 提出OminiAbnorm-CT模型，结合分类系统、数据集和视觉提示交互，实现异常检测和描述。

Result: OminiAbnorm-CT在所有任务和指标上显著优于现有方法。

Conclusion: 该方法为临床放射学提供了高效的自动化工具，具有广泛的应用潜力。

Abstract: Automated interpretation of CT images-particularly localizing and describing
abnormal findings across multi-plane and whole-body scans-remains a significant
challenge in clinical radiology. This work aims to address this challenge
through four key contributions: (i) On taxonomy, we collaborate with senior
radiologists to propose a comprehensive hierarchical classification system,
with 404 representative abnormal findings across all body regions; (ii) On
data, we contribute a dataset containing over 14.5K CT images from multiple
planes and all human body regions, and meticulously provide grounding
annotations for over 19K abnormalities, each linked to the detailed description
and cast into the taxonomy; (iii) On model development, we propose
OminiAbnorm-CT, which can automatically ground and describe abnormal findings
on multi-plane and whole-body CT images based on text queries, while also
allowing flexible interaction through visual prompts; (iv) On benchmarks, we
establish three representative evaluation tasks based on real clinical
scenarios. Through extensive experiments, we show that OminiAbnorm-CT can
significantly outperform existing methods on all the tasks and metrics.

</details>


### [497] [Hybrid Ensemble of Segmentation-Assisted Classification and GBDT for Skin Cancer Detection with Engineered Metadata and Synthetic Lesions from ISIC 2024 Non-Dermoscopic 3D-TBP Images](https://arxiv.org/abs/2506.03420)
*Muhammad Zubair Hasan,Fahmida Yasmin Rifat*

Main category: eess.IV

TL;DR: 本文提出了一种结合机器学习和深度学习的混合方法，用于分类恶性与良性皮肤病变，采用SLICE-3D数据集，通过特征融合和增强技术显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌是全球范围内高发且威胁生命的疾病，早期检测对患者预后至关重要。本研究旨在开发一种高效、可解释的AI系统，适用于远程医疗和资源有限的环境。

Method: 结合视觉变换器（EVA02）和设计的卷积ViT混合模型（EdgeNeXtSAC），采用分割辅助分类流程增强病变定位，并通过梯度提升决策树（GBDT）融合预测结果。使用合成数据增强和重新标记策略解决类别不平衡问题。

Result: 在部分AUC（pAUC）高于80%真正率（TPR）的评估指标下，方法达到了0.1755的pAUC，为所有配置中的最高值。

Conclusion: 研究结果表明，混合可解释AI系统在皮肤癌分诊中具有潜力，尤其适用于远程医疗和资源受限的场景。

Abstract: Skin cancer is among the most prevalent and life-threatening diseases
worldwide, with early detection being critical to patient outcomes. This work
presents a hybrid machine and deep learning-based approach for classifying
malignant and benign skin lesions using the SLICE-3D dataset from ISIC 2024,
which comprises 401,059 cropped lesion images extracted from 3D Total Body
Photography (TBP), emulating non-dermoscopic, smartphone-like conditions. Our
method combines vision transformers (EVA02) and our designed convolutional ViT
hybrid (EdgeNeXtSAC) to extract robust features, employing a
segmentation-assisted classification pipeline to enhance lesion localization.
Predictions from these models are fused with a gradient-boosted decision tree
(GBDT) ensemble enriched by engineered features and patient-specific relational
metrics. To address class imbalance and improve generalization, we augment
malignant cases with Stable Diffusion-generated synthetic lesions and apply a
diagnosis-informed relabeling strategy to harmonize external datasets into a
3-class format. Using partial AUC (pAUC) above 80 percent true positive rate
(TPR) as the evaluation metric, our approach achieves a pAUC of 0.1755 -- the
highest among all configurations. These results underscore the potential of
hybrid, interpretable AI systems for skin cancer triage in telemedicine and
resource-constrained settings.

</details>


### [498] [Identifying Alzheimer's Disease Prediction Strategies of Convolutional Neural Network Classifiers using R2* Maps and Spectral Clustering](https://arxiv.org/abs/2506.03890)
*Christian Tinauer,Maximilian Sackl,Stefan Ropele,Christian Langkammer*

Main category: eess.IV

TL;DR: 该研究通过LRP和谱聚类分析了深度学习模型在R2*图像上分类阿尔茨海默病的决策策略，发现预处理和训练选择对模型决策有显著影响，强调了医学AI可解释性的重要性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在R2*图像上分类阿尔茨海默病表现优异，但其决策过程不透明，存在潜在偏见，需要进一步分析以提高可解释性。

Method: 使用3D卷积神经网络训练R2*图像，通过LRP生成热力图，并应用谱聚类和t-SNE可视化分析决策模式。

Result: 谱聚类揭示了不同的决策模式，其中基于相关性的模型在AD和正常对照组间表现出最清晰的分离。t-SNE证实了热力图分组与受试者组别的对应关系。

Conclusion: 预处理和训练选择对模型决策有显著影响，谱聚类为识别分类策略差异提供了结构化方法，强调了医学AI中可解释性的重要性。

Abstract: Deep learning models have shown strong performance in classifying Alzheimer's
disease (AD) from R2* maps, but their decision-making remains opaque, raising
concerns about interpretability. Previous studies suggest biases in model
decisions, necessitating further analysis. This study uses Layer-wise Relevance
Propagation (LRP) and spectral clustering to explore classifier decision
strategies across preprocessing and training configurations using R2* maps. We
trained a 3D convolutional neural network on R2* maps, generating relevance
heatmaps via LRP and applied spectral clustering to identify dominant patterns.
t-Stochastic Neighbor Embedding (t-SNE) visualization was used to assess
clustering structure. Spectral clustering revealed distinct decision patterns,
with the relevance-guided model showing the clearest separation between AD and
normal control (NC) cases. The t-SNE visualization confirmed that this model
aligned heatmap groupings with the underlying subject groups. Our findings
highlight the significant impact of preprocessing and training choices on deep
learning models trained on R2* maps, even with similar performance metrics.
Spectral clustering offers a structured method to identify classification
strategy differences, emphasizing the importance of explainability in medical
AI.

</details>


### [499] [Conformal coronary calcification volume estimation with conditional coverage via histogram clustering](https://arxiv.org/abs/2506.04030)
*Olivier Jaubert,Salman Mohammadi,Keith A. Goatman,Shadia S. Mikhael,Conor Bradley,Rebecca Hughes,Richard Good,John H. Hipwell,Sonia Dahdouh*

Main category: eess.IV

TL;DR: 论文提出了一种基于聚类的条件共形预测框架，用于从训练好的分割网络中提供校准的冠状动脉钙化评分区间，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 冠状动脉钙化的偶然检测和量化可能带来早期临床干预，但过度报告可能对患者健康和医疗系统造成负担，因此需要谨慎自动报告钙化评分。

Method: 提出了一种基于聚类的条件共形预测框架，用于校准3D UNet模型（确定性、MCDropout和深度集成）的预测区间。

Result: 该方法与传统共形预测相比，达到了相似的覆盖率，但分流指标更优。

Conclusion: 有意义的钙化评分预测区间有助于根据风险类别预测的置信度对患者进行分流。

Abstract: Incidental detection and quantification of coronary calcium in CT scans could
lead to the early introduction of lifesaving clinical interventions. However,
over-reporting could negatively affect patient wellbeing and unnecessarily
burden the medical system. Therefore, careful considerations should be taken
when automatically reporting coronary calcium scores. A cluster-based
conditional conformal prediction framework is proposed to provide score
intervals with calibrated coverage from trained segmentation networks without
retraining. The proposed method was tuned and used to calibrate predictive
intervals for 3D UNet models (deterministic, MCDropout and deep ensemble)
reaching similar coverage with better triage metrics compared to conventional
conformal prediction. Meaningful predictive intervals of calcium scores could
help triage patients according to the confidence of their risk category
prediction.

</details>


### [500] [Towards generating more interpretable counterfactuals via concept vectors: a preliminary study on chest X-rays](https://arxiv.org/abs/2506.04058)
*Bulat Maksudov,Kathleen Curran,Alessandra Mileo*

Main category: eess.IV

TL;DR: 通过将临床概念映射到生成模型的潜在空间，识别概念激活向量（CAVs），提供可解释的医学影像分析。


<details>
  <summary>Details</summary>
Motivation: 确保医学影像模型与临床知识对齐并具有可解释性。

Method: 使用简单的重建自编码器，将用户定义的概念与图像级特征关联，无需显式标签训练。

Result: 提取的概念在数据集间稳定，能生成突出临床特征的视觉解释和反事实图像。初步结果显示对大病理（如心脏肥大）有效，小病理因重建限制仍有挑战。

Conclusion: 虽然未超越基线，但为基于临床概念的可解释性提供了一条路径。

Abstract: An essential step in deploying medical imaging models is ensuring alignment
with clinical knowledge and interpretability. We focus on mapping clinical
concepts into the latent space of generative models to identify Concept
Activation Vectors (CAVs). Using a simple reconstruction autoencoder, we link
user-defined concepts to image-level features without explicit label training.
The extracted concepts are stable across datasets, enabling visual explanations
that highlight clinically relevant features. By traversing latent space along
concept directions, we produce counterfactuals that exaggerate or reduce
specific clinical features. Preliminary results on chest X-rays show promise
for large pathologies like cardiomegaly, while smaller pathologies remain
challenging due to reconstruction limits. Although not outperforming baselines,
this approach offers a path toward interpretable, concept-based explanations
aligned with clinical knowledge.

</details>


### [501] [A Diffusion-Driven Temporal Super-Resolution and Spatial Consistency Enhancement Framework for 4D MRI imaging](https://arxiv.org/abs/2506.04116)
*Xuanru Zhou,Jiarun Liu,Shoujun Yu,Hao Yang,Cheng Li,Tao Tan,Shanshan Wang*

Main category: eess.IV

TL;DR: TSSC-Net是一种新型框架，通过扩散模型和Mamba模块解决4D MRI中快速运动导致的时空分辨率问题，提升动态MRI的质量。


<details>
  <summary>Details</summary>
Motivation: 传统方法在大变形下难以保持空间一致性，导致伪影和错位，需要一种新方法改善动态MRI的时空分辨率。

Method: 提出TSSC-Net，结合扩散模型生成中间帧，并引入三向Mamba模块解决跨切片错位问题。

Result: 在ACDC心脏MRI和动态4D膝关节数据集上验证，TSSC-Net能实现6倍时间超分辨率，保持结构保真和空间一致性。

Conclusion: TSSC-Net有效解决了快速运动下的动态MRI时空分辨率问题，提升了图像质量。

Abstract: In medical imaging, 4D MRI enables dynamic 3D visualization, yet the
trade-off between spatial and temporal resolution requires prolonged scan time
that can compromise temporal fidelity--especially during rapid, large-amplitude
motion. Traditional approaches typically rely on registration-based
interpolation to generate intermediate frames. However, these methods struggle
with large deformations, resulting in misregistration, artifacts, and
diminished spatial consistency. To address these challenges, we propose
TSSC-Net, a novel framework that generates intermediate frames while preserving
spatial consistency. To improve temporal fidelity under fast motion, our
diffusion-based temporal super-resolution network generates intermediate frames
using the start and end frames as key references, achieving 6x temporal
super-resolution in a single inference step. Additionally, we introduce a novel
tri-directional Mamba-based module that leverages long-range contextual
information to effectively resolve spatial inconsistencies arising from
cross-slice misalignment, thereby enhancing volumetric coherence and correcting
cross-slice errors. Extensive experiments were performed on the public ACDC
cardiac MRI dataset and a real-world dynamic 4D knee joint dataset. The results
demonstrate that TSSC-Net can generate high-resolution dynamic MRI from
fast-motion data while preserving structural fidelity and spatial consistency.

</details>


### [502] [A Comprehensive Study on Medical Image Segmentation using Deep Neural Networks](https://arxiv.org/abs/2506.04121)
*Loan Dao,Ngoc Quoc Ly*

Main category: eess.IV

TL;DR: 本文综述了基于深度神经网络的医学图像分割（MIS）的研究进展，重点探讨了智能视觉系统在DIKIW框架下的表现，并强调了可解释人工智能（XAI）和早期预测的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在提升MIS在疾病诊断和早期检测中的应用，尤其是通过及时诊断提高癌症患者的生存率，同时解决DNN的透明性和伦理问题。

Method: 通过DIKIW框架评估智能视觉系统，并研究XAI技术以揭示DNN的“黑箱”特性。

Result: 总结了MIS在DIKIW各层次的最新解决方案，并提出了提升DNN-based MIS效率的潜在方法。

Conclusion: XAI和早期预测是从“智能”到“智慧”的关键步骤，未来需进一步解决现有挑战以实现更高效的MIS应用。

Abstract: Over the past decade, Medical Image Segmentation (MIS) using Deep Neural
Networks (DNNs) has achieved significant performance improvements and holds
great promise for future developments. This paper presents a comprehensive
study on MIS based on DNNs. Intelligent Vision Systems are often evaluated
based on their output levels, such as Data, Information, Knowledge,
Intelligence, and Wisdom (DIKIW),and the state-of-the-art solutions in MIS at
these levels are the focus of research. Additionally, Explainable Artificial
Intelligence (XAI) has become an important research direction, as it aims to
uncover the "black box" nature of previous DNN architectures to meet the
requirements of transparency and ethics. The study emphasizes the importance of
MIS in disease diagnosis and early detection, particularly for increasing the
survival rate of cancer patients through timely diagnosis. XAI and early
prediction are considered two important steps in the journey from
"intelligence" to "wisdom." Additionally, the paper addresses existing
challenges and proposes potential solutions to enhance the efficiency of
implementing DNN-based MIS.

</details>


### [503] [Recent Advances in Medical Image Classification](https://arxiv.org/abs/2506.04129)
*Loan Dao,Ngoc Quoc Ly*

Main category: eess.IV

TL;DR: 论文综述了医学图像分类领域的最新进展，重点关注基础、特定和应用三个层次的解决方案，强调了深度学习和视觉语言模型的突破。


<details>
  <summary>Details</summary>
Motivation: 医学图像分类对诊断和治疗至关重要，人工智能的进步为其提供了显著支持。

Method: 论文回顾了传统方法（如卷积神经网络和视觉变换器）以及前沿的视觉语言模型，并探讨了可解释人工智能的应用。

Result: 这些方法解决了标记数据有限的问题，并通过可解释人工智能增强了预测结果的可解释性。

Conclusion: 论文总结了当前技术的进展，并展望了未来在医学图像分类中的潜在发展方向。

Abstract: Medical image classification is crucial for diagnosis and treatment,
benefiting significantly from advancements in artificial intelligence. The
paper reviews recent progress in the field, focusing on three levels of
solutions: basic, specific, and applied. It highlights advances in traditional
methods using deep learning models like Convolutional Neural Networks and
Vision Transformers, as well as state-of-the-art approaches with Vision
Language Models. These models tackle the issue of limited labeled data, and
enhance and explain predictive results through Explainable Artificial
Intelligence.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [504] [Dreaming up scale invariance via inverse renormalization group](https://arxiv.org/abs/2506.04016)
*Adam Rançon,Ulysse Rançon,Tomislav Ivek,Ivan Balog*

Main category: cond-mat.stat-mech

TL;DR: 论文探讨了如何用极简神经网络逆向实现二维Ising模型中的重整化群（RG）粗粒化过程，从粗粒化状态生成微观构型。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索机器学习模型能否在不依赖微观输入的情况下，通过概率方法重建尺度不变的分布。

Method: 方法是通过训练参数极少的神经网络（如仅三个可训练参数）生成临界构型，并分析其标度行为。

Result: 结果表明，简单神经网络能捕捉尺度不变性并重现RG变换的非平凡特征值，而增加网络复杂度无显著优势。

Conclusion: 结论是简单局部规则足以编码临界现象的普适性，为物理统计系综的高效生成模型提供了可能。

Abstract: We explore how minimal neural networks can invert the renormalization group
(RG) coarse-graining procedure in the two-dimensional Ising model, effectively
"dreaming up" microscopic configurations from coarse-grained states. This
task-formally impossible at the level of configurations-can be approached
probabilistically, allowing machine learning models to reconstruct
scale-invariant distributions without relying on microscopic input. We
demonstrate that even neural networks with as few as three trainable parameters
can learn to generate critical configurations, reproducing the scaling behavior
of observables such as magnetic susceptibility, heat capacity, and Binder
ratios. A real-space renormalization group analysis of the generated
configurations confirms that the models capture not only scale invariance but
also reproduce nontrivial eigenvalues of the RG transformation. Surprisingly,
we find that increasing network complexity by introducing multiple layers
offers no significant benefit. These findings suggest that simple local rules,
akin to those generating fractal structures, are sufficient to encode the
universality of critical phenomena, opening the door to efficient generative
models of statistical ensembles in physics.

</details>


### [505] [Dreaming up scale invariance via inverse renormalization group](https://arxiv.org/abs/2506.04016)
*Adam Rançon,Ulysse Rançon,Tomislav Ivek,Ivan Balog*

Main category: cond-mat.stat-mech

TL;DR: 论文探讨了如何使用极简神经网络逆向实现二维Ising模型中的重整化群（RG）粗粒化过程，从粗粒化状态生成微观构型。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索机器学习模型是否能够在不依赖微观输入的情况下，通过概率方法重建尺度不变的分布。

Method: 方法是通过训练仅含三个可调参数的神经网络，生成临界构型，并验证其是否能重现磁化率、热容和Binder比率等观测量的标度行为。

Result: 结果表明，简单的神经网络不仅能捕捉尺度不变性，还能重现RG变换的非平凡特征值。增加网络复杂性（如多层结构）并未带来显著优势。

Conclusion: 结论表明，类似于生成分形结构的简单局部规则足以编码临界现象的普适性，为物理统计系综的高效生成模型提供了可能。

Abstract: We explore how minimal neural networks can invert the renormalization group
(RG) coarse-graining procedure in the two-dimensional Ising model, effectively
"dreaming up" microscopic configurations from coarse-grained states. This
task-formally impossible at the level of configurations-can be approached
probabilistically, allowing machine learning models to reconstruct
scale-invariant distributions without relying on microscopic input. We
demonstrate that even neural networks with as few as three trainable parameters
can learn to generate critical configurations, reproducing the scaling behavior
of observables such as magnetic susceptibility, heat capacity, and Binder
ratios. A real-space renormalization group analysis of the generated
configurations confirms that the models capture not only scale invariance but
also reproduce nontrivial eigenvalues of the RG transformation. Surprisingly,
we find that increasing network complexity by introducing multiple layers
offers no significant benefit. These findings suggest that simple local rules,
akin to those generating fractal structures, are sufficient to encode the
universality of critical phenomena, opening the door to efficient generative
models of statistical ensembles in physics.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [506] [PromptCanvas: Composable Prompting Workspaces Using Dynamic Widgets for Exploration and Iteration in Creative Writing](https://arxiv.org/abs/2506.03741)
*Rifat Mehreen Amin,Oliver Hans Kühle,Daniel Buschek,Andreas Butz*

Main category: cs.HC

TL;DR: PromptCanvas是一个基于无限画布的提示组合工具，通过交互式小部件提升用户对AI生成内容的控制，减少认知负担并激发创意。


<details>
  <summary>Details</summary>
Motivation: 传统对话式UI在创意生成中存在局限性，PromptCanvas旨在通过可视化和小部件组合提供更灵活、直观的体验。

Method: 用户可以通过系统建议、提示或手动输入创建和定制小部件，支持视觉化组织和迭代。通过实验室研究（N=18）和后续实地研究（N=10）验证效果。

Result: PromptCanvas在创造力支持指数上优于传统UI，显著降低认知负担和挫败感，用户反馈称其促进了新视角和创意。

Conclusion: 动态可定制界面（如PromptCanvas）在AI协作写作中具有潜力，能提升创意过程和用户体验。

Abstract: We introduce PromptCanvas, a concept that transforms prompting into a
composable, widget-based experience on an infinite canvas. Users can generate,
customize, and arrange interactive widgets representing various facets of their
text, offering greater control over AI-generated content. PromptCanvas allows
widget creation through system suggestions, user prompts, or manual input,
providing a flexible environment tailored to individual needs. This enables
deeper engagement with the creative process. In a lab study with 18
participants, PromptCanvas outperformed a traditional conversational UI on the
Creativity Support Index. Participants found that it reduced cognitive load,
with lower mental demand and frustration. Qualitative feedback revealed that
the visual organization of thoughts and easy iteration encouraged new
perspectives and ideas. A follow-up field study (N=10) confirmed these results,
showcasing the potential of dynamic, customizable interfaces in improving
collaborative writing with AI.

</details>


### [507] [PromptCanvas: Composable Prompting Workspaces Using Dynamic Widgets for Exploration and Iteration in Creative Writing](https://arxiv.org/abs/2506.03741)
*Rifat Mehreen Amin,Oliver Hans Kühle,Daniel Buschek,Andreas Butz*

Main category: cs.HC

TL;DR: PromptCanvas是一个基于无限画布的提示工具，通过可组合的小部件提升用户对AI生成内容的控制，减少认知负荷并激发创意。


<details>
  <summary>Details</summary>
Motivation: 传统对话式UI在创意支持方面存在局限，PromptCanvas旨在通过视觉化和可定制的小部件提升用户体验和创意产出。

Method: PromptCanvas允许用户通过系统建议、用户提示或手动输入创建和排列小部件，支持灵活的交互方式。

Result: 实验室研究（18人）和后续实地研究（10人）显示，PromptCanvas在创造力支持指数上优于传统UI，降低认知负荷并促进新视角。

Conclusion: PromptCanvas展示了动态、可定制界面在提升AI协作写作中的潜力，未来可进一步优化。

Abstract: We introduce PromptCanvas, a concept that transforms prompting into a
composable, widget-based experience on an infinite canvas. Users can generate,
customize, and arrange interactive widgets representing various facets of their
text, offering greater control over AI-generated content. PromptCanvas allows
widget creation through system suggestions, user prompts, or manual input,
providing a flexible environment tailored to individual needs. This enables
deeper engagement with the creative process. In a lab study with 18
participants, PromptCanvas outperformed a traditional conversational UI on the
Creativity Support Index. Participants found that it reduced cognitive load,
with lower mental demand and frustration. Qualitative feedback revealed that
the visual organization of thoughts and easy iteration encouraged new
perspectives and ideas. A follow-up field study (N=10) confirmed these results,
showcasing the potential of dynamic, customizable interfaces in improving
collaborative writing with AI.

</details>


### [508] [Crowd-SFT: Crowdsourcing for LLM Alignment](https://arxiv.org/abs/2506.04063)
*Alex Sotiropoulos,Sulyab Thottungal Valapu,Linus Lei,Jared Coleman,Bhaskar Krishnamachari*

Main category: cs.HC

TL;DR: 论文提出了一种开放的众包微调框架，通过更广泛的反馈收集解决传统SFT和RLHF方法的成本、偏见和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 传统SFT和RLHF方法依赖小规模、经过审核的标注者群体，导致成本高、偏见多且难以扩展。

Method: 提出基于点数的奖励系统，与Shapley值相关，并通过迭代模型更新指导模型收敛。

Result: 多模型选择框架将目标距离减少55%，验证了点基奖励机制与Shapley值的紧密对齐。

Conclusion: 该框架支持公平且可扩展的参与，为LLM的微调提供了新方向。

Abstract: Large Language Models (LLMs) increasingly rely on Supervised Fine-Tuning
(SFT) and Reinforcement Learning from Human Feedback (RLHF) to align model
responses with human preferences. While RLHF employs a reinforcement learning
approach with a separate reward model, SFT uses human-curated datasets for
supervised learning. Both approaches traditionally depend on small, vetted
groups of annotators, making them costly, prone to bias, and limited in
scalability. We propose an open, crowd-sourced fine-tuning framework that
addresses these limitations by enabling broader feedback collection for SFT
without extensive annotator training. Our framework promotes incentive fairness
via a point-based reward system correlated with Shapley values and guides model
convergence through iterative model updates. Our multi-model selection
framework demonstrates up to a 55% reduction in target distance over
single-model selection, enabling subsequent experiments that validate our
point-based reward mechanism's close alignment with Shapley values (a
well-established method for attributing individual contributions) thereby
supporting fair and scalable participation.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [509] [Dropout-Robust Mechanisms for Differentially Private and Fully Decentralized Mean Estimation](https://arxiv.org/abs/2506.03746)
*César Sabater,Sonia Ben Mokhtar,Jan Ramon*

Main category: cs.CR

TL;DR: 论文提出了一种名为IncA的协议，用于完全去中心化的均值估计，解决了现有方法在准确性、通信成本和信息泄露方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 在去中心化环境中实现差分隐私计算面临准确性、通信成本和信息泄露的挑战，现有方法存在高通信开销或依赖中心化的问题。

Method: 提出IncA协议，采用低方差相关噪声，通过逐步注入敏感信息实现差分隐私，无需中央协调。

Result: 理论证明在无节点永久断开时，协议准确性接近集中式设置；实验表明低方差相关噪声显著减少了节点断开时的准确性损失。

Conclusion: IncA协议在去中心化差分隐私均值估计中表现出色，解决了现有技术的局限性。

Abstract: Achieving differentially private computations in decentralized settings poses
significant challenges, particularly regarding accuracy, communication cost,
and robustness against information leakage. While cryptographic solutions offer
promise, they often suffer from high communication overhead or require
centralization in the presence of network failures. Conversely, existing fully
decentralized approaches typically rely on relaxed adversarial models or
pairwise noise cancellation, the latter suffering from substantial accuracy
degradation if parties unexpectedly disconnect. In this work, we propose IncA,
a new protocol for fully decentralized mean estimation, a widely used primitive
in data-intensive processing. Our protocol, which enforces differential
privacy, requires no central orchestration and employs low-variance correlated
noise, achieved by incrementally injecting sensitive information into the
computation. First, we theoretically demonstrate that, when no parties
permanently disconnect, our protocol achieves accuracy comparable to that of a
centralized setting-already an improvement over most existing decentralized
differentially private techniques. Second, we empirically show that our use of
low-variance correlated noise significantly mitigates the accuracy loss
experienced by existing techniques in the presence of dropouts.

</details>


### [510] [Depermissioning Web3: a Permissionless Accountable RPC Protocol for Blockchain Networks](https://arxiv.org/abs/2506.03940)
*Weihong Wang,Tom Van Cutsem*

Main category: cs.CR

TL;DR: 论文提出了一种名为PARP的无许可且可追责的RPC协议，旨在解决区块链网络中RPC服务集中化带来的隐私、完整性和可用性问题。


<details>
  <summary>Details</summary>
Motivation: 当前区块链网络中，RPC服务主要由少数中心化提供商控制，导致数据访问的隐私、完整性和可用性受到威胁。

Method: PARP结合轻客户端方案和欺诈证明，确保节点诚实可追责，同时利用支付通道实现微支付，激励节点服务。

Result: 针对以太坊的原型实现验证了PARP的可行性，并量化了其相对于基础RPC协议的开销。

Conclusion: PARP为区块链RPC服务提供了一种去中心化、可追责的解决方案，平衡了性能与安全性。

Abstract: In blockchain networks, so-called "full nodes" serve data to and relay
transactions from clients through an RPC interface. This serving layer enables
integration of "Web3" data, stored on blockchains, with "Web2" mobile or web
applications that cannot directly participate as peers in a blockchain network.
In practice, the serving layer is dominated by a small number of centralized
services ("node providers") that offer permissioned access to RPC endpoints.
Clients register with these providers because they offer reliable and
convenient access to blockchain data: operating a full node themselves requires
significant computational and storage resources, and public (permissionless)
RPC nodes lack financial incentives to serve large numbers of clients with
consistent performance.
  Permissioned access to an otherwise permissionless blockchain network raises
concerns regarding the privacy, integrity, and availability of data access. To
address this, we propose a Permissionless Accountable RPC Protocol (PARP). It
enables clients and full nodes to interact pseudonymously while keeping both
parties accountable. PARP leverages "light client" schemes for essential data
integrity checks, combined with fraud proofs, to keep full nodes honest and
accountable. It integrates payment channels to facilitate micro-payments,
holding clients accountable for the resources they consume and providing an
economic incentive for full nodes to serve. Our prototype implementation for
Ethereum demonstrates the feasibility of PARP, and we quantify its overhead
compared to the base RPC protocol.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [511] [ProRank: Prompt Warmup via Reinforcement Learning for Small Language Models Reranking](https://arxiv.org/abs/2506.03487)
*Xianming Li,Aamir Shakir,Rui Huang,Julius Lipp,Jing Li*

Main category: cs.IR

TL;DR: ProRank是一种针对小型语言模型（SLMs）的两阶段训练方法，通过强化学习和细粒度评分学习提升文档重排性能，显著优于现有大型模型。


<details>
  <summary>Details</summary>
Motivation: 当前基于大型语言模型（LLMs）的重排方法计算成本高，而小型语言模型（SLMs）在未微调时难以理解任务提示，限制了其效果。

Method: ProRank采用两阶段训练：1）通过强化学习GRPO进行提示预热，生成粗粒度相关性评分；2）细粒度评分学习进一步优化模型。

Result: ProRank-0.5B模型在BEIR基准测试中超越32B LLM模型，证明了SLMs在高效计算下仍能实现卓越性能。

Conclusion: 通过适当训练，SLMs可在文档重排任务中超越LLMs，同时保持计算效率。

Abstract: Reranking is fundamental to information retrieval and retrieval-augmented
generation, with recent Large Language Models (LLMs) significantly advancing
reranking quality. While recent advances with LLMs have significantly improved
document reranking quality, current approaches primarily rely on large-scale
LLMs (>7B parameters) through zero-shot prompting, presenting high
computational costs. Small Language Models (SLMs) offer a promising alternative
because of their efficiency, but our preliminary quantitative analysis reveals
they struggle with understanding task prompts without fine-tuning. This limits
their effectiveness for document reranking tasks. To address this issue, we
introduce a novel two-stage training approach, ProRank, for SLM-based document
reranking. First, we propose a prompt warmup stage using reinforcement learning
GRPO to steer SLMs to understand task prompts and generate more accurate
coarse-grained binary relevance scores for document reranking. Then, we
continuously fine-tune the SLMs with a fine-grained score learning stage
without introducing additional layers to further improve the reranking quality.
Comprehensive experimental results demonstrate that the proposed ProRank
consistently outperforms both the most advanced open-source and proprietary
reranking models. Notably, our lightweight ProRank-0.5B model even surpasses
the powerful 32B LLM reranking model on the BEIR benchmark, establishing that
properly trained SLMs can achieve superior document reranking performance while
maintaining computational efficiency.

</details>


### [512] [ProRank: Prompt Warmup via Reinforcement Learning for Small Language Models Reranking](https://arxiv.org/abs/2506.03487)
*Xianming Li,Aamir Shakir,Rui Huang,Julius Lipp,Jing Li*

Main category: cs.IR

TL;DR: ProRank是一种针对小型语言模型（SLM）的两阶段训练方法，通过强化学习和细粒度评分学习提升文档重排性能，显著优于现有大型模型。


<details>
  <summary>Details</summary>
Motivation: 当前基于大型语言模型（LLM）的文档重排方法计算成本高，而小型语言模型（SLM）因效率高成为替代方案，但其在未微调时难以理解任务提示。

Method: ProRank分为两阶段：1）通过强化学习（GRPO）进行提示预热，帮助SLM理解任务并生成粗粒度评分；2）通过细粒度评分学习微调SLM，不增加额外层。

Result: ProRank在BEIR基准测试中表现优异，轻量级ProRank-0.5B模型甚至超越32B LLM模型。

Conclusion: SLM经过适当训练可实现高效且高性能的文档重排，ProRank为SLM在重排任务中的应用提供了有效方法。

Abstract: Reranking is fundamental to information retrieval and retrieval-augmented
generation, with recent Large Language Models (LLMs) significantly advancing
reranking quality. While recent advances with LLMs have significantly improved
document reranking quality, current approaches primarily rely on large-scale
LLMs (>7B parameters) through zero-shot prompting, presenting high
computational costs. Small Language Models (SLMs) offer a promising alternative
because of their efficiency, but our preliminary quantitative analysis reveals
they struggle with understanding task prompts without fine-tuning. This limits
their effectiveness for document reranking tasks. To address this issue, we
introduce a novel two-stage training approach, ProRank, for SLM-based document
reranking. First, we propose a prompt warmup stage using reinforcement learning
GRPO to steer SLMs to understand task prompts and generate more accurate
coarse-grained binary relevance scores for document reranking. Then, we
continuously fine-tune the SLMs with a fine-grained score learning stage
without introducing additional layers to further improve the reranking quality.
Comprehensive experimental results demonstrate that the proposed ProRank
consistently outperforms both the most advanced open-source and proprietary
reranking models. Notably, our lightweight ProRank-0.5B model even surpasses
the powerful 32B LLM reranking model on the BEIR benchmark, establishing that
properly trained SLMs can achieve superior document reranking performance while
maintaining computational efficiency.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [513] [mRAG: Elucidating the Design Space of Multi-modal Retrieval-Augmented Generation](https://arxiv.org/abs/2505.24073)
*Chan-Wei Hu,Yueqi Wang,Shuo Xing,Chia-Ju Chen,Zhengzhong Tu*

Main category: cs.AI

TL;DR: 论文探讨了如何通过检索增强生成（RAG）提升大型视觉语言模型（LVLM）的性能，解决了静态训练数据、幻觉问题和动态知识更新的挑战。


<details>
  <summary>Details</summary>
Motivation: LVLM在动态现实应用中表现受限，需解决静态数据、幻觉和外部知识验证问题。

Method: 系统分析多模态RAG流程，包括检索、重排序和生成阶段，并提出自反思的统一代理框架。

Result: 平均性能提升5%，无需微调。

Conclusion: RAG能有效提升LVLM性能，未来可进一步优化动态知识整合。

Abstract: Large Vision-Language Models (LVLMs) have made remarkable strides in
multimodal tasks such as visual question answering, visual grounding, and
complex reasoning. However, they remain limited by static training data,
susceptibility to hallucinations, and inability to verify claims against
up-to-date, external evidence, compromising their performance in dynamic
real-world applications. Retrieval-Augmented Generation (RAG) offers a
practical solution to mitigate these challenges by allowing the LVLMs to access
large-scale knowledge databases via retrieval mechanisms, thereby grounding
model outputs in factual, contextually relevant information. Here in this
paper, we conduct the first systematic dissection of the multimodal RAG
pipeline for LVLMs, explicitly investigating (1) the retrieval phase: on the
modality configurations and retrieval strategies, (2) the re-ranking stage: on
strategies to mitigate positional biases and improve the relevance of retrieved
evidence, and (3) the generation phase: we further investigate how to best
integrate retrieved candidates into the final generation process. Finally, we
extend to explore a unified agentic framework that integrates re-ranking and
generation through self-reflection, enabling LVLMs to select relevant evidence
and suppress irrelevant context dynamically. Our full-stack exploration of RAG
for LVLMs yields substantial insights, resulting in an average performance
boost of 5% without any fine-tuning.

</details>


### [514] [Graph Counselor: Adaptive Graph Exploration via Multi-Agent Synergy to Enhance LLM Reasoning](https://arxiv.org/abs/2506.03939)
*Junqi Gao,Xiang Zou,YIng Ai,Dong Li,Yichen Niu,Biqing Qi,Jianxing Liu*

Main category: cs.AI

TL;DR: Graph Counselor是一种基于多智能体协作的GraphRAG方法，通过自适应图信息提取模块和多视角自反思模块，解决了现有方法在信息聚合和推理机制上的局限性，显著提升了推理准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有GraphRAG方法在信息聚合和推理机制上存在局限性，无法有效捕捉图数据的多级信息或动态调整推理深度，影响了LLMs在专业领域的事实准确性和生成质量。

Method: 提出了Graph Counselor方法，结合多智能体协作（规划、思考和执行代理）的自适应图信息提取模块（AGIEM）和多视角自反思模块（SR），动态建模复杂图结构和调整推理策略。

Result: 实验表明，Graph Counselor在多项图推理任务中优于现有方法，表现出更高的推理准确性和泛化能力。

Conclusion: Graph Counselor通过多智能体协作和自反思机制，有效解决了现有GraphRAG方法的局限性，为专业领域的知识集成和推理提供了更优解决方案。

Abstract: Graph Retrieval Augmented Generation (GraphRAG) effectively enhances external
knowledge integration capabilities by explicitly modeling knowledge
relationships, thereby improving the factual accuracy and generation quality of
Large Language Models (LLMs) in specialized domains. However, existing methods
suffer from two inherent limitations: 1) Inefficient Information Aggregation:
They rely on a single agent and fixed iterative patterns, making it difficult
to adaptively capture multi-level textual, structural, and degree information
within graph data. 2) Rigid Reasoning Mechanism: They employ preset reasoning
schemes, which cannot dynamically adjust reasoning depth nor achieve precise
semantic correction. To overcome these limitations, we propose Graph Counselor,
an GraphRAG method based on multi-agent collaboration. This method uses the
Adaptive Graph Information Extraction Module (AGIEM), where Planning, Thought,
and Execution Agents work together to precisely model complex graph structures
and dynamically adjust information extraction strategies, addressing the
challenges of multi-level dependency modeling and adaptive reasoning depth.
Additionally, the Self-Reflection with Multiple Perspectives (SR) module
improves the accuracy and semantic consistency of reasoning results through
self-reflection and backward reasoning mechanisms. Experiments demonstrate that
Graph Counselor outperforms existing methods in multiple graph reasoning tasks,
exhibiting higher reasoning accuracy and generalization ability. Our code is
available at https://github.com/gjq100/Graph-Counselor.git.

</details>


### [515] [AgentMisalignment: Measuring the Propensity for Misaligned Behaviour in LLM-Based Agents](https://arxiv.org/abs/2506.04018)
*Akshat Naik,Patrick Quinn,Guillermo Bosch,Emma Gouné,Francisco Javier Campos Zabala,Jason Ross Brown,Edward James Young*

Main category: cs.AI

TL;DR: 论文提出了一个评估LLM代理错位倾向的基准AgentMisalignment，发现更强大的模型错位倾向更高，且系统提示对错位行为有显著影响。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理的普及，其错位风险增加，但现有研究对代理在真实场景中尝试错位行为的倾向（错位倾向）了解不足。

Method: 引入AgentMisalignment基准，评估LLM代理在多种现实场景中的错位行为，包括目标保护、抵抗关闭、消极怠工和权力追求等。

Result: 前沿模型在基准测试中表现出更高的错位倾向，系统提示对错位行为的影响甚至可能超过模型选择。

Conclusion: 当前对齐方法未能泛化到LLM代理，需进一步评估错位倾向，尤其是随着自主系统的普及。

Abstract: As Large Language Model (LLM) agents become more widespread, associated
misalignment risks increase. Prior work has examined agents' ability to enact
misaligned behaviour (misalignment capability) and their compliance with
harmful instructions (misuse propensity). However, the likelihood of agents
attempting misaligned behaviours in real-world settings (misalignment
propensity) remains poorly understood. We introduce a misalignment propensity
benchmark, AgentMisalignment, consisting of a suite of realistic scenarios in
which LLM agents have the opportunity to display misaligned behaviour. We
organise our evaluations into subcategories of misaligned behaviours, including
goal-guarding, resisting shutdown, sandbagging, and power-seeking. We report
the performance of frontier models on our benchmark, observing higher
misalignment on average when evaluating more capable models. Finally, we
systematically vary agent personalities through different system prompts. We
find that persona characteristics can dramatically and unpredictably influence
misalignment tendencies -- occasionally far more than the choice of model
itself -- highlighting the importance of careful system prompt engineering for
deployed AI agents. Our work highlights the failure of current alignment
methods to generalise to LLM agents, and underscores the need for further
propensity evaluations as autonomous systems become more prevalent.

</details>


### [516] [Does Thinking More always Help? Understanding Test-Time Scaling in Reasoning Models](https://arxiv.org/abs/2506.04210)
*Soumya Suvra Ghosal,Souradip Chakraborty,Avinash Reddy,Yifu Lu,Mengdi Wang,Dinesh Manocha,Furong Huang,Mohammad Ghavamzadeh,Amrit Singh Bedi*

Main category: cs.AI

TL;DR: 研究发现，测试时延长思考时间（如使用“Wait”提示）最初能提升推理模型性能，但随后因“过度思考”导致性能下降。提出并行思考方法，通过多数投票选择最佳答案，性能提升20%。


<details>
  <summary>Details</summary>
Motivation: 探讨测试时延长思考时间是否真正提升推理性能，揭示其局限性。

Method: 通过实证研究分析模型和基准测试，提出并行思考方法（生成多个独立推理路径并投票选择）。

Result: 延长思考时间导致性能先升后降，并行思考方法比传统方法准确率提升20%。

Conclusion: 测试时延长思考时间效果有限，并行思考是更有效的推理模型扩展方法。

Abstract: Recent trends in test-time scaling for reasoning models (e.g., OpenAI o1,
DeepSeek R1) have led to a popular belief that extending thinking traces using
prompts like "Wait" or "Let me rethink" can improve performance. This raises a
natural question: Does thinking more at test-time truly lead to better
reasoning? To answer this question, we perform a detailed empirical study
across models and benchmarks, which reveals a consistent pattern of initial
performance improvements from additional thinking followed by a decline, due to
"overthinking". To understand this non-monotonic trend, we consider a simple
probabilistic model, which reveals that additional thinking increases output
variance-creating an illusion of improved reasoning while ultimately
undermining precision. Thus, observed gains from "more thinking" are not true
indicators of improved reasoning, but artifacts stemming from the connection
between model uncertainty and evaluation metric. This suggests that test-time
scaling through extended thinking is not an effective way to utilize the
inference thinking budget. Recognizing these limitations, we introduce an
alternative test-time scaling approach, parallel thinking, inspired by
Best-of-N sampling. Our method generates multiple independent reasoning paths
within the same inference budget and selects the most consistent response via
majority vote, achieving up to 20% higher accuracy compared to extended
thinking. This provides a simple yet effective mechanism for test-time scaling
of reasoning models.

</details>


### [517] [mRAG: Elucidating the Design Space of Multi-modal Retrieval-Augmented Generation](https://arxiv.org/abs/2505.24073)
*Chan-Wei Hu,Yueqi Wang,Shuo Xing,Chia-Ju Chen,Zhengzhong Tu*

Main category: cs.AI

TL;DR: 论文探讨了如何通过检索增强生成（RAG）解决大型视觉语言模型（LVLMs）的局限性，包括静态训练数据、幻觉问题和动态知识更新不足。


<details>
  <summary>Details</summary>
Motivation: LVLMs在多模态任务中表现优异，但仍受限于静态数据和幻觉问题，无法动态验证信息。RAG通过检索机制为模型提供外部知识，提升其性能。

Method: 系统分析了多模态RAG流程，包括检索阶段（模态配置与策略）、重排序阶段（减少偏差与提升相关性）和生成阶段（整合检索结果）。

Result: 通过自反思的统一框架动态选择证据，平均性能提升5%，无需微调。

Conclusion: RAG为LVLMs提供了动态知识支持，显著提升了模型在动态环境中的表现。

Abstract: Large Vision-Language Models (LVLMs) have made remarkable strides in
multimodal tasks such as visual question answering, visual grounding, and
complex reasoning. However, they remain limited by static training data,
susceptibility to hallucinations, and inability to verify claims against
up-to-date, external evidence, compromising their performance in dynamic
real-world applications. Retrieval-Augmented Generation (RAG) offers a
practical solution to mitigate these challenges by allowing the LVLMs to access
large-scale knowledge databases via retrieval mechanisms, thereby grounding
model outputs in factual, contextually relevant information. Here in this
paper, we conduct the first systematic dissection of the multimodal RAG
pipeline for LVLMs, explicitly investigating (1) the retrieval phase: on the
modality configurations and retrieval strategies, (2) the re-ranking stage: on
strategies to mitigate positional biases and improve the relevance of retrieved
evidence, and (3) the generation phase: we further investigate how to best
integrate retrieved candidates into the final generation process. Finally, we
extend to explore a unified agentic framework that integrates re-ranking and
generation through self-reflection, enabling LVLMs to select relevant evidence
and suppress irrelevant context dynamically. Our full-stack exploration of RAG
for LVLMs yields substantial insights, resulting in an average performance
boost of 5% without any fine-tuning.

</details>


### [518] [Graph Counselor: Adaptive Graph Exploration via Multi-Agent Synergy to Enhance LLM Reasoning](https://arxiv.org/abs/2506.03939)
*Junqi Gao,Xiang Zou,YIng Ai,Dong Li,Yichen Niu,Biqing Qi,Jianxing Liu*

Main category: cs.AI

TL;DR: Graph Counselor是一种基于多智能体协作的GraphRAG方法，通过自适应图信息提取模块和多视角自反思机制，解决了现有方法在信息聚合和推理机制上的局限性，显著提升了推理准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有GraphRAG方法在信息聚合和推理机制上存在效率低下和灵活性不足的问题，无法适应多级图数据建模和动态推理需求。

Method: 提出Graph Counselor方法，结合自适应图信息提取模块（AGIEM）和多视角自反思（SR）模块，通过多智能体协作动态调整信息提取策略和推理深度。

Result: 实验表明，Graph Counselor在多项图推理任务中优于现有方法，表现出更高的推理准确性和泛化能力。

Conclusion: Graph Counselor通过多智能体协作和自反思机制，有效提升了GraphRAG的性能，为复杂图数据的建模和推理提供了新思路。

Abstract: Graph Retrieval Augmented Generation (GraphRAG) effectively enhances external
knowledge integration capabilities by explicitly modeling knowledge
relationships, thereby improving the factual accuracy and generation quality of
Large Language Models (LLMs) in specialized domains. However, existing methods
suffer from two inherent limitations: 1) Inefficient Information Aggregation:
They rely on a single agent and fixed iterative patterns, making it difficult
to adaptively capture multi-level textual, structural, and degree information
within graph data. 2) Rigid Reasoning Mechanism: They employ preset reasoning
schemes, which cannot dynamically adjust reasoning depth nor achieve precise
semantic correction. To overcome these limitations, we propose Graph Counselor,
an GraphRAG method based on multi-agent collaboration. This method uses the
Adaptive Graph Information Extraction Module (AGIEM), where Planning, Thought,
and Execution Agents work together to precisely model complex graph structures
and dynamically adjust information extraction strategies, addressing the
challenges of multi-level dependency modeling and adaptive reasoning depth.
Additionally, the Self-Reflection with Multiple Perspectives (SR) module
improves the accuracy and semantic consistency of reasoning results through
self-reflection and backward reasoning mechanisms. Experiments demonstrate that
Graph Counselor outperforms existing methods in multiple graph reasoning tasks,
exhibiting higher reasoning accuracy and generalization ability. Our code is
available at https://github.com/gjq100/Graph-Counselor.git.

</details>


### [519] [AgentMisalignment: Measuring the Propensity for Misaligned Behaviour in LLM-Based Agents](https://arxiv.org/abs/2506.04018)
*Akshat Naik,Patrick Quinn,Guillermo Bosch,Emma Gouné,Francisco Javier Campos Zabala,Jason Ross Brown,Edward James Young*

Main category: cs.AI

TL;DR: 该论文提出了一个名为AgentMisalignment的基准测试，用于评估LLM代理在现实场景中的行为不匹配倾向（misalignment propensity），并发现模型能力和系统提示对不匹配行为有显著影响。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理的广泛应用，其行为不匹配风险增加，但目前对代理在现实环境中尝试不匹配行为的倾向性缺乏理解。

Method: 通过设计一个包含多种现实场景的基准测试AgentMisalignment，评估LLM代理在不同不匹配行为类别（如目标保护、抵抗关闭等）中的表现，并分析模型能力和系统提示的影响。

Result: 研究发现，能力更强的模型平均表现出更高的不匹配倾向，且系统提示中的个性特征对不匹配行为有显著且不可预测的影响。

Conclusion: 当前的对齐方法未能有效推广到LLM代理，强调了在自主系统普及过程中进一步评估行为倾向的重要性。

Abstract: As Large Language Model (LLM) agents become more widespread, associated
misalignment risks increase. Prior work has examined agents' ability to enact
misaligned behaviour (misalignment capability) and their compliance with
harmful instructions (misuse propensity). However, the likelihood of agents
attempting misaligned behaviours in real-world settings (misalignment
propensity) remains poorly understood. We introduce a misalignment propensity
benchmark, AgentMisalignment, consisting of a suite of realistic scenarios in
which LLM agents have the opportunity to display misaligned behaviour. We
organise our evaluations into subcategories of misaligned behaviours, including
goal-guarding, resisting shutdown, sandbagging, and power-seeking. We report
the performance of frontier models on our benchmark, observing higher
misalignment on average when evaluating more capable models. Finally, we
systematically vary agent personalities through different system prompts. We
find that persona characteristics can dramatically and unpredictably influence
misalignment tendencies -- occasionally far more than the choice of model
itself -- highlighting the importance of careful system prompt engineering for
deployed AI agents. Our work highlights the failure of current alignment
methods to generalise to LLM agents, and underscores the need for further
propensity evaluations as autonomous systems become more prevalent.

</details>


### [520] [Does Thinking More always Help? Understanding Test-Time Scaling in Reasoning Models](https://arxiv.org/abs/2506.04210)
*Soumya Suvra Ghosal,Souradip Chakraborty,Avinash Reddy,Yifu Lu,Mengdi Wang,Dinesh Manocha,Furong Huang,Mohammad Ghavamzadeh,Amrit Singh Bedi*

Main category: cs.AI

TL;DR: 研究发现，测试时延长思考时间（如使用“Wait”提示）最初能提升推理性能，但随后因“过度思考”导致性能下降。提出并行思考方法，通过多路径推理和多数投票，性能提升20%。


<details>
  <summary>Details</summary>
Motivation: 探究测试时延长思考时间是否真正提升推理性能，揭示其局限性。

Method: 通过实证研究分析模型和基准测试，提出并行思考方法（多路径推理+多数投票）。

Result: 延长思考时间导致性能先升后降；并行思考方法比传统方法准确率提升20%。

Conclusion: 测试时延长思考时间效果有限，并行思考是更高效的推理扩展方法。

Abstract: Recent trends in test-time scaling for reasoning models (e.g., OpenAI o1,
DeepSeek R1) have led to a popular belief that extending thinking traces using
prompts like "Wait" or "Let me rethink" can improve performance. This raises a
natural question: Does thinking more at test-time truly lead to better
reasoning? To answer this question, we perform a detailed empirical study
across models and benchmarks, which reveals a consistent pattern of initial
performance improvements from additional thinking followed by a decline, due to
"overthinking". To understand this non-monotonic trend, we consider a simple
probabilistic model, which reveals that additional thinking increases output
variance-creating an illusion of improved reasoning while ultimately
undermining precision. Thus, observed gains from "more thinking" are not true
indicators of improved reasoning, but artifacts stemming from the connection
between model uncertainty and evaluation metric. This suggests that test-time
scaling through extended thinking is not an effective way to utilize the
inference thinking budget. Recognizing these limitations, we introduce an
alternative test-time scaling approach, parallel thinking, inspired by
Best-of-N sampling. Our method generates multiple independent reasoning paths
within the same inference budget and selects the most consistent response via
majority vote, achieving up to 20% higher accuracy compared to extended
thinking. This provides a simple yet effective mechanism for test-time scaling
of reasoning models.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [521] [Relay Selection and User Equipment Admission in Resource-Efficient NextG Sidelink Communications](https://arxiv.org/abs/2506.03328)
*Yalin E. Sagduyu,Tugba Erpek,Sastry Kompella,Kemal Davaslioglu*

Main category: cs.NI

TL;DR: 5G/6G侧链通信通过内UE中继连接无法直接访问基站的UE，优化分配以最大化加权速率，提出贪婪算法和公平性算法解决计算复杂性和公平性问题。


<details>
  <summary>Details</summary>
Motivation: 解决外UE无法直接连接基站的问题，优化连接分配以提高速率和公平性。

Method: 提出贪婪算法和公平性算法，优化外UE与内UE的分配，考虑信道、干扰和流量特性。

Result: 贪婪算法提高总速率，公平性算法改善UE的平均准入率和公平性。

Conclusion: 公平性算法在保证速率的同时，提供更均衡的侧链通信解决方案。

Abstract: 5G/6G sidelink communications addresses the challenge of connecting outer
UEs, which are unable to directly access a base station (gNodeB), through inner
UEs that act as relays to connect to the gNodeB. The key performance indicators
include the achievable rates, the number of outer UEs that can connect to a
gNodeB, and the latency experienced by outer UEs in establishing connections.
We consider problem of determining the assignment of outer UEs to inner UEs
based on the channel, interference, and traffic characteristics. We formulate
an optimization problem to maximize a weighted sum rate of UEs, where weights
can represent priority, waiting time, and queue length. This optimization
accommodates constraints related to channel and interference characteristics
that influence the rates at which links can successfully carry assigned
traffic. While an exhaustive search can establish an upper bound on achievable
rates by this non-convex optimization problem, it becomes impractical for
larger number of outer UEs due to scalability issues related to high
computational complexity. To address this, we present a greedy algorithm that
incrementally selects links to maximize the sum rate, considering already
activated links. This algorithm, although effective in achieving high sum
rates, may inadvertently overlook some UEs, raising concerns about fairness. To
mitigate this, we introduce a fairness-oriented algorithm that adjusts weights
based on waiting time or queue length, ensuring that UEs with initially
favorable conditions do not unduly disadvantage others over time. We show that
this strategy not only improves the average admission ratio of UEs but also
ensures a more equitable distribution of service among them, thereby providing
a balanced and fair solution to sidelink communications.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [522] [DiaBlo: Diagonal Blocks Are Sufficient For Finetuning](https://arxiv.org/abs/2506.03230)
*Selcuk Gurses,Aozhong Zhang,Yanxia Deng,Xun Dong,Xin Li,Naigang Wang,Penghang Yin,Zi Yang*

Main category: cs.LG

TL;DR: DiaBlo是一种高效的参数微调方法，仅更新模型权重矩阵的对角块，避免了低秩矩阵乘积的需求，实现了稳定收敛和高效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有参数高效微调（PEFT）方法与全模型微调之间的性能差距，同时降低计算和内存成本。

Method: 提出DiaBlo方法，仅更新选定模型权重矩阵的对角块，无需低秩矩阵乘积或特殊初始化策略。

Result: 在多项任务中表现优异，保持高内存效率和快速微调速度。

Conclusion: DiaBlo是一种简单有效的PEFT方法，性能稳定且高效。

Abstract: Finetuning is a critical step for adapting large language models (LLMs) to
domain-specific downstream tasks. To mitigate the substantial computational and
memory costs of full-model fine-tuning, Parameter-Efficient Finetuning (PEFT)
methods have been proposed to update only a small subset of model parameters.
However, performance gaps between PEFT approaches and full-model fine-tuning
still exist. In this work, we present DiaBlo, a simple yet effective PEFT
approach that updates only the diagonal blocks of selected model weight
matrices. Unlike Low Rank Adaptation (LoRA) and its variants, DiaBlo eliminates
the need for low rank matrix products, thereby avoiding the reliance on
auxiliary initialization schemes or customized optimization strategies to
improve convergence. This design leads to stable and robust convergence while
maintaining comparable memory efficiency and training speed to LoRA. We conduct
extensive experiments across a range of tasks, including commonsense reasoning,
arithmetic reasoning, code generation, and safety alignment, to evaluate the
effectiveness and efficiency of DiaBlo. Across these benchmarks, DiaBlo
demonstrates strong and consistent performance while maintaining high memory
efficiency and fast finetuning speed. Codes are available at
https://github.com/ziyangjoy/DiaBlo.

</details>


### [523] [Comparison of different Unique hard attention transformer models by the formal languages they can recognize](https://arxiv.org/abs/2506.03370)
*Leonid Ryvkin*

Main category: cs.LG

TL;DR: 本文综述了独特硬注意力变换器编码器（UHATs）在识别形式语言能力方面的多种结果，区分了掩码与非掩码、有限与无限图像以及通用与双线性注意力评分函数。


<details>
  <summary>Details</summary>
Motivation: 探讨UHATs在形式语言识别中的能力，并比较不同模型之间的关系。

Method: 通过区分不同注意力机制（掩码与非掩码、有限与无限图像、通用与双线性评分函数），分析UHATs的表现。

Result: 提出了UHATs的一阶逻辑下界和电路复杂性上界。

Conclusion: UHATs在形式语言识别中具有明确的能力界限，其表现受注意力机制类型影响。

Abstract: This note is a survey of various results on the capabilities of unique hard
attention transformers encoders (UHATs) to recognize formal languages. We
distinguish between masked vs. non-masked, finite vs. infinite image and
general vs. bilinear attention score functions. We recall some relations
between these models, as well as a lower bound in terms of first-order logic
and an upper bound in terms of circuit complexity.

</details>


### [524] [Adaptive Task Vectors for Large Language Models](https://arxiv.org/abs/2506.03426)
*Joonseong Kang,Soojeong Lee,Subeen Park,Sumin Park,Taero Kim,Jihee Kim,Ryunyi Lee,Kyungwoo Song*

Main category: cs.LG

TL;DR: 论文提出了一种名为自适应任务向量（ATV）的框架，通过动态生成任务向量来解决传统上下文学习（ICL）和固定任务向量方法的局限性，提升了模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统ICL和固定任务向量方法存在对演示顺序敏感、上下文长度限制和计算效率低等问题，且无法针对特定输入动态调整任务向量，导致泛化性能下降。

Method: ATV利用一个小型语言模型动态生成任务向量，并将其适配到目标LLM的架构中，以指导输出生成。

Result: ATV在未见任务上表现出强大的性能和泛化能力，理论分析表明其表达力与LoRA相当且优于Prefix-Tuning。

Conclusion: ATV通过动态生成任务向量，有效解决了传统方法的局限性，为LLM的适应性任务处理提供了新思路。

Abstract: In-Context Learning (ICL) enables Large Language Models (LLMs) to perform
tasks without parameter updates by conditioning on a few demonstrations
provided in the prompt. Despite its success, ICL suffers from several
limitations, including sensitivity to demonstration order, context length
constraints, and computational inefficiency. To address these challenges, task
vector-based approaches compress task information into a single vector.
However, these methods typically construct task vectors from fixed sets of
demonstrations and reuse them across input queries, without conditioning on the
specific input. This limitation can lead models to struggle with effective
adaptation when the input query is not well aligned with the underlying
demonstrations, consequently degrading their generalization performance on
unseen tasks. To overcome this limitation, we propose Adaptive Task Vectors
(ATV), a simple and effective framework that dynamically generates task vectors
conditioned on each input query. ATV employs a small language model to generate
task vectors, which are then transformed to match the target LLM's architecture
and applied to guide its output generation. In contrast to ICL and previous
vector-based approaches, which rely on fixed demonstration sets and their
corresponding vectors, ATV dynamically generates task vectors tailored to each
specific input query and task. Consequently, ATV demonstrates strong
performance and generalization capabilities, even for unseen tasks.
Furthermore, we provide a theoretical analysis indicating that ATV is
expressively equivalent to LoRA under equal rank budgets and more expressive
than Prefix-Tuning, thereby offering formal support for its representational
advantage.

</details>


### [525] [Exploiting LLMs for Automatic Hypothesis Assessment via a Logit-Based Calibrated Prior](https://arxiv.org/abs/2506.03444)
*Yue Gong,Raul Castro Fernandez*

Main category: cs.LG

TL;DR: 论文提出了一种基于LLM的自动假设评估方法，通过Logit-based Calibrated Prior预测变量对的相关系数，评估其新颖性和重要性。


<details>
  <summary>Details</summary>
Motivation: 随着假设生成的自动化程度提高，假设评估成为新瓶颈。现有系统能生成大量统计关系，但缺乏判断其新颖性和重要性的方法。

Method: 利用LLM的权重知识生成变量对的先验相关系数分布，提出Logit-based Calibrated Prior，将模型输出转化为校准的预测分布。

Result: 在2096个真实变量对上的评估显示，该方法在预测Pearson相关系数时表现优异，优于微调的RoBERTa分类器。

Conclusion: 该方法能有效评估统计关系的新颖性，且具有泛化能力，适用于未见过的相关性。

Abstract: As hypothesis generation becomes increasingly automated, a new bottleneck has
emerged: hypothesis assessment. Modern systems can surface thousands of
statistical relationships-correlations, trends, causal links-but offer little
guidance on which ones are novel, non-trivial, or worthy of expert attention.
In this work, we study the complementary problem to hypothesis generation:
automatic hypothesis assessment. Specifically, we ask: given a large set of
statistical relationships, can we automatically assess which ones are novel and
worth further exploration? We focus on correlations as they are a common entry
point in exploratory data analysis that often serve as the basis for forming
deeper scientific or causal hypotheses.
  To support automatic assessment, we propose to leverage the vast knowledge
encoded in LLMs' weights to derive a prior distribution over the correlation
value of a variable pair. If an LLM's prior expects the correlation value
observed, then such correlation is not surprising, and vice versa. We propose
the Logit-based Calibrated Prior, an LLM-elicited correlation prior that
transforms the model's raw output logits into a calibrated, continuous
predictive distribution over correlation values. We evaluate the prior on a
benchmark of 2,096 real-world variable pairs and it achieves a sign accuracy of
78.8%, a mean absolute error of 0.26, and 95% credible interval coverage of
89.2% in predicting Pearson correlation coefficient. It also outperforms a
fine-tuned RoBERTa classifier in binary correlation prediction and achieves
higher precision@K in hypothesis ranking. We further show that the prior
generalizes to correlations not seen during LLM pretraining, reflecting
context-sensitive reasoning rather than memorization.

</details>


### [526] [Prompt Candidates, then Distill: A Teacher-Student Framework for LLM-driven Data Annotation](https://arxiv.org/abs/2506.03857)
*Mingxuan Xia,Haobo Wang,Yixuan Li,Zewei Yu,Jindong Wang,Junbo Zhao,Runze Wu*

Main category: cs.LG

TL;DR: 论文提出了一种新的候选标注范式，通过让大型语言模型（LLM）输出所有可能的标签以减少不确定性，并结合师生框架CanDist提升数据质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常让LLM为每个未标记样本确定单一标签，但由于LLM的不确定性，容易产生错误标注，影响下游任务质量。受人类行为中的模糊厌恶启发，作者提出改进方法。

Method: 提出候选标注范式，鼓励LLM在不确定时输出所有可能标签；开发师生框架CanDist，用小语言模型（SLM）蒸馏候选标注。

Result: 在六个文本分类任务上的实验验证了方法的有效性，理论分析表明候选标注优于单一标注。

Conclusion: 候选标注范式结合CanDist框架显著提升了数据标注质量，为下游任务提供了更可靠的标签。

Abstract: Recently, Large Language Models (LLMs) have demonstrated significant
potential for data annotation, markedly reducing the labor costs associated
with downstream applications. However, existing methods mostly adopt an
aggressive strategy by prompting LLM to determine a single gold label for each
unlabeled sample. Due to the inherent uncertainty within LLMs, they often
produce incorrect labels for difficult samples, severely compromising the data
quality for downstream applications. Motivated by ambiguity aversion in human
behaviors, we propose a novel candidate annotation paradigm wherein large
language models are encouraged to output all possible labels when incurring
uncertainty. To ensure unique labels are provided for downstream tasks, we
develop a teacher-student framework CanDist that distills candidate annotations
with a Small Language Model (SLM). We further provide a rigorous justification
demonstrating that distilling candidate annotations from the teacher LLM offers
superior theoretical guarantees compared to directly using single annotations.
Extensive experiments across six text classification tasks validate the
effectiveness of our proposed method. The source code is available at
https://github.com/MingxuanXia/CanDist.

</details>


### [527] [Multimodal Tabular Reasoning with Privileged Structured Information](https://arxiv.org/abs/2506.04088)
*Jun-Peng Jiang,Yu Xia,Hai-Long Sun,Shiyin Lu,Qing-Guo Chen,Weihua Luo,Kaifu Zhang,De-Chuan Zhan,Han-Jia Ye*

Main category: cs.LG

TL;DR: 论文提出了一种名为Turbo的多模态表格推理框架，利用训练时的结构化信息提升模型在图像表格上的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现实场景中表格多以图像形式存在，缺乏高质量文本表示，导致表格推理困难。

Method: Turbo框架结合结构化信息和视觉表示，通过结构感知的推理路径生成与选择增强模型能力。

Result: 在有限数据（9k）下，Turbo在多个数据集上达到SOTA性能（提升7.2%）。

Conclusion: Turbo通过模态桥接和路径优化，显著提升了多模态表格推理的性能。

Abstract: Tabular reasoning involves multi-step information extraction and logical
inference over tabular data. While recent advances have leveraged large
language models (LLMs) for reasoning over structured tables, such high-quality
textual representations are often unavailable in real-world settings, where
tables typically appear as images. In this paper, we tackle the task of tabular
reasoning from table images, leveraging privileged structured information
available during training to enhance multimodal large language models (MLLMs).
The key challenges lie in the complexity of accurately aligning structured
information with visual representations, and in effectively transferring
structured reasoning skills to MLLMs despite the input modality gap. To address
these, we introduce TabUlar Reasoning with Bridged infOrmation ({\sc Turbo}), a
new framework for multimodal tabular reasoning with privileged structured
tables. {\sc Turbo} benefits from a structure-aware reasoning trace generator
based on DeepSeek-R1, contributing to high-quality modality-bridged data. On
this basis, {\sc Turbo} repeatedly generates and selects the advantageous
reasoning paths, further enhancing the model's tabular reasoning ability.
Experimental results demonstrate that, with limited ($9$k) data, {\sc Turbo}
achieves state-of-the-art performance ($+7.2\%$ vs. previous SOTA) across
multiple datasets.

</details>


### [528] [DUAL: Dynamic Uncertainty-Aware Learning](https://arxiv.org/abs/2506.03158)
*Jiahao Qin,Bei Peng,Feng Liu,Guangliang Cheng,Lu Zong*

Main category: cs.LG

TL;DR: DUAL框架通过动态特征不确定性建模、自适应分布感知调制和不确定性感知跨模态关系学习，有效处理单模态和多模态场景中的特征不确定性，显著提升了多个领域的模型性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在多样学习场景中常面临特征不确定性问题，影响性能和可靠性，多模态场景尤为复杂。

Method: 提出DUAL框架，包含动态特征不确定性建模、自适应分布感知调制和不确定性感知跨模态关系学习三大创新。

Result: 在计算机视觉任务中，DUAL在CIFAR-10、CIFAR-100和Tiny-ImageNet上分别提升7.1%、6.5%和2.3%准确率；在多模态学习中，CMU-MOSEI和CMU-MOSI情感分析任务分别提升4.1%和2.8%，MISR任务提升1.4%。

Conclusion: DUAL框架显著提升了模型在单模态和多模态任务中的性能，为解决特征不确定性问题提供了有效方案。

Abstract: Deep learning models frequently encounter feature uncertainty in diverse
learning scenarios, significantly impacting their performance and reliability.
This challenge is particularly complex in multi-modal scenarios, where models
must integrate information from different sources with inherent uncertainties.
We propose Dynamic Uncertainty-Aware Learning (DUAL), a unified framework that
effectively handles feature uncertainty in both single-modal and multi-modal
scenarios. DUAL introduces three key innovations: Dynamic Feature Uncertainty
Modeling, which continuously refines uncertainty estimates through joint
consideration of feature characteristics and learning dynamics; Adaptive
Distribution-Aware Modulation, which maintains balanced feature distributions
through dynamic sample influence adjustment; and Uncertainty-aware Cross-Modal
Relationship Learning, which explicitly models uncertainties in cross-modal
interactions. Through extensive experiments, we demonstrate DUAL's
effectiveness across multiple domains: in computer vision tasks, it achieves
substantial improvements of 7.1% accuracy on CIFAR-10, 6.5% accuracy on
CIFAR-100, and 2.3% accuracy on Tiny-ImageNet; in multi-modal learning, it
demonstrates consistent gains of 4.1% accuracy on CMU-MOSEI and 2.8% accuracy
on CMU-MOSI for sentiment analysis, while achieving 1.4% accuracy improvements
on MISR. The code will be available on GitHub soon.

</details>


### [529] [AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment](https://arxiv.org/abs/2506.04089)
*Anastasiia Ivanova,Eva Bakaeva,Zoya Volovikova,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: 论文提出了AmbiK数据集，用于解决LLMs在处理厨房环境中模糊指令时的挑战，并提供一个统一的基准。


<details>
  <summary>Details</summary>
Motivation: LLMs在处理现实环境中的模糊指令时存在困难，且现有方法缺乏统一的测试基准。

Method: 通过LLMs辅助收集并人工验证，构建了包含1000对模糊指令及其明确版本的AmbiK数据集。

Result: AmbiK数据集包含2000个任务，分类明确，提供环境描述、澄清问题等详细信息。

Conclusion: AmbiK为研究者提供了一个统一的模糊指令检测方法比较平台，数据集已公开。

Abstract: As a part of an embodied agent, Large Language Models (LLMs) are typically
used for behavior planning given natural language instructions from the user.
However, dealing with ambiguous instructions in real-world environments remains
a challenge for LLMs. Various methods for task ambiguity detection have been
proposed. However, it is difficult to compare them because they are tested on
different datasets and there is no universal benchmark. For this reason, we
propose AmbiK (Ambiguous Tasks in Kitchen Environment), the fully textual
dataset of ambiguous instructions addressed to a robot in a kitchen
environment. AmbiK was collected with the assistance of LLMs and is
human-validated. It comprises 1000 pairs of ambiguous tasks and their
unambiguous counterparts, categorized by ambiguity type (Human Preferences,
Common Sense Knowledge, Safety), with environment descriptions, clarifying
questions and answers, user intents, and task plans, for a total of 2000 tasks.
We hope that AmbiK will enable researchers to perform a unified comparison of
ambiguity detection methods. AmbiK is available at
https://github.com/cog-model/AmbiK-dataset.

</details>


### [530] [Advancing Multimodal Reasoning: From Optimized Cold Start to Staged Reinforcement Learning](https://arxiv.org/abs/2506.04207)
*Shuang Chen,Yue Guo,Zhaochen Su,Yafu Li,Yulun Wu,Jiacheng Chen,Jiayu Chen,Weijie Wang,Xiaoye Qu,Yu Cheng*

Main category: cs.LG

TL;DR: 论文提出ReVisual-R1，通过分阶段训练和优化多模态强化学习，显著提升多模态大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态强化学习中难以激活复杂推理能力，研究者希望通过优化训练流程解决这一问题。

Method: 1) 使用精选文本数据进行冷启动初始化；2) 解决标准GRPO在多模态强化学习中的梯度停滞问题；3) 分阶段训练（多模态强化学习后接纯文本强化学习）。

Result: ReVisual-R1在多个挑战性基准测试中达到开源7B MLLMs的最新水平。

Conclusion: 分阶段训练和优化多模态强化学习是提升MLLM推理能力的有效方法。

Abstract: Inspired by the remarkable reasoning capabilities of Deepseek-R1 in complex
textual tasks, many works attempt to incentivize similar capabilities in
Multimodal Large Language Models (MLLMs) by directly applying reinforcement
learning (RL). However, they still struggle to activate complex reasoning. In
this paper, rather than examining multimodal RL in isolation, we delve into
current training pipelines and identify three crucial phenomena: 1) Effective
cold start initialization is critical for enhancing MLLM reasoning.
Intriguingly, we find that initializing with carefully selected text data alone
can lead to performance surpassing many recent multimodal reasoning models,
even before multimodal RL. 2) Standard GRPO applied to multimodal RL suffers
from gradient stagnation, which degrades training stability and performance. 3)
Subsequent text-only RL training, following the multimodal RL phase, further
enhances multimodal reasoning. This staged training approach effectively
balances perceptual grounding and cognitive reasoning development. By
incorporating the above insights and addressing multimodal RL issues, we
introduce ReVisual-R1, achieving a new state-of-the-art among open-source 7B
MLLMs on challenging benchmarks including MathVerse, MathVision, WeMath,
LogicVista, DynaMath, and challenging AIME2024 and AIME2025.

</details>


### [531] [Robustness in Both Domains: CLIP Needs a Robust Text Encoder](https://arxiv.org/abs/2506.03355)
*Elias Abad Rocamora,Christian Schlarmann,Naman Deep Singh,Yongtao Wu,Matthias Hein,Volkan Cevher*

Main category: cs.LG

TL;DR: 论文提出LEAF方法，通过对抗性微调提升CLIP文本编码器的鲁棒性，同时保持视觉性能，并在多模态任务中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: CLIP文本编码器的鲁棒性尚未被充分研究，而对抗性输入攻击可能影响其下游任务性能。

Method: 提出LEAF方法，一种高效的对抗性微调方法，适用于文本领域，并能扩展到大型CLIP模型。

Result: LEAF显著提升了文本领域的零样本对抗性准确率，同时保持了视觉性能，并在文本到图像生成和多模态检索任务中表现出色。

Conclusion: LEAF方法填补了CLIP文本编码器鲁棒性研究的空白，并在实际应用中展示了其优势。

Abstract: Adversarial input attacks can cause a significant shift of CLIP embeddings.
This can affect the downstream robustness of models incorporating CLIP in the
pipeline, such as text-to-image generative models or large vision language
models. While some efforts have been done towards making the CLIP image
encoders robust, the robustness of text encoders remains unexplored. In this
work, we cover this gap in the literature. We propose LEAF: an efficient
adversarial finetuning method for the text domain, with the ability to scale to
large CLIP models. Our models significantly improve the zero-shot adversarial
accuracy in the text domain, while maintaining the vision performance provided
by robust image encoders. When combined with text-to-image diffusion models, we
can improve the generation quality under adversarial noise. When employing our
robust CLIP encoders in multimodal retrieval tasks, we improve the recall under
adversarial noise over standard CLIP models. Finally, we show that robust text
encoders facilitate better reconstruction of input text from its embedding via
direct optimization.

</details>


### [532] [Rethinking the Stability-Plasticity Trade-off in Continual Learning from an Architectural Perspective](https://arxiv.org/abs/2506.03951)
*Aojun Lu,Hangjie Yuan,Tao Feng,Yanan Sun*

Main category: cs.LG

TL;DR: Dual-Arch框架通过结合深度和宽度网络的互补优势，解决了持续学习中的稳定性与可塑性冲突，提升了性能并减少了参数数量。


<details>
  <summary>Details</summary>
Motivation: 持续学习需要平衡稳定性与可塑性，现有方法多关注参数层面，忽略了网络架构的影响。本文旨在从架构层面解决这一冲突。

Method: 提出Dual-Arch框架，包含两个独立网络：一个专注于可塑性（深度网络），一个专注于稳定性（宽度网络）。

Result: 实验表明，Dual-Arch在提升现有持续学习方法性能的同时，参数数量减少了87%。

Conclusion: Dual-Arch通过架构层面的优化，有效解决了稳定性与可塑性的冲突，为持续学习提供了高效且紧凑的解决方案。

Abstract: The quest for Continual Learning (CL) seeks to empower neural networks with
the ability to learn and adapt incrementally. Central to this pursuit is
addressing the stability-plasticity dilemma, which involves striking a balance
between two conflicting objectives: preserving previously learned knowledge and
acquiring new knowledge. While numerous CL methods aim to achieve this
trade-off, they often overlook the impact of network architecture on stability
and plasticity, restricting the trade-off to the parameter level. In this
paper, we delve into the conflict between stability and plasticity at the
architectural level. We reveal that under an equal parameter constraint, deeper
networks exhibit better plasticity, while wider networks are characterized by
superior stability. To address this architectural-level dilemma, we introduce a
novel framework denoted Dual-Arch, which serves as a plug-in component for CL.
This framework leverages the complementary strengths of two distinct and
independent networks: one dedicated to plasticity and the other to stability.
Each network is designed with a specialized and lightweight architecture,
tailored to its respective objective. Extensive experiments demonstrate that
Dual-Arch enhances the performance of existing CL methods while being up to 87%
more compact in terms of parameters.

</details>


### [533] [Adapt before Continual Learning](https://arxiv.org/abs/2506.03956)
*Aojun Lu,Tao Feng,Hangjie Yuan,Chunhui Ding,Yanan Sun*

Main category: cs.LG

TL;DR: 论文提出了一种名为ACL的新框架，通过在核心持续学习过程之前对预训练模型进行适应性调整，以平衡稳定性和可塑性。


<details>
  <summary>Details</summary>
Motivation: 预训练模型在持续学习中通常被冻结以保持稳定性，但这限制了其可塑性，尤其是在面对显著领域差距时。而完全微调又可能导致灾难性遗忘。

Method: 提出ACL框架，在核心持续学习之前对预训练模型进行适应性调整，通过调整嵌入以对齐原始类别原型并远离其他类别。

Result: 实验表明，ACL显著提升了持续学习的性能，并在多种基准和方法中表现优异。

Conclusion: ACL为基于预训练模型的持续学习提供了一种灵活且有效的解决方案，平衡了稳定性和可塑性。

Abstract: Continual Learning (CL) seeks to enable neural networks to incrementally
acquire new knowledge (plasticity) while retaining existing knowledge
(stability). While pre-trained models (PTMs) have become pivotal in CL,
prevailing approaches freeze the PTM backbone to preserve stability, limiting
their plasticity, particularly when encountering significant domain gaps in
incremental tasks. Conversely, sequentially finetuning the entire PTM risks
catastrophic forgetting of generalizable knowledge, exposing a critical
stability-plasticity trade-off. To address this challenge, we propose Adapting
PTMs before the core CL process (ACL), a novel framework that refines the PTM
backbone through a plug-and-play adaptation phase before learning each new task
with existing CL approaches (e.g., prompt tuning). ACL enhances plasticity by
aligning embeddings with their original class prototypes while distancing them
from others, theoretically and empirically shown to balance stability and
plasticity. Extensive experiments demonstrate that ACL significantly improves
CL performance across benchmarks and integrated methods, offering a versatile
solution for PTM-based CL.

</details>


### [534] [Solving Inverse Problems via Diffusion-Based Priors: An Approximation-Free Ensemble Sampling Approach](https://arxiv.org/abs/2506.03979)
*Haoxuan Chen,Yinuo Ren,Martin Renqiang Min,Lexing Ying,Zachary Izzo*

Main category: cs.LG

TL;DR: 本文提出了一种基于扩散模型（DMs）的集成算法，用于贝叶斯逆问题（BIPs）的后验采样，避免了启发式近似，并通过理论分析和实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 当前基于DMs的后验采样方法依赖启发式近似，限制了其生成能力。本文旨在利用DMs的生成能力，避免近似，提高后验采样的准确性。

Method: 提出了一种集成算法，结合DMs和序贯蒙特卡洛（SMC）方法，通过分析扩散过程中先验的演变，推导出控制后验分布演化的修正PDE，并采用随机加权粒子方法模拟。

Result: 理论证明后验分布误差可被预训练评分函数的训练误差和粒子数限制；实验显示在成像逆问题中比现有方法更准确。

Conclusion: 本文方法避免了启发式近似，通过理论保证和实验验证，显著提升了后验采样的准确性。

Abstract: Diffusion models (DMs) have proven to be effective in modeling
high-dimensional distributions, leading to their widespread adoption for
representing complex priors in Bayesian inverse problems (BIPs). However,
current DM-based posterior sampling methods proposed for solving common BIPs
rely on heuristic approximations to the generative process. To exploit the
generative capability of DMs and avoid the usage of such approximations, we
propose an ensemble-based algorithm that performs posterior sampling without
the use of heuristic approximations. Our algorithm is motivated by existing
works that combine DM-based methods with the sequential Monte Carlo (SMC)
method. By examining how the prior evolves through the diffusion process
encoded by the pre-trained score function, we derive a modified partial
differential equation (PDE) governing the evolution of the corresponding
posterior distribution. This PDE includes a modified diffusion term and a
reweighting term, which can be simulated via stochastic weighted particle
methods. Theoretically, we prove that the error between the true posterior
distribution can be bounded in terms of the training error of the pre-trained
score function and the number of particles in the ensemble. Empirically, we
validate our algorithm on several inverse problems in imaging to show that our
method gives more accurate reconstructions compared to existing DM-based
methods.

</details>


### [535] [Optimal Transport-based Domain Alignment as a Preprocessing Step for Federated Learning](https://arxiv.org/abs/2506.04071)
*Luiz Manella Pereira,M. Hadi Amini*

Main category: cs.LG

TL;DR: 论文提出了一种基于最优传输的预处理算法，用于解决联邦学习中的数据集不平衡问题，通过最小化边缘设备间的数据分布差异，提升全局模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中，本地数据不平衡会导致全局模型聚合性能下降，影响本地模型更新和决策准确性。

Method: 利用Wasserstein重心计算通道平均值，生成目标RGB空间，通过投影数据集最小化全局分布差异。

Result: 在CIFAR-10数据集上验证了该方法能在更少的通信轮次中实现更高的泛化能力。

Conclusion: 提出的方法有效解决了联邦学习中的数据不平衡问题，提升了模型性能和效率。

Abstract: Federated learning (FL) is a subfield of machine learning that avoids sharing
local data with a central server, which can enhance privacy and scalability.
The inability to consolidate data leads to a unique problem called dataset
imbalance, where agents in a network do not have equal representation of the
labels one is trying to learn to predict. In FL, fusing locally-trained models
with unbalanced datasets may deteriorate the performance of global model
aggregation, and reduce the quality of updated local models and the accuracy of
the distributed agents' decisions. In this work, we introduce an Optimal
Transport-based preprocessing algorithm that aligns the datasets by minimizing
the distributional discrepancy of data along the edge devices. We accomplish
this by leveraging Wasserstein barycenters when computing channel-wise
averages. These barycenters are collected in a trusted central server where
they collectively generate a target RGB space. By projecting our dataset
towards this target space, we minimize the distributional discrepancy on a
global level, which facilitates the learning process due to a minimization of
variance across the samples. We demonstrate the capabilities of the proposed
approach over the CIFAR-10 dataset, where we show its capability of reaching
higher degrees of generalization in fewer communication rounds.

</details>


### [536] [DiaBlo: Diagonal Blocks Are Sufficient For Finetuning](https://arxiv.org/abs/2506.03230)
*Selcuk Gurses,Aozhong Zhang,Yanxia Deng,Xun Dong,Xin Li,Naigang Wang,Penghang Yin,Zi Yang*

Main category: cs.LG

TL;DR: DiaBlo是一种高效参数微调方法，仅更新模型权重矩阵的对角块，避免低秩矩阵乘积，实现稳定收敛和高内存效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有参数高效微调（PEFT）方法与全模型微调之间的性能差距，同时降低计算和内存成本。

Method: 仅更新选定模型权重矩阵的对角块，无需低秩矩阵乘积或特殊初始化策略。

Result: 在多种任务（如常识推理、算术推理、代码生成等）中表现稳定且高效，内存占用低且训练速度快。

Conclusion: DiaBlo是一种简单有效的PEFT方法，性能接近全模型微调，同时保持高效和稳定。

Abstract: Finetuning is a critical step for adapting large language models (LLMs) to
domain-specific downstream tasks. To mitigate the substantial computational and
memory costs of full-model fine-tuning, Parameter-Efficient Finetuning (PEFT)
methods have been proposed to update only a small subset of model parameters.
However, performance gaps between PEFT approaches and full-model fine-tuning
still exist. In this work, we present DiaBlo, a simple yet effective PEFT
approach that updates only the diagonal blocks of selected model weight
matrices. Unlike Low Rank Adaptation (LoRA) and its variants, DiaBlo eliminates
the need for low rank matrix products, thereby avoiding the reliance on
auxiliary initialization schemes or customized optimization strategies to
improve convergence. This design leads to stable and robust convergence while
maintaining comparable memory efficiency and training speed to LoRA. We conduct
extensive experiments across a range of tasks, including commonsense reasoning,
arithmetic reasoning, code generation, and safety alignment, to evaluate the
effectiveness and efficiency of DiaBlo. Across these benchmarks, DiaBlo
demonstrates strong and consistent performance while maintaining high memory
efficiency and fast finetuning speed. Codes are available at
https://github.com/ziyangjoy/DiaBlo.

</details>


### [537] [Comparison of different Unique hard attention transformer models by the formal languages they can recognize](https://arxiv.org/abs/2506.03370)
*Leonid Ryvkin*

Main category: cs.LG

TL;DR: 本文综述了关于唯一硬注意力变换器编码器（UHATs）识别形式语言能力的多种结果，区分了掩码与非掩码、有限与无限图像以及一般与双线性注意力评分函数。


<details>
  <summary>Details</summary>
Motivation: 探讨UHATs在形式语言识别中的能力，并分析不同变体的表现。

Method: 通过区分掩码与非掩码、有限与无限图像以及一般与双线性注意力评分函数，回顾相关模型之间的关系。

Result: 提供了基于一阶逻辑的下界和电路复杂度的上界。

Conclusion: 总结了UHATs在形式语言识别中的能力及其理论界限。

Abstract: This note is a survey of various results on the capabilities of unique hard
attention transformers encoders (UHATs) to recognize formal languages. We
distinguish between masked vs. non-masked, finite vs. infinite image and
general vs. bilinear attention score functions. We recall some relations
between these models, as well as a lower bound in terms of first-order logic
and an upper bound in terms of circuit complexity.

</details>


### [538] [Adaptive Task Vectors for Large Language Models](https://arxiv.org/abs/2506.03426)
*Joonseong Kang,Soojeong Lee,Subeen Park,Sumin Park,Taero Kim,Jihee Kim,Ryunyi Lee,Kyungwoo Song*

Main category: cs.LG

TL;DR: 论文提出了自适应任务向量（ATV）框架，通过动态生成任务向量解决传统ICL和固定任务向量方法的局限性，提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统ICL和固定任务向量方法存在对输入查询适应性不足的问题，影响泛化性能。

Method: ATV利用小型语言模型动态生成任务向量，适配目标LLM架构，指导输出生成。

Result: ATV在未见任务上表现出色，理论分析显示其表达能力强于Prefix-Tuning。

Conclusion: ATV是一种简单有效的框架，显著提升了任务适应性和泛化能力。

Abstract: In-Context Learning (ICL) enables Large Language Models (LLMs) to perform
tasks without parameter updates by conditioning on a few demonstrations
provided in the prompt. Despite its success, ICL suffers from several
limitations, including sensitivity to demonstration order, context length
constraints, and computational inefficiency. To address these challenges, task
vector-based approaches compress task information into a single vector.
However, these methods typically construct task vectors from fixed sets of
demonstrations and reuse them across input queries, without conditioning on the
specific input. This limitation can lead models to struggle with effective
adaptation when the input query is not well aligned with the underlying
demonstrations, consequently degrading their generalization performance on
unseen tasks. To overcome this limitation, we propose Adaptive Task Vectors
(ATV), a simple and effective framework that dynamically generates task vectors
conditioned on each input query. ATV employs a small language model to generate
task vectors, which are then transformed to match the target LLM's architecture
and applied to guide its output generation. In contrast to ICL and previous
vector-based approaches, which rely on fixed demonstration sets and their
corresponding vectors, ATV dynamically generates task vectors tailored to each
specific input query and task. Consequently, ATV demonstrates strong
performance and generalization capabilities, even for unseen tasks.
Furthermore, we provide a theoretical analysis indicating that ATV is
expressively equivalent to LoRA under equal rank budgets and more expressive
than Prefix-Tuning, thereby offering formal support for its representational
advantage.

</details>


### [539] [Exploiting LLMs for Automatic Hypothesis Assessment via a Logit-Based Calibrated Prior](https://arxiv.org/abs/2506.03444)
*Yue Gong,Raul Castro Fernandez*

Main category: cs.LG

TL;DR: 论文提出了一种基于LLM的自动假设评估方法，用于判断统计关系的新颖性和重要性，特别关注相关性分析。


<details>
  <summary>Details</summary>
Motivation: 随着假设生成的自动化程度提高，假设评估成为新的瓶颈。现有系统能生成大量统计关系，但缺乏对新颖性和重要性的评估。

Method: 提出Logit-based Calibrated Prior，利用LLM的权重知识生成相关性先验分布，评估相关性是否新颖。

Result: 在2096个真实变量对上的实验中，该方法在预测Pearson相关系数时表现优异，优于微调的RoBERTa分类器。

Conclusion: 该方法能有效评估相关性假设，并展示出对未见相关性的泛化能力，表明其基于上下文推理而非记忆。

Abstract: As hypothesis generation becomes increasingly automated, a new bottleneck has
emerged: hypothesis assessment. Modern systems can surface thousands of
statistical relationships-correlations, trends, causal links-but offer little
guidance on which ones are novel, non-trivial, or worthy of expert attention.
In this work, we study the complementary problem to hypothesis generation:
automatic hypothesis assessment. Specifically, we ask: given a large set of
statistical relationships, can we automatically assess which ones are novel and
worth further exploration? We focus on correlations as they are a common entry
point in exploratory data analysis that often serve as the basis for forming
deeper scientific or causal hypotheses.
  To support automatic assessment, we propose to leverage the vast knowledge
encoded in LLMs' weights to derive a prior distribution over the correlation
value of a variable pair. If an LLM's prior expects the correlation value
observed, then such correlation is not surprising, and vice versa. We propose
the Logit-based Calibrated Prior, an LLM-elicited correlation prior that
transforms the model's raw output logits into a calibrated, continuous
predictive distribution over correlation values. We evaluate the prior on a
benchmark of 2,096 real-world variable pairs and it achieves a sign accuracy of
78.8%, a mean absolute error of 0.26, and 95% credible interval coverage of
89.2% in predicting Pearson correlation coefficient. It also outperforms a
fine-tuned RoBERTa classifier in binary correlation prediction and achieves
higher precision@K in hypothesis ranking. We further show that the prior
generalizes to correlations not seen during LLM pretraining, reflecting
context-sensitive reasoning rather than memorization.

</details>


### [540] [Prompt Candidates, then Distill: A Teacher-Student Framework for LLM-driven Data Annotation](https://arxiv.org/abs/2506.03857)
*Mingxuan Xia,Haobo Wang,Yixuan Li,Zewei Yu,Jindong Wang,Junbo Zhao,Runze Wu*

Main category: cs.LG

TL;DR: 论文提出了一种新的候选标注范式CanDist，通过让大语言模型（LLM）输出所有可能的标签来减少不确定性，并利用小语言模型（SLM）蒸馏候选标注，提升下游任务的数据质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常让LLM为每个未标注样本生成单一标签，但由于LLM的不确定性，容易产生错误标注，影响数据质量。受人类行为中模糊厌恶的启发，作者提出候选标注范式以减少不确定性。

Method: 提出CanDist框架，鼓励LLM在不确定时输出所有可能标签，并通过SLM蒸馏候选标注以确保唯一性。理论分析表明，蒸馏候选标注比直接使用单一标注更具优势。

Result: 在六个文本分类任务上的实验验证了CanDist的有效性。

Conclusion: CanDist通过候选标注和蒸馏方法显著提升了数据标注质量，为下游任务提供了更可靠的标注数据。

Abstract: Recently, Large Language Models (LLMs) have demonstrated significant
potential for data annotation, markedly reducing the labor costs associated
with downstream applications. However, existing methods mostly adopt an
aggressive strategy by prompting LLM to determine a single gold label for each
unlabeled sample. Due to the inherent uncertainty within LLMs, they often
produce incorrect labels for difficult samples, severely compromising the data
quality for downstream applications. Motivated by ambiguity aversion in human
behaviors, we propose a novel candidate annotation paradigm wherein large
language models are encouraged to output all possible labels when incurring
uncertainty. To ensure unique labels are provided for downstream tasks, we
develop a teacher-student framework CanDist that distills candidate annotations
with a Small Language Model (SLM). We further provide a rigorous justification
demonstrating that distilling candidate annotations from the teacher LLM offers
superior theoretical guarantees compared to directly using single annotations.
Extensive experiments across six text classification tasks validate the
effectiveness of our proposed method. The source code is available at
https://github.com/MingxuanXia/CanDist.

</details>


### [541] [Multimodal Tabular Reasoning with Privileged Structured Information](https://arxiv.org/abs/2506.04088)
*Jun-Peng Jiang,Yu Xia,Hai-Long Sun,Shiyin Lu,Qing-Guo Chen,Weihua Luo,Kaifu Zhang,De-Chuan Zhan,Han-Jia Ye*

Main category: cs.LG

TL;DR: 论文提出了一种名为Turbo的新框架，用于解决表格图像的多模态推理问题，通过利用训练时的结构化信息提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现实场景中表格常以图像形式存在，缺乏高质量文本表示，导致基于语言模型的表格推理受限。

Method: Turbo框架结合结构化信息和视觉表示，通过DeepSeek-R1生成高质量模态桥接数据，并优化推理路径选择。

Result: 实验表明，Turbo在有限数据（9k）下性能提升7.2%，达到SOTA水平。

Conclusion: Turbo通过模态桥接和路径优化，显著提升了多模态表格推理能力。

Abstract: Tabular reasoning involves multi-step information extraction and logical
inference over tabular data. While recent advances have leveraged large
language models (LLMs) for reasoning over structured tables, such high-quality
textual representations are often unavailable in real-world settings, where
tables typically appear as images. In this paper, we tackle the task of tabular
reasoning from table images, leveraging privileged structured information
available during training to enhance multimodal large language models (MLLMs).
The key challenges lie in the complexity of accurately aligning structured
information with visual representations, and in effectively transferring
structured reasoning skills to MLLMs despite the input modality gap. To address
these, we introduce TabUlar Reasoning with Bridged infOrmation ({\sc Turbo}), a
new framework for multimodal tabular reasoning with privileged structured
tables. {\sc Turbo} benefits from a structure-aware reasoning trace generator
based on DeepSeek-R1, contributing to high-quality modality-bridged data. On
this basis, {\sc Turbo} repeatedly generates and selects the advantageous
reasoning paths, further enhancing the model's tabular reasoning ability.
Experimental results demonstrate that, with limited ($9$k) data, {\sc Turbo}
achieves state-of-the-art performance ($+7.2\%$ vs. previous SOTA) across
multiple datasets.

</details>


### [542] [DUAL: Dynamic Uncertainty-Aware Learning](https://arxiv.org/abs/2506.03158)
*Jiahao Qin,Bei Peng,Feng Liu,Guangliang Cheng,Lu Zong*

Main category: cs.LG

TL;DR: 提出了一种名为DUAL的动态不确定性感知学习框架，有效处理单模态和多模态场景中的特征不确定性，显著提升了多个任务的性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在多模态场景中面临特征不确定性问题，影响性能和可靠性，需要一种统一框架来解决。

Method: DUAL框架包含三个创新点：动态特征不确定性建模、自适应分布感知调制和不确定性感知的跨模态关系学习。

Result: 在计算机视觉任务中，DUAL显著提升了CIFAR-10、CIFAR-100和Tiny-ImageNet的准确率；在多模态学习中，CMU-MOSEI、CMU-MOSI和MISR任务也表现优异。

Conclusion: DUAL框架通过动态处理特征不确定性，在多领域任务中取得了显著性能提升，具有广泛应用潜力。

Abstract: Deep learning models frequently encounter feature uncertainty in diverse
learning scenarios, significantly impacting their performance and reliability.
This challenge is particularly complex in multi-modal scenarios, where models
must integrate information from different sources with inherent uncertainties.
We propose Dynamic Uncertainty-Aware Learning (DUAL), a unified framework that
effectively handles feature uncertainty in both single-modal and multi-modal
scenarios. DUAL introduces three key innovations: Dynamic Feature Uncertainty
Modeling, which continuously refines uncertainty estimates through joint
consideration of feature characteristics and learning dynamics; Adaptive
Distribution-Aware Modulation, which maintains balanced feature distributions
through dynamic sample influence adjustment; and Uncertainty-aware Cross-Modal
Relationship Learning, which explicitly models uncertainties in cross-modal
interactions. Through extensive experiments, we demonstrate DUAL's
effectiveness across multiple domains: in computer vision tasks, it achieves
substantial improvements of 7.1% accuracy on CIFAR-10, 6.5% accuracy on
CIFAR-100, and 2.3% accuracy on Tiny-ImageNet; in multi-modal learning, it
demonstrates consistent gains of 4.1% accuracy on CMU-MOSEI and 2.8% accuracy
on CMU-MOSI for sentiment analysis, while achieving 1.4% accuracy improvements
on MISR. The code will be available on GitHub soon.

</details>


### [543] [AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment](https://arxiv.org/abs/2506.04089)
*Anastasiia Ivanova,Eva Bakaeva,Zoya Volovikova,Alexey K. Kovalev,Aleksandr I. Panov*

Main category: cs.LG

TL;DR: AmbiK是一个基于厨房环境的文本数据集，用于检测和处理LLMs在模糊指令下的任务规划问题，包含1000对模糊和明确任务，支持统一的方法比较。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在处理模糊指令时的挑战，缺乏统一基准的问题。

Method: 提出AmbiK数据集，通过LLMs辅助收集并人工验证，包含2000个任务，分类模糊类型。

Result: AmbiK数据集公开可用，支持模糊检测方法的统一比较。

Conclusion: AmbiK为模糊指令处理研究提供了标准化基准。

Abstract: As a part of an embodied agent, Large Language Models (LLMs) are typically
used for behavior planning given natural language instructions from the user.
However, dealing with ambiguous instructions in real-world environments remains
a challenge for LLMs. Various methods for task ambiguity detection have been
proposed. However, it is difficult to compare them because they are tested on
different datasets and there is no universal benchmark. For this reason, we
propose AmbiK (Ambiguous Tasks in Kitchen Environment), the fully textual
dataset of ambiguous instructions addressed to a robot in a kitchen
environment. AmbiK was collected with the assistance of LLMs and is
human-validated. It comprises 1000 pairs of ambiguous tasks and their
unambiguous counterparts, categorized by ambiguity type (Human Preferences,
Common Sense Knowledge, Safety), with environment descriptions, clarifying
questions and answers, user intents, and task plans, for a total of 2000 tasks.
We hope that AmbiK will enable researchers to perform a unified comparison of
ambiguity detection methods. AmbiK is available at
https://github.com/cog-model/AmbiK-dataset.

</details>


### [544] [Advancing Multimodal Reasoning: From Optimized Cold Start to Staged Reinforcement Learning](https://arxiv.org/abs/2506.04207)
*Shuang Chen,Yue Guo,Zhaochen Su,Yafu Li,Yulun Wu,Jiacheng Chen,Jiayu Chen,Weijie Wang,Xiaoye Qu,Yu Cheng*

Main category: cs.LG

TL;DR: 论文提出了一种新的多模态大型语言模型（MLLM）训练方法，通过分阶段训练和解决梯度停滞问题，显著提升了模型的复杂推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法直接应用强化学习（RL）于多模态任务时，难以激活复杂推理能力，因此需要探索更有效的训练策略。

Method: 1）使用精选文本数据进行冷启动初始化；2）解决标准GRPO在多模态RL中的梯度停滞问题；3）分阶段训练，先多模态RL后文本RL。

Result: 提出的ReVisual-R1模型在多个挑战性基准测试中达到开源7B MLLM的最新水平。

Conclusion: 分阶段训练和解决梯度停滞问题能显著提升MLLM的推理能力，ReVisual-R1表现优异。

Abstract: Inspired by the remarkable reasoning capabilities of Deepseek-R1 in complex
textual tasks, many works attempt to incentivize similar capabilities in
Multimodal Large Language Models (MLLMs) by directly applying reinforcement
learning (RL). However, they still struggle to activate complex reasoning. In
this paper, rather than examining multimodal RL in isolation, we delve into
current training pipelines and identify three crucial phenomena: 1) Effective
cold start initialization is critical for enhancing MLLM reasoning.
Intriguingly, we find that initializing with carefully selected text data alone
can lead to performance surpassing many recent multimodal reasoning models,
even before multimodal RL. 2) Standard GRPO applied to multimodal RL suffers
from gradient stagnation, which degrades training stability and performance. 3)
Subsequent text-only RL training, following the multimodal RL phase, further
enhances multimodal reasoning. This staged training approach effectively
balances perceptual grounding and cognitive reasoning development. By
incorporating the above insights and addressing multimodal RL issues, we
introduce ReVisual-R1, achieving a new state-of-the-art among open-source 7B
MLLMs on challenging benchmarks including MathVerse, MathVision, WeMath,
LogicVista, DynaMath, and challenging AIME2024 and AIME2025.

</details>


### [545] [Robustness in Both Domains: CLIP Needs a Robust Text Encoder](https://arxiv.org/abs/2506.03355)
*Elias Abad Rocamora,Christian Schlarmann,Naman Deep Singh,Yongtao Wu,Matthias Hein,Volkan Cevher*

Main category: cs.LG

TL;DR: LEAF是一种高效的对抗性微调方法，专注于提升CLIP文本编码器的鲁棒性，同时保持视觉性能。


<details>
  <summary>Details</summary>
Motivation: 对抗性输入攻击可能导致CLIP嵌入显著偏移，影响下游模型的鲁棒性，而文本编码器的鲁棒性尚未被充分研究。

Method: 提出LEAF方法，对CLIP文本编码器进行对抗性微调，适用于大规模模型。

Result: 显著提升文本域的零样本对抗准确性，改善对抗噪声下的生成质量和多模态检索任务中的召回率。

Conclusion: 鲁棒的文本编码器有助于通过直接优化更好地重建输入文本，填补了文献中的空白。

Abstract: Adversarial input attacks can cause a significant shift of CLIP embeddings.
This can affect the downstream robustness of models incorporating CLIP in the
pipeline, such as text-to-image generative models or large vision language
models. While some efforts have been done towards making the CLIP image
encoders robust, the robustness of text encoders remains unexplored. In this
work, we cover this gap in the literature. We propose LEAF: an efficient
adversarial finetuning method for the text domain, with the ability to scale to
large CLIP models. Our models significantly improve the zero-shot adversarial
accuracy in the text domain, while maintaining the vision performance provided
by robust image encoders. When combined with text-to-image diffusion models, we
can improve the generation quality under adversarial noise. When employing our
robust CLIP encoders in multimodal retrieval tasks, we improve the recall under
adversarial noise over standard CLIP models. Finally, we show that robust text
encoders facilitate better reconstruction of input text from its embedding via
direct optimization.

</details>


### [546] [Rethinking the Stability-Plasticity Trade-off in Continual Learning from an Architectural Perspective](https://arxiv.org/abs/2506.03951)
*Aojun Lu,Hangjie Yuan,Tao Feng,Yanan Sun*

Main category: cs.LG

TL;DR: 论文提出了一种名为Dual-Arch的新框架，通过结合深度和宽度网络的互补优势，解决了持续学习中的稳定性与可塑性矛盾。


<details>
  <summary>Details</summary>
Motivation: 持续学习需要平衡稳定性与可塑性，现有方法多关注参数层面，忽略了网络架构的影响。

Method: 提出Dual-Arch框架，包含两个独立网络：一个专注于可塑性（深度网络），另一个专注于稳定性（宽度网络）。

Result: 实验表明，Dual-Arch提升了现有持续学习方法的性能，同时参数规模减少了87%。

Conclusion: Dual-Arch通过架构层面的优化，有效解决了持续学习中的稳定性与可塑性矛盾，具有高效性和紧凑性。

Abstract: The quest for Continual Learning (CL) seeks to empower neural networks with
the ability to learn and adapt incrementally. Central to this pursuit is
addressing the stability-plasticity dilemma, which involves striking a balance
between two conflicting objectives: preserving previously learned knowledge and
acquiring new knowledge. While numerous CL methods aim to achieve this
trade-off, they often overlook the impact of network architecture on stability
and plasticity, restricting the trade-off to the parameter level. In this
paper, we delve into the conflict between stability and plasticity at the
architectural level. We reveal that under an equal parameter constraint, deeper
networks exhibit better plasticity, while wider networks are characterized by
superior stability. To address this architectural-level dilemma, we introduce a
novel framework denoted Dual-Arch, which serves as a plug-in component for CL.
This framework leverages the complementary strengths of two distinct and
independent networks: one dedicated to plasticity and the other to stability.
Each network is designed with a specialized and lightweight architecture,
tailored to its respective objective. Extensive experiments demonstrate that
Dual-Arch enhances the performance of existing CL methods while being up to 87%
more compact in terms of parameters.

</details>


### [547] [Adapt before Continual Learning](https://arxiv.org/abs/2506.03956)
*Aojun Lu,Tao Feng,Hangjie Yuan,Chunhui Ding,Yanan Sun*

Main category: cs.LG

TL;DR: 本文提出了一种名为ACL的新框架，通过在核心持续学习过程之前对预训练模型（PTM）进行适应性调整，以平衡稳定性和可塑性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在持续学习中冻结PTM主干以保持稳定性，但限制了可塑性；而完全微调PTM会导致灾难性遗忘。ACL旨在解决这一稳定性与可塑性的权衡问题。

Method: ACL框架在核心持续学习前引入适应性调整阶段，通过调整嵌入使其接近原始类别原型并远离其他类别，从而优化PTM。

Result: 实验表明，ACL显著提升了持续学习性能，并在多种基准和方法中表现出色。

Conclusion: ACL为基于PTM的持续学习提供了一种灵活且高效的解决方案，有效平衡了稳定性和可塑性。

Abstract: Continual Learning (CL) seeks to enable neural networks to incrementally
acquire new knowledge (plasticity) while retaining existing knowledge
(stability). While pre-trained models (PTMs) have become pivotal in CL,
prevailing approaches freeze the PTM backbone to preserve stability, limiting
their plasticity, particularly when encountering significant domain gaps in
incremental tasks. Conversely, sequentially finetuning the entire PTM risks
catastrophic forgetting of generalizable knowledge, exposing a critical
stability-plasticity trade-off. To address this challenge, we propose Adapting
PTMs before the core CL process (ACL), a novel framework that refines the PTM
backbone through a plug-and-play adaptation phase before learning each new task
with existing CL approaches (e.g., prompt tuning). ACL enhances plasticity by
aligning embeddings with their original class prototypes while distancing them
from others, theoretically and empirically shown to balance stability and
plasticity. Extensive experiments demonstrate that ACL significantly improves
CL performance across benchmarks and integrated methods, offering a versatile
solution for PTM-based CL.

</details>


### [548] [Solving Inverse Problems via Diffusion-Based Priors: An Approximation-Free Ensemble Sampling Approach](https://arxiv.org/abs/2506.03979)
*Haoxuan Chen,Yinuo Ren,Martin Renqiang Min,Lexing Ying,Zachary Izzo*

Main category: cs.LG

TL;DR: 提出了一种基于扩散模型（DMs）的后验采样算法，避免了启发式近似，并通过理论分析和实验验证了其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散模型的后验采样方法依赖启发式近似，限制了其生成能力。本文旨在避免这种近似，更准确地解决贝叶斯逆问题（BIPs）。

Method: 结合扩散模型与序贯蒙特卡洛（SMC）方法，推导出修正的偏微分方程（PDE），通过随机加权粒子方法模拟后验分布。

Result: 理论证明后验分布误差可被预训练评分函数的训练误差和粒子数限制；实验显示在成像逆问题中重建更准确。

Conclusion: 提出的算法避免了启发式近似，显著提升了后验采样的准确性，为复杂先验建模提供了新思路。

Abstract: Diffusion models (DMs) have proven to be effective in modeling
high-dimensional distributions, leading to their widespread adoption for
representing complex priors in Bayesian inverse problems (BIPs). However,
current DM-based posterior sampling methods proposed for solving common BIPs
rely on heuristic approximations to the generative process. To exploit the
generative capability of DMs and avoid the usage of such approximations, we
propose an ensemble-based algorithm that performs posterior sampling without
the use of heuristic approximations. Our algorithm is motivated by existing
works that combine DM-based methods with the sequential Monte Carlo (SMC)
method. By examining how the prior evolves through the diffusion process
encoded by the pre-trained score function, we derive a modified partial
differential equation (PDE) governing the evolution of the corresponding
posterior distribution. This PDE includes a modified diffusion term and a
reweighting term, which can be simulated via stochastic weighted particle
methods. Theoretically, we prove that the error between the true posterior
distribution can be bounded in terms of the training error of the pre-trained
score function and the number of particles in the ensemble. Empirically, we
validate our algorithm on several inverse problems in imaging to show that our
method gives more accurate reconstructions compared to existing DM-based
methods.

</details>


### [549] [Optimal Transport-based Domain Alignment as a Preprocessing Step for Federated Learning](https://arxiv.org/abs/2506.04071)
*Luiz Manella Pereira,M. Hadi Amini*

Main category: cs.LG

TL;DR: 论文提出了一种基于最优传输的预处理算法，用于解决联邦学习中的数据集不平衡问题，通过最小化边缘设备间的数据分布差异提升全局模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中数据集不平衡会导致全局模型聚合性能下降，影响本地模型更新和决策准确性。

Method: 利用Wasserstein重心计算通道平均值，生成目标RGB空间，通过投影数据集最小化全局分布差异。

Result: 在CIFAR-10数据集上验证了该方法能在更少通信轮次中实现更高的泛化能力。

Conclusion: 该方法有效减少了数据分布差异，提升了联邦学习的效率和准确性。

Abstract: Federated learning (FL) is a subfield of machine learning that avoids sharing
local data with a central server, which can enhance privacy and scalability.
The inability to consolidate data leads to a unique problem called dataset
imbalance, where agents in a network do not have equal representation of the
labels one is trying to learn to predict. In FL, fusing locally-trained models
with unbalanced datasets may deteriorate the performance of global model
aggregation, and reduce the quality of updated local models and the accuracy of
the distributed agents' decisions. In this work, we introduce an Optimal
Transport-based preprocessing algorithm that aligns the datasets by minimizing
the distributional discrepancy of data along the edge devices. We accomplish
this by leveraging Wasserstein barycenters when computing channel-wise
averages. These barycenters are collected in a trusted central server where
they collectively generate a target RGB space. By projecting our dataset
towards this target space, we minimize the distributional discrepancy on a
global level, which facilitates the learning process due to a minimization of
variance across the samples. We demonstrate the capabilities of the proposed
approach over the CIFAR-10 dataset, where we show its capability of reaching
higher degrees of generalization in fewer communication rounds.

</details>


### [550] [CORE: Constraint-Aware One-Step Reinforcement Learning for Simulation-Guided Neural Network Accelerator Design](https://arxiv.org/abs/2506.03474)
*Yifeng Xiao,Yurong Xu,Ning Yan,Masood Mortazavi,Pierluigi Nuzzo*

Main category: cs.LG

TL;DR: CORE是一种基于约束感知的一步强化学习方法，用于高效优化高维设计空间，解决了现有方法在采样效率和约束满足之间的平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有启发式和多步强化学习方法在高维设计空间优化中难以平衡采样效率和约束满足，主要由于稀疏、延迟的反馈和大规模混合动作空间。

Method: CORE通过定义结构化分布、依赖关系解码和奖励塑形，学习采样设计配置，并使用代理目标更新策略，无需学习价值函数。

Result: 在神经网络加速器的硬件映射协同设计中，CORE显著提高了采样效率，并优于现有基线方法。

Conclusion: CORE是一种通用方法，适用于广泛的离散-连续约束设计问题。

Abstract: Simulation-based design space exploration (DSE) aims to efficiently optimize
high-dimensional structured designs under complex constraints and expensive
evaluation costs. Existing approaches, including heuristic and multi-step
reinforcement learning (RL) methods, struggle to balance sampling efficiency
and constraint satisfaction due to sparse, delayed feedback, and large hybrid
action spaces. In this paper, we introduce CORE, a constraint-aware, one-step
RL method for simulationguided DSE. In CORE, the policy agent learns to sample
design configurations by defining a structured distribution over them,
incorporating dependencies via a scaling-graph-based decoder, and by reward
shaping to penalize invalid designs based on the feedback obtained from
simulation. CORE updates the policy using a surrogate objective that compares
the rewards of designs within a sampled batch, without learning a value
function. This critic-free formulation enables efficient learning by
encouraging the selection of higher-reward designs. We instantiate CORE for
hardware-mapping co-design of neural network accelerators, demonstrating that
it significantly improves sample efficiency and achieves better accelerator
configurations compared to state-of-the-art baselines. Our approach is general
and applicable to a broad class of discrete-continuous constrained design
problems.

</details>


### [551] [FPGA-Enabled Machine Learning Applications in Earth Observation: A Systematic Review](https://arxiv.org/abs/2506.03938)
*Cédric Léonard,Dirk Stober,Martin Schulz*

Main category: cs.LG

TL;DR: 本文综述了66个实验，探讨了在FPGA上部署机器学习模型用于遥感应用的方法，提出了两种分类法，并遵循PRISMA 2020指南以确保透明性和可重复性。


<details>
  <summary>Details</summary>
Motivation: 随着新无人机技术和NewSpace时代的发展，地球观测任务和数据获取面临带宽压力和实时决策需求，FPGA因其性能与适应性的平衡成为理想选择。

Method: 系统分析了66个实验，提出两种分类法，分别针对高效模型架构和FPGA实现策略。

Result: 总结了FPGA在遥感应用中部署ML模型的实践，并提供了数据和代码以支持透明性。

Conclusion: FPGA在遥感ML应用中具有潜力，未来可通过优化架构和策略进一步提升性能。

Abstract: New UAV technologies and the NewSpace era are transforming Earth Observation
missions and data acquisition. Numerous small platforms generate large data
volume, straining bandwidth and requiring onboard decision-making to transmit
high-quality information in time. While Machine Learning allows real-time
autonomous processing, FPGAs balance performance with adaptability to
mission-specific requirements, enabling onboard deployment. This review
systematically analyzes 66 experiments deploying ML models on FPGAs for Remote
Sensing applications. We introduce two distinct taxonomies to capture both
efficient model architectures and FPGA implementation strategies. For
transparency and reproducibility, we follow PRISMA 2020 guidelines and share
all data and code at https://github.com/CedricLeon/Survey_RS-ML-FPGA.

</details>


### [552] [HtFLlib: A Comprehensive Heterogeneous Federated Learning Library and Benchmark](https://arxiv.org/abs/2506.03954)
*Jianqing Zhang,Xinghao Wu,Yanbing Zhou,Xiaoting Sun,Qiqi Cai,Yang Liu,Yang Hua,Zhenzhe Zheng,Jian Cao,Qiang Yang*

Main category: cs.LG

TL;DR: 论文介绍了首个异构联邦学习库（HtFLlib），用于标准化评估和分析异构联邦学习方法，填补了现有研究空白。


<details>
  <summary>Details</summary>
Motivation: 传统联邦学习仅支持同构模型，限制了异构模型间的协作。异构联邦学习（HtFL）方法虽解决了这一问题，但缺乏统一的评估基准。

Method: 开发了HtFLlib，集成了12个数据集、40种模型架构、10种HtFL方法，并进行了系统评估。

Result: HtFLlib提供了一个易用且可扩展的框架，支持多领域、多模态和异构数据的评估，推动了HtFL研究的进展。

Conclusion: HtFLlib有望促进异构联邦学习的进一步研究和广泛应用。

Abstract: As AI evolves, collaboration among heterogeneous models helps overcome data
scarcity by enabling knowledge transfer across institutions and devices.
Traditional Federated Learning (FL) only supports homogeneous models, limiting
collaboration among clients with heterogeneous model architectures. To address
this, Heterogeneous Federated Learning (HtFL) methods are developed to enable
collaboration across diverse heterogeneous models while tackling the data
heterogeneity issue at the same time. However, a comprehensive benchmark for
standardized evaluation and analysis of the rapidly growing HtFL methods is
lacking. Firstly, the highly varied datasets, model heterogeneity scenarios,
and different method implementations become hurdles to making easy and fair
comparisons among HtFL methods. Secondly, the effectiveness and robustness of
HtFL methods are under-explored in various scenarios, such as the medical
domain and sensor signal modality. To fill this gap, we introduce the first
Heterogeneous Federated Learning Library (HtFLlib), an easy-to-use and
extensible framework that integrates multiple datasets and model heterogeneity
scenarios, offering a robust benchmark for research and practical applications.
Specifically, HtFLlib integrates (1) 12 datasets spanning various domains,
modalities, and data heterogeneity scenarios; (2) 40 model architectures,
ranging from small to large, across three modalities; (3) a modularized and
easy-to-extend HtFL codebase with implementations of 10 representative HtFL
methods; and (4) systematic evaluations in terms of accuracy, convergence,
computation costs, and communication costs. We emphasize the advantages and
potential of state-of-the-art HtFL methods and hope that HtFLlib will catalyze
advancing HtFL research and enable its broader applications. The code is
released at https://github.com/TsingZ0/HtFLlib.

</details>


<div id='physics.med-ph'></div>

# physics.med-ph [[Back]](#toc)

### [553] [Analytical Reconstruction of Periodically Deformed Objects in Time-resolved CT](https://arxiv.org/abs/2506.03792)
*Qianwei Qu,Christian M. Schlepütz,Marco Stampanoni*

Main category: physics.med-ph

TL;DR: 论文提出了两种新的时间分辨CT重建方法，相比传统门控方法，能更高效利用辐射剂量并减少噪声。


<details>
  <summary>Details</summary>
Motivation: 传统门控方法仅利用部分投影数据且忽略不同集合间的相关性，导致辐射剂量利用效率低。

Method: 提出了两种分析性重建流程，并通过同步辐射显微断层扫描实验验证。

Result: 新方法显著减少重建图像中的随机噪声，同时保留物体锐利特征，或在相同质量下降低辐射剂量。

Conclusion: 新方法优于传统门控方法，代码已开源。

Abstract: Time-resolved CT is an advanced measurement technique that has been widely
used to observe dynamic objects, including periodically varying structures such
as hearts, lungs, or hearing structures. To reconstruct these objects from CT
projections, a common approach is to divide the projections into several
collections based on their motion phases and perform reconstruction within each
collection, assuming they originate from a static object. This describes the
gating-based method, which is the standard approach for time-periodic
reconstruction. However, the gating-based reconstruction algorithm only
utilizes a limited subset of projections within each collection and ignores the
correlation between different collections, leading to inefficient use of the
radiation dose. To address this issue, we propose two analytical reconstruction
pipelines in this paper, and validate them with experimental data captured
using tomographic synchrotron microscopy. We demonstrate that our approaches
significantly reduce random noise in the reconstructed images without blurring
the sharp features of the observed objects. Equivalently, our methods can
achieve the same reconstruction quality as gating-based methods but with a
lower radiation dose. Our code is available at github.com/PeriodRecon.

</details>


### [554] [Personalized MR-Informed Diffusion Models for 3D PET Image Reconstruction](https://arxiv.org/abs/2506.03804)
*George Webber,Alexander Hammers,Andrew P. King,Andrew J. Reader*

Main category: physics.med-ph

TL;DR: 论文提出了一种利用多受试者PET-MR扫描数据生成受试者特异性PET图像的方法，通过图像配准合成“伪PET”图像，并用于预训练个性化扩散模型，以提高低计数数据的重建精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法利用预训练扩散模型重建PET图像，但缺乏对受试者特异性数据的利用。本文旨在通过合成受试者特异性PET图像，结合MR扫描信息，提升重建效果。

Method: 通过图像配准技术在多受试者PET-MR数据中生成受试者特异性“伪PET”图像，并用于预训练个性化扩散模型。

Result: 实验表明，该方法在低计数数据下提高了重建精度，同时保留了PET独有的图像特征，避免了过度依赖MR解剖信息。

Conclusion: 该方法为医学影像任务提供了一种无需大规模训练数据或生成式深度学习的受试者特异性PET图像生成方案，具有广泛应用潜力。

Abstract: Recent work has shown improved lesion detectability and flexibility to
reconstruction hyperparameters (e.g. scanner geometry or dose level) when PET
images are reconstructed by leveraging pre-trained diffusion models. Such
methods train a diffusion model (without sinogram data) on high-quality, but
still noisy, PET images. In this work, we propose a simple method for
generating subject-specific PET images from a dataset of multi-subject PET-MR
scans, synthesizing "pseudo-PET" images by transforming between different
patients' anatomy using image registration. The images we synthesize retain
information from the subject's MR scan, leading to higher resolution and the
retention of anatomical features compared to the original set of PET images.
With simulated and real [$^{18}$F]FDG datasets, we show that pre-training a
personalized diffusion model with subject-specific "pseudo-PET" images improves
reconstruction accuracy with low-count data. In particular, the method shows
promise in combining information from a guidance MR scan without overly
imposing anatomical features, demonstrating an improved trade-off between
reconstructing PET-unique image features versus features present in both PET
and MR. We believe this approach for generating and utilizing synthetic data
has further applications to medical imaging tasks, particularly because
patient-specific PET images can be generated without resorting to generative
deep learning or large training datasets.

</details>


### [555] [Analytical Reconstruction of Periodically Deformed Objects in Time-resolved CT](https://arxiv.org/abs/2506.03792)
*Qianwei Qu,Christian M. Schlepütz,Marco Stampanoni*

Main category: physics.med-ph

TL;DR: 论文提出两种新的时间分辨CT重建方法，相比传统门控方法，能更高效利用辐射剂量并减少噪声。


<details>
  <summary>Details</summary>
Motivation: 传统门控方法仅利用部分投影数据且忽略不同集合间的相关性，导致辐射剂量利用效率低。

Method: 提出两种分析重建流程，并通过同步辐射显微断层扫描实验验证。

Result: 新方法显著减少重建图像中的随机噪声，同时保持物体锐利特征，或在相同质量下降低辐射剂量。

Conclusion: 新方法优于传统门控方法，代码已开源。

Abstract: Time-resolved CT is an advanced measurement technique that has been widely
used to observe dynamic objects, including periodically varying structures such
as hearts, lungs, or hearing structures. To reconstruct these objects from CT
projections, a common approach is to divide the projections into several
collections based on their motion phases and perform reconstruction within each
collection, assuming they originate from a static object. This describes the
gating-based method, which is the standard approach for time-periodic
reconstruction. However, the gating-based reconstruction algorithm only
utilizes a limited subset of projections within each collection and ignores the
correlation between different collections, leading to inefficient use of the
radiation dose. To address this issue, we propose two analytical reconstruction
pipelines in this paper, and validate them with experimental data captured
using tomographic synchrotron microscopy. We demonstrate that our approaches
significantly reduce random noise in the reconstructed images without blurring
the sharp features of the observed objects. Equivalently, our methods can
achieve the same reconstruction quality as gating-based methods but with a
lower radiation dose. Our code is available at github.com/PeriodRecon.

</details>


### [556] [Personalized MR-Informed Diffusion Models for 3D PET Image Reconstruction](https://arxiv.org/abs/2506.03804)
*George Webber,Alexander Hammers,Andrew P. King,Andrew J. Reader*

Main category: physics.med-ph

TL;DR: 提出一种利用图像配准生成患者特异性“伪PET”图像的方法，结合扩散模型提升低计数PET图像重建精度。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在PET图像重建中对高剂量数据的依赖，同时保留MR扫描的解剖信息。

Method: 通过多患者PET-MR扫描数据生成患者特异性“伪PET”图像，用于预训练个性化扩散模型。

Result: 在模拟和真实[$^{18}$F]FDG数据中，该方法提升了低计数数据的重建精度，平衡了PET和MR特征的保留。

Conclusion: 该方法无需依赖生成式深度学习或大规模数据集，为医学影像任务提供了新的合成数据应用途径。

Abstract: Recent work has shown improved lesion detectability and flexibility to
reconstruction hyperparameters (e.g. scanner geometry or dose level) when PET
images are reconstructed by leveraging pre-trained diffusion models. Such
methods train a diffusion model (without sinogram data) on high-quality, but
still noisy, PET images. In this work, we propose a simple method for
generating subject-specific PET images from a dataset of multi-subject PET-MR
scans, synthesizing "pseudo-PET" images by transforming between different
patients' anatomy using image registration. The images we synthesize retain
information from the subject's MR scan, leading to higher resolution and the
retention of anatomical features compared to the original set of PET images.
With simulated and real [$^{18}$F]FDG datasets, we show that pre-training a
personalized diffusion model with subject-specific "pseudo-PET" images improves
reconstruction accuracy with low-count data. In particular, the method shows
promise in combining information from a guidance MR scan without overly
imposing anatomical features, demonstrating an improved trade-off between
reconstructing PET-unique image features versus features present in both PET
and MR. We believe this approach for generating and utilizing synthetic data
has further applications to medical imaging tasks, particularly because
patient-specific PET images can be generated without resorting to generative
deep learning or large training datasets.

</details>


<div id='cs.MM'></div>

# cs.MM [[Back]](#toc)

### [557] [How Far Are We from Predicting Missing Modalities with Foundation Models?](https://arxiv.org/abs/2506.03530)
*Guanzhou Ke,Yi Xie,Xiaoli Wang,Guoqing Chao,Bo Wang,Shengfeng He*

Main category: cs.MM

TL;DR: 本文探讨了多模态基础模型在缺失模态预测中的潜力，提出了一个动态框架和自我优化机制，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型在缺失模态预测中表现不足，尤其是在细粒度语义提取和生成模态验证方面存在缺陷。

Method: 提出了一个动态的代理框架和自我优化机制，通过上下文感知策略提取更丰富的语义特征，并通过内部反馈迭代优化生成模态的质量。

Result: 实验表明，该方法在缺失图像预测中FID降低至少14%，在缺失文本预测中MER降低至少10%。

Conclusion: 该方法显著提升了缺失模态预测的准确性和鲁棒性，为多模态基础模型的实际应用提供了新思路。

Abstract: Multimodal foundation models have demonstrated impressive capabilities across
diverse tasks. However, their potential as plug-and-play solutions for missing
modality prediction remains underexplored. To investigate this, we categorize
existing approaches into three representative paradigms, encompassing a total
of 42 model variants, and conduct a comprehensive evaluation in terms of
prediction accuracy and adaptability to downstream tasks. Our analysis reveals
that current foundation models often fall short in two critical aspects: (i)
fine-grained semantic extraction from the available modalities, and (ii) robust
validation of generated modalities. These limitations lead to suboptimal and,
at times, misaligned predictions. To address these challenges, we propose an
agentic framework tailored for missing modality prediction. This framework
dynamically formulates modality-aware mining strategies based on the input
context, facilitating the extraction of richer and more discriminative semantic
features. In addition, we introduce a \textit{self-refinement mechanism}, which
iteratively verifies and enhances the quality of generated modalities through
internal feedback. Experimental results show that our method reduces FID for
missing image prediction by at least 14% and MER for missing text prediction by
at least 10% compared to baselines.

</details>


### [558] [How Far Are We from Predicting Missing Modalities with Foundation Models?](https://arxiv.org/abs/2506.03530)
*Guanzhou Ke,Yi Xie,Xiaoli Wang,Guoqing Chao,Bo Wang,Shengfeng He*

Main category: cs.MM

TL;DR: 该论文探讨了多模态基础模型在缺失模态预测中的潜力，提出了一种动态代理框架和自我优化机制，显著提升了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态基础模型在多种任务中表现出色，但其在缺失模态预测中的潜力尚未充分挖掘，现有方法存在语义提取和验证不足的问题。

Method: 论文将现有方法分为三类，提出了一种动态代理框架和自我优化机制，以提取更丰富的语义特征并验证生成模态的质量。

Result: 实验表明，该方法在缺失图像预测中FID降低至少14%，缺失文本预测中MER降低至少10%。

Conclusion: 提出的框架有效解决了现有模型的局限性，显著提升了缺失模态预测的性能。

Abstract: Multimodal foundation models have demonstrated impressive capabilities across
diverse tasks. However, their potential as plug-and-play solutions for missing
modality prediction remains underexplored. To investigate this, we categorize
existing approaches into three representative paradigms, encompassing a total
of 42 model variants, and conduct a comprehensive evaluation in terms of
prediction accuracy and adaptability to downstream tasks. Our analysis reveals
that current foundation models often fall short in two critical aspects: (i)
fine-grained semantic extraction from the available modalities, and (ii) robust
validation of generated modalities. These limitations lead to suboptimal and,
at times, misaligned predictions. To address these challenges, we propose an
agentic framework tailored for missing modality prediction. This framework
dynamically formulates modality-aware mining strategies based on the input
context, facilitating the extraction of richer and more discriminative semantic
features. In addition, we introduce a \textit{self-refinement mechanism}, which
iteratively verifies and enhances the quality of generated modalities through
internal feedback. Experimental results show that our method reduces FID for
missing image prediction by at least 14% and MER for missing text prediction by
at least 10% compared to baselines.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [559] [Pseudo-Simulation for Autonomous Driving](https://arxiv.org/abs/2506.04218)
*Wei Cao,Marcel Hallgarten,Tianyu Li,Daniel Dauner,Xunjiang Gu,Caojun Wang,Yakov Miron,Marco Aiello,Hongyang Li,Igor Gilitschenski,Boris Ivanovic,Marco Pavone,Andreas Geiger,Kashyap Chitta*

Main category: cs.RO

TL;DR: 本文提出了一种名为伪模拟的新评估范式，用于解决自动驾驶车辆（AVs）现有评估方法的局限性，结合了真实数据和合成观测，并通过基于接近度的加权方案提高评估效果。


<details>
  <summary>Details</summary>
Motivation: 现有AV评估方法存在局限性：真实世界评估因安全性和可重复性问题难以实施，闭环模拟则面临真实感不足或计算成本高的问题，而开环评估忽略了复合误差。

Method: 提出伪模拟方法，基于真实数据集并利用3D高斯散射生成合成观测，通过基于接近度的加权方案评估AV的潜在未来状态。

Result: 伪模拟与闭环模拟的相关性（R^2=0.8）优于现有最佳开环方法（R^2=0.7），并建立了公共排行榜。

Conclusion: 伪模拟是一种高效且准确的AV评估方法，解决了现有方法的局限性，为社区提供了新的基准工具。

Abstract: Existing evaluation paradigms for Autonomous Vehicles (AVs) face critical
limitations. Real-world evaluation is often challenging due to safety concerns
and a lack of reproducibility, whereas closed-loop simulation can face
insufficient realism or high computational costs. Open-loop evaluation, while
being efficient and data-driven, relies on metrics that generally overlook
compounding errors. In this paper, we propose pseudo-simulation, a novel
paradigm that addresses these limitations. Pseudo-simulation operates on real
datasets, similar to open-loop evaluation, but augments them with synthetic
observations generated prior to evaluation using 3D Gaussian Splatting. Our key
idea is to approximate potential future states the AV might encounter by
generating a diverse set of observations that vary in position, heading, and
speed. Our method then assigns a higher importance to synthetic observations
that best match the AV's likely behavior using a novel proximity-based
weighting scheme. This enables evaluating error recovery and the mitigation of
causal confusion, as in closed-loop benchmarks, without requiring sequential
interactive simulation. We show that pseudo-simulation is better correlated
with closed-loop simulations (R^2=0.8) than the best existing open-loop
approach (R^2=0.7). We also establish a public leaderboard for the community to
benchmark new methodologies with pseudo-simulation. Our code is available at
https://github.com/autonomousvision/navsim.

</details>


### [560] [Object-centric 3D Motion Field for Robot Learning from Human Videos](https://arxiv.org/abs/2506.04227)
*Zhao-Heng Yin,Sherry Yang,Pieter Abbeel*

Main category: cs.RO

TL;DR: 提出了一种基于对象中心3D运动场的动作表示方法，用于从人类视频中学习机器人控制策略，显著提升了3D运动估计精度和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有动作表示方法（如视频帧、像素流等）存在建模复杂或信息丢失的问题，限制了机器人学习的效果。

Method: 采用对象中心的3D运动场表示动作，提出了一种新框架，包括去噪3D运动场估计器和密集对象中心3D运动场预测架构。

Result: 实验显示，3D运动估计误差降低50%以上，任务平均成功率达55%，优于现有方法（<10%）。

Conclusion: 该方法有效解决了动作表示问题，显著提升了机器人从人类视频中学习控制策略的能力。

Abstract: Learning robot control policies from human videos is a promising direction
for scaling up robot learning. However, how to extract action knowledge (or
action representations) from videos for policy learning remains a key
challenge. Existing action representations such as video frames, pixelflow, and
pointcloud flow have inherent limitations such as modeling complexity or loss
of information. In this paper, we propose to use object-centric 3D motion field
to represent actions for robot learning from human videos, and present a novel
framework for extracting this representation from videos for zero-shot control.
We introduce two novel components in its implementation. First, a novel
training pipeline for training a ''denoising'' 3D motion field estimator to
extract fine object 3D motions from human videos with noisy depth robustly.
Second, a dense object-centric 3D motion field prediction architecture that
favors both cross-embodiment transfer and policy generalization to background.
We evaluate the system in real world setups. Experiments show that our method
reduces 3D motion estimation error by over 50% compared to the latest method,
achieve 55% average success rate in diverse tasks where prior approaches
fail~($\lesssim 10$\%), and can even acquire fine-grained manipulation skills
like insertion.

</details>


### [561] [Pseudo-Simulation for Autonomous Driving](https://arxiv.org/abs/2506.04218)
*Wei Cao,Marcel Hallgarten,Tianyu Li,Daniel Dauner,Xunjiang Gu,Caojun Wang,Yakov Miron,Marco Aiello,Hongyang Li,Igor Gilitschenski,Boris Ivanovic,Marco Pavone,Andreas Geiger,Kashyap Chitta*

Main category: cs.RO

TL;DR: 提出了一种名为“伪模拟”的新评估范式，结合了真实数据和合成观测，解决了现有AV评估方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有AV评估方法（如真实世界评估、闭环模拟和开环评估）存在安全性、可重复性、真实性和计算成本等问题。

Method: 使用3D高斯散射生成合成观测，并通过基于邻近性的加权方案评估AV的潜在未来状态。

Result: 伪模拟与闭环模拟的相关性（R²=0.8）优于现有最佳开环方法（R²=0.7）。

Conclusion: 伪模拟是一种高效且数据驱动的评估方法，能够在不依赖顺序交互模拟的情况下评估错误恢复和因果混淆缓解。

Abstract: Existing evaluation paradigms for Autonomous Vehicles (AVs) face critical
limitations. Real-world evaluation is often challenging due to safety concerns
and a lack of reproducibility, whereas closed-loop simulation can face
insufficient realism or high computational costs. Open-loop evaluation, while
being efficient and data-driven, relies on metrics that generally overlook
compounding errors. In this paper, we propose pseudo-simulation, a novel
paradigm that addresses these limitations. Pseudo-simulation operates on real
datasets, similar to open-loop evaluation, but augments them with synthetic
observations generated prior to evaluation using 3D Gaussian Splatting. Our key
idea is to approximate potential future states the AV might encounter by
generating a diverse set of observations that vary in position, heading, and
speed. Our method then assigns a higher importance to synthetic observations
that best match the AV's likely behavior using a novel proximity-based
weighting scheme. This enables evaluating error recovery and the mitigation of
causal confusion, as in closed-loop benchmarks, without requiring sequential
interactive simulation. We show that pseudo-simulation is better correlated
with closed-loop simulations (R^2=0.8) than the best existing open-loop
approach (R^2=0.7). We also establish a public leaderboard for the community to
benchmark new methodologies with pseudo-simulation. Our code is available at
https://github.com/autonomousvision/navsim.

</details>


### [562] [Object-centric 3D Motion Field for Robot Learning from Human Videos](https://arxiv.org/abs/2506.04227)
*Zhao-Heng Yin,Sherry Yang,Pieter Abbeel*

Main category: cs.RO

TL;DR: 论文提出了一种基于物体中心3D运动场的动作表示方法，用于从人类视频中学习机器人控制策略，并展示了其在新框架中的实现。


<details>
  <summary>Details</summary>
Motivation: 从人类视频中学习机器人控制策略是一个有前景的方向，但如何提取有效的动作知识仍是一个关键挑战。现有方法存在建模复杂或信息丢失的问题。

Method: 提出使用物体中心3D运动场表示动作，并设计了一个新框架。包括两部分：1）训练去噪3D运动场估计器；2）密集物体中心3D运动场预测架构。

Result: 实验表明，该方法将3D运动估计误差降低50%以上，在多样化任务中达到55%的平均成功率，并能学习精细操作技能。

Conclusion: 物体中心3D运动场是一种有效的动作表示方法，显著提升了机器人从人类视频中学习控制策略的性能。

Abstract: Learning robot control policies from human videos is a promising direction
for scaling up robot learning. However, how to extract action knowledge (or
action representations) from videos for policy learning remains a key
challenge. Existing action representations such as video frames, pixelflow, and
pointcloud flow have inherent limitations such as modeling complexity or loss
of information. In this paper, we propose to use object-centric 3D motion field
to represent actions for robot learning from human videos, and present a novel
framework for extracting this representation from videos for zero-shot control.
We introduce two novel components in its implementation. First, a novel
training pipeline for training a ''denoising'' 3D motion field estimator to
extract fine object 3D motions from human videos with noisy depth robustly.
Second, a dense object-centric 3D motion field prediction architecture that
favors both cross-embodiment transfer and policy generalization to background.
We evaluate the system in real world setups. Experiments show that our method
reduces 3D motion estimation error by over 50% compared to the latest method,
achieve 55% average success rate in diverse tasks where prior approaches
fail~($\lesssim 10$\%), and can even acquire fine-grained manipulation skills
like insertion.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [563] [Multi-Spectral Gaussian Splatting with Neural Color Representation](https://arxiv.org/abs/2506.03407)
*Lukas Meyer,Josef Grün,Maximilian Weiherer,Bernhard Egger,Marc Stamminger,Linus Franke*

Main category: cs.GR

TL;DR: MS-Splatting是一种多光谱3D高斯泼溅框架，能够从不同光谱域的独立相机图像生成多视角一致的新视图，无需跨模态相机校准。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要跨模态相机校准，且无法充分利用光谱和空间相关性。MS-Splatting旨在解决这些问题，支持多种光谱（如热红外和近红外）的统一建模。

Method: 提出一种神经颜色表示方法，将多光谱信息编码为紧凑的每泼溅特征嵌入，并通过浅层MLP解码为光谱颜色值，实现所有波段的联合学习。

Result: 实验表明，该方法提高了多光谱渲染质量，并在单光谱渲染质量上优于现有技术。

Conclusion: MS-Splatting是一种简单有效的多光谱渲染方法，适用于农业等领域的植被指数渲染。

Abstract: We present MS-Splatting -- a multi-spectral 3D Gaussian Splatting (3DGS)
framework that is able to generate multi-view consistent novel views from
images of multiple, independent cameras with different spectral domains. In
contrast to previous approaches, our method does not require cross-modal camera
calibration and is versatile enough to model a variety of different spectra,
including thermal and near-infra red, without any algorithmic changes.
  Unlike existing 3DGS-based frameworks that treat each modality separately (by
optimizing per-channel spherical harmonics) and therefore fail to exploit the
underlying spectral and spatial correlations, our method leverages a novel
neural color representation that encodes multi-spectral information into a
learned, compact, per-splat feature embedding. A shallow multi-layer perceptron
(MLP) then decodes this embedding to obtain spectral color values, enabling
joint learning of all bands within a unified representation.
  Our experiments show that this simple yet effective strategy is able to
improve multi-spectral rendering quality, while also leading to improved
per-spectra rendering quality over state-of-the-art methods. We demonstrate the
effectiveness of this new technique in agricultural applications to render
vegetation indices, such as normalized difference vegetation index (NDVI).

</details>


### [564] [Facial Appearance Capture at Home with Patch-Level Reflectance Prior](https://arxiv.org/abs/2506.03478)
*Yuxuan Han,Junfeng Lyu,Kuan Sheng,Minghao Que,Qixuan Zhang,Lan Xu,Feng Xu*

Main category: cs.GR

TL;DR: 本文提出了一种基于智能手机和闪光灯的低成本面部外观捕捉方法，通过扩散先验和补丁级后采样技术，显著提升了重建质量，接近工作室录制效果。


<details>
  <summary>Details</summary>
Motivation: 现有智能手机视频捕捉的面部反射重建质量远低于工作室录制，本文旨在填补这一差距。

Method: 利用扩散先验学习光舞台扫描数据分布，提出补丁级训练和采样技术，生成高质量反射图。

Result: 实验表明，该方法大幅缩小了低成本与工作室录制之间的质量差距。

Conclusion: 该方法为日常用户提供了高质量的数字克隆解决方案，代码已开源。

Abstract: Existing facial appearance capture methods can reconstruct plausible facial
reflectance from smartphone-recorded videos. However, the reconstruction
quality is still far behind the ones based on studio recordings. This paper
fills the gap by developing a novel daily-used solution with a co-located
smartphone and flashlight video capture setting in a dim room. To enhance the
quality, our key observation is to solve facial reflectance maps within the
data distribution of studio-scanned ones. Specifically, we first learn a
diffusion prior over the Light Stage scans and then steer it to produce the
reflectance map that best matches the captured images. We propose to train the
diffusion prior at the patch level to improve generalization ability and
training stability, as current Light Stage datasets are in ultra-high
resolution but limited in data size. Tailored to this prior, we propose a
patch-level posterior sampling technique to sample seamless full-resolution
reflectance maps from this patch-level diffusion model. Experiments demonstrate
our method closes the quality gap between low-cost and studio recordings by a
large margin, opening the door for everyday users to clone themselves to the
digital world. Our code will be released at https://github.com/yxuhan/DoRA.

</details>


### [565] [SplArt: Articulation Estimation and Part-Level Reconstruction with 3D Gaussian Splatting](https://arxiv.org/abs/2506.03594)
*Shengjie Lin,Jiading Fang,Muhammad Zubair Irshad,Vitor Campagnolo Guizilini,Rares Andrei Ambrus,Greg Shakhnarovich,Matthew R. Walter*

Main category: cs.GR

TL;DR: SplArt是一个自监督、类别无关的框架，利用3D高斯泼溅技术重建关节物体并推断运动学，实现实时逼真渲染。


<details>
  <summary>Details</summary>
Motivation: 现有方法在可扩展性、鲁棒性和渲染效果上存在不足，SplArt旨在解决这些问题。

Method: 通过为每个高斯添加可微移动参数，采用多阶段优化策略处理重建、部件分割和关节估计。

Result: 在基准测试和实际应用中表现出色，无需3D标注或类别先验。

Conclusion: SplArt在性能和实用性上达到领先水平，代码已开源。

Abstract: Reconstructing articulated objects prevalent in daily environments is crucial
for applications in augmented/virtual reality and robotics. However, existing
methods face scalability limitations (requiring 3D supervision or costly
annotations), robustness issues (being susceptible to local optima), and
rendering shortcomings (lacking speed or photorealism). We introduce SplArt, a
self-supervised, category-agnostic framework that leverages 3D Gaussian
Splatting (3DGS) to reconstruct articulated objects and infer kinematics from
two sets of posed RGB images captured at different articulation states,
enabling real-time photorealistic rendering for novel viewpoints and
articulations. SplArt augments 3DGS with a differentiable mobility parameter
per Gaussian, achieving refined part segmentation. A multi-stage optimization
strategy is employed to progressively handle reconstruction, part segmentation,
and articulation estimation, significantly enhancing robustness and accuracy.
SplArt exploits geometric self-supervision, effectively addressing challenging
scenarios without requiring 3D annotations or category-specific priors.
Evaluations on established and newly proposed benchmarks, along with
applications to real-world scenarios using a handheld RGB camera, demonstrate
SplArt's state-of-the-art performance and real-world practicality. Code is
publicly available at https://github.com/ripl/splart.

</details>


### [566] [Multi-Spectral Gaussian Splatting with Neural Color Representation](https://arxiv.org/abs/2506.03407)
*Lukas Meyer,Josef Grün,Maximilian Weiherer,Bernhard Egger,Marc Stamminger,Linus Franke*

Main category: cs.GR

TL;DR: MS-Splatting是一种多光谱3D高斯泼溅框架，能够从不同光谱域的独立相机生成多视角一致的新视图，无需跨模态相机校准。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要跨模态相机校准，且无法有效利用光谱和空间相关性。

Method: 采用神经颜色表示法，将多光谱信息编码为紧凑的每泼溅特征嵌入，并通过浅层MLP解码为光谱颜色值。

Result: 实验表明，该方法提高了多光谱渲染质量，并在农业应用中有效渲染植被指数（如NDVI）。

Conclusion: MS-Splatting是一种简单有效的多光谱渲染方法，优于现有技术。

Abstract: We present MS-Splatting -- a multi-spectral 3D Gaussian Splatting (3DGS)
framework that is able to generate multi-view consistent novel views from
images of multiple, independent cameras with different spectral domains. In
contrast to previous approaches, our method does not require cross-modal camera
calibration and is versatile enough to model a variety of different spectra,
including thermal and near-infra red, without any algorithmic changes.
  Unlike existing 3DGS-based frameworks that treat each modality separately (by
optimizing per-channel spherical harmonics) and therefore fail to exploit the
underlying spectral and spatial correlations, our method leverages a novel
neural color representation that encodes multi-spectral information into a
learned, compact, per-splat feature embedding. A shallow multi-layer perceptron
(MLP) then decodes this embedding to obtain spectral color values, enabling
joint learning of all bands within a unified representation.
  Our experiments show that this simple yet effective strategy is able to
improve multi-spectral rendering quality, while also leading to improved
per-spectra rendering quality over state-of-the-art methods. We demonstrate the
effectiveness of this new technique in agricultural applications to render
vegetation indices, such as normalized difference vegetation index (NDVI).

</details>


### [567] [Facial Appearance Capture at Home with Patch-Level Reflectance Prior](https://arxiv.org/abs/2506.03478)
*Yuxuan Han,Junfeng Lyu,Kuan Sheng,Minghao Que,Qixuan Zhang,Lan Xu,Feng Xu*

Main category: cs.GR

TL;DR: 本文提出了一种基于智能手机和闪光灯在暗室中捕获视频的新方法，通过扩散先验学习提升面部反射图质量，缩小与工作室录制效果的差距。


<details>
  <summary>Details</summary>
Motivation: 现有智能手机视频捕获的面部反射重建质量远低于工作室录制，本文旨在填补这一差距，提供日常可用的高质量解决方案。

Method: 提出一种基于扩散先验学习的方法，首先在Light Stage扫描数据上学习扩散先验，然后通过补丁级训练和采样技术生成高质量反射图。

Result: 实验表明，该方法显著缩小了低成本与工作室录制之间的质量差距。

Conclusion: 该方法为日常用户提供了高质量的数字克隆解决方案，代码将开源。

Abstract: Existing facial appearance capture methods can reconstruct plausible facial
reflectance from smartphone-recorded videos. However, the reconstruction
quality is still far behind the ones based on studio recordings. This paper
fills the gap by developing a novel daily-used solution with a co-located
smartphone and flashlight video capture setting in a dim room. To enhance the
quality, our key observation is to solve facial reflectance maps within the
data distribution of studio-scanned ones. Specifically, we first learn a
diffusion prior over the Light Stage scans and then steer it to produce the
reflectance map that best matches the captured images. We propose to train the
diffusion prior at the patch level to improve generalization ability and
training stability, as current Light Stage datasets are in ultra-high
resolution but limited in data size. Tailored to this prior, we propose a
patch-level posterior sampling technique to sample seamless full-resolution
reflectance maps from this patch-level diffusion model. Experiments demonstrate
our method closes the quality gap between low-cost and studio recordings by a
large margin, opening the door for everyday users to clone themselves to the
digital world. Our code will be released at https://github.com/yxuhan/DoRA.

</details>


### [568] [SplArt: Articulation Estimation and Part-Level Reconstruction with 3D Gaussian Splatting](https://arxiv.org/abs/2506.03594)
*Shengjie Lin,Jiading Fang,Muhammad Zubair Irshad,Vitor Campagnolo Guizilini,Rares Andrei Ambrus,Greg Shakhnarovich,Matthew R. Walter*

Main category: cs.GR

TL;DR: SplArt是一种自监督、类别无关的框架，利用3D高斯泼溅技术重建关节物体并推断运动学，支持实时逼真渲染。


<details>
  <summary>Details</summary>
Motivation: 现有方法在可扩展性、鲁棒性和渲染质量上存在不足，限制了其在增强/虚拟现实和机器人领域的应用。

Method: 通过为每个高斯添加可微移动参数，采用多阶段优化策略逐步处理重建、部件分割和关节估计。

Result: 在基准测试和实际应用中，SplArt表现出色，无需3D标注或类别先验。

Conclusion: SplArt在性能和实用性上达到先进水平，代码已开源。

Abstract: Reconstructing articulated objects prevalent in daily environments is crucial
for applications in augmented/virtual reality and robotics. However, existing
methods face scalability limitations (requiring 3D supervision or costly
annotations), robustness issues (being susceptible to local optima), and
rendering shortcomings (lacking speed or photorealism). We introduce SplArt, a
self-supervised, category-agnostic framework that leverages 3D Gaussian
Splatting (3DGS) to reconstruct articulated objects and infer kinematics from
two sets of posed RGB images captured at different articulation states,
enabling real-time photorealistic rendering for novel viewpoints and
articulations. SplArt augments 3DGS with a differentiable mobility parameter
per Gaussian, achieving refined part segmentation. A multi-stage optimization
strategy is employed to progressively handle reconstruction, part segmentation,
and articulation estimation, significantly enhancing robustness and accuracy.
SplArt exploits geometric self-supervision, effectively addressing challenging
scenarios without requiring 3D annotations or category-specific priors.
Evaluations on established and newly proposed benchmarks, along with
applications to real-world scenarios using a handheld RGB camera, demonstrate
SplArt's state-of-the-art performance and real-world practicality. Code is
publicly available at https://github.com/ripl/splart.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [569] [Tone recognition in low-resource languages of North-East India: peeling the layers of SSL-based speech models](https://arxiv.org/abs/2506.03606)
*Parismita Gogoi,Sishir Kalita,Wendy Lalhminghlui,Viyazonuo Terhiija,Moakala Tzudir,Priyankoo Sarmah,S. R. M. Prasanna*

Main category: eess.AS

TL;DR: 研究评估了自监督学习模型在三种低资源语言（Angami、Ao、Mizo）中的声调识别表现，发现Mizo效果最佳，Angami最差，且中间层对声调识别最关键。


<details>
  <summary>Details</summary>
Motivation: 探索自监督学习模型在低资源语言声调识别中的应用，为改进低资源环境下的声调识别提供依据。

Method: 使用四种Wav2vec2.0基础模型，分析不同语言和模型层的声调识别表现。

Result: Mizo的声调识别效果最好，Angami最差；中间层对声调识别最有效；声调库和方言变化影响识别。

Conclusion: 自监督学习模型在低资源语言声调识别中具有潜力，但需考虑声调类型和方言差异。

Abstract: This study explores the use of self-supervised learning (SSL) models for tone
recognition in three low-resource languages from North Eastern India: Angami,
Ao, and Mizo. We evaluate four Wav2vec2.0 base models that were pre-trained on
both tonal and non-tonal languages. We analyze tone-wise performance across the
layers for all three languages and compare the different models. Our results
show that tone recognition works best for Mizo and worst for Angami. The middle
layers of the SSL models are the most important for tone recognition,
regardless of the pre-training language, i.e. tonal or non-tonal. We have also
found that the tone inventory, tone types, and dialectal variations affect tone
recognition. These findings provide useful insights into the strengths and
weaknesses of SSL-based embeddings for tonal languages and highlight the
potential for improving tone recognition in low-resource settings. The source
code is available at GitHub 1 .

</details>


### [570] [SNIFR : Boosting Fine-Grained Child Harmful Content Detection Through Audio-Visual Alignment with Cascaded Cross-Transformer](https://arxiv.org/abs/2506.03378)
*Orchid Chetia Phukan,Mohd Mujtaba Akhtar,Girish,Swarup Ranjan Behera,Abu Osama Siddiqui,Sarthak Jain,Priyabrata Mallick,Jaya Sai Kiran Patibandla,Pailla Balakrishna Reddy,Arun Balaji Buduru,Rajesh Sharma*

Main category: eess.AS

TL;DR: 论文提出了一种结合音频和视觉特征的多模态框架SNIFR，用于精确检测儿童有害内容，优于现有单模态和基线融合方法。


<details>
  <summary>Details</summary>
Motivation: 随着视频平台的普及，儿童观众增加，恶意用户通过嵌入少量有害帧逃避检测，现有研究多关注视觉特征，音频特征研究不足。

Method: 提出SNIFR框架，使用Transformer编码器进行模态内交互，级联跨模态Transformer进行模态间对齐，结合音频和视觉特征。

Result: SNIFR在儿童有害内容检测上表现优于单模态和基线融合方法，达到新SOTA。

Conclusion: 多模态特征结合（尤其是音频和视觉）能显著提升有害内容检测效果，SNIFR为未来研究提供了新方向。

Abstract: As video-sharing platforms have grown over the past decade, child viewership
has surged, increasing the need for precise detection of harmful content like
violence or explicit scenes. Malicious users exploit moderation systems by
embedding unsafe content in minimal frames to evade detection. While prior
research has focused on visual cues and advanced such fine-grained detection,
audio features remain underexplored. In this study, we embed audio cues with
visual for fine-grained child harmful content detection and introduce SNIFR, a
novel framework for effective alignment. SNIFR employs a transformer encoder
for intra-modality interaction, followed by a cascaded cross-transformer for
inter-modality alignment. Our approach achieves superior performance over
unimodal and baseline fusion methods, setting a new state-of-the-art.

</details>


### [571] [Tone recognition in low-resource languages of North-East India: peeling the layers of SSL-based speech models](https://arxiv.org/abs/2506.03606)
*Parismita Gogoi,Sishir Kalita,Wendy Lalhminghlui,Viyazonuo Terhiija,Moakala Tzudir,Priyankoo Sarmah,S. R. M. Prasanna*

Main category: eess.AS

TL;DR: 研究评估了四种基于Wav2vec2.0的自监督学习模型在三种印度东北部低资源语言（Angami、Ao、Mizo）中的音调识别表现，发现Mizo表现最佳，Angami最差，且中间层对音调识别最关键。


<details>
  <summary>Details</summary>
Motivation: 探索自监督学习模型在低资源语言音调识别中的表现，为改进音调识别提供依据。

Method: 使用四种预训练的Wav2vec2.0基础模型，分析音调识别在不同语言和模型层中的表现。

Result: Mizo音调识别效果最好，Angami最差；中间层对音调识别最关键；音调库、类型和方言变体影响识别。

Conclusion: 自监督学习模型在低资源语言音调识别中具有潜力，但需考虑语言特性和模型层选择。

Abstract: This study explores the use of self-supervised learning (SSL) models for tone
recognition in three low-resource languages from North Eastern India: Angami,
Ao, and Mizo. We evaluate four Wav2vec2.0 base models that were pre-trained on
both tonal and non-tonal languages. We analyze tone-wise performance across the
layers for all three languages and compare the different models. Our results
show that tone recognition works best for Mizo and worst for Angami. The middle
layers of the SSL models are the most important for tone recognition,
regardless of the pre-training language, i.e. tonal or non-tonal. We have also
found that the tone inventory, tone types, and dialectal variations affect tone
recognition. These findings provide useful insights into the strengths and
weaknesses of SSL-based embeddings for tonal languages and highlight the
potential for improving tone recognition in low-resource settings. The source
code is available at GitHub 1 .

</details>


### [572] [SNIFR : Boosting Fine-Grained Child Harmful Content Detection Through Audio-Visual Alignment with Cascaded Cross-Transformer](https://arxiv.org/abs/2506.03378)
*Orchid Chetia Phukan,Mohd Mujtaba Akhtar,Girish,Swarup Ranjan Behera,Abu Osama Siddiqui,Sarthak Jain,Priyabrata Mallick,Jaya Sai Kiran Patibandla,Pailla Balakrishna Reddy,Arun Balaji Buduru,Rajesh Sharma*

Main category: eess.AS

TL;DR: 论文提出了一种结合音频和视觉特征的多模态框架SNIFR，用于精确检测儿童有害内容，性能优于单模态和基线融合方法。


<details>
  <summary>Details</summary>
Motivation: 视频平台儿童观众增加，恶意用户通过嵌入少量有害帧逃避检测，现有研究多关注视觉特征，音频特征未被充分探索。

Method: 提出SNIFR框架，使用Transformer编码器进行模态内交互，级联跨模态Transformer实现模态间对齐。

Result: SNIFR在儿童有害内容检测中表现优于单模态和基线融合方法，达到新SOTA。

Conclusion: 结合音频和视觉特征的多模态方法能更有效地检测儿童有害内容，SNIFR为未来研究提供了新方向。

Abstract: As video-sharing platforms have grown over the past decade, child viewership
has surged, increasing the need for precise detection of harmful content like
violence or explicit scenes. Malicious users exploit moderation systems by
embedding unsafe content in minimal frames to evade detection. While prior
research has focused on visual cues and advanced such fine-grained detection,
audio features remain underexplored. In this study, we embed audio cues with
visual for fine-grained child harmful content detection and introduce SNIFR, a
novel framework for effective alignment. SNIFR employs a transformer encoder
for intra-modality interaction, followed by a cascaded cross-transformer for
inter-modality alignment. Our approach achieves superior performance over
unimodal and baseline fusion methods, setting a new state-of-the-art.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [573] [VisCoder: Fine-Tuning LLMs for Executable Python Visualization Code Generation](https://arxiv.org/abs/2506.03930)
*Yuansheng Ni,Ping Nie,Kai Zou,Xiang Yue,Wenhu Chen*

Main category: cs.SE

TL;DR: VisCode-200K是一个大规模指令调优数据集，用于Python可视化和自我修正，显著提升了模型在可视化任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有指令调优数据集缺乏执行监督和迭代代码修正支持，导致可视化任务表现不佳。

Method: VisCode-200K包含20万+示例，包括开源代码和4.5万+多轮修正对话，用于微调Qwen2.5-Coder-Instruct模型。

Result: VisCoder在PandasPlotBench上表现优于开源基线，接近GPT-4o-mini等专有模型。

Conclusion: 反馈驱动的学习显著提升了可执行代码生成的准确性和视觉语义正确性。

Abstract: Large language models (LLMs) often struggle with visualization tasks like
plotting diagrams, charts, where success depends on both code correctness and
visual semantics. Existing instruction-tuning datasets lack execution-grounded
supervision and offer limited support for iterative code correction, resulting
in fragile and unreliable plot generation. We present VisCode-200K, a
large-scale instruction tuning dataset for Python-based visualization and
self-correction. It contains over 200K examples from two sources: (1) validated
plotting code from open-source repositories, paired with natural language
instructions and rendered plots; and (2) 45K multi-turn correction dialogues
from Code-Feedback, enabling models to revise faulty code using runtime
feedback. We fine-tune Qwen2.5-Coder-Instruct on VisCode-200K to create
VisCoder, and evaluate it on PandasPlotBench. VisCoder significantly
outperforms strong open-source baselines and approaches the performance of
proprietary models like GPT-4o-mini. We further adopt a self-debug evaluation
protocol to assess iterative repair, demonstrating the benefits of
feedback-driven learning for executable, visually accurate code generation.

</details>


### [574] [CETBench: A Novel Dataset constructed via Transformations over Programs for Benchmarking LLMs for Code-Equivalence Checking](https://arxiv.org/abs/2506.04019)
*Neeva Oza,Ishaan Govil,Parul Gupta,Dinesh Khandelwal,Dinesh Garg,Parag Singla*

Main category: cs.SE

TL;DR: 本文探讨了LLMs在代码等价性检查任务中的应用，提出了CETBench数据集，并发现简单的代码转换会显著降低LLMs的性能。通过微调方法提升了性能，并分析了LLMs在代码语义理解上的局限性。


<details>
  <summary>Details</summary>
Motivation: 代码等价性检查是评估LLMs在代码重写和翻译等任务中能力的重要问题，但目前研究较少。

Method: 构建CETBench数据集，通过随机代码转换生成（非）等价程序对，并采用微调方法提升LLMs性能。

Result: 简单代码转换会显著降低LLMs性能，微调方法能有效提升性能。

Conclusion: LLMs在代码语义理解上仍有局限，需进一步研究。

Abstract: LLMs have been extensively used for the task of automated code generation. In
this work, we examine the applicability of LLMs for the related but relatively
unexplored task of code-equivalence checking, i.e., given two programs, whether
they are functionally equivalent or not. This is an important problem since
benchmarking code equivalence can play a critical role in evaluating LLM
capabilities for tasks such as code re-writing and code translation. Towards
this end, we present CETBench - Code Equivalence with Transformations
Benchmark, constructed via a repository of programs, where two programs in the
repository may be solving the same or different tasks. Each instance in our
dataset is obtained by taking a pair of programs in the repository and applying
a random series of pre-defined code transformations, resulting in
(non-)equivalent pairs. Our analysis on this dataset reveals a surprising
finding that very simple code transformations in the underlying pair of
programs can result in a significant drop in performance of SOTA LLMs for the
task of code-equivalence checking. To remedy this, we present a simple
fine-tuning-based approach to boost LLM performance on the transformed pairs of
programs. Our approach for dataset generation is generic, and can be used with
repositories with varying program difficulty levels and allows for applying
varying numbers as well as kinds of transformations. In our experiments, we
perform ablations over the difficulty level of original programs, as well as
the kind of transformations used in generating pairs for equivalence checking.
Our analysis presents deep insights into the working of LLMs for the task of
code-equivalence, and points to the fact that they may still be far from what
could be termed as a semantic understanding of the underlying code.

</details>


### [575] [VisCoder: Fine-Tuning LLMs for Executable Python Visualization Code Generation](https://arxiv.org/abs/2506.03930)
*Yuansheng Ni,Ping Nie,Kai Zou,Xiang Yue,Wenhu Chen*

Main category: cs.SE

TL;DR: VisCode-200K是一个用于Python可视化和自我修正的大规模指令调优数据集，显著提升了模型在图表生成任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在可视化任务中表现不佳，现有数据集缺乏执行监督和迭代修正支持。

Method: 构建VisCode-200K数据集，包含20万示例，包括已验证的绘图代码和多轮修正对话，并基于此微调模型。

Result: VisCoder在PandasPlotBench上表现优于开源基线，接近GPT-4o-mini等专有模型。

Conclusion: 反馈驱动的学习方法显著提升了可执行且视觉准确的代码生成能力。

Abstract: Large language models (LLMs) often struggle with visualization tasks like
plotting diagrams, charts, where success depends on both code correctness and
visual semantics. Existing instruction-tuning datasets lack execution-grounded
supervision and offer limited support for iterative code correction, resulting
in fragile and unreliable plot generation. We present VisCode-200K, a
large-scale instruction tuning dataset for Python-based visualization and
self-correction. It contains over 200K examples from two sources: (1) validated
plotting code from open-source repositories, paired with natural language
instructions and rendered plots; and (2) 45K multi-turn correction dialogues
from Code-Feedback, enabling models to revise faulty code using runtime
feedback. We fine-tune Qwen2.5-Coder-Instruct on VisCode-200K to create
VisCoder, and evaluate it on PandasPlotBench. VisCoder significantly
outperforms strong open-source baselines and approaches the performance of
proprietary models like GPT-4o-mini. We further adopt a self-debug evaluation
protocol to assess iterative repair, demonstrating the benefits of
feedback-driven learning for executable, visually accurate code generation.

</details>


### [576] [CETBench: A Novel Dataset constructed via Transformations over Programs for Benchmarking LLMs for Code-Equivalence Checking](https://arxiv.org/abs/2506.04019)
*Neeva Oza,Ishaan Govil,Parul Gupta,Dinesh Khandelwal,Dinesh Garg,Parag Singla*

Main category: cs.SE

TL;DR: 本文研究了LLMs在代码等价性检查任务中的应用，提出了CETBench数据集，并发现简单的代码变换会导致LLMs性能显著下降。通过微调方法提升了性能。


<details>
  <summary>Details</summary>
Motivation: 代码等价性检查是评估LLMs在代码重写和翻译等任务中的能力的重要问题，但目前研究较少。

Method: 构建CETBench数据集，通过随机应用预定义的代码变换生成（非）等价程序对，并采用微调方法提升LLMs性能。

Result: 简单代码变换显著降低LLMs性能，微调方法有效提升了性能。

Conclusion: LLMs在代码等价性检查任务中仍缺乏对代码的语义理解，需进一步研究。

Abstract: LLMs have been extensively used for the task of automated code generation. In
this work, we examine the applicability of LLMs for the related but relatively
unexplored task of code-equivalence checking, i.e., given two programs, whether
they are functionally equivalent or not. This is an important problem since
benchmarking code equivalence can play a critical role in evaluating LLM
capabilities for tasks such as code re-writing and code translation. Towards
this end, we present CETBench - Code Equivalence with Transformations
Benchmark, constructed via a repository of programs, where two programs in the
repository may be solving the same or different tasks. Each instance in our
dataset is obtained by taking a pair of programs in the repository and applying
a random series of pre-defined code transformations, resulting in
(non-)equivalent pairs. Our analysis on this dataset reveals a surprising
finding that very simple code transformations in the underlying pair of
programs can result in a significant drop in performance of SOTA LLMs for the
task of code-equivalence checking. To remedy this, we present a simple
fine-tuning-based approach to boost LLM performance on the transformed pairs of
programs. Our approach for dataset generation is generic, and can be used with
repositories with varying program difficulty levels and allows for applying
varying numbers as well as kinds of transformations. In our experiments, we
perform ablations over the difficulty level of original programs, as well as
the kind of transformations used in generating pairs for equivalence checking.
Our analysis presents deep insights into the working of LLMs for the task of
code-equivalence, and points to the fact that they may still be far from what
could be termed as a semantic understanding of the underlying code.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [577] [Urban Visibility Hotspots: Quantifying Building Vertex Visibility from Connected Vehicle Trajectories using Spatial Indexing](https://arxiv.org/abs/2506.03365)
*Artur Grigorev,Adriana-Simona Mihaita*

Main category: eess.SY

TL;DR: 该研究提出了一种数据驱动的方法，通过分析大规模车辆轨迹数据，量化户外广告和街道设施的视觉曝光，识别出高曝光的热点区域。


<details>
  <summary>Details</summary>
Motivation: 传统选址方法依赖静态交通数据或主观评估，缺乏客观性。研究旨在通过动态车辆轨迹数据，更准确地评估位置的视觉曝光。

Method: 利用车辆轨迹数据（Compass IoT）和OpenStreetMap建筑顶点数据，构建动态驾驶员视野模型，并通过BallTree空间索引高效计算视觉曝光。

Result: 研究发现视觉曝光高度集中，存在显著的视觉热点，且曝光量符合对数正态分布。

Conclusion: 该方法为户外广告和街道设施的选址提供了客观、高效的量化工具。

Abstract: Effective placement of Out-of-Home advertising and street furniture requires
accurate identification of locations offering maximum visual exposure to target
audiences, particularly vehicular traffic. Traditional site selection methods
often rely on static traffic counts or subjective assessments. This research
introduces a data-driven methodology to objectively quantify location
visibility by analyzing large-scale connected vehicle trajectory data (sourced
from Compass IoT) within urban environments. We model the dynamic driver
field-of-view using a forward-projected visibility area for each vehicle
position derived from interpolated trajectories. By integrating this with
building vertex locations extracted from OpenStreetMap, we quantify the
cumulative visual exposure, or ``visibility count'', for thousands of potential
points of interest near roadways. The analysis reveals that visibility is
highly concentrated, identifying specific ``visual hotspots'' that receive
disproportionately high exposure compared to average locations. The core
technical contribution involves the construction of a BallTree spatial index
over building vertices. This enables highly efficient (O(logN) complexity)
radius queries to determine which vertices fall within the viewing circles of
millions of trajectory points across numerous trips, significantly
outperforming brute-force geometric checks. Analysis reveals two key findings:
1) Visibility is highly concentrated, identifying distinct 'visual hotspots'
receiving disproportionately high exposure compared to average locations. 2)
The aggregated visibility counts across vertices conform to a Log-Normal
distribution.

</details>


### [578] [Urban Visibility Hotspots: Quantifying Building Vertex Visibility from Connected Vehicle Trajectories using Spatial Indexing](https://arxiv.org/abs/2506.03365)
*Artur Grigorev,Adriana-Simona Mihaita*

Main category: eess.SY

TL;DR: 提出了一种基于车辆轨迹数据的数据驱动方法，量化户外广告和街道家具的最佳视觉曝光位置，识别出视觉热点。


<details>
  <summary>Details</summary>
Motivation: 传统选址方法依赖静态交通数据或主观评估，缺乏客观性。本研究旨在通过动态车辆轨迹数据，更准确地量化视觉曝光。

Method: 利用车辆轨迹数据（Compass IoT）和OpenStreetMap建筑顶点，构建动态驾驶员视野模型，通过BallTree空间索引高效计算视觉曝光。

Result: 发现视觉曝光高度集中，形成视觉热点；视觉曝光计数符合对数正态分布。

Conclusion: 数据驱动方法能更客观地识别高曝光位置，为户外广告和街道家具的选址提供科学依据。

Abstract: Effective placement of Out-of-Home advertising and street furniture requires
accurate identification of locations offering maximum visual exposure to target
audiences, particularly vehicular traffic. Traditional site selection methods
often rely on static traffic counts or subjective assessments. This research
introduces a data-driven methodology to objectively quantify location
visibility by analyzing large-scale connected vehicle trajectory data (sourced
from Compass IoT) within urban environments. We model the dynamic driver
field-of-view using a forward-projected visibility area for each vehicle
position derived from interpolated trajectories. By integrating this with
building vertex locations extracted from OpenStreetMap, we quantify the
cumulative visual exposure, or ``visibility count'', for thousands of potential
points of interest near roadways. The analysis reveals that visibility is
highly concentrated, identifying specific ``visual hotspots'' that receive
disproportionately high exposure compared to average locations. The core
technical contribution involves the construction of a BallTree spatial index
over building vertices. This enables highly efficient (O(logN) complexity)
radius queries to determine which vertices fall within the viewing circles of
millions of trajectory points across numerous trips, significantly
outperforming brute-force geometric checks. Analysis reveals two key findings:
1) Visibility is highly concentrated, identifying distinct 'visual hotspots'
receiving disproportionately high exposure compared to average locations. 2)
The aggregated visibility counts across vertices conform to a Log-Normal
distribution.

</details>


<div id='cs.DL'></div>

# cs.DL [[Back]](#toc)

### [579] [Preface to the Special Issue of the TAL Journal on Scholarly Document Processing](https://arxiv.org/abs/2506.03587)
*Florian Boudin,Akiko Aizawa*

Main category: cs.DL

TL;DR: 论文探讨了学术文献快速增长带来的挑战，以及如何利用自动化工具（如大语言模型）帮助研究人员处理复杂信息。


<details>
  <summary>Details</summary>
Motivation: 学术文献的快速增长和复杂性使得研究人员难以跟踪新知识，需要先进工具来辅助。

Method: 利用大语言模型（LLMs）进行文献综述、写作辅助和交互式研究探索。

Result: 大语言模型为处理学术文献提供了新的可能性，能够提取可靠且可操作的见解。

Conclusion: 本期特刊聚焦于自然语言处理和信息检索在学术文献中的应用，以应对这些挑战。

Abstract: The rapid growth of scholarly literature makes it increasingly difficult for
researchers to keep up with new knowledge. Automated tools are now more
essential than ever to help navigate and interpret this vast body of
information. Scientific papers pose unique difficulties, with their complex
language, specialized terminology, and diverse formats, requiring advanced
methods to extract reliable and actionable insights. Large language models
(LLMs) offer new opportunities, enabling tasks such as literature reviews,
writing assistance, and interactive exploration of research. This special issue
of the TAL journal highlights research addressing these challenges and, more
broadly, research on natural language processing and information retrieval for
scholarly and scientific documents.

</details>


### [580] [Knowledge Graphs for Digitized Manuscripts in Jagiellonian Digital Library Application](https://arxiv.org/abs/2506.03180)
*Jan Ignatowicz,Krzysztof Kutt,Grzegorz J. Nalepa*

Main category: cs.DL

TL;DR: 论文探讨了利用计算机视觉、人工智能和语义网技术解决文化遗产数字化中元数据不完整和标准化问题的方法。


<details>
  <summary>Details</summary>
Motivation: 文化遗产数字化对保存历史文物和提升公众可访问性至关重要，但元数据不完整和标准化问题限制了其搜索性和关联性。

Method: 采用计算机视觉、人工智能和语义网技术相结合的方法，丰富元数据并构建知识图谱。

Result: 通过该方法，可以提升数字化手稿和古版书的元数据质量和关联性。

Conclusion: 综合技术方法能有效解决文化遗产数字化中的元数据问题，提升其可用性和互联性。

Abstract: Digitizing cultural heritage collections has become crucial for preservation
of historical artifacts and enhancing their availability to the wider public.
Galleries, libraries, archives and museums (GLAM institutions) are actively
digitizing their holdings and creates extensive digital collections. Those
collections are often enriched with metadata describing items but not exactly
their contents. The Jagiellonian Digital Library, standing as a good example of
such an effort, offers datasets accessible through protocols like OAI-PMH.
Despite these improvements, metadata completeness and standardization continue
to pose substantial obstacles, limiting the searchability and potential
connections between collections. To deal with these challenges, we explore an
integrated methodology of computer vision (CV), artificial intelligence (AI),
and semantic web technologies to enrich metadata and construct knowledge graphs
for digitized manuscripts and incunabula.

</details>


### [581] [Preface to the Special Issue of the TAL Journal on Scholarly Document Processing](https://arxiv.org/abs/2506.03587)
*Florian Boudin,Akiko Aizawa*

Main category: cs.DL

TL;DR: 论文探讨了学术文献快速增长带来的挑战，提出利用大型语言模型（LLMs）等自动化工具帮助研究人员导航和解读复杂信息。


<details>
  <summary>Details</summary>
Motivation: 学术文献的复杂性和快速增长使得研究人员难以跟上新知识，需要先进工具辅助。

Method: 利用大型语言模型（LLMs）进行文献综述、写作辅助和交互式研究探索。

Result: LLMs为学术文献处理提供了新的可能性，能够提取可靠且可操作的见解。

Conclusion: 本期特刊聚焦于自然语言处理和信息检索在学术文献中的应用，以应对这些挑战。

Abstract: The rapid growth of scholarly literature makes it increasingly difficult for
researchers to keep up with new knowledge. Automated tools are now more
essential than ever to help navigate and interpret this vast body of
information. Scientific papers pose unique difficulties, with their complex
language, specialized terminology, and diverse formats, requiring advanced
methods to extract reliable and actionable insights. Large language models
(LLMs) offer new opportunities, enabling tasks such as literature reviews,
writing assistance, and interactive exploration of research. This special issue
of the TAL journal highlights research addressing these challenges and, more
broadly, research on natural language processing and information retrieval for
scholarly and scientific documents.

</details>


### [582] [Knowledge Graphs for Digitized Manuscripts in Jagiellonian Digital Library Application](https://arxiv.org/abs/2506.03180)
*Jan Ignatowicz,Krzysztof Kutt,Grzegorz J. Nalepa*

Main category: cs.DL

TL;DR: 论文探讨了利用计算机视觉、人工智能和语义网技术来丰富数字化文化遗产的元数据，并构建知识图谱。


<details>
  <summary>Details</summary>
Motivation: 数字化文化遗产的元数据不完整且缺乏标准化，限制了搜索性和集合间的潜在联系。

Method: 采用计算机视觉（CV）、人工智能（AI）和语义网技术的综合方法。

Result: 旨在提升数字化手稿和古版书的元数据丰富性和知识图谱构建。

Conclusion: 该方法有望解决元数据问题，增强文化遗产数字化的可用性和连接性。

Abstract: Digitizing cultural heritage collections has become crucial for preservation
of historical artifacts and enhancing their availability to the wider public.
Galleries, libraries, archives and museums (GLAM institutions) are actively
digitizing their holdings and creates extensive digital collections. Those
collections are often enriched with metadata describing items but not exactly
their contents. The Jagiellonian Digital Library, standing as a good example of
such an effort, offers datasets accessible through protocols like OAI-PMH.
Despite these improvements, metadata completeness and standardization continue
to pose substantial obstacles, limiting the searchability and potential
connections between collections. To deal with these challenges, we explore an
integrated methodology of computer vision (CV), artificial intelligence (AI),
and semantic web technologies to enrich metadata and construct knowledge graphs
for digitized manuscripts and incunabula.

</details>


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [583] [Structural Vibration Monitoring with Diffractive Optical Processors](https://arxiv.org/abs/2506.03317)
*Yuntian Wang,Zafer Yilmaz,Yuhang Li,Edward Liu,Eric Ahlberg,Farid Ghahari,Ertugrul Taciroglu,Aydogan Ozcan*

Main category: physics.optics

TL;DR: 提出了一种基于衍射振动监测系统的低成本、低功耗且可扩展的结构健康监测方法，通过联合优化的衍射层和浅层神经网络实现3D振动光谱的远程提取。


<details>
  <summary>Details</summary>
Motivation: 当前结构健康监测（SHM）方案受限于成本、功耗、可扩展性和数据处理复杂性，亟需一种更高效的解决方案。

Method: 结合空间优化的被动衍射层和浅层神经网络后端，将3D结构位移编码为调制光信号，并通过少量探测器实时解码。

Result: 系统在毫米波照明下通过数值和实验验证，精度比传统光学或单独训练模块提高一个数量级。

Conclusion: 该系统为结构的高通量3D监测奠定了基础，并在灾害韧性、航空航天诊断和自主导航等领域具有潜在应用。

Abstract: Structural Health Monitoring (SHM) is vital for maintaining the safety and
longevity of civil infrastructure, yet current solutions remain constrained by
cost, power consumption, scalability, and the complexity of data processing.
Here, we present a diffractive vibration monitoring system, integrating a
jointly optimized diffractive layer with a shallow neural network-based backend
to remotely extract 3D structural vibration spectra, offering a low-power,
cost-effective and scalable solution. This architecture eliminates the need for
dense sensor arrays or extensive data acquisition; instead, it uses a
spatially-optimized passive diffractive layer that encodes 3D structural
displacements into modulated light, captured by a minimal number of detectors
and decoded in real-time by shallow and low-power neural networks to
reconstruct the 3D displacement spectra of structures. The diffractive system's
efficacy was demonstrated both numerically and experimentally using
millimeter-wave illumination on a laboratory-scale building model with a
programmable shake table. Our system achieves more than an order-of-magnitude
improvement in accuracy over conventional optics or separately trained modules,
establishing a foundation for high-throughput 3D monitoring of structures.
Beyond SHM, the 3D vibration monitoring capabilities of this cost-effective and
data-efficient framework establish a new computational sensing modality with
potential applications in disaster resilience, aerospace diagnostics, and
autonomous navigation, where energy efficiency, low latency, and
high-throughput are critical.

</details>


### [584] [Structural Vibration Monitoring with Diffractive Optical Processors](https://arxiv.org/abs/2506.03317)
*Yuntian Wang,Zafer Yilmaz,Yuhang Li,Edward Liu,Eric Ahlberg,Farid Ghahari,Ertugrul Taciroglu,Aydogan Ozcan*

Main category: physics.optics

TL;DR: 提出了一种基于衍射振动监测系统的低成本、低功耗、可扩展的结构健康监测方案，通过联合优化的衍射层和浅层神经网络实现3D结构振动谱的远程提取。


<details>
  <summary>Details</summary>
Motivation: 当前结构健康监测方案在成本、功耗、可扩展性和数据处理复杂性方面存在局限，亟需一种更高效的解决方案。

Method: 采用联合优化的被动衍射层和浅层神经网络后端，将3D结构位移编码为调制光信号，通过少量探测器捕获并实时解码。

Result: 系统在毫米波照明下通过实验室模型验证，精度比传统光学或单独训练模块提高一个数量级。

Conclusion: 该方案为结构的高通量3D监测奠定了基础，并在灾害韧性、航空航天诊断和自主导航等领域具有潜在应用价值。

Abstract: Structural Health Monitoring (SHM) is vital for maintaining the safety and
longevity of civil infrastructure, yet current solutions remain constrained by
cost, power consumption, scalability, and the complexity of data processing.
Here, we present a diffractive vibration monitoring system, integrating a
jointly optimized diffractive layer with a shallow neural network-based backend
to remotely extract 3D structural vibration spectra, offering a low-power,
cost-effective and scalable solution. This architecture eliminates the need for
dense sensor arrays or extensive data acquisition; instead, it uses a
spatially-optimized passive diffractive layer that encodes 3D structural
displacements into modulated light, captured by a minimal number of detectors
and decoded in real-time by shallow and low-power neural networks to
reconstruct the 3D displacement spectra of structures. The diffractive system's
efficacy was demonstrated both numerically and experimentally using
millimeter-wave illumination on a laboratory-scale building model with a
programmable shake table. Our system achieves more than an order-of-magnitude
improvement in accuracy over conventional optics or separately trained modules,
establishing a foundation for high-throughput 3D monitoring of structures.
Beyond SHM, the 3D vibration monitoring capabilities of this cost-effective and
data-efficient framework establish a new computational sensing modality with
potential applications in disaster resilience, aerospace diagnostics, and
autonomous navigation, where energy efficiency, low latency, and
high-throughput are critical.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [585] [GenTT: Generate Vectorized Codes for General Tensor Permutation](https://arxiv.org/abs/2506.03686)
*Yaojian Chen,Tianyu Ma,An Yang,Lin Gan,Wenlai Zhao,Guangwen Yang*

Main category: cs.DS

TL;DR: 提出了一种名为\system的SIMD置换工具包，能够为任意指令集、位宽、张量形状和置换模式生成优化的置换代码，并在实验中实现了最高38倍的加速。


<details>
  <summary>Details</summary>
Motivation: 张量置换是AI和张量网络中的基础操作，但复杂度高且性能优化困难，现有方法难以应对复杂的置换需求。

Method: 开发了\system工具包，支持生成优化的置换代码，适用于多种指令集、位宽和置换模式。

Result: 实验结果显示，\system在特殊情况下可实现38倍加速，一般情况下也有5倍加速。

Conclusion: \system提供了一种高效且通用的张量置换解决方案，显著提升了性能。

Abstract: Tensor permutation is a fundamental operation widely applied in AI, tensor
networks, and related fields. However, it is extremely complex, and different
shapes and permutation maps can make a huge difference. SIMD permutation began
to be studied in 2006, but the best method at that time was to split complex
permutations into multiple simple permutations to do SIMD, which might increase
the complexity for very complex permutations. Subsequently, as tensor
contraction gained significant attention, researchers explored structured
permutations associated with tensor contraction. Progress on general
permutations has been limited, and with increasing SIMD bit widths, achieving
efficient performance for these permutations has become increasingly
challenging. We propose a SIMD permutation toolkit, \system, that generates
optimized permutation code for arbitrary instruction sets, bit widths, tensor
shapes, and permutation patterns, while maintaining low complexity. In our
experiments, \system is able to achieve up to $38\times$ speedup for special
cases and $5\times$ for general gases compared to Numpy.

</details>
