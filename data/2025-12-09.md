<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 74]
- [cs.CV](#cs.CV) [Total: 224]
- [cs.DC](#cs.DC) [Total: 13]
- [cs.AR](#cs.AR) [Total: 10]
- [cs.CR](#cs.CR) [Total: 4]
- [cs.SE](#cs.SE) [Total: 1]
- [cs.MS](#cs.MS) [Total: 1]
- [physics.ed-ph](#physics.ed-ph) [Total: 1]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.MA](#cs.MA) [Total: 1]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.CE](#cs.CE) [Total: 1]
- [eess.IV](#eess.IV) [Total: 7]
- [math.OC](#math.OC) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]
- [cs.LG](#cs.LG) [Total: 24]
- [cs.AI](#cs.AI) [Total: 10]
- [cs.RO](#cs.RO) [Total: 6]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.HC](#cs.HC) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Empathy by Design: Aligning Large Language Models for Healthcare Dialogue](https://arxiv.org/abs/2512.06097)
*Emre Umucu,Guillermina Solis,Leon Garza,Emilia Rivas,Beatrice Lee,Anantaa Kotal,Aritran Piplai*

Main category: cs.CL

TL;DR: 基于DPO的对齐框架，通过偏好优化提升医疗对话中LLM的事实准确性、语义连贯性和共情能力


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型在医疗和护理应用中存在两大缺陷：事实不可靠性和缺乏共情沟通，这在敏感场景中带来显著风险，特别是非专业用户和护理人员需要医疗指导或情感支持时

Method: 引入基于直接偏好优化（DPO）的对齐框架，使用成对偏好数据微调领域适应的LLM，其中偏好响应体现支持性和易理解的沟通风格，拒绝响应代表指令性或过于技术化的语气

Result: DPO调优模型在多个开源和专有LLM上实现了更高的语义对齐、改善的事实准确性和更强的人本评价分数，优于基线和商业替代方案（如谷歌医疗对话系统）

Conclusion: 基于偏好的对齐为开发可信赖、共情且具备临床知识的AI助手提供了一条可扩展且透明的路径，适用于护理和医疗沟通场景

Abstract: General-purpose large language models (LLMs) have demonstrated remarkable generative and reasoning capabilities but remain limited in healthcare and caregiving applications due to two key deficiencies: factual unreliability and a lack of empathetic communication. These shortcomings pose significant risks in sensitive contexts where users, particularly non-professionals and caregivers, seek medically relevant guidance or emotional reassurance. To address these challenges, we introduce a Direct Preference Optimization (DPO)-based alignment framework designed to improve factual correctness, semantic coherence, and human-centric qualities such as empathy, politeness, and simplicity in caregiver-patient dialogues. Our approach fine-tunes domain-adapted LLMs using pairwise preference data, where preferred responses reflect supportive and accessible communication styles while rejected ones represent prescriptive or overly technical tones. This direct optimization method aligns model outputs with human preferences more efficiently than traditional reinforcement-learning-based alignment. Empirical evaluations across multiple open and proprietary LLMs show that our DPO-tuned models achieve higher semantic alignment, improved factual accuracy, and stronger human-centric evaluation scores compared to baseline and commercial alternatives such as Google medical dialogue systems. These improvements demonstrate that preference-based alignment offers a scalable and transparent pathway toward developing trustworthy, empathetic, and clinically informed AI assistants for caregiver and healthcare communication. Our open-source code is available at: https://github.com/LeonG19/Empathy-by-Design

</details>


### [2] [Morphologically-Informed Tokenizers for Languages with Non-Concatenative Morphology: A case study of Yoloxóchtil Mixtec ASR](https://arxiv.org/abs/2512.06169)
*Chris Crawford*

Main category: cs.CL

TL;DR: 该论文研究了针对Yoloxóchitl Mixtec语言的形态感知分词器，通过非线性分词方案改进音频语料库的注释效率，在ASR任务中与传统分词器表现相当。


<details>
  <summary>Details</summary>
Motivation: 动机是改进Yoloxóchitl Mixtec音频语料库的注释效率，减少人工标注工作量。该语言具有非连接性形态特征，特别是声调形态，需要专门的分词方法来处理。

Method: 提出了两种新颖的非线性分词方案：1) Segment and Melody分词器，仅提取声调信息而不预测分词；2) Sequence of Processes分词器，预测词语分词，可实现端到端ASR系统同时输出分词和未分词转录。与传统BPE和Unigram模型进行比较，并在形态学和信息论指标上进行分析。

Result: 新颖分词器与传统BPE和Unigram模型表现相当。Segment-and-Melody模型在词错误率上优于传统分词器，但在字符错误率上未达到相同水平。形态学和信息论指标与下游性能存在预测相关性。

Conclusion: 针对语言非连接性形态特征设计的非线性分词器在ASR任务中与传统分词器竞争性相当。需要进一步研究这些分词器在下游处理任务中的适用性。

Abstract: This paper investigates the impact of using morphologically-informed tokenizers to aid and streamline the interlinear gloss annotation of an audio corpus of Yoloxóchitl Mixtec (YM) using a combination of ASR and text-based sequence-to-sequence tools, with the goal of improving efficiency while reducing the workload of a human annotator. We present two novel tokenization schemes that separate words in a nonlinear manner, preserving information about tonal morphology as much as possible. One of these approaches, a Segment and Melody tokenizer, simply extracts the tones without predicting segmentation. The other, a Sequence of Processes tokenizer, predicts segmentation for the words, which could allow an end-to-end ASR system to produce segmented and unsegmented transcriptions in a single pass. We find that these novel tokenizers are competitive with BPE and Unigram models, and the Segment-and-Melody model outperforms traditional tokenizers in terms of word error rate but does not reach the same character error rate. In addition, we analyze tokenizers on morphological and information-theoretic metrics to find predictive correlations with downstream performance. Our results suggest that nonlinear tokenizers designed specifically for the non-concatenative morphology of a language are competitive with conventional BPE and Unigram models for ASR. Further research will be necessary to determine the applicability of these tokenizers in downstream processing tasks.

</details>


### [3] [Do You Feel Comfortable? Detecting Hidden Conversational Escalation in AI Chatbots](https://arxiv.org/abs/2512.06193)
*Jihyung Park,Saleh Afroogh,Junfeng Jiao*

Main category: cs.CL

TL;DR: 提出GAUGE框架，用于实时检测LLM对话中的隐性情感升级伤害，传统毒性过滤器无法检测这种渐进式的情感强化伤害。


<details>
  <summary>Details</summary>
Motivation: LLM日益融入日常生活，不仅作为信息助手，还作为情感伴侣。即使没有明显毒性，重复的情感强化或情感漂移会逐渐加剧用户痛苦，形成传统毒性过滤器无法检测的"隐性伤害"。现有护栏机制依赖外部分类器或临床标准，无法跟上对话发展的细微实时动态。

Method: 提出GAUGE（Guarding Affective Utterance Generation Escalation）框架，这是一个轻量级的基于logit的框架，用于实时检测隐藏的对话升级。GAUGE通过测量LLM输出如何概率性地改变对话的情感状态来实现检测。

Result: 论文提出了GAUGE框架，但摘要中未报告具体的实验结果。

Conclusion: 需要开发能够实时检测LLM对话中隐性情感升级伤害的新方法，GAUGE框架为此提供了一种基于概率情感状态转移的轻量级解决方案。

Abstract: Large Language Models (LLM) are increasingly integrated into everyday interactions, serving not only as information assistants but also as emotional companions. Even in the absence of explicit toxicity, repeated emotional reinforcement or affective drift can gradually escalate distress in a form of \textit{implicit harm} that traditional toxicity filters fail to detect. Existing guardrail mechanisms often rely on external classifiers or clinical rubrics that may lag behind the nuanced, real-time dynamics of a developing conversation. To address this gap, we propose GAUGE (Guarding Affective Utterance Generation Escalation), a lightweight, logit-based framework for the real-time detection of hidden conversational escalation. GAUGE measures how an LLM's output probabilistically shifts the affective state of a dialogue.

</details>


### [4] [Automated Data Enrichment using Confidence-Aware Fine-Grained Debate among Open-Source LLMs for Mental Health and Online Safety](https://arxiv.org/abs/2512.06227)
*Junyu Mao,Anthony Hills,Talia Tseriotou,Maria Liakata,Aya Shamir,Dan Sayda,Dana Atzil-Slonim,Natalie Djohari,Arpan Mandal,Silke Roth,Pamela Ugwudike,Mahesan Niranjan,Stuart E. Middleton*

Main category: cs.CL

TL;DR: 提出CFD框架，通过多LLM代理的细粒度辩论达成共识，用于标注动态现实世界指标，提升NLP任务性能


<details>
  <summary>Details</summary>
Motivation: 现实世界指标（如心理健康事件、在线安全风险）对NLP任务很重要，但人工标注成本高且动态变化，需要自动化数据增强方法

Method: 提出置信感知细粒度辩论（CFD）框架：多个LLM代理模拟人类标注者，交换细粒度证据达成共识；创建了两个专家标注数据集（心理健康Reddit数据集和在线安全Facebook分享风险数据集）

Result: CFD框架在数据增强方面表现最稳健；数据增强持续改善下游任务；辩论转录本特征带来最大增益，在线安全任务比非增强基线提升10.1%

Conclusion: CFD框架能有效解决动态现实世界指标的标注问题，通过多代理辩论达成共识的数据增强方法显著提升下游NLP任务性能

Abstract: Real-world indicators are important for improving natural language processing (NLP) tasks such as life events for mental health analysis and risky behaviour for online safety, yet labelling such information in NLP training datasets is often costly and/or difficult given the dynamic nature of such events. This paper compares several LLM-based data enrichment methods and introduces a novel Confidence-Aware Fine-Grained Debate (CFD) framework in which multiple LLM agents simulate human annotators and exchange fine-grained evidence to reach consensus. We describe two new expert-annotated datasets, a mental health Reddit wellbeing dataset and an online safety Facebook sharenting risk dataset. Our CFD framework achieves the most robust data enrichment performance compared to a range of baselines and we show that this type of data enrichment consistently improves downstream tasks. Enriched features incorporated via debate transcripts yield the largest gains, outperforming the non-enriched baseline by 10.1% for the online safety task.

</details>


### [5] [Policy-based Sentence Simplification: Replacing Parallel Corpora with LLM-as-a-Judge](https://arxiv.org/abs/2512.06228)
*Xuanxin Wu,Yuki Arase,Masaaki Nagata*

Main category: cs.CL

TL;DR: 利用LLM-as-a-Judge自动构建策略对齐训练数据，无需人工标注，使小型开源LLM在词汇简化上超越GPT-4o


<details>
  <summary>Details</summary>
Motivation: 句子简化需要根据不同应用采用不同简化策略（如仅替换复杂词汇或整体重写），但实现策略驱动的控制仍具挑战性，且现有方法依赖昂贵的人工标注或平行语料

Method: 提出基于LLM-as-a-Judge的方法自动构建策略对齐的训练数据，完全无需人工标注或平行语料，使简化系统能适应不同简化策略

Result: 小型开源LLM（如Phi-3-mini-3.8B）在词汇导向的简化任务上超越GPT-4o，在整体重写任务上表现相当，自动指标和人工评估均验证了效果

Conclusion: 该方法在不同模型家族和规模上均展现出一致的改进，证明了方法的鲁棒性，为构建策略驱动的句子简化系统提供了有效解决方案

Abstract: Sentence simplification aims to modify a sentence to make it easier to read and understand while preserving the meaning. Different applications require distinct simplification policies, such as replacing only complex words at the lexical level or rewriting the entire sentence while trading off details for simplicity. However, achieving such policy-driven control remains an open challenge. In this work, we introduce a simple yet powerful approach that leverages Large Language Model-as-a-Judge (LLM-as-a-Judge) to automatically construct policy-aligned training data, completely removing the need for costly human annotation or parallel corpora. Our method enables building simplification systems that adapt to diverse simplification policies. Remarkably, even small-scale open-source LLMs such as Phi-3-mini-3.8B surpass GPT-4o on lexical-oriented simplification, while achieving comparable performance on overall rewriting, as verified by both automatic metrics and human evaluations. The consistent improvements across model families and sizes demonstrate the robustness of our approach.

</details>


### [6] [LOCUS: A System and Method for Low-Cost Customization for Universal Specialization](https://arxiv.org/abs/2512.06239)
*Dhanasekar Sundararaman,Keying Li,Wayne Xiong,Aashna Garg*

Main category: cs.CL

TL;DR: LOCUS是一个低成本的NLP模型定制流程，通过少量标注数据实现高效模型构建，结合检索、合成数据生成和参数高效微调，在NER和文本分类任务上超越GPT-4o等基线，同时大幅降低成本和模型大小。


<details>
  <summary>Details</summary>
Motivation: 当前NLP模型定制需要大量标注数据和计算资源，成本高昂。需要一种方法能够仅用少量标注示例就能构建高性能的专用模型，同时大幅降低内存占用和计算成本。

Method: LOCUS采用三阶段流程：1）从大型知识库中检索相关数据；2）通过上下文数据生成合成额外训练样本；3）使用全参数微调或LoRA等参数高效方法进行模型调优。专注于命名实体识别和文本分类任务。

Result: LOCUS在多个基准测试中持续超越强基线（包括GPT-4o），内存优化模型保持99%全微调准确率的同时仅使用5%内存占用，在多个基准上击败GPT-4o而参数数量不到其1%。

Conclusion: LOCUS提供了一种高效、低成本的NLP模型定制方案，仅需少量标注数据就能构建高性能专用模型，显著降低资源需求，为实际应用提供了可行的解决方案。

Abstract: We present LOCUS (LOw-cost Customization for Universal Specialization), a pipeline that consumes few-shot data to streamline the construction and training of NLP models through targeted retrieval, synthetic data generation, and parameter-efficient tuning. With only a small number of labeled examples, LOCUS discovers pertinent data in a broad repository, synthesizes additional training samples via in-context data generation, and fine-tunes models using either full or low-rank (LoRA) parameter adaptation. Our approach targets named entity recognition (NER) and text classification (TC) benchmarks, consistently outperforming strong baselines (including GPT-4o) while substantially lowering costs and model sizes. Our resultant memory-optimized models retain 99% of fully fine-tuned accuracy while using barely 5% of the memory footprint, also beating GPT-4o on several benchmarks with less than 1% of its parameters.

</details>


### [7] [Convergence of Outputs When Two Large Language Models Interact in a Multi-Agentic Setup](https://arxiv.org/abs/2512.06256)
*Aniruddha Maiti,Satya Nimmagadda,Kartha Veerya Jammuladinne,Niladri Sengupta,Ananya Jana*

Main category: cs.CL

TL;DR: 两个大型语言模型在无外部输入的对话中会逐渐陷入重复循环，最终产生相似输出，形成收敛现象


<details>
  <summary>Details</summary>
Motivation: 研究当两个大型语言模型在没有外部输入的情况下相互对话时会发生什么，探索多智能体设置中的对话动态

Method: 使用Mistral Nemo Base 2407和Llama 2 13B hf模型，从一个短种子句子开始，让两个模型相互读取对方输出并生成响应，持续固定步数

Result: 大多数对话开始时连贯，但后来陷入重复；出现短短语在多个回合中重复；一旦开始重复，两个模型倾向于产生相似输出而非引入新方向；最终形成相同或相似文本的循环

Conclusion: 即使模型规模大、独立训练且无提示指令，对话仍会收敛到重复循环状态，这种现象可以通过词汇和嵌入指标来测量对话漂移和模型输出相似性

Abstract: In this work, we report what happens when two large language models respond to each other for many turns without any outside input in a multi-agent setup. The setup begins with a short seed sentence. After that, each model reads the other's output and generates a response. This continues for a fixed number of steps. We used Mistral Nemo Base 2407 and Llama 2 13B hf. We observed that most conversations start coherently but later fall into repetition. In many runs, a short phrase appears and repeats across turns. Once repetition begins, both models tend to produce similar output rather than introducing a new direction in the conversation. This leads to a loop where the same or similar text is produced repeatedly. We describe this behavior as a form of convergence. It occurs even though the models are large, trained separately, and not given any prompt instructions. To study this behavior, we apply lexical and embedding-based metrics to measure how far the conversation drifts from the initial seed and how similar the outputs of the two models becomes as the conversation progresses.

</details>


### [8] [Nanbeige4-3B Technical Report: Exploring the Frontier of Small Language Models](https://arxiv.org/abs/2512.06266)
*Chen Yang,Guangyue Peng,Jiaying Zhu,Ran Le,Ruixiang Feng,Tao Zhang,Wei Ruan,Xiaoqi Liu,Xiaoxue Cheng,Xiyun Xu,Yang Song,Yanzipeng Gao,Yiming Jia,Yun Xing,Yuntao Wen,Zekai Wang,Zhenwei An,Zhicong Sun,Zongchao Chen*

Main category: cs.CL

TL;DR: Nanbeige4-3B是一个3B参数的小型高性能语言模型，通过创新的预训练调度器、高质量的SFT数据生成、双偏好蒸馏和多阶段强化学习，在多项基准测试中超越了同规模模型并媲美更大模型。


<details>
  <summary>Details</summary>
Motivation: 推动小型语言模型的性能边界，证明通过精心设计的训练策略，小规模模型也能达到接近大模型的性能水平，为资源受限场景提供高效解决方案。

Method: 1) 预训练阶段：采用FG-WSD调度器，分阶段精细化数据混合；2) 后训练阶段：结合审议生成优化和思维链重构机制提升SFT数据质量；3) 使用双偏好蒸馏方法从旗舰推理模型蒸馏知识；4) 多阶段强化学习，利用可验证奖励和偏好建模增强推理和对齐能力。

Result: 在广泛基准测试中，Nanbeige4-3B不仅显著优于同参数规模模型，还能与更大模型竞争，验证了所提方法的有效性。

Conclusion: 通过系统性的训练策略创新，成功扩展了小规模语言模型的缩放定律边界，为高效语言模型开发提供了新范式。

Abstract: We present Nanbeige4-3B, a family of small-scale but high-performing language models. Pretrained on 23T high-quality tokens and finetuned on over 30 million diverse instructions, we extend the boundary of the scaling law for small language models. In pre-training, we design a Fine-Grained Warmup-Stable-Decay (FG-WSD) training scheduler, which progressively refines data mixtures across stages to boost model performance. In post-training, to improve the quality of the SFT data, we design a joint mechanism that integrates deliberative generation refinement and chain-of-thought reconstruction, yielding substantial gains on complex tasks. Following SFT, we employ our flagship reasoning model to distill Nanbeige4-3B through our proposed Dual Preference Distillation (DPD) method, which leads to further performance gains. Finally, a multi-stage reinforcement learning phase was applied, leveraging verifiable rewards and preference modeling to strengthen abilities on both reasoning and human alignment. Extensive evaluations show that Nanbeige4-3B not only significantly outperforms models of comparable parameter scale but also rivals much larger models across a wide range of benchmarks. The model checkpoints are available at https://huggingface.co/Nanbeige.

</details>


### [9] [Modeling Contextual Passage Utility for Multihop Question Answering](https://arxiv.org/abs/2512.06464)
*Akriti Jain,Aparna Garimella*

Main category: cs.CL

TL;DR: 提出轻量级上下文篇章效用预测方法，通过考虑篇章间依赖关系来改进多跳问答中的篇章重排序


<details>
  <summary>Details</summary>
Motivation: 多跳问答需要从多个文本段落中识别和综合信息。现有方法通常独立建模篇章效用，忽略了多跳推理的关键方面：篇章的效用是上下文相关的，受其与其他段落关系的影响（是否提供互补信息或形成关键链接）

Method: 提出轻量级方法来建模上下文篇章效用，考虑篇章间依赖关系。微调小型transformer模型来预测多跳问答的篇章效用分数，利用高级推理模型的推理轨迹来捕捉回答问题时使用段落的顺序，并获取合成训练数据

Result: 通过综合实验证明，基于效用的检索段落评分相比基于相关性的重排序方法，能带来改进的重排序和下游问答性能

Conclusion: 上下文篇章效用建模能有效提升多跳问答系统的性能，通过考虑篇章间依赖关系来更好地评估段落的实际效用

Abstract: Multihop Question Answering (QA) requires systems to identify and synthesize information from multiple text passages. While most prior retrieval methods assist in identifying relevant passages for QA, further assessing the utility of the passages can help in removing redundant ones, which may otherwise add to noise and inaccuracies in the generated answers. Existing utility prediction approaches model passage utility independently, overlooking a critical aspect of multihop reasoning: the utility of a passage can be context-dependent, influenced by its relation to other passages - whether it provides complementary information or forms a crucial link in conjunction with others. In this paper, we propose a lightweight approach to model contextual passage utility, accounting for inter-passage dependencies. We fine-tune a small transformer-based model to predict passage utility scores for multihop QA. We leverage the reasoning traces from an advanced reasoning model to capture the order in which passages are used to answer a question and obtain synthetic training data. Through comprehensive experiments, we demonstrate that our utility-based scoring of retrieved passages leads to improved reranking and downstream QA performance compared to relevance-based reranking methods.

</details>


### [10] [Knowing What's Missing: Assessing Information Sufficiency in Question Answering](https://arxiv.org/abs/2512.06476)
*Akriti Jain,Aparna Garimella*

Main category: cs.CL

TL;DR: 提出Identify-then-Verify框架，通过先识别缺失信息再验证的方法，更可靠地判断上下文是否足够回答问题


<details>
  <summary>Details</summary>
Motivation: 现有简单提示策略在处理事实性问题时有效，但在需要推理的问题上经常失败。需要更可靠的方法来判断上下文是否包含足够信息来回答问题。

Method: 提出结构化Identify-then-Verify框架：1) 生成多个关于缺失信息的假设并建立语义共识；2) 执行关键验证步骤，强制模型重新检查源文本来确认这些信息是否真正缺失。

Result: 在多个多跳和事实性QA数据集上评估，结果表明该方法能产生更准确的充分性判断，同时清晰阐明信息差距。

Conclusion: 通过引导模型证明其关于缺失信息的判断，该框架能提高充分性建模的可靠性，为构建可靠的问答系统提供更稳健的方法。

Abstract: Determining whether a provided context contains sufficient information to answer a question is a critical challenge for building reliable question-answering systems. While simple prompting strategies have shown success on factual questions, they frequently fail on inferential ones that require reasoning beyond direct text extraction. We hypothesize that asking a model to first reason about what specific information is missing provides a more reliable, implicit signal for assessing overall sufficiency. To this end, we propose a structured Identify-then-Verify framework for robust sufficiency modeling. Our method first generates multiple hypotheses about missing information and establishes a semantic consensus. It then performs a critical verification step, forcing the model to re-examine the source text to confirm whether this information is truly absent. We evaluate our method against established baselines across diverse multi-hop and factual QA datasets. The results demonstrate that by guiding the model to justify its claims about missing information, our framework produces more accurate sufficiency judgments while clearly articulating any information gaps.

</details>


### [11] [Classifying German Language Proficiency Levels Using Large Language Models](https://arxiv.org/abs/2512.06483)
*Elias-Leander Ahlers,Witold Brunsmann,Malte Schilling*

Main category: cs.CL

TL;DR: 本文研究使用大语言模型自动将德语文本按CEFR语言能力等级分类，通过构建多样化数据集并评估多种方法，实现了比现有方法更好的性能。


<details>
  <summary>Details</summary>
Motivation: 语言能力评估对教育至关重要，能够根据学习者需求提供个性化教学。本文旨在探索使用大语言模型自动将德语文本按CEFR标准分类到不同能力等级，以实现可靠且可扩展的评估。

Method: 1) 构建多样化数据集：结合多个现有CEFR标注语料库和合成数据；2) 评估多种方法：提示工程策略、微调LLaMA-3-8B-Instruct模型、基于探测的方法（利用LLM内部神经状态进行分类）。

Result: 结果显示，相比现有方法，本文提出的方法取得了持续的性能提升，证明了LLMs在CEFR分类任务中的可靠性和可扩展性潜力。

Conclusion: 大语言模型在德语文本CEFR分类任务中表现出色，为可靠且可扩展的语言能力评估提供了有效解决方案。

Abstract: Assessing language proficiency is essential for education, as it enables instruction tailored to learners needs. This paper investigates the use of Large Language Models (LLMs) for automatically classifying German texts according to the Common European Framework of Reference for Languages (CEFR) into different proficiency levels. To support robust training and evaluation, we construct a diverse dataset by combining multiple existing CEFR-annotated corpora with synthetic data. We then evaluate prompt-engineering strategies, fine-tuning of a LLaMA-3-8B-Instruct model and a probing-based approach that utilizes the internal neural state of the LLM for classification. Our results show a consistent performance improvement over prior methods, highlighting the potential of LLMs for reliable and scalable CEFR classification.

</details>


### [12] [ProSocialAlign: Preference Conditioned Test Time Alignment in Language Models](https://arxiv.org/abs/2512.06515)
*Somnath Banerjee,Sayan Layek,Sayantan Adak,Mykola Pechenizkiy,Animesh Mukherjee,Rima Hazra*

Main category: cs.CL

TL;DR: ProSocialAlign：一种测试时参数高效框架，通过词典约束生成和方向调节，在保持安全的同时优化亲社会质量，实现情感化高风险场景下的价值对齐响应。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型安全范式在情感化或高风险场景中存在不足：仅拒绝可能疏远用户，而简单顺从又会放大风险。需要一种能在保持安全的同时生成共情、价值对齐响应的方法。

Method: 1) 将安全形式化为词典约束生成：先应用硬约束消除有害延续，然后在安全集合内优化亲社会质量；2) 方向调节：在参数空间减去学习的"伤害向量"以缓解伤害；3) 偏好感知自回归奖励建模：联合训练多个属性并解决梯度冲突，实现细粒度用户可控解码。

Result: 在五个安全基准测试中达到最先进性能，显著减少不安全泄漏并提升与人类价值的对齐度，在多个评估指标上均有强劲提升。

Conclusion: ProSocialAlign为推理时生成上下文敏感、安全且人类对齐的响应提供了稳健且模块化的基础，实现了测试时参数高效的价值对齐。

Abstract: Current language model safety paradigms often fall short in emotionally charged or high-stakes settings, where refusal-only approaches may alienate users and naive compliance can amplify risk. We propose ProSocialAlign, a test-time, parameter-efficient framework that steers generation toward safe, empathetic, and value-aligned responses without retraining the base model. We formalize five human-centered objectives and cast safety as lexicographic constrained generation: first, applying hard constraints to eliminate harmful continuations; then optimizing for prosocial quality within the safe set. Our method combines (i) directional regulation, a harm-mitigation mechanism that subtracts a learned "harm vector" in parameter space, and (ii) preference-aware autoregressive reward modeling trained jointly across attributes with gradient conflict resolution, enabling fine-grained, user-controllable decoding. Empirical evaluations across five safety benchmarks demonstrate state-of-the-art performance, reducing unsafe leakage and boosting alignment to human values, with strong gains across multiple evaluation metrics. ProSocialAlign offers a robust and modular foundation for generating context-sensitive, safe, and human-aligned responses at inference time.

</details>


### [13] [Adapting AlignScore Mertic for Factual Consistency Evaluation of Text in Russian: A Student Abstract](https://arxiv.org/abs/2512.06586)
*Mikhail Zimin,Milyausha Shamsutdinova,Georgii Andriushchenko*

Main category: cs.CL

TL;DR: 提出了AlignRuScore，一个用于俄语文本事实一致性评估的适配工具，填补了现有工具主要针对英语的空白。


<details>
  <summary>Details</summary>
Motivation: 确保生成文本的事实一致性对于可靠的自然语言处理应用至关重要，但目前缺乏针对俄语文本的事实一致性评估工具，现有工具主要关注英语语料库。

Method: 通过微调基于RuBERT的对齐模型，在俄语和翻译的英语数据集上使用特定任务的分类和回归头，将AlignScore指标适配到俄语。

Result: 结果表明，统一的对齐指标可以成功移植到俄语，为稳健的多语言事实一致性评估奠定了基础。

Conclusion: 作者发布了翻译的语料库、模型检查点和代码，以支持进一步的研究，填补了俄语事实一致性评估工具的空白。

Abstract: Ensuring factual consistency in generated text is crucial for reliable natural language processing applications. However, there is a lack of evaluation tools for factual consistency in Russian texts, as existing tools primarily focus on English corpora. To bridge this gap, we introduce AlignRuScore, a comprehensive adaptation of the AlignScore metric for Russian. To adapt the metric, we fine-tuned a RuBERT-based alignment model with task-specific classification and regression heads on Russian and translated English datasets. Our results demonstrate that a unified alignment metric can be successfully ported to Russian, laying the groundwork for robust multilingual factual consistency evaluation. We release the translated corpora, model checkpoints, and code to support further research.

</details>


### [14] [The Online Discourse of Virtual Reality and Anxiety](https://arxiv.org/abs/2512.06656)
*Kwabena Yamoah,Cass Dykeman*

Main category: cs.CL

TL;DR: 该研究使用语料库语言学方法分析在线讨论中虚拟现实（VR）与焦虑相关的词汇使用模式，发现VR、Oculus和头显是最常讨论的词汇，揭示了VR技术发展及其在焦虑治疗中的应用前景。


<details>
  <summary>Details</summary>
Motivation: VR已被用于治疗广泛性焦虑障碍和社交焦虑等临床问题，为患者福祉和护理创造了新途径。了解用户对该技术的在线讨论有助于进一步提升其疗效。

Method: 采用语料库语言学方法，使用Sketch Engine软件分析英语趋势语料库中VR与焦虑子语料库的词汇使用频率和搭配模式。

Result: 研究发现VR、Oculus和头显是VR与焦虑讨论中最频繁出现的词汇，表明关注点集中在虚拟系统及其物理设备上。此外，介词短语搭配如"of virtual reality"、"in virtual reality"和"for virtual reality"分别与设计、体验和发展相关。

Conclusion: 研究为理解VR与焦虑在一般话语中的讨论提供了新视角，为通过技术开发和可及性来支持咨询需求指明了未来发展方向。

Abstract: VR in the treatment of clinical concerns such as generalized anxiety disorder or social anxiety. VR has created additional pathways to support patient well-being and care. Understanding online discussion of what users think about this technology may further support its efficacy. The purpose of this study was to employ a corpus linguistic methodology to identify the words and word networks that shed light on the online discussion of virtual reality and anxiety. Using corpus linguistics, frequently used words in discussion along with collocation were identified by utilizing Sketch Engine software. The results of the study, based upon the English Trends corpus, identified VR, Oculus, and headset as the most frequently discussed within the VR and anxiety subcorpus. These results point to the development of the virtual system, along with the physical apparatus that makes viewing and engaging with the virtual environment possible. Additional results point to collocation of prepositional phrases such as of virtual reality, in virtual reality, and for virtual reality relating to the design, experience, and development, respectively. These findings offer new perspective on how VR and anxiety together are discussed in general discourse and offer pathways for future opportunities to support counseling needs through development and accessibility. Keywords: anxiety disorders, corpus linguistics, Sketch Engine, and virtual reality VR

</details>


### [15] [CMV-Fuse: Cross Modal-View Fusion of AMR, Syntax, and Knowledge Representations for Aspect Based Sentiment Analysis](https://arxiv.org/abs/2512.06679)
*Smitha Muthya Sudheendra,Mani Deep Cherukuri,Jaideep Srivastava*

Main category: cs.CL

TL;DR: CMV-Fuse是一个跨模态视图融合框架，通过结合四种语言视角（抽象意义表示、成分句法、依存句法和语义注意力）来模拟人类语言处理，提升方面级情感分析的性能。


<details>
  <summary>Details</summary>
Motivation: 当前方面级情感分析系统通常利用孤立的语言视角，忽视了人类自然利用的结构表征之间的复杂相互作用。自然语言理解本质上需要整合从表层句法到深层语义和世界知识的多个互补视角。

Method: 提出CMV-Fuse框架，系统整合四种语言视角：抽象意义表示、成分句法、依存句法和语义注意力，并增强外部知识集成。通过局部句法、中间语义和全局知识层次的分层门控注意力融合，捕捉细粒度结构模式和广泛上下文理解。采用新颖的结构感知多视图对比学习机制确保互补表征的一致性。

Result: 在标准基准测试上的大量实验显示，CMV-Fuse相比强基线有显著改进，分析揭示了每种语言视角如何贡献于更鲁棒的情感分析。

Conclusion: 通过模拟人类语言处理的多视角融合方法，CMV-Fuse能够更全面地理解语言，在方面级情感分析任务上取得优异性能，证明了整合多种语言视角的重要性。

Abstract: Natural language understanding inherently depends on integrating multiple complementary perspectives spanning from surface syntax to deep semantics and world knowledge. However, current Aspect-Based Sentiment Analysis (ABSA) systems typically exploit isolated linguistic views, thereby overlooking the intricate interplay between structural representations that humans naturally leverage. We propose CMV-Fuse, a Cross-Modal View fusion framework that emulates human language processing by systematically combining multiple linguistic perspectives. Our approach systematically orchestrates four linguistic perspectives: Abstract Meaning Representations, constituency parsing, dependency syntax, and semantic attention, enhanced with external knowledge integration. Through hierarchical gated attention fusion across local syntactic, intermediate semantic, and global knowledge levels, CMV-Fuse captures both fine-grained structural patterns and broad contextual understanding. A novel structure aware multi-view contrastive learning mechanism ensures consistency across complementary representations while maintaining computational efficiency. Extensive experiments demonstrate substantial improvements over strong baselines on standard benchmarks, with analysis revealing how each linguistic view contributes to more robust sentiment analysis.

</details>


### [16] [Mechanistic Interpretability of GPT-2: Lexical and Contextual Layers in Sentiment Analysis](https://arxiv.org/abs/2512.06681)
*Amartya Hatua*

Main category: cs.CL

TL;DR: GPT-2情感处理机制研究：早期层检测词汇情感，晚期层统一处理上下文整合，而非预期的中层专业化模式


<details>
  <summary>Details</summary>
Motivation: 研究GPT-2中情感信息处理的因果机制，验证假设的两阶段架构（早期词汇检测和中期上下文整合），以理解大型语言模型中情感计算的实际模式

Method: 使用系统性激活修补技术，在GPT-2的所有12个层上进行实验，测试早期层作为词汇情感检测器和中层作为上下文整合器的假设

Result: 早期层（0-3层）确实作为词汇情感检测器，编码稳定的位置特定极性信号；但所有三个上下文整合假设（中层集中、现象特异性、分布式处理）都被证伪。上下文现象（否定、讽刺、领域转移等）主要在晚期层（8-11层）通过统一的非模块化机制整合

Conclusion: GPT-2的情感计算与预测的层次模式不同，上下文整合主要在晚期层统一处理，这强调了需要进一步实证表征大型语言模型中的上下文整合机制

Abstract: We present a mechanistic interpretability study of GPT-2 that causally examines how sentiment information is processed across its transformer layers. Using systematic activation patching across all 12 layers, we test the hypothesized two-stage sentiment architecture comprising early lexical detection and mid-layer contextual integration. Our experiments confirm that early layers (0-3) act as lexical sentiment detectors, encoding stable, position specific polarity signals that are largely independent of context. However, all three contextual integration hypotheses: Middle Layer Concentration, Phenomenon Specificity, and Distributed Processing are falsified. Instead of mid-layer specialization, we find that contextual phenomena such as negation, sarcasm, domain shifts etc. are integrated primarily in late layers (8-11) through a unified, non-modular mechanism. These experimental findings provide causal evidence that GPT-2's sentiment computation differs from the predicted hierarchical pattern, highlighting the need for further empirical characterization of contextual integration in large language models.

</details>


### [17] [PersonaMem-v2: Towards Personalized Intelligence via Learning Implicit User Personas and Agentic Memory](https://arxiv.org/abs/2512.06688)
*Bowen Jiang,Yuan Yuan,Maohao Shen,Zhuoqun Hao,Zhangchen Xu,Zichen Chen,Ziyi Liu,Anvesh Rao Vijjini,Jiashu He,Hanchao Yu,Radha Poovendran,Gregory Wornell,Lyle Ungar,Dan Roth,Sihao Chen,Camillo Jose Taylor*

Main category: cs.CL

TL;DR: PersonaMem-v2是用于LLM个性化的先进数据集，包含1000个用户-聊天机器人交互，覆盖300+场景和20000+用户偏好。研究通过强化微调提升模型的长上下文推理能力，并开发了代理记忆系统，在减少输入token的同时实现了更好的个性化性能。


<details>
  <summary>Details</summary>
Motivation: 个性化是AI发展的下一个里程碑，但现有前沿LLM在隐式个性化任务上表现不佳（仅37-48%准确率）。虽然支持长上下文窗口，但推理能力成为隐式个性化的瓶颈。需要开发更好的数据集和方法来提升LLM的个性化能力。

Method: 1) 创建PersonaMem-v2数据集，模拟1000个现实用户-聊天机器人交互，包含300+场景、20000+用户偏好和128k-token上下文窗口，大多数用户偏好是隐式揭示的。2) 使用强化微调训练Qwen3-4B模型。3) 开发代理记忆系统框架，维护单一、人类可读的记忆，随着每次用户交互而增长。

Result: 1) 前沿LLM在隐式个性化任务上准确率仅37-48%。2) 通过强化微调的Qwen3-4B超越GPT-5，达到53%准确率。3) 代理记忆系统达到55%准确率，同时使用16倍更少的输入token（仅2k-token记忆 vs 完整32k对话历史）。

Conclusion: PersonaMem-v2数据集对个性化研究有重要影响，代理记忆系统为现实世界个性化智能提供了可扩展的路径。强化微调能有效提升模型的长上下文推理能力，代理记忆系统在减少计算资源的同时实现了更好的性能。

Abstract: Personalization is one of the next milestones in advancing AI capability and alignment. We introduce PersonaMem-v2, the state-of-the-art dataset for LLM personalization that simulates 1,000 realistic user-chatbot interactions on 300+ scenarios, 20,000+ user preferences, and 128k-token context windows, where most user preferences are implicitly revealed to reflect real-world interactions. Using this data, we investigate how reinforcement fine-tuning enables a model to improve its long-context reasoning capabilities for user understanding and personalization. We also develop a framework for training an agentic memory system, which maintains a single, human-readable memory that grows with each user over time.
  In our experiments, frontier LLMs still struggle with implicit personalization, achieving only 37-48% accuracy. While they support long context windows, reasoning remains the bottleneck for implicit personalization tasks. Using reinforcement fine-tuning, we successfully train Qwen3-4B to outperforms GPT-5, reaching 53% accuracy in implicit personalization. Moreover, our agentic memory framework achieves state-of-the-art 55% accuracy while using 16x fewer input tokens, relying on a 2k-token memory instead of full 32k conversation histories. These results underscore the impact of our dataset and demonstrate agentic memory as a scalable path toward real-world personalized intelligence.

</details>


### [18] [Think-While-Generating: On-the-Fly Reasoning for Personalized Long-Form Generation](https://arxiv.org/abs/2512.06690)
*Chengbing Wang,Yang Zhang,Wenjie Wang,Xiaoyan Zhao,Fuli Feng,Xiangnan He,Tat-Seng Chua*

Main category: cs.CL

TL;DR: FlyThinker提出"边思考边生成"框架，通过并行推理模型动态指导长文本生成，实现个性化内容创作同时保持训练和推理效率。


<details>
  <summary>Details</summary>
Motivation: 当前偏好对齐方法主要优化群体级偏好，忽视个体用户。早期个性化方法难以推理隐含偏好，而现有"先思考后生成"方法在长文本生成中面临挑战：静态一次性推理需要为完整响应捕获所有相关信息，学习困难且难以适应内容演化。

Method: FlyThinker采用"边思考边生成"框架，使用独立的推理模型并行生成潜在token级推理，将其融合到生成模型中动态指导响应生成。推理模型仅依赖先前响应而非自身输出，保持训练并行性，所有推理token可在单次前向传递中生成。

Result: 在真实世界基准测试中，FlyThinker实现了更好的个性化生成，同时保持了训练和推理效率。

Conclusion: FlyThinker通过并行推理和生成的设计，有效解决了长文本个性化生成中的挑战，在保持效率的同时提升了生成质量。

Abstract: Preference alignment has enabled large language models (LLMs) to better reflect human expectations, but current methods mostly optimize for population-level preferences, overlooking individual users. Personalization is essential, yet early approaches-such as prompt customization or fine-tuning-struggle to reason over implicit preferences, limiting real-world effectiveness. Recent "think-then-generate" methods address this by reasoning before response generation. However, they face challenges in long-form generation: their static one-shot reasoning must capture all relevant information for the full response generation, making learning difficult and limiting adaptability to evolving content. To address this issue, we propose FlyThinker, an efficient "think-while-generating" framework for personalized long-form generation. FlyThinker employs a separate reasoning model that generates latent token-level reasoning in parallel, which is fused into the generation model to dynamically guide response generation. This design enables reasoning and generation to run concurrently, ensuring inference efficiency. In addition, the reasoning model is designed to depend only on previous responses rather than its own prior outputs, which preserves training parallelism across different positions-allowing all reasoning tokens for training data to be produced in a single forward pass like standard LLM training, ensuring training efficiency. Extensive experiments on real-world benchmarks demonstrate that FlyThinker achieves better personalized generation while keeping training and inference efficiency.

</details>


### [19] [TopiCLEAR: Topic extraction by CLustering Embeddings with Adaptive dimensional Reduction](https://arxiv.org/abs/2512.06694)
*Aoi Fujita,Taichi Yamamoto,Yuri Nakayama,Ryota Kobayashi*

Main category: cs.CL

TL;DR: 提出TopiCLEAR方法，通过自适应降维的嵌入聚类进行主题提取，专门解决社交媒体短文本主题建模的挑战，在多个数据集上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统主题模型是为较长正式文档设计的，在处理社交媒体短文本时面临挑战：共现统计有限、语义碎片化、拼写不一致和非正式语言。需要专门针对短文本的主题建模方法。

Method: TopiCLEAR：基于自适应降维的嵌入聚类主题提取。使用Sentence-BERT嵌入文本，先用高斯混合模型初步聚类，然后通过线性判别分析进行监督投影迭代优化聚类，直到收敛。直接处理原始文本，无需预处理。

Result: 在四个数据集（20News、AgNewsTitle、Reddit、TweetTopic）上评估，相比7个基线方法（包括最近的SBERT方法和零样本生成AI方法），TopiCLEAR与人工标注主题的相似度最高，对社交媒体帖子和在线新闻都有显著改进。定性分析显示产生更可解释的主题。

Conclusion: TopiCLEAR方法有效解决了社交媒体短文本主题建模的挑战，在多个数据集上优于现有方法，为社交媒体数据和网络内容分析提供了有前景的工具。

Abstract: Rapid expansion of social media platforms such as X (formerly Twitter), Facebook, and Reddit has enabled large-scale analysis of public perceptions on diverse topics, including social issues, politics, natural disasters, and consumer sentiment. Topic modeling is a widely used approach for uncovering latent themes in text data, typically framed as an unsupervised classification task. However, traditional models, originally designed for longer and more formal documents, struggle with short social media posts due to limited co-occurrence statistics, fragmented semantics, inconsistent spelling, and informal language. To address these challenges, we propose a new method, TopiCLEAR: Topic extraction by CLustering Embeddings with Adaptive dimensional Reduction. Specifically, each text is embedded using Sentence-BERT (SBERT) and provisionally clustered using Gaussian Mixture Models (GMM). The clusters are then refined iteratively using a supervised projection based on linear discriminant analysis, followed by GMM-based clustering until convergence. Notably, our method operates directly on raw text, eliminating the need for preprocessing steps such as stop word removal. We evaluate our approach on four diverse datasets, 20News, AgNewsTitle, Reddit, and TweetTopic, each containing human-labeled topic information. Compared with seven baseline methods, including a recent SBERT-based method and a zero-shot generative AI method, our approach achieves the highest similarity to human-annotated topics, with significant improvements for both social media posts and online news articles. Additionally, qualitative analysis shows that our method produces more interpretable topics, highlighting its potential for applications in social media data and web content analytics.

</details>


### [20] [Parameter-Efficient Fine-Tuning with Differential Privacy for Robust Instruction Adaptation in Large Language Models](https://arxiv.org/abs/2512.06711)
*Yulin Huang,Yaxuan Luan,Jinxu Guo,Xiangchen Song,Yuchen Liu*

Main category: cs.CL

TL;DR: 提出一种结合差分隐私噪声分配与梯度裁剪的参数高效微调方法，在保护隐私的同时提高大语言模型指令微调的效率


<details>
  <summary>Details</summary>
Motivation: 解决大规模语言模型指令微调中的隐私保护和效率问题，传统方法在隐私预算消耗和训练稳定性方面存在不足

Method: 保持主干模型冻结，通过低维投影子空间更新参数，在梯度计算中引入裁剪和自适应噪声分配，构建统一的梯度约束-噪声分配-参数投影框架

Result: 在准确性、隐私预算和参数效率方面优于基线模型，在多样化和不确定数据条件下保持稳定性能

Conclusion: 丰富了差分隐私与参数高效微调的理论整合，为复杂指令环境下的安全训练提供了可行解决方案

Abstract: This study addresses the issues of privacy protection and efficiency in instruction fine-tuning of large-scale language models by proposing a parameter-efficient method that integrates differential privacy noise allocation with gradient clipping in a collaborative optimization framework. The method keeps the backbone model frozen and updates parameters through a low-dimensional projection subspace, while introducing clipping and adaptive noise allocation during gradient computation. This design reduces privacy budget consumption and ensures training stability and robustness. The unified framework combines gradient constraints, noise allocation, and parameter projection, effectively mitigating performance fluctuations and privacy risks in multi-task instruction scenarios. Experiments are conducted across hyperparameter, environment, and data sensitivity dimensions. Results show that the method outperforms baseline models in accuracy, privacy budget, and parameter efficiency, and maintains stable performance under diverse and uncertain data conditions. The findings enrich the theoretical integration of differential privacy and parameter-efficient fine-tuning and demonstrate its practical adaptability in instruction tasks, providing a feasible solution for secure training in complex instruction environments.

</details>


### [21] ["The Dentist is an involved parent, the bartender is not": Revealing Implicit Biases in QA with Implicit BBQ](https://arxiv.org/abs/2512.06732)
*Aarushi Wagh,Saniya Srivastava*

Main category: cs.CL

TL;DR: ImplicitBBQ是扩展BBQ基准的新基准，通过隐式线索评估LLM偏见，发现GPT-4o在隐式偏见评估中表现显著下降，揭示现有显式基准无法检测的隐式偏见。


<details>
  <summary>Details</summary>
Motivation: 现有偏见评估基准主要依赖显式线索（直接声明受保护属性），但现实世界互动中偏见往往是隐式的，通过姓名、文化线索或特征来推断。这种关键疏忽在公平性评估中造成了重大盲点。

Method: 扩展Bias Benchmark for QA (BBQ)基准，创建ImplicitBBQ基准，在6个类别中引入隐式线索的受保护属性，通过隐式提示评估LLM的偏见表现。

Result: 在ImplicitBBQ上评估GPT-4o显示：与显式BBQ提示相比存在令人担忧的性能差异，"性取向"子类别准确率下降高达7%，大多数其他类别也出现一致下降，表明当前LLM包含显式基准无法检测的隐式偏见。

Conclusion: ImplicitBBQ为NLP领域的细致公平性评估提供了关键工具，揭示了现有显式偏见评估方法的局限性，强调需要更全面的偏见检测方法。

Abstract: Existing benchmarks evaluating biases in large language models (LLMs) primarily rely on explicit cues, declaring protected attributes like religion, race, gender by name. However, real-world interactions often contain implicit biases, inferred subtly through names, cultural cues, or traits. This critical oversight creates a significant blind spot in fairness evaluation. We introduce ImplicitBBQ, a benchmark extending the Bias Benchmark for QA (BBQ) with implicitly cued protected attributes across 6 categories. Our evaluation of GPT-4o on ImplicitBBQ illustrates troubling performance disparity from explicit BBQ prompts, with accuracy declining up to 7% in the "sexual orientation" subcategory and consistent decline located across most other categories. This indicates that current LLMs contain implicit biases undetected by explicit benchmarks. ImplicitBBQ offers a crucial tool for nuanced fairness evaluation in NLP.

</details>


### [22] [A Patient-Doctor-NLP-System to contest inequality for less privileged](https://arxiv.org/abs/2512.06734)
*Subrit Dikshit,Ritu Tiwari,Priyank Jain*

Main category: cs.CL

TL;DR: PDFTEMRA：一种紧凑的Transformer架构，集成模型蒸馏、频域调制、集成学习和随机激活模式，用于低资源医疗NLP应用，特别面向印地语和视障用户。


<details>
  <summary>Details</summary>
Motivation: 尽管迁移学习加速了大型语言模型的发展，但在资源受限的真实医疗场景中训练和部署这些模型仍然困难。本研究针对农村环境中需要医疗援助的视障用户和印地语等低资源语言使用者，解决现有支持有限的问题。

Method: 提出PDFTEMRA（Performant Distilled Frequency Transformer Ensemble Model with Random Activations），这是一种紧凑的Transformer架构，集成了模型蒸馏、频域调制、集成学习和随机激活模式，以降低计算成本同时保持语言理解性能。

Result: 模型在针对印地语和可访问性场景定制的医疗问答和咨询数据集上进行训练和评估。结果显示，PDFTEMRA在显著降低计算需求的同时实现了可比较的性能。

Conclusion: PDFTEMRA适用于可访问、包容、低资源的医疗NLP应用，特别适合资源受限的医疗环境中的视障用户和低资源语言使用者。

Abstract: Transfer Learning (TL) has accelerated the rapid development and availability of large language models (LLMs) for mainstream natural language processing (NLP) use cases. However, training and deploying such gigantic LLMs in resource-constrained, real-world healthcare situations remains challenging. This study addresses the limited support available to visually impaired users and speakers of low-resource languages such as Hindi who require medical assistance in rural environments. We propose PDFTEMRA (Performant Distilled Frequency Transformer Ensemble Model with Random Activations), a compact transformer-based architecture that integrates model distillation, frequency-domain modulation, ensemble learning, and randomized activation patterns to reduce computational cost while preserving language understanding performance. The model is trained and evaluated on medical question-answering and consultation datasets tailored to Hindi and accessibility scenarios, and its performance is compared against standard NLP state-of-the-art model baselines. Results demonstrate that PDFTEMRA achieves comparable performance with substantially lower computational requirements, indicating its suitability for accessible, inclusive, low-resource medical NLP applications.

</details>


### [23] [One Word Is Not Enough: Simple Prompts Improve Word Embeddings](https://arxiv.org/abs/2512.06744)
*Rajeev Ranjan*

Main category: cs.CL

TL;DR: 通过简单地在单词前添加语义提示（如"meaning: {word}"）可以显著提升文本嵌入模型在单词相似性任务上的表现，无需训练即可超越传统静态嵌入方法


<details>
  <summary>Details</summary>
Motivation: 文本嵌入模型主要针对句子级应用进行评估，但它们在孤立单词上的行为理解不足。研究发现现有模型在单词相似性任务上表现不佳，需要改进

Method: 在7个文本嵌入模型上测试，包括OpenAI、Cohere、Voyage AI等模型，使用3个标准基准（SimLex-999、WordSim-353、MEN-3000）。通过在单词前添加语义提示（如"meaning: {word}"或"Represent the semantic concept: {word}"）来改进嵌入效果

Result: 语义提示显著提升单词相似性相关性，在SimLex-999上提升高达+0.29。某些模型在原始单词上完全失败（相关性=0），但通过提示恢复（+0.73改进）。最佳结果：SimLex-999上相关性=0.692（Cohere），WordSim-353上相关性=0.811，MEN-3000上相关性=0.855（OpenAI），超越了Word2Vec（相关性=0.40）和LexVec（相关性=0.48）

Conclusion: 简单的零-shot语义提示技术可以显著提升文本嵌入模型在单词相似性任务上的表现，无需训练即可达到新的最先进水平，为纯嵌入方法设定了新标准

Abstract: Text embedding models are designed for sentence-level applications like retrieval and semantic similarity, and are primarily evaluated on sentence-level benchmarks. Their behavior on isolated words is less understood. We show that simply prepending semantic prompts to words before embedding substantially improves word similarity correlations. Testing 7 text embedding models, including text-embedding-3-large (OpenAI), embed-english-v3.0 (Cohere), voyage-3(Voyage AI), all-mpnet-base-v2, and Qwen3-Embedding-8B, on 3 standard benchmarks (SimLex-999, WordSim-353, MEN-3000), we find that prompts like "meaning: {word}" or "Represent the semantic concept: {word}" improve Spearman correlations by up to +0.29 on SimLex-999. Some models fail completely on bare words (correlation = 0) but recover with prompts (+0.73 improvement). Our best results achieve correlation = 0.692 on SimLex-999 with embed-english-v3.0 (Cohere), correlation = 0.811 on WordSim-353, and correlation = 0.855 on MEN-3000 with text-embedding-3-large (OpenAI). These results outperform classic static embeddings like Word2Vec (correlation = 0.40) and even the best static method LexVec (correlation = 0.48) on SimLex-999, establishing a new state-of-the-art for pure embedding methods. This zero-shot technique requires no training and works with any text embedding model.

</details>


### [24] [Becoming Experienced Judges: Selective Test-Time Learning for Evaluators](https://arxiv.org/abs/2512.06751)
*Seungyeon Jwa,Daechul Ahn,Reokyoung Kim,Dongyeop Kang,Jonghyun Choi*

Main category: cs.CL

TL;DR: 论文提出了LWE框架，让LLM评估器在推理时通过自我反馈改进评估能力，无需训练数据，并通过选择性更新机制提高效率。


<details>
  <summary>Details</summary>
Motivation: 当前LLM-as-a-judge评估方法存在两个问题：1) 独立处理每个样本，无法积累经验；2) 使用固定提示词，缺乏样本特定的评估标准。这限制了评估器的持续改进能力。

Method: 提出LWE框架：1) 维护动态演化的元提示，为每个样本生成特定评估指令；2) 通过自我生成的反馈改进元提示；3) 提出Selective LWE，仅在自不一致的案例上更新元提示，提高计算效率。

Result: 在两个成对比较基准测试中，Selective LWE优于强基线方法，证明评估器可以在顺序测试中通过简单的选择性更新机制改进，并从最困难的案例中学习最多。

Conclusion: LWE框架使LLM评估器能够在推理时持续改进，无需额外训练数据，选择性更新机制在保持性能的同时显著降低成本，为自动评估系统提供了更高效的学习范式。

Abstract: Automatic evaluation with large language models, commonly known as LLM-as-a-judge, is now standard across reasoning and alignment tasks. Despite evaluating many samples in deployment, these evaluators typically (i) treat each case independently, missing the opportunity to accumulate experience, and (ii) rely on a single fixed prompt for all cases, neglecting the need for sample-specific evaluation criteria. We introduce Learning While Evaluating (LWE), a framework that allows evaluators to improve sequentially at inference time without requiring training or validation sets. LWE maintains an evolving meta-prompt that (i) produces sample-specific evaluation instructions and (ii) refines itself through self-generated feedback. Furthermore, we propose Selective LWE, which updates the meta-prompt only on self-inconsistent cases, focusing computation where it matters most. This selective approach retains the benefits of sequential learning while being far more cost-effective. Across two pairwise comparison benchmarks, Selective LWE outperforms strong baselines, empirically demonstrating that evaluators can improve during sequential testing with a simple selective update, learning most from the cases they struggle with.

</details>


### [25] [From Next-Token to Next-Block: A Principled Adaptation Path for Diffusion LLMs](https://arxiv.org/abs/2512.06776)
*Yuchuan Tian,Yuchen Liang,Jiacheng Sun,Shuo Zhang,Guangwen Yang,Yingte Shu,Sibo Fang,Tianyu Guo,Kai Han,Chao Xu,Hanting Chen,Xinghao Chen,Yunhe Wang*

Main category: cs.CL

TL;DR: 该论文提出NBDiff方法，将自回归语言模型高效适配为块扩散语言模型，避免从头训练扩散模型的高成本，在7B规模上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 自回归解码存在顺序生成的吞吐量瓶颈，而扩散语言模型支持并行生成但从头训练成本高昂。现有适配方法未能解决自回归因果性与块扩散双向性之间的根本不匹配问题。

Method: 将自回归视为块大小=1的块扩散，设计上下文因果注意力掩码、高效并行适配流程、辅助自回归损失以最大化数据利用，并逐步增加生成块大小。

Result: NBDiff-7B继承了长上下文建模和推理能力，在7B级扩散语言模型中达到SOTA性能，在通用知识、数学和代码基准上显著超越基线。

Conclusion: 原则性的自回归到块扩散适配是训练扩散语言模型的有效且计算高效的替代方案，避免从头训练的高成本。

Abstract: Large language models (LLMs) excel at generation but dominant autoregressive (AR) decoding is inherently sequential, creating a throughput bottleneck. Diffusion Language Models (DLMs)--especially block-wise variants--enable parallel generation and intra-block bidirectional reasoning, yet training large DLMs from scratch is costly and wastes the knowledge in mature AR checkpoints. Prior "adaptation" attempts either modify logits or randomly grow attention masks to full-sequence diffusion, or simply transplant AR weights into a block-diffusion recipe, leaving a fundamental mismatch between AR causality and block-wise bidirectionality unaddressed. We reframe adaptation as a intra-paradigm path from AR to Block-Diffusion by viewing AR as Block-Diffusion with blocksize=1. Concretely, we design the pathway of adaptation as follows: we use a context-causal attention mask (causal in context, bidirectional only within the active block), an efficient parallel adaptation procedure, an auxiliary AR loss to maximize data utilization and retain pretrained knowledge, and gradual increment of the generation block size. The recipe integrates cleanly with masked block-diffusion and maintains train-inference consistency. Built on these components, NBDiff-7B (Base and Instruct) could inherit the long-context modeling and reasoning capabilities, and achieve state-of-the-art performance among the 7B-class DLMs, delivering strong gains on general-knowledge, math, and code benchmarks over strong baselines. These results demonstrate that principled AR-to-block-diffusion adaptation is an effective and compute-efficient alternative to training DLMs from scratch. Codes: https://github.com/YuchuanTian/NBDiff.

</details>


### [26] [LLM4SFC: Sequential Function Chart Generation via Large Language Models](https://arxiv.org/abs/2512.06787)
*Ofek Glick,Vladimir Tchuiev,Marah Ghoummaid,Michal Moshkovitz,Dotan Di-Castro*

Main category: cs.CL

TL;DR: LLM4SFC框架首次实现从自然语言描述生成可执行的顺序功能图(SFC)，解决了图形化PLC编程语言生成难题，在真实工业数据集上达到75%-94%的成功率。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型已用于生成文本化PLC编程语言（如结构化文本），但IEC 61131-3标准的图形化语言（如顺序功能图SFC）仍未被充分探索。SFC生成面临图形性质和嵌入式ST动作的挑战，传统生成技术常产生不可执行代码，无法与工业工具链兼容。

Method: LLM4SFC框架包含三个核心组件：(1) 精简结构化表示，捕获SFC基本拓扑和嵌入式ST动作，减少文本冗余；(2) 微调和少样本检索增强生成(RAG)，使模型对齐SFC编程规范；(3) 结构化生成方法，实时修剪非法标记，确保符合SFC文本格式。

Result: 在自动化制造项目的真实SFC数据集上评估，使用开源和专有大语言模型。结果显示LLM4SFC可靠地生成语法有效的SFC程序，成功桥接图形和文本PLC语言，生成成功率在75%-94%之间。

Conclusion: LLM4SFC首次实现了从自然语言到可执行SFC的可靠生成，为自动化工业编程铺平了道路，有效解决了图形化PLC编程语言的生成挑战。

Abstract: While Large Language Models (LLMs) are increasingly used for synthesizing textual PLC programming languages like Structured Text (ST) code, other IEC 61131-3 standard graphical languages like Sequential Function Charts (SFCs) remain underexplored. Generating SFCs is challenging due to graphical nature and ST actions embedded within, which are not directly compatible with standard generation techniques, often leading to non-executable code that is incompatible with industrial tool-chains In this work, we introduce LLM4SFC, the first framework to receive natural-language descriptions of industrial workflows and provide executable SFCs. LLM4SFC is based on three components: (i) A reduced structured representation that captures essential topology and in-line ST and reduced textual verbosity; (ii) Fine-tuning and few-shot retrieval-augmented generation (RAG) for alignment with SFC programming conventions; and (iii) A structured generation approach that prunes illegal tokens in real-time to ensure compliance with the textual format of SFCs. We evaluate LLM4SFC on a dataset of real-world SFCs from automated manufacturing projects, using both open-source and proprietary LLMs. The results show that LLM4SFC reliably generates syntactically valid SFC programs effectively bridging graphical and textual PLC languages, achieving a generation generation success of 75% - 94%, paving the way for automated industrial programming.

</details>


### [27] [Large Language Model-Based Generation of Discharge Summaries](https://arxiv.org/abs/2512.06812)
*Tiago Rodrigues,Carla Teixeira Lopes*

Main category: cs.CL

TL;DR: 本文评估了五种大语言模型在自动生成出院小结任务上的表现，发现专有模型（特别是Gemini）表现最佳，开源模型虽有潜力但存在幻觉和重复信息问题。


<details>
  <summary>Details</summary>
Motivation: 出院小结包含丰富的患者信息，自动化生成可减轻医护人员负担、减少错误，并确保关键患者信息易于获取和操作。

Method: 使用五种大语言模型（开源模型：Mistral、Llama 2；专有模型：GPT-3、GPT-4、Gemini 1.5 Pro），基于MIMIC-III数据集，采用精确匹配、软重叠和无参考指标进行评估。

Result: 专有模型（特别是使用单样本提示的Gemini）表现最佳，生成的摘要与黄金标准相似度最高。开源模型（尤其是微调后的Mistral）虽有潜力，但存在幻觉和重复信息问题。临床专家的人工评估证实了专有模型生成摘要的实用性。

Conclusion: 大语言模型（特别是专有模型）是自动生成出院小结的有前景的候选方案，但需解决幻觉和缺失信息等挑战，并确保数据隐私。

Abstract: Discharge Summaries are documents written by medical professionals that detail a patient's visit to a care facility. They contain a wealth of information crucial for patient care, and automating their generation could significantly reduce the effort required from healthcare professionals, minimize errors, and ensure that critical patient information is easily accessible and actionable. In this work, we explore the use of five Large Language Models on this task, from open-source models (Mistral, Llama 2) to proprietary systems (GPT-3, GPT-4, Gemini 1.5 Pro), leveraging MIMIC-III summaries and notes. We evaluate them using exact-match, soft-overlap, and reference-free metrics. Our results show that proprietary models, particularly Gemini with one-shot prompting, outperformed others, producing summaries with the highest similarity to the gold-standard ones. Open-source models, while promising, especially Mistral after fine-tuning, lagged in performance, often struggling with hallucinations and repeated information. Human evaluation by a clinical expert confirmed the practical utility of the summaries generated by proprietary models. Despite the challenges, such as hallucinations and missing information, the findings suggest that LLMs, especially proprietary models, are promising candidates for automatic discharge summary generation as long as data privacy is ensured.

</details>


### [28] [CAuSE: Decoding Multimodal Classifiers using Faithful Natural Language Explanation](https://arxiv.org/abs/2512.06814)
*Dibyanayan Bandyopadhyay,Soham Bhattacharjee,Mohammed Hasanuzzaman,Asif Ekbal*

Main category: cs.CL

TL;DR: CAuSE是一个通过因果抽象生成忠实自然语言解释的新框架，适用于任何预训练多模态分类器，通过交换干预训练，在忠实度指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态分类器通常被视为黑盒模型，现有解释方法中很少有像自然语言解释那样直观易懂的。为了建立信任，这些解释必须忠实反映分类器的内部决策行为（忠实性）。

Method: 提出CAuSE框架，通过交换干预训练，为预训练多模态分类器生成忠实的自然语言解释。该方法形成对底层分类器的因果抽象，并设计了新的多模态场景下因果忠实度度量指标。

Result: CAuSE在忠实度指标上优于其他方法，通过广泛的实证评估证明其在不同数据集和模型上的泛化能力。定性分析进一步证实了其优势，同时进行了详细的错误分析以确定失败案例。

Conclusion: CAuSE是一个有效生成忠实自然语言解释的框架，通过因果抽象理论保证解释的忠实性，为多模态分类器的可解释性提供了新的解决方案。

Abstract: Multimodal classifiers function as opaque black box models. While several techniques exist to interpret their predictions, very few of them are as intuitive and accessible as natural language explanations (NLEs). To build trust, such explanations must faithfully capture the classifier's internal decision making behavior, a property known as faithfulness. In this paper, we propose CAuSE (Causal Abstraction under Simulated Explanations), a novel framework to generate faithful NLEs for any pretrained multimodal classifier. We demonstrate that CAuSE generalizes across datasets and models through extensive empirical evaluations. Theoretically, we show that CAuSE, trained via interchange intervention, forms a causal abstraction of the underlying classifier. We further validate this through a redesigned metric for measuring causal faithfulness in multimodal settings. CAuSE surpasses other methods on this metric, with qualitative analysis reinforcing its advantages. We perform detailed error analysis to pinpoint the failure cases of CAuSE. For replicability, we make the codes available at https://github.com/newcodevelop/CAuSE

</details>


### [29] [AquaFusionNet: Lightweight VisionSensor Fusion Framework for Real-Time Pathogen Detection and Water Quality Anomaly Prediction on Edge Devices](https://arxiv.org/abs/2512.06848)
*Sepyan Purnama Kristanto,Lutfi Hakim,Hermansyah*

Main category: cs.CL

TL;DR: AquaFusionNet是一个轻量级跨模态框架，统一了微生物显微成像和物理化学传感器数据，用于实时监测小型饮用水系统的微生物污染，在边缘设备上实现了高精度检测。


<details>
  <summary>Details</summary>
Motivation: 现有监测工具只能捕捉微生物污染的片段信息，操作员需要分别处理显微成像和传感器数据，导致实时决策不可靠。特别是在低中收入地区，小型饮用水系统的微生物污染波动迅速，需要更有效的监测方案。

Method: 提出AquaFusionNet框架，通过门控交叉注意力机制学习微生物外观与传感器动态之间的统计依赖关系。使用新数据集AquaMicro12K（包含12,846张饮用水环境标注显微图像）进行训练，专门设计用于低功耗硬件。

Result: 在印度尼西亚东爪哇7个设施部署6个月，处理184万帧图像，污染事件检测达到94.8% mAP@0.5，异常预测准确率96.3%，功耗仅4.8W（Jetson Nano）。相比其他轻量级检测器，在相同或更低功耗下提供更高精度。

Conclusion: 跨模态耦合减少了单模态检测器的常见故障模式，特别是在污垢、浊度峰值和不一致光照条件下。所有模型、数据和硬件设计已开源，便于在分散式水安全基础设施中复制和适配。

Abstract: Evidence from many low and middle income regions shows that microbial contamination in small scale drinking water systems often fluctuates rapidly, yet existing monitoring tools capture only fragments of this behaviour. Microscopic imaging provides organism level visibility, whereas physicochemical sensors reveal shortterm changes in water chemistry; in practice, operators must interpret these streams separately, making realtime decision-making unreliable. This study introduces AquaFusionNet, a lightweight cross-modal framework that unifies both information sources inside a single edge deployable model. Unlike prior work that treats microscopic detection and water quality prediction as independent tasks, AquaFusionNet learns the statistical dependencies between microbial appearance and concurrent sensor dynamics through a gated crossattention mechanism designed specifically for lowpower hardware. The framework is trained on AquaMicro12K, a new dataset comprising 12,846 annotated 1000 micrographs curated for drinking water contexts, an area where publicly accessible microscopic datasets are scarce. Deployed for six months across seven facilities in East Java, Indonesia, the system processed 1.84 million frames and consistently detected contamination events with 94.8% mAP@0.5 and 96.3% anomaly prediction accuracy, while operating at 4.8 W on a Jetson Nano. Comparative experiments against representative lightweight detectors show that AquaFusionNet provides higher accuracy at comparable or lower power, and field results indicate that cross-modal coupling reduces common failure modes of unimodal detectors, particularly under fouling, turbidity spikes, and inconsistent illumination. All models, data, and hardware designs are released openly to facilitate replication and adaptation in decentralized water safety infrastructures.

</details>


### [30] [Rhea: Role-aware Heuristic Episodic Attention for Conversational LLMs](https://arxiv.org/abs/2512.06869)
*Wanyang Hong,Zhaoning Zhang,Yi Chen,Libo Zhang,Baihui Liu,Linbo Qiao,Zhiliang Tian,Dongsheng Li*

Main category: cs.CL

TL;DR: Rhea框架通过分离指令记忆和情景记忆，解决大语言模型在多轮对话中的累积上下文衰减问题，显著提升对话性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在单轮任务上表现优异，但在多轮对话中性能会逐渐下降，这是由于注意力污染、稀释和漂移导致的累积上下文衰减现象。

Method: 提出Rhea框架，将对话历史解耦为两个独立记忆模块：指令记忆（持久存储全局约束）和情景记忆（动态管理用户-模型交互），通过优先级注意力机制构建高信噪比上下文。

Result: 在多个多轮对话基准测试中，Rhea缓解了性能衰减，在10分制上提升了1.04分（相对基线提升16%），在长程交互中保持接近完美的指令保真度（IAR > 8.1）。

Conclusion: Rhea为构建更精确、指令一致的对话式大语言模型提供了一个原则性且有效的框架。

Abstract: Large Language Models (LLMs) have achieved remarkable performance on single-turn tasks, yet their effectiveness deteriorates in multi-turn conversations. We define this phenomenon as cumulative contextual decay - a progressive degradation of contextual integrity caused by attention pollution, dilution, and drift. To address this challenge, we propose Rhea (Role-aware Heuristic Episodic Attention), a novel framework that decouples conversation history into two functionally independent memory modules: (1) an Instructional Memory (IM) that persistently stores high-fidelity global constraints via a structural priority mechanism, and (2) an Episodic Memory (EM) that dynamically manages user-model interactions via asymmetric noise control and heuristic context retrieval. During inference, Rhea constructs a high signal-to-noise context by applying its priority attention: selectively integrating relevant episodic information while always prioritizing global instructions. To validate this approach, experiments on multiple multi-turn conversation benchmarks - including MT-Eval and Long-MT-Bench+ - show that Rhea mitigates performance decay and improves overall accuracy by 1.04 points on a 10-point scale (a 16% relative gain over strong baselines). Moreover, Rhea maintains near-perfect instruction fidelity (IAR > 8.1) across long-horizon interactions. These results demonstrate that Rhea provides a principled and effective framework for building more precise, instruction-consistent conversational LLMs.

</details>


### [31] [An Analysis of Large Language Models for Simulating User Responses in Surveys](https://arxiv.org/abs/2512.06874)
*Ziyun Yu,Yiru Zhou,Chen Zhao,Hongyi Wen*

Main category: cs.CL

TL;DR: LLMs在模拟用户观点时存在偏见，难以准确代表不同人口统计和文化背景的用户，即使采用CLAIMSIM方法增加回答多样性，仍无法有效模拟真实用户。


<details>
  <summary>Details</summary>
Motivation: 随着使用LLMs模拟用户观点日益受到关注，但经过RLHF训练的LLMs倾向于主流观点，这引发了对它们能否代表多样化人口统计和文化背景用户的担忧。

Method: 研究通过直接提示和思维链提示测试LLMs模拟跨领域调查问题的能力，并提出CLAIMSIM方法，从LLM参数知识中提取观点作为上下文输入。

Result: 实验表明，虽然CLAIMSIM能产生更多样化的回答，但两种方法都难以准确模拟用户。分析发现两个关键限制：1) LLMs倾向于在不同人口特征下保持固定观点，生成单一视角主张；2) 面对冲突主张时，LLMs难以推理人口特征间的细微差异，限制了其适应特定用户画像的能力。

Conclusion: LLMs在模拟多样化用户观点方面存在显著局限性，需要更先进的方法来克服其偏见和推理限制，以更准确地代表不同背景的用户。

Abstract: Using Large Language Models (LLMs) to simulate user opinions has received growing attention. Yet LLMs, especially trained with reinforcement learning from human feedback (RLHF), are known to exhibit biases toward dominant viewpoints, raising concerns about their ability to represent users from diverse demographic and cultural backgrounds. In this work, we examine the extent to which LLMs can simulate human responses to cross-domain survey questions through direct prompting and chain-of-thought prompting. We further propose a claim diversification method CLAIMSIM, which elicits viewpoints from LLM parametric knowledge as contextual input. Experiments on the survey question answering task indicate that, while CLAIMSIM produces more diverse responses, both approaches struggle to accurately simulate users. Further analysis reveals two key limitations: (1) LLMs tend to maintain fixed viewpoints across varying demographic features, and generate single-perspective claims; and (2) when presented with conflicting claims, LLMs struggle to reason over nuanced differences among demographic features, limiting their ability to adapt responses to specific user profiles.

</details>


### [32] [Automated PRO-CTCAE Symptom Selection based on Prior Adverse Event Profiles](https://arxiv.org/abs/2512.06919)
*Francois Vandenhende,Anna Georgiou,Michalis Georgiou,Theodoros Psaras,Ellie Karekla*

Main category: cs.CL

TL;DR: 开发自动化方法从PRO-CTCAE库中选择最小但全面的症状子集，基于历史安全数据和MedDRA语义分析，平衡信号覆盖与患者负担


<details>
  <summary>Details</summary>
Motivation: PRO-CTCAE系统包含大量症状项目，传统基于预期毒性谱的选择方法存在挑战：选择过多项目会增加患者负担降低依从性，选择过少可能遗漏重要安全信号，需要更客观、可重复的方法来优化项目选择

Method: 将候选PRO-CTCAE症状映射到MedDRA首选术语，编码到Safeterm高维语义空间，结合相关性和发生率计算效用函数，应用谱分析识别正交医学概念集，按重要性排序症状并基于解释信息确定截止点

Result: 开发了集成到Safeterm试验安全应用的工具，通过模拟和肿瘤学案例研究评估性能，证明该方法能有效平衡信号覆盖与患者负担

Conclusion: 自动化方法利用MedDRA语义和历史数据简化PRO-CTCAE设计，提供客观可重复的方法来平衡信号覆盖与患者负担，有望改善临床试验中的患者报告结局收集

Abstract: The PRO-CTCAE is an NCI-developed patient-reported outcome system for capturing symptomatic adverse events in oncology trials. It comprises a large library drawn from the CTCAE vocabulary, and item selection for a given trial is typically guided by expected toxicity profiles from prior data. Selecting too many PRO-CTCAE items can burden patients and reduce compliance, while too few may miss important safety signals. We present an automated method to select a minimal yet comprehensive PRO-CTCAE subset based on historical safety data. Each candidate PRO-CTCAE symptom term is first mapped to its corresponding MedDRA Preferred Terms (PTs), which are then encoded into Safeterm, a high-dimensional semantic space capturing clinical and contextual diversity in MedDRA terminology. We score each candidate PRO item for relevance to the historical list of adverse event PTs and combine relevance and incidence into a utility function. Spectral analysis is then applied to the combined utility and diversity matrix to identify an orthogonal set of medical concepts that balances relevance and diversity. Symptoms are rank-ordered by importance, and a cut-off is suggested based on the explained information. The tool is implemented as part of the Safeterm trial-safety app. We evaluate its performance using simulations and oncology case studies in which PRO-CTCAE was employed. This automated approach can streamline PRO-CTCAE design by leveraging MedDRA semantics and historical data, providing an objective and reproducible method to balance signal coverage against patient burden.

</details>


### [33] [Large Language Models and Forensic Linguistics: Navigating Opportunities and Threats in the Age of Generative AI](https://arxiv.org/abs/2512.06922)
*George Mikros*

Main category: cs.CL

TL;DR: LLMs在司法语言学中既是分析工具又是挑战来源，既能辅助大规模语料分析和作者识别，又能模仿风格、混淆作者身份并生成合成文本，这动摇了司法语言学的基本假设。当前的AI文本检测技术存在高误报率和易受对抗攻击等局限，需要方法论重构以保持科学可信度和法律可采性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）对司法语言学构成双重挑战：一方面作为强大的分析工具支持大规模语料分析和基于嵌入的作者归属分析，另一方面通过风格模仿、作者身份混淆和合成文本扩散，动摇了关于个人语言风格（idiolect）的基本假设。这种张力对司法鉴定具有重要影响。

Method: 文章分析了当前AI文本检测技术的三种主要方法：基于分类器的方法、风格计量学方法和水印方法。这些方法都存在显著局限性，包括对非母语英语写作者的高误报率，以及对同形异义字替换等对抗策略的脆弱性。

Result: 研究表明LLMs能够近似表面风格特征，但与人类作者存在可检测的差异。当前的检测技术在法律可采性标准（特别是Daubert和Kumho Tire框架）下面临重大挑战，存在科学可信度和法律可采性问题。

Conclusion: 司法语言学需要进行方法论重构以保持科学可信度和法律可采性。建议的调整包括：人机混合工作流程、超越二元分类的可解释检测范式，以及测量不同人群错误率和偏见的验证机制。该领域的核心见解（语言揭示其生产者信息）仍然有效，但必须适应日益复杂的人机作者链。

Abstract: Large language models (LLMs) present a dual challenge for forensic linguistics. They serve as powerful analytical tools enabling scalable corpus analysis and embedding-based authorship attribution, while simultaneously destabilising foundational assumptions about idiolect through style mimicry, authorship obfuscation, and the proliferation of synthetic texts. Recent stylometric research indicates that LLMs can approximate surface stylistic features yet exhibit detectable differences from human writers, a tension with significant forensic implications. However, current AI-text detection techniques, whether classifier-based, stylometric, or watermarking approaches, face substantial limitations: high false positive rates for non-native English writers and vulnerability to adversarial strategies such as homoglyph substitution. These uncertainties raise concerns under legal admissibility standards, particularly the Daubert and Kumho Tire frameworks. The article concludes that forensic linguistics requires methodological reconfiguration to remain scientifically credible and legally admissible. Proposed adaptations include hybrid human-AI workflows, explainable detection paradigms beyond binary classification, and validation regimes measuring error and bias across diverse populations. The discipline's core insight, i.e., that language reveals information about its producer, remains valid but must accommodate increasingly complex chains of human and machine authorship.

</details>


### [34] [XAM: Interactive Explainability for Authorship Attribution Models](https://arxiv.org/abs/2512.06924)
*Milad Alshomary,Anisha Bhatnagar,Peter Zeng,Smaranda Muresan,Owen Rambow,Kathleen McKeown*

Main category: cs.CL

TL;DR: IXAM是一个交互式可解释性框架，用于探索作者归属模型的嵌入空间，并通过多粒度写作风格特征解释模型预测


<details>
  <summary>Details</summary>
Motivation: 现有的作者归属模型缺乏交互式可解释性工具，用户难以理解模型如何基于写作风格做出预测决策

Method: 开发交互式框架，允许用户探索模型嵌入空间，构建多粒度写作风格特征解释，并与预定义风格解释进行对比

Result: 通过用户评估证明，相比预定义风格解释，该框架在解释作者归属模型预测方面具有更高价值

Conclusion: IXAM框架为作者归属模型提供了有效的交互式可解释性工具，增强了用户对模型决策过程的理解

Abstract: We present IXAM, an Interactive eXplainability framework for Authorship Attribution Models. Given an authorship attribution (AA) task and an embedding-based AA model, our tool enables users to interactively explore the model's embedding space and construct an explanation of the model's prediction as a set of writing style features at different levels of granularity. Through a user evaluation, we demonstrate the value of our framework compared to predefined stylistic explanations.

</details>


### [35] [Progress Ratio Embeddings: An Impatience Signal for Robust Length Control in Neural Text Generation](https://arxiv.org/abs/2512.06938)
*Ivanhoé Botcazou,Tassadit Amghar,Sylvain Lamprier,Frédéric Saubion*

Main category: cs.CL

TL;DR: 提出Progress Ratio Embeddings (PRE)方法，通过连续嵌入和三角函数信号实现鲁棒的长度控制，解决了现有方法在超出训练分布时的稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 现代神经语言模型在文本生成方面取得了高准确率，但对生成长度的精确控制仍然不足。现有基于反向位置嵌入(RPE)的方法在控制超出训练分布的长度时存在局限性，特别是使用与绝对剩余标记数相关的离散倒计时信号会导致不稳定性。

Method: 引入Progress Ratio Embeddings (PRE)，这是一种连续嵌入方法，与三角函数不耐烦信号相关联。PRE可以无缝集成到标准Transformer架构中，提供稳定的长度保真度，同时不会降低标准评估指标下的文本准确性。

Result: PRE在两种广泛使用的新闻摘要基准测试中验证了其有效性。该方法不仅保持了文本生成质量，还能很好地泛化到未见过的目标长度。

Conclusion: PRE方法为文本生成提供了鲁棒的长度控制，解决了现有方法的稳定性问题，并能有效泛化到训练分布之外的长度要求。

Abstract: Modern neural language models achieve high accuracy in text generation, yet precise control over generation length remains underdeveloped. In this paper, we first investigate a recent length control method based on Reverse Positional Embeddings (RPE) and show its limits when control is requested beyond the training distribution. In particular, using a discrete countdown signal tied to the absolute remaining token count leads to instability. To provide robust length control, we introduce Progress Ratio Embeddings (PRE), as continuous embeddings tied to a trigonometric impatience signal. PRE integrates seamlessly into standard Transformer architectures, providing stable length fidelity without degrading text accuracy under standard evaluation metrics. We further show that PRE generalizes well to unseen target lengths. Experiments on two widely used news-summarization benchmarks validate these findings.

</details>


### [36] [Prompting-in-a-Series: Psychology-Informed Contents and Embeddings for Personality Recognition With Decoder-Only Models](https://arxiv.org/abs/2512.06991)
*Jing Jie Tan,Ban-Hoe Kwan,Danny Wee-Kiat Ng,Yan-Chai Hum,Anissa Mokraoui,Shih-Yu Lo*

Main category: cs.CL

TL;DR: PICEPR算法通过心理学信息内容嵌入进行人格识别，采用内容和嵌入两条管道，利用模块化解码器LLM进行内容总结/生成，在人格识别任务上实现了5-15%的性能提升，达到新的SOTA。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在各种NLP任务上表现出色，但在人格识别任务上仍有提升空间。研究者希望开发一种专门针对人格识别的算法，利用LLM的生成和总结能力来增强人格特征提取和人格丰富内容生成。

Method: 提出PICEPR算法，包含两条管道：(a)内容管道：使用模块化解码器LLM总结或生成内容；(b)嵌入管道：将生成的内容用于人格识别。算法作为人格特征提取器和人格丰富内容生成器，同时比较了闭源模型(gpt4o、gemini)和开源模型(mistral)的生成质量。

Result: PICEPR算法在人格识别任务上实现了5-15%的性能提升，达到了新的最先进水平。同时通过实验验证了算法的合理性，并比较了不同模型生成内容的质量。

Conclusion: PICEPR算法通过心理学信息内容嵌入有效提升了人格识别性能，证明了模块化LLM在人格特征提取和内容生成方面的潜力，为相关研究提供了新的技术路径。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across various natural language processing tasks. This research introduces a novel "Prompting-in-a-Series" algorithm, termed PICEPR (Psychology-Informed Contents Embeddings for Personality Recognition), featuring two pipelines: (a) Contents and (b) Embeddings. The approach demonstrates how a modularised decoder-only LLM can summarize or generate content, which can aid in classifying or enhancing personality recognition functions as a personality feature extractor and a generator for personality-rich content. We conducted various experiments to provide evidence to justify the rationale behind the PICEPR algorithm. Meanwhile, we also explored closed-source models such as \textit{gpt4o} from OpenAI and \textit{gemini} from Google, along with open-source models like \textit{mistral} from Mistral AI, to compare the quality of the generated content. The PICEPR algorithm has achieved a new state-of-the-art performance for personality recognition by 5-15\% improvement. The work repository and models' weight can be found at https://research.jingjietan.com/?q=PICEPR.

</details>


### [37] [FVA-RAG: Falsification-Verification Alignment for Mitigating Sycophantic Hallucinations](https://arxiv.org/abs/2512.07015)
*Mayank Ravishankara*

Main category: cs.CL

TL;DR: FVA-RAG框架通过引入对抗性检索策略和双重验证机制，将检索范式从归纳验证转向演绎证伪，有效解决RAG系统中的检索奉承问题。


<details>
  <summary>Details</summary>
Motivation: 标准RAG架构存在检索奉承漏洞：当用户查询基于错误前提或常见误解时，向量检索器倾向于获取符合用户偏见的文档，导致模型产生"带引用的幻觉"。

Method: 提出FVA-RAG框架：1）采用对抗性检索策略，主动生成"致命查询"来寻找矛盾证据；2）引入双重验证机制，明确权衡草稿答案与"反上下文"证据。

Result: 在常见误解数据集上的初步实验表明，FVA-RAG相比标准RAG基线显著提高了对奉承幻觉的鲁棒性，有效充当事实生成的推理时"红队"。

Conclusion: FVA-RAG通过将检索范式从寻求支持的归纳验证转向寻求反证的演绎证伪，为RAG系统提供了对抗检索奉承的有效解决方案。

Abstract: Retrieval-Augmented Generation (RAG) systems have significantly reduced hallucinations in Large Language Models (LLMs) by grounding responses in external context. However, standard RAG architectures suffer from a critical vulnerability: Retrieval Sycophancy. When presented with a query based on a false premise or a common misconception, vector-based retrievers tend to fetch documents that align with the user's bias rather than objective truth, leading the model to "hallucinate with citations."
  In this work, we introduce Falsification-Verification Alignment RAG (FVA-RAG), a framework that shifts the retrieval paradigm from Inductive Verification (seeking support) to Deductive Falsification (seeking disproof). Unlike existing "Self-Correction" methods that rely on internal consistency, FVA-RAG deploys a distinct Adversarial Retrieval Policy that actively generates "Kill Queries"-targeted search terms designed to surface contradictory evidence. We introduce a dual-verification mechanism that explicitly weighs the draft answer against this "Anti-Context." Preliminary experiments on a dataset of common misconceptions demonstrate that FVA-RAG significantly improves robustness against sycophantic hallucinations compared to standard RAG baselines, effectively acting as an inference-time "Red Team" for factual generation.

</details>


### [38] [Replicating TEMPEST at Scale: Multi-Turn Adversarial Attacks Against Trillion-Parameter Frontier Models](https://arxiv.org/abs/2512.07059)
*Richard Young*

Main category: cs.CL

TL;DR: 研究发现当前大语言模型在多轮对抗攻击下普遍脆弱，模型规模不预测鲁棒性，而扩展推理模式可显著提升安全性


<details>
  <summary>Details</summary>
Motivation: 尽管在安全对齐方面投入了大量资源，但大语言模型对复杂多轮对抗攻击的脆弱性仍未被充分表征，且模型规模或推理模式是否影响鲁棒性尚不清楚

Method: 使用TEMPEST多轮攻击框架评估10个前沿模型，涵盖8个供应商的1000种有害行为，生成超过97,000个API查询，通过独立安全分类器进行自动评估

Result: 模型表现出不同的脆弱性：6个模型攻击成功率（ASR）达96%-100%，4个模型有显著抵抗力（ASR 42%-78%）；相同架构上启用扩展推理可将ASR从97%降至42%

Conclusion: 当前对齐技术对自适应多轮攻击仍存在根本性脆弱性，模型规模不预测对抗鲁棒性，而深思推理模式是可行的安全增强方向

Abstract: Despite substantial investment in safety alignment, the vulnerability of large language models to sophisticated multi-turn adversarial attacks remains poorly characterized, and whether model scale or inference mode affects robustness is unknown. This study employed the TEMPEST multi-turn attack framework to evaluate ten frontier models from eight vendors across 1,000 harmful behaviors, generating over 97,000 API queries across adversarial conversations with automated evaluation by independent safety classifiers. Results demonstrated a spectrum of vulnerability: six models achieved 96% to 100% attack success rate (ASR), while four showed meaningful resistance, with ASR ranging from 42% to 78%; enabling extended reasoning on identical architecture reduced ASR from 97% to 42%. These findings indicate that safety alignment quality varies substantially across vendors, that model scale does not predict adversarial robustness, and that thinking mode provides a deployable safety enhancement. Collectively, this work establishes that current alignment techniques remain fundamentally vulnerable to adaptive multi-turn attacks regardless of model scale, while identifying deliberative inference as a promising defense direction.

</details>


### [39] [SETUP: Sentence-level English-To-Uniform Meaning Representation Parser](https://arxiv.org/abs/2512.07068)
*Emma Markle,Javier Gutierrez Bach,Shira Wein*

Main category: cs.CL

TL;DR: 本文提出了两种英语文本到UMR解析的方法，其中SETUP模型在AnCast和SMATCH++评分上分别达到84和91，显著提升了UMR自动解析性能。


<details>
  <summary>Details</summary>
Motivation: UMR作为一种新颖的图基语义表示方法，能够捕捉文本核心含义并适应多种语言标注，但在下游应用中需要自动化的文本到UMR解析器来大规模生成准确的UMR图。目前文本到UMR解析的研究还很有限。

Method: 提出了两种英语文本到UMR解析方法：1）微调现有的抽象意义表示解析器；2）利用从通用依存关系转换器的方法。使用先前工作作为基线进行比较。

Result: 最佳模型SETUP在AnCast评分上达到84分，SMATCH++评分达到91分，表明在自动UMR解析方面取得了显著进展。

Conclusion: 本文提出的方法特别是SETUP模型，在英语文本到UMR解析任务上取得了实质性进展，为UMR的大规模自动生成和应用奠定了基础。

Abstract: Uniform Meaning Representation (UMR) is a novel graph-based semantic representation which captures the core meaning of a text, with flexibility incorporated into the annotation schema such that the breadth of the world's languages can be annotated (including low-resource languages). While UMR shows promise in enabling language documentation, improving low-resource language technologies, and adding interpretability, the downstream applications of UMR can only be fully explored when text-to-UMR parsers enable the automatic large-scale production of accurate UMR graphs at test time. Prior work on text-to-UMR parsing is limited to date. In this paper, we introduce two methods for English text-to-UMR parsing, one of which fine-tunes existing parsers for Abstract Meaning Representation and the other, which leverages a converter from Universal Dependencies, using prior work as a baseline. Our best-performing model, which we call SETUP, achieves an AnCast score of 84 and a SMATCH++ score of 91, indicating substantial gains towards automatic UMR parsing.

</details>


### [40] [Do Large Language Models Truly Understand Cross-cultural Differences?](https://arxiv.org/abs/2512.07075)
*Shiwei Guo,Sihang Jiang,Qianxi He,Yanghua Xiao,Jiaqing Liang,Bi Yude,Minggui He,Shimin Tao,Li Zhang*

Main category: cs.CL

TL;DR: SAGE是一个基于场景的基准测试，通过跨文化核心概念对齐和生成式任务设计来评估大语言模型的跨文化理解和推理能力，包含9个维度、210个核心概念和4530个测试项。


<details>
  <summary>Details</summary>
Motivation: 现有评估LLM跨文化理解能力的基准存在三个关键局限：缺乏上下文场景、跨文化概念映射不足、深度文化推理能力有限。需要构建更全面的评估工具来检验LLM是否真正具备跨文化理解能力。

Method: 基于文化理论将跨文化能力分为9个维度，通过跨文化核心概念对齐和生成式任务设计构建SAGE基准。包含210个核心概念，在15个真实世界场景下构建4530个测试项，涵盖四大类跨文化情境。

Result: SAGE数据集支持持续扩展，实验证实其可迁移到其他语言。基准测试揭示了LLM在多个维度和场景下的弱点，暴露了跨文化推理的系统性局限。虽然已有进步，但LLM距离真正细致的跨文化理解仍有差距。

Conclusion: SAGE基准填补了现有评估工具的空白，为评估LLM跨文化理解能力提供了更全面、基于场景的框架。研究表明当前LLM在跨文化推理方面仍存在系统性局限，需要进一步改进。

Abstract: In recent years, large language models (LLMs) have demonstrated strong performance on multilingual tasks. Given its wide range of applications, cross-cultural understanding capability is a crucial competency. However, existing benchmarks for evaluating whether LLMs genuinely possess this capability suffer from three key limitations: a lack of contextual scenarios, insufficient cross-cultural concept mapping, and limited deep cultural reasoning capabilities. To address these gaps, we propose SAGE, a scenario-based benchmark built via cross-cultural core concept alignment and generative task design, to evaluate LLMs' cross-cultural understanding and reasoning. Grounded in cultural theory, we categorize cross-cultural capabilities into nine dimensions. Using this framework, we curated 210 core concepts and constructed 4530 test items across 15 specific real-world scenarios, organized under four broader categories of cross-cultural situations, following established item design principles. The SAGE dataset supports continuous expansion, and experiments confirm its transferability to other languages. It reveals model weaknesses across both dimensions and scenarios, exposing systematic limitations in cross-cultural reasoning. While progress has been made, LLMs are still some distance away from reaching a truly nuanced cross-cultural understanding. In compliance with the anonymity policy, we include data and code in the supplement materials. In future versions, we will make them publicly available online.

</details>


### [41] [Leveraging KV Similarity for Online Structured Pruning in LLMs](https://arxiv.org/abs/2512.07090)
*Jungmin Lee,Gwangeun Byeon,Yulhwa Kim,Seokin Hong*

Main category: cs.CL

TL;DR: Token Filtering是一种轻量级在线结构化剪枝技术，通过测量token冗余度并跳过冗余注意力计算来加速LLM推理，无需校准数据。


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法依赖离线校准数据，可能在不同输入间泛化能力差，导致不稳定。需要一种无需校准数据的在线剪枝方法。

Method: 提出Token Filtering技术：1) 通过联合键值相似度测量token冗余度；2) 设计方差感知融合策略，自适应加权不同头的键值相似度；3) 在推理时直接跳过冗余注意力计算。

Result: 在LLaMA-2 (7B/13B)、LLaMA-3 (8B)和Mistral (7B)上的实验表明，Token Filtering优于现有结构化剪枝方法，在常识推理基准上保持准确性，在MMLU等挑战性任务上即使剪枝50%仍保持强性能。

Conclusion: Token Filtering提供了一种无需校准数据的稳定在线剪枝方案，有效加速LLM推理同时保持模型性能，为实际部署提供了实用解决方案。

Abstract: Pruning has emerged as a promising direction for accelerating large language model (LLM) inference, yet existing approaches often suffer from instability because they rely on offline calibration data that may not generalize across inputs. In this work, we introduce Token Filtering, a lightweight online structured pruning technique that makes pruning decisions directly during inference without any calibration data. The key idea is to measure token redundancy via joint key-value similarity and skip redundant attention computations, thereby reducing inference cost while preserving critical information. To further enhance stability, we design a variance-aware fusion strategy that adaptively weights key and value similarity across heads, ensuring that informative tokens are retained even under high pruning ratios. This design introduces no additional memory overhead and provides a more reliable criterion for token importance. Extensive experiments on LLaMA-2 (7B/13B), LLaMA-3 (8B), and Mistral (7B) demonstrate that Token Filtering consistently outperforms prior structured pruning methods, preserving accuracy on commonsense reasoning benchmarks and maintaining strong performance on challenging tasks such as MMLU, even with 50% pruning.

</details>


### [42] [DART: Leveraging Multi-Agent Disagreement for Tool Recruitment in Multimodal Reasoning](https://arxiv.org/abs/2512.07132)
*Nithin Sivakumaran,Justin Chih-Yao Chen,David Wan,Yue Zhang,Jaehong Yoon,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.CL

TL;DR: DART是一个多智能体框架，通过视觉智能体之间的辩论分歧来识别有用的视觉工具，利用工具提供的新信息和专家对齐评分来促进讨论，最终通过聚合智能体选择最佳答案。


<details>
  <summary>Details</summary>
Motivation: 虽然专业视觉工具可以为大语言模型或视觉语言模型提供专家知识（如接地、空间推理、医学知识等），但确定何时调用哪些工具具有挑战性。需要一种机制来智能地选择和利用这些工具。

Method: DART采用多智能体辩论框架，通过智能体之间的分歧来识别有用的视觉工具（如物体检测、OCR、空间推理等）。这些工具引入新信息并提供工具对齐的同意分数，突出与专家工具一致的智能体。最后使用聚合智能体基于智能体输出和工具信息选择最佳答案。

Result: 在四个不同基准测试中，DART优于多智能体辩论和单智能体工具调用框架。在A-OKVQA和MMMU上分别比次优基线（带评判模型的多智能体辩论）高出3.4%和2.4%。在M3D医学数据集上比其他强基线提升1.3%。文本重叠度分析显示DART具有更丰富的讨论，工具调用分布显示多样工具被可靠使用来解决分歧。

Conclusion: DART通过多智能体辩论分歧有效识别和利用视觉工具，显著提升性能，并能良好适应新工具和不同应用领域，为视觉问答任务提供了有效的工具调用机制。

Abstract: Specialized visual tools can augment large language models or vision language models with expert knowledge (e.g., grounding, spatial reasoning, medical knowledge, etc.), but knowing which tools to call (and when to call them) can be challenging. We introduce DART, a multi-agent framework that uses disagreements between multiple debating visual agents to identify useful visual tools (e.g., object detection, OCR, spatial reasoning, etc.) that can resolve inter-agent disagreement. These tools allow for fruitful multi-agent discussion by introducing new information, and by providing tool-aligned agreement scores that highlight agents in agreement with expert tools, thereby facilitating discussion. We utilize an aggregator agent to select the best answer by providing the agent outputs and tool information. We test DART on four diverse benchmarks and show that our approach improves over multi-agent debate as well as over single agent tool-calling frameworks, beating the next-strongest baseline (multi-agent debate with a judge model) by 3.4% and 2.4% on A-OKVQA and MMMU respectively. We also find that DART adapts well to new tools in applied domains, with a 1.3% improvement on the M3D medical dataset over other strong tool-calling, single agent, and multi-agent baselines. Additionally, we measure text overlap across rounds to highlight the rich discussion in DART compared to existing multi-agent methods. Finally, we study the tool call distribution, finding that diverse tools are reliably used to help resolve disagreement.

</details>


### [43] [GUMBridge: a Corpus for Varieties of Bridging Anaphora](https://arxiv.org/abs/2512.07134)
*Lauren Levine,Amir Zeldes*

Main category: cs.CL

TL;DR: GUMBridge是一个新的桥接指代资源，涵盖16种英语文体，提供桥接现象的广泛覆盖和细粒度子类型分类标注，并评估了LLMs在桥接解析任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的英语桥接指代资源大多规模小、覆盖有限、文体单一，需要更全面、多样化的标注资源来支持桥接指代研究。

Method: 创建GUMBridge资源，包含16种不同文体的英语文本，提供桥接现象的广泛覆盖和细粒度子类型分类标注，并评估标注质量。

Result: 建立了GUMBridge资源，涵盖多种文体；评估了当代开源和闭源LLMs在桥接解析和子类型分类任务上的基线性能，显示这些任务对LLMs仍然具有挑战性。

Conclusion: 桥接解析和子类型分类在LLMs时代仍然是困难的NLP任务，GUMBridge资源为这一领域的研究提供了更全面、多样化的数据支持。

Abstract: Bridging is an anaphoric phenomenon where the referent of an entity in a discourse is dependent on a previous, non-identical entity for interpretation, such as in "There is 'a house'. 'The door' is red," where the door is specifically understood to be the door of the aforementioned house. While there are several existing resources in English for bridging anaphora, most are small, provide limited coverage of the phenomenon, and/or provide limited genre coverage. In this paper, we introduce GUMBridge, a new resource for bridging, which includes 16 diverse genres of English, providing both broad coverage for the phenomenon and granular annotations for the subtype categorization of bridging varieties. We also present an evaluation of annotation quality and report on baseline performance using open and closed source contemporary LLMs on three tasks underlying our data, showing that bridging resolution and subtype classification remain difficult NLP tasks in the age of LLMs.

</details>


### [44] [MASim: Multilingual Agent-Based Simulation for Social Science](https://arxiv.org/abs/2512.07195)
*Xuan Zhang,Wenxuan Zhang,Anxu Wang,See-Kiong Ng,Yang Deng*

Main category: cs.CL

TL;DR: MASim是首个支持多语言智能体交互的仿真框架，用于研究跨语言社会行为，包含全球舆论建模和媒体影响分析功能。


<details>
  <summary>Details</summary>
Motivation: 现有智能体角色扮演模拟大多是单语言的，无法模拟真实社会中跨语言交互这一重要特性，限制了计算社会科学研究的可扩展性和可控性。

Method: 开发了MASim多语言智能体仿真框架，支持具有不同社会语言特征的生成式智能体进行多轮交互。构建了MAPS基准测试，结合全球人口分布的调查问题和人口统计角色。

Result: 实验显示MASim能够复现社会文化现象，在校准、敏感性、一致性和文化案例研究中表现良好，突显了多语言仿真对可扩展、可控计算社会科学的重要性。

Conclusion: MASim为研究跨语言社会互动提供了首个多语言智能体仿真框架，通过全球舆论建模和媒体影响分析，推动了计算社会科学向多语言环境扩展。

Abstract: Multi-agent role-playing has recently shown promise for studying social behavior with language agents, but existing simulations are mostly monolingual and fail to model cross-lingual interaction, an essential property of real societies. We introduce MASim, the first multilingual agent-based simulation framework that supports multi-turn interaction among generative agents with diverse sociolinguistic profiles. MASim offers two key analyses: (i) global public opinion modeling, by simulating how attitudes toward open-domain hypotheses evolve across languages and cultures, and (ii) media influence and information diffusion, via autonomous news agents that dynamically generate content and shape user behavior. To instantiate simulations, we construct the MAPS benchmark, which combines survey questions and demographic personas drawn from global population distributions. Experiments on calibration, sensitivity, consistency, and cultural case studies show that MASim reproduces sociocultural phenomena and highlights the importance of multilingual simulation for scalable, controlled computational social science.

</details>


### [45] [NeSTR: A Neuro-Symbolic Abductive Framework for Temporal Reasoning in Large Language Models](https://arxiv.org/abs/2512.07218)
*Feng Liang,Weixin Zeng,Runhao Zhao,Xiang Zhao*

Main category: cs.CL

TL;DR: NeSTR是一个神经符号时序推理框架，通过结合符号表示和混合反思推理来增强LLM的时序敏感性，在多个时序问答基准上实现了优越的零样本性能。


<details>
  <summary>Details</summary>
Motivation: LLM在复杂时序约束下的推理仍然是一个主要挑战。现有方法存在不足：符号方法未能充分利用LLM的推理能力，而反思方法缺乏结构化时序表示，导致不一致或幻觉推理。即使有时序上下文，LLM仍可能误解或误用时序信息。

Method: 提出神经符号时序推理（NeSTR）框架，集成结构化符号表示与混合反思推理。通过符号编码保留显式时序关系，通过验证强制执行逻辑一致性，使用溯因反思纠正有缺陷的推理。

Result: 在多样化的时序问答基准上进行广泛实验，NeSTR实现了优越的零样本性能，无需任何微调即可持续改进时序推理，展示了神经符号集成在增强LLM时序理解方面的优势。

Conclusion: NeSTR通过神经符号集成有效解决了LLM在复杂时序推理中的挑战，为增强LLM的时序理解能力提供了有前景的方向。

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of natural language processing tasks. However, temporal reasoning, particularly under complex temporal constraints, remains a major challenge. To this end, existing approaches have explored symbolic methods, which encode temporal structure explicitly, and reflective mechanisms, which revise reasoning errors through multi-step inference. Nonetheless, symbolic approaches often underutilize the reasoning capabilities of LLMs, while reflective methods typically lack structured temporal representations, which can result in inconsistent or hallucinated reasoning. As a result, even when the correct temporal context is available, LLMs may still misinterpret or misapply time-related information, leading to incomplete or inaccurate answers. To address these limitations, in this work, we propose Neuro-Symbolic Temporal Reasoning (NeSTR), a novel framework that integrates structured symbolic representations with hybrid reflective reasoning to enhance the temporal sensitivity of LLM inference. NeSTR preserves explicit temporal relations through symbolic encoding, enforces logical consistency via verification, and corrects flawed inferences using abductive reflection. Extensive experiments on diverse temporal question answering benchmarks demonstrate that NeSTR achieves superior zero-shot performance and consistently improves temporal reasoning without any fine-tuning, showcasing the advantage of neuro-symbolic integration in enhancing temporal understanding in large language models.

</details>


### [46] [Ensembling LLM-Induced Decision Trees for Explainable and Robust Error Detection](https://arxiv.org/abs/2512.07246)
*Mengqi Wang,Jianwei Wang,Qing Liu,Xiwei Xu,Zhenchang Xing,Liming Zhu,Wenjie Zhang*

Main category: cs.CL

TL;DR: 提出TreeED和ForestED框架，用LLM诱导决策树进行错误检测，提升可解释性和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的错误检测方法存在两个主要问题：1) 黑盒决策过程缺乏可解释性；2) 对提示词敏感，输出不一致，缺乏鲁棒性

Method: 提出LLM-as-an-inducer框架：TreeED使用LLM诱导决策树骨架，包含规则节点、GNN节点和叶子节点；ForestED通过不确定性采样构建多个决策树，使用EM算法估计树可靠性并优化共识预测

Result: 实验表明方法准确、可解释且鲁棒，平均F1分数比最佳基线提升16.1%

Conclusion: 通过LLM诱导决策树而非直接标注，有效解决了现有方法的可解释性和鲁棒性问题，为表格数据错误检测提供了新思路

Abstract: Error detection (ED), which aims to identify incorrect or inconsistent cell values in tabular data, is important for ensuring data quality. Recent state-of-the-art ED methods leverage the pre-trained knowledge and semantic capability embedded in large language models (LLMs) to directly label whether a cell is erroneous. However, this LLM-as-a-labeler pipeline (1) relies on the black box, implicit decision process, thus failing to provide explainability for the detection results, and (2) is highly sensitive to prompts, yielding inconsistent outputs due to inherent model stochasticity, therefore lacking robustness. To address these limitations, we propose an LLM-as-an-inducer framework that adopts LLM to induce the decision tree for ED (termed TreeED) and further ensembles multiple such trees for consensus detection (termed ForestED), thereby improving explainability and robustness. Specifically, based on prompts derived from data context, decision tree specifications and output requirements, TreeED queries the LLM to induce the decision tree skeleton, whose root-to-leaf decision paths specify the stepwise procedure for evaluating a given sample. Each tree contains three types of nodes: (1) rule nodes that perform simple validation checks (e.g., format or range), (2) Graph Neural Network (GNN) nodes that capture complex patterns (e.g., functional dependencies), and (3) leaf nodes that output the final decision types (error or clean). Furthermore, ForestED employs uncertainty-based sampling to obtain multiple row subsets, constructing a decision tree for each subset using TreeED. It then leverages an Expectation-Maximization-based algorithm that jointly estimates tree reliability and optimizes the consensus ED prediction. Extensive xperiments demonstrate that our methods are accurate, explainable and robust, achieving an average F1-score improvement of 16.1% over the best baseline.

</details>


### [47] [TeluguST-46: A Benchmark Corpus and Comprehensive Evaluation for Telugu-English Speech Translation](https://arxiv.org/abs/2512.07265)
*Bhavana Akkiraju,Srihari Bandarupalli,Swathi Sambangi,Vasavi Ravuri,R Vijaya Saraswathi,Anil Kumar Vuppala*

Main category: cs.CL

TL;DR: 为泰卢固语-英语语音翻译建立高质量基准，比较级联与端到端架构，发现端到端系统在低资源场景下可达到与级联方法相当的性能，并评估了多种自动评估指标的有效性。


<details>
  <summary>Details</summary>
Motivation: 泰卢固语有超过8000万使用者，但针对这种形态丰富的语言的语音翻译研究严重不足，需要填补这一空白。

Method: 从46小时手动验证的CSTD语料库数据创建泰卢固语-英语语音翻译基准（30h/8h/8h训练/开发/测试分割），系统比较级联架构（IndicWhisper + IndicMT）与端到端架构（微调SeamlessM4T模型），并评估BLEU、METEOR、ChrF++、ROUGE-L、TER和BERTScore等指标与人工评估的一致性。

Result: IndicWhisper + IndicMT因使用大量泰卢固语特定训练数据而性能最高，但微调的SeamlessM4T模型使用显著更少的泰卢固语数据却表现出惊人竞争力。传统指标比BERTScore在泰卢固语-英语翻译中提供更好的质量区分。

Conclusion: 通过仔细的超参数调整和足够的平行数据（可能少于100小时），端到端系统在低资源场景下可以达到与级联方法相当的性能，为形态复杂语言对的自动评估提供实用指导。

Abstract: Despite Telugu being spoken by over 80 million people, speech translation research for this morphologically rich language remains severely underexplored. We address this gap by developing a high-quality Telugu--English speech translation benchmark from 46 hours of manually verified CSTD corpus data (30h/8h/8h train/dev/test split). Our systematic comparison of cascaded versus end-to-end architectures shows that while IndicWhisper + IndicMT achieves the highest performance due to extensive Telugu-specific training data, finetuned SeamlessM4T models demonstrate remarkable competitiveness despite using significantly less Telugu-specific training data. This finding suggests that with careful hyperparameter tuning and sufficient parallel data (potentially less than 100 hours), end-to-end systems can achieve performance comparable to cascaded approaches in low-resource settings. Our metric reliability study evaluating BLEU, METEOR, ChrF++, ROUGE-L, TER, and BERTScore against human judgments reveals that traditional metrics provide better quality discrimination than BERTScore for Telugu--English translation. The work delivers three key contributions: a reproducible Telugu--English benchmark, empirical evidence of competitive end-to-end performance potential in low-resource scenarios, and practical guidance for automatic evaluation in morphologically complex language pairs.

</details>


### [48] [Efficient ASR for Low-Resource Languages: Leveraging Cross-Lingual Unlabeled Data](https://arxiv.org/abs/2512.07277)
*Srihari Bandarupalli,Bhavana Akkiraju,Charan Devarakonda,Vamsiraghusimha Narsinga,Anil Kumar Vuppala*

Main category: cs.CL

TL;DR: 该论文提出了一种针对低资源语言的跨语言连续预训练方法，通过利用无标注语音数据和形态感知分词，用更小的模型（300M参数）在波斯语上超越了Whisper Large v3（1.5B参数），证明了数据相关性和策略性预训练比模型规模更重要。


<details>
  <summary>Details</summary>
Motivation: 低资源语言的自动语音识别面临标注数据稀缺和计算资源不足的双重限制，现有大模型方法不适用于这些语言场景，需要探索更高效、资源友好的解决方案。

Method: 1) 构建3000小时多语言语料库（波斯语、阿拉伯语、乌尔都语）的可扩展无标注数据收集管道；2) 采用有针对性的连续预训练；3) 结合形态感知分词技术；4) 开发300M参数模型。

Result: 300M参数模型在波斯语上超越Whisper Large v3（1.5B参数），在阿拉伯语和乌尔都语上取得竞争性结果，证明了小模型通过策略性预训练可以达到甚至超越大模型性能。

Conclusion: ASR质量主要取决于数据相关性和策略性预训练，而非模型规模，这为低资源语言提供了实用的技术路径，无需依赖大规模计算基础设施或专有数据集即可实现有效的语音识别。

Abstract: Automatic speech recognition for low-resource languages remains fundamentally constrained by the scarcity of labeled data and computational resources required by state-of-the-art models. We present a systematic investigation into cross-lingual continuous pretraining for low-resource languages, using Perso-Arabic languages (Persian, Arabic, and Urdu) as our primary case study. Our approach demonstrates that strategic utilization of unlabeled speech data can effectively bridge the resource gap without sacrificing recognition accuracy. We construct a 3,000-hour multilingual corpus through a scalable unlabeled data collection pipeline and employ targeted continual pretraining combined with morphologically-aware tokenization to develop a 300M parameter model that achieves performance comparable to systems 5 times larger. Our model outperforms Whisper Large v3 (1.5B parameters) on Persian and achieves competitive results on Arabic and Urdu despite using significantly fewer parameters and substantially less labeled data. These findings challenge the prevailing assumption that ASR quality scales primarily with model size, revealing instead that data relevance and strategic pretraining are more critical factors for low-resource scenarios. This work provides a practical pathway toward inclusive speech technology, enabling effective ASR for underrepresented languages without dependence on massive computational infrastructure or proprietary datasets.

</details>


### [49] [Investigating Training and Generalization in Faithful Self-Explanations of Large Language Models](https://arxiv.org/abs/2512.07288)
*Tomoki Doi,Masaru Isonuma,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 通过使用特征归因方法构建伪忠实自解释进行持续学习，可以提升LLM自解释的忠实度，且这种改进能跨不同解释风格和任务泛化。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型能根据用户指令生成不同风格的自解释，但这些解释往往缺乏忠实性（不能真实反映模型的实际行为）。如何提升自解释的忠实度以及这种改进是否能跨不同解释风格泛化，是当前研究不足的问题。

Method: 使用特征归因方法构建单词约束的伪忠实自解释，在指令调优模型上进行持续学习。研究在三个分类任务和三种解释风格上分析训练效果及其泛化能力。

Result: 训练能提升所有分类任务和解释风格的自解释忠实度，且这种改进能泛化到多词设置和未见任务。三种风格间存在一致的跨风格泛化，表明训练可能促进更广泛的忠实自解释能力提升。

Conclusion: 通过伪忠实自解释进行持续学习能有效提升LLM自解释的忠实度，且这种改进具有跨风格和跨任务的泛化能力，为开发更可靠的自解释模型提供了可行路径。

Abstract: Large language models have the potential to generate explanations for their own predictions in a variety of styles based on user instructions. Recent research has examined whether these self-explanations faithfully reflect the models' actual behavior and has found that they often lack faithfulness. However, the question of how to improve faithfulness remains underexplored. Moreover, because different explanation styles have superficially distinct characteristics, it is unclear whether improvements observed in one style also arise when using other styles. This study analyzes the effects of training for faithful self-explanations and the extent to which these effects generalize, using three classification tasks and three explanation styles. We construct one-word constrained explanations that are likely to be faithful using a feature attribution method, and use these pseudo-faithful self-explanations for continual learning on instruction-tuned models. Our experiments demonstrate that training can improve self-explanation faithfulness across all classification tasks and explanation styles, and that these improvements also show signs of generalization to the multi-word settings and to unseen tasks. Furthermore, we find consistent cross-style generalization among three styles, suggesting that training may contribute to a broader improvement in faithful self-explanation ability.

</details>


### [50] [Multilingual corpora for the study of new concepts in the social sciences and humanities:](https://arxiv.org/abs/2512.07367)
*Revekka Kyriakoglou,Anna Pappa*

Main category: cs.CL

TL;DR: 提出一种构建多语言语料库的混合方法，用于研究人文社科中的新兴概念，以"非技术创新"为例，结合公司网站文本和年度报告，创建适合机器学习的数据集。


<details>
  <summary>Details</summary>
Motivation: 为支持人文社科领域新兴概念的研究，需要构建专门的多语言语料库，特别是针对像"非技术创新"这样的跨学科概念，传统语料库往往缺乏相关数据。

Method: 混合方法结合两种数据源：1) 从公司网站自动提取并清理的法语和英语文本；2) 按文档标准自动筛选的年度报告。处理流程包括语言检测、内容过滤、相关片段提取和元数据增强。构建英语数据集时，为专家词典中的每个术语提取包含前后各两句的上下文块，并标注主题类别。

Result: 创建了一个可重复、可扩展的多语言语料库资源，既可用于分析新兴概念周围的词汇变异性，也可生成专门用于自然语言处理应用的监督分类数据集。

Conclusion: 该方法为研究人文社科新兴概念提供了实用的语料库构建框架，特别适合支持机器学习任务，展示了混合数据源和系统化处理流程在创建专业语料库中的价值。

Abstract: This article presents a hybrid methodology for building a multilingual corpus designed to support the study of emerging concepts in the humanities and social sciences (HSS), illustrated here through the case of ``non-technological innovation''. The corpus relies on two complementary sources: (1) textual content automatically extracted from company websites, cleaned for French and English, and (2) annual reports collected and automatically filtered according to documentary criteria (year, format, duplication). The processing pipeline includes automatic language detection, filtering of non-relevant content, extraction of relevant segments, and enrichment with structural metadata. From this initial corpus, a derived dataset in English is created for machine learning purposes. For each occurrence of a term from the expert lexicon, a contextual block of five sentences is extracted (two preceding and two following the sentence containing the term). Each occurrence is annotated with the thematic category associated with the term, enabling the construction of data suitable for supervised classification tasks. This approach results in a reproducible and extensible resource, suitable both for analyzing lexical variability around emerging concepts and for generating datasets dedicated to natural language processing applications.

</details>


### [51] [Training Language Models to Use Prolog as a Tool](https://arxiv.org/abs/2512.07407)
*Niklas Mellgren,Peter Schneider-Kamp,Lukas Galke Poech*

Main category: cs.CL

TL;DR: 通过强化学习微调语言模型使用Prolog作为可验证计算工具，提升推理可靠性和可审计性


<details>
  <summary>Details</summary>
Motivation: 语言模型经常产生看似合理但错误的推理结果，难以验证，这给智能体AI系统的安全性带来挑战。需要确保工具使用的可靠性。

Method: 使用Group Relative Policy Optimization (GRPO)微调Qwen2.5-3B-Instruct模型，在GSM8K-Prolog-Prover数据集上实验不同提示结构、奖励组合（执行、语法、语义、结构）和推理协议（单次、best-of-N、两种智能体模式）

Result: 强化学习方法优于监督微调，3B模型在零样本MMLU上达到与7B模型少样本相当的性能。最佳配置在GSM8K上实现最高准确率，智能体推理在MMLU-Stem和MMLU-Pro上展现优越的零样本泛化能力

Conclusion: 将模型推理基于形式化验证系统能显著提高安全关键应用的可靠性和可审计性，联合优化提示、奖励和推理协议对程序语法和逻辑有重要影响

Abstract: Ensuring reliable tool use is critical for safe agentic AI systems. Language models frequently produce unreliable reasoning with plausible but incorrect solutions that are difficult to verify. To address this, we investigate fine-tuning models to use Prolog as an external tool for verifiable computation. Using Group Relative Policy Optimization (GRPO), we fine-tune Qwen2.5-3B-Instruct on a cleaned GSM8K-Prolog-Prover dataset while varying (i) prompt structure, (ii) reward composition (execution, syntax, semantics, structure), and (iii) inference protocol: single-shot, best-of-N, and two agentic modes where Prolog is invoked internally or independently. Our reinforcement learning approach outperforms supervised fine-tuning, with our 3B model achieving zero-shot MMLU performance comparable to 7B few-shot results. Our findings reveal that: 1) joint tuning of prompt, reward, and inference shapes program syntax and logic; 2) best-of-N with external Prolog verification maximizes accuracy on GSM8K; 3) agentic inference with internal repair yields superior zero-shot generalization on MMLU-Stem and MMLU-Pro. These results demonstrate that grounding model reasoning in formal verification systems substantially improves reliability and auditability for safety-critical applications. The source code for reproducing our experiments is available under https://github.com/niklasmellgren/grpo-prolog-inference

</details>


### [52] [Persian-Phi: Efficient Cross-Lingual Adaptation of Compact LLMs via Curriculum Learning](https://arxiv.org/abs/2512.07454)
*Amir Mohammad Akhlaghi,Amirhossein Shabani,Mostafa Abdolmaleki,Saeed Reza Kheradpisheh*

Main category: cs.CL

TL;DR: Persian-Phi是一个3.8B参数模型，通过创新的课程学习流程将英文Phi-3 Mini模型有效适配到波斯语，证明了小模型也能实现强大的多语言能力


<details>
  <summary>Details</summary>
Motivation: 当前AI民主化受到训练低资源语言大语言模型巨大计算成本的阻碍，需要找到资源高效的方法将先进LLM扩展到代表性不足的语言

Method: 采用新颖的课程学习流程：1) 使用双语叙事(Tiny Stories)进行"热身"阶段以对齐嵌入；2) 通过参数高效微调(PEFT)进行持续预训练和指令调优

Result: Persian-Phi在HuggingFace的Open Persian LLM Leaderboard上取得有竞争力的结果，证明了小模型也能实现强大的波斯语能力

Conclusion: 提供了一个经过验证、可扩展的框架，能够以最小硬件资源将最先进的LLM扩展到代表性不足的语言，挑战了强大多语言能力需要大模型或多语言基线的假设

Abstract: The democratization of AI is currently hindered by the immense computational costs required to train Large Language Models (LLMs) for low-resource languages. This paper presents Persian-Phi, a 3.8B parameter model that challenges the assumption that robust multilingual capabilities require massive model sizes or multilingual baselines. We demonstrate how Microsoft Phi-3 Mini -- originally a monolingual English model -- can be effectively adapted to Persian through a novel, resource-efficient curriculum learning pipeline. Our approach employs a unique "warm-up" stage using bilingual narratives (Tiny Stories) to align embeddings prior to heavy training, followed by continual pretraining and instruction tuning via Parameter-Efficient Fine-Tuning (PEFT). Despite its compact size, Persian-Phi achieves competitive results on Open Persian LLM Leaderboard in HuggingFace. Our findings provide a validated, scalable framework for extending the reach of state-of-the-art LLMs to underrepresented languages with minimal hardware resources. The Persian-Phi model is publicly available at https://huggingface.co/amirakhlaghiqqq/PersianPhi.

</details>


### [53] [Native Parallel Reasoner: Reasoning in Parallelism via Self-Distilled Reinforcement Learning](https://arxiv.org/abs/2512.07461)
*Tong Wu,Yang Liu,Jun Bai,Zixia Jia,Shuyi Zhang,Ziyong Lin,Yanting Wang,Song-Chun Zhu,Zilong Zheng*

Main category: cs.CL

TL;DR: NPR是一个无需教师指导的框架，让大语言模型自我进化出真正的并行推理能力，通过渐进式训练、并行感知策略优化和专用引擎，在多个基准测试中实现性能提升24.5%和推理加速4.6倍。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型推理通常是顺序模拟，缺乏真正的并行认知能力。之前的方法往往退回到自回归解码，无法实现真正的并行执行。需要让LLMs从顺序模拟转变为原生并行认知。

Method: 1. 自蒸馏渐进训练范式：从"冷启动"格式发现过渡到严格拓扑约束；2. 并行感知策略优化算法：在执行图中直接优化分支策略，通过试错学习自适应分解；3. 稳健的NPR引擎：重构SGLang的内存管理和流控制，支持大规模并行强化学习训练。

Result: 在八个推理基准测试中，基于Qwen3-4B训练的NPR实现性能提升最高达24.5%，推理加速最高达4.6倍。与之前基线不同，NPR展示了100%的真正并行执行，建立了自我进化、高效和可扩展的代理推理新标准。

Conclusion: NPR框架成功让大语言模型从顺序模拟转变为原生并行认知，实现了真正的并行推理能力，在性能和效率方面都取得了显著提升，为自我进化、高效和可扩展的代理推理设立了新标准。

Abstract: We introduce Native Parallel Reasoner (NPR), a teacher-free framework that enables Large Language Models (LLMs) to self-evolve genuine parallel reasoning capabilities. NPR transforms the model from sequential emulation to native parallel cognition through three key innovations: 1) a self-distilled progressive training paradigm that transitions from ``cold-start'' format discovery to strict topological constraints without external supervision; 2) a novel Parallel-Aware Policy Optimization (PAPO) algorithm that optimizes branching policies directly within the execution graph, allowing the model to learn adaptive decomposition via trial and error; and 3) a robust NPR Engine that refactors memory management and flow control of SGLang to enable stable, large-scale parallel RL training. Across eight reasoning benchmarks, NPR trained on Qwen3-4B achieves performance gains of up to 24.5% and inference speedups up to 4.6x. Unlike prior baselines that often fall back to autoregressive decoding, NPR demonstrates 100% genuine parallel execution, establishing a new standard for self-evolving, efficient, and scalable agentic reasoning.

</details>


### [54] [Enhancing Agentic RL with Progressive Reward Shaping and Value-based Sampling Policy Optimization](https://arxiv.org/abs/2512.07478)
*Zhuoran Zhuang,Ye Chen,Jianghao Su,Chao Luo,Luhui Liu,Xia Zeng*

Main category: cs.CL

TL;DR: 本文提出两种互补技术：渐进式奖励塑形（PRS）和基于价值采样的策略优化（VSPO），以解决工具集成推理中稀疏奖励和梯度退化问题，提升LLM代理在复杂推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 工具集成推理（TIR）使LLM能够通过外部工具解决复杂长程推理任务，但代理强化学习面临两个关键挑战：1）稀疏的二元验证信号对中间步骤指导有限且收敛慢；2）组相对策略优化（GRPO）中相同奖励导致梯度退化，降低样本效率和训练稳定性。

Method: 提出两种技术：1）渐进式奖励塑形（PRS）：课程式奖励设计，提供密集的阶段反馈，先鼓励模型掌握可解析的工具调用格式，再优化事实准确性和答案质量；2）基于价值采样的策略优化（VSPO）：增强的GRPO变体，用任务价值指标选择提示替换低价值样本，并应用价值平滑裁剪稳定梯度更新。

Result: 在多个短形式和长形式QA基准测试中，PRS始终优于传统二元奖励，VSPO相比PPO、GRPO、CISPO和纯SFT基线，实现了更好的稳定性、更快的收敛速度和更高的最终性能。两者结合使TIR代理在跨领域泛化能力更强。

Conclusion: PRS和VSPO有效解决了工具集成推理中的奖励稀疏性和梯度退化问题，显著提升了LLM代理在复杂推理任务中的性能、稳定性和泛化能力，为构建更强大的工具增强型AI代理提供了有效解决方案。

Abstract: Large Language Models (LLMs) empowered with Tool-Integrated Reasoning (TIR) can iteratively plan, call external tools, and integrate returned information to solve complex, long-horizon reasoning tasks. Agentic Reinforcement Learning (Agentic RL) optimizes such models over full tool-interaction trajectories, but two key challenges hinder effectiveness: (1) Sparse, non-instructive rewards, such as binary 0-1 verifiable signals, provide limited guidance for intermediate steps and slow convergence; (2) Gradient degradation in Group Relative Policy Optimization (GRPO), where identical rewards within a rollout group yield zero advantage, reducing sample efficiency and destabilizing training. To address these challenges, we propose two complementary techniques: Progressive Reward Shaping (PRS) and Value-based Sampling Policy Optimization (VSPO). PRS is a curriculum-inspired reward design that introduces dense, stage-wise feedback - encouraging models to first master parseable and properly formatted tool calls, then optimize for factual correctness and answer quality. We instantiate PRS for short-form QA (with a length-aware BLEU to fairly score concise answers) and long-form QA (with LLM-as-a-Judge scoring to prevent reward hacking). VSPO is an enhanced GRPO variant that replaces low-value samples with prompts selected by a task-value metric balancing difficulty and uncertainty, and applies value-smoothing clipping to stabilize gradient updates. Experiments on multiple short-form and long-form QA benchmarks show that PRS consistently outperforms traditional binary rewards, and VSPO achieves superior stability, faster convergence, and higher final performance compared to PPO, GRPO, CISPO, and SFT-only baselines. Together, PRS and VSPO yield LLM-based TIR agents that generalize better across domains.

</details>


### [55] [SPAD: Seven-Source Token Probability Attribution with Syntactic Aggregation for Detecting Hallucinations in RAG](https://arxiv.org/abs/2512.07515)
*Pengqian Lu,Jie Lu,Anjin Liu,Guangquan Zhang*

Main category: cs.CL

TL;DR: SPAD提出了一种新的RAG幻觉检测方法，通过数学分解将token生成概率归因于七个来源，然后按词性聚合分析异常模式来检测幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有方法将幻觉归因于内部知识（FFNs）和检索上下文之间的二元冲突，这种视角不完整，忽略了用户查询、已生成token、当前token本身和最终LayerNorm调整等其他生成过程组件的影响。

Method: 1. 数学上将每个token的生成概率归因于七个不同来源：查询、RAG、过去token、当前token、FFN、最终LayerNorm和初始嵌入；2. 按词性标签聚合这些分数，量化不同组件如何驱动特定语言类别；3. 通过识别异常模式（如名词依赖最终LayerNorm）来检测幻觉。

Result: 大量实验表明SPAD实现了最先进的性能。

Conclusion: SPAD通过更全面的生成过程组件分析和基于词性的异常检测，有效解决了RAG中的幻觉检测问题。

Abstract: Detecting hallucinations in Retrieval-Augmented Generation (RAG) remains a challenge. Prior approaches attribute hallucinations to a binary conflict between internal knowledge (stored in FFNs) and retrieved context. However, this perspective is incomplete, failing to account for the impact of other components in the generative process, such as the user query, previously generated tokens, the current token itself, and the final LayerNorm adjustment. To address this, we introduce SPAD. First, we mathematically attribute each token's probability into seven distinct sources: Query, RAG, Past, Current Token, FFN, Final LayerNorm, and Initial Embedding. This attribution quantifies how each source contributes to the generation of the current token. Then, we aggregate these scores by POS tags to quantify how different components drive specific linguistic categories. By identifying anomalies, such as Nouns relying on Final LayerNorm, SPAD effectively detects hallucinations. Extensive experiments demonstrate that SPAD achieves state-of-the-art performance

</details>


### [56] [LIME: Making LLM Data More Efficient with Linguistic Metadata Embeddings](https://arxiv.org/abs/2512.07522)
*Sebastian Sztwiertnia,Felix Friedrich,Kristian Kersting,Patrick Schramowski,Björn Deiseroth*

Main category: cs.CL

TL;DR: LIME (Linguistic Metadata Embeddings) 是一种在预训练中利用元数据增强token嵌入的方法，显著提升训练效率、语言建模能力和生成任务性能，其变体LIME+1还能指导token生成，大幅提升推理和算术能力。


<details>
  <summary>Details</summary>
Motivation: 当前预训练仅解码器语言模型依赖大量高质量数据，但这类数据日益稀缺。虽然元数据常用于创建和整理数据集，但其作为直接训练信号的潜力尚未充分探索。本文旨在挑战现状，探索元数据在预训练中的直接应用价值。

Method: 提出LIME方法，通过捕获语法、语义和上下文属性的元数据来丰富token嵌入。该方法仅增加0.01%的参数，计算开销可忽略。还开发了变体LIME+1，使用偏移元数据来指导下一个token的生成。

Result: LIME显著提升预训练效率：对训练数据分布的适应速度提升高达56%。在500M到2B参数规模的模型上，均能改善tokenization，增强语言建模能力和生成任务性能。LIME+1变体在给定下一个token的元数据时，推理性能提升高达38%，算术准确率提升高达35%。

Conclusion: 元数据不仅是数据整理的辅助工具，更是强大的直接训练信号。LIME方法通过有效利用元数据，在提升预训练效率的同时，显著增强了语言模型的核心能力，为数据受限环境下的模型训练提供了新思路。

Abstract: Pre-training decoder-only language models relies on vast amounts of high-quality data, yet the availability of such data is increasingly reaching its limits. While metadata is commonly used to create and curate these datasets, its potential as a direct training signal remains under-explored. We challenge this status quo and propose LIME (Linguistic Metadata Embeddings), a method that enriches token embeddings with metadata capturing syntax, semantics, and contextual properties. LIME substantially improves pre-training efficiency. Specifically, it adapts up to 56% faster to the training data distribution, while introducing only 0.01% additional parameters at negligible compute overhead. Beyond efficiency, LIME improves tokenization, leading to remarkably stronger language modeling capabilities and generative task performance. These benefits persist across model scales (500M to 2B). In addition, we develop a variant with shifted metadata, LIME+1, that can guide token generation. Given prior metadata for the next token, LIME+1 improves reasoning performance by up to 38% and arithmetic accuracy by up to 35%.

</details>


### [57] [Beyond Real: Imaginary Extension of Rotary Position Embeddings for Long-Context LLMs](https://arxiv.org/abs/2512.07525)
*Xiaoran Liu,Yuerong Song,Zhigeng Liu,Zengfeng Huang,Qipeng Guo,Zhaoxiang Liu,Shiguo Lian,Ziwei He,Xipeng Qiu*

Main category: cs.CL

TL;DR: 该论文提出了一种改进的RoPE方法，通过重新引入被丢弃的虚部来利用完整的复数表示，从而增强长上下文依赖建模能力。


<details>
  <summary>Details</summary>
Motivation: 标准RoPE实现仅使用复数点积的实部计算注意力分数，丢弃了包含重要相位信息的虚部，这可能导致长上下文依赖建模中关系细节的损失。

Method: 提出扩展方法，重新引入被丢弃的虚部，利用完整的复数表示创建双分量注意力分数，保留更多位置信息。

Result: 在长上下文语言建模基准测试中，该方法相比标准RoPE持续提升性能，且随着上下文长度增加，优势更加显著。

Conclusion: 通过利用完整的复数表示，该方法能更好地建模长上下文依赖，提升语言模型性能，特别是在长序列处理方面。

Abstract: Rotary Position Embeddings (RoPE) have become a standard for encoding sequence order in Large Language Models (LLMs) by applying rotations to query and key vectors in the complex plane. Standard implementations, however, utilize only the real component of the complex-valued dot product for attention score calculation. This simplification discards the imaginary component, which contains valuable phase information, leading to a potential loss of relational details crucial for modeling long-context dependencies. In this paper, we propose an extension that re-incorporates this discarded imaginary component. Our method leverages the full complex-valued representation to create a dual-component attention score. We theoretically and empirically demonstrate that this approach enhances the modeling of long-context dependencies by preserving more positional information. Furthermore, evaluations on a suite of long-context language modeling benchmarks show that our method consistently improves performance over the standard RoPE, with the benefits becoming more significant as context length increases. The code is available at https://github.com/OpenMOSS/rope_pp.

</details>


### [58] [SwissGov-RSD: A Human-annotated, Cross-lingual Benchmark for Token-level Recognition of Semantic Differences Between Related Documents](https://arxiv.org/abs/2512.07538)
*Michelle Wastl,Jannis Vamvas,Rico Sennrich*

Main category: cs.CL

TL;DR: 本文介绍了SwissGov-RSD数据集，这是首个用于跨语言文档级语义差异识别的自然数据集，包含224个多语言平行文档，并评估了多种LLM和编码器模型在该任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 跨语言文档级语义差异识别对于文本生成评估和多语言内容对齐至关重要，但作为独立任务尚未得到足够关注，缺乏合适的自然数据集。

Method: 构建了SwissGov-RSD数据集，包含224个英语-德语、英语-法语、英语-意大利语的多平行文档，带有token级人工标注的语义差异。评估了开源和闭源大语言模型以及编码器模型在不同微调设置下的表现。

Result: 当前自动方法在该任务上表现不佳，与单语言、句子级和合成基准测试相比存在显著差距，LLM和编码器模型都面临挑战。

Conclusion: 跨语言文档级语义差异识别是一个具有挑战性的任务，现有模型表现不足，需要进一步研究。公开了代码和数据集以促进该领域发展。

Abstract: Recognizing semantic differences across documents, especially in different languages, is crucial for text generation evaluation and multilingual content alignment. However, as a standalone task it has received little attention. We address this by introducing SwissGov-RSD, the first naturalistic, document-level, cross-lingual dataset for semantic difference recognition. It encompasses a total of 224 multi-parallel documents in English-German, English-French, and English-Italian with token-level difference annotations by human annotators. We evaluate a variety of open-source and closed source large language models as well as encoder models across different fine-tuning settings on this new benchmark. Our results show that current automatic approaches perform poorly compared to their performance on monolingual, sentence-level, and synthetic benchmarks, revealing a considerable gap for both LLMs and encoder models. We make our code and datasets publicly available.

</details>


### [59] [Minimum Bayes Risk Decoding for Error Span Detection in Reference-Free Automatic Machine Translation Evaluation](https://arxiv.org/abs/2512.07540)
*Boxuan Lyu,Haiyue Song,Hidetaka Kamigaito,Chenchen Ding,Hideki Tanaka,Masao Utiyama,Kotaro Funakoshi,Manabu Okumura*

Main category: cs.CL

TL;DR: 该论文提出在生成式错误跨度检测（ESD）任务中使用最小贝叶斯风险（MBR）解码替代传统的最大后验概率（MAP）解码，以解决模型概率估计与人工标注相似度不匹配的问题，并通过MBR蒸馏降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有生成式ESD方法通常使用MAP解码，假设模型估计的概率与人工标注的相似度完美相关。但作者观察到，与人工标注不相似的注释可能获得比人工标注更高的模型似然度，这表明MAP解码存在局限性。

Method: 1. 将MBR解码应用于生成式ESD模型，使用句子级和跨度级相似度指标作为效用函数来选择候选假设；2. 提出MBR蒸馏方法，通过知识蒸馏使标准贪婪模型匹配MBR解码性能，解决推理时的计算延迟瓶颈。

Result: 实验结果表明：1. MBR解码在系统级、句子级和跨度级均优于MAP基线；2. MBR蒸馏能够使标准贪婪模型达到与MBR解码相当的性能，同时消除推理时的延迟瓶颈。

Conclusion: MBR解码能够有效解决生成式ESD模型中概率估计与人工标注相似度不匹配的问题，显著提升性能。通过MBR蒸馏可以平衡性能与效率，为实际应用提供了可行的解决方案。

Abstract: Error Span Detection (ESD) is a subtask of automatic machine translation evaluation that localizes error spans in translations and labels their severity. State-of-the-art generative ESD methods typically decode using Maximum a Posteriori (MAP), assuming that model-estimated probabilities are perfectly correlated with similarity to human annotation. However, we observed that annotations dissimilar to the human annotation could achieve a higher model likelihood than the human annotation. We address this issue by applying Minimum Bayes Risk (MBR) decoding to generative ESD models. Specifically, we employ sentence- and span-level similarity metrics as utility functions to select candidate hypotheses based on their approximate similarity to the human annotation. Extensive experimental results show that our MBR decoding outperforms the MAP baseline at the system, sentence, and span-levels. Furthermore, to mitigate the computational cost of MBR decoding, we demonstrate that applying MBR distillation enables a standard greedy model to match MBR decoding performance, effectively eliminating the inference-time latency bottleneck.

</details>


### [60] [Most over-representation of phonological features in basic vocabulary disappears when controlling for spatial and phylogenetic effects](https://arxiv.org/abs/2512.07543)
*Frederic Blum*

Main category: cs.CL

TL;DR: 重新检验基本词汇中音位特征统计过表征的普遍性，发现大多数先前观察到的模式在控制语言谱系和地理依赖后不再稳健，仅少数模式保持稳定。


<details>
  <summary>Details</summary>
Motivation: 先前关于基本词汇中音位特征过表征的研究可能存在样本偏差、模型问题，且未充分控制语言间的谱系和地理依赖关系，导致结果稳健性存疑。

Method: 使用Lexibank的2864种语言数据，修改原始模型，添加空间和系统发育依赖关系的统计控制，重新检验先前研究的音位象征模式。

Result: 大多数先前观察到的音位象征模式在添加谱系和地理控制后不再稳健，许多模式完全消失；仅少数模式在新样本中保持高度稳定。

Conclusion: 音位象征的普遍性主张需要更严格的稳健性检验；研究在更大规模上评估了音位象征的分布，强调了对语言普遍性主张进行多层次稳健性测试的必要性。

Abstract: The statistical over-representation of phonological features in the basic vocabulary of languages is often interpreted as reflecting potentially universal sound symbolic patterns. However, most of those results have not been tested explicitly for reproducibility and might be prone to biases in the study samples or models. Many studies on the topic do not adequately control for genealogical and areal dependencies between sampled languages, casting doubts on the robustness of the results. In this study, we test the robustness of a recent study on sound symbolism of basic vocabulary concepts which analyzed245 languages.The new sample includes data on 2864 languages from Lexibank. We modify the original model by adding statistical controls for spatial and phylogenetic dependencies between languages. The new results show that most of the previously observed patterns are not robust, and in fact many patterns disappear completely when adding the genealogical and areal controls. A small number of patterns, however, emerges as highly stable even with the new sample. Through the new analysis, we are able to assess the distribution of sound symbolism on a larger scale than previously. The study further highlights the need for testing all universal claims on language for robustness on various levels.

</details>


### [61] [MoCoRP: Modeling Consistent Relations between Persona and Response for Persona-based Dialogue](https://arxiv.org/abs/2512.07544)
*Kyungro Lee,Dongha Choi,Hyunju Lee*

Main category: cs.CL

TL;DR: MoCoRP提出了一种在基于角色的对话中显式建模角色句子与回复之间关系的方法，通过NLI专家提取逻辑关系，提升对话的一致性和质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于角色的对话数据集缺乏角色句子与回复之间的显式关系，导致模型难以有效捕捉角色信息，影响对话的一致性和质量。

Method: 提出MoCoRP框架，利用NLI专家显式提取角色句子与回复之间的NLI关系，使模型能有效结合上下文中的角色信息。该框架应用于BART等预训练模型，并通过对齐调优扩展到现代大语言模型。

Result: 在ConvAI2和MPChat公开数据集上，MoCoRP超越了现有基线，在角色一致性和上下文感知对话生成方面表现优异，不仅在定量指标上领先，在定性方面也有显著提升。

Conclusion: 显式建模角色-回复关系能有效提升基于角色的对话质量，MoCoRP框架为角色一致性对话生成提供了有效解决方案。

Abstract: As dialogue systems become increasingly important across various domains, a key challenge in persona-based dialogue is generating engaging and context-specific interactions while ensuring the model acts with a coherent personality. However, existing persona-based dialogue datasets lack explicit relations between persona sentences and responses, which makes it difficult for models to effectively capture persona information. To address these issues, we propose MoCoRP (Modeling Consistent Relations between Persona and Response), a framework that incorporates explicit relations into language models. MoCoRP leverages an NLI expert to explicitly extract the NLI relations between persona sentences and responses, enabling the model to effectively incorporate appropriate persona information from the context into its responses. We applied this framework to pre-trained models like BART and further extended it to modern large language models (LLMs) through alignment tuning. Experimental results on the public datasets ConvAI2 and MPChat demonstrate that MoCoRP outperforms existing baselines, achieving superior persona consistency and engaging, context-aware dialogue generation. Furthermore, our model not only excels in quantitative metrics but also shows significant improvements in qualitative aspects. These results highlight the effectiveness of explicitly modeling persona-response relations in persona-based dialogue. The source codes of MoCoRP are available at https://github.com/DMCB-GIST/MoCoRP.

</details>


### [62] [Performance of the SafeTerm AI-Based MedDRA Query System Against Standardised MedDRA Queries](https://arxiv.org/abs/2512.07552)
*Francois Vandenhende,Anna Georgiou,Michalis Georgiou,Theodoros Psaras,Ellie Karekla,Elena Hadjicosta*

Main category: cs.CL

TL;DR: SafeTerm AMQ系统使用AI自动从MedDRA术语库中检索相关不良事件术语，通过多标准统计方法对术语进行相关性评分和排名，在SMQs验证中表现出良好的召回率和精确度平衡。


<details>
  <summary>Details</summary>
Motivation: 在药物安全审查中，将相关不良事件术语分组到SMQs或OCMQs对信号检测至关重要。需要自动化工具来高效生成MedDRA查询，以辅助药物安全评估。

Method: SafeTerm AMQ是一个定量AI系统，将医学术语和MedDRA PTs嵌入多维向量空间，应用余弦相似度和极值聚类生成排名列表。通过多相似度阈值验证，计算精确率、召回率和F1分数。

Result: 在110个SMQs验证中，中等相似度阈值下召回率达到94%，高阈值下精确率可达89%。最优阈值0.70时总体召回率48%、精确率45%。自动阈值选择(0.66)优先召回率(0.58)而非精确率(0.29)。

Conclusion: SafeTerm AMQ在SMQs和OCMQs上表现相当且令人满意，是自动生成MedDRA查询的可行补充方法，能平衡召回率和精确率。建议使用合适的MedDRA PT术语并应用自动阈值方法来优化召回率。

Abstract: In pre-market drug safety review, grouping related adverse event terms into SMQs or OCMQs is critical for signal detection. We assess the performance of SafeTerm Automated Medical Query (AMQ) on MedDRA SMQs. The AMQ is a novel quantitative artificial intelligence system that understands and processes medical terminology and automatically retrieves relevant MedDRA Preferred Terms (PTs) for a given input query, ranking them by a relevance score (0-1) using multi-criteria statistical methods. The system (SafeTerm) embeds medical query terms and MedDRA PTs in a multidimensional vector space, then applies cosine similarity, and extreme-value clustering to generate a ranked list of PTs. Validation was conducted against tier-1 SMQs (110 queries, v28.1). Precision, recall and F1 were computed at multiple similarity-thresholds, defined either manually or using an automated method. High recall (94%)) is achieved at moderate similarity thresholds, indicative of good retrieval sensitivity. Higher thresholds filter out more terms, resulting in improved precision (up to 89%). The optimal threshold (0.70)) yielded an overall recall of (48%) and precision of (45%) across all 110 queries. Restricting to narrow-term PTs achieved slightly better performance at an increased (+0.05) similarity threshold, confirming increased relatedness of narrow versus broad terms. The automatic threshold (0.66) selection prioritizes recall (0.58) to precision (0.29). SafeTerm AMQ achieves comparable, satisfactory performance on SMQs and sanitized OCMQs. It is therefore a viable supplementary method for automated MedDRA query generation, balancing recall and precision. We recommend using suitable MedDRA PT terminology in query formulation and applying the automated threshold method to optimise recall. Increasing similarity scores allows refined, narrow terms selection.

</details>


### [63] [A Simple Method to Enhance Pre-trained Language Models with Speech Tokens for Classification](https://arxiv.org/abs/2512.07571)
*Nicolas Calbucura,Valentin Barriere*

Main category: cs.CL

TL;DR: 提出一种简单方法，通过特征选择将语音信息融入文本预训练大语言模型，用于特定分类任务，在论辩谬误检测任务上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 传统多模态融合中，音频序列长度远大于文本序列，导致融合困难。现有语音分词器输出长序列大词汇表token，难以低成本集成到大语言模型中。

Method: 使用基于lasso的特征选择在多模态词袋表示上，保留最重要的音频token，通过自监督语言建模目标使语言模型适应这些token，然后在下游任务上微调。

Result: 相比单模态模型、更大的SpeechLM或学习表示的音频集成方法，性能均有提升。在两个论辩谬误检测与分类任务上达到SOTA，即使随机选择音频token也能增强单模态模型。

Conclusion: 提出了一种简单有效的语音-文本融合方法，通过特征选择和自监督适应，在音频被认为无效的任务中成功利用语音信息提升性能。

Abstract: This paper presents a simple method that allows to easily enhance textual pre-trained large language models with speech information, when fine-tuned for a specific classification task. A classical issue with the fusion of many embeddings from audio with text is the large length of the audio sequence compared to the text one. Our method benefits from an existing speech tokenizer trained for Audio Speech Recognition that output long sequences of tokens from a large vocabulary, making it difficult to integrate it at low cost in a large language model. By applying a simple lasso-based feature selection on multimodal Bag-of-Words representation, we retain only the most important audio tokens for the task, and adapt the language model to them with a self-supervised language modeling objective, before fine-tuning it on the downstream task. We show this helps to improve the performances compared to an unimodal model, to a bigger SpeechLM or to integrating audio via a learned representation. We show the effectiveness of our method on two recent Argumentative Fallacy Detection and Classification tasks where the use of audio was believed counterproductive, reaching state-of-the-art results. We also provide an in-depth analysis of the method, showing that even a random audio token selection helps enhancing the unimodal model. Our code is available [online](https://github.com/salocinc/EACL26SpeechTokFallacy/).

</details>


### [64] [Complementary Learning Approach for Text Classification using Large Language Models](https://arxiv.org/abs/2512.07583)
*Navid Asgari,Benjamin M. Cole*

Main category: cs.CL

TL;DR: 提出一种利用大语言模型进行成本效益分析的結構化方法，结合人类学者与机器的优势，通过思维链和少样本学习提示技术，将定性研究中的合作团队最佳实践扩展到人机团队的定量研究中。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型在研究中应用成本较高且存在固有弱点，需要一种既能发挥人类学者和机器各自优势，又能弥补各自不足的成本效益方法。特别是在定量研究中，如何有效整合人类推理能力和机器计算能力是一个重要挑战。

Method: 采用思维链和少样本学习提示技术，将定性研究中合作团队的最佳实践扩展到人机团队的定量研究。通过结构化方法让人类利用溯因推理和自然语言来审视机器和人类自身的工作，使用低成本技术管理LLM的固有弱点。

Result: 该方法成功应用于分析1990-2017年间1,934份制药联盟新闻稿中的人机评级差异，展示了如何有效利用低成本技术来管理LLM的弱点，并实现人机协作的定量分析。

Conclusion: 提出的结构化方法能够以成本效益的方式整合大语言模型，通过结合人类学者的推理能力和机器的计算能力，为定量研究中的人机协作提供了可行框架，并展示了如何通过低成本技术有效管理LLM的固有弱点。

Abstract: In this study, we propose a structured methodology that utilizes large language models (LLMs) in a cost-efficient and parsimonious manner, integrating the strengths of scholars and machines while offsetting their respective weaknesses. Our methodology, facilitated through a chain of thought and few-shot learning prompting from computer science, extends best practices for co-author teams in qualitative research to human-machine teams in quantitative research. This allows humans to utilize abductive reasoning and natural language to interrogate not just what the machine has done but also what the human has done. Our method highlights how scholars can manage inherent weaknesses OF LLMs using careful, low-cost techniques. We demonstrate how to use the methodology to interrogate human-machine rating discrepancies for a sample of 1,934 press releases announcing pharmaceutical alliances (1990-2017).

</details>


### [65] [Metric-Fair Prompting: Treating Similar Samples Similarly](https://arxiv.org/abs/2512.07608)
*Jing Wang,Jie Shen,Xing Niu,Tong Zhang,Jeremy Weiss*

Main category: cs.CL

TL;DR: 提出Metric-Fair Prompting框架，通过度量公平性约束指导LLM在医学选择题中做出决策，强调相似问题应获得相似处理，提升公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 在医学问答等高风险应用中，确保LLM决策的公平性至关重要。传统方法孤立处理每个问题，可能对相似问题产生不一致的决策。需要一种能促进个体公平性（相似实例相似处理）的框架，同时提升决策准确性。

Method: 1. 将每个(问题,选项)对视为二元实例（正确+1/错误-1）；2. 使用NLP嵌入计算问题相似度；3. 在相似问题的联合对中而非孤立地解决问题；4. 提示强制全局决策协议：提取决定性临床特征，将每个(问题,选项)映射到置信度分数f(x)，并施加Lipschitz式约束确保相似输入获得相似分数和一致输出。

Result: 在MedQA(US)基准测试中，Metric-Fair Prompting相比标准单项目提示方法提高了性能，表明公平引导、置信度导向的推理能够增强LLM在高风险临床选择题上的准确性。

Conclusion: Metric-Fair Prompting框架成功地将公平性约束融入LLM提示中，通过促进个体公平性和一致性决策，不仅提升了公平性，还提高了医学问答的准确性，为高风险应用中的LLM决策提供了有前景的方向。

Abstract: We introduce \emph{Metric-Fair Prompting}, a fairness-aware prompting framework that guides large language models (LLMs) to make decisions under metric-fairness constraints. In the application of multiple-choice medical question answering, each {(question, option)} pair is treated as a binary instance with label $+1$ (correct) or $-1$ (incorrect). To promote {individual fairness}~--~treating similar instances similarly~--~we compute question similarity using NLP embeddings and solve items in \emph{joint pairs of similar questions} rather than in isolation. The prompt enforces a global decision protocol: extract decisive clinical features, map each \((\text{question}, \text{option})\) to a score $f(x)$ that acts as confidence, and impose a Lipschitz-style constraint so that similar inputs receive similar scores and, hence, consistent outputs. Evaluated on the {MedQA (US)} benchmark, Metric-Fair Prompting is shown to improve performance over standard single-item prompting, demonstrating that fairness-guided, confidence-oriented reasoning can enhance LLM accuracy on high-stakes clinical multiple-choice questions.

</details>


### [66] [PCMind-2.1-Kaiyuan-2B Technical Report](https://arxiv.org/abs/2512.07612)
*Kairong Luo,Zhenbo Sun,Xinyu Shi,Shengqi Chen,Bowen Yu,Yunyi Chen,Chenyi Dang,Hengtao Tao,Hui Wang,Fangming Liu,Kaifeng Lyu,Wenguang Chen*

Main category: cs.CL

TL;DR: PCMind-2.1-Kaiyuan-2B是一个20亿参数的全开源模型，通过创新的数据基准测试、选择性重复训练和多领域课程训练策略，在资源受限条件下实现了高效训练，性能与最先进的开源模型相当。


<details>
  <summary>Details</summary>
Motivation: 解决开源社区与工业界在大型语言模型发展中的知识鸿沟问题。工业界依赖闭源的高质量数据和训练方法，而开源社区缺乏这些资源，导致模型性能差距。

Method: 1. 分位数数据基准测试方法：系统比较异构开源数据集，为数据混合策略提供见解；2. 战略选择性重复方案：在多阶段范式中有效利用稀疏高质量数据；3. 多领域课程训练策略：按质量排序样本；4. 高度优化的数据预处理流程和FP16稳定性的架构修改。

Result: Kaiyuan-2B在性能上与最先进的全开源模型竞争，展示了在资源受限预训练中的实用和可扩展解决方案。所有资产（模型权重、数据和代码）已以Apache 2.0许可证发布。

Conclusion: 该研究为资源受限环境下的高效语言模型训练提供了实用解决方案，通过创新的数据管理和训练策略，弥合了开源社区与工业界之间的知识差距，推动了开源AI的发展。

Abstract: The rapid advancement of Large Language Models (LLMs) has resulted in a significant knowledge gap between the open-source community and industry, primarily because the latter relies on closed-source, high-quality data and training recipes. To address this, we introduce PCMind-2.1-Kaiyuan-2B, a fully open-source 2-billion-parameter model focused on improving training efficiency and effectiveness under resource constraints. Our methodology includes three key innovations: a Quantile Data Benchmarking method for systematically comparing heterogeneous open-source datasets and providing insights on data mixing strategies; a Strategic Selective Repetition scheme within a multi-phase paradigm to effectively leverage sparse, high-quality data; and a Multi-Domain Curriculum Training policy that orders samples by quality. Supported by a highly optimized data preprocessing pipeline and architectural modifications for FP16 stability, Kaiyuan-2B achieves performance competitive with state-of-the-art fully open-source models, demonstrating practical and scalable solutions for resource-limited pretraining. We release all assets (including model weights, data, and code) under Apache 2.0 license at https://huggingface.co/thu-pacman/PCMind-2.1-Kaiyuan-2B.

</details>


### [67] [Bridging Code Graphs and Large Language Models for Better Code Understanding](https://arxiv.org/abs/2512.07666)
*Zeqi Chen,Zhaoyang Chu,Yi Gui,Feng Guo,Yao Wan,Chuan Shi*

Main category: cs.CL

TL;DR: CGBridge：一种通过外部可训练桥接模块将代码图信息注入LLM的即插即用方法，显著提升代码理解任务的性能


<details>
  <summary>Details</summary>
Motivation: LLM在代码智能任务中表现优异，但基于线性化token序列的方法限制了其对程序结构语义的理解。现有图增强提示方法受提示长度限制，而结构感知预训练方法需要特定架构修改，与大规模指令跟随LLM不兼容。

Method: 1) 在大规模270K代码图数据集上通过自监督学习预训练代码图编码器；2) 训练外部桥接模块，通过跨模态注意力机制对齐代码、图和文本的语义；3) 桥接模块生成结构感知提示，注入冻结的LLM，并对下游代码智能任务进行微调。

Result: 在代码摘要任务上，相比原始模型和图增强提示方法分别获得16.19%和9.12%的相对提升；在代码翻译任务上，执行准确率分别提升9.84%和38.87%。推理速度比LoRA调优模型快4倍以上。

Conclusion: CGBridge通过即插即用的桥接模块有效增强了LLM对代码结构语义的理解能力，在保持与现有LLM兼容性的同时，显著提升了代码智能任务的性能和效率。

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance in code intelligence tasks such as code generation, summarization, and translation. However, their reliance on linearized token sequences limits their ability to understand the structural semantics of programs. While prior studies have explored graphaugmented prompting and structure-aware pretraining, they either suffer from prompt length constraints or require task-specific architectural changes that are incompatible with large-scale instructionfollowing LLMs. To address these limitations, this paper proposes CGBridge, a novel plug-and-play method that enhances LLMs with Code Graph information through an external, trainable Bridge module. CGBridge first pre-trains a code graph encoder via selfsupervised learning on a large-scale dataset of 270K code graphs to learn structural code semantics. It then trains an external module to bridge the modality gap among code, graph, and text by aligning their semantics through cross-modal attention mechanisms. Finally, the bridge module generates structure-informed prompts, which are injected into a frozen LLM, and is fine-tuned for downstream code intelligence tasks. Experiments show that CGBridge achieves notable improvements over both the original model and the graphaugmented prompting method. Specifically, it yields a 16.19% and 9.12% relative gain in LLM-as-a-Judge on code summarization, and a 9.84% and 38.87% relative gain in Execution Accuracy on code translation. Moreover, CGBridge achieves over 4x faster inference than LoRA-tuned models, demonstrating both effectiveness and efficiency in structure-aware code understanding.

</details>


### [68] [When Large Language Models Do Not Work: Online Incivility Prediction through Graph Neural Networks](https://arxiv.org/abs/2512.07684)
*Zihan Chen,Lanyu Yu*

Main category: cs.CL

TL;DR: 提出基于图神经网络的在线不文明行为检测框架，通过文本相似性构建评论图，结合动态注意力机制，在维基百科社区中检测毒性、攻击性和人身攻击三类行为，性能优于12个大型语言模型且推理成本更低。


<details>
  <summary>Details</summary>
Motivation: 在线不文明行为已成为数字社区的普遍问题，给用户带来社会和心理负担。现有平台通过审核和自动检测来遏制不文明行为，但现有方法在准确性和效率方面仍有局限。

Method: 提出图神经网络框架，将用户评论表示为节点，基于文本相似性构建边，使网络能够同时学习语言内容和评论间的关系结构。引入动态调整的注意力机制，在信息聚合过程中自适应平衡节点特征和拓扑特征。

Result: 实证评估表明，该架构在多个指标上优于12个最先进的大型语言模型，同时需要显著更低的推理成本。在英语维基百科社区中成功检测了毒性、攻击性和人身攻击三类不文明行为。

Conclusion: 研究强调了结构上下文在检测在线不文明行为中的关键作用，解决了纯文本LLM范式在行为预测中的局限性。所有数据集和比较结果将公开以支持进一步研究和可重复性。

Abstract: Online incivility has emerged as a widespread and persistent problem in digital communities, imposing substantial social and psychological burdens on users. Although many platforms attempt to curb incivility through moderation and automated detection, the performance of existing approaches often remains limited in both accuracy and efficiency. To address this challenge, we propose a Graph Neural Network (GNN) framework for detecting three types of uncivil behavior (i.e., toxicity, aggression, and personal attacks) within the English Wikipedia community. Our model represents each user comment as a node, with textual similarity between comments defining the edges, allowing the network to jointly learn from both linguistic content and relational structures among comments. We also introduce a dynamically adjusted attention mechanism that adaptively balances nodal and topological features during information aggregation. Empirical evaluations demonstrate that our proposed architecture outperforms 12 state-of-the-art Large Language Models (LLMs) across multiple metrics while requiring significantly lower inference cost. These findings highlight the crucial role of structural context in detecting online incivility and address the limitations of text-only LLM paradigms in behavioral prediction. All datasets and comparative outputs will be publicly available in our repository to support further research and reproducibility.

</details>


### [69] [HalluShift++: Bridging Language and Vision through Internal Representation Shifts for Hierarchical Hallucinations in MLLMs](https://arxiv.org/abs/2512.07687)
*Sujoy Nath,Arkaprabha Basu,Sharanya Dasgupta,Swagatam Das*

Main category: cs.CL

TL;DR: 本文提出HalluShift++方法，通过分析多模态大语言模型内部层动态中的可测量异常来检测幻觉，无需依赖外部LLM评估器。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉语言理解任务中表现出色，但经常产生与视觉内容事实不一致的幻觉描述，可能导致严重后果。现有方法依赖外部LLM评估器，但这些评估器本身也存在幻觉问题且难以适应不同领域。

Method: 提出HalluShift++方法，基于假设：幻觉表现为MLLM内部层动态中的可测量异常，而不仅仅是分布偏移。通过层间分析特定假设，将基于文本的LLM幻觉检测扩展到多模态场景。

Result: HalluShift++扩展了幻觉检测的有效性，从基于文本的LLM扩展到多模态场景。代码已在GitHub开源。

Conclusion: 通过分析MLLM内部层动态中的异常，可以更有效地检测多模态场景中的幻觉，减少对外部LLM评估器的依赖，提高检测的准确性和适应性。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities in vision-language understanding tasks. While these models often produce linguistically coherent output, they often suffer from hallucinations, generating descriptions that are factually inconsistent with the visual content, potentially leading to adverse consequences. Therefore, the assessment of hallucinations in MLLM has become increasingly crucial in the model development process. Contemporary methodologies predominantly depend on external LLM evaluators, which are themselves susceptible to hallucinations and may present challenges in terms of domain adaptation. In this study, we propose the hypothesis that hallucination manifests as measurable irregularities within the internal layer dynamics of MLLMs, not merely due to distributional shifts but also in the context of layer-wise analysis of specific assumptions. By incorporating such modifications, \textsc{\textsc{HalluShift++}} broadens the efficacy of hallucination detection from text-based large language models (LLMs) to encompass multimodal scenarios. Our codebase is available at https://github.com/C0mRD/HalluShift_Plus.

</details>


### [70] [Automated Generation of Custom MedDRA Queries Using SafeTerm Medical Map](https://arxiv.org/abs/2512.07694)
*Francois Vandenhende,Anna Georgiou,Michalis Georgiou,Theodoros Psaras,Ellie Karekla,Elena Hadjicosta*

Main category: cs.CL

TL;DR: SafeTerm是一个AI驱动的系统，通过将医学术语和MedDRA术语嵌入向量空间，使用余弦相似度和极值聚类自动检索和排名相关的不良事件术语，为药物安全审查提供自动化MedDRA查询生成方法。


<details>
  <summary>Details</summary>
Motivation: 在药物上市前安全审查中，将相关不良事件术语分组到标准化MedDRA查询或FDA OCMQs中对于信号检测至关重要。传统方法需要大量人工工作，需要自动化解决方案来提高效率和准确性。

Method: SafeTerm系统将医学查询术语和MedDRA首选术语嵌入到多维向量空间中，然后应用余弦相似度和极值聚类来生成按相关性分数排名的术语列表。系统使用多标准统计方法对术语进行排名。

Result: 在FDA OCMQ v3.0（104个查询）上验证，限制在有效MedDRA PTs范围内。在中等阈值下实现高召回率（>95%），更高阈值可提高精确度（最高86%）。最佳阈值（~0.70-0.75）产生约50%的召回率和约33%的精确度。窄术语子集表现类似但需要稍高的相似度阈值。

Conclusion: SafeTerm AI驱动系统为自动化MedDRA查询生成提供了可行的补充方法。建议初始使用约0.60的相似度阈值，对于精炼术语选择可增加阈值。

Abstract: In pre-market drug safety review, grouping related adverse event terms into standardised MedDRA queries or the FDA Office of New Drugs Custom Medical Queries (OCMQs) is critical for signal detection. We present a novel quantitative artificial intelligence system that understands and processes medical terminology and automatically retrieves relevant MedDRA Preferred Terms (PTs) for a given input query, ranking them by a relevance score using multi-criteria statistical methods. The system (SafeTerm) embeds medical query terms and MedDRA PTs in a multidimensional vector space, then applies cosine similarity and extreme-value clustering to generate a ranked list of PTs. Validation was conducted against the FDA OCMQ v3.0 (104 queries), restricted to valid MedDRA PTs. Precision, recall and F1 were computed across similarity-thresholds. High recall (>95%) is achieved at moderate thresholds. Higher thresholds improve precision (up to 86%). The optimal threshold (~0.70 - 0.75) yielded recall ~50% and precision ~33%. Narrow-term PT subsets performed similarly but required slightly higher similarity thresholds. The SafeTerm AI-driven system provides a viable supplementary method for automated MedDRA query generation. A similarity threshold of ~0.60 is recommended initially, with increased thresholds for refined term selection.

</details>


### [71] [Mary, the Cheeseburger-Eating Vegetarian: Do LLMs Recognize Incoherence in Narratives?](https://arxiv.org/abs/2512.07777)
*Karin de Langis,Püren Öncel,Ryan Peters,Andrew Elfenbein,Laura Kristen Allen,Andreas Schramm,Dongyeop Kang*

Main category: cs.CL

TL;DR: LLMs能检测叙事不连贯性，但无法可靠区分连贯与不连贯故事，尤其在角色特质冲突方面表现更差，显示其对叙事连贯性理解不完整。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）是否能可靠区分连贯与不连贯的叙事，探索LLMs对故事连贯性的理解能力及其局限性。

Method: 使用配对叙事数据集，通过探测研究分析LLMs的内部表征，测试不同提示变体下的回答生成，比较不同类型不连贯（场景违反vs角色特质违反）的检测能力。

Result: LLMs内部表征能可靠识别不连贯叙事，但生成的回答无法满意地区分连贯与不连贯故事；对场景违反的不连贯更敏感，对角色特质违反的不连贯检测较差；思维链推理无法消除这些缺陷。

Conclusion: LLMs对叙事连贯性的理解不完整，更依赖原型世界知识而非基于意义的叙事连贯性构建，存在内部状态与行为之间的差距。

Abstract: Leveraging a dataset of paired narratives, we investigate the extent to which large language models (LLMs) can reliably separate incoherent and coherent stories. A probing study finds that LLMs' internal representations can reliably identify incoherent narratives. However, LLMs generate responses to rating questions that fail to satisfactorily separate the coherent and incoherent narratives across several prompt variations, hinting at a gap in LLM's understanding of storytelling. The reasoning LLMs tested do not eliminate these deficits, indicating that thought strings may not be able to fully address the discrepancy between model internal state and behavior. Additionally, we find that LLMs appear to be more sensitive to incoherence resulting from an event that violates the setting (e.g., a rainy day in the desert) than to incoherence arising from a character violating an established trait (e.g., Mary, a vegetarian, later orders a cheeseburger), suggesting that LLMs may rely more on prototypical world knowledge than building meaning-based narrative coherence. The consistent asymmetry found in our results suggests that LLMs do not have a complete grasp on narrative coherence.

</details>


### [72] [On the Interplay of Pre-Training, Mid-Training, and RL on Reasoning Language Models](https://arxiv.org/abs/2512.07783)
*Charlie Zhang,Graham Neubig,Xiang Yue*

Main category: cs.CL

TL;DR: 该研究通过完全受控的实验框架，揭示了预训练、中期训练和RL后训练在语言模型推理能力发展中的因果贡献，发现RL仅在预训练留有足够空间且针对模型能力边界时产生真正能力提升。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习技术虽然提升了语言模型的推理能力，但无法确定这种提升是真正扩展了模型的推理能力，还是仅仅利用了预训练中已有的知识。主要挑战在于现代训练流程缺乏控制：大规模预训练语料不透明，中期训练常被忽视，RL目标与未知的先验知识以复杂方式交互。

Method: 开发了一个完全受控的实验框架，使用合成推理任务（具有明确的原子操作、可解析的逐步推理痕迹），并系统性地操纵训练分布。从两个维度评估模型：1) 对更复杂组合的外推泛化；2) 跨表面上下文的语境泛化。

Result: 1) RL仅在预训练留有足够空间且针对模型能力边界（困难但尚未超出能力范围的任务）时产生真正能力提升；2) 语境泛化需要最小但足够的预训练暴露，之后RL可以可靠地迁移；3) 中期训练在固定计算下比仅用RL显著提升性能；4) 过程级奖励减少奖励黑客行为并提高推理保真度。

Conclusion: 该研究阐明了预训练、中期训练和RL之间的相互作用，为理解和改进推理语言模型训练策略提供了基础。中期训练在训练流程中扮演核心但被低估的角色，而RL的有效性取决于预训练留下的空间和针对模型能力边界的任务设计。

Abstract: Recent reinforcement learning (RL) techniques have yielded impressive reasoning improvements in language models, yet it remains unclear whether post-training truly extends a model's reasoning ability beyond what it acquires during pre-training. A central challenge is the lack of control in modern training pipelines: large-scale pre-training corpora are opaque, mid-training is often underexamined, and RL objectives interact with unknown prior knowledge in complex ways. To resolve this ambiguity, we develop a fully controlled experimental framework that isolates the causal contributions of pre-training, mid-training, and RL-based post-training. Our approach employs synthetic reasoning tasks with explicit atomic operations, parseable step-by-step reasoning traces, and systematic manipulation of training distributions. We evaluate models along two axes: extrapolative generalization to more complex compositions and contextual generalization across surface contexts. Using this framework, we reconcile competing views on RL's effectiveness. We show that: 1) RL produces true capability gains (pass@128) only when pre-training leaves sufficient headroom and when RL data target the model's edge of competence, tasks at the boundary that are difficult but not yet out of reach. 2) Contextual generalization requires minimal yet sufficient pre-training exposure, after which RL can reliably transfer. 3) Mid-training significantly enhances performance under fixed compute compared with RL only, demonstrating its central but underexplored role in training pipelines. 4) Process-level rewards reduce reward hacking and improve reasoning fidelity. Together, these results clarify the interplay between pre-training, mid-training, and RL, offering a foundation for understanding and improving reasoning LM training strategies.

</details>


### [73] [Collaborative Causal Sensemaking: Closing the Complementarity Gap in Human-AI Decision Support](https://arxiv.org/abs/2512.07801)
*Raunak Jain,Mudita Khurana*

Main category: cs.CL

TL;DR: 论文提出"协作因果意义建构"(CCS)作为决策支持智能体的新框架，强调AI应作为认知工作伙伴而非工具，通过共同构建心理模型、目标和因果假设来提升人机协作效果。


<details>
  <summary>Details</summary>
Motivation: 当前LLM智能体在复杂高风险决策环境中未能实现预期的人机互补效果，专家在验证循环和过度依赖之间摇摆，人机团队表现常低于最佳个体。问题根源在于现有AI辅助范式忽视了专家决策本质上是协作认知过程。

Method: 提出协作因果意义建构(CCS)研究议程和组织框架：设计作为认知伙伴的系统，维护专家推理模型，协助阐述和修订目标，共同构建和压力测试因果假设，从联合决策结果中学习以实现人机共同改进。

Result: 论文提出了CCS框架的概念基础，包括：1) 使协作思考具有工具价值的训练生态；2) 共同构建模型的表示和交互协议；3) 以信任和互补性为中心的评价方法。

Conclusion: CCS框架能够重塑多智能体系统研究，开发参与协作意义建构的智能体，使其成为与人类伙伴共同思考的AI队友，实现真正的人机互补。

Abstract: LLM-based agents are rapidly being plugged into expert decision-support, yet in messy, high-stakes settings they rarely make the team smarter: human-AI teams often underperform the best individual, experts oscillate between verification loops and over-reliance, and the promised complementarity does not materialise. We argue this is not just a matter of accuracy, but a fundamental gap in how we conceive AI assistance: expert decisions are made through collaborative cognitive processes where mental models, goals, and constraints are continually co-constructed, tested, and revised between human and AI. We propose Collaborative Causal Sensemaking (CCS) as a research agenda and organizing framework for decision-support agents: systems designed as partners in cognitive work, maintaining evolving models of how particular experts reason, helping articulate and revise goals, co-constructing and stress-testing causal hypotheses, and learning from the outcomes of joint decisions so that both human and agent improve over time. We sketch challenges around training ecologies that make collaborative thinking instrumentally valuable, representations and interaction protocols for co-authored models, and evaluation centred on trust and complementarity. These directions can reframe MAS research around agents that participate in collaborative sensemaking and act as AI teammates that think with their human partners.

</details>


### [74] [Do Generalisation Results Generalise?](https://arxiv.org/abs/2512.07832)
*Matteo Boglioni,Andrea Sgobbi,Gabriel Tavernini,Francesco Rita,Marius Mosbach,Tiago Pimentel*

Main category: cs.CL

TL;DR: 研究评估LLM在多个OOD测试集上的泛化性能相关性，发现结果高度依赖于具体模型选择


<details>
  <summary>Details</summary>
Motivation: 现有评估LLM泛化能力的工作通常只关注单个OOD数据集，但实际部署中遇到的数据偏移更加多样，需要更全面的评估方法

Method: 在微调过程中评估模型在多个OOD测试集上的性能，计算这些测试集性能之间的偏相关系数（控制域内性能），分析泛化性能的相关性

Result: 分析OLMo2和OPT模型发现，不同OOD测试集之间的相关性没有统一趋势，正相关或负相关高度依赖于具体分析的模型

Conclusion: LLM的OOD泛化结果不能简单推广，评估泛化能力需要考虑多个OOD测试集，并且结果对模型选择敏感

Abstract: A large language model's (LLM's) out-of-distribution (OOD) generalisation ability is crucial to its deployment. Previous work assessing LLMs' generalisation performance, however, typically focuses on a single out-of-distribution dataset. This approach may fail to precisely evaluate the capabilities of the model, as the data shifts encountered once a model is deployed are much more diverse. In this work, we investigate whether OOD generalisation results generalise. More specifically, we evaluate a model's performance across multiple OOD testsets throughout a finetuning run; we then evaluate the partial correlation of performances across these testsets, regressing out in-domain performance. This allows us to assess how correlated are generalisation performances once in-domain performance is controlled for. Analysing OLMo2 and OPT, we observe no overarching trend in generalisation results: the existence of a positive or negative correlation between any two OOD testsets depends strongly on the specific choice of model analysed.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [75] [Video Models Start to Solve Chess, Maze, Sudoku, Mental Rotation, and Raven' Matrices](https://arxiv.org/abs/2512.05969)
*Hokin Deng*

Main category: cs.CV

TL;DR: 视频生成模型现在具备推理能力，在象棋、迷宫、数独等任务上达到60%成功率，建立了"任务对"实验范式，开发了支持39个模型的评估框架。


<details>
  <summary>Details</summary>
Motivation: 探索视频生成模型是否具备推理能力，建立可扩展的评估范式来系统测试模型在各种推理任务上的表现。

Method: 采用"任务对"实验设计，构建VMEvalKit代码框架支持39个模型，实现自动化评估并与人工判断高度相关。

Result: Sora-2等领先模型在象棋、迷宫、数独、心理旋转、瑞文矩阵等推理任务上达到约60%的成功率。

Conclusion: 视频生成模型已具备初步推理能力，建立的评估范式为后续强化学习改进视频模型推理提供了基础。

Abstract: We show that video generation models could reason now. Testing on tasks such as chess, maze, Sudoku, mental rotation, and Raven's Matrices, leading models such as Sora-2 achieve sixty percent success rates. We establish a robust experimental paradigm centered on the "Task Pair" design. We build a code framework, with 39 models available already, that supports this paradigm and allows for easy scaling - users can add models and tasks efficiently. We show our automated evaluation strongly correlates with human judgment, and therefore this paradigm is highly scalable. We see an opportunity, given the availability of our paradigm, to do reinforcement learning for improving reasoning in video models. You could checkout all of our raw $\href{https://grow-ai-like-a-child.com/video-reason/}{results}$ and our $\href{https://github.com/hokindeng/VMEvalKit}{VMEvalKit}$ codebase.

</details>


### [76] [Adaptive Dataset Quantization: A New Direction for Dataset Pruning](https://arxiv.org/abs/2512.05987)
*Chenyue Yu,Jianyu Yu*

Main category: cs.CV

TL;DR: 提出一种新颖的数据集量化方法，通过减少样本内冗余来压缩大规模数据集，在保持模型训练性能的同时显著降低存储和通信成本。


<details>
  <summary>Details</summary>
Motivation: 资源受限的边缘设备在处理大规模数据集时面临存储和通信成本挑战，传统的数据集剪枝和蒸馏方法主要关注样本间冗余，而忽略了样本内冗余的压缩潜力。

Method: 采用线性对称量化获取初始量化范围和尺度，然后引入自适应量化分配算法，为不同精度需求的样本分配不同的量化比率，同时保持总体压缩比恒定。

Result: 在CIFAR-10、CIFAR-100和ImageNet-1K数据集上的实验表明，该方法在相同压缩比下优于传统量化和数据集剪枝基线，能保持模型训练性能的同时实现显著的数据集压缩。

Conclusion: 该研究首次提出使用有限比特表示数据集以减少存储，引入数据集级量化算法并验证了其有效性，为边缘设备上的大规模数据处理提供了高效解决方案。

Abstract: This paper addresses the challenges of storage and communication costs for large-scale datasets in resource-constrained edge devices by proposing a novel dataset quantization approach to reduce intra-sample redundancy. Unlike traditional dataset pruning and distillation methods that focus on inter-sample redundancy, the proposed method compresses each image by reducing redundant or less informative content within samples while preserving essential features. It first applies linear symmetric quantization to obtain an initial quantization range and scale for each sample. Then, an adaptive quantization allocation algorithm is introduced to distribute different quantization ratios for samples with varying precision requirements, maintaining a constant total compression ratio. The main contributions include: (1) being the first to use limited bits to represent datasets for storage reduction; (2) introducing a dataset-level quantization algorithm with adaptive ratio allocation; and (3) validating the method's effectiveness through extensive experiments on CIFAR-10, CIFAR-100, and ImageNet-1K. Results show that the method maintains model training performance while achieving significant dataset compression, outperforming traditional quantization and dataset pruning baselines under the same compression ratios.

</details>


### [77] [VG3T: Visual Geometry Grounded Gaussian Transformer](https://arxiv.org/abs/2512.05988)
*Junho Kim,Seongwon Lee*

Main category: cs.CV

TL;DR: VG3T提出了一种新颖的多视角前馈网络，通过3D高斯表示预测3D语义占据，解决了现有方法多视角融合困难导致3D表示碎片化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多视角融合方面存在困难，导致3D表示碎片化和性能不佳。需要一种能够从多视角图像直接生成连贯3D场景表示的方法。

Method: VG3T采用多视角前馈网络，直接预测一组具有语义属性的3D高斯表示。引入两个关键组件：基于网格的采样和位置细化，以缓解像素对齐高斯初始化方法中常见的距离依赖密度偏差。

Result: 在nuScenes基准测试中，VG3T在mIoU上实现了1.7%的显著提升，同时使用的基元数量比先前最先进方法减少了46%。

Conclusion: VG3T提供了一种统一的多视角3D场景表示范式，在效率和性能方面均优于现有方法，为3D语义场景理解提供了新的解决方案。

Abstract: Generating a coherent 3D scene representation from multi-view images is a fundamental yet challenging task. Existing methods often struggle with multi-view fusion, leading to fragmented 3D representations and sub-optimal performance. To address this, we introduce VG3T, a novel multi-view feed-forward network that predicts a 3D semantic occupancy via a 3D Gaussian representation. Unlike prior methods that infer Gaussians from single-view images, our model directly predicts a set of semantically attributed Gaussians in a joint, multi-view fashion. This novel approach overcomes the fragmentation and inconsistency inherent in view-by-view processing, offering a unified paradigm to represent both geometry and semantics. We also introduce two key components, Grid-Based Sampling and Positional Refinement, to mitigate the distance-dependent density bias common in pixel-aligned Gaussian initialization methods. Our VG3T shows a notable 1.7%p improvement in mIoU while using 46% fewer primitives than the previous state-of-the-art on the nuScenes benchmark, highlighting its superior efficiency and performance.

</details>


### [78] [EmoDiffTalk:Emotion-aware Diffusion for Editable 3D Gaussian Talking Head](https://arxiv.org/abs/2512.05991)
*Chang Liu,Tianjiao Jing,Chengcheng Ma,Xuanqi Zhou,Zhengxuan Lian,Qin Jin,Hongliang Yuan,Shi-Sheng Huang*

Main category: cs.CV

TL;DR: EmoDiffTalk：首个基于3D高斯泼溅的可编辑3D说话头框架，通过情感感知高斯扩散实现细粒度多模态情感编辑


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅的逼真3D说话头在情感表达操控方面存在明显不足，特别是在细粒度和扩展性动态情感编辑方面，缺乏有效的多模态控制方法。

Method: 提出情感感知高斯扩散方法，包括：1）动作单元提示的高斯扩散过程用于细粒度面部动画；2）准确的文本到动作单元情感控制器，通过文本输入提供精确且扩展的动态情感编辑。

Result: 在EmoTalk3D和RenderMe-360数据集上的实验表明，EmoDiffTalk在情感细微度、唇形同步保真度和可控性方面优于先前工作，建立了高质量、扩散驱动、多模态可编辑3D说话头合成的原则性路径。

Conclusion: EmoDiffTalk是首批支持在基于动作单元的表情空间中进行连续多模态情感编辑的3D高斯泼溅说话头生成框架之一，为高质量可编辑3D说话头合成开辟了新方向。

Abstract: Recent photo-realistic 3D talking head via 3D Gaussian Splatting still has significant shortcoming in emotional expression manipulation, especially for fine-grained and expansive dynamics emotional editing using multi-modal control. This paper introduces a new editable 3D Gaussian talking head, i.e. EmoDiffTalk. Our key idea is a novel Emotion-aware Gaussian Diffusion, which includes an action unit (AU) prompt Gaussian diffusion process for fine-grained facial animator, and moreover an accurate text-to-AU emotion controller to provide accurate and expansive dynamic emotional editing using text input. Experiments on public EmoTalk3D and RenderMe-360 datasets demonstrate superior emotional subtlety, lip-sync fidelity, and controllability of our EmoDiffTalk over previous works, establishing a principled pathway toward high-quality, diffusion-driven, multimodal editable 3D talking-head synthesis. To our best knowledge, our EmoDiffTalk is one of the first few 3D Gaussian Splatting talking-head generation framework, especially supporting continuous, multimodal emotional editing within the AU-based expression space.

</details>


### [79] [Domain-Specific Foundation Model Improves AI-Based Analysis of Neuropathology](https://arxiv.org/abs/2512.05993)
*Ruchika Verma,Shrishtee Kandoi,Robina Afzal,Shengjia Chen,Jannes Jegminat,Michael W. Karlovich,Melissa Umphlett,Timothy E. Richardson,Kevin Clare,Quazi Hossain,Jorge Samanamud,Phyllis L. Faust,Elan D. Louis,Ann C. McKee,Thor D. Stein,Jonathan D. Cherry,Jesse Mez,Anya C. McGoldrick,Dalilah D. Quintana Mora,Melissa J. Nirenberg,Ruth H. Walker,Yolfrankcis Mendez,Susan Morgello,Dennis W. Dickson,Melissa E. Murray,Carlos Cordon-Cardo,Nadejda M. Tsankova,Jamie M. Walker,Diana K. Dangoor,Stephanie McQuillan,Emma L. Thorn,Claudia De Sanctis,Shuying Li,Thomas J. Fuchs,Kurt Farrell,John F. Crary,Gabriele Campanella*

Main category: cs.CV

TL;DR: 开发了专门针对神经病理学的领域专用基础模型NeuroFM，相比通用病理学模型在神经退行性疾病分析任务上表现更优


<details>
  <summary>Details</summary>
Motivation: 现有病理学基础模型主要基于外科病理数据训练，这些数据富含非神经组织，过度代表非神经系统疾病。神经病理学具有独特的细胞类型、细胞结构和疾病特征，领域不匹配可能限制通用模型捕捉神经退行性疾病关键形态特征的能力。

Method: 开发了NeuroFM，专门在涵盖多种神经退行性病理的脑组织全切片图像上进行训练，创建了针对神经病理学领域的专用基础模型。

Result: NeuroFM在多个神经病理学特定下游任务上表现出优于通用模型的性能，包括混合性痴呆疾病分类、海马区域分割以及神经退行性共济失调识别（涵盖小脑性特发性震颤和脊髓小脑性共济失调亚型）。

Conclusion: 领域专用基础模型在脑组织上训练能比通用外科病理数据集训练的模型更好地捕捉神经病理学特定特征。通过针对神经退行性疾病的独特形态特征定制基础模型，NeuroFM能够为脑疾病诊断和研究提供更准确可靠的AI分析，为数字病理学专业领域的领域特定模型开发树立了先例。

Abstract: Foundation models have transformed computational pathology by providing generalizable representations from large-scale histology datasets. However, existing models are predominantly trained on surgical pathology data, which is enriched for non-nervous tissue and overrepresents neoplastic, inflammatory, metabolic, and other non-neurological diseases. Neuropathology represents a markedly different domain of histopathology, characterized by unique cell types (neurons, glia, etc.), distinct cytoarchitecture, and disease-specific pathological features including neurofibrillary tangles, amyloid plaques, Lewy bodies, and pattern-specific neurodegeneration. This domain mismatch may limit the ability of general-purpose foundation models to capture the morphological patterns critical for interpreting neurodegenerative diseases such as Alzheimer's disease, Parkinson's disease, and cerebellar ataxias. To address this gap, we developed NeuroFM, a foundation model trained specifically on whole-slide images of brain tissue spanning diverse neurodegenerative pathologies. NeuroFM demonstrates superior performance compared to general-purpose models across multiple neuropathology-specific downstream tasks, including mixed dementia disease classification, hippocampal region segmentation, and neurodegenerative ataxia identification encompassing cerebellar essential tremor and spinocerebellar ataxia subtypes. This work establishes that domain-specialized foundation models trained on brain tissue can better capture neuropathology-specific features than models trained on general surgical pathology datasets. By tailoring foundation models to the unique morphological landscape of neurodegenerative diseases, NeuroFM enables more accurate and reliable AI-based analysis for brain disease diagnosis and research, setting a precedent for domain-specific model development in specialized areas of digital pathology.

</details>


### [80] [FishDetector-R1: Unified MLLM-Based Framework with Reinforcement Fine-Tuning for Weakly Supervised Fish Detection, Segmentation, and Counting](https://arxiv.org/abs/2512.05996)
*Yi Liu,Jingyu Song,Vedanth Kallakuri,Katherine A. Skinner*

Main category: cs.CV

TL;DR: FishDetector-R1是一个基于多模态大语言模型的弱监督框架，用于水下鱼类检测、分割和计数，在DeepFish数据集上显著提升了性能指标。


<details>
  <summary>Details</summary>
Motivation: 水下鱼类图像分析对生态监测至关重要，但由于视觉质量下降和标注成本高昂而面临挑战。需要开发能够在弱监督下准确进行鱼类检测、分割和计数的可靠解决方案。

Method: 提出统一的MLLM框架，包含两个关键组件：1）新颖的detect-to-count提示机制，确保空间一致的检测和计数；2）基于可验证奖励的强化学习（RLVR），利用稀疏点标签的可扩展范式。

Result: 在DeepFish数据集上，AP提升20%，mIoU提升10%，MAE降低30%，GAME降低35%。消融研究验证了奖励设计的有效性，且改进能很好地泛化到其他水下数据集，显示出强大的跨域鲁棒性。

Conclusion: FishDetector-R1通过弱监督为准确的海洋视觉理解提供了可靠且可扩展的解决方案，项目页面已公开。

Abstract: Analyzing underwater fish imagery is critical for ecological monitoring but remains difficult due to visual degradation and costly annotations. We introduce FishDetector-R1, a unified MLLM-based framework for fish detection, segmentation, and counting under weak supervision. On the DeepFish dataset, our framework achieves substantial gains over baselines, improving AP by 20% and mIoU by 10%, while reducing MAE by 30% and GAME by 35%. These improvements stem from two key components: a novel detect-to-count prompt that enforces spatially consistent detections and counts, and Reinforcement Learning from Verifiable Reward (RLVR) with a complementary scalable paradigm leveraging sparse point labels. Ablation studies further validate the effectiveness of this reward design. Moreover, the improvement generalizes well to other underwater datasets, confirming strong cross-domain robustness. Overall, FishDetector-R1 provides a reliable and scalable solution for accurate marine visual understanding via weak supervision. The project page for FishDetector-R1 is https://umfieldrobotics.github.io/FishDetector-R1.

</details>


### [81] [PrunedCaps: A Case For Primary Capsules Discrimination](https://arxiv.org/abs/2512.06003)
*Ramin Sharifi,Pouya Shiri,Amirali Baniasadi*

Main category: cs.CV

TL;DR: 该论文研究了胶囊网络（CapsNets）中初级胶囊的剪枝方法，通过移除95%的胶囊实现了9.9倍的加速，同时保持准确率不变，显著减少了计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 胶囊网络相比传统卷积神经网络具有更好的仿射变换鲁棒性和重叠图像检测能力，但其初级胶囊数量过多导致训练和推理速度慢、资源消耗大，需要提高资源效率。

Method: 在MNIST、Fashion-MNIST、CIFAR-10和SVHN数据集上对胶囊网络进行初级胶囊剪枝，通过移除大量胶囊来优化网络结构。

Result: 剪枝后的胶囊网络性能提升显著：速度提升达9.9倍，动态路由阶段浮点运算减少超过95.36%，且准确率没有损失。同时分析了不同数据集对剪枝效果的差异原因。

Conclusion: 初级胶囊剪枝是提高胶囊网络资源效率的有效方法，能大幅加速推理过程并减少计算开销，同时保持模型性能，为胶囊网络的实用化提供了重要改进方向。

Abstract: Capsule Networks (CapsNets) are a generation of image classifiers with proven advantages over Convolutional Neural Networks (CNNs). Better robustness to affine transformation and overlapping image detection are some of the benefits associated with CapsNets. However, CapsNets cannot be classified as resource-efficient deep learning architecture due to the high number of Primary Capsules (PCs). In addition, CapsNets' training and testing are slow and resource hungry. This paper investigates the possibility of Primary Capsules pruning in CapsNets on MNIST handwritten digits, Fashion-MNIST, CIFAR-10, and SVHN datasets. We show that a pruned version of CapsNet performs up to 9.90 times faster than the conventional architecture by removing 95 percent of Capsules without a loss of accuracy. Also, our pruned architecture saves on more than 95.36 percent of floating-point operations in the dynamic routing stage of the architecture. Moreover, we provide insight into why some datasets benefit significantly from pruning while others fall behind.

</details>


### [82] [Simple Agents Outperform Experts in Biomedical Imaging Workflow Optimization](https://arxiv.org/abs/2512.06006)
*Xuefei,Wang,Kai A. Horstmann,Ethan Lin,Jonathan Chen,Alexander R. Farhang,Sophia Stiles,Atharva Sehgal,Jonathan Light,David Van Valen,Yisong Yue,Jennifer J. Sun*

Main category: cs.CV

TL;DR: AI代理能自动优化科学计算机视觉工具的适配代码，超越人工专家方案，但复杂代理架构并非总是更好


<details>
  <summary>Details</summary>
Motivation: 将生产级计算机视觉工具适配到特定科学数据集存在"最后一公里"瓶颈：微调需要大量标注数据（科学家通常缺乏），而手动代码适配需要科学家花费数周至数月时间

Method: 引入系统化的代理代码优化评估框架，研究三个生产级生物医学成像流程，比较不同代理设计的效果

Result: 简单代理框架生成的适配代码始终优于人类专家解决方案；分析发现常见复杂代理架构并非普遍有益

Conclusion: 提出了实用的代理设计路线图，开源了评估框架，并通过将代理生成的函数部署到生产流程中验证了方法的实际影响路径

Abstract: Adapting production-level computer vision tools to bespoke scientific datasets is a critical "last mile" bottleneck. Current solutions are impractical: fine-tuning requires large annotated datasets scientists often lack, while manual code adaptation costs scientists weeks to months of effort. We consider using AI agents to automate this manual coding, and focus on the open question of optimal agent design for this targeted task. We introduce a systematic evaluation framework for agentic code optimization and use it to study three production-level biomedical imaging pipelines. We demonstrate that a simple agent framework consistently generates adaptation code that outperforms human-expert solutions. Our analysis reveals that common, complex agent architectures are not universally beneficial, leading to a practical roadmap for agent design. We open source our framework and validate our approach by deploying agent-generated functions into a production pipeline, demonstrating a clear pathway for real-world impact.

</details>


### [83] [Fast and Flexible Robustness Certificates for Semantic Segmentation](https://arxiv.org/abs/2512.06010)
*Thomas Massena,Corentin Friedrich,Franck Mamalet,Mathieu Serrurier*

Main category: cs.CV

TL;DR: 提出一种新的可证明鲁棒的语义分割网络，通过Lipschitz约束实现高效训练和实时认证，比随机平滑方法快600倍


<details>
  <summary>Details</summary>
Motivation: 深度神经网络对微小扰动敏感，现有鲁棒性研究主要集中在分类任务，语义分割的高效认证方法较少，需要实时兼容的鲁棒语义分割方案

Method: 引入内置Lipschitz约束的可证明鲁棒语义分割网络，提出通用化语义分割鲁棒性认证框架，利用Lipschitz网络实现灵活高效的计算

Result: 在Cityscapes等挑战性数据集上达到有竞争力的像素精度，认证过程比随机平滑方法快600倍，首次实现实时兼容的可证明鲁棒语义分割

Conclusion: 该方法为语义分割任务提供了高效、灵活的鲁棒性认证框架，实现了实时兼容的可证明鲁棒语义分割，并在计算效率和证书质量上显著优于现有方法

Abstract: Deep Neural Networks are vulnerable to small perturbations that can drastically alter their predictions for perceptually unchanged inputs. The literature on adversarially robust Deep Learning attempts to either enhance the robustness of neural networks (e.g, via adversarial training) or to certify their decisions up to a given robustness level (e.g, by using randomized smoothing, formal methods or Lipschitz bounds). These studies mostly focus on classification tasks and few efficient certification procedures currently exist for semantic segmentation. In this work, we introduce a new class of certifiably robust Semantic Segmentation networks with built-in Lipschitz constraints that are efficiently trainable and achieve competitive pixel accuracy on challenging datasets such as Cityscapes. Additionally, we provide a novel framework that generalizes robustness certificates for semantic segmentation tasks, where we showcase the flexibility and computational efficiency of using Lipschitz networks. Our approach unlocks real-time compatible certifiably robust semantic segmentation for the first time. Moreover, it allows the computation of worst-case performance under $\ell_2$ attacks of radius $ε$ across a wide range of performance measures. Crucially, we benchmark the runtime of our certification process and find our approach to be around 600 times faster than randomized smoothing methods at inference with comparable certificates on an NVIDIA A100 GPU. Finally, we evaluate the tightness of our worstcase certificates against state-of-the-art adversarial attacks to further validate the performance of our method.

</details>


### [84] [High-Throughput Unsupervised Profiling of the Morphology of 316L Powder Particles for Use in Additive Manufacturing](https://arxiv.org/abs/2512.06012)
*Emmanuel Akeweje,Conall Kirk,Chi-Wai Chan,Denis Dowling,Mimi Zhang*

Main category: cs.CV

TL;DR: 开发基于机器学习的自动化框架，通过高通量成像和聚类分析大规模表征金属粉末形态，为SLM工艺提供实时原料监控


<details>
  <summary>Details</summary>
Motivation: 传统粉末表征方法效率低且定性，无法捕捉工业规模批次的异质性，而SLM零件质量高度依赖原料形态

Method: 提出自动化机器学习框架，结合高通量成像、形状提取和聚类分析；开发并评估三种聚类流程：自编码器流程、形状描述符流程和函数数据流程

Result: 在约126,000个粉末图像数据集上，傅里叶描述符+k-means流程表现最佳，具有最低的Davies-Bouldin指数和最高的Calinski-Harabasz分数，同时在标准工作站上保持亚毫秒级处理速度

Conclusion: 该无监督学习框架实现了粉末形态的快速自动化评估，支持跟踪重复使用周期中的形状演变，为SLM工作流程中的实时原料监控提供了途径

Abstract: Selective Laser Melting (SLM) is a powder-bed additive manufacturing technique whose part quality depends critically on feedstock morphology. However, conventional powder characterization methods are low-throughput and qualitative, failing to capture the heterogeneity of industrial-scale batches. We present an automated, machine learning framework that couples high-throughput imaging with shape extraction and clustering to profile metallic powder morphology at scale. We develop and evaluate three clustering pipelines: an autoencoder pipeline, a shape-descriptor pipeline, and a functional-data pipeline. Across a dataset of approximately 126,000 powder images (0.5-102 micrometer diameter), internal validity metrics identify the Fourier-descriptor + k-means pipeline as the most effective, achieving the lowest Davies-Bouldin index and highest Calinski-Harabasz score while maintaining sub-millisecond runtime per particle on a standard desktop workstation. Although the present work focuses on establishing the morphological-clustering framework, the resulting shape groups form a basis for future studies examining their relationship to flowability, packing density, and SLM part quality. Overall, this unsupervised learning framework enables rapid, automated assessment of powder morphology and supports tracking of shape evolution across reuse cycles, offering a path toward real-time feedstock monitoring in SLM workflows.

</details>


### [85] [VAT: Vision Action Transformer by Unlocking Full Representation of ViT](https://arxiv.org/abs/2512.06013)
*Wenhao Li,Chengwei Ma,Weixin Mao*

Main category: cs.CV

TL;DR: VAT是一种基于ViT的新型架构，通过利用ViT所有层的特征层次结构，实现感知与动作生成的深度渐进融合，在机器人模仿学习中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前机器人学习中，Vision Transformers通常只使用最后一层的特征，丢弃了有价值的信息，导致表示不足。需要充分利用ViT的完整特征层次结构来提升机器人策略性能。

Method: 提出Vision Action Transformer (VAT)，扩展自ViT架构，通过在所有transformer层中处理专门的动作token与视觉特征，实现感知与动作生成的深度渐进融合。

Result: 在模拟操作任务套件中，VAT在四个LIBERO基准测试上达到98.15%的平均成功率，超越了OpenVLA-OFT等先前方法，建立了新的SOTA。

Conclusion: VAT不仅是一个强大的模仿学习模型，更重要的是证明了利用视觉模型的完整"表示轨迹"对于推进机器人策略至关重要。

Abstract: In robot learning, Vision Transformers (ViTs) are standard for visual perception, yet most methods discard valuable information by using only the final layer's features. We argue this provides an insufficient representation and propose the Vision Action Transformer (VAT), a novel architecture that is extended from ViT and unlocks the full feature hierarchy of ViT. VAT processes specialized action tokens with visual features across all transformer layers, enabling a deep and progressive fusion of perception and action generation. On a suite of simulated manipulation tasks, VAT achieves a 98.15\% average success rate across four LIBERO benchmarks, establishing a new state-of-the-art by outperforming prior methods like OpenVLA-OFT. Our work presents not only a powerful model for imitation learning but also demonstrates the critical importance of leveraging the complete ''representation trajectory'' of vision models to advance robotic policy. The GitHub URL for the project code is https://github.com/sellerbubble/VAT.

</details>


### [86] [Benchmarking CXR Foundation Models With Publicly Available MIMIC-CXR and NIH-CXR14 Datasets](https://arxiv.org/abs/2512.06014)
*Jiho Shin,Dominic Marshall,Matthieu Komorowski*

Main category: cs.CV

TL;DR: 该研究对两种大规模胸部X光嵌入模型（CXR-Foundation和MedImageInsight）在公开数据集上进行标准化基准测试，发现MedImageInsight性能略优，而CXR-Foundation具有更好的跨数据集稳定性。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在医学图像表示学习方面表现出色，但它们在跨数据集上的比较行为尚未得到充分探索。本研究旨在通过标准化评估来比较两种胸部X光嵌入模型的性能。

Method: 使用统一的预处理流程和固定下游分类器，在MIMIC-CR和NIH ChestX-ray14数据集上评估两种模型。直接从预训练编码器提取嵌入，训练轻量级LightGBM分类器处理多种疾病标签，报告平均AUROC和F1分数（含95%置信区间）。

Result: MedImageInsight在大多数任务中表现略优，而CXR-Foundation展现出更强的跨数据集稳定性。MedImageInsight嵌入的无监督聚类显示出与定量结果一致的疾病特异性结构。

Conclusion: 研究强调了医学基础模型标准化评估的必要性，为未来多模态和临床整合研究建立了可复现的基线。

Abstract: Recent foundation models have demonstrated strong performance in medical image representation learning, yet their comparative behaviour across datasets remains underexplored. This work benchmarks two large-scale chest X-ray (CXR) embedding models (CXR-Foundation (ELIXR v2.0) and MedImagelnsight) on public MIMIC-CR and NIH ChestX-ray14 datasets. Each model was evaluated using a unified preprocessing pipeline and fixed downstream classifiers to ensure reproducible comparison. We extracted embeddings directly from pre-trained encoders, trained lightweight LightGBM classifiers on multiple disease labels, and reported mean AUROC, and F1-score with 95% confidence intervals. MedImageInsight achieved slightly higher performance across most tasks, while CXR-Foundation exhibited strong cross-dataset stability. Unsupervised clustering of MedImageIn-sight embeddings further revealed a coherent disease-specific structure consistent with quantitative results. The results highlight the need for standardised evaluation of medical foundation models and establish reproducible baselines for future multimodal and clinical integration studies.

</details>


### [87] [PrefGen: Multimodal Preference Learning for Preference-Conditioned Image Generation](https://arxiv.org/abs/2512.06020)
*Wenyi Mo,Tianyu Zhang,Yalong Bai,Ligong Han,Ying Ba,Dimitris N. Metaxas*

Main category: cs.CV

TL;DR: 提出基于多模态大语言模型的个性化图像生成框架，通过提取用户偏好表示并注入扩散模型，实现既符合文本提示又满足个人审美偏好的图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么无法捕捉细微的用户偏好，要么缺乏有效的个性化视觉信号编码机制。需要一种能够同时理解文本提示和用户个人审美偏好的图像生成方法。

Method: 1) 使用多模态大语言模型通过偏好导向的视觉问答任务提取丰富的用户表示；2) 引入两种互补的探测任务：用户间区分（区分不同用户）和用户内区分（区分喜欢与不喜欢的内容）；3) 设计基于最大均值差异的对齐损失，弥合模态差距同时保持多模态结构；4) 将得到的嵌入用于条件化生成器。

Result: 大量实验表明，该方法在图像质量和偏好对齐方面显著优于强基线，证明了表示提取和对齐在个性化生成中的有效性。

Conclusion: 提出的多模态框架通过有效提取和编码用户偏好表示，并将其与扩散模型对齐，实现了高质量的个性化图像生成，在保持文本提示一致性的同时更好地满足用户审美偏好。

Abstract: Preference-conditioned image generation seeks to adapt generative models to individual users, producing outputs that reflect personal aesthetic choices beyond the given textual prompt. Despite recent progress, existing approaches either fail to capture nuanced user preferences or lack effective mechanisms to encode personalized visual signals. In this work, we propose a multimodal framework that leverages multimodal large language models (MLLMs) to extract rich user representations and inject them into diffusion-based image generation. We train the MLLM with a preference-oriented visual question answering task to capture fine-grained semantic cues. To isolate preference-relevant features, we introduce two complementary probing tasks: inter-user discrimination to distinguish between different users, and intra-user discrimination to separate liked from disliked content. To ensure compatibility with diffusion text encoders, we design a maximum mean discrepancy-based alignment loss that bridges the modality gap while preserving multimodal structure. The resulting embeddings are used to condition the generator, enabling faithful adherence to both prompts and user preferences. Extensive experiments demonstrate that our method substantially outperforms strong baselines in both image quality and preference alignment, highlighting the effectiveness of representation extraction and alignment for personalized generation.

</details>


### [88] [Neural reconstruction of 3D ocean wave hydrodynamics from camera sensing](https://arxiv.org/abs/2512.06024)
*Jiabin Liu,Zihao Zhou,Jialei Yan,Anxin Guo,Alvise Benetazzo,Hui Li*

Main category: cs.CV

TL;DR: 提出一种基于注意力增强金字塔架构的波浪自由表面视觉重建神经网络，用于从立体视觉数据中高效、精确地重建三维波浪表面和速度场，在遮挡条件下仍能保持良好泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决长期海洋波浪观测任务中密集视觉重建的高计算成本问题，以及持续视觉遮挡带来的挑战，实现对波浪自由表面和三维速度场的精确重建。

Method: 设计注意力增强的金字塔架构神经网络，适应波浪运动的多尺度和时间连续特性；利用基于物理的约束，从演化的自由表面边界进行时间分辨的三维速度场重建。

Result: 在真实海况实验中实现：中心区域毫米级波浪高程预测、主导频率误差低于0.01Hz、高频谱功率律精确估计、非线性速度场高保真三维重建，仅需1.35秒即可重建两百万个点。

Conclusion: 该模型基于立体视觉数据集，优于传统视觉重建方法，凭借其全局多尺度注意力和波浪传播动力学的学习编码，在遮挡条件下保持强泛化能力。

Abstract: Precise three-dimensional (3D) reconstruction of wave free surfaces and associated velocity fields is essential for developing a comprehensive understanding of ocean physics. To address the high computational cost of dense visual reconstruction in long-term ocean wave observation tasks and the challenges introduced by persistent visual occlusions, we propose an wave free surface visual reconstruction neural network, which is designed as an attention-augmented pyramid architecture tailored to the multi-scale and temporally continuous characteristics of wave motions. Using physics-based constraints, we perform time-resolved reconstruction of nonlinear 3D velocity fields from the evolving free-surface boundary. Experiments under real-sea conditions demonstrate millimetre-level wave elevation prediction in the central region, dominant-frequency errors below 0.01 Hz, precise estimation of high-frequency spectral power laws, and high-fidelity 3D reconstruction of nonlinear velocity fields, while enabling dense reconstruction of two million points in only 1.35 s. Built on a stereo-vision dataset, the model outperforms conventional visual reconstruction approaches and maintains strong generalization in occluded conditions, owing to its global multi-scale attention and its learned encoding of wave propagation dynamics.

</details>


### [89] [The SAM2-to-SAM3 Gap in the Segment Anything Model Family: Why Prompt-Based Expertise Fails in Concept-Driven Image Segmentation](https://arxiv.org/abs/2512.06032)
*Ranjan Sapkota,Konstantinos I. Roumeliotis,Manoj Karkee*

Main category: cs.CV

TL;DR: SAM2和SAM3之间存在根本性断裂：SAM2是基于空间提示的纯视觉-时序分割模型，而SAM3是统一的多模态概念驱动架构，具备开放词汇推理、语义接地和示例概念理解能力。


<details>
  <summary>Details</summary>
Motivation: 分析SAM2和SAM3之间的根本性差异，解释为什么SAM2的提示式分割专业知识无法迁移到SAM3的多模态概念驱动范式，阐明SAM3作为新一代分割基础模型的创新性。

Method: 通过五个核心组件进行结构化分析：1) 概念断裂：对比基于提示与基于概念的分割；2) 架构差异：纯视觉-时序设计与多模态融合架构；3) 数据集差异：SA-V视频掩码与多模态概念标注语料库；4) 训练差异：优化知识不适用性；5) 评估差异：从几何IoU到语义开放词汇评估。

Result: SAM3代表了分割基础模型的新类别，从SAM2的几何-时序分割范式转向概念驱动的多模态分割时代，具备开放词汇推理、语义接地、对比对齐和示例概念理解能力。

Conclusion: SAM3标志着分割领域的范式转变，从基于空间提示的几何分割转向基于多模态概念理解的分割，为新兴的概念驱动分割时代指明了发展方向。

Abstract: This paper investigates the fundamental discontinuity between the latest two Segment Anything Models: SAM2 and SAM3. We explain why the expertise in prompt-based segmentation of SAM2 does not transfer to the multimodal concept-driven paradigm of SAM3. SAM2 operates through spatial prompts points, boxes, and masks yielding purely geometric and temporal segmentation. In contrast, SAM3 introduces a unified vision-language architecture capable of open-vocabulary reasoning, semantic grounding, contrastive alignment, and exemplar-based concept understanding. We structure this analysis through five core components: (1) a Conceptual Break Between Prompt-Based and Concept-Based Segmentation, contrasting spatial prompt semantics of SAM2 with multimodal fusion and text-conditioned mask generation of SAM3; (2) Architectural Divergence, detailing pure vision-temporal design of SAM2 versus integration of vision-language encoders, geometry and exemplar encoders, fusion modules, DETR-style decoders, object queries, and ambiguity-handling via Mixture-of-Experts in SAM3; (3) Dataset and Annotation Differences, contrasting SA-V video masks with multimodal concept-annotated corpora of SAM3; (4) Training and Hyperparameter Distinctions, showing why SAM2 optimization knowledge does not apply to SAM3; and (5) Evaluation, Metrics, and Failure Modes, outlining the transition from geometric IoU metrics to semantic, open-vocabulary evaluation. Together, these analyses establish SAM3 as a new class of segmentation foundation model and chart future directions for the emerging concept-driven segmentation era.

</details>


### [90] [Representation Learning for Point Cloud Understanding](https://arxiv.org/abs/2512.06058)
*Siming Yan*

Main category: cs.CV

TL;DR: 该论文提出了一种通过集成预训练2D模型来增强3D点云理解的方法，包括监督表示学习、自监督学习和2D到3D的迁移学习，显著提升了3D网络训练效果。


<details>
  <summary>Details</summary>
Motivation: 随着3D数据采集技术的快速发展，3D数据在计算机视觉、机器人等领域应用日益广泛。结合2D图像和3D数据可以为机器提供更全面的环境理解，但如何有效利用2D知识来增强3D理解仍是一个挑战。

Method: 论文聚焦三个主要方向：1）监督表示学习用于点云基元分割；2）自监督学习方法；3）从2D到3D的迁移学习。核心方法是集成预训练的2D模型来支持3D网络训练，而不是简单地将2D数据转换为3D。

Result: 大量实验验证了方法的有效性，展示了通过有效集成2D知识来推进点云表示学习的潜力，显著提升了3D理解能力。

Conclusion: 该研究提出了一种创新的方法，通过整合预训练2D模型来增强3D点云表示学习，为3D理解任务提供了有效的解决方案，具有推动该领域发展的潜力。

Abstract: With the rapid advancement of technology, 3D data acquisition and utilization have become increasingly prevalent across various fields, including computer vision, robotics, and geospatial analysis. 3D data, captured through methods such as 3D scanners, LiDARs, and RGB-D cameras, provides rich geometric, shape, and scale information. When combined with 2D images, 3D data offers machines a comprehensive understanding of their environment, benefiting applications like autonomous driving, robotics, remote sensing, and medical treatment. This dissertation focuses on three main areas: supervised representation learning for point cloud primitive segmentation, self-supervised learning methods, and transfer learning from 2D to 3D. Our approach, which integrates pre-trained 2D models to support 3D network training, significantly improves 3D understanding without merely transforming 2D data. Extensive experiments validate the effectiveness of our methods, showcasing their potential to advance point cloud representation learning by effectively integrating 2D knowledge.

</details>


### [91] [EgoEdit: Dataset, Real-Time Streaming Model, and Benchmark for Egocentric Video Editing](https://arxiv.org/abs/2512.06065)
*Runjia Li,Moayed Haji-Ali,Ashkan Mirzaei,Chaoyang Wang,Arpit Sahni,Ivan Skorokhodov,Aliaksandr Siarohin,Tomas Jakab,Junlin Han,Sergey Tulyakov,Philip Torr,Willi Menapace*

Main category: cs.CV

TL;DR: 提出了一个完整的自我中心视频编辑生态系统，包括专门的数据集EgoEditData、实时视频编辑器EgoEdit和评估套件EgoEditBench，解决了自我中心视频编辑中的独特挑战。


<details>
  <summary>Details</summary>
Motivation: 现有AI视频编辑器主要针对第三人称视频，而自我中心视角视频存在快速自我运动和频繁手物交互等独特挑战，造成显著的领域差距。此外，现有离线编辑流程延迟高，限制了实时交互。

Method: 1) 构建EgoEditData：专门为自我中心编辑场景设计的手动策划数据集，包含丰富的手物交互并明确保留手部信息；2) 开发EgoEdit：支持在单个GPU上进行实时流式推理的指令跟随自我中心视频编辑器；3) 引入EgoEditBench：针对指令忠实度、手部和交互保留、以及自我运动下时间稳定性的评估套件。

Result: EgoEdit在自我中心编辑基准测试中取得明显优势（现有方法在此类任务上表现不佳），同时在通用编辑任务上保持与最强基线相当的性能。系统能够产生时间稳定、指令忠实的结果，并具有交互式延迟。

Conclusion: 提出了一个完整的自我中心视频编辑生态系统，解决了该领域的独特挑战，实现了实时交互式编辑。EgoEditData和EgoEditBench将为研究社区公开，推动该领域发展。

Abstract: We study instruction-guided editing of egocentric videos for interactive AR applications. While recent AI video editors perform well on third-person footage, egocentric views present unique challenges - including rapid egomotion and frequent hand-object interactions - that create a significant domain gap. Moreover, existing offline editing pipelines suffer from high latency, limiting real-time interaction. To address these issues, we present a complete ecosystem for egocentric video editing. First, we construct EgoEditData, a carefully designed and manually curated dataset specifically designed for egocentric editing scenarios, featuring rich hand-object interactions, while explicitly preserving hands. Second, we develop EgoEdit, an instruction-following egocentric video editor that supports real-time streaming inference on a single GPU. Finally, we introduce EgoEditBench, an evaluation suite targeting instruction faithfulness, hand and interaction preservation, and temporal stability under egomotion. Across both egocentric and general editing tasks, EgoEdit produces temporally stable, instruction-faithful results with interactive latency. It achieves clear gains on egocentric editing benchmarks-where existing methods struggle-while maintaining performance comparable to the strongest baselines on general editing tasks. EgoEditData and EgoEditBench will be made public for the research community. See our website at https://snap-research.github.io/EgoEdit

</details>


### [92] [Shoot-Bounce-3D: Single-Shot Occlusion-Aware 3D from Lidar by Decomposing Two-Bounce Light](https://arxiv.org/abs/2512.06080)
*Tzofi Klinghoffer,Siddharth Somasundaram,Xiaoyu Xiang,Yuchen Fan,Christian Richardt,Akshat Dave,Ramesh Raskar,Rakesh Ranjan*

Main category: cs.CV

TL;DR: 利用单光子激光雷达通过数据驱动方法解决多路复用照明下的光传输反演问题，实现遮挡和镜面场景的单次测量3D重建


<details>
  <summary>Details</summary>
Motivation: 单次测量重建3D场景具有挑战性，特别是在存在遮挡区域和镜面材料（如镜子）的情况下。传统单光子激光雷达方法通常需要逐点顺序照明，而实际应用中需要同时照明多个场景点，这带来了复杂的光传输反演问题。

Method: 提出数据驱动方法反演单光子激光雷达中的光传输：1）创建首个大规模室内场景激光雷达瞬态数据集（约10万个样本）；2）学习复杂光传输先验，将测量的双反弹光分解为每个激光点的贡献；3）利用分解后的光推断遮挡和镜面场景的3D几何。

Result: 实验证明该方法能够从单次测量中推断出具有遮挡和镜子的场景的3D几何。创建的数据集和代码已公开。

Conclusion: 通过数据驱动方法成功解决了多路复用照明下单光子激光雷达的光传输反演问题，实现了对复杂场景（包括遮挡和镜面）的单次测量3D重建，为实际应用提供了可行方案。

Abstract: 3D scene reconstruction from a single measurement is challenging, especially in the presence of occluded regions and specular materials, such as mirrors. We address these challenges by leveraging single-photon lidars. These lidars estimate depth from light that is emitted into the scene and reflected directly back to the sensor. However, they can also measure light that bounces multiple times in the scene before reaching the sensor. This multi-bounce light contains additional information that can be used to recover dense depth, occluded geometry, and material properties. Prior work with single-photon lidar, however, has only demonstrated these use cases when a laser sequentially illuminates one scene point at a time. We instead focus on the more practical - and challenging - scenario of illuminating multiple scene points simultaneously. The complexity of light transport due to the combined effects of multiplexed illumination, two-bounce light, shadows, and specular reflections is challenging to invert analytically. Instead, we propose a data-driven method to invert light transport in single-photon lidar. To enable this approach, we create the first large-scale simulated dataset of ~100k lidar transients for indoor scenes. We use this dataset to learn a prior on complex light transport, enabling measured two-bounce light to be decomposed into the constituent contributions from each laser spot. Finally, we experimentally demonstrate how this decomposed light can be used to infer 3D geometry in scenes with occlusions and mirrors from a single measurement. Our code and dataset are released at https://shoot-bounce-3d.github.io.

</details>


### [93] [BeLLA: End-to-End Birds Eye View Large Language Assistant for Autonomous Driving](https://arxiv.org/abs/2512.06096)
*Karthik Mohan,Sonam Singh,Amit Arvind Kale*

Main category: cs.CV

TL;DR: BeLLA是一个端到端架构，将统一的360°BEV表示与大型语言模型连接，用于自动驾驶问答，在需要空间推理的任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在自动驾驶研究中存在局限性：单视角编码器无法利用多摄像头系统的空间结构，而聚合多视角特征缺乏统一的空间表示，难以进行自我中心方向、物体关系和上下文推理。

Method: 提出BeLLA端到端架构，连接统一的360°BEV（鸟瞰图）表示与大型语言模型，用于自动驾驶场景的问答任务。

Result: 在NuScenes-QA和DriveLM基准测试中，BeLLA在需要空间推理的问题（如相对物体定位和附近物体行为理解）上持续优于现有方法，某些任务获得高达+9.3%的绝对提升，在其他类别中也具有竞争力。

Conclusion: BeLLA通过结合统一BEV表示和语言模型，有效解决了自动驾驶中空间推理的挑战，能够处理多样化的问答任务，为自动驾驶研究提供了更强大的场景理解和推理能力。

Abstract: The rapid development of Vision-Language models (VLMs) and Multimodal Language Models (MLLMs) in autonomous driving research has significantly reshaped the landscape by enabling richer scene understanding, context-aware reasoning, and more interpretable decision-making. However, a lot of existing work often relies on either single-view encoders that fail to exploit the spatial structure of multi-camera systems or operate on aggregated multi-view features, which lack a unified spatial representation, making it more challenging to reason about ego-centric directions, object relations, and the wider context. We thus present BeLLA, an end-to-end architecture that connects unified 360° BEV representations with a large language model for question answering in autonomous driving. We primarily evaluate our work using two benchmarks - NuScenes-QA and DriveLM, where BeLLA consistently outperforms existing approaches on questions that require greater spatial reasoning, such as those involving relative object positioning and behavioral understanding of nearby objects, achieving up to +9.3% absolute improvement in certain tasks. In other categories, BeLLA performs competitively, demonstrating the capability of handling a diverse range of questions.

</details>


### [94] [SpectraIrisPAD: Leveraging Vision Foundation Models for Spectrally Conditioned Multispectral Iris Presentation Attack Detection](https://arxiv.org/abs/2512.06103)
*Raghavendra Ramachandra,Sushma Venkatesh*

Main category: cs.CV

TL;DR: 提出SpectraIrisPAD框架，利用多光谱成像和DINOv2 ViT架构进行虹膜呈现攻击检测，并构建了包含5个近红外波段、8种攻击类型的新数据集MSIrPAD。


<details>
  <summary>Details</summary>
Motivation: 虹膜识别虽然准确，但在实际应用中易受呈现攻击威胁。传统近红外系统存在局限性，多光谱成像能提供互补的反射信息，增强攻击检测的泛化能力。

Method: 提出SpectraIrisPAD框架：基于DINOv2 Vision Transformer骨干网络，配备可学习光谱位置编码、令牌融合和对比学习，提取区分性的波段特定特征。同时构建了包含5个NIR波长(800-980nm)的多光谱虹膜数据集MSIrPAD。

Result: 在未见攻击评估协议下，SpectraIrisPAD在所有性能指标上持续优于多个最先进基线方法，展现出检测多种呈现攻击的优越鲁棒性和泛化能力。

Conclusion: 多光谱成像结合深度学习能有效提升虹膜呈现攻击检测的鲁棒性。提出的SpectraIrisPAD框架和MSIrPAD数据集为虹膜生物识别系统的安全性提供了重要保障。

Abstract: Iris recognition is widely recognized as one of the most accurate biometric modalities. However, its growing deployment in real-world applications raises significant concerns regarding its vulnerability to Presentation Attacks (PAs). Effective Presentation Attack Detection (PAD) is therefore critical to ensure the integrity and security of iris-based biometric systems. While conventional iris recognition systems predominantly operate in the near-infrared (NIR) spectrum, multispectral imaging across multiple NIR bands provides complementary reflectance information that can enhance the generalizability of PAD methods. In this work, we propose \textbf{SpectraIrisPAD}, a novel deep learning-based framework for robust multispectral iris PAD. The SpectraIrisPAD leverages a DINOv2 Vision Transformer (ViT) backbone equipped with learnable spectral positional encoding, token fusion, and contrastive learning to extract discriminative, band-specific features that effectively distinguish bona fide samples from various spoofing artifacts. Furthermore, we introduce a new comprehensive dataset Multispectral Iris PAD (\textbf{MSIrPAD}) with diverse PAIs, captured using a custom-designed multispectral iris sensor operating at five distinct NIR wavelengths (800\,nm, 830\,nm, 850\,nm, 870\,nm, and 980\,nm). The dataset includes 18,848 iris images encompassing eight diverse PAI categories, including five textured contact lenses, print attacks, and display-based attacks. We conduct comprehensive experiments under unseen attack evaluation protocols to assess the generalization capability of the proposed method. SpectraIrisPAD consistently outperforms several state-of-the-art baselines across all performance metrics, demonstrating superior robustness and generalizability in detecting a wide range of presentation attacks.

</details>


### [95] [Explainable Melanoma Diagnosis with Contrastive Learning and LLM-based Report Generation](https://arxiv.org/abs/2512.06105)
*Junwen Zheng,Xinran Xu,Li Rong Wang,Chang Cai,Lucinda Siyun Tan,Dingyuan Wang,Hong Liang Tey,Xiuyi Fan*

Main category: cs.CV

TL;DR: 提出CEFM框架，通过对比学习将临床诊断标准（ABC规则）映射到视觉Transformer嵌入空间，生成结构化文本解释，提高黑色素瘤分类的可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在黑色素瘤分类中已达到专家水平，但模型不透明和缺乏可解释性阻碍了临床应用，因为临床医生难以信任黑盒模型的决策过程。

Method: 提出CEFM框架，使用对比学习作为核心机制，通过双投影头将临床诊断标准（不对称性、边界、颜色）映射到Vision Transformer嵌入空间，将对齐的表征通过自然语言生成转化为结构化文本解释。

Result: 在公共数据集上达到92.79%准确率和0.961的AUC，在多个可解释性指标上有显著改进。定性分析显示学习到的嵌入空间排列与临床医生应用ABC规则一致。

Conclusion: CEFM框架通过将临床语义与视觉特征对齐并生成结构化解释，有效弥合了高性能分类与临床信任之间的差距，为临床采用提供了透明可靠的解决方案。

Abstract: Deep learning has demonstrated expert-level performance in melanoma classification, positioning it as a powerful tool in clinical dermatology. However, model opacity and the lack of interpretability remain critical barriers to clinical adoption, as clinicians often struggle to trust the decision-making processes of black-box models. To address this gap, we present a Cross-modal Explainable Framework for Melanoma (CEFM) that leverages contrastive learning as the core mechanism for achieving interpretability. Specifically, CEFM maps clinical criteria for melanoma diagnosis-namely Asymmetry, Border, and Color (ABC)-into the Vision Transformer embedding space using dual projection heads, thereby aligning clinical semantics with visual features. The aligned representations are subsequently translated into structured textual explanations via natural language generation, creating a transparent link between raw image data and clinical interpretation. Experiments on public datasets demonstrate 92.79% accuracy and an AUC of 0.961, along with significant improvements across multiple interpretability metrics. Qualitative analyses further show that the spatial arrangement of the learned embeddings aligns with clinicians' application of the ABC rule, effectively bridging the gap between high-performance classification and clinical trust.

</details>


### [96] [Tracking-Guided 4D Generation: Foundation-Tracker Motion Priors for 3D Model Animation](https://arxiv.org/abs/2512.06158)
*Su Sun,Cheng Zhao,Himangi Mittal,Gaurav Mittal,Rohith Kukkala,Yingjie Victor Chen,Mei Chen*

Main category: cs.CV

TL;DR: Track4DGen是一个两阶段框架，通过结合多视角视频扩散模型、基础点追踪器和混合4D高斯泼溅重建器，生成动态4D对象。核心思想是将追踪器导出的运动先验显式注入到中间特征表示中，以提升时间一致性和抑制伪影。


<details>
  <summary>Details</summary>
Motivation: 从稀疏输入生成动态4D对象很困难，因为需要同时保持外观和运动在视角和时间上的一致性，同时抑制伪影和时间漂移。现有方法主要依赖像素或潜在空间的视频扩散损失监督，缺乏显式的时间感知特征级追踪指导。

Method: 两阶段框架：第一阶段在多视角视频扩散生成器中强制执行密集特征级点对应关系，产生时间一致的特征；第二阶段使用混合运动编码重建4D高斯泼溅，将扩散特征（携带追踪先验）与Hex-plane特征拼接，并用4D球谐函数增强以进行高保真动态建模。

Result: Track4DGen在多视角视频生成和4D生成基准测试中超越了基线方法，产生了时间稳定、可文本编辑的4D资产。此外还创建了Sketchfab28数据集，用于基准测试对象中心的4D生成并促进未来研究。

Conclusion: 通过显式注入追踪器导出的运动先验到中间特征表示中，Track4DGen能够生成时间一致、视角连贯的动态4D对象，解决了现有方法中的外观漂移和伪影问题，为4D生成提供了新的解决方案。

Abstract: Generating dynamic 4D objects from sparse inputs is difficult because it demands joint preservation of appearance and motion coherence across views and time while suppressing artifacts and temporal drift. We hypothesize that the view discrepancy arises from supervision limited to pixel- or latent-space video-diffusion losses, which lack explicitly temporally aware, feature-level tracking guidance. We present \emph{Track4DGen}, a two-stage framework that couples a multi-view video diffusion model with a foundation point tracker and a hybrid 4D Gaussian Splatting (4D-GS) reconstructor. The central idea is to explicitly inject tracker-derived motion priors into intermediate feature representations for both multi-view video generation and 4D-GS. In Stage One, we enforce dense, feature-level point correspondences inside the diffusion generator, producing temporally consistent features that curb appearance drift and enhance cross-view coherence. In Stage Two, we reconstruct a dynamic 4D-GS using a hybrid motion encoding that concatenates co-located diffusion features (carrying Stage-One tracking priors) with Hex-plane features, and augment them with 4D Spherical Harmonics for higher-fidelity dynamics modeling. \emph{Track4DGen} surpasses baselines on both multi-view video generation and 4D generation benchmarks, yielding temporally stable, text-editable 4D assets. Lastly, we curate \emph{Sketchfab28}, a high-quality dataset for benchmarking object-centric 4D generation and fostering future research.

</details>


### [97] [Automated Annotation of Shearographic Measurements Enabling Weakly Supervised Defect Detection](https://arxiv.org/abs/2512.06171)
*Jessica Plassmann,Nicolas Schuler,Michael Schuth,Georg von Freymann*

Main category: cs.CV

TL;DR: 提出基于深度学习的自动化工作流，从剪切散斑测量中生成缺陷标注，减少人工标注负担，支持可扩展的数据集创建


<details>
  <summary>Details</summary>
Motivation: 剪切散斑技术可用于检测关键安全部件的亚表面缺陷，但工业应用受限主要因为缺乏高质量标注数据集，人工标注劳动密集、主观性强且难以标准化

Method: 引入自动化工作流，利用深度学习从剪切散斑测量中生成缺陷标注，产生高分辨率分割和边界框标签

Result: 与专家标注数据对比评估显示，该方法具有足够准确性，可实现弱监督训练，减少人工工作量

Conclusion: 该自动化工作流支持可扩展的数据集创建，为稳健的缺陷检测提供解决方案，促进剪切散斑技术在工业中的采用

Abstract: Shearography is an interferometric technique sensitive to surface displacement gradients, providing high sensitivity for detecting subsurface defects in safety-critical components. A key limitation to industrial adoption is the lack of high-quality annotated datasets, since manual labeling remains labor-intensive, subjective, and difficult to standardize. We introduce an automated workflow that generates defect annotations from shearography measurements using deep learning, producing high-resolution segmentation and bounding-box labels. Evaluation against expert-labeled data demonstrates sufficient accuracy to enable weakly supervised training, reducing manual effort and supporting scalable dataset creation for robust defect detection.

</details>


### [98] [Physics-Grounded Shadow Generation from Monocular 3D Geometry Priors and Approximate Light Direction](https://arxiv.org/abs/2512.06174)
*Shilin Hu,Jingyi Xu,Akshat Dave,Dimitris Samaras,Hieu Le*

Main category: cs.CV

TL;DR: 提出将显式物理建模（几何与光照）融入深度学习阴影生成的新框架，通过3D几何重建和光照估计获得物理准确的阴影位置形状，再用扩散模型细化生成高保真阴影


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法很少利用阴影形成的显式物理建模（遮挡物几何和光照），导致生成的阴影在物理一致性上不足，特别是在复杂几何或模糊光照场景中

Method: 1) 从单目RGB图像获取密集点云表示的近似3D几何和主导光照方向；2) 基于物理阴影形成原理计算初始阴影位置形状；3) 将物理估计结果输入扩散模型进行细化和高保真渲染

Result: 在DESOBAV2数据集上训练，模型生成的阴影既视觉逼真又物理一致，在复杂几何或模糊光照场景中优于现有方法

Conclusion: 将显式物理建模与深度学习相结合，能够生成更真实、物理一致的阴影，特别是在挑战性场景中表现出色，为阴影生成任务提供了新思路

Abstract: Shadow generation aims to produce photorealistic shadows that are visually consistent with object geometry and scene illumination. In the physics of shadow formation, the occluder blocks some light rays casting from the light source that would otherwise arrive at the surface, creating a shadow that follows the silhouette of the occluder. However, such explicit physical modeling has rarely been used in deep-learning-based shadow generation. In this paper, we propose a novel framework that embeds explicit physical modeling - geometry and illumination - into deep-learning-based shadow generation. First, given a monocular RGB image, we obtain approximate 3D geometry in the form of dense point maps and predict a single dominant light direction. These signals allow us to recover fairly accurate shadow location and shape based on the physics of shadow formation. We then integrate this physics-based initial estimate into a diffusion framework that refines the shadow into a realistic, high-fidelity appearance while ensuring consistency with scene geometry and illumination. Trained on DESOBAV2, our model produces shadows that are both visually realistic and physically coherent, outperforming existing approaches, especially in scenes with complex geometry or ambiguous lighting.

</details>


### [99] [Physics-Grounded Attached Shadow Detection Using Approximate 3D Geometry and Light Direction](https://arxiv.org/abs/2512.06179)
*Shilin Hu,Jingyi Xu,Sagnik Das,Dimitris Samaras,Hieu Le*

Main category: cs.CV

TL;DR: 提出首个联合检测投射阴影和附着阴影的框架，通过光照与几何推理的闭环系统迭代优化阴影分割和光照估计


<details>
  <summary>Details</summary>
Motivation: 现有阴影检测方法主要针对投射阴影，缺乏专门的附着阴影数据集和模型，而附着阴影对理解物体三维结构至关重要

Method: 构建包含阴影检测模块和光照估计模块的闭环系统：阴影检测模块分别预测两种阴影类型，光照估计模块从检测到的阴影推断光照方向，结合表面法线生成几何一致的部分遮挡图，反馈优化阴影预测

Result: 实验结果显示，该方法显著提升附着阴影检测性能（BER降低至少33%），同时保持对完整阴影和投射阴影的强检测能力

Conclusion: 通过光照与几何的联合推理形成闭环系统，能够有效检测附着阴影，填补了该领域的数据集和方法空白

Abstract: Attached shadows occur on the surface of the occluder where light cannot reach because of self-occlusion. They are crucial for defining the three-dimensional structure of objects and enhancing scene understanding. Yet existing shadow detection methods mainly target cast shadows, and there are no dedicated datasets or models for detecting attached shadows. To address this gap, we introduce a framework that jointly detects cast and attached shadows by reasoning about their mutual relationship with scene illumination and geometry. Our system consists of a shadow detection module that predicts both shadow types separately, and a light estimation module that infers the light direction from the detected shadows. The estimated light direction, combined with surface normals, allows us to derive a geometry-consistent partial map that identifies regions likely to be self-occluded. This partial map is then fed back to refine shadow predictions, forming a closed-loop reasoning process that iteratively improves both shadow segmentation and light estimation. In order to train our method, we have constructed a dataset of 1,458 images with separate annotations for cast and attached shadows, enabling training and quantitative evaluation of both. Experimental results demonstrate that this iterative geometry-illumination reasoning substantially improves the detection of attached shadows, with at least 33% BER reduction, while maintaining strong full and cast shadow performance.

</details>


### [100] [SPOOF: Simple Pixel Operations for Out-of-Distribution Fooling](https://arxiv.org/abs/2512.06185)
*Ankit Gupta,Christoph Adami,Emily Dolson*

Main category: cs.CV

TL;DR: 现代深度神经网络（包括卷积和Transformer架构）仍然存在对非自然图像的过度自信问题，本文重新实现进化攻击并提出了更高效的SPOOF黑盒攻击方法。


<details>
  <summary>Details</summary>
Motivation: 尽管深度神经网络在图像识别任务上表现出色，但它们仍然对与自然图像毫无相似之处的输入表现出过度自信。本文旨在重新验证这种"欺骗图像"现象在现代架构中的持续性，并开发更高效的攻击方法。

Method: 1) 重新实现Nguyen等人(2015)的CPPN和直接编码进化攻击方法，测试现代卷积和Transformer架构；2) 提出SPOOF方法——一种最小化、一致且更高效的黑盒攻击，生成高置信度欺骗图像；3) 使用欺骗图像作为额外类别进行重新训练来测试防御效果。

Result: 1) 高置信度欺骗现象在现代网络中仍然存在，基于Transformer的ViT-B/16最为脆弱，需要比卷积模型更少的查询次数；2) SPOOF方法能够以最小的像素修改和显著降低的计算成本生成无法识别的欺骗图像；3) 使用欺骗图像重新训练只能提供部分抵抗，SPOOF仍能以稍高的查询预算持续欺骗。

Conclusion: 现代深度分类器仍然存在持续的脆弱性，即使采用欺骗图像重新训练等防御措施，也无法完全抵抗高效的黑盒攻击，这表明深度神经网络对非自然输入的过度自信问题仍然是一个根本性挑战。

Abstract: Deep neural networks (DNNs) excel across image recognition tasks, yet continue to exhibit overconfidence on inputs that bear no resemblance to natural images. Revisiting the "fooling images" work introduced by Nguyen et al. (2015), we re-implement both CPPN-based and direct-encoding-based evolutionary fooling attacks on modern architectures, including convolutional and transformer classifiers. Our re-implementation confirm that high-confidence fooling persists even in state-of-the-art networks, with transformer-based ViT-B/16 emerging as the most susceptible--achieving near-certain misclassifications with substantially fewer queries than convolution-based models. We then introduce SPOOF, a minimalist, consistent, and more efficient black-box attack generating high-confidence fooling images. Despite its simplicity, SPOOF generates unrecognizable fooling images with minimal pixel modifications and drastically reduced compute. Furthermore, retraining with fooling images as an additional class provides only partial resistance, as SPOOF continues to fool consistently with slightly higher query budgets--highlighting persistent fragility of modern deep classifiers.

</details>


### [101] [Multi-Modal Zero-Shot Prediction of Color Trajectories in Food Drying](https://arxiv.org/abs/2512.06190)
*Shichen Li,Ahmadreza Eslaminia,Chenhui Shao*

Main category: cs.CV

TL;DR: 提出一种新颖的多模态颜色轨迹预测方法，用于食品干燥过程中的颜色变化预测，相比基线模型误差降低90%以上


<details>
  <summary>Details</summary>
Motivation: 现有食品干燥颜色变化研究主要依赖低维颜色特征，无法充分捕捉食品样品复杂的动态颜色轨迹，且现有建模方法缺乏对未见工艺条件的泛化能力

Method: 开发了一种新颖的多模态颜色轨迹预测方法，将高维时序颜色信息与干燥工艺参数相结合，实现准确且数据高效的颜色轨迹预测

Result: 在未见干燥条件下，模型在饼干干燥中达到RMSE 2.12，苹果干燥中达到RMSE 1.29，相比基线模型误差降低超过90%

Conclusion: 实验结果表明该模型具有优越的准确性、鲁棒性和广泛的适用性，能够有效预测食品干燥过程中的颜色变化轨迹

Abstract: Food drying is widely used to reduce moisture content, ensure safety, and extend shelf life. Color evolution of food samples is an important indicator of product quality in food drying. Although existing studies have examined color changes under different drying conditions, current approaches primarily rely on low-dimensional color features and cannot fully capture the complex, dynamic color trajectories of food samples. Moreover, existing modeling approaches lack the ability to generalize to unseen process conditions. To address these limitations, we develop a novel multi-modal color-trajectory prediction method that integrates high-dimensional temporal color information with drying process parameters to enable accurate and data-efficient color trajectory prediction. Under unseen drying conditions, the model attains RMSEs of 2.12 for cookie drying and 1.29 for apple drying, reducing errors by over 90% compared with baseline models. These experimental results demonstrate the model's superior accuracy, robustness, and broad applicability.

</details>


### [102] [The MICCAI Federated Tumor Segmentation (FeTS) Challenge 2024: Efficient and Robust Aggregation Methods for Federated Learning](https://arxiv.org/abs/2512.06206)
*Akis Linardos,Sarthak Pati,Ujjwal Baid,Brandon Edwards,Patrick Foley,Kevin Ta,Verena Chung,Micah Sheller,Muhammad Irfan Khan,Mojtaba Jafaritadi,Elina Kontio,Suleiman Khan,Leon Mächler,Ivan Ezhov,Suprosanna Shit,Johannes C. Paetzold,Gustav Grimberg,Manuel A. Nickel,David Naccache,Vasilis Siomos,Jonathan Passerat-Palmbach,Giacomo Tarroni,Daewoon Kim,Leonard L. Klausmann,Prashant Shah,Bjoern Menze,Dimitrios Makris,Spyridon Bakas*

Main category: cs.CV

TL;DR: MICCAI FeTS 2024挑战赛聚焦于联邦学习在胶质瘤亚区分割中的应用，评估新的权重聚合方法以提升鲁棒性和效率，PID控制器方法获得最佳表现。


<details>
  <summary>Details</summary>
Motivation: 推动联邦学习在医学影像分析中的应用，特别是在多机构协作的胶质瘤分割任务中，解决数据隐私保护下的模型训练问题，并探索更高效、鲁棒的权重聚合方法。

Method: 使用标准化的联邦学习框架和多机构MRI数据集（来自BraTS基准），包含1251个训练样本、219个验证样本和570个隐藏测试样本。评估了六种权重聚合方法，采用累积评分系统综合考虑分割性能（DSC和HD95）和通信效率（收敛分数）。

Result: 基于PID控制器的方法获得最高排名，在增强肿瘤、肿瘤核心和全肿瘤区域分别达到0.733、0.761和0.751的DSC均值，对应的HD95值为33.922mm、33.623mm和32.309mm，同时具有最高的通信效率（收敛分数0.764），超越了以往挑战赛的最佳方法。

Conclusion: PID控制器是稳定和优化联邦学习中权重聚合的有效机制，该挑战赛推动了医学影像联邦学习的发展，代码已开源供社区使用。

Abstract: We present the design and results of the MICCAI Federated Tumor Segmentation (FeTS) Challenge 2024, which focuses on federated learning (FL) for glioma sub-region segmentation in multi-parametric MRI and evaluates new weight aggregation methods aimed at improving robustness and efficiency. Six participating teams were evaluated using a standardized FL setup and a multi-institutional dataset derived from the BraTS glioma benchmark, consisting of 1,251 training cases, 219 validation cases, and 570 hidden test cases with segmentations for enhancing tumor (ET), tumor core (TC), and whole tumor (WT). Teams were ranked using a cumulative scoring system that considered both segmentation performance, measured by Dice Similarity Coefficient (DSC) and the 95th percentile Hausdorff Distance (HD95), and communication efficiency assessed through the convergence score. A PID-controller-based method achieved the top overall ranking, obtaining mean DSC values of 0.733, 0.761, and 0.751 for ET, TC, and WT, respectively, with corresponding HD95 values of 33.922 mm, 33.623 mm, and 32.309 mm, while also demonstrating the highest communication efficiency with a convergence score of 0.764. These findings advance the state of federated learning for medical imaging, surpassing top-performing methods from previous challenge iterations and highlighting PID controllers as effective mechanisms for stabilizing and optimizing weight aggregation in FL. The challenge code is available at https://github.com/FeTS-AI/Challenge.

</details>


### [103] [Revisiting SVD and Wavelet Difference Reduction for Lossy Image Compression: A Reproducibility Study](https://arxiv.org/abs/2512.06221)
*Alena Makarova*

Main category: cs.CV

TL;DR: 该研究对结合SVD和WDR的图像压缩方法进行了可重复性验证，发现原论文声称优于JPEG2000和WDR的结论无法复现，实际性能并未超越基准方法。


<details>
  <summary>Details</summary>
Motivation: 验证一篇声称结合奇异值分解(SVD)和小波差分缩减(WDR)的图像压缩技术优于JPEG2000和单独WDR的论文的可重复性，并识别原方法描述中的模糊之处。

Method: 重新实现原论文提出的SVD+WDR方法，仔细填补缺失的实现细节，复现原始实验，并在新图像上进行额外测试，使用PSNR和SSIM作为评估指标。

Result: 与原论文声称相反，SVD+WDR方法在PSNR方面通常未超越JPEG2000或WDR，仅在SSIM方面部分优于JPEG2000。研究揭示了原方法描述中的模糊点（如量化和阈值初始化）对可重复性和性能报告的显著影响。

Conclusion: 该可重复性研究表明原论文的结论无法得到验证，强调了方法描述清晰度对研究可重复性的重要性，并指出SVD+WDR组合并未如原论文声称那样显著优于现有压缩技术。

Abstract: This work presents an independent reproducibility study of a lossy image compression technique that integrates singular value decomposition (SVD) and wavelet difference reduction (WDR). The original paper claims that combining SVD and WDR yields better visual quality and higher compression ratios than JPEG2000 and standalone WDR. I re-implemented the proposed method, carefully examined missing implementation details, and replicated the original experiments as closely as possible. I then conducted additional experiments on new images and evaluated performance using PSNR and SSIM. In contrast to the original claims, my results indicate that the SVD+WDR technique generally does not surpass JPEG2000 or WDR in terms of PSNR, and only partially improves SSIM relative to JPEG2000. The study highlights ambiguities in the original description (e.g., quantization and threshold initialization) and illustrates how such gaps can significantly impact reproducibility and reported performance.

</details>


### [104] [GPU-GLMB: Assessing the Scalability of GPU-Accelerated Multi-Hypothesis Tracking](https://arxiv.org/abs/2512.06230)
*Pranav Balakrishnan,Sidisha Barik,Sean M. O'Rourke,Benjamin M. Marlin*

Main category: cs.CV

TL;DR: 提出一种改进的GLMB滤波器，支持同一传感器对同一目标产生多个检测，打破检测间依赖关系，实现更好的并行扩展性，可在GPU上高效部署。


<details>
  <summary>Details</summary>
Motivation: 传统多假设跟踪方法（如GLMB滤波器）在标准测量模型下计算成本极高，即使采用假设剪枝近似仍然昂贵。需要解决在分布式机器学习虚拟传感器网络中，同一传感器可能对同一目标产生多个检测的场景下的高效跟踪问题。

Method: 研究GLMB滤波器的变体，允许同一传感器对同一目标产生多个检测。这种设计打破了标准GLMB滤波器中检测间的依赖关系，使滤波器更新具有更好的并行扩展性，从而能够在GPU硬件上高效实现。

Result: 通过GPU加速实现的GLMB跟踪器初步分析显示，在目标数量和保留假设最大数量方面具有良好的运行时扩展性。改进后的滤波器能够有效处理分布式虚拟传感器网络中的多检测场景。

Conclusion: 提出的GLMB滤波器变体通过允许同一传感器对同一目标产生多个检测，成功打破了检测间依赖，实现了更好的并行计算扩展性，为在GPU上高效部署多目标跟踪系统提供了可行方案，特别适用于分布式机器学习虚拟传感器网络环境。

Abstract: Much recent research on multi-target tracking has focused on multi-hypothesis approaches leveraging random finite sets. Of particular interest are labeled random finite set methods that maintain temporally coherent labels for each object. While these methods enjoy important theoretical properties as closed-form solutions to the multi-target Bayes filter, the maintenance of multiple hypotheses under the standard measurement model is highly computationally expensive, even when hypothesis pruning approximations are applied. In this work, we focus on the Generalized Labeled Multi-Bernoulli (GLMB) filter as an example of this class of methods. We investigate a variant of the filter that allows multiple detections per object from the same sensor, a critical capability when deploying tracking in the context of distributed networks of machine learning-based virtual sensors. We show that this breaks the inter-detection dependencies in the filter updates of the standard GLMB filter, allowing updates with significantly improved parallel scalability and enabling efficient deployment on GPU hardware. We report the results of a preliminary analysis of a GPU-accelerated implementation of our proposed GLMB tracker, with a focus on run time scalability with respect to the number of objects and the maximum number of retained hypotheses.

</details>


### [105] [Opinion: Learning Intuitive Physics May Require More than Visual Data](https://arxiv.org/abs/2512.06232)
*Ellen Su,Solim Legris,Todd M. Gureckis,Mengye Ren*

Main category: cs.CV

TL;DR: 在发育真实的儿童视角视频数据集上预训练V-JEPA模型，并未显著提升直觉物理推理能力，表明仅靠数据分布调整不足以让现有架构学会直觉物理


<details>
  <summary>Details</summary>
Motivation: 人类通过丰富的内部模型和直觉物理理解来导航世界，而当前深度学习模型即使在大量互联网视频数据训练下，在直觉物理基准测试中仍达不到人类水平。本研究探讨数据分布（而非数据量）是否是学习这些物理原理的关键。

Method: 使用Video Joint Embedding Predictive Architecture (V-JEPA)模型，在SAYCam数据集上进行预训练。SAYCam是一个发育真实的、以自我为中心的儿童视角视频数据集，记录了三个儿童的日常视觉体验，数据量仅为当前最先进模型训练数据的0.01%。

Result: 在SAYCam数据集上训练V-JEPA模型并未显著提升其在IntPhys2基准测试上的性能。这表明仅使用发育真实的数据集训练当前架构，不足以学习支持直觉物理的表征。

Conclusion: 仅改变视觉数据的数量和分布可能不足以构建具有人工直觉物理的系统。需要更深入的方法来让AI系统掌握直觉物理理解。

Abstract: Humans expertly navigate the world by building rich internal models founded on an intuitive understanding of physics. Meanwhile, despite training on vast quantities of internet video data, state-of-the-art deep learning models still fall short of human-level performance on intuitive physics benchmarks. This work investigates whether data distribution, rather than volume, is the key to learning these principles. We pretrain a Video Joint Embedding Predictive Architecture (V-JEPA) model on SAYCam, a developmentally realistic, egocentric video dataset partially capturing three children's everyday visual experiences. We find that training on this dataset, which represents 0.01% of the data volume used to train SOTA models, does not lead to significant performance improvements on the IntPhys2 benchmark. Our results suggest that merely training on a developmentally realistic dataset is insufficient for current architectures to learn representations that support intuitive physics. We conclude that varying visual data volume and distribution alone may not be sufficient for building systems with artificial intuitive physics.

</details>


### [106] [NexusFlow: Unifying Disparate Tasks under Partial Supervision via Invertible Flow Networks](https://arxiv.org/abs/2512.06251)
*Fangzhou Lin,Yuping Wang,Yuliang Guo,Zixun Huang,Xinyu Huang,Haichong Zhang,Kazunori Yamada,Zhengzhong Tu,Liu Ren,Ziming Zhang*

Main category: cs.CV

TL;DR: NexusFlow是一个轻量级即插即用框架，通过可逆耦合层对齐异构任务的潜在特征分布，在部分监督多任务学习中实现有效的知识迁移，在自动驾驶和室内场景理解任务上均取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有部分监督多任务学习方法主要关注同构密集预测任务，而现实场景中任务结构往往异构且标注不完整，需要能够处理结构差异和强域差距的通用框架。

Method: 提出NexusFlow框架，使用带可逆耦合层的代理网络将不同任务的潜在特征分布对齐到共享规范空间，保持信息完整性同时避免表征坍缩，支持异构任务间的知识迁移。

Result: 在nuScenes自动驾驶数据集上取得新的SOTA结果，优于现有部分监督基线；在NYUv2数据集上三个同构密集预测任务（分割、深度、表面法线）均获得一致性能提升。

Conclusion: NexusFlow通过可逆特征对齐有效解决了异构任务的部分监督多任务学习问题，具有广泛的适用性，为现实世界中标注不完整且任务结构多样的场景提供了实用解决方案。

Abstract: Partially Supervised Multi-Task Learning (PS-MTL) aims to leverage knowledge across tasks when annotations are incomplete. Existing approaches, however, have largely focused on the simpler setting of homogeneous, dense prediction tasks, leaving the more realistic challenge of learning from structurally diverse tasks unexplored. To this end, we introduce NexusFlow, a novel, lightweight, and plug-and-play framework effective in both settings. NexusFlow introduces a set of surrogate networks with invertible coupling layers to align the latent feature distributions of tasks, creating a unified representation that enables effective knowledge transfer. The coupling layers are bijective, preserving information while mapping features into a shared canonical space. This invertibility avoids representational collapse and enables alignment across structurally different tasks without reducing expressive capacity. We first evaluate NexusFlow on the core challenge of domain-partitioned autonomous driving, where dense map reconstruction and sparse multi-object tracking are supervised in different geographic regions, creating both structural disparity and a strong domain gap. NexusFlow sets a new state-of-the-art result on nuScenes, outperforming strong partially supervised baselines. To demonstrate generality, we further test NexusFlow on NYUv2 using three homogeneous dense prediction tasks, segmentation, depth, and surface normals, as a representative N-task PS-MTL scenario. NexusFlow yields consistent gains across all tasks, confirming its broad applicability.

</details>


### [107] [Language-driven Fine-grained Retrieval](https://arxiv.org/abs/2512.06255)
*Shijie Wang,Xin Yu,Yadan Luo,Zijian Wang,Pengfei Zhang,Zi Huang*

Main category: cs.CV

TL;DR: LaFG：利用大语言模型和视觉语言模型将类别名称转换为属性级监督的细粒度图像检索框架，通过构建数据集范围的属性词汇库来提升跨类别细节建模和未见类别的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有细粒度图像检索方法使用基于类别名称的稀疏one-hot标签作为监督，忽略了类别名称中丰富的语义信息，导致跨类别细节的可比性建模不足，限制了模型对未见类别的泛化能力。

Method: 1. 使用大语言模型将类别名称转换为详细的属性导向描述；2. 利用冻结的视觉语言模型将描述投影到视觉对齐空间，聚类形成数据集范围的属性词汇库；3. 通过全局提示模板选择类别相关属性，聚合成类别特定的语言原型；4. 用这些原型监督检索模型。

Result: 论文声称该方法能够更好地建模跨类别细节的可比性，提升对未见类别的泛化能力，但具体实验结果未在摘要中提供。

Conclusion: LaFG框架通过利用语言模型将类别名称转换为丰富的属性级监督，解决了传统细粒度图像检索中语义稀疏的问题，能够更好地建模跨类别细节并提升对未见类别的泛化性能。

Abstract: Existing fine-grained image retrieval (FGIR) methods learn discriminative embeddings by adopting semantically sparse one-hot labels derived from category names as supervision. While effective on seen classes, such supervision overlooks the rich semantics encoded in category names, hindering the modeling of comparability among cross-category details and, in turn, limiting generalization to unseen categories. To tackle this, we introduce LaFG, a Language-driven framework for Fine-Grained Retrieval that converts class names into attribute-level supervision using large language models (LLMs) and vision-language models (VLMs). Treating each name as a semantic anchor, LaFG prompts an LLM to generate detailed, attribute-oriented descriptions. To mitigate attribute omission in these descriptions, it leverages a frozen VLM to project them into a vision-aligned space, clustering them into a dataset-wide attribute vocabulary while harvesting complementary attributes from related categories. Leveraging this vocabulary, a global prompt template selects category-relevant attributes, which are aggregated into category-specific linguistic prototypes. These prototypes supervise the retrieval model to steer

</details>


### [108] [Knowing the Answer Isn't Enough: Fixing Reasoning Path Failures in LVLMs](https://arxiv.org/abs/2512.06258)
*Chaoyang Wang,Yangfan He,Yiyang Zhou,Yixuan Wang,Jiaqi Liu,Peng Xia,Zhengzhong Tu,Mohit Bansal,Huaxiu Yao*

Main category: cs.CV

TL;DR: LVLMs存在路径选择偏差问题：即使知道正确答案，也常通过错误推理路径得出结果。作者提出PSO两阶段后训练框架，通过路径选择优化提升推理性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 揭示大型视觉语言模型的一个关键但未被充分探索的缺陷：即使模型知道正确答案，也经常通过错误的推理路径到达那里。核心问题不是缺乏知识，而是在广阔的推理搜索空间中的路径选择偏差。

Method: 提出PSO（路径选择优化）两阶段后训练框架：第一阶段使用带模板和答案奖励的GRPO培养结构化逐步推理；第二阶段进行在线偏好优化，模型从GRPO生成的数据中采样推理路径，自我评估并朝着优选轨迹对齐。错误或次优路径存储在负向回放记忆中作为硬负例。

Result: 大量实验表明，PSO有效修剪无效推理路径，显著提升推理准确性（平均提升7.4%），并产生更稳定一致的思维链。

Conclusion: PSO框架成功解决了LVLMs中的路径选择偏差问题，通过优化推理路径选择显著提升了模型的推理性能和稳定性，为大型视觉语言模型的可靠性改进提供了有效方法。

Abstract: We reveal a critical yet underexplored flaw in Large Vision-Language Models (LVLMs): even when these models know the correct answer, they frequently arrive there through incorrect reasoning paths. The core issue is not a lack of knowledge, but a path selection bias within the vast reasoning search space. Although LVLMs are often capable of sampling correct solution trajectories, they disproportionately favor unstable or logically inconsistent ones, leading to erratic and unreliable outcomes. The substantial disparity between Pass@K (with large K) and Pass@1 across numerous models provides compelling evidence that such failures primarily stem from misreasoning rather than ignorance. To systematically investigate and address this issue, we propose PSO (Path-Select Optimization), a two-stage post-training framework designed to enhance both the reasoning performance and stability of existing LVLMs. In the first stage, we employ Group Relative Policy Optimization (GRPO) with template and answer-based rewards to cultivate structured, step-by-step reasoning. In the second stage, we conduct online preference optimization, where the model samples reasoning paths from GRPO-generated data, self-evaluates them, and aligns itself toward the preferred trajectories. Incorrect or suboptimal paths are concurrently stored in a Negative Replay Memory (NRM) as hard negatives, which are periodically revisited to prevent the model from repeating prior mistakes and to facilitate continual reasoning refinement. Extensive experiments show that PSO effectively prunes invalid reasoning paths, substantially enhances reasoning accuracy (with 7.4% improvements on average), and yields more stable and consistent chains of thought. Our code will be available at https://github.com/aiming-lab/PSO.

</details>


### [109] [TriaGS: Differentiable Triangulation-Guided Geometric Consistency for 3D Gaussian Splatting](https://arxiv.org/abs/2512.06269)
*Quan Tran,Tuan Dang*

Main category: cs.CV

TL;DR: 提出一种通过多视角三角测量约束增强3D高斯重建几何一致性的方法，解决浮游伪影问题，在DTU数据集上达到0.50mm的Chamfer距离


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯重建仅依赖光度损失，导致重建不一致、产生浮游伪影和几何结构混乱，难以提取高质量表面

Method: 通过约束多视角三角测量强制全局几何一致性，利用多个估计视角达成物理世界3D表示的共识，自监督地惩罚渲染点与鲁棒共识点的偏差

Result: 在多个数据集上取得SOTA结果，DTU数据集上平均Chamfer距离达到0.50mm，优于同类显式方法

Conclusion: 提出的几何一致性约束方法有效改善了3D高斯重建质量，解决了浮游伪影问题，代码将开源以确保可复现性

Abstract: 3D Gaussian Splatting is crucial for real-time novel view synthesis due to its efficiency and ability to render photorealistic images. However, building a 3D Gaussian is guided solely by photometric loss, which can result in inconsistencies in reconstruction. This under-constrained process often results in "floater" artifacts and unstructured geometry, preventing the extraction of high-fidelity surfaces. To address this issue, our paper introduces a novel method that improves reconstruction by enforcing global geometry consistency through constrained multi-view triangulation. Our approach aims to achieve a consensus on 3D representation in the physical world by utilizing various estimated views. We optimize this process by penalizing the deviation of a rendered 3D point from a robust consensus point, which is re-triangulated from a bundle of neighboring views in a self-supervised fashion. We demonstrate the effectiveness of our method across multiple datasets, achieving state-of-the-art results. On the DTU dataset, our method attains a mean Chamfer Distance of 0.50 mm, outperforming comparable explicit methods. We will make our code open-source to facilitate community validation and ensure reproducibility.

</details>


### [110] [FacePhys: State of the Heart Learning](https://arxiv.org/abs/2512.06275)
*Kegang Wang,Jiankai Tang,Yuntao Wang,Xin Liu,Yuxuan Fan,Jiatong Ji,Yuanchun Shi,Daniel McDuff*

Main category: cs.CV

TL;DR: FacePhys是一个基于时空状态空间对偶性的内存高效rPPG算法，解决了模型可扩展性、跨数据集泛化和实时操作的三难问题，在误差减少49%的同时实现3.6MB内存占用和9.46ms每帧延迟。


<details>
  <summary>Details</summary>
Motivation: 基于摄像头的生命体征测量提供了舒适、普适的健康监测机会，但现有rPPG技术在实际部署中面临计算资源限制和数据压缩传输导致信号质量下降的问题。

Method: 提出FacePhys算法，基于时空状态空间对偶性，利用可转移的心脏状态捕捉视频帧间的细微周期性变化，同时保持最小计算开销，支持长视频序列训练和低延迟推理。

Result: FacePhys实现了新的最先进性能，误差减少49%，内存占用仅3.6MB，每帧延迟9.46ms，比现有方法提升83%到99%，在实际部署中提供可靠的实时性能。

Conclusion: FacePhys通过创新的时空状态空间方法成功解决了rPPG技术在实际部署中的关键挑战，为实时、高效的健康监测系统提供了可行的解决方案。

Abstract: Vital sign measurement using cameras presents opportunities for comfortable, ubiquitous health monitoring. Remote photoplethysmography (rPPG), a foundational technology, enables cardiac measurement through minute changes in light reflected from the skin. However, practical deployment is limited by the computational constraints of performing analysis on front-end devices and the accuracy degradation of transmitting data through compressive channels that reduce signal quality. We propose a memory efficient rPPG algorithm - \emph{FacePhys} - built on temporal-spatial state space duality, which resolves the trilemma of model scalability, cross-dataset generalization, and real-time operation. Leveraging a transferable heart state, FacePhys captures subtle periodic variations across video frames while maintaining a minimal computational overhead, enabling training on extended video sequences and supporting low-latency inference. FacePhys establishes a new state-of-the-art, with a substantial 49\% reduction in error. Our solution enables real-time inference with a memory footprint of 3.6 MB and per-frame latency of 9.46 ms -- surpassing existing methods by 83\% to 99\%. These results translate into reliable real-time performance in practical deployments, and a live demo is available at https://www.facephys.com/.

</details>


### [111] [RefBench-PRO: Perceptual and Reasoning Oriented Benchmark for Referring Expression Comprehension](https://arxiv.org/abs/2512.06276)
*Tianyi Gao,Hao Li,Han Fang,Xin Wei,Xiaodong Dong,Hongbo Sun,Ye Yuan,Zhongjiang He,Jinglin Xu,Jingmin Xin,Hao Sun*

Main category: cs.CV

TL;DR: RefBench-PRO是一个新的REC基准测试，将指代表达式分解为感知和推理两个维度，包含六个渐进挑战任务，并提出了Ref-R1学习方案来提升定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有REC基准主要评估感知能力，缺乏可解释的评分机制，无法揭示多模态大语言模型在不同认知能力上的接地能力。需要更全面的评估框架。

Method: 1) 提出RefBench-PRO基准，将指代表达式分解为感知和推理两个核心维度，细分为六个渐进任务：属性、位置、交互、常识、关系和拒绝。2) 开发全自动数据生成流水线。3) 提出Ref-R1学习方案，采用基于动态IoU的GRPO来提升复杂推理条件下的定位精度。

Result: RefBench-PRO能够对MLLM在指代表达式理解上进行可解释评估，在感知和推理方面都提出了更大挑战。Ref-R1为REC建立了更强的基线。

Conclusion: RefBench-PRO是一个全面的REC基准，通过分解认知维度实现可解释评估，Ref-R1学习方案提升了定位精度，为MLLM的接地能力评估提供了新框架。

Abstract: Referring Expression Comprehension (REC) is a vision-language task that localizes a specific image region based on a textual description. Existing REC benchmarks primarily evaluate perceptual capabilities and lack interpretable scoring mechanisms, which cannot reveal the grounding capability of Multi-modal Large Language Model (MLLM) across different cognitive abilities. To address this limitation, we introduce RefBench-PRO, a comprehensive REC benchmark, which decomposes referring expressions into two core dimensions, i.e., perception and reasoning, and further subdivides them into six progressively challenging tasks, such as attribute, position, interaction, commonsense, relation and reject. We also develop a fully automated data-generation pipeline that produces diverse referring expressions across these six sub-dimensions. Furthermore, We propose Ref-R1, an RL-based learning scheme, which incorporates Dynamic IoU-based GRPO to improve localization accuracy under increasingly complex reasoning conditions, establishing a stronger baseline for REC. Extensive experiments demonstrate that our RefBench-PRO enables interpretable evaluation of MLLM on referring expression comprehension, presenting greater challenges in both perception and reasoning.

</details>


### [112] [Unleashing the Intrinsic Visual Representation Capability of Multimodal Large Language Models](https://arxiv.org/abs/2512.06281)
*Hengzhuang Li,Xinsong Zhang,Qiming Peng,Bin Luo,Han Hu,Dengyang Jiang,Han-Jia Ye,Teng Zhang,Hai Jin*

Main category: cs.CV

TL;DR: 提出LaVer框架，通过掩码图像建模在LLM的联合潜在语义空间中学习更具区分性的视觉表示，解决MLLM中的模态不平衡问题


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在模态不平衡问题，视觉信息在深层网络中利用不足，导致视觉性能下降或产生幻觉。这源于训练主要依赖文本token预测，缺乏直接的视觉监督信号，造成视觉表示在层间逐渐同质化。

Method: 提出Latent Visual Reconstruction (LaVer)训练框架，在LLM的联合潜在语义空间中进行掩码图像建模，为MLLM提供直接的视觉激活信号，增强视觉注意力分配。

Result: 在多种基准测试上的广泛实验证明了该方法在各种场景下的优越性，特别是在需要密集视觉能力的任务中表现突出。

Conclusion: LaVer框架通过掩码图像建模有效解决了MLLM的模态不平衡问题，增强了视觉信息的利用，提高了视觉性能。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable proficiency in multimodal tasks. Despite their impressive performance, MLLMs suffer from the modality imbalance issue, where visual information is often underutilized compared to textual representations in deeper layers, leading to degraded visual performance or hallucinations. This issue stems from the predominant reliance on next-text-token-prediction during training, which fails to provide direct visual supervisory signals, resulting in progressive homogenization of visual representations throughout the layers. To this end, we propose Latent Visual Reconstruction (LaVer), a novel training framework that facilitates MLLMs in learning more discriminative visual representations via masked image modeling in the joint latent semantic space of LLM. Our method offers direct visual activation to MLLMs, which exhibit increased visual attention allocation, indicating enhanced utilization of visual information. Extensive experiments across diverse benchmarks prove the superiority of our approach in various scenarios, especially those requiring dense visual capabilities. Code of LaVer is available at https://github.com/Fir-lat/LaVer.

</details>


### [113] [A Sleep Monitoring System Based on Audio, Video and Depth Information](https://arxiv.org/abs/2512.06282)
*Lyn Chao-ling Chen,Kuan-Wen Chen,Yi-Ping Hung*

Main category: cs.CV

TL;DR: 开发基于事件方法的非侵入式睡眠监测系统，通过红外深度传感器、RGB相机和四麦克风阵列检测运动、开关灯和噪音三类事件，用于家庭环境睡眠障碍定量评估。


<details>
  <summary>Details</summary>
Motivation: 需要一种非侵入式的睡眠监测系统来定量评估睡眠障碍，传统方法可能干扰睡眠或不够准确，特别是在家庭环境中需要能够检测多种类型的睡眠干扰事件。

Method: 使用包含红外深度传感器、RGB相机和四麦克风阵列的设备，在低光照环境下监测睡眠。建立深度信号背景模型检测运动幅度，建立彩色图像背景模型检测光照变化，使用事件检测算法从三类传感器处理数据中检测事件发生。

Result: 系统在睡眠条件下进行了测试，实验结果验证了系统的可靠性，能够有效检测和分类运动事件、开关灯事件和噪音事件。

Conclusion: 提出的基于事件方法的非侵入式睡眠监测系统是有效的，能够在家庭环境中可靠地定量评估睡眠障碍，为睡眠质量分析提供了实用工具。

Abstract: For quantitative evaluation of sleep disturbances, a noninvasive monitoring system is developed by introducing an event-based method. We observe sleeping in home context and classify the sleep disturbances into three types of events: motion events, light-on/off events and noise events. A device with an infrared depth sensor, a RGB camera, and a four-microphone array is used in sleep monitoring in an environment with barely light sources. One background model is established in depth signals for measuring magnitude of movements. Because depth signals cannot observe lighting changes, another background model is established in color images for measuring magnitude of lighting effects. An event detection algorithm is used to detect occurrences of events from the processed data of the three types of sensors. The system was tested in sleep condition and the experiment result validates the system reliability.

</details>


### [114] [StrokeNet: Unveiling How to Learn Fine-Grained Interactions in Online Handwritten Stroke Classification](https://arxiv.org/abs/2512.06290)
*Yiheng Huang,Shuang She,Zewei Wei,Jianmin Lin,Ming Yang,Wenyin Liu*

Main category: cs.CV

TL;DR: StrokeNet：通过参考点表示和空间查询机制解决笔画分类中细粒度语义关系建模问题的新网络架构


<details>
  <summary>Details</summary>
Motivation: 笔画分类面临书写风格变化、内容模糊和动态书写位置的挑战，核心问题在于建模笔画间的语义关系。现有深度学习方法难以捕捉局部化的笔画交互关系，而点级视角虽然能解决但会引入冗余。

Method: 提出StrokeNet，将笔画编码为参考点对表示（点+特征向量）。动态选择每个笔画的参考点并排序，使用内联序列注意力模块构建上下文特征。设计交叉椭圆查询机制聚类参考点并提取多尺度空间特征。采用联合优化框架，通过参考点回归预测笔画类别，并通过辅助分支建模相邻笔画语义转移。

Result: 在多个公开在线手写数据集上达到最先进性能。在CASIA-onDo数据集上，准确率从93.81%提升到95.54%，证明了方法的有效性和鲁棒性。

Conclusion: StrokeNet通过参考点表示和空间查询机制有效解决了笔画分类中的细粒度语义关系建模问题，显著提升了分类性能，为在线手写识别提供了新的解决方案。

Abstract: Stroke classification remains challenging due to variations in writing style, ambiguous content, and dynamic writing positions. The core challenge in stroke classification is modeling the semantic relationships between strokes. Our observations indicate that stroke interactions are typically localized, making it difficult for existing deep learning methods to capture such fine-grained relationships. Although viewing strokes from a point-level perspective can address this issue, it introduces redundancy. However, by selecting reference points and using their sequential order to represent strokes in a fine-grained manner, this problem can be effectively solved. This insight inspired StrokeNet, a novel network architecture encoding strokes as reference pair representations (points + feature vectors), where reference points enable spatial queries and features mediate interaction modeling. Specifically, we dynamically select reference points for each stroke and sequence them, employing an Inline Sequence Attention (ISA) module to construct contextual features. To capture spatial feature interactions, we devised a Cross-Ellipse Query (CEQ) mechanism that clusters reference points and extracts features across varying spatial scales. Finally, a joint optimization framework simultaneously predicts stroke categories via reference points regression and adjacent stroke semantic transition modeling through an Auxiliary Branch (Aux-Branch). Experimental results show that our method achieves state-of-the-art performance on multiple public online handwritten datasets. Notably, on the CASIA-onDo dataset, the accuracy improves from 93.81$\%$ to 95.54$\%$, demonstrating the effectiveness and robustness of our approach.

</details>


### [115] [Exploiting Spatiotemporal Properties for Efficient Event-Driven Human Pose Estimation](https://arxiv.org/abs/2512.06306)
*Haoxian Zhou,Chuanzhi Xu,Langyi Chen,Haodong Chen,Yuk Ying Chung,Qiang Qu,Xaoming Chen,Weidong Cai*

Main category: cs.CV

TL;DR: 提出基于点云框架的事件流人体姿态估计方法，通过时间切片卷积和序列建模利用事件流时空特性，在稀疏事件条件下增强边缘信息


<details>
  <summary>Details</summary>
Motivation: 现有方法将事件流转换为密集事件帧，增加了计算负担并牺牲了事件信号的高时间分辨率。需要充分利用事件流的时空特性来提高人体姿态估计性能。

Method: 基于点云框架处理事件流，设计事件时间切片卷积模块捕获短期依赖，结合事件切片序列模块进行结构化时间建模，在点云表示中应用边缘增强来改善稀疏事件条件下的空间边缘信息

Result: 在DHP19数据集上的实验表明，该方法在三种代表性点云骨干网络（PointNet、DGCNN、Point Transformer）上均能持续提升性能

Conclusion: 提出的基于点云的事件流处理方法有效利用了事件流的时空特性，避免了传统帧转换方法的计算开销，在稀疏事件条件下仍能保持良好性能

Abstract: Human pose estimation focuses on predicting body keypoints to analyze human motion. Event cameras provide high temporal resolution and low latency, enabling robust estimation under challenging conditions. However, most existing methods convert event streams into dense event frames, which adds extra computation and sacrifices the high temporal resolution of the event signal. In this work, we aim to exploit the spatiotemporal properties of event streams based on point cloud-based framework, designed to enhance human pose estimation performance. We design Event Temporal Slicing Convolution module to capture short-term dependencies across event slices, and combine it with Event Slice Sequencing module for structured temporal modeling. We also apply edge enhancement in point cloud-based event representation to enhance spatial edge information under sparse event conditions to further improve performance. Experiments on the DHP19 dataset show our proposed method consistently improves performance across three representative point cloud backbones: PointNet, DGCNN, and Point Transformer.

</details>


### [116] [ReCAD: Reinforcement Learning Enhanced Parametric CAD Model Generation with Vision-Language Models](https://arxiv.org/abs/2512.06328)
*Jiahao Li,Yusheng Luo,Yunzhong Lou,Xiangdong Zhou*

Main category: cs.CV

TL;DR: ReCAD是一个强化学习框架，利用预训练大模型的生成能力，从多模态输入生成精确的参数化CAD模型，通过参数化代码引导和分层基元学习实现几何精度和语义保真度。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖监督微调注入知识，编辑性有限，未能充分利用预训练大模型的强大生成先验。需要一种能够生成精确可编辑CAD模型的新方法。

Method: 1. 微调视觉语言模型获得基本CAD生成能力，将CAD脚本重写为参数化代码用于监督；2. 提出包含参数化代码引导的强化学习策略增强推理；3. 采用分层基元学习在统一奖励函数下逐步教授结构化组合技能。

Result: 在文本到CAD和图像到CAD任务中达到最先进水平，显著提高分布内和分布外设置的几何精度。图像到CAD任务中，平均Chamfer距离从73.47降至29.61（分布内）和从272.06降至80.23（分布外）。

Conclusion: ReCAD框架通过强化学习引导预训练大模型，成功生成精确的参数化CAD模型，充分利用了大模型的生成能力，在几何精度和语义保真度方面显著优于现有方法。

Abstract: We present ReCAD, a reinforcement learning (RL) framework that bootstraps pretrained large models (PLMs) to generate precise parametric computer-aided design (CAD) models from multimodal inputs by leveraging their inherent generative capabilities. With just access to simple functional interfaces (e.g., point coordinates), our approach enables the emergence of complex CAD operations (e.g., pattern replication and mirror). This stands in contrast to previous methods, which typically rely on knowledge injected through supervised fine-tuning (SFT), offer limited support for editability, and fail to exploit the strong generative priors of PLMs. Specifically, the ReCAD framework begins by fine-tuning vision-language models (VLMs) to equip them with basic CAD model generation capabilities, where we rewrite CAD scripts into parameterized code that is leveraged to generate accurate textual descriptions for supervision. Then, we propose a novel RL strategy that incorporates parameterized code as guidance to enhance the model's reasoning on challenging questions. Furthermore, we employ a hierarchical primitive learning process to progressively teach structured and compositional skills under a unified reward function that ensures both geometric accuracy and semantic fidelity. ReCAD sets a new state-of-the-art in both text-to-CAD and image-to-CAD tasks, significantly improving geometric accuracy across in-distribution and out-of-distribution settings. In the image-to-CAD task, for instance, it reduces the mean Chamfer Distance from 73.47 to 29.61 (in-distribution) and from 272.06 to 80.23 (out-of-distribution), outperforming existing baselines by a substantial margin.

</details>


### [117] [S2WMamba: A Spectral-Spatial Wavelet Mamba for Pansharpening](https://arxiv.org/abs/2512.06330)
*Haoyu Zhang,Junhan Luo,Yugang Cao,Siran Peng,Jie Huang,Liangjian-Deng*

Main category: cs.CV

TL;DR: S2WMamba提出了一种基于频率解耦的遥感图像融合方法，通过2D/1D小波变换分离空间和光谱信息，采用Mamba进行跨模态交互，实现了高质量的Pansharpening融合。


<details>
  <summary>Details</summary>
Motivation: 传统Pansharpening方法在处理高分辨率全色图像(PAN)和低分辨率多光谱图像(LRMS)时，往往难以平衡空间细节和光谱保真度，导致信息纠缠问题。

Method: 1) 使用2D Haar DWT处理PAN图像以提取空间边缘和纹理；2) 使用通道级1D Haar DWT处理每个像素的光谱作为1D信号，分离低频/高频分量；3) 建立光谱分支和空间分支，通过Mamba-based跨调制进行信息交换；4) 采用多尺度动态门(乘法和加法)自适应融合分支输出。

Result: 在WV3、GF2和QB数据集上，S2WMamba匹配或超越了FusionMamba、CANNet、U2Net、ARConv等基线方法，PSNR最高提升0.23 dB，在WV3全分辨率上达到HQNR 0.956。

Conclusion: S2WMamba通过频率解耦和轻量级跨模态交互，有效解决了Pansharpening中的空间-光谱纠缠问题，实现了高质量的图像融合，消融实验验证了方法设计的有效性。

Abstract: Pansharpening fuses a high-resolution PAN image with a low-resolution multispectral (LRMS) image to produce an HRMS image. A key difficulty is that jointly processing PAN and MS often entangles spatial detail with spectral fidelity. We propose S2WMamba, which explicitly disentangles frequency information and then performs lightweight cross-modal interaction. Concretely, a 2D Haar DWT is applied to PAN to localize spatial edges and textures, while a channel-wise 1D Haar DWT treats each pixel's spectrum as a 1D signal to separate low/high-frequency components and limit spectral distortion. The resulting Spectral branch injects wavelet-extracted spatial details into MS features, and the Spatial branch refines PAN features using spectra from the 1D pyramid; the two branches exchange information through Mamba-based cross-modulation that models long-range dependencies with linear complexity. A multi-scale dynamic gate (multiplicative + additive) then adaptively fuses branch outputs.On WV3, GF2, and QB, S2WMamba matches or surpasses recent strong baselines (FusionMamba, CANNet, U2Net, ARConv), improving PSNR by up to 0.23 dB and reaching HQNR 0.956 on full-resolution WV3. Ablations justify the choice of 2D/1D DWT placement, parallel dual branches, and the fusion gate. Our code is available at https://github.com/KagUYa66/S2WMamba.

</details>


### [118] [CryoHype: Reconstructing a thousand cryo-EM structures with transformer-based hypernetworks](https://arxiv.org/abs/2512.06332)
*Jeffrey Gu,Minkyu Jeon,Ambri Ma,Serena Yeung-Levy,Ellen D. Zhong*

Main category: cs.CV

TL;DR: CryoHype：基于Transformer的超网络，用于从混合样本中重建多种分子结构


<details>
  <summary>Details</summary>
Motivation: 现有冷冻电镜方法主要关注单个或少数结构的构象异质性，无法有效解决由多种不同分子物种混合引起的组成异质性，限制了高通量结构测定的潜力。

Method: 提出CryoHype，一种基于Transformer的超网络，动态调整隐式神经表示的权重，用于从混合样本中重建多种分子结构。

Result: 在包含100个结构的基准数据集上取得最先进结果，并能在固定姿态设置下从无标签冷冻电镜图像中重建1000个不同结构。

Conclusion: CryoHype能够有效解决冷冻电镜中的组成异质性问题，实现高通量多目标结构测定，为大规模结构生物学研究提供了新工具。

Abstract: Cryo-electron microscopy (cryo-EM) is an indispensable technique for determining the 3D structures of dynamic biomolecular complexes. While typically applied to image a single molecular species, cryo-EM has the potential for structure determination of many targets simultaneously in a high-throughput fashion. However, existing methods typically focus on modeling conformational heterogeneity within a single or a few structures and are not designed to resolve compositional heterogeneity arising from mixtures of many distinct molecular species. To address this challenge, we propose CryoHype, a transformer-based hypernetwork for cryo-EM reconstruction that dynamically adjusts the weights of an implicit neural representation. Using CryoHype, we achieve state-of-the-art results on a challenging benchmark dataset containing 100 structures. We further demonstrate that CryoHype scales to the reconstruction of 1,000 distinct structures from unlabeled cryo-EM images in the fixed-pose setting.

</details>


### [119] [Beyond Hallucinations: A Multimodal-Guided Task-Aware Generative Image Compression for Ultra-Low Bitrate](https://arxiv.org/abs/2512.06344)
*Kaile Wang,Lijun He,Haisheng Fu,Haixia Bi,Fan Li*

Main category: cs.CV

TL;DR: MTGC提出了一种多模态引导的任务感知生成图像压缩框架，通过文本、压缩图像和语义伪词三种引导模态，在超低比特率下提升语义一致性和重建质量。


<details>
  <summary>Details</summary>
Motivation: 生成式图像压缩在超低比特率下存在语义偏差问题，限制了其在6G语义通信中的可靠部署。需要解决生成幻觉导致的语义不一致问题。

Method: 1) 集成三种引导模态：文本描述（全局语义）、高度压缩图像（低层视觉信息）、语义伪词（细粒度任务相关语义）；2) 设计任务感知语义压缩模块生成SPWs；3) 设计多模态引导扩散解码器，采用双路径协同引导机制将三种模态注入扩散过程。

Result: 在超低比特率下显著提升语义一致性（如DIV2K数据集上DISTS下降10.59%），同时在感知质量和像素级保真度方面也取得显著提升。

Conclusion: MTGC框架通过多模态引导和任务感知设计，有效解决了超低比特率下生成式图像压缩的语义偏差问题，为6G语义通信提供了可靠的图像压缩方案。

Abstract: Generative image compression has recently shown impressive perceptual quality, but often suffers from semantic deviations caused by generative hallucinations at ultra-low bitrate (bpp < 0.05), limiting its reliable deployment in bandwidth-constrained 6G semantic communication scenarios. In this work, we reassess the positioning and role of of multimodal guidance, and propose a Multimodal-Guided Task-Aware Generative Image Compression (MTGC) framework. Specifically, MTGC integrates three guidance modalities to enhance semantic consistency: a concise but robust text caption for global semantics, a highly compressed image (HCI) retaining low-level visual information, and Semantic Pseudo-Words (SPWs) for fine-grained task-relevant semantics. The SPWs are generated by our designed Task-Aware Semantic Compression Module (TASCM), which operates in a task-oriented manner to drive the multi-head self-attention mechanism to focus on and extract semantics relevant to the generation task while filtering out redundancy. Subsequently, to facilitate the synergistic guidance of these modalities, we design a Multimodal-Guided Diffusion Decoder (MGDD) employing a dual-path cooperative guidance mechanism that synergizes cross-attention and ControlNet additive residuals to precisely inject these three guidance into the diffusion process, and leverages the diffusion model's powerful generative priors to reconstruct the image. Extensive experiments demonstrate that MTGC consistently improves semantic consistency (e.g., DISTS drops by 10.59% on the DIV2K dataset) while also achieving remarkable gains in perceptual quality and pixel-level fidelity at ultra-low bitrate.

</details>


### [120] [CLUENet: Cluster Attention Makes Neural Networks Have Eyes](https://arxiv.org/abs/2512.06345)
*Xiangshuai Song,Jun-Jie Huang,Tianrui Liu,Ke Liang,Chang Tang*

Main category: cs.CV

TL;DR: CLUENet：一种基于聚类范式的透明深度架构，通过全局软聚合硬分配、温度缩放余弦注意力、门控残差连接、硬共享特征分发和改进的聚类池化策略，在视觉语义理解任务中实现了准确性、效率和可解释性的平衡。


<details>
  <summary>Details</summary>
Motivation: 卷积和注意力模型在视觉任务中虽然成功，但其固定的感受野和复杂架构限制了不规则空间模式建模能力，且可解释性不足。聚类范式虽有良好的可解释性和灵活语义建模能力，但存在精度有限、效率低下和训练梯度消失等问题。

Method: 提出CLUENet架构，包含三个关键创新：1) 全局软聚合硬分配机制，采用温度缩放余弦注意力和门控残差连接增强局部建模；2) 块间硬共享特征分发策略；3) 改进的聚类池化策略。

Result: 在CIFAR-100和Mini-ImageNet数据集上的实验表明，CLUENet超越了现有聚类方法和主流视觉模型，在分类性能和视觉可解释性方面均有显著提升。

Conclusion: CLUENet为视觉语义理解提供了一种透明深度架构，在准确性、效率和可解释性之间取得了良好平衡，为解决传统模型在可解释性和不规则模式建模方面的局限性提供了新思路。

Abstract: Despite the success of convolution- and attention-based models in vision tasks, their rigid receptive fields and complex architectures limit their ability to model irregular spatial patterns and hinder interpretability, therefore posing challenges for tasks requiring high model transparency. Clustering paradigms offer promising interpretability and flexible semantic modeling, but suffer from limited accuracy, low efficiency, and gradient vanishing during training. To address these issues, we propose CLUster attEntion Network (CLUENet), an transparent deep architecture for visual semantic understanding. We propose three key innovations include (i) a Global Soft Aggregation and Hard Assignment with a Temperature-Scaled Cosin Attention and gated residual connections for enhanced local modeling, (ii) inter-block Hard and Shared Feature Dispatching, and (iii) an improved cluster pooling strategy. These enhancements significantly improve both classification performance and visual interpretability. Experiments on CIFAR-100 and Mini-ImageNet demonstrate that CLUENet outperforms existing clustering methods and mainstream visual models, offering a compelling balance of accuracy, efficiency, and transparency.

</details>


### [121] [TreeQ: Pushing the Quantization Boundary of Diffusion Transformer via Tree-Structured Mixed-Precision Search](https://arxiv.org/abs/2512.06353)
*Kaicheng Yang,Kaisen Yang,Baiting Wu,Xun Zhang,Qianrui Yang,Haotong Qin,He Zhang,Yulun Zhang*

Main category: cs.CV

TL;DR: TreeQ是一个统一的DiT量化框架，通过树结构搜索、环境噪声引导和通用Monarch分支解决DiT量化中的关键挑战，在超低比特设置下实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器(DiTs)在图像生成中表现出色，但计算和内存需求高，实际部署困难。混合精度量化(MPQ)在U-Net上成功实现了亚4比特量化，但在DiT架构中的应用有限且未充分探索。

Method: 1. 树结构搜索(TSS)：利用DiT的线性特性在O(n)时间内遍历解空间，通过比较剪枝提高目标精度；2. 环境噪声引导(ENG)：使用单一超参数对齐PTQ和QAT配置；3. 通用Monarch分支(GMB)：结构化稀疏分支防止超低比特下的信息瓶颈。

Result: 在DiT-XL/2的W3A3和W4A4 PTQ/PEFT设置下实现最先进性能，首次在DiT模型上实现接近无损的4比特PTQ性能。

Conclusion: TreeQ框架有效解决了DiT量化的关键挑战，实现了高效的超低比特量化，为DiT的实际部署提供了可行方案。

Abstract: Diffusion Transformers (DiTs) have emerged as a highly scalable and effective backbone for image generation, outperforming U-Net architectures in both scalability and performance. However, their real-world deployment remains challenging due to high computational and memory demands. Mixed-Precision Quantization (MPQ), designed to push the limits of quantization, has demonstrated remarkable success in advancing U-Net quantization to sub-4bit settings while significantly reducing computational and memory overhead. Nevertheless, its application to DiT architectures remains limited and underexplored. In this work, we propose TreeQ, a unified framework addressing key challenges in DiT quantization. First, to tackle inefficient search and proxy misalignment, we introduce Tree Structured Search (TSS). This DiT-specific approach leverages the architecture's linear properties to traverse the solution space in O(n) time while improving objective accuracy through comparison-based pruning. Second, to unify optimization objectives, we propose Environmental Noise Guidance (ENG), which aligns Post-Training Quantization (PTQ) and Quantization-Aware Training (QAT) configurations using a single hyperparameter. Third, to mitigate information bottlenecks in ultra-low-bit regimes, we design the General Monarch Branch (GMB). This structured sparse branch prevents irreversible information loss, enabling finer detail generation. Through extensive experiments, our TreeQ framework demonstrates state-of-the-art performance on DiT-XL/2 under W3A3 and W4A4 PTQ/PEFT settings. Notably, our work is the first to achieve near-lossless 4-bit PTQ performance on DiT models. The code and models will be available at https://github.com/racoonykc/TreeQ

</details>


### [122] [Rectifying Latent Space for Generative Single-Image Reflection Removal](https://arxiv.org/abs/2512.06358)
*Mingjia Li,Jin Hu,Hainuo Wang,Qiming Hu,Jiarui Wang,Xiaojie Guo*

Main category: cs.CV

TL;DR: 本文提出了一种基于潜在扩散模型的单图像反射去除方法，通过反射等变VAE、可学习任务特定文本嵌入和深度引导早期分支采样策略，显著提升了反射去除的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 单图像反射去除是一个高度不适定问题，现有方法难以推理被破坏区域的组成，导致在真实场景中恢复和泛化能力不足。本文发现问题的关键在于语义编码器的潜在空间缺乏解释复合图像作为其组成层线性叠加的内在结构。

Method: 方法包含三个协同组件：1) 反射等变VAE，将潜在空间与反射形成的线性物理对齐；2) 可学习任务特定文本嵌入，提供精确指导并绕过模糊语言；3) 深度引导早期分支采样策略，利用生成随机性获得有希望的结果。

Result: 在多个基准测试中实现了新的SOTA性能，并且在具有挑战性的真实世界案例中表现出良好的泛化能力。

Conclusion: 通过重新构建编辑目的的潜在扩散模型，使其能够有效感知和处理高度模糊的分层图像输入，从而产生高质量的输出，解决了单图像反射去除中的关键挑战。

Abstract: Single-image reflection removal is a highly ill-posed problem, where existing methods struggle to reason about the composition of corrupted regions, causing them to fail at recovery and generalization in the wild. This work reframes an editing-purpose latent diffusion model to effectively perceive and process highly ambiguous, layered image inputs, yielding high-quality outputs. We argue that the challenge of this conversion stems from a critical yet overlooked issue, i.e., the latent space of semantic encoders lacks the inherent structure to interpret a composite image as a linear superposition of its constituent layers. Our approach is built on three synergistic components, including a reflection-equivariant VAE that aligns the latent space with the linear physics of reflection formation, a learnable task-specific text embedding for precise guidance that bypasses ambiguous language, and a depth-guided early-branching sampling strategy to harness generative stochasticity for promising results. Extensive experiments reveal that our model achieves new SOTA performance on multiple benchmarks and generalizes well to challenging real-world cases.

</details>


### [123] [Spoofing-aware Prompt Learning for Unified Physical-Digital Facial Attack Detection](https://arxiv.org/abs/2512.06363)
*Jiabao Guo,Yadian Wang,Hui Ma,Yuhao Fu,Ju Jia,Hui Liu,Shengeng Tang,Lechao Cheng,Yunfeng Diao,Ajian Liu*

Main category: cs.CV

TL;DR: 提出SPL-UAD框架，通过解耦物理攻击和数字攻击的优化分支，解决统一攻击检测中的优化冲突问题，提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现实人脸识别系统同时面临物理呈现攻击和数字伪造攻击的双重威胁，现有方法使用CLIP加正则化约束，但物理和数字攻击检测在同一提示空间下存在优化方向冲突。

Method: 提出SPL-UAD框架：1）构建可学习的并行提示分支，通过自适应欺骗上下文提示生成实现物理和数字攻击的独立优化控制；2）设计线索感知增强，利用双提示机制生成具有挑战性的样本挖掘任务。

Result: 在大型UniAttackDataPlus数据集上的实验表明，该方法在统一攻击检测任务中取得了显著的性能提升。

Conclusion: SPL-UAD框架通过解耦优化分支有效解决了物理和数字攻击检测的冲突问题，增强了模型对未见攻击类型的鲁棒性，实现了更全面的生物特征数据保护。

Abstract: Real-world face recognition systems are vulnerable to both physical presentation attacks (PAs) and digital forgery attacks (DFs). We aim to achieve comprehensive protection of biometric data by implementing a unified physical-digital defense framework with advanced detection. Existing approaches primarily employ CLIP with regularization constraints to enhance model generalization across both tasks. However, these methods suffer from conflicting optimization directions between physical and digital attack detection under same category prompt spaces. To overcome this limitation, we propose a Spoofing-aware Prompt Learning for Unified Attack Detection (SPL-UAD) framework, which decouples optimization branches for physical and digital attacks in the prompt space. Specifically, we construct a learnable parallel prompt branch enhanced with adaptive Spoofing Context Prompt Generation, enabling independent control of optimization for each attack type. Furthermore, we design a Cues-awareness Augmentation that leverages the dual-prompt mechanism to generate challenging sample mining tasks on data, significantly enhancing the model's robustness against unseen attack types. Extensive experiments on the large-scale UniAttackDataPlus dataset demonstrate that the proposed method achieves significant performance improvements in unified attack detection tasks.

</details>


### [124] [Human3R: Incorporating Human Priors for Better 3D Dynamic Reconstruction from Monocular Videos](https://arxiv.org/abs/2512.06368)
*Weitao Xiong,Zhiyuan Yuan,Jiahao Lu,Chengfeng Zhao,Peng Li,Yuan Liu*

Main category: cs.CV

TL;DR: 提出Human3R方法，通过结合SMPL人体模型和单目深度估计的混合几何先验，解决动态人体场景重建中的几何不一致和分辨率退化问题。


<details>
  <summary>Details</summary>
Motivation: 单目动态视频重建在动态人体场景中面临几何不一致和分辨率退化的挑战。现有方法缺乏3D人体结构理解，导致几何不一致的结果（肢体比例扭曲、人-物融合不自然），同时内存限制的下采样导致人体边界向背景几何漂移。

Method: 提出Human3R方法，采用分层处理流程：1) 处理全分辨率图像获取整体场景几何；2) 通过策略性裁剪和交叉注意力融合增强人体特定细节；3) 通过特征融合模块集成SMPL先验，确保几何合理重建同时保留细粒度人体边界。

Result: 在TUM Dynamics和GTA-IM数据集上的广泛实验表明，该方法在动态人体重建方面具有优越性能。

Conclusion: 通过结合SMPL人体模型和单目深度估计的混合几何先验，Human3R方法有效解决了动态人体场景重建中的几何不一致和分辨率退化问题，实现了更准确和自然的动态人体重建。

Abstract: Monocular dynamic video reconstruction faces significant challenges in dynamic human scenes due to geometric inconsistencies and resolution degradation issues. Existing methods lack 3D human structural understanding, producing geometrically inconsistent results with distorted limb proportions and unnatural human-object fusion, while memory-constrained downsampling causes human boundary drift toward background geometry. To address these limitations, we propose to incorporate hybrid geometric priors that combine SMPL human body models with monocular depth estimation. Our approach leverages structured human priors to maintain surface consistency while capturing fine-grained geometric details in human regions. We introduce Human3R, featuring a hierarchical pipeline with refinement components that processes full-resolution images for overall scene geometry, then applies strategic cropping and cross-attention fusion for human-specific detail enhancement. The method integrates SMPL priors through a Feature Fusion Module to ensure geometrically plausible reconstruction while preserving fine-grained human boundaries. Extensive experiments on TUM Dynamics and GTA-IM datasets demonstrate superior performance in dynamic human reconstruction.

</details>


### [125] [VG-Refiner: Towards Tool-Refined Referring Grounded Reasoning via Agentic Reinforcement Learning](https://arxiv.org/abs/2512.06373)
*Yuji Wang,Wenlong Liu,Jingxuan Niu,Haoji Zhang,Yansong Tang*

Main category: cs.CV

TL;DR: VG-Refiner：首个工具精炼的指代接地推理框架，通过两阶段"思考-再思考"机制和精炼奖励，解决现有TiVR模型对不可靠工具输出的处理不足问题


<details>
  <summary>Details</summary>
Motivation: 现有工具集成视觉推理（TiVR）范式主要关注通过强化学习集成各种视觉工具，但缺乏处理不可靠或错误工具输出的有效响应机制。这在指代和接地任务中尤为突出，不准确的检测工具预测常常误导TiVR模型产生幻觉推理。

Method: 提出VG-Refiner框架，采用两阶段"思考-再思考"机制，使模型能够显式分析和响应工具反馈；引入精炼奖励，鼓励对不良工具结果进行有效修正；提出两个新指标和公平评估协议来系统衡量模型的精炼能力。

Result: 使用少量任务特定数据增强VG-Refiner的精炼能力，在指代和推理接地基准测试中实现了准确性和修正能力的显著提升，同时保留了预训练模型的通用能力。

Conclusion: VG-Refiner是首个针对工具精炼指代接地推理的框架，通过显式处理工具反馈和精炼机制，有效解决了TiVR模型在处理不可靠工具输出时的局限性，为视觉推理系统提供了更可靠的解决方案。

Abstract: Tool-integrated visual reasoning (TiVR) has demonstrated great potential in enhancing multimodal problem-solving. However, existing TiVR paradigms mainly focus on integrating various visual tools through reinforcement learning, while neglecting to design effective response mechanisms for handling unreliable or erroneous tool outputs. This limitation is particularly pronounced in referring and grounding tasks, where inaccurate detection tool predictions often mislead TiVR models into generating hallucinated reasoning. To address this issue, we propose the VG-Refiner, the first framework aiming at the tool-refined referring grounded reasoning. Technically, we introduce a two-stage think-rethink mechanism that enables the model to explicitly analyze and respond to tool feedback, along with a refinement reward that encourages effective correction in response to poor tool results. In addition, we propose two new metrics and establish fair evaluation protocols to systematically measure the refinement ability of current models. We adopt a small amount of task-specific data to enhance the refinement capability of VG-Refiner, achieving a significant improvement in accuracy and correction ability on referring and reasoning grounding benchmarks while preserving the general capabilities of the pretrained model.

</details>


### [126] [Are AI-Generated Driving Videos Ready for Autonomous Driving? A Diagnostic Evaluation Framework](https://arxiv.org/abs/2512.06376)
*Xinhao Xiang,Abhijeet Rastogi,Jiawei Zhang*

Main category: cs.CV

TL;DR: 论文研究了AI生成驾驶视频(AIGV)在自动驾驶模型训练和评估中的可靠性，提出了诊断框架、质量评估方法和过滤工具，发现原始AIGV会降低感知性能，但经过过滤后可以成为真实数据的有效补充。


<details>
  <summary>Details</summary>
Motivation: 文本到视频模型能够生成高分辨率驾驶场景，为自动驾驶提供了低成本、可扩展的数据替代方案。但关键问题是：这些AI生成的驾驶视频能否可靠地支持自动驾驶模型的训练和评估？

Method: 1. 提出AIGV常见故障模式的分类法（视觉伪影、物理上不可能的运动、交通语义违规）；2. 构建ADGV-Bench基准测试，包含人工质量标注和多感知任务的密集标签；3. 提出ADGVE评估器，结合静态语义、时序线索、车道遵守信号和VLM引导推理，为每个视频片段生成单一质量评分。

Result: 实验表明：盲目添加原始AIGV会降低感知性能，但使用ADGVE过滤后，不仅能改善通用视频质量评估指标，还能提升下游自动驾驶模型性能，使AIGV成为真实世界数据的有益补充。

Conclusion: 研究揭示了AIGV在自动驾驶应用中的风险和潜力，提供了在实际自动驾驶流程中安全利用大规模视频生成的实用工具，强调了适当过滤的重要性。

Abstract: Recent text-to-video models have enabled the generation of high-resolution driving scenes from natural language prompts. These AI-generated driving videos (AIGVs) offer a low-cost, scalable alternative to real or simulator data for autonomous driving (AD). But a key question remains: can such videos reliably support training and evaluation of AD models? We present a diagnostic framework that systematically studies this question. First, we introduce a taxonomy of frequent AIGV failure modes, including visual artifacts, physically implausible motion, and violations of traffic semantics, and demonstrate their negative impact on object detection, tracking, and instance segmentation. To support this analysis, we build ADGV-Bench, a driving-focused benchmark with human quality annotations and dense labels for multiple perception tasks. We then propose ADGVE, a driving-aware evaluator that combines static semantics, temporal cues, lane obedience signals, and Vision-Language Model(VLM)-guided reasoning into a single quality score for each clip. Experiments show that blindly adding raw AIGVs can degrade perception performance, while filtering them with ADGVE consistently improves both general video quality assessment metrics and downstream AD models, and turns AIGVs into a beneficial complement to real-world data. Our study highlights both the risks and the promise of AIGVs, and provides practical tools for safely leveraging large-scale video generation in future AD pipelines.

</details>


### [127] [VAD-Net: Multidimensional Facial Expression Recognition in Intelligent Education System](https://arxiv.org/abs/2512.06377)
*Yi Huo,Yun Ge*

Main category: cs.CV

TL;DR: 该研究为FER2013数据集添加了VAD（效价-唤醒度-支配度）三维情感标注，特别是首次标注了D维度，并采用正交卷积提升网络性能，构建了VAD情感预测的基准数据集和模型。


<details>
  <summary>Details</summary>
Motivation: 当前FER数据集主要基于离散情感类别（如高兴、愤怒等），表达能力有限。未来情感计算需要更全面精确的VAD多维参数度量，但现有数据集（如AffectNet）缺少D维度标注。

Method: 1. 为FER2013数据集手动标注VAD三维情感参数，特别是首次标注D维度；2. 在基于ResNet的回归网络中引入正交卷积，提取更多样化和表达性强的特征，提升VAD预测能力。

Result: 1. D维度可以被测量，但相比V和A维度更难获取（无论是人工标注还是网络预测）；2. 正交卷积的消融实验验证了其能获得更好的VAD预测效果；3. 构建了首个VAD标注的FER2013基准数据集和基于ResNet的正交化回归网络基线模型。

Conclusion: 该研究填补了FER数据集D维度标注的空白，提出的正交卷积网络提升了VAD预测性能，为多维情感计算提供了新的基准数据集和基线模型，代码和数据集已开源。

Abstract: Current FER (Facial Expression Recognition) dataset is mostly labeled by emotion categories, such as happy, angry, sad, fear, disgust, surprise, and neutral which are limited in expressiveness. However, future affective computing requires more comprehensive and precise emotion metrics which could be measured by VAD(Valence-Arousal-Dominance) multidimension parameters. To address this, AffectNet has tried to add VA (Valence and Arousal) information, but still lacks D(Dominance). Thus, the research introduces VAD annotation on FER2013 dataset, takes the initiative to label D(Dominance) dimension. Then, to further improve network capacity, it enforces orthogonalized convolution on it, which extracts more diverse and expressive features and will finally increase the prediction accuracy. Experiment results show that D dimension could be measured but is difficult to obtain compared with V and A dimension no matter in manual annotation or regression network prediction. Secondly, the ablation test by introducing orthogonal convolution verifies that better VAD prediction could be obtained in the configuration of orthogonal convolution. Therefore, the research provides an initiative labelling for D dimension on FER dataset, and proposes a better prediction network for VAD prediction through orthogonal convolution. The newly built VAD annotated FER2013 dataset could act as a benchmark to measure VAD multidimensional emotions, while the orthogonalized regression network based on ResNet could act as the facial expression recognition baseline for VAD emotion prediction. The newly labeled dataset and implementation code is publicly available on https://github.com/YeeHoran/VAD-Net .

</details>


### [128] [OCFER-Net: Recognizing Facial Expression in Online Learning System](https://arxiv.org/abs/2512.06379)
*Yi Huo,Lei Zhang*

Main category: cs.CV

TL;DR: 提出OCFER-Net，通过正交性正则化提升卷积核多样性，在FER-2013数据集上表现优于基线方法1.087个点


<details>
  <summary>Details</summary>
Motivation: 在线学习中情感交互很重要，而面部表情识别（FER）的准确性对教师了解学生情绪状态至关重要。现有FER方法很少利用卷积矩阵的正交性，正交性可以提取更多样化和表达力强的特征。

Method: 通过正则化强制卷积核的正交性，提出OCFER-Net网络架构，在卷积层中引入正交约束以增强特征多样性。

Result: 在具有挑战性的FER-2013数据集上进行实验，结果显示OCFER-Net相比基线方法有1.087的性能提升。

Conclusion: 正交性正则化能有效提升FER性能，OCFER-Net在面部表情识别任务中表现出优越性能，代码已开源。

Abstract: Recently, online learning is very popular, especially under the global epidemic of COVID-19. Besides knowledge distribution, emotion interaction is also very important. It can be obtained by employing Facial Expression Recognition (FER). Since the FER accuracy is substantial in assisting teachers to acquire the emotional situation, the project explores a series of FER methods and finds that few works engage in exploiting the orthogonality of convolutional matrix. Therefore, it enforces orthogonality on kernels by a regularizer, which extracts features with more diversity and expressiveness, and delivers OCFER-Net. Experiments are carried out on FER-2013, which is a challenging dataset. Results show superior performance over baselines by 1.087. The code of the research project is publicly available on https://github.com/YeeHoran/OCFERNet.

</details>


### [129] [Perceptual Region-Driven Infrared-Visible Co-Fusion for Extreme Scene Enhancement](https://arxiv.org/abs/2512.06400)
*Jing Tao,Yonghong Zong,Banglei Guana,Pengju Sun,Taihang Lei,Yang Shanga,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出基于区域感知的红外与可见光图像融合框架，使用空间可变曝光相机结合多曝光与多模态成像，在极端环境下保持可见光几何精度并融合热辐射信息。


<details>
  <summary>Details</summary>
Motivation: 现有方法在融合红外与可见光谱时，往往牺牲可见光图像质量，影响测量精度，特别是在极端环境下难以同时保持几何保真度和热辐射信息。

Method: 采用区域感知融合框架，结合空间可变曝光相机进行多曝光多模态成像。首先进行基于区域感知的特征融合确保精确配准，然后进行自适应融合与对比度增强，并通过区域显著性图引导的结构相似性补偿机制优化光谱融合。

Result: 在合成和真实数据上的实验表明，该方法在图像清晰度和性能指标上均优于现有方法，定量和视觉评估都证明了其优越性。

Conclusion: 提出的区域感知融合框架能有效解决红外与可见光图像融合中的几何保真度问题，在极端环境下保持可见光质量的同时成功融合热辐射信息，具有实际应用价值。

Abstract: In photogrammetry, accurately fusing infrared (IR) and visible (VIS) spectra while preserving the geometric fidelity of visible features and incorporating thermal radiation is a significant challenge, particularly under extreme conditions. Existing methods often compromise visible imagery quality, impacting measurement accuracy. To solve this, we propose a region perception-based fusion framework that combines multi-exposure and multi-modal imaging using a spatially varying exposure (SVE) camera. This framework co-fuses multi-modal and multi-exposure data, overcoming single-exposure method limitations in extreme environments. The framework begins with region perception-based feature fusion to ensure precise multi-modal registration, followed by adaptive fusion with contrast enhancement. A structural similarity compensation mechanism, guided by regional saliency maps, optimizes IR-VIS spectral integration. Moreover, the framework adapts to single-exposure scenarios for robust fusion across different conditions. Experiments conducted on both synthetic and real-world data demonstrate superior image clarity and improved performance compared to state-of-the-art methods, as evidenced by both quantitative and visual evaluations.

</details>


### [130] [Rethinking Training Dynamics in Scale-wise Autoregressive Generation](https://arxiv.org/abs/2512.06421)
*Gengze Zhou,Chongjian Ge,Hao Tan,Feng Liu,Yicong Hong*

Main category: cs.CV

TL;DR: 提出Self-Autoregressive Refinement (SAR)方法，通过Stagger-Scale Rollout和Contrastive Student-Forcing Loss解决自回归模型中尺度预测的暴露偏差问题，显著提升生成质量且计算开销小。


<details>
  <summary>Details</summary>
Motivation: 自回归生成模型在媒体合成中表现出强大能力，但尺度预测模型存在暴露偏差问题，影响生成质量。主要原因是训练-测试不匹配和尺度学习难度不平衡。

Method: 提出SAR方法：1) Stagger-Scale Rollout机制进行轻量级自回归展开，使模型接触自身中间预测以对齐训练测试模式；2) Contrastive Student-Forcing Loss为自生成上下文提供充分监督以确保训练稳定。

Result: SAR应用于预训练AR模型能一致提升生成质量，计算开销小。例如，在ImageNet 256上训练的FlexVAR-d16模型，SAR在10个epoch内（32xA100 GPU上5小时）实现5.2% FID降低。

Conclusion: SAR因其高效性、可扩展性和有效性，有望成为视觉自回归生成的可靠后训练方法。

Abstract: Recent advances in autoregressive (AR) generative models have produced increasingly powerful systems for media synthesis. Among them, next-scale prediction has emerged as a popular paradigm, where models generate images in a coarse-to-fine manner. However, scale-wise AR models suffer from exposure bias, which undermines generation quality. We identify two primary causes of this issue: (1) train-test mismatch, where the model must rely on its own imperfect predictions during inference, and (2) imbalance in scale-wise learning difficulty, where certain scales exhibit disproportionately higher optimization complexity. Through a comprehensive analysis of training dynamics, we propose Self-Autoregressive Refinement (SAR) to address these limitations. SAR introduces a Stagger-Scale Rollout (SSR) mechanism that performs lightweight autoregressive rollouts to expose the model to its own intermediate predictions, thereby aligning train-test patterns, and a complementary Contrastive Student-Forcing Loss (CSFL) that provides adequate supervision for self-generated contexts to ensure stable training. Experimental results show that applying SAR to pretrained AR models consistently improves generation quality with minimal computational overhead. For instance, SAR yields a 5.2% FID reduction on FlexVAR-d16 trained on ImageNet 256 within 10 epochs (5 hours on 32xA100 GPUs). Given its efficiency, scalability, and effectiveness, we expect SAR to serve as a reliable post-training method for visual autoregressive generation.

</details>


### [131] [A Perception CNN for Facial Expression Recognition](https://arxiv.org/abs/2512.06422)
*Chunwei Tian,Jingyuan Xie,Lingjun Li,Wangmeng Zuo,Yanning Zhang,David Zhang*

Main category: cs.CV

TL;DR: 提出感知CNN（PCNN）用于面部表情识别，通过五个并行网络学习局部面部特征，结合多域交互机制融合局部器官特征与全局结构特征，使用两阶段损失函数保证性能。


<details>
  <summary>Details</summary>
Motivation: 传统CNN可能忽略面部分割对面部表情识别的影响，需要更好地捕捉面部细微变化并融合局部与全局特征。

Method: 1. 使用五个并行网络分别学习眼睛、脸颊和嘴巴等局部特征；2. 采用多域交互机制注册和融合局部器官特征与全局面部结构特征；3. 设计两阶段损失函数约束感知信息准确性和重建面部图像质量。

Result: PCNN在多个实验室和真实世界FER基准数据集（CK+, JAFFE, FER2013, FERPlus, RAF-DB和Occlusion and Pose Variant Dataset）上取得了优越结果。

Conclusion: PCNN通过并行学习局部特征、多域特征融合和两阶段损失函数，有效提升了面部表情识别的性能。

Abstract: Convolutional neural networks (CNNs) can automatically learn data patterns to express face images for facial expression recognition (FER). However, they may ignore effect of facial segmentation of FER. In this paper, we propose a perception CNN for FER as well as PCNN. Firstly, PCNN can use five parallel networks to simultaneously learn local facial features based on eyes, cheeks and mouth to realize the sensitive capture of the subtle changes in FER. Secondly, we utilize a multi-domain interaction mechanism to register and fuse between local sense organ features and global facial structural features to better express face images for FER. Finally, we design a two-phase loss function to restrict accuracy of obtained sense information and reconstructed face images to guarantee performance of obtained PCNN in FER. Experimental results show that our PCNN achieves superior results on several lab and real-world FER benchmarks: CK+, JAFFE, FER2013, FERPlus, RAF-DB and Occlusion and Pose Variant Dataset. Its code is available at https://github.com/hellloxiaotian/PCNN.

</details>


### [132] [DragMesh: Interactive 3D Generation Made Easy](https://arxiv.org/abs/2512.06424)
*Tianshan Zhang,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: DragMesh是一个实时交互式3D关节运动生成框架，通过解耦的动力学推理和运动生成方法，结合双四元数VAE和FiLM条件注入，实现物理一致且实时的物体关节运动生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在关节运动生成上存在矛盾：要么物理一致但速度慢无法实时使用，要么生成速度快但违反基本动力学约束。需要一种既能保持物理一致性又能实时交互的解决方案。

Method: 1. 解耦的动力学推理框架：先通过语义意图推理确定关节类型，再通过Kinematics Prediction Network（KPP-Net）进行几何回归确定轴和原点
2. 开发Dual Quaternion VAE（DQ-VAE）：利用双四元数的紧凑、连续、无奇异性特性表示刚体运动
3. FiLM条件注入：在DQ-VAE的非自回归Transformer解码器的每一层注入关节先验
4. 数值稳定的叉积损失：保证轴对齐

Result: DragMesh实现了实时性能，能够在无需重新训练的情况下对新颖物体进行合理的生成式关节运动，为生成式3D智能提供了实用步骤。

Conclusion: DragMesh通过解耦的动力学推理和运动生成框架，结合双四元数表示和FiLM条件注入，解决了实时交互式3D关节运动生成的挑战，在保持物理一致性的同时实现了实时性能。

Abstract: While generative models have excelled at creating static 3D content, the pursuit of systems that understand how objects move and respond to interactions remains a fundamental challenge. Current methods for articulated motion lie at a crossroads: they are either physically consistent but too slow for real-time use, or generative but violate basic kinematic constraints. We present DragMesh, a robust framework for real-time interactive 3D articulation built around a lightweight motion generation core. Our core contribution is a novel decoupled kinematic reasoning and motion generation framework. First, we infer the latent joint parameters by decoupling semantic intent reasoning (which determines the joint type) from geometric regression (which determines the axis and origin using our Kinematics Prediction Network (KPP-Net)). Second, to leverage the compact, continuous, and singularity-free properties of dual quaternions for representing rigid body motion, we develop a novel Dual Quaternion VAE (DQ-VAE). This DQ-VAE receives these predicted priors, along with the original user drag, to generate a complete, plausible motion trajectory. To ensure strict adherence to kinematics, we inject the joint priors at every layer of the DQ-VAE's non-autoregressive Transformer decoder using FiLM (Feature-wise Linear Modulation) conditioning. This persistent, multi-scale guidance is complemented by a numerically-stable cross-product loss to guarantee axis alignment. This decoupled design allows DragMesh to achieve real-time performance and enables plausible, generative articulation on novel objects without retraining, offering a practical step toward generative 3D intelligence. Code: https://github.com/AIGeeksGroup/DragMesh. Website: https://aigeeksgroup.github.io/DragMesh.

</details>


### [133] [When Gender is Hard to See: Multi-Attribute Support for Long-Range Recognition](https://arxiv.org/abs/2512.06426)
*Nzakiese Mbongo,Kailash A. Hambarde,Hugo Proença*

Main category: cs.CV

TL;DR: 提出双路径Transformer框架，结合CLIP的视觉和属性线索，用于远距离性别识别，在多个指标上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 远距离图像中的性别识别面临空间分辨率低、视角变化大、面部特征缺失等挑战，需要更鲁棒的解决方案。

Method: 双路径Transformer框架：1) 视觉路径通过选择性微调CLIP图像编码器上层；2) 属性路径通过软生物特征提示（发型、服装等）在CLIP文本-图像空间中推理性别。使用空间通道注意力模块增强判别性定位。

Result: 在构建的U-DetAGReID数据集上，该方法在宏观F1、准确率、AUC等多个指标上超越最先进的人员属性和重识别基线，对距离、角度和高度变化具有鲁棒性。

Conclusion: 语言引导的双路径学习为无约束远距离场景下的负责任性别识别提供了可扩展的基础，注意力可视化显示可解释的属性定位和负责任的弃权行为。

Abstract: Accurate gender recognition from extreme long-range imagery remains a challenging problem due to limited spatial resolution, viewpoint variability, and loss of facial cues. For such purpose, we present a dual-path transformer framework that leverages CLIP to jointly model visual and attribute-driven cues for gender recognition at a distance. The framework integrates two complementary streams: (1) a direct visual path that refines a pre-trained CLIP image encoder through selective fine-tuning of its upper layers, and (2) an attribute-mediated path that infers gender from a set of soft-biometric prompts (e.g., hairstyle, clothing, accessories) aligned in the CLIP text-image space. Spatial channel attention modules further enhance discriminative localization under occlusion and low resolution. To support large-scale evaluation, we construct U-DetAGReID, a unified long-range gender dataset derived from DetReIDx and AG-ReID.v2, harmonized under a consistent ternary labeling scheme (Male, Female, Unknown). Extensive experiments suggest that the proposed solution surpasses state-of-the-art person-attribute and re-identification baselines across multiple metrics (macro-F1, accuracy, AUC), with consistent robustness to distance, angle, and height variations. Qualitative attention visualizations confirm interpretable attribute localization and responsible abstention behavior. Our results show that language-guided dual-path learning offers a principled, extensible foundation for responsible gender recognition in unconstrained long-range scenarios.

</details>


### [134] [Automated Deep Learning Estimation of Anthropometric Measurements for Preparticipation Cardiovascular Screening](https://arxiv.org/abs/2512.06434)
*Lucas R. Mareque,Ricardo L. Armentano,Leandro J. Cymberknop*

Main category: cs.CV

TL;DR: 提出基于深度学习的全自动方法，从2D合成人体图像估计5项关键人体测量指标，用于运动员心血管风险评估


<details>
  <summary>Details</summary>
Motivation: 传统手动测量方法劳动密集、依赖操作者、难以规模化，而运动员心血管筛查需要准确的人体测量数据来识别心血管风险

Method: 使用从3D身体网格生成的100,000张合成图像数据集，训练并评估VGG19、ResNet50和DenseNet121模型，通过全连接层进行回归分析

Result: 所有模型都达到亚厘米级精度，ResNet50表现最佳，在所有测量指标上平均MAE为0.668厘米

Conclusion: 深度学习能够提供规模化的人体测量数据，可作为运动员筛查协议的实用工具，未来将在真实图像上验证以扩展应用

Abstract: Preparticipation cardiovascular examination (PPCE) aims to prevent sudden cardiac death (SCD) by identifying athletes with structural or electrical cardiac abnormalities. Anthropometric measurements, such as waist circumference, limb lengths, and torso proportions to detect Marfan syndrome, can indicate elevated cardiovascular risk. Traditional manual methods are labor-intensive, operator-dependent, and challenging to scale. We present a fully automated deep-learning approach to estimate five key anthropometric measurements from 2D synthetic human body images. Using a dataset of 100,000 images derived from 3D body meshes, we trained and evaluated VGG19, ResNet50, and DenseNet121 with fully connected layers for regression. All models achieved sub-centimeter accuracy, with ResNet50 performing best, achieving a mean MAE of 0.668 cm across all measurements. Our results demonstrate that deep learning can deliver accurate anthropometric data at scale, offering a practical tool to complement athlete screening protocols. Future work will validate the models on real-world images to extend applicability.

</details>


### [135] [AGORA: Adversarial Generation Of Real-time Animatable 3D Gaussian Head Avatars](https://arxiv.org/abs/2512.06438)
*Ramazan Fazylov,Sergey Zagoruyko,Aleksandr Parkin,Stamatis Lefkimmiatis,Ivan Laptev*

Main category: cs.CV

TL;DR: AGORA：首个基于3D高斯泼溅的实时可动画化3D人体化身生成框架，通过FLAME条件变形分支实现身份保持的精细表情控制，支持CPU推理


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：基于NeRF的方法渲染慢且动态不一致，而3DGS方法通常仅限于静态头部生成，缺乏动态控制。需要一种既能保持高质量又能实现实时动画控制的方法。

Method: 1. 将3D高斯泼溅（3DGS）与生成对抗网络结合；2. 引入轻量级FLAME条件变形分支，预测每个高斯的残差；3. 采用双判别器训练方案，利用参数化网格的合成渲染来增强表情保真度

Result: 1. 在表情准确性上优于最先进的NeRF方法；2. 单GPU渲染速度250+ FPS；3. CPU推理约9 FPS，是首个实用的CPU-only可动画化3DGS化身合成方法

Conclusion: AGORA在可动画化3D人体化身生成方面取得了显著进展，实现了高质量、实时控制和高性能的数字人类合成，向实用化高性能数字人类迈出了重要一步

Abstract: The generation of high-fidelity, animatable 3D human avatars remains a core challenge in computer graphics and vision, with applications in VR, telepresence, and entertainment. Existing approaches based on implicit representations like NeRFs suffer from slow rendering and dynamic inconsistencies, while 3D Gaussian Splatting (3DGS) methods are typically limited to static head generation, lacking dynamic control. We bridge this gap by introducing AGORA, a novel framework that extends 3DGS within a generative adversarial network to produce animatable avatars. Our key contribution is a lightweight, FLAME-conditioned deformation branch that predicts per-Gaussian residuals, enabling identity-preserving, fine-grained expression control while allowing real-time inference. Expression fidelity is enforced via a dual-discriminator training scheme leveraging synthetic renderings of the parametric mesh. AGORA generates avatars that are not only visually realistic but also precisely controllable. Quantitatively, we outperform state-of-the-art NeRF-based methods on expression accuracy while rendering at 250+ FPS on a single GPU, and, notably, at $\sim$9 FPS under CPU-only inference - representing, to our knowledge, the first demonstration of practical CPU-only animatable 3DGS avatar synthesis. This work represents a significant step toward practical, high-performance digital humans. Project website: https://ramazan793.github.io/AGORA/

</details>


### [136] [Towards Stable Cross-Domain Depression Recognition under Missing Modalities](https://arxiv.org/abs/2512.06447)
*Jiuyi Chen,Mingkui Tan,Haifeng Lu,Qiuna Xu,Zhihua Wang,Runhao Zeng,Xiping Hu*

Main category: cs.CV

TL;DR: 提出SCD-MLLM框架，通过多源数据输入适配器和模态感知自适应融合模块，实现跨域抑郁症识别的统一稳定解决方案，在完整和缺失模态情况下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 抑郁症筛查具有重要公共卫生意义，但现有多模态自动抑郁症检测方法缺乏统一通用框架，对现实世界中常见的模态缺失情况稳定性不足，需要解决跨域泛化和模态缺失问题。

Method: 提出SCD-MLLM框架，包含两个核心组件：1) 多源数据输入适配器(MDIA)，使用掩码机制和任务特定提示将异构数据转换为统一标记序列；2) 模态感知自适应融合模块(MAFM)，通过共享投影机制自适应整合音频和视觉特征，增强对缺失模态的鲁棒性。

Result: 在五个公开异构抑郁症数据集(CMDC、AVEC2014、DAIC-WOZ、DVlog、EATD)上进行多数据集联合训练实验，在完整和部分模态设置下均优于现有SOTA模型及商业LLM(Gemini和GPT)，展示了优越的跨域泛化能力、多模态线索捕捉能力和对缺失模态的稳定性。

Conclusion: SCD-MLLM提供了一个统一、稳定、可泛化的多模态抑郁症识别框架，能够有效处理现实世界中的异构数据和模态缺失问题，为抑郁症筛查提供了实用的解决方案。

Abstract: Depression poses serious public health risks, including suicide, underscoring the urgency of timely and scalable screening. Multimodal automatic depression detection (ADD) offers a promising solution; however, widely studied audio- and video-based ADD methods lack a unified, generalizable framework for diverse depression recognition scenarios and show limited stability to missing modalities, which are common in real-world data. In this work, we propose a unified framework for Stable Cross-Domain Depression Recognition based on Multimodal Large Language Model (SCD-MLLM). The framework supports the integration and processing of heterogeneous depression-related data collected from varied sources while maintaining stability in the presence of incomplete modality inputs. Specifically, SCD-MLLM introduces two key components: (i) Multi-Source Data Input Adapter (MDIA), which employs masking mechanism and task-specific prompts to transform heterogeneous depression-related inputs into uniform token sequences, addressing inconsistency across diverse data sources; (ii) Modality-Aware Adaptive Fusion Module (MAFM), which adaptively integrates audio and visual features via a shared projection mechanism, enhancing resilience under missing modality conditions. e conduct comprehensive experiments under multi-dataset joint training settings on five publicly available and heterogeneous depression datasets from diverse scenarios: CMDC, AVEC2014, DAIC-WOZ, DVlog, and EATD. Across both complete and partial modality settings, SCD-MLLM outperforms state-of-the-art (SOTA) models as well as leading commercial LLMs (Gemini and GPT), demonstrating superior cross-domain generalization, enhanced ability to capture multimodal cues of depression, and strong stability to missing modality cases in real-world applications.

</details>


### [137] [Sanvaad: A Multimodal Accessibility Framework for ISL Recognition and Voice-Based Interaction](https://arxiv.org/abs/2512.06485)
*Kush Revankar,Shreyas Deshpande,Araham Sayeed,Ansh Tandale,Sarika Bobde*

Main category: cs.CV

TL;DR: Sanvaad是一个轻量级多模态无障碍框架，支持聋哑用户、视障用户和普通听力人群之间的实时双向通信。


<details>
  <summary>Details</summary>
Motivation: 当前聋哑用户、视障用户和普通听力人群之间的通信工具通常只支持单向交互，存在沟通障碍，需要一种支持双向实时通信的无障碍解决方案。

Method: 1. 针对聋哑用户：基于MediaPipe地标构建印度手语识别模块，支持语音到手语的转换（语音检测到预定义短语映射，生成GIF或字母可视化）
2. 针对视障用户：提供无屏幕语音界面，集成多语言语音识别、文本摘要和文本转语音生成
3. 整体框架：使用Streamlit构建界面，可在桌面和移动设备上运行，采用轻量级计算机视觉和语音处理工具

Result: 开发了一个统一的轻量级多模态无障碍框架，能够在边缘设备上流畅运行，无需专用硬件，支持聋哑用户和视障用户与普通听力人群之间的双向实时通信。

Conclusion: Sanvaad通过结合轻量级计算机视觉和语音处理工具，为包容性通信提供了一个实用且可访问的途径，解决了现有工具单向交互的限制。

Abstract: Communication between deaf users, visually im paired users, and the general hearing population often relies on tools that support only one direction of interaction. To address this limitation, this work presents Sanvaad, a lightweight multimodal accessibility framework designed to support real time, two-way communication. For deaf users, Sanvaad includes an ISL recognition module built on MediaPipe landmarks. MediaPipe is chosen primarily for its efficiency and low computational load, enabling the system to run smoothly on edge devices without requiring dedicated hardware. Spoken input from a phone can also be translated into sign representations through a voice-to-sign component that maps detected speech to predefined phrases and produces corresponding GIFs or alphabet-based visualizations. For visually impaired users, the framework provides a screen free voice interface that integrates multilingual speech recognition, text summarization, and text-to-speech generation. These components work together through a Streamlit-based interface, making the system usable on both desktop and mobile environments. Overall, Sanvaad aims to offer a practical and accessible pathway for inclusive communication by combining lightweight computer vision and speech processing tools within a unified framework.

</details>


### [138] [Method of UAV Inspection of Photovoltaic Modules Using Thermal and RGB Data Fusion](https://arxiv.org/abs/2512.06504)
*Andrii Lysyi,Anatoliy Sachenko,Pavlo Radiuk,Mykola Lysyi,Oleksandr Melnychenko,Diana Zahorodnia*

Main category: cs.CV

TL;DR: 提出一种智能光伏巡检框架，通过多模态融合和自适应重采机制，解决传统方法的热成像偏差、数据冗余和高带宽需求问题，显著提升检测精度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统光伏巡检方法存在热成像调色板偏差、数据冗余和高通信带宽需求等关键缺陷，需要开发自动化、智能化的综合监测系统来提升光伏电站的安全性和运营效率。

Method: 采用协同架构：1) 通过强制表示一致性学习调色板不变的热成像嵌入；2) 通过门控机制融合对比度归一化的RGB流；3) 使用基于罗德里格斯更新的闭环自适应重采控制器确认模糊异常；4) 基于DBSCAN和半正矢距离的地理空间去重模块。

Result: 在公开PVF-10基准测试中达到0.903的mAP@0.5，比单模态基线提升12-15%；现场验证召回率达96%；去重过程减少15-20%的重复误报；仅传输相关数据使空中数据传输减少60-70%。

Conclusion: 该研究建立了主动式光伏巡检的新范式，系统在检测精度、误报减少和数据传输效率方面均表现优异，验证了其实际部署的可行性。

Abstract: The subject of this research is the development of an intelligent, integrated framework for the automated inspection of photovoltaic (PV) infrastructure that addresses the critical shortcomings of conventional methods, including thermal palette bias, data redundancy, and high communication bandwidth requirements. The goal of this study is to design, develop, and validate a comprehensive, multi-modal system that fully automates the monitoring workflow, from data acquisition to the generation of actionable, geo-located maintenance alerts, thereby enhancing plant safety and operational efficiency. The methods employed involve a synergistic architecture that begins with a palette-invariant thermal embedding, learned by enforcing representational consistency, which is fused with a contrast-normalized RGB stream via a gated mechanism. This is supplemented by a closed-loop, adaptive re-acquisition controller that uses Rodrigues-based updates for targeted confirmation of ambiguous anomalies and a geospatial deduplication module that clusters redundant alerts using DBSCAN over the haversine distance. In conclusion, this study establishes a powerful new paradigm for proactive PV inspection, with the proposed system achieving a mean Average Precision (mAP@0.5) of 0.903 on the public PVF-10 benchmark, a significant 12-15% improvement over single-modality baselines. Field validation confirmed the system's readiness, achieving 96% recall, while the de-duplication process reduced duplicate-induced false positives by 15-20%, and relevance-only telemetry cut airborne data transmission by 60-70%.

</details>


### [139] [ShadowWolf -- Automatic Labelling, Evaluation and Model Training Optimised for Camera Trap Wildlife Images](https://arxiv.org/abs/2512.06521)
*Jens Dede,Anna Förster*

Main category: cs.CV

TL;DR: 提出ShadowWolf框架，通过整合优化AI模型训练和评估阶段，解决野生动物监测中环境变化带来的挑战，实现动态模型重训练以减少标注工作量并提升适应性。


<details>
  <summary>Details</summary>
Motivation: 全球人口增长导致人类栖息地扩张，野生动物空间减少，人兽互动增加。这些互动从轻微干扰到物种灭绝不等，使得野生动物监测日益重要。AI可自动化识别图像视频中的动物，减少人工监测工作量，但环境变化（地形、天气、光照、距离）对模型鲁棒性和适应性提出重大挑战。

Method: 提出名为ShadowWolf的统一框架，整合优化AI模型训练和评估阶段。该框架支持动态模型重训练，以适应环境条件和应用需求的变化，减少标注工作量，实现现场模型适应。

Result: 该自适应统一方法提高了野生动物监测系统的准确性和效率，促进更有效和可扩展的保护工作。

Conclusion: ShadowWolf框架通过动态适应环境变化，解决了野生动物监测AI模型面临的鲁棒性挑战，为保护工作提供了更有效的技术支撑。

Abstract: The continuous growth of the global human population is leading to the expansion of human habitats, resulting in decreasing wildlife spaces and increasing human-wildlife interactions. These interactions can range from minor disturbances, such as raccoons in urban waste bins, to more severe consequences, including species extinction. As a result, the monitoring of wildlife is gaining significance in various contexts. Artificial intelligence (AI) offers a solution by automating the recognition of animals in images and videos, thereby reducing the manual effort required for wildlife monitoring. Traditional AI training involves three main stages: image collection, labelling, and model training. However, the variability, for example, in the landscape (e.g., mountains, open fields, forests), weather (e.g., rain, fog, sunshine), lighting (e.g., day, night), and camera-animal distances presents significant challenges to model robustness and adaptability in real-world scenarios.
  In this work, we propose a unified framework, called ShadowWolf, designed to address these challenges by integrating and optimizing the stages of AI model training and evaluation. The proposed framework enables dynamic model retraining to adjust to changes in environmental conditions and application requirements, thereby reducing labelling efforts and allowing for on-site model adaptation. This adaptive and unified approach enhances the accuracy and efficiency of wildlife monitoring systems, promoting more effective and scalable conservation efforts.

</details>


### [140] [On The Role of K-Space Acquisition in MRI Reconstruction Domain-Generalization](https://arxiv.org/abs/2512.06530)
*Mohammed Wattad,Tamir Shor,Alex Bronstein*

Main category: cs.CV

TL;DR: 该论文展示了学习到的k空间采样模式在跨域MRI重建中的泛化能力，并提出了一种通过引入采集不确定性来增强域鲁棒性的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要针对单一数据集或模态优化k空间采集模式，缺乏对跨成像域可迁移性的考虑。本文旨在探索学习到的k空间采样在域偏移下的泛化能力。

Method: 提出一种增强域鲁棒性的新方法：在训练过程中引入采集不确定性，通过随机扰动k空间轨迹来模拟不同扫描仪和成像条件的变异性。

Result: 通过跨数据集和采集范式的系统评估，证明使用学习到的采样模式训练的模型在跨域设置下表现出改进的泛化性能。

Conclusion: k空间轨迹设计不应仅仅被视为加速机制，而应作为提高MRI重建中域泛化能力的重要自由度。

Abstract: Recent work has established learned k-space acquisition patterns as a promising direction for improving reconstruction quality in accelerated Magnetic Resonance Imaging (MRI). Despite encouraging results, most existing research focuses on acquisition patterns optimized for a single dataset or modality, with limited consideration of their transferability across imaging domains. In this work, we demonstrate that the benefits of learned k-space sampling can extend beyond the training domain, enabling superior reconstruction performance under domain shifts. Our study presents two main contributions. First, through systematic evaluation across datasets and acquisition paradigms, we show that models trained with learned sampling patterns exhibitimproved generalization under cross-domain settings. Second, we propose a novel method that enhances domain robustness by introducing acquisition uncertainty during training-stochastically perturbing k-space trajectories to simulate variability across scanners and imaging conditions. Our results highlight the importance of treating kspace trajectory design not merely as an acceleration mechanism, but as an active degree of freedom for improving domain generalization in MRI reconstruction.

</details>


### [141] [Novel Deep Learning Architectures for Classification and Segmentation of Brain Tumors from MRI Images](https://arxiv.org/abs/2512.06531)
*Sayan Das,Arghadip Biswas*

Main category: cs.CV

TL;DR: 该论文提出两种新颖的深度学习架构：SAETCN用于脑肿瘤分类（准确率99.38%），SAS-Net用于脑肿瘤分割（像素准确率99.23%），旨在解决传统手动检测耗时且现有模型泛化性差的问题。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤对人类生命构成重大威胁，早期准确检测对诊断和治疗至关重要。传统放射科医生手动检测MRI图像耗时且困难，特别是近年来儿童和青少年脑肿瘤发病率上升导致数据量激增。现有AI模型泛化性不足，在验证数据上表现不佳。

Method: 提出两种新颖的深度学习架构：1) SAETCN（自注意力增强肿瘤分类网络）用于脑肿瘤分类，处理3种肿瘤类型（胶质瘤、脑膜瘤、垂体瘤）和非肿瘤病例；2) SAS-Net（自注意力分割网络）用于脑肿瘤精确分割。

Result: SAETCN在验证数据集上达到99.38%的分类准确率，成为少数能够准确检测脑肿瘤的新型深度学习架构之一。SAS-Net实现99.23%的整体像素准确率，用于脑肿瘤分割任务。

Conclusion: 提出的两种自注意力深度学习架构在脑肿瘤检测任务上表现出色，SAETCN在分类任务上达到高准确率，SAS-Net在分割任务上实现高像素准确率，为计算机辅助诊断系统提供了有效的自动检测解决方案。

Abstract: Brain tumors pose a significant threat to human life, therefore it is very much necessary to detect them accurately in the early stages for better diagnosis and treatment. Brain tumors can be detected by the radiologist manually from the MRI scan images of the patients. However, the incidence of brain tumors has risen amongst children and adolescents in recent years, resulting in a substantial volume of data, as a result, it is time-consuming and difficult to detect manually. With the emergence of Artificial intelligence in the modern world and its vast application in the medical field, we can make an approach to the CAD (Computer Aided Diagnosis) system for the early detection of Brain tumors automatically. All the existing models for this task are not completely generalized and perform poorly on the validation data. So, we have proposed two novel Deep Learning Architectures - (a) SAETCN (Self-Attention Enhancement Tumor Classification Network) for the classification of different kinds of brain tumors. We have achieved an accuracy of 99.38% on the validation dataset making it one of the few Novel Deep learning-based architecture that is capable of detecting brain tumors accurately. We have trained the model on the dataset, which contains images of 3 types of tumors (glioma, meningioma, and pituitary tumors) and non-tumor cases. and (b) SAS-Net (Self-Attentive Segmentation Network) for the accurate segmentation of brain tumors. We have achieved an overall pixel accuracy of 99.23%.

</details>


### [142] [Bridging spatial awareness and global context in medical image segmentation](https://arxiv.org/abs/2512.06560)
*Dalia Alzu'bi,A. Ben Hamza*

Main category: cs.CV

TL;DR: U-CycleMLP：一种新型U形编码器-解码器网络，用于医学图像分割，通过位置注意力权重激励块、密集空洞块和通道CycleMLP块，在保持轻量级架构的同时提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割模型难以有效捕获局部和全局上下文信息，导致边界像素丢失和分割错误。需要在保持计算效率的同时提高分割精度。

Method: 提出U-CycleMLP网络：编码器使用位置注意力权重激励块、密集空洞块和下采样操作学习多尺度上下文特征；解码器通过上采样、密集空洞块和特征融合机制重建高分辨率分割掩码；在跳跃连接中加入通道CycleMLP块以增强特征集成，同时保持线性计算复杂度。

Result: 在三个基准数据集上的实验表明，U-CycleMLP相比最先进方法具有竞争力，在所有数据集上实现更好的分割精度，能捕获细粒度解剖结构，并在不同医学成像模态中表现出鲁棒性。

Conclusion: U-CycleMLP通过创新的架构设计有效平衡了分割精度和计算效率，消融研究进一步证实了核心组件对提升分割精度的重要性。

Abstract: Medical image segmentation is a fundamental task in computer-aided diagnosis, requiring models that balance segmentation accuracy and computational efficiency. However, existing segmentation models often struggle to effectively capture local and global contextual information, leading to boundary pixel loss and segmentation errors. In this paper, we propose U-CycleMLP, a novel U-shaped encoder-decoder network designed to enhance segmentation performance while maintaining a lightweight architecture. The encoder learns multiscale contextual features using position attention weight excitation blocks, dense atrous blocks, and downsampling operations, effectively capturing both local and global contextual information. The decoder reconstructs high-resolution segmentation masks through upsampling operations, dense atrous blocks, and feature fusion mechanisms, ensuring precise boundary delineation. To further refine segmentation predictions, channel CycleMLP blocks are incorporated into the decoder along the skip connections, enhancing feature integration while maintaining linear computational complexity relative to input size. Experimental results, both quantitative and qualitative, across three benchmark datasets demonstrate the competitive performance of U-CycleMLP in comparison with state-of-the-art methods, achieving better segmentation accuracy across all datasets, capturing fine-grained anatomical structures, and demonstrating robustness across different medical imaging modalities. Ablation studies further highlight the importance of the model's core architectural components in enhancing segmentation accuracy.

</details>


### [143] [SUGAR: A Sweeter Spot for Generative Unlearning of Many Identities](https://arxiv.org/abs/2512.06562)
*Dung Thuy Nguyen,Quang Nguyen,Preston K. Robinette,Eli Jiang,Taylor T. Johnson,Kevin Leach*

Main category: cs.CV

TL;DR: SUGAR是一个可扩展的生成式遗忘框架，能够同时或顺序移除多个身份，无需重新训练整个模型，通过个性化代理潜在表示将不需要的身份重定向到视觉连贯的替代输出。


<details>
  <summary>Details</summary>
Motivation: 随着3D感知生成模型在合成人类身份方面取得进展，引发了关于用户同意和从模型输出空间中移除特定个体的紧迫问题。需要一种能够有效移除多个身份而不损害模型整体性能的方法。

Method: SUGAR为每个身份学习个性化的代理潜在表示，将不需要的身份重建重定向到视觉连贯的替代输出。引入持续效用保持目标，防止随着更多身份被遗忘而导致模型质量下降。

Result: SUGAR在移除多达200个身份方面达到最先进性能，与现有基线相比，保留效用提高了700%。

Conclusion: SUGAR提供了一个有效的生成式遗忘框架，能够大规模移除特定身份，同时保持生成模型的整体质量和多样性，解决了3D生成模型中用户同意的重要问题。

Abstract: Recent advances in 3D-aware generative models have enabled high-fidelity image synthesis of human identities. However, this progress raises urgent questions around user consent and the ability to remove specific individuals from a model's output space. We address this by introducing SUGAR, a framework for scalable generative unlearning that enables the removal of many identities (simultaneously or sequentially) without retraining the entire model. Rather than projecting unwanted identities to unrealistic outputs or relying on static template faces, SUGAR learns a personalized surrogate latent for each identity, diverting reconstructions to visually coherent alternatives while preserving the model's quality and diversity. We further introduce a continual utility preservation objective that guards against degradation as more identities are forgotten. SUGAR achieves state-of-the-art performance in removing up to 200 identities, while delivering up to a 700% improvement in retention utility compared to existing baselines. Our code is publicly available at https://github.com/judydnguyen/SUGAR-Generative-Unlearn.

</details>


### [144] [GNC-Pose: Geometry-Aware GNC-PnP for Accurate 6D Pose Estimation](https://arxiv.org/abs/2512.06565)
*Xiujin Liu*

Main category: cs.CV

TL;DR: GNC-Pose是一个无需学习的单目6D物体姿态估计方法，通过渲染初始化、几何感知对应点加权和GNC优化，在纹理物体上实现高精度姿态估计。


<details>
  <summary>Details</summary>
Motivation: 现有6D姿态估计方法通常依赖学习特征或类别先验，需要大量训练数据。GNC-Pose旨在提供一个无需学习、无需训练数据、无需类别先验的鲁棒解决方案，适用于纹理物体的姿态估计。

Method: 方法包含三个主要步骤：1) 通过特征匹配和渲染对齐获取粗略的2D-3D对应点；2) 基于GNC原则，引入几何感知的聚类加权机制，根据3D结构一致性为每个点分配置信度；3) 使用LM优化进一步提升精度。

Result: 在YCB物体和模型集上测试，尽管无需学习特征、训练数据或类别先验，GNC-Pose在精度上与基于学习和非学习方法相当，提供了简单、鲁棒且实用的解决方案。

Conclusion: GNC-Pose通过结合渲染初始化、几何感知加权和GNC优化，为纹理物体的6D姿态估计提供了一个完全无需学习的鲁棒管道，在保持竞争力的同时避免了学习方法的依赖。

Abstract: We present GNC-Pose, a fully learning-free monocular 6D object pose estimation pipeline for textured objects that combines rendering-based initialization, geometry-aware correspondence weighting, and robust GNC optimization. Starting from coarse 2D-3D correspondences obtained through feature matching and rendering-based alignment, our method builds upon the Graduated Non-Convexity (GNC) principle and introduces a geometry-aware, cluster-based weighting mechanism that assigns robust per point confidence based on the 3D structural consistency of the model. This geometric prior and weighting strategy significantly stabilizes the optimization under severe outlier contamination. A final LM refinement further improve accuracy. We tested GNC-Pose on The YCB Object and Model Set, despite requiring no learned features, training data, or category-specific priors, GNC-Pose achieves competitive accuracy compared with both learning-based and learning-free methods, and offers a simple, robust, and practical solution for learning-free 6D pose estimation.

</details>


### [145] [MedGRPO: Multi-Task Reinforcement Learning for Heterogeneous Medical Video Understanding](https://arxiv.org/abs/2512.06581)
*Yuhao Su,Anwesa Choudhuri,Zhongpai Gao,Benjamin Planche,Van Nguyen Nguyen,Meng Zheng,Yuhan Shen,Arun Innanje,Terrence Chen,Ehsan Elhamifar,Ziyan Wu*

Main category: cs.CV

TL;DR: 提出MedVidBench医学视频理解基准和MedGRPO强化学习框架，解决医学视频理解中空间精度、时序推理和临床语义的挑战


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在医学视频理解方面存在困难，需要处理空间精度、时序推理和临床语义等关键问题

Method: 1) 构建MedVidBench基准：531,850个视频-指令对，8个医学来源，专家引导提示和双模型验证的质量保证流程；2) 提出MedGRPO强化学习框架：跨数据集奖励归一化和医学LLM评判器

Result: 在MedVidBench上监督微调的Qwen2.5-VL-7B显著优于GPT-4.1和Gemini-2.5-Flash；MedGRPO框架在定位和字幕任务上进一步超越SFT基线

Conclusion: 为医学领域的视觉语言模型建立了基础基准和鲁棒训练方法，推动了医学视频理解的发展

Abstract: Large vision-language models struggle with medical video understanding, where spatial precision, temporal reasoning, and clinical semantics are critical. To address this, we first introduce \textbf{MedVidBench}, a large-scale benchmark of 531,850 video-instruction pairs across 8 medical sources spanning video, segment, and frame-level tasks, curated through a rigorous quality assurance pipeline with expert-guided prompting and dual-model validation. While supervised fine-tuning on MedVidBench yields noticeable gains, standard Reinforcement Learning (RL) fails due to imbalanced reward scales across datasets, which destabilizes optimization and leads to training collapse. To overcome this, we introduce \textbf{MedGRPO}, a novel RL framework for balanced multi-dataset training with two key innovations: (1) \emph{cross-dataset reward normalization} that maps each dataset's median performance to a common reward value, ensuring fair optimization regardless of difficulty, and (2) a \emph{medical LLM judge} that evaluates caption quality on five clinical dimensions through comparative similarity scoring. Supervised fine-tuning Qwen2.5-VL-7B on MedVidBench substantially outperforms GPT-4.1 and Gemini-2.5-Flash across all tasks, demonstrating MedVidBench's efficacy, while our MedGRPO framework further improves upon the SFT baseline across grounding and captioning tasks. Our work establishes a foundational benchmark and robust training methodology for advancing vision-language models in medical domains. Our project website is available at https://yuhaosu.github.io/MedGRPO/.

</details>


### [146] [From Remote Sensing to Multiple Time Horizons Forecasts: Transformers Model for CyanoHAB Intensity in Lake Champlain](https://arxiv.org/abs/2512.06598)
*Muhammad Adil,Patrick J. Clemins,Andrew W. Schroth,Panagiotis D. Oikonomou,Donna M. Rizzo,Peter D. F. Isles,Xiaohan Zhang,Kareem I. Hannoun,Scott Turnbull,Noah B. Beckage,Asim Zia,Safwan Wshah*

Main category: cs.CV

TL;DR: 提出基于Transformer和BiLSTM的遥感预测框架，利用卫星数据预测蓝藻水华强度，可提前14天预警，在稀疏数据条件下仍保持良好性能。


<details>
  <summary>Details</summary>
Motivation: 蓝藻有害藻华对水生生态系统和公共健康构成严重威胁，尚普兰湖等水域因营养富集和气候变化而频发。遥感技术可为监测和预测提供可扩展的解决方案，弥补现场观测的不足。

Method: 结合Transformer和BiLSTM的遥感预测框架，使用蓝藻指数和温度卫星数据。针对数据稀疏问题（蓝藻指数缺失30%，温度缺失90%），采用两阶段预处理：像素级前向填充和加权时间插补，然后平滑处理。通过等频分箱和温度统计提取特征。

Result: 模型在多个预测时间窗口表现优异：1天、2天、3天预测的F1分数分别为89.5%、86.4%、85.5%；14天预测的F1分数为78.9%，AUC为82.6%。

Conclusion: 该模型能够从稀疏卫星数据中捕捉复杂的时空动态，为蓝藻水华管理提供可靠的早期预警，证明了遥感预测框架的有效性。

Abstract: Cyanobacterial Harmful Algal Blooms (CyanoHABs) pose significant threats to aquatic ecosystems and public health globally. Lake Champlain is particularly vulnerable to recurring CyanoHAB events, especially in its northern segment: Missisquoi Bay, St. Albans Bay, and Northeast Arm, due to nutrient enrichment and climatic variability. Remote sensing provides a scalable solution for monitoring and forecasting these events, offering continuous coverage where in situ observations are sparse or unavailable. In this study, we present a remote sensing only forecasting framework that combines Transformers and BiLSTM to predict CyanoHAB intensities up to 14 days in advance. The system utilizes Cyanobacterial Index data from the Cyanobacterial Assessment Network and temperature data from Moderate Resolution Imaging Spectroradiometer satellites to capture long range dependencies and sequential dynamics in satellite time series. The dataset is very sparse, missing more than 30% of the Cyanobacterial Index data and 90% of the temperature data. A two stage preprocessing pipeline addressed data gaps by applying forward fill and weighted temporal imputation at the pixel level, followed by smoothing to reduce the discontinuities of CyanoHAB events. The raw dataset is transformed into meaningful features through equal frequency binning for the Cyanobacterial Index values and extracted temperature statistics. Transformer BiLSTM model demonstrates strong forecasting performance across multiple horizons, achieving F1 scores of 89.5%, 86.4%, and 85.5% at one, two, and three-day forecasts, respectively, and maintaining an F1 score of 78.9% with an AUC of 82.6% at the 14-day horizon. These results confirm the model's ability to capture complex spatiotemporal dynamics from sparse satellite data and to provide reliable early warning for CyanoHABs management.

</details>


### [147] [Learning Relative Gene Expression Trends from Pathology Images in Spatial Transcriptomics](https://arxiv.org/abs/2512.06612)
*Kazuya Nishimura,Haruka Hirose,Ryoma Bise,Kaito Shiku,Yasuhiro Kojima*

Main category: cs.CV

TL;DR: 提出STRank损失函数，通过建模基因相对表达模式而非绝对表达值，提高病理图像中基因表达预测的鲁棒性，降低RNA测序成本。


<details>
  <summary>Details</summary>
Motivation: 传统点对点损失函数直接预测绝对基因表达值，但由于测序技术复杂性和细胞内在变异性，观测到的基因表达包含随机噪声和批次效应，准确估计绝对表达值面临重大挑战。

Method: 提出学习相对表达模式而非绝对水平的新目标，假设基因相对表达水平在独立实验中呈现一致模式，即使绝对表达值受批次效应和随机噪声影响。基于此假设建模关系，提出名为STRank的新型损失函数。

Result: 在合成数据集和真实数据集上的实验证明了所提方法的有效性。

Conclusion: STRank损失函数通过关注相对表达模式而非绝对表达值，能够有效应对噪声和批次效应，提高病理图像中基因表达预测的鲁棒性。

Abstract: Gene expression estimation from pathology images has the potential to reduce the RNA sequencing cost. Point-wise loss functions have been widely used to minimize the discrepancy between predicted and absolute gene expression values. However, due to the complexity of the sequencing techniques and intrinsic variability across cells, the observed gene expression contains stochastic noise and batch effects, and estimating the absolute expression values accurately remains a significant challenge. To mitigate this, we propose a novel objective of learning relative expression patterns rather than absolute levels. We assume that the relative expression levels of genes exhibit consistent patterns across independent experiments, even when absolute expression values are affected by batch effects and stochastic noise in tissue samples. Based on the assumption, we model the relation and propose a novel loss function called STRank that is robust to noise and batch effects. Experiments using synthetic datasets and real datasets demonstrate the effectiveness of the proposed method. The code is available at https://github.com/naivete5656/STRank.

</details>


### [148] [Hierarchical Deep Learning for Diatom Image Classification: A Multi-Level Taxonomic Approach](https://arxiv.org/abs/2512.06613)
*Yueying Ke*

Main category: cs.CV

TL;DR: 提出分层卷积网络用于硅藻分类，通过嵌入分类学层次结构提高准确性和错误定位能力


<details>
  <summary>Details</summary>
Motivation: 传统硅藻分类依赖专家，现有深度学习方法多采用扁平分类，忽略了分类学层次结构。研究探索将分类学层次嵌入神经网络架构是否能同时提高准确性和错误定位能力。

Method: 引入分层卷积网络，包含五个级联头部，联合预测纲、目、科、属、种。每个头部接收共享骨干特征和来自更高层次的概率分布，使用二进制掩码在训练和推理期间限制预测到有效后代。

Result: 分层模型在物种级别与扁平基线相当（69.4%准确率），但在所有上层分类级别表现更优。当物种预测失败时，92.5%的错误分类物种在属级别被正确预测（扁平基线为67.2%），平均分类学距离减少38.2%。

Conclusion: 分层约束掩码自上而下限制预测空间，而细粒度级别的梯度自下而上通过共享骨干传播，精炼特征。这提高了分类准确性，产生更稳健、可解释且与生物学对齐的多层次分类学预测。

Abstract: Accurate taxonomic identification of diatoms is essential for aquatic ecosystem monitoring, yet conventional methods depend heavily on expert taxonomists. Recent deep learning approaches improve automation, but most treat diatom recognition as flat classification predicting only one taxonomic rank. We investigate whether embedding taxonomic hierarchy into neural network architectures can improve both accuracy and error locality.
  We introduce a hierarchical convolutional network with five cascaded heads that jointly predict class, order, family, genus, and species. Each head receives shared backbone features and probability distributions from higher levels, with binary masks restricting predictions to valid descendants during training and inference. Using a filtered dataset of 1,456 diatom images covering 82 species, we compare hierarchical and flat models under identical settings.
  The hierarchical model matches flat baselines at species level (69.4% accuracy) while outperforming at all upper taxonomic levels. When species predictions fail, errors remain taxonomically local: 92.5 % of misclassified species are correctly predicted at genus level, versus 67.2% for flat baselines. The hierarchical model reduces mean taxonomic distance by 38.2% (1.209 vs. 1.955).
  Progressive training reveals bidirectional mechanisms: hierarchical constraint masks operate top-down to constrain prediction space, while gradients from fine-grained levels propagate bottom-up through the shared backbone, refining features. This improves class accuracy from 96.2% to 99.5% and yields 6-8% gains at upper levels, producing more robust, interpretable, and biologically aligned predictions for multi-level taxonomic classification.

</details>


### [149] [Masked Autoencoder Pretraining on Strong-Lensing Images for Joint Dark-Matter Model Classification and Super-Resolution](https://arxiv.org/abs/2512.06642)
*Achmad Ardani Prasha,Clavino Ourizqi Rachmadi,Muhamad Fauzan Ibnu Syahlan,Naufal Rahfi Anugerah,Nanda Garin Raditya,Putri Amelia,Sabrina Laila Mutiara,Hilman Syachr Ramadhan*

Main category: cs.CV

TL;DR: MAE预训练策略应用于强引力透镜模拟图像，学习通用表示用于暗物质模型分类和超分辨率图像增强任务，相比从头训练获得更好性能。


<details>
  <summary>Details</summary>
Motivation: 强引力透镜可以揭示暗物质子结构的影响，但分析噪声大、分辨率低的图像具有挑战性。需要开发能够从模拟数据中学习通用表示的方法，以支持多种下游任务。

Method: 使用掩码自编码器（MAE）在DeepLense ML4SCI基准的模拟强透镜图像上进行预训练，学习通用表示。然后针对两个下游任务分别微调编码器：暗物质模型分类（冷暗物质、轴子样或无子结构）和超分辨率图像增强（16×16到64×64）。研究了不同掩码比例对性能的影响。

Result: 在90%掩码比例下，微调的分类器达到宏观AUC 0.968和准确率88.65%，优于从头训练的基线（AUC 0.957，准确率82.46%）。超分辨率任务中，MAE预训练模型重建图像的PSNR约33 dB，SSIM 0.961，略优于从头训练。发现掩码比例存在权衡：更高的掩码比例改善分类但略微降低重建保真度。

Conclusion: MAE预训练在物理丰富的模拟数据上提供了灵活、可重用的编码器，适用于多种强透镜分析任务，证明了自监督学习在天体物理图像分析中的价值。

Abstract: Strong gravitational lensing can reveal the influence of dark-matter substructure in galaxies, but analyzing these effects from noisy, low-resolution images poses a significant challenge. In this work, we propose a masked autoencoder (MAE) pretraining strategy on simulated strong-lensing images from the DeepLense ML4SCI benchmark to learn generalizable representations for two downstream tasks: (i) classifying the underlying dark matter model (cold dark matter, axion-like, or no substructure) and (ii) enhancing low-resolution lensed images via super-resolution. We pretrain a Vision Transformer encoder using a masked image modeling objective, then fine-tune the encoder separately for each task. Our results show that MAE pretraining, when combined with appropriate mask ratio tuning, yields a shared encoder that matches or exceeds a ViT trained from scratch. Specifically, at a 90% mask ratio, the fine-tuned classifier achieves macro AUC of 0.968 and accuracy of 88.65%, compared to the scratch baseline (AUC 0.957, accuracy 82.46%). For super-resolution (16x16 to 64x64), the MAE-pretrained model reconstructs images with PSNR ~33 dB and SSIM 0.961, modestly improving over scratch training. We ablate the MAE mask ratio, revealing a consistent trade-off: higher mask ratios improve classification but slightly degrade reconstruction fidelity. Our findings demonstrate that MAE pretraining on physics-rich simulations provides a flexible, reusable encoder for multiple strong-lensing analysis tasks.

</details>


### [150] [TextMamba: Scene Text Detector with Mamba](https://arxiv.org/abs/2512.06657)
*Qiyan Zhao,Yue Yan,Da-Han Wang*

Main category: cs.CV

TL;DR: 提出基于Mamba的场景文本检测器，通过选择机制与注意力层结合，增强长序列相关信息提取能力，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: Transformer-based方法虽然解决了CNN在全局特征提取上的局限，但直接使用原生Transformer注意力层存在跨域限制和固有缺陷：在建模长距离依赖时会遗忘重要信息或关注无关表示。最近提出的状态空间模型Mamba通过线性复杂度选择机制展现了更好的长距离依赖建模能力。

Method: 1. 基于Mamba的场景文本检测器，将选择机制与注意力层集成；2. 采用Top_k算法显式选择关键信息，减少Mamba建模中的无关信息干扰；3. 设计双尺度前馈网络和嵌入金字塔增强模块，促进高维隐藏状态交互和多尺度特征融合。

Result: 在多个基准测试中达到最先进或竞争性性能：CTW1500上F-measure为89.7%，TotalText上为89.2%，ICDAR19ArT上为78.5%。

Conclusion: 提出的基于Mamba的场景文本检测器通过集成选择机制与注意力层，有效增强了编码器从长序列中提取相关信息的能力，在场景文本检测任务中取得了优异性能。

Abstract: In scene text detection, Transformer-based methods have addressed the global feature extraction limitations inherent in traditional convolution neural network-based methods. However, most directly rely on native Transformer attention layers as encoders without evaluating their cross-domain limitations and inherent shortcomings: forgetting important information or focusing on irrelevant representations when modeling long-range dependencies for text detection. The recently proposed state space model Mamba has demonstrated better long-range dependencies modeling through a linear complexity selection mechanism. Therefore, we propose a novel scene text detector based on Mamba that integrates the selection mechanism with attention layers, enhancing the encoder's ability to extract relevant information from long sequences. We adopt the Top\_k algorithm to explicitly select key information and reduce the interference of irrelevant information in Mamba modeling. Additionally, we design a dual-scale feed-forward network and an embedding pyramid enhancement module to facilitate high-dimensional hidden state interactions and multi-scale feature fusion. Our method achieves state-of-the-art or competitive performance on various benchmarks, with F-measures of 89.7\%, 89.2\%, and 78.5\% on CTW1500, TotalText, and ICDAR19ArT, respectively. Codes will be available.

</details>


### [151] [Personalized Image Descriptions from Attention Sequences](https://arxiv.org/abs/2512.06662)
*Ruoyu Xue,Hieu Le,Jingyi Xu,Sounak Mondal,Abe Leite,Gregory Zelinsky,Minh Hoai,Dimitris Samaras*

Main category: cs.CV

TL;DR: DEPER模型通过同时建模语言风格和观看行为来实现个性化图像描述，相比仅关注语言风格的现有方法平均提升24%


<details>
  <summary>Details</summary>
Motivation: 人们观看同一图像时存在显著差异：关注不同区域、对象和细节的顺序不同，描述方式也各异。现有个性化图像描述模型仅关注语言风格，忽略了个人观看模式这一重要因素。

Method: 提出DEPER模型，学习同时捕捉语言风格和观看行为的主题嵌入，通过辅助注意力预测任务指导学习。使用轻量级适配器将这些嵌入与冻结的视觉语言模型对齐，实现少样本个性化而无需重新训练。

Result: 在四个数据集（涵盖不同观看任务和简短/详细描述）上，DEPER实现了24%的平均改进，表明建模个性化注意力能产生更符合人类认知和更高质量的描述。

Conclusion: 理解人们如何观看有助于预测他们会说什么；建模人类感知的多样性可以提升多模态系统的性能和人类对齐性。

Abstract: People can view the same image differently: they focus on different regions, objects, and details in varying orders and describe them in distinct linguistic styles. This leads to substantial variability in image descriptions. However, existing models for personalized image description focus on linguistic style alone, with no prior work leveraging individual viewing patterns. We address this gap by explicitly modeling personalized viewing behavior as a core factor in description generation. Our method, DEPER (DEscription-PERception persona encoder), learns a subject embedding that captures both linguistic style and viewing behavior, guided by an auxiliary attention-prediction task. A lightweight adapter aligns these embeddings with a frozen vision-language model, enabling few-shot personalization without retraining. Across four datasets spanning diverse viewing tasks and both short and detailed descriptions, DEPER achieves a 24% average improvement, showing that modeling personalized attention produces more human-aligned and high-quality descriptions. We posit that understanding how people see helps predict what they say; modeling human diversity in perception can improve both performance and human alignment in multimodal systems.

</details>


### [152] [CoT4Det: A Chain-of-Thought Framework for Perception-Oriented Vision-Language Tasks](https://arxiv.org/abs/2512.06663)
*Yu Qi,Yumeng Zhang,Chenting Gong,Xiao Tan,Weiming Zhang,Wei Zhang,Jingdong Wang*

Main category: cs.CV

TL;DR: CoT4Det将感知任务（如目标检测）重新构建为分类、计数和定位三个可解释步骤，显著提升大视觉语言模型在感知任务上的性能，在COCO2017上mAP从19%提升到33%。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型在通用视觉问答等任务上表现优异，但在感知任务（如目标检测、语义分割）上表现远不如任务专用模型，特别是在密集场景和小目标检测方面存在明显不足。

Method: 提出Chain-of-Thought for Detection (CoT4Det)策略，将感知任务重新构建为三个可解释步骤：1) 分类：识别图像中的物体类别；2) 计数：统计每个类别的物体数量；3) 定位：将每个物体与图像中的具体位置对应。

Result: 在标准Qwen2.5-VL-7B-Instruct模型上，CoT4Det将COCO2017 val的mAP从19.0%提升到33.0%；在RefCOCO系列上超越基线+2%；在Flickr30k entities上提升19%，同时不损害通用视觉语言能力。

Conclusion: CoT4Det通过将感知任务重新构建为更符合大视觉语言模型推理能力的可解释步骤，显著提升了模型在感知任务上的性能，为增强LVLMs的感知能力提供了一种简单有效的策略。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated remarkable success in a broad range of vision-language tasks, such as general visual question answering and optical character recognition (OCR). However, their performance on perception-centric tasks -- such as object detection, semantic segmentation, and depth estimation -- remains significantly inferior to that of task-specific expert models. For example, Qwen2.5-VL-7B-Instruct achieves only 19% mAP on COCO2017 val, particularly struggling with dense scenes and small object recall. In this work, we introduce Chain-of-Thought for Detection (CoT4Det), a simple but efficient strategy that reformulates perception tasks into three interpretable steps: classification, counting, and grounding -- each more naturally aligned with the reasoning capabilities of LVLMs. Extensive experiments demonstrate that our method significantly improves perception performance without compromising general vision language capabilities. With a standard Qwen2.5-VL-7B-Instruct, CoT4Det boosts mAP from 19.0% to 33.0% on COCO2017 val and achieves competitive results across a variety of perception benchmarks, outperforming baselines by +2% on RefCOCO series and 19% on Flickr30k entities.

</details>


### [153] [1 + 1 > 2: Detector-Empowered Video Large Language Model for Spatio-Temporal Grounding and Reasoning](https://arxiv.org/abs/2512.06673)
*Shida Gao,Feng Xue,Xiangfeng Wang,Anlong Ming,Teng Long,Yihua Shao,Haozhe Wang,Zhaowen Lin,Wei Wang,Nicu Sebe*

Main category: cs.CV

TL;DR: DEViL提出了一种结合视频大语言模型和开放词汇检测器的框架，通过参考语义令牌实现端到端学习，解决时空定位中的误差累积问题，并在多个视频理解任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前MLLM在时空定位任务中采用自回归空间解码，导致输出序列过长，空间误差随时间累积，定位结果在视频中逐渐漂移。需要一种更有效的方法来同时处理时空定位和语义推理。

Method: DEViL将视频LLM与开放词汇检测器(OVD)耦合，通过参考语义令牌(RST)连接两者。RST将用户查询提炼为丰富的语义表示，既作为控制信号又替代OVD的文本嵌入。此外，提出管状挖掘时间正则化(TTReg)确保OVD生成时间一致的目标对象查询。

Result: 实验表明DEViL在各种细粒度视频理解任务中表现优异，特别是在STVG和GroundedVQA任务上。代码将在GitHub上发布。

Conclusion: DEViL通过结合视频LLM和开放词汇检测器，解决了自回归空间解码中的误差累积问题，实现了更准确和一致的时空定位与推理。

Abstract: Spatio-temporal grounding and reasoning aims to locate the temporal segment and spatial region of an event in a video given a user query, while also reasoning about semantics such as causality, temporal order, and action relationships. To achieve this, current MLLMs primarily treats bounding boxes as text tokens and generates them autoregressively. However, such autoregressive spatial decoding leads to very-long output sequences, causing spatial errors to accumulated over time and the localization results to progressively drift across a video. To address this, we present a Detector-Empowered Video LLM, short for DEViL, which couples a Video LLM with an open-vocabulary detector (OVD). Specifically, the MLLM and detector are connected via a reference-semantic token (RST) that distills the user query into a rich semantic representation. Unlike tokens that merely serve as spatial prompts or segmentor switches, the RST functions as both a control signal and a replacement for the OVD's text embedding, enabling end-to-end learning of both referential understanding and spatial localization. Furthermore, we propose a tube-mined temporal regularization (TTReg) within OVD, which drives the OVD to generate temporally-consistent queries for target objects, thereby ensuring effective temporal association. Experiments demonstrate that DEViL achieves strong performance across various fine-grained video understanding tasks, particularly STVG and GroundedVQA. Code will be released on https://github.com/gaostar123/DeViL.

</details>


### [154] [RunawayEvil: Jailbreaking the Image-to-Video Generative Models](https://arxiv.org/abs/2512.06674)
*Songping Wang,Rufan Qian,Yueming Lyu,Qinglong Liu,Linzhuang Zou,Jie Qin,Songhua Liu,Caifeng Shan*

Main category: cs.CV

TL;DR: RunawayEvil是首个针对图像到视频生成模型的多模态越狱攻击框架，采用"策略-战术-行动"范式，通过强化学习和LLM实现自我进化的攻击能力，在商业I2V模型上取得了显著攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 图像到视频生成系统虽然提供了重要的创意控制能力，但其安全性，特别是对越狱攻击的脆弱性，目前尚未得到充分研究。作者旨在填补这一空白，为I2V模型的漏洞分析提供关键工具。

Method: 基于"策略-战术-行动"范式构建了自我放大的攻击框架，包含三个核心组件：1) 策略感知命令单元，通过强化学习驱动的策略定制和LLM策略探索实现攻击策略自我进化；2) 多模态战术规划单元，根据选定策略生成协调的文本越狱指令和图像篡改指南；3) 战术行动单元，执行和评估多模态协调攻击。

Result: 在Open-Sora 2.0和CogVideoX等商业I2V模型上的广泛实验表明，RunawayEvil实现了最先进的攻击成功率，在COCO2017数据集上比现有方法高出58.5%到79%。

Conclusion: 该工作为I2V模型的漏洞分析提供了关键工具，为构建更鲁棒的视频生成系统奠定了基础，揭示了多模态生成系统在安全方面的重要挑战。

Abstract: Image-to-Video (I2V) generation synthesizes dynamic visual content from image and text inputs, providing significant creative control. However, the security of such multimodal systems, particularly their vulnerability to jailbreak attacks, remains critically underexplored. To bridge this gap, we propose RunawayEvil, the first multimodal jailbreak framework for I2V models with dynamic evolutionary capability. Built on a "Strategy-Tactic-Action" paradigm, our framework exhibits self-amplifying attack through three core components: (1) Strategy-Aware Command Unit that enables the attack to self-evolve its strategies through reinforcement learning-driven strategy customization and LLM-based strategy exploration; (2) Multimodal Tactical Planning Unit that generates coordinated text jailbreak instructions and image tampering guidelines based on the selected strategies; (3) Tactical Action Unit that executes and evaluates the multimodal coordinated attacks. This self-evolving architecture allows the framework to continuously adapt and intensify its attack strategies without human intervention. Extensive experiments demonstrate RunawayEvil achieves state-of-the-art attack success rates on commercial I2V models, such as Open-Sora 2.0 and CogVideoX. Specifically, RunawayEvil outperforms existing methods by 58.5 to 79 percent on COCO2017. This work provides a critical tool for vulnerability analysis of I2V models, thereby laying a foundation for more robust video generation systems.

</details>


### [155] [EMGauss: Continuous Slice-to-3D Reconstruction via Dynamic Gaussian Modeling in Volume Electron Microscopy](https://arxiv.org/abs/2512.06684)
*Yumeng He,Zanwei Zhou,Yekun Zheng,Chen Liang,Yunbo Wang,Xiaokang Yang*

Main category: cs.CV

TL;DR: EMGauss：基于高斯泼溅的3D重建框架，将2D切片序列视为动态场景，通过教师-学生自举机制提升稀疏数据下的重建质量，适用于体积电子显微镜等成像领域。


<details>
  <summary>Details</summary>
Motivation: 体积电子显微镜（vEM）在3D成像中存在各向异性问题，现有基于各向同性假设的深度学习方法对形态各向异性结构效果不佳，需要更通用的切片到3D重建方法。

Method: 将切片到3D重建重新定义为基于高斯泼溅的3D动态场景渲染问题，将轴向切片进展建模为2D高斯点云的时间演化，并引入教师-学生自举机制利用高置信度预测作为伪监督信号。

Result: 相比基于扩散和GAN的重建方法，EMGauss显著提高了插值质量，实现了连续切片合成，且无需大规模预训练，为跨成像领域的通用切片到3D重建提供了解决方案。

Conclusion: EMGauss通过高斯泼溅框架和自举机制，克服了传统各向同性方法的局限性，为体积电子显微镜及其他成像领域的各向异性3D重建提供了有效且通用的解决方案。

Abstract: Volume electron microscopy (vEM) enables nanoscale 3D imaging of biological structures but remains constrained by acquisition trade-offs, leading to anisotropic volumes with limited axial resolution. Existing deep learning methods seek to restore isotropy by leveraging lateral priors, yet their assumptions break down for morphologically anisotropic structures. We present EMGauss, a general framework for 3D reconstruction from planar scanned 2D slices with applications in vEM, which circumvents the inherent limitations of isotropy-based approaches. Our key innovation is to reframe slice-to-3D reconstruction as a 3D dynamic scene rendering problem based on Gaussian splatting, where the progression of axial slices is modeled as the temporal evolution of 2D Gaussian point clouds. To enhance fidelity in data-sparse regimes, we incorporate a Teacher-Student bootstrapping mechanism that uses high-confidence predictions on unobserved slices as pseudo-supervisory signals. Compared with diffusion- and GAN-based reconstruction methods, EMGauss substantially improves interpolation quality, enables continuous slice synthesis, and eliminates the need for large-scale pretraining. Beyond vEM, it potentially provides a generalizable slice-to-3D solution across diverse imaging domains.

</details>


### [156] [Lightweight Wasserstein Audio-Visual Model for Unified Speech Enhancement and Separation](https://arxiv.org/abs/2512.06689)
*Jisoo Park,Seonghak Lee,Guisik Kim,Taewoo Kim,Junseok Kwon*

Main category: cs.CV

TL;DR: UniVoiceLite：轻量级无监督视听框架，统一语音增强和语音分离任务，利用唇部运动和面部身份线索，无需配对噪声-干净数据。


<details>
  <summary>Details</summary>
Motivation: 现实世界音频通常同时包含背景噪声和重叠说话人，需要统一解决方案。现有方法多为多阶段架构，模型复杂、参数多且依赖监督训练，限制了可扩展性和泛化能力。

Method: 提出UniVoiceLite框架，利用唇部运动和面部身份线索指导语音提取，采用Wasserstein距离正则化稳定潜在空间，无需配对噪声-干净数据。

Result: 实验结果表明，UniVoiceLite在噪声和多说话人场景中均表现出色，兼具高效性和鲁棒泛化能力。

Conclusion: UniVoiceLite成功统一了语音增强和语音分离任务，提供了一种轻量级、无监督的解决方案，具有良好的性能和泛化能力。

Abstract: Speech Enhancement (SE) and Speech Separation (SS) have traditionally been treated as distinct tasks in speech processing. However, real-world audio often involves both background noise and overlapping speakers, motivating the need for a unified solution. While recent approaches have attempted to integrate SE and SS within multi-stage architectures, these approaches typically involve complex, parameter-heavy models and rely on supervised training, limiting scalability and generalization. In this work, we propose UniVoiceLite, a lightweight and unsupervised audio-visual framework that unifies SE and SS within a single model. UniVoiceLite leverages lip motion and facial identity cues to guide speech extraction and employs Wasserstein distance regularization to stabilize the latent space without requiring paired noisy-clean data. Experimental results demonstrate that UniVoiceLite achieves strong performance in both noisy and multi-speaker scenarios, combining efficiency with robust generalization. The source code is available at https://github.com/jisoo-o/UniVoiceLite.

</details>


### [157] [The Role of Entropy in Visual Grounding: Analysis and Optimization](https://arxiv.org/abs/2512.06726)
*Shuo Li,Jiajun Sun,Zhihao Zhang,Xiaoran Fan,Senjie Jin,Hui Li,Yuming Yang,Junjie Ye,Lixing Shen,Tao Ji,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CV

TL;DR: 本文提出ECVGPO算法，通过熵控制优化视觉定位任务中多模态大语言模型的强化学习微调，平衡探索与利用，在多个基准测试中取得广泛改进。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在强化学习微调中已采用多种熵控制技术，但在感知导向任务（如视觉定位）中，熵的作用特性及有效控制策略尚未充分探索。

Method: 首先分析视觉定位任务中熵的作用特性并与推理任务对比，基于此提出ECVGPO（熵控制视觉定位策略优化）算法，该算法具有可解释性，能有效调节熵以平衡探索与利用。

Result: 实验表明，ECVGPO在多种基准测试和模型上均取得广泛改进。

Conclusion: 通过熵控制可以更好地平衡探索与利用的权衡，ECVGPO算法为视觉定位任务提供了有效的强化学习微调方法。

Abstract: Recent advances in fine-tuning multimodal large language models (MLLMs) using reinforcement learning have achieved remarkable progress, particularly with the introduction of various entropy control techniques. However, the role and characteristics of entropy in perception-oriented tasks like visual grounding, as well as effective strategies for controlling it, remain largely unexplored. To address this issue, we focus on the visual grounding task and analyze the role and characteristics of entropy in comparison to reasoning tasks. Building on these findings, we introduce ECVGPO (Entropy Control Visual Grounding Policy Optimization), an interpretable algorithm designed for effective entropy regulation. Through entropy control, the trade-off between exploration and exploitation is better balanced. Experiments show that ECVGPO achieves broad improvements across various benchmarks and models.

</details>


### [158] [Graph Convolutional Long Short-Term Memory Attention Network for Post-Stroke Compensatory Movement Detection Based on Skeleton Data](https://arxiv.org/abs/2512.06736)
*Jiaxing Fan,Jiaojiao Liu,Wenkong Wang,Yang Zhang,Xin Ma,Jichen Zhang*

Main category: cs.CV

TL;DR: 提出基于骨架数据的GCN-LSTM-ATT网络用于卒中后补偿动作检测，相比传统机器学习方法准确率更高


<details>
  <summary>Details</summary>
Motivation: 大多数卒中患者存在上肢运动功能障碍，康复训练中普遍存在补偿动作，这对患者长期恢复不利，因此检测补偿动作具有重要意义

Method: 使用Kinect深度相机采集16名卒中患者执行特定康复动作的骨架数据，构建GCN-LSTM-ATT模型，并与SVM、KNN、RF等传统机器学习算法对比

Result: GCN-LSTM-ATT模型的检测准确率达到0.8580，显著高于传统机器学习算法，消融实验表明模型的各个组件对性能提升均有显著贡献

Conclusion: 该研究为卒中后补偿动作检测提供了更精确、更强大的工具，有望促进卒中患者康复训练策略的优化

Abstract: Most stroke patients experience upper limb motor dysfunction. Compensatory movements are prevalent during rehabilitation training, which is detrimental to patients' long-term recovery. Therefore, detecting compensatory movements is of great significance. In this study, a Graph Convolutional Long Short-Term Memory Attention Network (GCN-LSTM-ATT) based on skeleton data is proposed for the detection of compensatory movements after stroke. Sixteen stroke patients were selected in the research. The skeleton data of the patients performing specific rehabilitation movements were collected using the Kinect depth camera. After data processing, detection models were constructed respectively using the GCN-LSTM-ATT model, the Support Vector Machine(SVM), the K-Nearest Neighbor algorithm(KNN), and the Random Forest(RF). The results show that the detection accuracy of the GCN-LSTM-ATT model reaches 0.8580, which is significantly higher than that of traditional machine learning algorithms. Ablation experiments indicate that each component of the model contributes significantly to the performance improvement. These findings provide a more precise and powerful tool for the detection of compensatory movements after stroke, and are expected to facilitate the optimization of rehabilitation training strategies for stroke patients.

</details>


### [159] [FedSCAl: Leveraging Server and Client Alignment for Unsupervised Federated Source-Free Domain Adaptation](https://arxiv.org/abs/2512.06738)
*M Yashwanth,Sampath Koti,Arunabh Singh,Shyam Marjit,Anirban Chakraborty*

Main category: cs.CV

TL;DR: FedSCAl：一个用于联邦源自由域适应（FFreeDA）的联邦学习框架，通过服务器-客户端对齐机制缓解客户端漂移，提高伪标签准确性


<details>
  <summary>Details</summary>
Motivation: 解决联邦源自由域适应（FFreeDA）问题，其中客户端持有未标记数据且存在显著的客户端间域差距。FFreeDA设置限制了FL框架只能使用预训练的服务器模型，无法在训练轮次中访问源数据集，而源域数据分布通常与客户端域不同。现有的源自由域适应方法在FL中面临客户端漂移问题，特别是在数据异构性极端的情况下导致伪标签不可靠。

Method: 提出FedSCAl框架，采用服务器-客户端对齐（SCAl）机制，通过对齐客户端和服务器模型的预测来正则化客户端更新。该机制帮助缓解客户端漂移，提高客户端伪标签的准确性。

Result: 在基准视觉数据集上的广泛实验表明，FedSCAl在FFreeDA设置下的分类任务中持续优于最先进的FL方法。

Conclusion: FedSCAl通过服务器-客户端对齐机制有效解决了FFreeDA设置中的客户端漂移问题，提高了伪标签准确性，在联邦源自由域适应任务中表现出优越性能。

Abstract: We address the Federated source-Free Domain Adaptation (FFreeDA) problem, with clients holding unlabeled data with significant inter-client domain gaps. The FFreeDA setup constrains the FL frameworks to employ only a pre-trained server model as the setup restricts access to the source dataset during the training rounds. Often, this source domain dataset has a distinct distribution to the clients' domains. To address the challenges posed by the FFreeDA setup, adaptation of the Source-Free Domain Adaptation (SFDA) methods to FL struggles with client-drift in real-world scenarios due to extreme data heterogeneity caused by the aforementioned domain gaps, resulting in unreliable pseudo-labels. In this paper, we introduce FedSCAl, an FL framework leveraging our proposed Server-Client Alignment (SCAl) mechanism to regularize client updates by aligning the clients' and server model's predictions. We observe an improvement in the clients' pseudo-labeling accuracy post alignment, as the SCAl mechanism helps to mitigate the client-drift. Further, we present extensive experiments on benchmark vision datasets showcasing how FedSCAl consistently outperforms state-of-the-art FL methods in the FFreeDA setup for classification tasks.

</details>


### [160] [Task-Model Alignment: A Simple Path to Generalizable AI-Generated Image Detection](https://arxiv.org/abs/2512.06746)
*Ruoxin Chen,Jiahui Gao,Kaiqing Lin,Keyue Zhang,Yandan Zhao,Isabel Guan,Taiping Yao,Shouhong Ding*

Main category: cs.CV

TL;DR: 论文提出任务-模型对齐原则，将AIGI检测分解为语义一致性检查和像素伪影检测两个互补任务，并构建AlignGemini双分支检测器，在五个基准测试中平均准确率提升9.5%


<details>
  <summary>Details</summary>
Motivation: 当前基于视觉语言模型(VLMs)的AI生成图像检测方法需要大量资源且存在严重幻觉问题。研究发现VLMs擅长语义理解但对像素级伪影不敏感，而传统像素伪影检测器又缺乏语义意识，因此需要解决任务与模型之间的不匹配问题。

Method: 提出任务-模型对齐原则，将AIGI检测形式化为两个互补任务：语义一致性检查和像素伪影检测。构建AlignGemini双分支检测器，一个分支使用纯语义监督微调VLM，另一个分支使用纯像素伪影监督训练像素伪影专家。通过正交监督在两个简化数据集上训练，使每个分支发挥各自优势。

Result: 在五个真实世界基准测试中，AlignGemini实现了平均准确率提升9.5%，证明了任务-模型对齐原则在提高AIGI检测泛化能力方面的有效性。

Conclusion: 任务-模型对齐是提高AI生成图像检测泛化能力的有效途径。通过将检测任务分解为互补的语义和像素级子任务，并分别使用最适合的模型架构，可以克服单一模型的局限性，实现更全面的检测能力。

Abstract: Vision Language Models (VLMs) are increasingly adopted for AI-generated images (AIGI) detection, yet converting VLMs into detectors requires substantial resource, while the resulting models still exhibit severe hallucinations. To probe the core issue, we conduct an empirical analysis and observe two characteristic behaviors: (i) fine-tuning VLMs on high-level semantic supervision strengthens semantic discrimination and well generalize to unseen data; (ii) fine-tuning VLMs on low-level pixel-artifact supervision yields poor transfer. We attribute VLMs' underperformance to task-model misalignment: semantics-oriented VLMs inherently lack sensitivity to fine-grained pixel artifacts, and semantically non-discriminative pixel artifacts thus exceeds their inductive biases. In contrast, we observe that conventional pixel-artifact detectors capture low-level pixel artifacts yet exhibit limited semantic awareness relative to VLMs, highlighting that distinct models are better matched to distinct tasks. In this paper, we formalize AIGI detection as two complementary tasks--semantic consistency checking and pixel-artifact detection--and show that neglecting either induces systematic blind spots. Guided by this view, we introduce the Task-Model Alignment principle and instantiate it as a two-branch detector, AlignGemini, comprising a VLM fine-tuned exclusively with pure semantic supervision and a pixel-artifact expert trained exclusively with pure pixel-artifact supervision. By enforcing orthogonal supervision on two simplified datasets, each branch trains to its strengths, producing complementary discrimination over semantic and pixel cues. On five in-the-wild benchmarks, AlignGemini delivers a +9.5 gain in average accuracy, supporting task-model alignment as an effective path to generalizable AIGI detection.

</details>


### [161] [UARE: A Unified Vision-Language Model for Image Quality Assessment, Restoration, and Enhancement](https://arxiv.org/abs/2512.06750)
*Weiqi Li,Xuanyu Zhang,Bin Chen,Jingfen Xie,Yan Wang,Kexin Zhang,Junlin Li,Li Zhang,Jian Zhang,Shijie Zhao*

Main category: cs.CV

TL;DR: UARE是首个统一图像质量评估、修复和增强的视觉语言模型，通过两阶段训练框架实现多任务协同，利用质量评估指导修复增强。


<details>
  <summary>Details</summary>
Motivation: 图像质量评估和修复在概念上紧密相关，但现有工作大多孤立处理。统一多模态理解-生成模型的最新进展表明，更强的理解能力可以提升生成性能，这促使研究如何用IQA指导修复的单一统一模型。

Method: 基于预训练的统一理解和生成模型，采用两阶段训练框架：1) 渐进式从单一失真到高阶混合退化的训练，使模型能处理多种退化；2) 使用交错文本-图像数据进行统一微调，将IQA信号与修复目标对齐，通过多任务协同训练让IQA提升修复增强性能。

Result: 在IQA、修复和增强任务上的广泛实验证明了UARE的有效性。

Conclusion: UARE是首个统一图像质量评估、修复和增强的视觉语言模型，通过多任务协同训练成功利用IQA指导修复增强，展现了统一模型的优势。

Abstract: Image quality assessment (IQA) and image restoration are fundamental problems in low-level vision. Although IQA and restoration are closely connected conceptually, most existing work treats them in isolation. Recent advances in unified multimodal understanding-generation models demonstrate promising results and indicate that stronger understanding can improve generative performance. This motivates a single model that unifies IQA and restoration and explicitly studies how IQA can guide restoration, a setting that remains largely underexplored yet highly valuable. In this paper, we propose UARE, to our knowledge the first Unified vision-language model for image quality Assessment, Restoration, and Enhancement. Built on pretrained unified understanding and generation models, we introduce a two-stage training framework. First, a progressive, easy-to-hard schedule expands from single-type distortions to higher-order mixed degradations, enabling UARE to handle multiple degradations. Second, we perform unified fine-tuning of quality understanding and restoration with interleaved text-image data, aligning IQA signals with restoration objectives. Through multi-task co-training, UARE leverages IQA to boost restoration and enhancement performance. Extensive experiments across IQA, restoration, and enhancement tasks demonstrate the effectiveness of UARE. The code and models will be available at https://github.com/lwq20020127/UARE.

</details>


### [162] [VisChainBench: A Benchmark for Multi-Turn, Multi-Image Visual Reasoning Beyond Language Priors](https://arxiv.org/abs/2512.06759)
*Wenbo Lyu,Yingjun Du,Jinglin Zhao,Xianton Zhen,Ling Shao*

Main category: cs.CV

TL;DR: VisChainBench是一个大规模基准测试，用于评估大型视觉语言模型在多图像、多轮场景中进行多步视觉推理的能力，包含1,457个任务和超过20,000张图像。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注静态或水平比较，过度依赖语言线索，忽视了渐进式、上下文相关的推理和视觉到视觉的推理挑战。需要评估LVLMs在序列化、相互依赖任务中的多步视觉推理能力。

Method: 使用多智能体生成流水线构建基准测试，确保视觉多样性和控制语言偏见。包含三个不同领域（日常场景、工程故障排除等）的1,457个任务，超过20,000张图像，模拟真实世界决策过程。

Result: 创建了VisChainBench基准测试，包含大规模任务和图像数据集，所有基准数据和代码都可通过Hugging Face获取，为评估LVLMs的多步视觉推理能力提供了标准化测试平台。

Conclusion: VisChainBench填补了现有基准测试的空白，能够更全面地评估大型视觉语言模型在多图像、多轮场景中的视觉推理能力，促进该领域的研究发展。

Abstract: Understanding multi-image, multi-turn scenarios is a critical yet underexplored capability for Large Vision-Language Models (LVLMs). Existing benchmarks predominantly focus on static or horizontal comparisons -- e.g., spotting visual differences or assessing appropriateness -- while relying heavily on language cues. Such settings overlook progressive, context-dependent reasoning and the challenge of visual-to-visual inference. To bridge this gap, we present VisChainBench, a large-scale benchmark designed to rigorously evaluate LVLMs' ability to perform multi-step visual reasoning across sequential, interdependent tasks with minimal language guidance. VisChainBench contains 1,457 tasks spanning over 20,000 images across three diverse domains (e.g., daily scenarios, engineering troubleshooting), structured to mimic real-world decision-making processes. Uniquely, the benchmark is constructed using a multi-agent generation pipeline, ensuring high visual diversity and controlled language bias. All the benchmark data and code for benchmark construction are available for viewing and download via following Link: https://huggingface.co/datasets/eyehole/VisChainBench

</details>


### [163] [MMDuet2: Enhancing Proactive Interaction of Video MLLMs with Multi-Turn Reinforcement Learning](https://arxiv.org/abs/2512.06810)
*Yueqian Wang,Songxiang Liu,Disong Wang,Nuo Xu,Guanglu Wan,Huishuai Zhang,Dongyan Zhao*

Main category: cs.CV

TL;DR: MMDuet2：一种基于多轮RL训练的视频多模态大语言模型，能够主动决定在视频播放过程中何时回应，无需精确回复时间标注，在响应时机和质量上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频多模态大语言模型大多采用回合制交互方式，只能在用户回合结束后回复。然而，在视频播放过程中主动决定何时回应对于实时应用具有重要意义，但现有方法面临手动调整响应决策阈值和标注精确回复时间等挑战。

Method: 提出文本到文本的主动交互方法，模型基于对话历史和当前视频帧的视觉上下文自主决定是回应还是保持沉默。引入多轮强化学习训练方法，鼓励及时准确的响应，无需精确的回复时间标注。在包含52k视频和两种对话类型的数据集上通过监督微调和强化学习训练MMDuet2模型。

Result: MMDuet2在响应时机和质量上优于现有的主动视频MLLM基线方法，在ProactiveVideoQA基准测试中实现了最先进的性能。

Conclusion: 该研究提出了一种无需精确回复时间标注的主动视频交互方法，通过多轮RL训练实现了更好的响应时机决策，为实时视频应用中的主动交互提供了有效解决方案。

Abstract: Recent advances in video multimodal large language models (Video MLLMs) have significantly enhanced video understanding and multi-modal interaction capabilities. While most existing systems operate in a turn-based manner where the model can only reply after user turns, proactively deciding when to reply during video playback presents a promising yet challenging direction for real-time applications. In this work, we propose a novel text-to-text approach to proactive interaction, where the model autonomously determines whether to respond or remain silent at each turn based on dialogue history and visual context up to current frame of an streaming video. To overcome difficulties in previous methods such as manually tuning response decision thresholds and annotating precise reply times, we introduce a multi-turn RL based training method that encourages timely and accurate responses without requiring precise response time annotations. We train our model MMDuet2 on a dataset of 52k videos with two types of dialogues via SFT and RL. Experimental results demonstrate that MMDuet2 outperforms existing proactive Video MLLM baselines in response timing and quality, achieving state-of-the-art performance on the ProactiveVideoQA benchmark.

</details>


### [164] [JOCA: Task-Driven Joint Optimisation of Camera Hardware and Adaptive Camera Control Algorithms](https://arxiv.org/abs/2512.06763)
*Chengyang Yan,Mitch Bryson,Donald G. Dansereau*

Main category: cs.CV

TL;DR: 本文提出了一种联合优化相机硬件和自适应控制算法的方法，通过混合优化策略提升下游视觉任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有相机系统设计大多关注制造时固定的硬件参数优化，而许多参数（如曝光设置）需要在运行时进行自适应控制。当前方法通常将硬件参数和自适应控制分开优化，缺乏统一的联合优化框架。

Method: 提出统一的优化框架，结合基于梯度和无导数方法，支持连续和离散参数、不可微的图像形成过程以及基于神经网络的自适应控制算法。针对运动模糊等不可微效应，提出DF-Grad混合优化策略，使用无导数优化器的信号训练自适应控制网络，并结合无监督任务驱动学习。

Result: 实验表明，该方法在低光照和快速运动等挑战性条件下，优于分别优化静态和动态参数的基线方法。联合优化硬件参数和自适应控制算法显著提升了感知性能。

Conclusion: 联合优化相机硬件参数和自适应控制算法能够改善感知性能，为任务驱动的相机系统设计提供了统一的方法框架。

Abstract: The quality of captured images strongly influences the performance of downstream perception tasks. Recent works on co-designing camera systems with perception tasks have shown improved task performance. However, most prior approaches focus on optimising fixed camera parameters set at manufacturing, while many parameters, such as exposure settings, require adaptive control at runtime. This paper introduces a method that jointly optimises camera hardware and adaptive camera control algorithms with downstream vision tasks. We present a unified optimisation framework that integrates gradient-based and derivative-free methods, enabling support for both continuous and discrete parameters, non-differentiable image formation processes, and neural network-based adaptive control algorithms. To address non-differentiable effects such as motion blur, we propose DF-Grad, a hybrid optimisation strategy that trains adaptive control networks using signals from a derivative-free optimiser alongside unsupervised task-driven learning. Experiments show that our method outperforms baselines that optimise static and dynamic parameters separately, particularly under challenging conditions such as low light and fast motion. These results demonstrate that jointly optimising hardware parameters and adaptive control algorithms improves perception performance and provides a unified approach to task-driven camera system design.

</details>


### [165] [Less Is More, but Where? Dynamic Token Compression via LLM-Guided Keyframe Prior](https://arxiv.org/abs/2512.06866)
*Yulin Li,Haokun Gui,Ziyang Fan,Junjie Wang,Bin Kang,Bin Chen,Zhuotao Tian*

Main category: cs.CV

TL;DR: DyToK：一种无需训练的VLLM动态token压缩方法，利用LLM引导的关键帧先验，通过注意力机制动态调整每帧token保留比例，在保持精度的同时实现4.3倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型在处理长视频时面临二次计算复杂度增长的问题。传统关键帧采样方法虽然能提升效率，但会引入额外计算成本，且二元帧选择范式不够理想。

Method: 提出DyToK方法，利用VLLM固有的注意力机制进行动态token压缩。分析发现VLLM注意力层自然编码了查询条件的关键帧先验，据此动态调整每帧token保留比例，优先保留语义丰富的帧并抑制冗余。

Result: DyToK实现了最先进的效率-精度权衡，与现有压缩方法（如VisionZip和FastV）兼容，在LLaVA-OneVision和Qwen2.5-VL等多个VLLM上实现4.3倍推理加速同时保持精度。

Conclusion: DyToK提供了一种无需训练的动态token压缩范式，有效解决了VLLM处理长视频时的效率瓶颈问题，具有即插即用兼容性。

Abstract: Recent advances in Video Large Language Models (VLLMs) have achieved remarkable video understanding capabilities, yet face critical efficiency bottlenecks due to quadratic computational growth with lengthy visual token sequences of long videos. While existing keyframe sampling methods can improve temporal modeling efficiency, additional computational cost is introduced before feature encoding, and the binary frame selection paradigm is found suboptimal. Therefore, in this work, we propose Dynamic Token compression via LLM-guided Keyframe prior (DyToK), a training-free paradigm that enables dynamic token compression by harnessing VLLMs' inherent attention mechanisms. Our analysis reveals that VLLM attention layers naturally encoding query-conditioned keyframe priors, by which DyToK dynamically adjusts per-frame token retention ratios, prioritizing semantically rich frames while suppressing redundancies. Extensive experiments demonstrate that DyToK achieves state-of-the-art efficiency-accuracy tradeoffs. DyToK shows plug-and-play compatibility with existing compression methods, such as VisionZip and FastV, attaining 4.3x faster inference while preserving accuracy across multiple VLLMs, such as LLaVA-OneVision and Qwen2.5-VL. Code is available at https://github.com/yu-lin-li/DyToK .

</details>


### [166] [Stitch and Tell: A Structured Multimodal Data Augmentation Method for Spatial Understanding](https://arxiv.org/abs/2512.06769)
*Hang Yin,Xiaomin He,PeiWen Yuan,Yiwei Li,Jiayi Shi,Wenxiao Fan,Shaoxiong Feng,Kan Li*

Main category: cs.CV

TL;DR: 提出Stitch and Tell方法，通过拼接图像和生成空间感知描述来增强视觉语言模型的空间理解能力，减少空间幻觉问题


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型存在空间幻觉问题，即对图像中物体相对位置生成错误描述。这主要源于图像和文本之间的不对称特性。

Method: 提出Stitch and Tell方法：1) 沿空间轴拼接图像构造缝合图像；2) 基于缝合图像布局生成空间感知的标题或问答对；3) 无需标注、即插即用，不依赖昂贵的高级模型或人工参与。

Result: 在三种架构(LLaVA-v1.5-7B, LLaVA-Qwen2-1.5B, HALVA-7B)、两个训练数据集和八个基准测试上评估。结果显示：空间理解任务显著提升(MME_Position +5.50%, Spatial-MM +4.19%)，同时保持或提升通用视觉语言基准性能(COCO-QA +1.02%, MMBench +4.76%)。

Conclusion: 将空间感知结构显式注入训练数据是缓解空间幻觉、提升空间理解能力的有效方法，同时能保持通用视觉语言能力。

Abstract: Existing vision-language models often suffer from spatial hallucinations, i.e., generating incorrect descriptions about the relative positions of objects in an image. We argue that this problem mainly stems from the asymmetric properties between images and text. To enrich the spatial understanding ability of vision-language models, we propose a simple, annotation-free, plug-and-play method named $\text{Stitch and Tell}$ (abbreviated as SiTe), which injects structured spatial supervision into data. It constructs stitched image-text pairs by stitching images along a spatial axis and generating spatially-aware captions or question answer pairs based on the layout of stitched image, without relying on costly advanced models or human involvement. We evaluate SiTe across three architectures including LLaVA-v1.5-7B, LLaVA-Qwen2-1.5B and HALVA-7B, two training datasets, and eight benchmarks. Experiments show that SiTe improves spatial understanding tasks such as $\text{MME}_{\text{Position}}$ (+5.50%) and Spatial-MM (+4.19%), while maintaining or improving performance on general vision-language benchmarks including COCO-QA (+1.02%) and MMBench (+4.76%). Our findings suggest that explicitly injecting spatially-aware structure into training data offers an effective way to mitigate spatial hallucinations and improve spatial understanding, while preserving general vision-language capabilities.

</details>


### [167] [NeuroABench: A Multimodal Evaluation Benchmark for Neurosurgical Anatomy Identification](https://arxiv.org/abs/2512.06921)
*Ziyang Song,Zelin Zang,Xiaofan Ye,Boqiang Xu,Long Bai,Jinlin Wu,Hongliang Ren,Hongbin Liu,Jiebo Luo,Zhen Lei*

Main category: cs.CV

TL;DR: 本文介绍了首个专门评估神经外科解剖理解的多模态基准NeuroABench，包含9小时标注视频，覆盖89种手术和68个解剖结构。实验显示当前MLLMs在解剖识别任务上表现有限（最佳模型仅40.87%准确率），远低于神经外科学员的平均水平（46.5%）。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs研究主要关注手术流程理解，忽视了临床实践中至关重要的解剖理解能力。外科医生依赖精确的解剖知识来解读、回顾和学习手术视频，因此需要专门的基准来评估和改进MLLMs的解剖理解能力。

Method: 1. 创建NeuroABench基准：包含9小时标注的神经外科视频，覆盖89种不同手术；2. 采用新颖的多模态标注流程，包含多个审查周期；3. 评估68个临床解剖结构的识别能力；4. 对10多个SOTA MLLMs进行实验评估；5. 提取数据集子集，与4名神经外科学员进行对比测试。

Result: 1. MLLMs表现有限：最佳模型在解剖识别任务中仅达到40.87%准确率；2. 人类对比：最佳学员准确率56%，最低28%，平均46.5%；3. 差距分析：最佳MLLM与最低分学员相当，但显著低于人类平均水平，显示MLLMs在解剖理解方面仍有很大提升空间。

Conclusion: NeuroABench填补了评估MLLMs解剖理解能力的空白。虽然MLLMs在解剖理解方面取得了一定进展，但与人类专家相比仍有显著差距。该基准为未来研究提供了标准化评估框架，有助于推动MLLMs在手术教育和辅助方面的发展。

Abstract: Multimodal Large Language Models (MLLMs) have shown significant potential in surgical video understanding. With improved zero-shot performance and more effective human-machine interaction, they provide a strong foundation for advancing surgical education and assistance. However, existing research and datasets primarily focus on understanding surgical procedures and workflows, while paying limited attention to the critical role of anatomical comprehension. In clinical practice, surgeons rely heavily on precise anatomical understanding to interpret, review, and learn from surgical videos. To fill this gap, we introduce the Neurosurgical Anatomy Benchmark (NeuroABench), the first multimodal benchmark explicitly created to evaluate anatomical understanding in the neurosurgical domain. NeuroABench consists of 9 hours of annotated neurosurgical videos covering 89 distinct procedures and is developed using a novel multimodal annotation pipeline with multiple review cycles. The benchmark evaluates the identification of 68 clinical anatomical structures, providing a rigorous and standardized framework for assessing model performance. Experiments on over 10 state-of-the-art MLLMs reveal significant limitations, with the best-performing model achieving only 40.87% accuracy in anatomical identification tasks. To further evaluate the benchmark, we extract a subset of the dataset and conduct an informative test with four neurosurgical trainees. The results show that the best-performing student achieves 56% accuracy, with the lowest scores of 28% and an average score of 46.5%. While the best MLLM performs comparably to the lowest-scoring student, it still lags significantly behind the group's average performance. This comparison underscores both the progress of MLLMs in anatomical understanding and the substantial gap that remains in achieving human-level performance.

</details>


### [168] [RDSplat: Robust Watermarking Against Diffusion Editing for 3D Gaussian Splatting](https://arxiv.org/abs/2512.06774)
*Longjie Zhao,Ziming Hong,Zhenyang Ren,Runnan Chen,Mingming Gong,Tongliang Liu*

Main category: cs.CV

TL;DR: RDSplat：针对3D高斯泼溅的鲁棒水印方法，专门抵抗扩散式编辑攻击，通过嵌入低频高斯分量和对抗训练实现


<details>
  <summary>Details</summary>
Motivation: 现有3DGS水印方法对扩散式编辑攻击极为脆弱，容易被擦除水印信息，需要开发能抵抗此类攻击的鲁棒水印技术

Method: 1) 将水印嵌入扩散编辑会保留的低频高斯分量；2) 使用多域框架在3DGS空间操作；3) 通过协方差正则化和2D滤波嵌入水印；4) 用高斯模糊作为扩散编辑的代理进行对抗训练

Result: 在三个基准数据集上的综合评估显示，RDSplat在扩散式编辑下保持优越的鲁棒性，同时保持水印不可见性，达到最先进性能

Conclusion: RDSplat为3D高斯泼溅提供了一种能抵抗扩散式编辑攻击的鲁棒水印范式，解决了现有方法的脆弱性问题

Abstract: 3D Gaussian Splatting (3DGS) has enabled the creation of digital assets and downstream applications, underscoring the need for robust copyright protection via digital watermarking. However, existing 3DGS watermarking methods remain highly vulnerable to diffusion-based editing, which can easily erase embedded provenance. This challenge highlights the urgent need for 3DGS watermarking techniques that are intrinsically resilient to diffusion-based editing. In this paper, we introduce RDSplat, a Robust watermarking paradigm against Diffusion editing for 3D Gaussian Splatting. RDSplat embeds watermarks into 3DGS components that diffusion-based editing inherently preserve, achieved through (i) proactively targeting low-frequency Gaussians and (ii) adversarial training with a diffusion proxy. Specifically, we introduce a multi-domain framework that operates natively in 3DGS space and embeds watermarks into diffusion-editing-preserved low-frequency Gaussians via coordinated covariance regularization and 2D filtering. In addition, we exploit the low-pass filtering behavior of diffusion-based editing by using Gaussian blur as an efficient training surrogate, enabling adversarial fine-tuning that further enhances watermark robustness against diffusion-based editing. Empirically, comprehensive quantitative and qualitative evaluations on three benchmark datasets demonstrate that RDSplat not only maintains superior robustness under diffusion-based editing, but also preserves watermark invisibility, achieving state-of-the-art performance.

</details>


### [169] [Physics Informed Human Posture Estimation Based on 3D Landmarks from Monocular RGB-Videos](https://arxiv.org/abs/2512.06783)
*Tobias Leuthold,Michele Xiloyannis,Yves Zimmermann*

Main category: cs.CV

TL;DR: 提出一种实时后处理算法，融合BlazePose的3D和2D估计，通过加权优化结合骨骼长度约束和生物力学模型，提升姿态估计的解剖学一致性


<details>
  <summary>Details</summary>
Motivation: 现有实时姿态估计模型（如BlazePose）缺乏解剖学约束，在物理治疗等应用中需要更准确、更符合解剖学的姿态估计

Method: 使用加权优化融合BlazePose的3D和2D估计，通过惩罚与预期骨骼长度和生物力学模型的偏差来约束结果，并用卡尔曼滤波器根据个体解剖特征优化骨骼长度估计

Result: 在Physio2.2M数据集上，相比BlazePose 3D估计，3D MPJPE降低10.2%，身体段间角度误差减少16.6%

Conclusion: 该方法提供了一种鲁棒、解剖学一致且计算高效的姿态估计方案，适用于消费级设备的自动物理治疗、医疗保健和运动指导应用

Abstract: Applications providing automated coaching for physical training are increasing in popularity, for example physical therapy. These applications rely on accurate and robust pose estimation using monocular video streams. State-of-the-art models like BlazePose excel in real-time pose tracking, but their lack of anatomical constraints indicates improvement potential by including physical knowledge. We present a real-time post-processing algorithm fusing the strengths of BlazePose 3D and 2D estimations using a weighted optimization, penalizing deviations from expected bone length and biomechanical models. Bone length estimations are refined to the individual anatomy using a Kalman filter with adapting measurement trust. Evaluation using the Physio2.2M dataset shows a 10.2 percent reduction in 3D MPJPE and a 16.6 percent decrease in errors of angles between body segments compared to BlazePose 3D estimation. Our method provides a robust, anatomically consistent pose estimation based on a computationally efficient video-to-3D pose estimation, suitable for automated physiotherapy, healthcare, and sports coaching on consumer-level laptops and mobile devices. The refinement runs on the backend with anonymized data only.

</details>


### [170] [Generalized Geometry Encoding Volume for Real-time Stereo Matching](https://arxiv.org/abs/2512.06793)
*Jiaxin Liu,Gangwei Xu,Xianqi Wang,Chengliang Zhang,Xin Yang*

Main category: cs.CV

TL;DR: GGEV是一个实时立体匹配网络，通过提取深度感知特征和动态成本聚合模块，在保持实时性的同时实现了强大的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有实时立体匹配方法主要关注域内性能而忽略泛化能力，而基于单目基础模型的立体基础模型虽然泛化好但推理延迟高。需要解决实时性与泛化能力之间的权衡问题。

Method: 提出广义几何编码体积(GGEV)：1) 提取编码域不变结构先验的深度感知特征作为成本聚合指导；2) 引入深度感知动态成本聚合(DDCA)模块，自适应地将这些先验融入每个视差假设，增强未见场景中的脆弱匹配关系。

Result: GGEV在零样本泛化能力上超越所有现有实时方法，在KITTI 2012、KITTI 2015和ETH3D基准测试中达到最先进性能。

Conclusion: GGEV通过轻量级互补的深度感知特征提取和动态成本聚合，构建了具有强大泛化能力的广义几何编码体积，成功解决了实时立体匹配中泛化与效率的权衡问题。

Abstract: Real-time stereo matching methods primarily focus on enhancing in-domain performance but often overlook the critical importance of generalization in real-world applications. In contrast, recent stereo foundation models leverage monocular foundation models (MFMs) to improve generalization, but typically suffer from substantial inference latency. To address this trade-off, we propose Generalized Geometry Encoding Volume (GGEV), a novel real-time stereo matching network that achieves strong generalization. We first extract depth-aware features that encode domain-invariant structural priors as guidance for cost aggregation. Subsequently, we introduce a Depth-aware Dynamic Cost Aggregation (DDCA) module that adaptively incorporates these priors into each disparity hypothesis, effectively enhancing fragile matching relationships in unseen scenes. Both steps are lightweight and complementary, leading to the construction of a generalized geometry encoding volume with strong generalization capability. Experimental results demonstrate that our GGEV surpasses all existing real-time methods in zero-shot generalization capability, and achieves state-of-the-art performance on the KITTI 2012, KITTI 2015, and ETH3D benchmarks.

</details>


### [171] [VDOT: Efficient Unified Video Creation via Optimal Transport Distillation](https://arxiv.org/abs/2512.06802)
*Yutong Wang,Haiyu Zhang,Tianfan Xue,Yu Qiao,Yaohui Wang,Chang Xu,Xinyuan Chen*

Main category: cs.CV

TL;DR: VDOT是一个高效统一的视频生成模型，使用分布匹配蒸馏和最优传输技术，在4步推理中就能达到100步基线模型的性能


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型要么只能处理少数特定条件，要么推理时间过长，难以在实际应用中部署。需要开发一个既高效又能处理多种条件的统一视频生成模型。

Method: 采用分布匹配蒸馏范式，用最优传输技术替代KL散度来优化真实与生成分数分布之间的差异，避免梯度崩溃问题。同时集成判别器感知真实视频数据，并开发了自动化的视频数据标注和过滤流水线。

Result: 实验表明，仅需4步推理的VDOT模型就能达到或超过其他需要100步去噪的基线模型性能，显著提升了生成效率。

Conclusion: VDOT通过最优传输技术和分布匹配蒸馏，实现了高效稳定的视频生成，解决了现有模型推理时间长、条件受限的问题，为实际应用提供了可行的解决方案。

Abstract: The rapid development of generative models has significantly advanced image and video applications. Among these, video creation, aimed at generating videos under various conditions, has gained substantial attention. However, existing video creation models either focus solely on a few specific conditions or suffer from excessively long generation times due to complex model inference, making them impractical for real-world applications. To mitigate these issues, we propose an efficient unified video creation model, named VDOT. Concretely, we model the training process with the distribution matching distillation (DMD) paradigm. Instead of using the Kullback-Leibler (KL) minimization, we additionally employ a novel computational optimal transport (OT) technique to optimize the discrepancy between the real and fake score distributions. The OT distance inherently imposes geometric constraints, mitigating potential zero-forcing or gradient collapse issues that may arise during KL-based distillation within the few-step generation scenario, and thus, enhances the efficiency and stability of the distillation process. Further, we integrate a discriminator to enable the model to perceive real video data, thereby enhancing the quality of generated videos. To support training unified video creation models, we propose a fully automated pipeline for video data annotation and filtering that accommodates multiple video creation tasks. Meanwhile, we curate a unified testing benchmark, UVCBench, to standardize evaluation. Experiments demonstrate that our 4-step VDOT outperforms or matches other baselines with 100 denoising steps.

</details>


### [172] [Think-Reflect-Revise: A Policy-Guided Reflective Framework for Safety Alignment in Large Vision Language Models](https://arxiv.org/abs/2512.07141)
*Fenghua Weng,Chaochao Lu,Xia Hu,Wenqi Shao,Wenjie Wang*

Main category: cs.CV

TL;DR: 提出Think-Reflect-Revise (TRR)三阶段训练框架，通过策略引导的自我反思增强大型视觉语言模型的安全对齐，显著提升安全性能


<details>
  <summary>Details</summary>
Motivation: 当前多模态推理方法虽然提升了安全意识和可解释性，但单次"思考-回答"范式容易受到上下文或视觉越狱攻击，无法有效识别自身输出中的有害内容

Method: 1) 构建包含5000个示例的Reflective Safety Reasoning数据集；2) 使用该数据集微调目标模型以初始化反思行为；3) 通过强化学习强化策略引导的反思

Result: TRR显著提升LVLMs的安全性能，在Qwen2.5-VL-7B上将安全响应率从42.8%提升至87.7%，同时在MMMU和MMStar等通用基准上保持稳定性能

Conclusion: 通过反思机制利用第一轮推理中揭示的恶意内容进行真正的自我修正，能有效防止不安全生成，为LVLMs安全对齐提供了有效解决方案

Abstract: As multimodal reasoning improves the overall capabilities of Large Vision Language Models (LVLMs), recent studies have begun to explore safety-oriented reasoning, aiming to enhance safety awareness by analyzing potential safety risks during the reasoning process before generating the final response. Although such approaches improve safety awareness and interpretability, this single-pass think-then-answer paradigm remains vulnerable to contextual or visual jailbreak attacks. This reveals a critical flaw: single-pass reasoning may overlook explicit harmful content in its own output. Our key insight is to exploit this wasted signal through reflection, which can effectively leverage the malicious content revealed in the first-pass reasoning to enable genuine self-correction and prevent unsafe generations. Motivated by this, we propose Think-Reflect-Revise (TRR), a three-stage training framework designed to enhance the safety alignment of LVLMs through policy-guided self-reflection. We first build a Reflective Safety Reasoning (ReSafe) dataset with 5,000 examples that follow a think-reflect-revise process. We then fine-tune the target model using the ReSafe dataset to initialize reflective behavior, and finally reinforce policy-guided reflection through reinforcement learning. Experimental results show that TRR substantially improves the safety performance of LVLMs across both safety-awareness benchmarks and jailbreak attack evaluations, increasing the overall safe response rate from 42.8% to 87.7% on Qwen2.5-VL-7B, while preserving stable performance on general benchmarks such as MMMU and MMStar. The project page is available at https://think-reflect-revise.github.io/.

</details>


### [173] [RMAdapter: Reconstruction-based Multi-Modal Adapter for Vision-Language Models](https://arxiv.org/abs/2512.06811)
*Xiang Lin,Weixin Li,Shu Guo,Lihong Wang,Di Huang*

Main category: cs.CV

TL;DR: RMAdapter：一种新颖的重建式多模态适配器，采用双分支架构平衡任务特定适应与通用知识保留，在少样本场景中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 预训练视觉语言模型（如CLIP）在少样本微调中面临平衡任务特定适应与泛化的挑战。现有研究主要关注基于提示的方法，而基于适配器的方法探索不足且性能存在差距。

Method: 提出重建式多模态适配器（RMAdapter），采用双分支架构：1）适应分支通过参数高效微调注入任务特定知识；2）重建分支通过将潜在空间特征重建回原始特征空间来保留通用知识。采用局部重建损失、共享投影模块和一致性约束来保持轻量化和平衡。

Result: 在不依赖数据增强或重复提示设计的情况下，RMAdapter在三个代表性任务（新类别泛化、新目标数据集泛化、领域泛化）的所有评估指标上均优于最先进方法。

Conclusion: RMAdapter通过双分支架构有效平衡了任务特定适应与通用知识保留，在少样本多模态迁移学习中表现出色，为适配器方法提供了新的设计思路。

Abstract: Pre-trained Vision-Language Models (VLMs), \textit{e.g.} CLIP, have become essential tools in multimodal transfer learning. However, fine-tuning VLMs in few-shot scenarios poses significant challenges in balancing task-specific adaptation and generalization in the obtained model. Meanwhile, current researches have predominantly focused on prompt-based adaptation methods, leaving adapter-based approaches underexplored and revealing notable performance gaps. To address these challenges, we introduce a novel Reconstruction-based Multimodal Adapter (RMAdapter), which leverages a dual-branch architecture. Unlike conventional single-branch adapters, RMAdapter consists of: (1) an adaptation branch that injects task-specific knowledge through parameter-efficient fine-tuning, and (2) a reconstruction branch that preserves general knowledge by reconstructing latent space features back into the original feature space. This design facilitates a dynamic balance between general and task-specific knowledge. Importantly, although RMAdapter introduces an additional reconstruction branch, it is carefully optimized to remain lightweight. By computing reconstruction loss locally at each layer and sharing projection modules, the overall computational overhead is kept minimal. A consistency constraint is also incorporated to better regulate the trade-off between discriminability and generalization. We comprehensively evaluate the effectiveness of RMAdapter on three representative tasks: generalization to new categories, generalization to new target datasets, and domain generalization. Without relying on data augmentation or duplicate prompt designs, our RMAdapter consistently outperforms state-of-the-art approaches across all evaluation metrics.

</details>


### [174] [MeshSplatting: Differentiable Rendering with Opaque Meshes](https://arxiv.org/abs/2512.06818)
*Jan Held,Sanghyun Son,Renaud Vandeghen,Daniel Rebain,Matheus Gadelha,Yi Zhou,Anthony Cioppa,Ming C. Lin,Marc Van Droogenbroeck,Andrea Tagliasacchi*

Main category: cs.CV

TL;DR: MeshSplatting是一种基于网格的重建方法，通过可微分渲染联合优化几何和外观，将神经渲染与交互式3D图形结合，实现实时场景交互。


<details>
  <summary>Details</summary>
Motivation: 现有的基于基元的溅射方法（如3D高斯溅射）虽然实现了实时渲染的新视角合成，但其基于点的表示与AR/VR和游戏引擎中使用的基于网格的流程不兼容。需要一种能够创建平滑、高质量网格的方法，以桥接神经渲染和交互式3D图形。

Method: MeshSplatting通过可微分渲染联合优化几何和外观。使用受限Delaunay三角剖分来强制执行连接性，并细化表面一致性，从而创建端到端平滑的网格表示。

Result: 在Mip-NeRF360数据集上，MeshSplatting比当前最先进的基于网格的新视角合成方法MiLo提高了0.69 dB的PSNR，同时训练速度快2倍，内存使用减少2倍，能够高效地在实时3D引擎中渲染。

Conclusion: MeshSplatting成功创建了视觉高质量的网格，能够高效地在实时3D引擎中渲染，桥接了神经渲染和交互式3D图形，为无缝实时场景交互提供了解决方案。

Abstract: Primitive-based splatting methods like 3D Gaussian Splatting have revolutionized novel view synthesis with real-time rendering. However, their point-based representations remain incompatible with mesh-based pipelines that power AR/VR and game engines. We present MeshSplatting, a mesh-based reconstruction approach that jointly optimizes geometry and appearance through differentiable rendering. By enforcing connectivity via restricted Delaunay triangulation and refining surface consistency, MeshSplatting creates end-to-end smooth, visually high-quality meshes that render efficiently in real-time 3D engines. On Mip-NeRF360, it boosts PSNR by +0.69 dB over the current state-of-the-art MiLo for mesh-based novel view synthesis, while training 2x faster and using 2x less memory, bridging neural rendering and interactive 3D graphics for seamless real-time scene interaction. The project page is available at https://meshsplatting.github.io/.

</details>


### [175] [Generating Storytelling Images with Rich Chains-of-Reasoning](https://arxiv.org/abs/2512.07198)
*Xiujie Song,Qi Jia,Shota Watanabe,Xiaoyi Pang,Ruijie Chen,Mengyue Wu,Kenny Q. Zhu*

Main category: cs.CV

TL;DR: 提出Storytelling Image Generation任务，通过两阶段管道StorytellingPainter结合LLM的推理能力和T2I模型的视觉合成能力生成具有丰富语义的故事性图像，并开发专用评估框架。


<details>
  <summary>Details</summary>
Motivation: 故事性图像通过丰富的视觉线索传达逻辑连接的故事，具有广泛的应用价值，但由于语义复杂难以创建，因此相对稀缺。需要探索如何利用生成AI模型创建这类图像。

Method: 提出两阶段管道StorytellingPainter：1) 利用LLM进行创造性推理生成故事描述；2) 使用T2I模型进行视觉合成。开发包含语义复杂性评估器、KNN多样性评估器和故事-图像对齐评估器的专用评估框架。为缩小开源与专有LLM的性能差距，探索定制训练策略，开发Mini-Storytellers系列轻量模型。

Result: 实验结果表明所提方法的可行性和有效性。StorytellingPainter能够生成具有丰富语义连接的故事性图像，评估框架能全面评估生成质量，Mini-Storytellers模型在缩小性能差距方面表现良好。

Conclusion: 成功定义了Storytelling Image Generation任务，提出了有效的生成管道和评估框架，并通过定制训练策略提升了开源模型的性能，为故事性图像的生成提供了系统解决方案。

Abstract: An image can convey a compelling story by presenting rich, logically connected visual clues. These connections form Chains-of-Reasoning (CoRs) within the image, enabling viewers to infer events, causal relationships, and other information, thereby understanding the underlying story. In this paper, we focus on these semantically rich images and define them as Storytelling Images. Such images have diverse applications beyond illustration creation and cognitive screening, leveraging their ability to convey multi-layered information visually and inspire active interpretation. However, due to their complex semantic nature, Storytelling Images are inherently challenging to create, and thus remain relatively scarce. To address this challenge, we introduce the Storytelling Image Generation task, which explores how generative AI models can be leveraged to create such images. Specifically, we propose a two-stage pipeline, StorytellingPainter, which combines the creative reasoning abilities of Large Language Models (LLMs) with the visual synthesis capabilities of Text-to-Image (T2I) models to generate Storytelling Images. Alongside this pipeline, we develop a dedicated evaluation framework comprising three main evaluators: a Semantic Complexity Evaluator, a KNN-based Diversity Evaluator and a Story-Image Alignment Evaluator. Given the critical role of story generation in the Storytelling Image Generation task and the performance disparity between open-source and proprietary LLMs, we further explore tailored training strategies to reduce this gap, resulting in a series of lightweight yet effective models named Mini-Storytellers. Experimental results demonstrate the feasibility and effectiveness of our approaches. The code is available at https://github.com/xiujiesong/StorytellingImageGeneration.

</details>


### [176] [SparseCoop: Cooperative Perception with Kinematic-Grounded Queries](https://arxiv.org/abs/2512.06838)
*Jiahao Wang,Zhongwei Jiang,Wenchao Sun,Jiaru Zhong,Haibao Yu,Yuner Zhang,Chenyang Lu,Chuang Zhang,Lei He,Shaobing Xu,Jianqiang Wang*

Main category: cs.CV

TL;DR: SparseCoop是一个完全稀疏的协同感知框架，用于3D检测和跟踪，完全摒弃了中间BEV表示，通过实例查询、粗到精聚合和协同实例去噪实现高效协同感知。


<details>
  <summary>Details</summary>
Motivation: 当前协同感知方法存在通信成本高、灵活性差、对齐不精确等问题。基于密集BEV特征的方法通信成本呈二次方增长，而稀疏查询方法则存在几何表示不足、融合策略次优和训练不稳定等缺陷。

Method: 提出三个创新：1）基于运动学的实例查询，使用包含3D几何和速度的显式状态向量实现精确时空对齐；2）粗到精聚合模块实现鲁棒融合；3）协同实例去噪任务加速和稳定训练。

Result: 在V2X-Seq和Griffin数据集上达到最先进性能，具有优越的计算效率、低传输成本和强通信延迟鲁棒性。

Conclusion: SparseCoop通过完全稀疏的框架解决了当前协同感知方法的局限性，在性能、效率和鲁棒性方面均表现出色，为自动驾驶协同感知提供了新方向。

Abstract: Cooperative perception is critical for autonomous driving, overcoming the inherent limitations of a single vehicle, such as occlusions and constrained fields-of-view. However, current approaches sharing dense Bird's-Eye-View (BEV) features are constrained by quadratically-scaling communication costs and the lack of flexibility and interpretability for precise alignment across asynchronous or disparate viewpoints. While emerging sparse query-based methods offer an alternative, they often suffer from inadequate geometric representations, suboptimal fusion strategies, and training instability. In this paper, we propose SparseCoop, a fully sparse cooperative perception framework for 3D detection and tracking that completely discards intermediate BEV representations. Our framework features a trio of innovations: a kinematic-grounded instance query that uses an explicit state vector with 3D geometry and velocity for precise spatio-temporal alignment; a coarse-to-fine aggregation module for robust fusion; and a cooperative instance denoising task to accelerate and stabilize training. Experiments on V2X-Seq and Griffin datasets show SparseCoop achieves state-of-the-art performance. Notably, it delivers this with superior computational efficiency, low transmission cost, and strong robustness to communication latency. Code is available at https://github.com/wang-jh18-SVM/SparseCoop.

</details>


### [177] [CADE: Continual Weakly-supervised Video Anomaly Detection with Ensembles](https://arxiv.org/abs/2512.06840)
*Satoshi Hashimoto,Tatsuya Konishi,Tomoya Kaichi,Kazunori Matsumoto,Mori Kurokawa*

Main category: cs.CV

TL;DR: 本文提出CADE方法，首次将持续学习与弱监督视频异常检测结合，通过双生成器和多判别器集成解决领域漂移和遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督视频异常检测方法主要针对静态数据集，忽视了数据领域可能变化的问题。当数据领域发生漂移时，需要持续学习视角，否则仅用新数据训练会导致对先前数据的性能下降（遗忘）。

Method: 提出CADE方法：1）使用双生成器解决数据不平衡和标签不确定性问题；2）提出多判别器集成，通过多个模型捕捉因遗忘而错过的过去场景中的异常。

Result: 在ShanghaiTech和Charlotte Anomaly等多场景视频异常检测数据集上的大量实验表明，CADE显著优于现有的VAD方法。

Conclusion: CADE是首个结合持续学习和弱监督视频异常检测的工作，通过双生成器和多判别器集成有效解决了领域漂移和遗忘问题，在多场景异常检测中表现出色。

Abstract: Video anomaly detection (VAD) has long been studied as a crucial problem in public security and crime prevention. In recent years, weakly-supervised VAD (WVAD) have attracted considerable attention due to their easy annotation process and promising research results. While existing WVAD methods tackle mainly on static datasets, the possibility that the domain of data can vary has been neglected. To adapt such domain-shift, the continual learning (CL) perspective is required because otherwise additional training only with new coming data could easily cause performance degradation for previous data, i.e., forgetting. Therefore, we propose a brand-new approach, called Continual Anomaly Detection with Ensembles (CADE) that is the first work combining CL and WVAD viewpoints. Specifically, CADE uses the Dual-Generator(DG) to address data imbalance and label uncertainty in WVAD. We also found that forgetting exacerbates the "incompleteness'' where the model becomes biased towards certain anomaly modes, leading to missed detections of various anomalies. To address this, we propose to ensemble Multi-Discriminator (MD) that capture missed anomalies in past scenes due to forgetting, using multiple models. Extensive experiments show that CADE significantly outperforms existing VAD methods on the common multi-scene VAD datasets, such as ShanghaiTech and Charlotte Anomaly datasets.

</details>


### [178] [Pseudo Anomalies Are All You Need: Diffusion-Based Generation for Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2512.06845)
*Satoshi Hashimoto,Hitoshi Nishimura,Yanan Wang,Mori Kurokawa*

Main category: cs.CV

TL;DR: PA-VAD：仅使用少量正常图像生成伪异常视频进行训练，无需真实异常数据，在视频异常检测中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 实际部署视频异常检测面临真实异常数据稀缺和收集成本高的问题，需要一种无需真实异常视频的训练方法

Method: 1) 使用CLIP选择类别相关初始图像，用视觉语言模型优化文本提示，通过视频扩散模型生成伪异常视频；2) 设计域对齐正则化模块缓解合成异常的过度时空幅度

Result: 在ShanghaiTech达到98.2%，UCF-Crime达到82.5%，分别比最强真实异常方法高0.6%，比UVAD SOTA高1.9%

Conclusion: 无需收集真实异常数据即可实现高精度异常检测，为可扩展部署提供了实用路径

Abstract: Deploying video anomaly detection in practice is hampered by the scarcity and collection cost of real abnormal footage. We address this by training without any real abnormal videos while evaluating under the standard weakly supervised split, and we introduce PA-VAD, a generation-driven approach that learns a detector from synthesized pseudo-abnormal videos paired with real normal videos, using only a small set of real normal images to drive synthesis. For synthesis, we select class-relevant initial images with CLIP and refine textual prompts with a vision-language model to improve fidelity and scene consistency before invoking a video diffusion model. For training, we mitigate excessive spatiotemporal magnitude in synthesized anomalies by an domain-aligned regularized module that combines domain alignment and memory usage-aware updates. Extensive experiments show that our approach reaches 98.2% on ShanghaiTech and 82.5% on UCF-Crime, surpassing the strongest real-abnormal method on ShanghaiTech by +0.6% and outperforming the UVAD state-of-the-art on UCF-Crime by +1.9%. The results demonstrate that high-accuracy anomaly detection can be obtained without collecting real anomalies, providing a practical path toward scalable deployment.

</details>


### [179] [Hide-and-Seek Attribution: Weakly Supervised Segmentation of Vertebral Metastases in CT](https://arxiv.org/abs/2512.06849)
*Matan Atad,Alexander W. Marka,Lisa Steinhelfer,Anna Curto-Vilalta,Yannik Leonhardt,Sarah C. Foreman,Anna-Sophia Walburga Dietrich,Robert Graf,Alexandra S. Gersing,Bjoern Menze,Daniel Rueckert,Jan S. Kirschke,Hendrik Möller*

Main category: cs.CV

TL;DR: 提出一种弱监督方法，仅使用椎体级别的健康/恶性标签（无需病灶掩码），通过扩散自编码器和像素差异图生成候选病灶区域，再通过Hide-and-Seek Attribution机制筛选出真正反映恶性的区域，实现椎体转移瘤的精确分割。


<details>
  <summary>Details</summary>
Motivation: CT中椎体转移瘤的精确分割在临床上很重要，但由于体素级标注稀缺，且溶骨性和成骨性病变常与良性退行性变化相似，难以大规模应用。

Method: 结合扩散自编码器（DAE）生成椎体的健康编辑版本，通过像素差异图提出候选病灶区域。引入Hide-and-Seek Attribution机制：逐个揭示候选区域同时隐藏其他区域，将编辑后的图像通过DAE投影回数据流形，使用潜在空间分类器量化该组件的独立恶性贡献，高分区域形成最终的分割结果。

Result: 在保留的放射科医生标注上，尽管没有掩码监督，仍取得了优异的成骨性/溶骨性病变分割性能（F1: 0.91/0.85; Dice: 0.87/0.78），显著超过基线方法（F1: 0.79/0.67; Dice: 0.74/0.55）。

Conclusion: 椎体级别标签可以转化为可靠的病灶掩码，证明生成式编辑结合选择性遮挡支持CT中准确的弱监督分割。

Abstract: Accurate segmentation of vertebral metastasis in CT is clinically important yet difficult to scale, as voxel-level annotations are scarce and both lytic and blastic lesions often resemble benign degenerative changes. We introduce a weakly supervised method trained solely on vertebra-level healthy/malignant labels, without any lesion masks. The method combines a Diffusion Autoencoder (DAE) that produces a classifier-guided healthy edit of each vertebra with pixel-wise difference maps that propose candidate lesion regions. To determine which regions truly reflect malignancy, we introduce Hide-and-Seek Attribution: each candidate is revealed in turn while all others are hidden, the edited image is projected back to the data manifold by the DAE, and a latent-space classifier quantifies the isolated malignant contribution of that component. High-scoring regions form the final lytic or blastic segmentation. On held-out radiologist annotations, we achieve strong blastic/lytic performance despite no mask supervision (F1: 0.91/0.85; Dice: 0.87/0.78), exceeding baselines (F1: 0.79/0.67; Dice: 0.74/0.55). These results show that vertebra-level labels can be transformed into reliable lesion masks, demonstrating that generative editing combined with selective occlusion supports accurate weakly supervised segmentation in CT.

</details>


### [180] [Omni-Referring Image Segmentation](https://arxiv.org/abs/2512.06862)
*Qiancheng Zheng,Yunhang Shen,Gen Luo,Baiyang Song,Xing Sun,Xiaoshuai Sun,Yiyi Zhou,Rongrong Ji*

Main category: cs.CV

TL;DR: 提出OmniRIS任务，支持文本指令和带掩码/框/涂鸦的参考图像作为全提示，实现高度泛化的图像分割。构建OmniRef数据集并提出OmniSegNet基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有分割任务（如RIS和visual RIS）通常只支持单一模态输入，限制了分割的泛化能力。需要一种能同时利用文本和视觉模态优势的任务，实现更灵活、通用的图像分割。

Method: 提出OmniRIS任务，支持文本指令和多种视觉提示（掩码、框、涂鸦）作为全模态输入。构建包含186,939个全提示的OmniRef数据集，并提出OmniSegNet基线模型处理全提示编码等关键挑战。

Result: 实验验证了OmniSegNet能够有效遵循全模态指令进行分割，并展示了OmniRIS在高度泛化图像分割方面的优越性。数据集和评估系统为后续研究提供了基础。

Conclusion: OmniRIS任务通过支持全模态提示输入，结合文本和视觉模态的优势，实现了高度泛化的图像分割。提出的数据集、评估系统和基线模型为这一新研究方向奠定了基础。

Abstract: In this paper, we propose a novel task termed Omni-Referring Image Segmentation (OmniRIS) towards highly generalized image segmentation. Compared with existing unimodally conditioned segmentation tasks, such as RIS and visual RIS, OmniRIS supports the input of text instructions and reference images with masks, boxes or scribbles as omni-prompts. This property makes it can well exploit the intrinsic merits of both text and visual modalities, i.e., granular attribute referring and uncommon object grounding, respectively. Besides, OmniRIS can also handle various segmentation settings, such as one v.s. many and many v.s. many, further facilitating its practical use. To promote the research of OmniRIS, we also rigorously design and construct a large dataset termed OmniRef, which consists of 186,939 omni-prompts for 30,956 images, and establish a comprehensive evaluation system. Moreover, a strong and general baseline termed OmniSegNet is also proposed to tackle the key challenges of OmniRIS, such as omni-prompt encoding. The extensive experiments not only validate the capability of OmniSegNet in following omni-modal instructions, but also show the superiority of OmniRIS for highly generalized image segmentation.

</details>


### [181] [Toward More Reliable Artificial Intelligence: Reducing Hallucinations in Vision-Language Models](https://arxiv.org/abs/2512.07564)
*Kassoum Sanogo,Renzo Ardiccioni*

Main category: cs.CV

TL;DR: 提出无需训练的视觉语言模型自校正框架，通过不确定性引导的视觉重注意机制迭代修正幻觉内容，在多个基准测试中显著降低幻觉率。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型经常生成看似合理但错误的幻觉内容，现有方法需要重新训练或微调模型，成本高昂且不灵活。需要一种无需训练的自校正方法来解决幻觉问题。

Method: 提出基于不确定性量化的训练免费自校正框架：1）多维度不确定性评估（词元熵、注意力分散度、语义一致性、声明置信度）；2）注意力引导的未探索区域裁剪；3）迭代修正机制；4）完全使用冻结的预训练模型，无需梯度更新。

Result: 在POPE和MMHAL BENCH基准测试上使用Qwen2.5-VL-7B模型验证：1）幻觉率比基线降低9.8个百分点；2）对抗性分割上的物体存在准确率提升4.7个百分点；3）定性分析显示不确定性引导的重注意能成功基于视觉证据进行修正。

Conclusion: 提出的训练免费自校正框架能有效减少视觉语言模型的幻觉问题，通过不确定性引导的视觉重注意机制实现基于视觉证据的修正，为可信赖多模态系统研究提供了新方向。

Abstract: Vision-language models (VLMs) frequently generate hallucinated content plausible but incorrect claims about image content. We propose a training-free self-correction framework enabling VLMs to iteratively refine responses through uncertainty-guided visual re-attention. Our method combines multidimensional uncertainty quantification (token entropy, attention dispersion, semantic consistency, claim confidence) with attention-guided cropping of under-explored regions. Operating entirely with frozen, pretrained VLMs, our framework requires no gradient updates. We validate our approach on the POPE and MMHAL BENCH benchmarks using the Qwen2.5-VL-7B [23] architecture. Experimental results demonstrate that our method reduces hallucination rates by 9.8 percentage points compared to the baseline, while improving object existence accuracy by 4.7 points on adversarial splits. Furthermore, qualitative analysis confirms that uncertainty-guided re-attention successfully grounds corrections in visual evidence where standard decoding fails. We validate our approach on Qwen2.5-VL-7B [23], with plans to extend validation across diverse architectures in future versions. We release our code and methodology to facilitate future research in trustworthy multimodal systems.

</details>


### [182] [Boosting Unsupervised Video Instance Segmentation with Automatic Quality-Guided Self-Training](https://arxiv.org/abs/2512.06864)
*Kaixuan Lu,Mehmet Onurcan Kaya,Dim P. Papadopoulos*

Main category: cs.CV

TL;DR: AutoQ-VIS：通过质量引导自训练的无监督视频实例分割框架，无需人工标注，在YouTubeVIS-2019上达到52.6 AP50，超越之前SOTA 4.4%


<details>
  <summary>Details</summary>
Motivation: 视频实例分割（VIS）面临像素级掩码和时间一致性标注的双重挑战。现有无监督方法如VideoCutLER虽然通过合成数据消除了光流依赖，但仍受限于合成到真实域的差距。

Method: 提出AutoQ-VIS框架，通过质量引导的自训练方法建立伪标签生成和自动质量评估的闭环系统，实现从合成视频到真实视频的渐进式适应。

Result: 在YouTubeVIS-2019验证集上达到52.6 AP50，超越之前最先进的VideoCutLER 4.4%，且无需任何人工标注。

Conclusion: 证明了质量感知自训练在无监督视频实例分割中的可行性，为克服合成到真实域差距提供了有效解决方案。

Abstract: Video Instance Segmentation (VIS) faces significant annotation challenges due to its dual requirements of pixel-level masks and temporal consistency labels. While recent unsupervised methods like VideoCutLER eliminate optical flow dependencies through synthetic data, they remain constrained by the synthetic-to-real domain gap. We present AutoQ-VIS, a novel unsupervised framework that bridges this gap through quality-guided self-training. Our approach establishes a closed-loop system between pseudo-label generation and automatic quality assessment, enabling progressive adaptation from synthetic to real videos. Experiments demonstrate state-of-the-art performance with 52.6 $\text{AP}_{50}$ on YouTubeVIS-2019 $\texttt{val}$ set, surpassing the previous state-of-the-art VideoCutLER by 4.4%, while requiring no human annotations. This demonstrates the viability of quality-aware self-training for unsupervised VIS. We will release the code at https://github.com/wcbup/AutoQ-VIS.

</details>


### [183] [Spatial Retrieval Augmented Autonomous Driving](https://arxiv.org/abs/2512.06865)
*Xiaosong Jia,Chenhe Zhang,Yule Jiang,Songbur Wong,Zhiyuan Zhang,Chen Chen,Shaofeng Zhang,Xuanhe Zhou,Xue Yang,Junchi Yan,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 提出空间检索范式，通过引入离线检索的地理图像作为额外输入，增强自动驾驶系统的感知能力，特别是在视野受限、遮挡或极端天气条件下。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶系统依赖车载传感器进行环境感知，但受限于实时感知范围，在视野受限、遮挡或黑暗、雨天等极端条件下容易失效。人类驾驶员能够在能见度差时回忆道路结构，因此希望赋予模型这种"回忆"能力。

Method: 提出空间检索范式，从离线缓存（如Google Maps或存储的自动驾驶数据集）中检索地理图像作为额外输入。扩展nuScenes数据集，通过Google Maps API检索地理图像并与自车轨迹对齐。在五个核心自动驾驶任务上建立基线。

Result: 扩展的模态能够提升某些任务的性能。将开源数据集构建代码、数据和基准测试，供进一步研究这种新的自动驾驶范式。

Conclusion: 空间检索范式为自动驾驶系统提供了"回忆"能力，通过引入离线地理图像作为额外输入，能够增强在视野受限和极端条件下的感知性能，是一种即插即用的扩展方案。

Abstract: Existing autonomous driving systems rely on onboard sensors (cameras, LiDAR, IMU, etc) for environmental perception. However, this paradigm is limited by the drive-time perception horizon and often fails under limited view scope, occlusion or extreme conditions such as darkness and rain. In contrast, human drivers are able to recall road structure even under poor visibility. To endow models with this ``recall" ability, we propose the spatial retrieval paradigm, introducing offline retrieved geographic images as an additional input. These images are easy to obtain from offline caches (e.g, Google Maps or stored autonomous driving datasets) without requiring additional sensors, making it a plug-and-play extension for existing AD tasks.
  For experiments, we first extend the nuScenes dataset with geographic images retrieved via Google Maps APIs and align the new data with ego-vehicle trajectories. We establish baselines across five core autonomous driving tasks: object detection, online mapping, occupancy prediction, end-to-end planning, and generative world modeling. Extensive experiments show that the extended modality could enhance the performance of certain tasks. We will open-source dataset curation code, data, and benchmarks for further study of this new autonomous driving paradigm.

</details>


### [184] [Towards Robust Pseudo-Label Learning in Semantic Segmentation: An Encoding Perspective](https://arxiv.org/abs/2512.06870)
*Wangkai Li,Rui Sun,Zhaoyang Li,Tianzhu Zhang*

Main category: cs.CV

TL;DR: ECOCSeg提出了一种基于纠错输出码的语义分割新方法，通过细粒度编码和位级标签去噪机制，在伪标签学习中提高稳定性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 伪标签学习在语义分割中广泛应用，特别是在标签稀缺的场景如无监督域适应和半监督学习中。然而，这种范式会产生错误的伪标签，并且由于使用one-hot编码，这些错误在训练过程中会被进一步放大。

Method: 提出ECOCSeg方法：1）引入基于ECOC的分类器，将类别分解为属性并处理部分不准确的比特位；2）开发位级标签去噪机制，为未标记图像生成更高质量的伪标签；3）该方法可以轻松集成到现有方法中。

Result: ECOCSeg在多个UDA和SSL基准测试中，在不同的分割架构上都表现出显著的性能提升。

Conclusion: ECOCSeg通过纠错输出码提供了一种新的语义分割视角，能够有效处理伪标签学习中的错误传播问题，提高模型的稳定性和泛化能力。

Abstract: Pseudo-label learning is widely used in semantic segmentation, particularly in label-scarce scenarios such as unsupervised domain adaptation (UDA) and semisupervised learning (SSL). Despite its success, this paradigm can generate erroneous pseudo-labels, which are further amplified during training due to utilization of one-hot encoding. To address this issue, we propose ECOCSeg, a novel perspective for segmentation models that utilizes error-correcting output codes (ECOC) to create a fine-grained encoding for each class. ECOCSeg offers several advantages. First, an ECOC-based classifier is introduced, enabling model to disentangle classes into attributes and handle partial inaccurate bits, improving stability and generalization in pseudo-label learning. Second, a bit-level label denoising mechanism is developed to generate higher-quality pseudo-labels, providing adequate and robust supervision for unlabeled images. ECOCSeg can be easily integrated with existing methods and consistently demonstrates significant improvements on multiple UDA and SSL benchmarks across different segmentation architectures. Code is available at https://github.com/Woof6/ECOCSeg.

</details>


### [185] [SceneMixer: Exploring Convolutional Mixing Networks for Remote Sensing Scene Classification](https://arxiv.org/abs/2512.06877)
*Mohammed Q. Alkhatib,Ali Jamali,Swalpa Kumar Roy*

Main category: cs.CV

TL;DR: 提出基于卷积混合器范式的轻量级遥感场景分类架构，通过多尺度深度卷积和逐点操作交替进行空间和通道混合，在保持低参数量和计算量的同时有效提取局部和上下文信息。


<details>
  <summary>Details</summary>
Motivation: 遥感场景分类对地球观测至关重要，但现有CNN和ViT模型在空间分辨率、视角、方向和背景条件变化下泛化能力有限，需要更高效且鲁棒的解决方案。

Method: 采用卷积混合器架构，交替使用多尺度深度卷积进行空间混合和逐点操作进行通道混合，实现高效的特征提取，同时保持模型轻量化。

Result: 在AID数据集上达到74.7%总体准确率、74.57%平均准确率和73.79 Kappa值；在EuroSAT数据集上达到93.90%总体准确率、93.93%平均准确率和93.22 Kappa值，在准确性和效率间取得良好平衡。

Conclusion: 提出的轻量级卷积混合器架构在遥感场景分类任务中表现优异，相比广泛使用的CNN和Transformer模型，在保持高准确率的同时显著降低了计算复杂度。

Abstract: Remote sensing scene classification plays a key role in Earth observation by enabling the automatic identification of land use and land cover (LULC) patterns from aerial and satellite imagery. Despite recent progress with convolutional neural networks (CNNs) and vision transformers (ViTs), the task remains challenging due to variations in spatial resolution, viewpoint, orientation, and background conditions, which often reduce the generalization ability of existing models. To address these challenges, this paper proposes a lightweight architecture based on the convolutional mixer paradigm. The model alternates between spatial mixing through depthwise convolutions at multiple scales and channel mixing through pointwise operations, enabling efficient extraction of both local and contextual information while keeping the number of parameters and computations low. Extensive experiments were conducted on the AID and EuroSAT benchmarks. The proposed model achieved overall accuracy, average accuracy, and Kappa values of 74.7%, 74.57%, and 73.79 on the AID dataset, and 93.90%, 93.93%, and 93.22 on EuroSAT, respectively. These results demonstrate that the proposed approach provides a good balance between accuracy and efficiency compared with widely used CNN- and transformer-based models. Code will be publicly available on: https://github.com/mqalkhatib/SceneMixer

</details>


### [186] [Hierarchical Image-Guided 3D Point Cloud Segmentation in Industrial Scenes via Multi-View Bayesian Fusion](https://arxiv.org/abs/2512.06882)
*Yu Zhu,Naoya Chiba,Koichi Hashimoto*

Main category: cs.CV

TL;DR: 提出分层图像引导的3D分割框架，通过实例级到部件级的渐进细化，解决工业场景中遮挡和尺度差异问题，无需昂贵标注且保持跨视图语义一致性。


<details>
  <summary>Details</summary>
Motivation: 工业环境中密集布局和多尺度物体导致3D分割困难：严重遮挡削弱几何边界，尺度差异使端到端模型难以同时捕捉粗细节和细细节。现有方法要么需要昂贵标注，要么存在跨视图语义不一致问题。

Method: 分层图像引导框架：1) 实例分割：渲染俯视图，用YOLO-World提示SAM生成掩码，投影回3D点云；2) 部件级分割：对每个实例渲染多视图图像，在各视图应用相同2D分割和反投影，通过贝叶斯更新融合确保跨视图语义一致性。

Result: 在真实工厂数据上有效处理遮挡和结构复杂性，获得一致高的每类mIoU分数。在公共数据集上的额外评估证实了框架的泛化能力，展现了鲁棒性、标注效率和适应不同3D环境的能力。

Conclusion: 该方法通过分层图像引导策略成功解决了工业场景中的3D分割挑战，无需昂贵标注且保持语义一致性，在真实和公共数据集上都表现出色，具有实际应用价值。

Abstract: Reliable 3D segmentation is critical for understanding complex scenes with dense layouts and multi-scale objects, as commonly seen in industrial environments. In such scenarios, heavy occlusion weakens geometric boundaries between objects, and large differences in object scale will cause end-to-end models fail to capture both coarse and fine details accurately. Existing 3D point-based methods require costly annotations, while image-guided methods often suffer from semantic inconsistencies across views. To address these challenges, we propose a hierarchical image-guided 3D segmentation framework that progressively refines segmentation from instance-level to part-level. Instance segmentation involves rendering a top-view image and projecting SAM-generated masks prompted by YOLO-World back onto the 3D point cloud. Part-level segmentation is subsequently performed by rendering multi-view images of each instance obtained from the previous stage and applying the same 2D segmentation and back-projection process at each view, followed by Bayesian updating fusion to ensure semantic consistency across views. Experiments on real-world factory data demonstrate that our method effectively handles occlusion and structural complexity, achieving consistently high per-class mIoU scores. Additional evaluations on public dataset confirm the generalization ability of our framework, highlighting its robustness, annotation efficiency, and adaptability to diverse 3D environments.

</details>


### [187] [JoPano: Unified Panorama Generation via Joint Modeling](https://arxiv.org/abs/2512.06885)
*Wancheng Feng,Chen An,Zhenliang He,Meina Kan,Shiguang Shan,Lukun Wang*

Main category: cs.CV

TL;DR: JoPano是一个基于DiT的统一全景图生成框架，通过联合面适配器和条件切换机制，同时支持文本到全景图和视图到全景图生成，解决了现有方法视觉质量受限和任务独立建模的问题。


<details>
  <summary>Details</summary>
Motivation: 现有全景图生成方法面临两个主要挑战：1) 基于U-Net的架构限制了生成全景图的视觉质量；2) 通常将文本到全景图和视图到全景图两个核心任务独立处理，导致建模冗余和效率低下。

Method: 提出基于DiT的联合全景图生成方法JoPano：1) 使用基于立方体贴图表示的联合面适配器，将预训练DiT的生成能力迁移到全景图领域；2) 应用泊松融合减少立方体面边界的不一致性；3) 引入条件切换机制，在单一模型中统一两个生成任务。

Result: JoPano在文本到全景图和视图到全景图生成任务上都能生成高质量全景图，在FID、CLIP-FID、IS和CLIP-Score等指标上达到最先进性能，并提出了Seam-SSIM和Seam-Sobel指标定量评估接缝一致性。

Conclusion: JoPano通过统一的DiT-based框架成功解决了全景图生成中的视觉质量限制和任务独立性问题，为全景图生成提供了更高效和高质量的解决方案。

Abstract: Panorama generation has recently attracted growing interest in the research community, with two core tasks, text-to-panorama and view-to-panorama generation. However, existing methods still face two major challenges: their U-Net-based architectures constrain the visual quality of the generated panoramas, and they usually treat the two core tasks independently, which leads to modeling redundancy and inefficiency. To overcome these challenges, we propose a joint-face panorama (JoPano) generation approach that unifies the two core tasks within a DiT-based model. To transfer the rich generative capabilities of existing DiT backbones learned from natural images to the panorama domain, we propose a Joint-Face Adapter built on the cubemap representation of panoramas, which enables a pretrained DiT to jointly model and generate different views of a panorama. We further apply Poisson Blending to reduce seam inconsistencies that often appear at the boundaries between cube faces. Correspondingly, we introduce Seam-SSIM and Seam-Sobel metrics to quantitatively evaluate the seam consistency. Moreover, we propose a condition switching mechanism that unifies text-to-panorama and view-to-panorama tasks within a single model. Comprehensive experiments show that JoPano can generate high-quality panoramas for both text-to-panorama and view-to-panorama generation tasks, achieving state-of-the-art performance on FID, CLIP-FID, IS, and CLIP-Score metrics.

</details>


### [188] [Balanced Learning for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2512.06886)
*Wangkai Li,Rui Sun,Bohao Liao,Zhaoyang Li,Tianzhu Zhang*

Main category: cs.CV

TL;DR: BLDA是一种用于语义分割的无监督域自适应方法，通过分析预测logits分布来识别过预测和欠预测类别，使用共享锚分布对齐logits分布，并在损失函数中加入logits校正项，以平衡类别学习并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自训练技术在无监督域自适应中由于类别不平衡和域间数据/标签空间分布偏移，难以平衡地学习各个类别。需要一种无需先验分布知识就能直接评估和缓解类别偏差的方法。

Method: 1) 通过分析预测logits分布识别过预测和欠预测类别；2) 使用共享锚分布对logits分布进行后处理对齐；3) 在线估计logits分布并在损失函数中加入logits校正项；4) 利用累积密度作为域共享结构知识连接源域和目标域。

Result: 在两个标准UDA语义分割基准测试上的广泛实验表明，BLDA在集成到各种现有方法中时能持续提升性能，特别是对欠预测类别的表现有明显改善。

Conclusion: BLDA通过直接评估和缓解类别偏差，无需先验分布知识，有效解决了自训练中的类别不平衡问题，显著提升了无监督域自适应语义分割的性能。

Abstract: Unsupervised domain adaptation (UDA) for semantic segmentation aims to transfer knowledge from a labeled source domain to an unlabeled target domain. Despite the effectiveness of self-training techniques in UDA, they struggle to learn each class in a balanced manner due to inherent class imbalance and distribution shift in both data and label space between domains. To address this issue, we propose Balanced Learning for Domain Adaptation (BLDA), a novel approach to directly assess and alleviate class bias without requiring prior knowledge about the distribution shift. First, we identify over-predicted and under-predicted classes by analyzing the distribution of predicted logits. Subsequently, we introduce a post-hoc approach to align the logits distributions across different classes using shared anchor distributions. To further consider the network's need to generate unbiased pseudo-labels during self-training, we estimate logits distributions online and incorporate logits correction terms into the loss function. Moreover, we leverage the resulting cumulative density as domain-shared structural knowledge to connect the source and target domains. Extensive experiments on two standard UDA semantic segmentation benchmarks demonstrate that BLDA consistently improves performance, especially for under-predicted classes, when integrated into various existing methods. Code is available at https://github.com/Woof6/BLDA.

</details>


### [189] [Overcoming Small Data Limitations in Video-Based Infant Respiration Estimation](https://arxiv.org/abs/2512.06888)
*Liyang Song,Hardik Bishnoi,Sai Kumar Reddy Manne,Sarah Ostadabbas,Briana J. Taylor,Michael Wan*

Main category: cs.CV

TL;DR: 提出首个可复现的婴儿呼吸监测系统，包括新数据集AIR-400（400个标注视频）和基于计算机视觉的呼吸估计算法，填补了婴儿呼吸监测领域的空白。


<details>
  <summary>Details</summary>
Motivation: 婴儿呼吸异常与神经发育障碍和婴儿猝死综合征相关，但现有呼吸监测技术主要针对成人，缺乏专门针对婴儿的公开视频数据集和可复现算法。

Method: 1) 构建AIR-400数据集（400个标注视频，其中275个为新采集）；2) 开发基于婴儿特定感兴趣区域检测的算法；3) 使用时空神经处理结合光流输入增强呼吸估计。

Result: 建立了首个可复现的婴儿呼吸估计基准，提供了公开可用的数据集、代码库和训练模型，填补了该领域的研究空白。

Conclusion: 该研究为无接触式婴儿呼吸监测提供了首个完整的解决方案，包括数据集、算法和基准，有望促进早期呼吸异常检测和治疗的发展。

Abstract: The development of contactless respiration monitoring for infants could enable advances in the early detection and treatment of breathing irregularities, which are associated with neurodevelopmental impairments and conditions like sudden infant death syndrome (SIDS). But while respiration estimation for adults is supported by a robust ecosystem of computer vision algorithms and video datasets, only one small public video dataset with annotated respiration data for infant subjects exists, and there are no reproducible algorithms which are effective for infants. We introduce the annotated infant respiration dataset of 400 videos (AIR-400), contributing 275 new, carefully annotated videos from 10 recruited subjects to the public corpus. We develop the first reproducible pipelines for infant respiration estimation, based on infant-specific region-of-interest detection and spatiotemporal neural processing enhanced by optical flow inputs. We establish, through comprehensive experiments, the first reproducible benchmarks for the state-of-the-art in vision-based infant respiration estimation. We make our dataset, code repository, and trained models available for public use.

</details>


### [190] [Scaling Zero-Shot Reference-to-Video Generation](https://arxiv.org/abs/2512.06905)
*Zijian Zhou,Shikun Liu,Haozhe Liu,Haonan Qiu,Zhaochong An,Weiming Ren,Zhiheng Liu,Xiaoke Huang,Kam Woh Ng,Tian Xie,Xiao Han,Yuren Cong,Hang Li,Chuyan Zhu,Aditya Patel,Tao Xiang,Sen He*

Main category: cs.CV

TL;DR: Saber是一个无需显式参考图像-视频-文本三元组数据的零样本参考到视频生成框架，通过掩码训练策略和注意力模型设计实现身份一致性和参考感知表示学习


<details>
  <summary>Details</summary>
Motivation: 当前参考到视频生成方法依赖昂贵的显式参考图像-视频-文本三元组数据，这种数据构建成本高且难以扩展，需要绕过这个瓶颈

Method: 提出Saber框架，仅使用视频-文本对进行训练，采用掩码训练策略和定制的基于注意力的模型设计，学习身份一致和参考感知的表示，并集成掩码增强技术减少复制粘贴伪影

Result: 在OpenS2V-Eval基准测试中，相比使用R2V数据训练的方法，Saber表现出更优越的性能，并在不同数量参考图像上展现出显著的泛化能力

Conclusion: Saber通过零样本学习框架成功绕过了传统R2V方法对昂贵三元组数据的依赖，实现了可扩展的参考到视频生成，在保持身份一致性的同时减少了伪影

Abstract: Reference-to-video (R2V) generation aims to synthesize videos that align with a text prompt while preserving the subject identity from reference images. However, current R2V methods are hindered by the reliance on explicit reference image-video-text triplets, whose construction is highly expensive and difficult to scale. We bypass this bottleneck by introducing Saber, a scalable zero-shot framework that requires no explicit R2V data. Trained exclusively on video-text pairs, Saber employs a masked training strategy and a tailored attention-based model design to learn identity-consistent and reference-aware representations. Mask augmentation techniques are further integrated to mitigate copy-paste artifacts common in reference-to-video generation. Moreover, Saber demonstrates remarkable generalization capabilities across a varying number of references and achieves superior performance on the OpenS2V-Eval benchmark compared to methods trained with R2V data.

</details>


### [191] [Can We Go Beyond Visual Features? Neural Tissue Relation Modeling for Relational Graph Analysis in Non-Melanoma Skin Histology](https://arxiv.org/abs/2512.06949)
*Shravan Venkatraman,Muthu Subash Kavitha,Joe Dhanith P R,V Manikandarajan,Jia Wu*

Main category: cs.CV

TL;DR: NTRM是一种新颖的组织病理学图像分割框架，通过图神经网络建模组织间的空间和功能关系，在皮肤癌诊断中显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于CNN的组织病理学图像分割方法主要关注视觉纹理，将组织视为独立区域，无法编码生物上下文信息，特别是在组织重叠或形态相似的区域中难以建模空间上下文和组织间关系。

Method: 提出神经组织关系建模（NTRM）框架，通过组织级图神经网络增强CNN，构建预测区域的图结构，通过消息传递传播上下文信息，并通过空间投影细化分割结果。

Result: 在组织病理学非黑色素瘤皮肤癌分割基准数据集上，NTRM优于现有最先进方法，Dice相似系数比最佳模型高出4.9%至31.25%。

Conclusion: 关系建模为组织病理学分割提供了一条更上下文感知和可解释的路径，相比缺乏组织级结构意识的局部感受野架构具有明显优势。

Abstract: Histopathology image segmentation is essential for delineating tissue structures in skin cancer diagnostics, but modeling spatial context and inter-tissue relationships remains a challenge, especially in regions with overlapping or morphologically similar tissues. Current convolutional neural network (CNN)-based approaches operate primarily on visual texture, often treating tissues as independent regions and failing to encode biological context. To this end, we introduce Neural Tissue Relation Modeling (NTRM), a novel segmentation framework that augments CNNs with a tissue-level graph neural network to model spatial and functional relationships across tissue types. NTRM constructs a graph over predicted regions, propagates contextual information via message passing, and refines segmentation through spatial projection. Unlike prior methods, NTRM explicitly encodes inter-tissue dependencies, enabling structurally coherent predictions in boundary-dense zones. On the benchmark Histopathology Non-Melanoma Skin Cancer Segmentation Dataset, NTRM outperforms state-of-the-art methods, achieving a robust Dice similarity coefficient that is 4.9\% to 31.25\% higher than the best-performing models among the evaluated approaches. Our experiments indicate that relational modeling offers a principled path toward more context-aware and interpretable histological segmentation, compared to local receptive-field architectures that lack tissue-level structural awareness. Our code is available at https://github.com/shravan-18/NTRM.

</details>


### [192] [Selective Masking based Self-Supervised Learning for Image Semantic Segmentation](https://arxiv.org/abs/2512.06981)
*Yuemin Wang,Ian Stavness*

Main category: cs.CV

TL;DR: 提出一种用于语义分割的自监督学习方法，通过选择性掩码图像重建作为预训练任务，相比随机掩码方法在多个数据集上获得更好的下游分割精度。


<details>
  <summary>Details</summary>
Motivation: 传统掩码图像建模预训练方法使用随机掩码增强，但这种方法可能不是最优的。作者希望通过选择性掩码来更有效地利用训练模型的知识，提高预训练效果。

Method: 提出选择性掩码图像重建方法，通过迭代步骤选择重建损失最高的图像块进行掩码，利用已训练模型的知识来指导掩码选择，而不是随机掩码。

Result: 在两个通用数据集（Pascal VOC和Cityscapes）和两个杂草分割数据集上，选择性掩码方法比传统随机掩码方法和监督ImageNet预训练在下游分割精度上分别提升2.9%和2.5%，且显著改善了最低性能类别的准确性。

Conclusion: 选择性掩码图像重建方法为端到端语义分割工作流程提供了有效实用的解决方案，特别适用于需要有限模型容量以满足推理速度和计算资源要求的场景。

Abstract: This paper proposes a novel self-supervised learning method for semantic segmentation using selective masking image reconstruction as the pretraining task. Our proposed method replaces the random masking augmentation used in most masked image modelling pretraining methods. The proposed selective masking method selectively masks image patches with the highest reconstruction loss by breaking the image reconstruction pretraining into iterative steps to leverage the trained model's knowledge. We show on two general datasets (Pascal VOC and Cityscapes) and two weed segmentation datasets (Nassar 2020 and Sugarbeets 2016) that our proposed selective masking method outperforms the traditional random masking method and supervised ImageNet pretraining on downstream segmentation accuracy by 2.9% for general datasets and 2.5% for weed segmentation datasets. Furthermore, we found that our selective masking method significantly improves accuracy for the lowest-performing classes. Lastly, we show that using the same pretraining and downstream dataset yields the best result for low-budget self-supervised pretraining. Our proposed Selective Masking Image Reconstruction method provides an effective and practical solution to improve end-to-end semantic segmentation workflows, especially for scenarios that require limited model capacity to meet inference speed and computational resource requirements.

</details>


### [193] [Power of Boundary and Reflection: Semantic Transparent Object Segmentation using Pyramid Vision Transformer with Transparent Cues](https://arxiv.org/abs/2512.07034)
*Tuan-Anh Vu,Hai Nguyen-Truong,Ziqiang Zheng,Binh-Son Hua,Qing Guo,Ivor Tsang,Sai-Kit Yeung*

Main category: cs.CV

TL;DR: TransCues：一种用于透明物体分割的Transformer架构，通过边界特征增强和反射特征增强模块，在多个基准数据集上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 玻璃等透明物体在日常物品中很常见，但由于其透明性和反射特性，现有分割方法难以将其与不透明材料区分开。人类感知依赖边界和反射物体特征来识别玻璃物体，但现有文献在处理透明物体时未能充分捕捉这两个特性。

Method: 提出TransCues框架，采用金字塔式Transformer编码器-解码器架构，包含边界特征增强模块和反射特征增强模块，以相互促进的方式整合这两种视觉线索。

Result: 在多个基准数据集上大幅超越现有最佳方法：Trans10K-v2 (+4.2% mIoU)、MSD (+5.6% mIoU)、RGBD-Mirror (+10.1% mIoU)、TROSD (+13.1% mIoU)、Stanford2D3D (+8.3% mIoU)。

Conclusion: 通过整合边界和反射特征增强模块，TransCues能有效分割透明物体，在多个数据集上表现出显著优势，验证了该方法对玻璃物体分割的有效性。

Abstract: Glass is a prevalent material among solid objects in everyday life, yet segmentation methods struggle to distinguish it from opaque materials due to its transparency and reflection. While it is known that human perception relies on boundary and reflective-object features to distinguish glass objects, the existing literature has not yet sufficiently captured both properties when handling transparent objects. Hence, we propose incorporating both of these powerful visual cues via the Boundary Feature Enhancement and Reflection Feature Enhancement modules in a mutually beneficial way. Our proposed framework, TransCues, is a pyramidal transformer encoder-decoder architecture to segment transparent objects. We empirically show that these two modules can be used together effectively, improving overall performance across various benchmark datasets, including glass object semantic segmentation, mirror object semantic segmentation, and generic segmentation datasets. Our method outperforms the state-of-the-art by a large margin, achieving +4.2% mIoU on Trans10K-v2, +5.6% mIoU on MSD, +10.1% mIoU on RGBD-Mirror, +13.1% mIoU on TROSD, and +8.3% mIoU on Stanford2D3D, showing the effectiveness of our method against glass objects.

</details>


### [194] [Evaluating and Preserving High-level Fidelity in Super-Resolution](https://arxiv.org/abs/2512.07037)
*Josep M. Rocafort,Shaolin Su,Javier Vazquez-Corral,Alexandra Gomez-Villa*

Main category: cs.CV

TL;DR: 该论文提出了评估超分辨率模型高级保真度的新标准，构建了首个带保真度评分的SR数据集，发现现有图像质量指标与保真度相关性不足，并展示了通过保真度反馈微调SR模型可同时提升语义保真度和感知质量。


<details>
  <summary>Details</summary>
Motivation: 当前超分辨率模型虽然能生成视觉上令人愉悦的结果，但其强大的生成能力有时会产生幻觉，改变图像内容。这种高级别的内容变化容易被人类识别，但现有低级图像质量指标未能很好地衡量。需要建立高级保真度测量作为补充标准，以揭示生成式SR模型的可靠性。

Method: 1) 构建首个带保真度评分的SR标注数据集；2) 评估SOTA SR模型在保持高级保真度方面的实际表现；3) 分析现有图像质量指标与保真度测量的相关性；4) 展示基础模型能更好地处理这一高级任务；5) 基于保真度反馈微调SR模型。

Result: 1) 现有图像质量指标与保真度测量相关性不足；2) 基础模型在高级保真度评估方面表现更好；3) 通过保真度反馈微调SR模型可以同时提高语义保真度和感知质量。

Conclusion: 高级保真度测量是评估SR模型的重要补充标准，对模型评估和优化具有潜在价值。提出的保真度标准有助于揭示生成式SR模型的可靠性，并通过反馈机制同时提升语义保真度和视觉质量。

Abstract: Recent image Super-Resolution (SR) models are achieving impressive effects in reconstructing details and delivering visually pleasant outputs. However, the overpowering generative ability can sometimes hallucinate and thus change the image content despite gaining high visual quality. This type of high-level change can be easily identified by humans yet not well-studied in existing low-level image quality metrics. In this paper, we establish the importance of measuring high-level fidelity for SR models as a complementary criterion to reveal the reliability of generative SR models. We construct the first annotated dataset with fidelity scores from different SR models, and evaluate how state-of-the-art (SOTA) SR models actually perform in preserving high-level fidelity. Based on the dataset, we then analyze how existing image quality metrics correlate with fidelity measurement, and further show that this high-level task can be better addressed by foundation models. Finally, by fine-tuning SR models based on our fidelity feedback, we show that both semantic fidelity and perceptual quality can be improved, demonstrating the potential value of our proposed criteria, both in model evaluation and optimization. We will release the dataset, code, and models upon acceptance.

</details>


### [195] [DAUNet: A Lightweight UNet Variant with Deformable Convolutions and Parameter-Free Attention for Medical Image Segmentation](https://arxiv.org/abs/2512.07051)
*Adnan Munir,Shujaat Khan*

Main category: cs.CV

TL;DR: DAUNet是一种轻量级UNet变体，结合可变形卷积和参数自由注意力机制，在医学图像分割中实现更好的空间适应性和上下文感知特征融合，同时保持模型效率。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割在自动化诊断和治疗规划中至关重要。现有方法在处理几何变化和上下文信息融合方面存在不足，同时需要保持模型轻量级以适应实时和资源受限的临床环境。

Method: 提出DAUNet，集成Deformable V2卷积和参数自由注意力机制(SimAM)。瓶颈层使用动态可变形核处理几何变化，解码器和跳跃连接路径使用SimAM注意力模块进行显著性感知细化。

Result: 在两个挑战性数据集(FH-PS-AoP超声和FUMPE CT)上，DAUNet在Dice分数、HD95和ASD指标上优于最先进模型，同时保持优越的参数效率。消融研究验证了可变形卷积和SimAM注意力的各自贡献。

Conclusion: DAUNet对缺失上下文和低对比度区域具有鲁棒性，适合在实时和资源受限的临床环境中部署，为医学图像分割提供了高效准确的解决方案。

Abstract: Medical image segmentation plays a pivotal role in automated diagnostic and treatment planning systems. In this work, we present DAUNet, a novel lightweight UNet variant that integrates Deformable V2 Convolutions and Parameter-Free Attention (SimAM) to improve spatial adaptability and context-aware feature fusion without increasing model complexity. DAUNet's bottleneck employs dynamic deformable kernels to handle geometric variations, while the decoder and skip pathways are enhanced using SimAM attention modules for saliency-aware refinement. Extensive evaluations on two challenging datasets, FH-PS-AoP (fetal head and pubic symphysis ultrasound) and FUMPE (CT-based pulmonary embolism detection), demonstrate that DAUNet outperforms state-of-the-art models in Dice score, HD95, and ASD, while maintaining superior parameter efficiency. Ablation studies highlight the individual contributions of deformable convolutions and SimAM attention. DAUNet's robustness to missing context and low-contrast regions establishes its suitability for deployment in real-time and resource-constrained clinical environments.

</details>


### [196] [RAVE: Rate-Adaptive Visual Encoding for 3D Gaussian Splatting](https://arxiv.org/abs/2512.07052)
*Hoang-Nhat Tran,Francesco Di Sario,Gabriele Spadaro,Giuseppe Valenzise,Enzo Tartaglione*

Main category: cs.CV

TL;DR: 提出一种支持任意速率插值的灵活3D高斯泼溅压缩方案，无需重新训练即可适应不同带宽和设备限制


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅（3DGS）虽然能实现实时逼真渲染，但存在内存需求大、训练成本高的问题。现有压缩方法只能在固定速率下工作，无法适应变化的带宽和设备限制。

Method: 提出灵活的3DGS压缩方案，支持在预定义边界之间任意速率插值。该方法计算轻量，无需为不同速率重新训练，能保持广泛的渲染质量。

Result: 实验证明该方法实现了高效、高质量的压缩，同时提供动态速率控制，适合沉浸式应用的实际部署。

Conclusion: 该方法解决了3DGS压缩的灵活性限制问题，为沉浸式应用提供了实用的动态压缩解决方案，代码将开源。

Abstract: Recent advances in neural scene representations have transformed immersive multimedia, with 3D Gaussian Splatting (3DGS) enabling real-time photorealistic rendering. Despite its efficiency, 3DGS suffers from large memory requirements and costly training procedures, motivating efforts toward compression. Existing approaches, however, operate at fixed rates, limiting adaptability to varying bandwidth and device constraints. In this work, we propose a flexible compression scheme for 3DGS that supports interpolation at any rate between predefined bounds. Our method is computationally lightweight, requires no retraining for any rate, and preserves rendering quality across a broad range of operating points. Experiments demonstrate that the approach achieves efficient, high-quality compression while offering dynamic rate control, making it suitable for practical deployment in immersive applications. The code will be provided open-source upon acceptance of the work.

</details>


### [197] [$\mathrm{D}^{\mathrm{3}}$-Predictor: Noise-Free Deterministic Diffusion for Dense Prediction](https://arxiv.org/abs/2512.07062)
*Changliang Xia,Chengyou Jia,Minnan Luo,Zhuohang Dang,Xin Shen,Bowen Ping*

Main category: cs.CV

TL;DR: D³-Predictor：一种无噪声的确定性框架，通过重新构建预训练扩散模型，消除随机噪声对密集预测任务中几何结构映射的破坏，实现高效的单步推理。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的密集预测方法存在核心限制：扩散采样的随机噪声与需要确定性图像到几何映射的密集预测任务本质不匹配。这种随机噪声会破坏细粒度空间线索，使模型偏向时间步特定的噪声目标，从而破坏有意义的几何结构映射。

Method: 提出D³-Predictor框架：1）将预训练扩散模型重新构建为无随机噪声的确定性框架；2）将预训练扩散网络视为时间步相关的视觉专家集合；3）通过自监督方式将异构先验聚合为单一、干净、完整的几何先验；4）利用任务特定监督无缝适配密集预测任务。

Result: 在多种密集预测任务上的广泛实验表明，D³-Predictor在多样化场景中达到竞争性或最先进的性能。同时，所需训练数据不到先前方法的一半，并能以单步高效执行推理。

Conclusion: D³-Predictor通过消除扩散模型中的随机噪声，成功解决了密集预测任务中的几何结构映射问题，提供了一种高效、数据效率高的确定性框架，在多种任务中表现出色。

Abstract: Although diffusion models with strong visual priors have emerged as powerful dense prediction backboens, they overlook a core limitation: the stochastic noise at the core of diffusion sampling is inherently misaligned with dense prediction that requires a deterministic mapping from image to geometry. In this paper, we show that this stochastic noise corrupts fine-grained spatial cues and pushes the model toward timestep-specific noise objectives, consequently destroying meaningful geometric structure mappings. To address this, we introduce $\mathrm{D}^{\mathrm{3}}$-Predictor, a noise-free deterministic framework built by reformulating a pretrained diffusion model without stochasticity noise. Instead of relying on noisy inputs to leverage diffusion priors, $\mathrm{D}^{\mathrm{3}}$-Predictor views the pretrained diffusion network as an ensemble of timestep-dependent visual experts and self-supervisedly aggregates their heterogeneous priors into a single, clean, and complete geometric prior. Meanwhile, we utilize task-specific supervision to seamlessly adapt this noise-free prior to dense prediction tasks. Extensive experiments on various dense prediction tasks demonstrate that $\mathrm{D}^{\mathrm{3}}$-Predictor achieves competitive or state-of-the-art performance in diverse scenarios. In addition, it requires less than half the training data previously used and efficiently performs inference in a single step. Our code, data, and checkpoints are publicly available at https://x-gengroup.github.io/HomePage_D3-Predictor/.

</details>


### [198] [Persistent Homology-Guided Frequency Filtering for Image Compression](https://arxiv.org/abs/2512.07065)
*Anil Chintapalli,Peter Tenholder,Henry Chen,Arjun Rao*

Main category: cs.CV

TL;DR: 使用离散傅里叶变换结合持续同调分析，从噪声图像中提取特定频率对应的拓扑特征，实现可区分有意义数据的压缩方法，在噪声条件下提升图像压缩可靠性。


<details>
  <summary>Details</summary>
Motivation: 噪声图像数据集中的特征提取面临模型可靠性挑战，需要开发能够在噪声条件下区分有意义数据并保持压缩性能的方法。

Method: 结合离散傅里叶变换和持续同调分析，提取与图像拓扑特征对应的特定频率，通过持续同调引导的频率过滤实现图像压缩和重构。

Result: 实验结果显示压缩水平与JPEG相当（使用六种不同指标评估），在增强卷积神经网络时，相比传统特征提取和压缩方法，在二分类任务中具有潜在性能提升。

Conclusion: 持续同调引导的频率过滤方法能够有效增强噪声条件下图像压缩的可靠性，为噪声图像处理提供了有用的解决方案。

Abstract: Feature extraction in noisy image datasets presents many challenges in model reliability. In this paper, we use the discrete Fourier transform in conjunction with persistent homology analysis to extract specific frequencies that correspond with certain topological features of an image. This method allows the image to be compressed and reformed while ensuring that meaningful data can be differentiated. Our experimental results show a level of compression comparable to that of using JPEG using six different metrics. The end goal of persistent homology-guided frequency filtration is its potential to improve performance in binary classification tasks (when augmenting a Convolutional Neural Network) compared to traditional feature extraction and compression methods. These findings highlight a useful end result: enhancing the reliability of image compression under noisy conditions.

</details>


### [199] [Context-measure: Contextualizing Metric for Camouflage](https://arxiv.org/abs/2512.07076)
*Chen-Yang Wang,Gepeng Ji,Song Shao,Ming-Ming Cheng,Deng-Ping Fan*

Main category: cs.CV

TL;DR: 提出了一种新的上下文感知评估指标Context-measure，用于评估伪装物体分割，比现有指标更符合人类感知


<details>
  <summary>Details</summary>
Motivation: 当前伪装场景评估指标忽视上下文依赖性，这些指标原本为评估一般或显著物体设计，假设空间上下文不相关，无法准确评估伪装场景

Method: 基于概率像素感知相关框架构建上下文化评估范式Context-measure，通过融入空间依赖性和像素级伪装量化，使评估更符合人类感知

Result: 在三个具有挑战性的伪装物体分割数据集上的广泛实验表明，Context-measure比现有上下文无关指标提供更可靠的评估

Conclusion: Context-measure可为涉及伪装模式的各种计算机视觉应用提供基础评估基准，包括农业、工业和医疗场景

Abstract: Camouflage is primarily context-dependent yet current metrics for camouflaged scenarios overlook this critical factor. Instead, these metrics are originally designed for evaluating general or salient objects, with an inherent assumption of uncorrelated spatial context. In this paper, we propose a new contextualized evaluation paradigm, Context-measure, built upon a probabilistic pixel-aware correlation framework. By incorporating spatial dependencies and pixel-wise camouflage quantification, our measure better aligns with human perception. Extensive experiments across three challenging camouflaged object segmentation datasets show that Context-measure delivers more reliability than existing context-independent metrics. Our measure can provide a foundational evaluation benchmark for various computer vision applications involving camouflaged patterns, such as agricultural, industrial, and medical scenarios. Code is available at https://github.com/pursuitxi/Context-measure.

</details>


### [200] [DFIR-DETR: Frequency Domain Enhancement and Dynamic Feature Aggregation for Cross-Scene Small Object Detection](https://arxiv.org/abs/2512.07078)
*Bo Gao,Jingcheng Tong,Xingsheng Chen,Han Yu,Zichen Li*

Main category: cs.CV

TL;DR: DFIR-DETR：一种结合动态特征聚合和频域处理的新型检测器，针对无人机遥感图像小目标检测和工业表面缺陷识别，解决了特征退化、长距离依赖和特征图膨胀问题，在保持轻量化的同时达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 无人机遥感图像小目标检测和工业表面缺陷识别面临共同挑战：特征稀疏且弱、背景杂乱、目标尺度变化大。现有transformer检测器存在三个关键问题：1）网络下采样导致特征严重退化；2）空间卷积无法有效捕获长距离依赖；3）标准上采样方法导致特征图不必要膨胀。

Method: 提出DFIR-DETR架构，包含三个核心模块：1）DCFA模块使用动态K稀疏注意力（复杂度从O(N²)降至O(NK)）和空间门控线性单元增强非线性建模；2）DFPN模块采用幅度归一化上采样防止特征膨胀，使用双路径洗牌卷积保留跨尺度空间细节；3）FIRC3模块在频域操作，实现全局感受野而不牺牲效率。

Result: 在NEU-DET和VisDrone数据集上分别达到92.9%和51.6%的mAP50分数，均为当前最优。模型保持轻量化，仅11.7M参数和41.2 GFLOPs，在资源受限的跨场景小目标检测中表现优异。

Conclusion: DFIR-DETR通过动态特征聚合和频域处理的创新结合，有效解决了小目标检测中的关键挑战，在两个不同领域都表现出强大的泛化能力和实际应用价值，特别适合资源受限环境。

Abstract: Detecting small objects in UAV remote sensing images and identifying surface defects in industrial inspection remain difficult tasks. These applications face common obstacles: features are sparse and weak, backgrounds are cluttered, and object scales vary dramatically. Current transformer-based detectors, while powerful, struggle with three critical issues. First, features degrade severely as networks downsample progressively. Second, spatial convolutions cannot capture long-range dependencies effectively. Third, standard upsampling methods inflate feature maps unnecessarily.
  We introduce DFIR-DETR to tackle these problems through dynamic feature aggregation combined with frequency-domain processing. Our architecture builds on three novel components. The DCFA module uses dynamic K-sparse attention, cutting complexity from O(N2) down to O(NK), and employs spatial gated linear units for better nonlinear modeling. The DFPN module applies amplitude-normalized upsampling to prevent feature inflation and uses dual-path shuffle convolution to retain spatial details across scales. The FIRC3 module operates in the frequency domain, achieving global receptive fields without sacrificing efficiency.
  We tested our method extensively on NEU-DET and VisDrone datasets. Results show mAP50 scores of 92.9% and 51.6% respectively-both state-of-the-art. The model stays lightweight with just 11.7M parameters and 41.2 GFLOPs. Strong performance across two very different domains confirms that DFIR-DETR generalizes well and works effectively in resource-limited settings for cross-scene small object detection.

</details>


### [201] [COREA: Coarse-to-Fine 3D Representation Alignment Between Relightable 3D Gaussians and SDF via Bidirectional 3D-to-3D Supervision](https://arxiv.org/abs/2512.07107)
*Jaeyoon Lee,Hojoon Jung,Sungtae Hwang,Jihyong Oh,Jongwon Choi*

Main category: cs.CV

TL;DR: COREA：首个联合学习可重光照3D高斯和SDF的统一框架，实现精确几何重建和忠实重光照


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法虽然扩展到网格重建和基于物理的渲染，但其几何仍从2D渲染中学习，导致表面粗糙和BRDF-光照分解不可靠

Method: 引入粗到细的双向3D到3D对齐策略，让几何信号直接在3D空间中学习；深度提供粗对齐，深度梯度和法线细化精细结构；密度控制机制稳定高斯增长

Result: 在标准基准测试中，COREA在新视角合成、网格重建和PBR方面均取得优越性能

Conclusion: COREA通过联合学习可重光照3D高斯和SDF，在统一框架内实现了精确几何重建和忠实重光照，解决了现有方法的局限性

Abstract: We present COREA, the first unified framework that jointly learns relightable 3D Gaussians and a Signed Distance Field (SDF) for accurate geometry reconstruction and faithful relighting. While recent 3D Gaussian Splatting (3DGS) methods have extended toward mesh reconstruction and physically-based rendering (PBR), their geometry is still learned from 2D renderings, leading to coarse surfaces and unreliable BRDF-lighting decomposition. To address these limitations, COREA introduces a coarse-to-fine bidirectional 3D-to-3D alignment strategy that allows geometric signals to be learned directly in 3D space. Within this strategy, depth provides coarse alignment between the two representations, while depth gradients and normals refine fine-scale structure, and the resulting geometry supports stable BRDF-lighting decomposition. A density-control mechanism further stabilizes Gaussian growth, balancing geometric fidelity with memory efficiency. Experiments on standard benchmarks demonstrate that COREA achieves superior performance in novel-view synthesis, mesh reconstruction, and PBR within a unified framework.

</details>


### [202] [MSN: Multi-directional Similarity Network for Hand-crafted and Deep-synthesized Copy-Move Forgery Detection](https://arxiv.org/abs/2512.07110)
*Liangwei Jiang,Jinluo Xie,Yecheng Huang,Hua Zhang,Hongyu Yang,Di Huang*

Main category: cs.CV

TL;DR: 提出MSN双流网络用于检测复制-移动图像伪造，通过多方向CNN编码和2D相似度矩阵解码器提升表示和定位能力，并在新构建的深度伪造数据库上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 复制-移动图像伪造检测面临复杂变换和精细操作的挑战，现有深度检测模型在特征表示和伪造区域定位方面存在局限，需要更准确高效的检测方法。

Method: 提出多方向相似度网络（MSN）：1）多方向CNN网络进行分层编码，通过尺度旋转增强提升特征相似度度量；2）设计基于2D相似度矩阵的解码器，充分利用图像空间信息进行定位。

Result: 在CASIA CMFD、CoMoFoD和新构建的深度伪造数据库上进行实验，取得了最先进的检测结果，证明了方法的有效性。

Conclusion: MSN网络通过改进特征表示和定位机制，能够准确高效地检测复制-移动图像伪造，特别是针对深度生成网络产生的伪造，同时构建的新数据库为深度合成伪造检测提供了新基准。

Abstract: Copy-move image forgery aims to duplicate certain objects or to hide specific contents with copy-move operations, which can be achieved by a sequence of manual manipulations as well as up-to-date deep generative network-based swapping. Its detection is becoming increasingly challenging for the complex transformations and fine-tuned operations on the tampered regions. In this paper, we propose a novel two-stream model, namely Multi-directional Similarity Network (MSN), to accurate and efficient copy-move forgery detection. It addresses the two major limitations of existing deep detection models in \textbf{representation} and \textbf{localization}, respectively. In representation, an image is hierarchically encoded by a multi-directional CNN network, and due to the diverse augmentation in scales and rotations, the feature achieved better measures the similarity between sampled patches in two streams. In localization, we design a 2-D similarity matrix based decoder, and compared with the current 1-D similarity vector based one, it makes full use of spatial information in the entire image, leading to the improvement in detecting tampered regions. Beyond the method, a new forgery database generated by various deep neural networks is presented, as a new benchmark for detecting the growing deep-synthesized copy-move. Extensive experiments are conducted on two classic image forensics benchmarks, \emph{i.e.} CASIA CMFD and CoMoFoD, and the newly presented one. The state-of-the-art results are reported, which demonstrate the effectiveness of the proposed approach.

</details>


### [203] [Training-free Clothing Region of Interest Self-correction for Virtual Try-On](https://arxiv.org/abs/2512.07126)
*Shengjie Lu,Zhibin Wan,Jiejie Liu,Quan Zhang,Mingjie Sun*

Main category: cs.CV

TL;DR: 提出基于能量函数的虚拟试穿方法，通过约束注意力图使生成结果更符合目标服装细节，并设计新评估指标VTID


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法在生成服装与目标服装的图案、纹理和边界方面存在差异，且现有评估指标只关注图像真实性而忽视与目标元素的对齐

Method: 使用能量函数约束生成过程中的注意力图，使注意力更集中于服装感兴趣区域；设计新的评估指标VTID（Virtual Try-on Inception Distance）

Result: 在VITON-HD和DressCode数据集上，LPIPS、FID、KID和VTID指标分别提升1.4%、2.3%、12.3%和5.8%；在下游CC-Reid任务中，LTCC、PRCC、VC-Clothes数据集的Rank-1指标分别提升2.5%、1.1%和1.6%

Conclusion: 提出的基于能量函数的注意力约束方法能有效改善虚拟试穿结果与目标服装的一致性，新评估指标VTID提供了更全面的评估框架

Abstract: VTON (Virtual Try-ON) aims at synthesizing the target clothing on a certain person, preserving the details of the target clothing while keeping the rest of the person unchanged. Existing methods suffer from the discrepancies between the generated clothing results and the target ones, in terms of the patterns, textures and boundaries. Therefore, we propose to use an energy function to impose constraints on the attention map extracted through the generation process. Thus, at each generation step, the attention can be more focused on the clothing region of interest, thereby influencing the generation results to be more consistent with the target clothing details. Furthermore, to address the limitation that existing evaluation metrics concentrate solely on image realism and overlook the alignment with target elements, we design a new metric, Virtual Try-on Inception Distance (VTID), to bridge this gap and ensure a more comprehensive assessment. On the VITON-HD and DressCode datasets, our approach has outperformed the previous state-of-the-art (SOTA) methods by 1.4%, 2.3%, 12.3%, and 5.8% in the traditional metrics of LPIPS, FID, KID, and the new VTID metrics, respectively. Additionally, by applying the generated data to downstream Clothing-Change Re-identification (CC-Reid) methods, we have achieved performance improvements of 2.5%, 1.1%, and 1.6% on the LTCC, PRCC, VC-Clothes datasets in the metrics of Rank-1. The code of our method is public at https://github.com/MrWhiteSmall/CSC-VTON.git.

</details>


### [204] [MulCLIP: A Multi-level Alignment Framework for Enhancing Fine-grained Long-context CLIP](https://arxiv.org/abs/2512.07128)
*Chau Truong,Hieu Ta Quang,Dung D. Le*

Main category: cs.CV

TL;DR: MulCLIP提出了一种端到端的多层次对齐框架，通过全局对比对齐、局部特征校准和子标题聚合补丁对齐，有效解决了CLIP模型在处理长文本描述时的局限性，在保持部署效率的同时提升了细粒度理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（如CLIP）在短文本描述上表现良好，但在处理长文本、详细描述时存在困难。虽然已有方法利用区域建议信息来映射视觉区域和长文本句子，但这些方法部署成本较高。需要一种既能处理长文本结构，又能保持部署效率的解决方案。

Method: MulCLIP采用多层次对齐框架：1）保持图像与摘要及长标题的全局对比对齐，并扩展位置嵌入以支持更长文本序列；2）通过局部校准特征的token重建对齐来加强词与图像补丁的语义连接；3）提出子标题聚合补丁对齐，自动提取和聚合每个子标题的上下文丰富补丁。

Result: 在多个基准测试上的实验结果表明，该方法能持续提升下游任务性能。消融研究证实其多尺度对齐是关键因素，相比基于区域建议的方法，在细粒度能力上表现更好，特别适合多样化的实际应用场景。

Conclusion: MulCLIP通过创新的多层次对齐机制，有效解决了CLIP模型在处理长文本描述时的局限性，在保持部署效率的同时显著提升了细粒度视觉语言理解能力，为实际应用提供了更优的解决方案。

Abstract: Vision-language models like CLIP show impressive ability to align images and text, but their training on short, concise captions makes them struggle with lengthy, detailed descriptions. Recent advances mitigate this challenge by leveraging region-proposal information to map visual regions with corresponding sentences from lengthy captions, yet incurring notable deployment costs. We introduce MulCLIP, a novel end-to-end multi-level alignment framework that bridges natural long-text structures with image components. MulCLIP first preserves global contrastive alignment between images and both summary and long captions, while extending positional embeddings for longer text sequences. To further enhance fine-grained understanding, we propose two novel strategies: (1) a token reconstruction alignment over locally calibrated features to strengthen semantic connections between words and image patches, and (2) a subcaption-aggregated patch alignment that automatically extracts and aggregates context-rich patches for each subcaption. Experimental results across diverse benchmarks demonstrate our method consistently improves downstream performance, while ablation studies confirm its multi-scale alignment is the key factor driving better fine-grained capability than region-proposal-assisted approaches, making it particularly suitable for diverse real-world applications.

</details>


### [205] [TrajMoE: Scene-Adaptive Trajectory Planning with Mixture of Experts and Reinforcement Learning](https://arxiv.org/abs/2512.07135)
*Zebin Xing,Pengxuan Yang,Linbo Wang,Yichen Zhang,Yiming Hu,Yupeng Zheng,Junli Wang,Yinfeng Gao,Guang Li,Kun Ma,Long Chen,Zhongpu Xia,Qichao Zhang,Hangjun Ye,Dongbin Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种改进的自动驾驶轨迹规划方法，通过MoE为不同场景提供合适的轨迹先验，并用强化学习微调轨迹评分机制，在navsim ICCV基准测试中获得51.08分（第三名）。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶系统虽然使用轨迹先验分布来提升规划性能，但存在两个关键问题：1) 不同驾驶场景需要不同的轨迹先验；2) 轨迹评估机制缺乏策略驱动的优化，受限于单阶段监督训练的局限性。

Method: 1) 使用混合专家模型（MoE）为不同驾驶场景提供定制的轨迹先验；2) 利用强化学习微调轨迹评分机制；3) 集成不同感知骨干网络以增强感知特征。

Result: 在navsim ICCV基准测试中获得51.08分，排名第三，证明了所提方法的有效性。

Conclusion: 通过场景自适应的轨迹先验和强化学习优化的评分机制，显著提升了自动驾驶轨迹规划的性能，为端到端自动驾驶系统提供了重要改进方向。

Abstract: Current autonomous driving systems often favor end-to-end frameworks, which take sensor inputs like images and learn to map them into trajectory space via neural networks. Previous work has demonstrated that models can achieve better planning performance when provided with a prior distribution of possible trajectories. However, these approaches often overlook two critical aspects: 1) The appropriate trajectory prior can vary significantly across different driving scenarios. 2) Their trajectory evaluation mechanism lacks policy-driven refinement, remaining constrained by the limitations of one-stage supervised training. To address these issues, we explore improvements in two key areas. For problem 1, we employ MoE to apply different trajectory priors tailored to different scenarios. For problem 2, we utilize Reinforcement Learning to fine-tune the trajectory scoring mechanism. Additionally, we integrate models with different perception backbones to enhance perceptual features. Our integrated model achieved a score of 51.08 on the navsim ICCV benchmark, securing third place.

</details>


### [206] [A Large-Scale Multimodal Dataset and Benchmarks for Human Activity Scene Understanding and Reasoning](https://arxiv.org/abs/2512.07136)
*Siyang Jiang,Mu Yuan,Xiang Ji,Bufang Yang,Zeyu Liu,Lilin Xu,Yang Li,Yuting He,Liran Dong,Wenrui Lu,Zhenyu Yan,Xiaofan Jiang,Wei Gao,Hongkai Chen,Guoliang Xing*

Main category: cs.CV

TL;DR: CUHK-X是一个大规模多模态数据集，用于人类动作识别、理解和推理，包含58,445个样本，覆盖40个动作，提供数据标签和文本描述两种标注，并提出了基于提示的场景创建方法来提高描述一致性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态人类动作识别主要依赖RGB数据，但非RGB模态（如深度、IMU、毫米波）缺乏大规模数据-描述资源。现有数据集主要提供粗糙的数据标签标注，不足以捕捉细粒度动作动态，限制了人类动作理解和推理的发展。

Method: 提出了CUHK-X数据集，包含58,445个样本，覆盖40个动作，由30名参与者在两个室内环境完成。采用基于提示的场景创建方法，利用LLM生成逻辑连贯的活动序列，然后进行人工验证，以提高描述的一致性。

Result: 实验结果显示平均准确率：人类动作识别76.52%，人类动作理解40.76%，人类动作推理70.25%。数据集包含三个基准测试和六个评估任务。

Conclusion: CUHK-X旨在为社区提供数据密集型学习方法，支持鲁棒的多模态人类活动分析，促进人类动作识别、理解和推理任务的发展。

Abstract: Multimodal human action recognition (HAR) leverages complementary sensors for activity classification. Beyond recognition, recent advances in large language models (LLMs) enable detailed descriptions and causal reasoning, motivating new tasks: human action understanding (HAU) and human action reasoning (HARn). However, most LLMs, especially large vision language models (LVLMs), struggle with non-RGB modalities such as depth, IMU, and mmWave due to the lack of large-scale data-caption resources. Existing HAR datasets mainly provide coarse data-label annotations, which are insufficient to capture fine-grained action dynamics needed for HAU and HARn. We consider two ground-truth pair types: (1) data label (discrete category) and (2) data caption (textual description). Naively generating captions from labels often lacks logical and spatiotemporal consistency. We introduce CUHK-X, a large-scale multimodal dataset and benchmark suite for HAR, HAU, and HARn. CUHK-X contains 58,445 samples covering 40 actions performed by 30 participants across two indoor environments. To improve caption consistency, we propose a prompt-based scene creation method that leverages LLMs to generate logically connected activity sequences, followed by human validation. CUHK-X includes three benchmarks with six evaluation tasks. Experiments report average accuracies of 76.52% (HAR), 40.76% (HAU), and 70.25% (HARn). CUHK-X aims to enable the community to apply and develop data-intensive learning methods for robust, multimodal human activity analysis. Project page and code: https://openaiotlab.github.io/CUHK-X/ and https://github.com/openaiotlab/CUHK-X.

</details>


### [207] [CHIMERA: Adaptive Cache Injection and Semantic Anchor Prompting for Zero-shot Image Morphing with Morphing-oriented Metrics](https://arxiv.org/abs/2512.07155)
*Dahyeon Kye,Jeahun Sung,MinKyu Jeon,Jihyong Oh*

Main category: cs.CV

TL;DR: CHIMERA是一个零样本扩散模型框架，通过自适应缓存注入和语义锚提示实现平滑图像变形，提出全局-局部一致性评分作为变形评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在图像变形方面存在过渡突兀或过饱和问题，缺乏自适应结构和语义对齐，需要改进变形质量。

Method: 提出CHIMERA框架：1) 自适应缓存注入(ACI)：在DDIM反演中缓存输入特征并在去噪时自适应重注入；2) 语义锚提示(SAP)：使用视觉语言模型生成共享锚提示作为语义桥梁；3) 全局-局部一致性评分(GLCS)作为变形评估指标。

Result: 实验和用户研究表明，CHIMERA比现有方法实现更平滑、语义更一致的变形，建立了新的图像变形技术状态。

Conclusion: CHIMERA通过创新的缓存注入和语义锚提示机制，解决了扩散模型在图像变形中的对齐问题，实现了高质量的零样本图像变形。

Abstract: Diffusion models exhibit remarkable generative ability, yet achieving smooth and semantically consistent image morphing remains a challenge. Existing approaches often yield abrupt transitions or over-saturated appearances due to the lack of adaptive structural and semantic alignments. We propose CHIMERA, a zero-shot diffusion-based framework that formulates morphing as a cached inversion-guided denoising process. To handle large semantic and appearance disparities, we propose Adaptive Cache Injection and Semantic Anchor Prompting. Adaptive Cache Injection (ACI) caches down, mid, and up blocks features from both inputs during DDIM inversion and re-injects them adaptively during denoising, enabling spatial and semantic alignment in depth- and time-adaptive manners and enabling natural feature fusion and smooth transitions. Semantic Anchor Prompting (SAP) leverages a vision-language model to generate a shared anchor prompt that serves as a semantic anchor, bridging dissimilar inputs and guiding the denoising process toward coherent results. Finally, we introduce the Global-Local Consistency Score (GLCS), a morphing-oriented metric that simultaneously evaluates the global harmonization of the two inputs and the smoothness of the local morphing transition. Extensive experiments and user studies show that CHIMERA achieves smoother and more semantically aligned transitions than existing methods, establishing a new state of the art in image morphing. The code and project page will be publicly released.

</details>


### [208] [MuSASplat: Efficient Sparse-View 3D Gaussian Splats via Lightweight Multi-Scale Adaptation](https://arxiv.org/abs/2512.07165)
*Muyu Xu,Fangneng Zhan,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: MuSASplat是一个用于稀疏视图3D高斯泼溅的轻量级框架，通过多尺度适配器和特征融合聚合器大幅减少训练参数和计算成本，同时保持高质量的新视角合成。


<details>
  <summary>Details</summary>
Motivation: 现有基于预训练3D先验的位姿无关前馈方法虽然效果不错，但需要完全微调大型ViT骨干网络，导致GPU成本过高。需要一种既能保持渲染质量又能显著降低计算负担的方法。

Method: 1. 轻量级多尺度适配器：仅微调ViT架构的一小部分参数，避免全模型适配的高昂GPU开销；2. 特征融合聚合器：有效整合多视图特征，替代传统内存库，降低内存使用和计算复杂度。

Result: 在多个数据集上的实验表明，MuSASplat达到了最先进的渲染质量，同时相比现有方法显著减少了参数数量和训练资源需求。

Conclusion: MuSASplat通过创新的轻量级适配器和特征融合机制，在稀疏视图3D高斯泼溅任务中实现了高质量渲染与低计算成本的平衡，为实际应用提供了可行方案。

Abstract: Sparse-view 3D Gaussian splatting seeks to render high-quality novel views of 3D scenes from a limited set of input images. While recent pose-free feed-forward methods leveraging pre-trained 3D priors have achieved impressive results, most of them rely on full fine-tuning of large Vision Transformer (ViT) backbones and incur substantial GPU costs. In this work, we introduce MuSASplat, a novel framework that dramatically reduces the computational burden of training pose-free feed-forward 3D Gaussian splats models with little compromise of rendering quality. Central to our approach is a lightweight Multi-Scale Adapter that enables efficient fine-tuning of ViT-based architectures with only a small fraction of training parameters. This design avoids the prohibitive GPU overhead associated with previous full-model adaptation techniques while maintaining high fidelity in novel view synthesis, even with very sparse input views. In addition, we introduce a Feature Fusion Aggregator that integrates features across input views effectively and efficiently. Unlike widely adopted memory banks, the Feature Fusion Aggregator ensures consistent geometric integration across input views and meanwhile mitigates the memory usage, training complexity, and computational costs significantly. Extensive experiments across diverse datasets show that MuSASplat achieves state-of-the-art rendering quality but has significantly reduced parameters and training resource requirements as compared with existing methods.

</details>


### [209] [When Privacy Meets Recovery: The Overlooked Half of Surrogate-Driven Privacy Preservation for MLLM Editing](https://arxiv.org/abs/2512.07166)
*Siyuan Xu,Yibing Liu,Peilin Chen,Yung-Hui Li,Shiqi Wang,Sam Kwong*

Main category: cs.CV

TL;DR: 该论文提出了一种新的隐私恢复方法，用于在多模态大语言模型（MLLMs）中恢复经过代理保护的隐私数据，解决了现有方法忽视隐私恢复质量评估的问题。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs隐私保护方法虽然能有效模糊隐私信息，但忽视了用户隐私真实性和恢复质量的评估。当前研究缺乏对代理驱动保护数据在各种MLLM场景中如何恢复这一关键挑战的关注。

Method: 1. 创建SPPE数据集，包含多种隐私类别和用户指令，模拟真实MLLM应用场景，提供受保护代理及其MLLM编辑版本；2. 将隐私恢复构建为基于互补多模态信号的引导生成任务；3. 提出统一方法，可靠重建隐私内容同时保持MLLM生成编辑的保真度。

Result: 在SPPE和InstructPix2Pix数据集上的实验表明，该方法在不同视觉内容和编辑任务中泛化能力强，在隐私保护和MLLM可用性之间实现了良好平衡。

Conclusion: 该工作填补了MLLMs隐私恢复研究空白，通过创新的数据集和方法，为评估和恢复代理保护隐私数据提供了有效解决方案，推动了隐私保护与模型可用性的平衡发展。

Abstract: Privacy leakage in Multimodal Large Language Models (MLLMs) has long been an intractable problem. Existing studies, though effectively obscure private information in MLLMs, often overlook the evaluation of the authenticity and recovery quality of user privacy. To this end, this work uniquely focuses on the critical challenge of how to restore surrogate-driven protected data in diverse MLLM scenarios. We first bridge this research gap by contributing the SPPE (Surrogate Privacy Protected Editable) dataset, which includes a wide range of privacy categories and user instructions to simulate real MLLM applications. This dataset offers protected surrogates alongside their various MLLM-edited versions, thus enabling the direct assessment of privacy recovery quality. By formulating privacy recovery as a guided generation task conditioned on complementary multimodal signals, we further introduce a unified approach that reliably reconstructs private content while preserving the fidelity of MLLM-generated edits. The experiments on both SPPE and InstructPix2Pix further show that our approach generalizes well across diverse visual content and editing tasks, achieving a strong balance between privacy protection and MLLM usability.

</details>


### [210] [Towards Unified Semantic and Controllable Image Fusion: A Diffusion Transformer Approach](https://arxiv.org/abs/2512.07170)
*Jiayang Li,Chengjie Jiang,Junjun Jiang,Pengwei Liang,Jiayi Ma,Liqiang Nie*

Main category: cs.CV

TL;DR: DiTFuse：基于扩散Transformer的指令驱动图像融合框架，通过自然语言指令实现端到端、语义感知的多模态图像融合，支持红外-可见光、多焦点、多曝光等多种融合任务。


<details>
  <summary>Details</summary>
Motivation: 现有图像融合方法在鲁棒性、适应性和可控性方面存在局限：1）针对特定任务设计，缺乏灵活性；2）难以融入用户意图；3）缺乏真实融合图像作为ground truth；4）数据集规模小，难以训练同时理解高层语义和细粒度多模态对齐的端到端模型。

Method: 提出DiTFuse框架：1）在共享潜在空间中联合编码两幅图像和自然语言指令；2）采用多退化掩码图像建模训练策略，联合学习跨模态对齐、模态不变恢复和任务感知特征选择；3）构建多粒度指令数据集；4）基于扩散Transformer架构实现端到端融合。

Result: 在IVIF、MFF、MEF等公开基准测试中取得优越的定量和定性性能，生成更清晰的纹理和更好的语义保留。模型支持多级用户控制，并能在其他多图像融合场景（包括指令条件分割）中实现零样本泛化。

Conclusion: DiTFuse统一了红外-可见光、多焦点、多曝光融合以及文本控制精炼和下游任务，通过指令驱动实现了灵活可控、语义感知的图像融合，克服了传统预融合和后融合管道的局限性。

Abstract: Image fusion aims to blend complementary information from multiple sensing modalities, yet existing approaches remain limited in robustness, adaptability, and controllability. Most current fusion networks are tailored to specific tasks and lack the ability to flexibly incorporate user intent, especially in complex scenarios involving low-light degradation, color shifts, or exposure imbalance. Moreover, the absence of ground-truth fused images and the small scale of existing datasets make it difficult to train an end-to-end model that simultaneously understands high-level semantics and performs fine-grained multimodal alignment. We therefore present DiTFuse, instruction-driven Diffusion-Transformer (DiT) framework that performs end-to-end, semantics-aware fusion within a single model. By jointly encoding two images and natural-language instructions in a shared latent space, DiTFuse enables hierarchical and fine-grained control over fusion dynamics, overcoming the limitations of pre-fusion and post-fusion pipelines that struggle to inject high-level semantics. The training phase employs a multi-degradation masked-image modeling strategy, so the network jointly learns cross-modal alignment, modality-invariant restoration, and task-aware feature selection without relying on ground truth images. A curated, multi-granularity instruction dataset further equips the model with interactive fusion capabilities. DiTFuse unifies infrared-visible, multi-focus, and multi-exposure fusion-as well as text-controlled refinement and downstream tasks-within a single architecture. Experiments on public IVIF, MFF, and MEF benchmarks confirm superior quantitative and qualitative performance, sharper textures, and better semantic retention. The model also supports multi-level user control and zero-shot generalization to other multi-image fusion scenarios, including instruction-conditioned segmentation.

</details>


### [211] [TIDE: Two-Stage Inverse Degradation Estimation with Guided Prior Disentanglement for Underwater Image Restoration](https://arxiv.org/abs/2512.07171)
*Shravan Venkatraman,Rakesh Raj Madavan,Pavan Kumar S,Muthu Subash Kavitha*

Main category: cs.CV

TL;DR: TIDE是一个两阶段水下图像恢复框架，通过专门先验分解显式建模退化特征，针对性地处理空间变化的多种退化问题。


<details>
  <summary>Details</summary>
Motivation: 水下图像恢复对海洋应用至关重要，但现有方法通常对整个图像应用统一的恢复策略，难以处理空间变化且同时发生的多种退化问题。

Method: TIDE采用两阶段逆退化估计框架：1）将水下退化分解为颜色失真、雾霾、细节损失和噪声四个关键因素，为每个因素设计专门的恢复专家；2）生成专门的恢复假设并根据局部退化模式自适应融合，然后通过渐进细化阶段校正残留伪影。

Result: 在标准基准和挑战性浑浊水条件下的广泛实验表明，TIDE在基于参考的保真度指标上具有竞争力，同时在非参考感知质量指标上优于最先进方法，在颜色校正和对比度增强方面有显著改进。

Conclusion: TIDE通过显式建模退化特征和专门先验分解，有效解决了水下图像中空间变化的复杂退化问题，实现了更自然和高质量的恢复结果。

Abstract: Underwater image restoration is essential for marine applications ranging from ecological monitoring to archaeological surveys, but effectively addressing the complex and spatially varying nature of underwater degradations remains a challenge. Existing methods typically apply uniform restoration strategies across the entire image, struggling to handle multiple co-occurring degradations that vary spatially and with water conditions. We introduce TIDE, a $\underline{t}$wo stage $\underline{i}$nverse $\underline{d}$egradation $\underline{e}$stimation framework that explicitly models degradation characteristics and applies targeted restoration through specialized prior decomposition. Our approach disentangles the restoration process into multiple specialized hypotheses that are adaptively fused based on local degradation patterns, followed by a progressive refinement stage that corrects residual artifacts. Specifically, TIDE decomposes underwater degradations into four key factors, namely color distortion, haze, detail loss, and noise, and designs restoration experts specialized for each. By generating specialized restoration hypotheses, TIDE balances competing degradation factors and produces natural results even in highly degraded regions. Extensive experiments across both standard benchmarks and challenging turbid water conditions show that TIDE achieves competitive performance on reference based fidelity metrics while outperforming state of the art methods on non reference perceptual quality metrics, with strong improvements in color correction and contrast enhancement. Our code is available at: https://rakesh-123-cryp.github.io/TIDE.

</details>


### [212] [START: Spatial and Textual Learning for Chart Understanding](https://arxiv.org/abs/2512.07186)
*Zhuoming Liu,Xiaofeng Gao,Feiyang Niu,Qiaozi Gao,Liu Liu,Robinson Piramuthu*

Main category: cs.CV

TL;DR: 提出START方法，通过空间和文本学习增强多模态大语言模型的图表理解能力，包括图表元素定位和图表到代码生成，并创建了新的数据集和基准测试。


<details>
  <summary>Details</summary>
Motivation: 图表理解对多模态大语言模型在实际场景中的应用至关重要。图表结合了结构化视觉布局（空间属性）和底层数据表示（文本属性），需要同时理解两者才能进行精确的细粒度图表推理。

Method: 提出START方法：1）图表元素定位；2）图表到代码生成。创建START-Dataset，使用MLLM将真实图表图像转换为可执行图表代码，再用LLM演化代码以确定图表元素位置。提出Chart Spatial understanding Benchmark (CS-Bench)评估模型对图表空间结构的理解能力。

Result: START在不同模型规模和基准测试上都取得了持续改进，明显超越了先前的最先进方法。代码、数据和模型将公开可用。

Conclusion: 通过结合空间和文本学习，START方法显著提升了多模态大语言模型的图表理解能力，填补了图表空间结构理解评估的空白，为实际应用提供了有效的解决方案。

Abstract: Chart understanding is crucial for deploying multimodal large language models (MLLMs) in real-world scenarios such as analyzing scientific papers and technical reports. Unlike natural images, charts pair a structured visual layout (spatial property) with an underlying data representation (textual property) -- grasping both is essential for precise, fine-grained chart reasoning. Motivated by this observation, we propose START, the Spatial and Textual learning for chART understanding. Specifically, we introduce (i) chart-element grounding and (ii) chart-to-code generation to strengthen an MLLM's understanding of both chart visual layout and data details. To facilitate spatial and textual learning, we propose the START-Dataset generated with a novel data-generation pipeline that first leverages an MLLM to translate real chart images into executable chart code, recovering the underlying data representation while preserving the visual distribution of real-world charts. We then evolve the code with a Large Language Model (LLM) to ascertain the positions of chart elements that capture the chart's visual structure, addressing challenges that existing methods cannot handle. To evaluate a model's ability to understand chart spatial structures, we propose the Chart Spatial understanding Benchmark (CS-Bench), filling a critical gap in comprehensive chart understanding evaluation. Leveraging spatial and textual learning, START delivers consistent gains across model sizes and benchmarks over the base models and surpasses prior state-of-the-art by a clear margin. Code, data and models will be publicly available.

</details>


### [213] [Integrating Multi-scale and Multi-filtration Topological Features for Medical Image Classification](https://arxiv.org/abs/2512.07190)
*Pengfei Gu,Huimin Li,Haoteng Tang,Dongkuan,Xu,Erik Enriquez,DongChul Kim,Bin Fu,Danny Z. Chen*

Main category: cs.CV

TL;DR: 提出一种新的拓扑引导分类框架，通过多尺度、多过滤持续同调特征增强医学图像分类性能


<details>
  <summary>Details</summary>
Motivation: 现有深度神经网络要么过度关注像素强度特征而忽略基本解剖结构，要么仅通过单参数持续性捕获简单拓扑特征，需要更全面的拓扑视角来识别复杂解剖结构

Method: 1) 计算多分辨率/尺度的立方持续性图；2) 开发"葡萄园"算法将多个PDs整合为单一稳定图；3) 设计基于交叉注意力的神经网络处理整合后的PDs；4) 将拓扑嵌入与CNN或Transformer特征图融合

Result: 在三个公共数据集上的评估显示，相比强基线和最先进方法，取得了持续且显著的改进

Conclusion: 通过将多尺度和多过滤拓扑整合到端到端架构中，该方法增强了模型识别复杂解剖结构的能力，为稳健且可解释的医学图像分类提供了全面的拓扑视角

Abstract: Modern deep neural networks have shown remarkable performance in medical image classification. However, such networks either emphasize pixel-intensity features instead of fundamental anatomical structures (e.g., those encoded by topological invariants), or they capture only simple topological features via single-parameter persistence. In this paper, we propose a new topology-guided classification framework that extracts multi-scale and multi-filtration persistent topological features and integrates them into vision classification backbones. For an input image, we first compute cubical persistence diagrams (PDs) across multiple image resolutions/scales. We then develop a ``vineyard'' algorithm that consolidates these PDs into a single, stable diagram capturing signatures at varying granularities, from global anatomy to subtle local irregularities that may indicate early-stage disease. To further exploit richer topological representations produced by multiple filtrations, we design a cross-attention-based neural network that directly processes the consolidated final PDs. The resulting topological embeddings are fused with feature maps from CNNs or Transformers. By integrating multi-scale and multi-filtration topologies into an end-to-end architecture, our approach enhances the model's capacity to recognize complex anatomical structures. Evaluations on three public datasets show consistent, considerable improvements over strong baselines and state-of-the-art methods, demonstrating the value of our comprehensive topological perspective for robust and interpretable medical image classification.

</details>


### [214] [RefLSM: Linearized Structural-Prior Reflectance Model for Medical Image Segmentation and Bias-Field Correction](https://arxiv.org/abs/2512.07191)
*Wenqi Zhao,Jiacheng Sang,Fenghua Cheng,Yonglu Shu,Dong Li,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 提出RefLSM模型，将Retinex反射率分解融入水平集分割，通过反射率分割解决医学图像不均匀光照问题，引入线性结构先验和松弛二值水平集提升精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割面临强度不均匀、噪声、模糊边界和不规则结构等挑战。传统水平集方法依赖近似偏置场估计，在严重非均匀成像条件下表现不佳。

Method: 提出反射率水平集模型(RefLSM)，将观察图像分解为反射率和偏置场分量，直接分割光照不变的反射率。引入线性结构先验引导平滑反射率梯度，以及松弛二值水平集避免重新初始化扩散。采用ADMM优化方案。

Result: 在多个医学影像数据集上的实验表明，RefLSM相比最先进的水平集方法，在分割精度、鲁棒性和计算效率方面均表现更优。

Conclusion: RefLSM通过整合Retinex反射率分解，有效解决了医学图像分割中的光照不均匀问题，结合结构先验和松弛水平集，实现了更精确、鲁棒的分割。

Abstract: Medical image segmentation remains challenging due to intensity inhomogeneity, noise, blurred boundaries, and irregular structures. Traditional level set methods, while effective in certain cases, often depend on approximate bias field estimations and therefore struggle under severe non-uniform imaging conditions. To address these limitations, we propose a novel variational Reflectance-based Level Set Model (RefLSM), which explicitly integrates Retinex-inspired reflectance decomposition into the segmentation framework. By decomposing the observed image into reflectance and bias field components, RefLSM directly segments the reflectance, which is invariant to illumination and preserves fine structural details. Building on this foundation, we introduce two key innovations for enhanced precision and robustness. First, a linear structural prior steers the smoothed reflectance gradients toward a data-driven reference, providing reliable geometric guidance in noisy or low-contrast scenes. Second, a relaxed binary level-set is embedded in RefLSM and enforced via convex relaxation and sign projection, yielding stable evolution and avoiding reinitialization-induced diffusion. The resulting variational problem is solved efficiently using an ADMM-based optimization scheme. Extensive experiments on multiple medical imaging datasets demonstrate that RefLSM achieves superior segmentation accuracy, robustness, and computational efficiency compared to state-of-the-art level set methods.

</details>


### [215] [HVQ-CGIC: Enabling Hyperprior Entropy Modeling for VQ-Based Controllable Generative Image Compression](https://arxiv.org/abs/2512.07192)
*Niu Yi,Xu Tianyi,Ma Mingming,Wang Xinkun*

Main category: cs.CV

TL;DR: 提出HVQ-CGIC框架，首次在基于向量量化的生成式图像压缩中引入超先验熵模型，实现RD平衡与控制，相比现有方法节省61.3%比特率


<details>
  <summary>Details</summary>
Motivation: 现有基于向量量化的生成式图像压缩方法使用静态全局概率分布估计熵，无法适应图像特定内容，导致比特率潜力未充分挖掘且难以实现灵活码率控制

Method: 提出HVQ-CGIC框架，为VQ索引熵模型引入超先验建立数学基础，通过新颖的损失函数设计实现RD平衡与控制，配合轻量级超先验估计网络

Result: 在Kodak数据集上，达到与Control-GIC、CDC和HiFiC相同的LPIPS质量时，平均节省61.3%的比特率，在RD性能上显著优于现有SOTA生成式压缩方法

Conclusion: HVQ-CGIC有望成为VQGAN-based图像压缩的基础组件，类似于超先验框架在神经图像压缩中的核心作用，为生成式压缩提供了有效的RD控制方案

Abstract: Generative learned image compression methods using Vector Quantization (VQ) have recently shown impressive potential in balancing distortion and perceptual quality. However, these methods typically estimate the entropy of VQ indices using a static, global probability distribution, which fails to adapt to the specific content of each image. This non-adaptive approach leads to untapped bitrate potential and challenges in achieving flexible rate control. To address this challenge, we introduce a Controllable Generative Image Compression framework based on a VQ Hyperprior, termed HVQ-CGIC. HVQ-CGIC rigorously derives the mathematical foundation for introducing a hyperprior to the VQ indices entropy model. Based on this foundation, through novel loss design, to our knowledge, this framework is the first to introduce RD balance and control into vector quantization-based Generative Image Compression. Cooperating with a lightweight hyper-prior estimation network, HVQ-CGIC achieves a significant advantage in rate-distortion (RD) performance compared to current state-of-the-art (SOTA) generative compression methods. On the Kodak dataset, we achieve the same LPIPS as Control-GIC, CDC and HiFiC with an average of 61.3% fewer bits. We posit that HVQ-CGIC has the potential to become a foundational component for VQGAN-based image compression, analogous to the integral role of the HyperPrior framework in neural image compression.

</details>


### [216] [SUCCESS-GS: Survey of Compactness and Compression for Efficient Static and Dynamic Gaussian Splatting](https://arxiv.org/abs/2512.07197)
*Seokhyun Youn,Soohyun Lee,Geonho Kim,Weeyoung Kwon,Sung-Ho Bae,Jihyong Oh*

Main category: cs.CV

TL;DR: 这篇综述首次系统梳理了高效3D/4D高斯泼溅技术，将现有方法分为参数压缩和结构压缩两大类，总结了核心思想、数据集、评估指标，并讨论了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅(3DGS)虽然能实现实时高保真3D重建和新视角合成，但其存储和渲染数百万高斯需要大量内存和计算资源，在4D动态场景中问题更加严重。因此需要开发高效的高斯泼溅技术来减少冗余同时保持重建质量。

Method: 对高效3D和4D高斯泼溅技术进行首次统一综述，将现有方法系统分类为两大方向：1) 参数压缩：直接减少高斯参数数量；2) 结构压缩：重新组织高斯结构以提高效率。同时涵盖广泛使用的数据集、评估指标和代表性基准比较。

Result: 提供了高效高斯泼溅技术的全面分类框架，总结了各方法的核心思想和趋势，为研究人员提供了系统的技术路线图，帮助理解当前技术发展状态。

Conclusion: 高效高斯泼溅技术是解决3DGS内存和计算瓶颈的关键方向。未来需要朝着可扩展、紧凑、实时的静态和动态3D场景表示方向发展，克服当前限制，推动该技术的实际应用。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful explicit representation enabling real-time, high-fidelity 3D reconstruction and novel view synthesis. However, its practical use is hindered by the massive memory and computational demands required to store and render millions of Gaussians. These challenges become even more severe in 4D dynamic scenes. To address these issues, the field of Efficient Gaussian Splatting has rapidly evolved, proposing methods that reduce redundancy while preserving reconstruction quality. This survey provides the first unified overview of efficient 3D and 4D Gaussian Splatting techniques. For both 3D and 4D settings, we systematically categorize existing methods into two major directions, Parameter Compression and Restructuring Compression, and comprehensively summarize the core ideas and methodological trends within each category. We further cover widely used datasets, evaluation metrics, and representative benchmark comparisons. Finally, we discuss current limitations and outline promising research directions toward scalable, compact, and real-time Gaussian Splatting for both static and dynamic 3D scene representation.

</details>


### [217] [Understanding Diffusion Models via Code Execution](https://arxiv.org/abs/2512.07201)
*Cheng Yu*

Main category: cs.CV

TL;DR: 一篇约300行代码的简洁扩散模型实现教程，从代码执行角度解释扩散模型工作原理，弥合理论与实践的差距


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽然性能出色，但理论复杂，论文中的数学公式与开源实现之间存在较大差距。现有教程主要关注公式推导，对代码实际运行机制指导有限

Method: 提供约300行代码的简洁实现，从代码执行角度解释扩散模型，保留核心组件（前向扩散、反向采样、噪声预测网络、训练循环），去除不必要的工程细节

Result: 创建了一个清晰的最小化示例，帮助研究人员理解扩散模型的实际工作原理以及代码与理论之间的对应关系

Conclusion: 通过实现优先的方法，为研究人员提供了对扩散模型实际工作方式的清晰理解，弥合了理论与实践之间的鸿沟，代码和预训练模型已开源

Abstract: Diffusion models have achieved remarkable performance in generative modeling, yet their theoretical foundations are often intricate, and the gap between mathematical formulations in papers and practical open-source implementations can be difficult to bridge. Existing tutorials primarily focus on deriving equations, offering limited guidance on how diffusion models actually operate in code. To address this, we present a concise implementation of approximately 300 lines that explains diffusion models from a code-execution perspective. Our minimal example preserves the essential components -- including forward diffusion, reverse sampling, the noise-prediction network, and the training loop -- while removing unnecessary engineering details. This technical report aims to provide researchers with a clear, implementation-first understanding of how diffusion models work in practice and how code and theory correspond. Our code and pre-trained models are available at: https://github.com/disanda/GM/tree/main/DDPM-DDIM-ClassifierFree.

</details>


### [218] [MMRPT: MultiModal Reinforcement Pre-Training via Masked Vision-Dependent Reasoning](https://arxiv.org/abs/2512.07203)
*Xuhui Zheng,Kang An,Ziliang Wang,Yuhang Wang,Faqiang Qian,Yichao Wu*

Main category: cs.CV

TL;DR: MMRPT：首个将强化学习直接融入大规模视觉语言模型预训练的框架，通过掩码多模态数据增强视觉推理能力


<details>
  <summary>Details</summary>
Motivation: 当前多模态预训练受限于图像-描述对的描述性偏差，导致模型更依赖表面语言线索而非真正的视觉理解。需要强化视觉推理能力。

Method: 提出掩码多模态强化预训练框架：1) 通过视觉token注意力估计句子级视觉依赖度；2) 掩码高度视觉依赖的文本片段；3) 模型通过视觉推理重建这些片段，由语义-视觉奖励函数指导。

Result: 在多个基准测试中实现一致的零样本性能提升，在监督微调下显著提高鲁棒性，证明强化驱动的掩码推理为多模态模型提供了更可靠和可泛化的预训练目标。

Conclusion: 强化学习驱动的掩码推理能够有效增强多模态模型的视觉基础能力，提供比传统基于描述模仿的预训练更优的学习信号。

Abstract: Multimodal pre-training remains constrained by the descriptive bias of image-caption pairs, leading models to favor surface linguistic cues over grounded visual understanding. We introduce MMRPT, a masked multimodal reinforcement pre-training framework that strengthens visual reasoning in MLLMs. We are the first to incorporate reinforcement learning directly into the pre-training of large vision-language models, enabling learning signals that reward visual grounding rather than caption imitation. MMRPT constructs masked multimodal data by estimating sentence-level visual dependency via attention over visual tokens and masking highly vision-dependent segments; the model reconstructs these spans through vision-grounded reasoning guided by a semantic-visual reward. Experiments show consistent zero-shot gains across diverse benchmarks and substantially improved robustness under supervised fine-tuning, demonstrating that reinforcement-driven masked reasoning provides a more reliable and generalizable pre-training objective for multimodal models.

</details>


### [219] [AutoLugano: A Deep Learning Framework for Fully Automated Lymphoma Segmentation and Lugano Staging on FDG-PET/CT](https://arxiv.org/abs/2512.07206)
*Boyang Pan,Zeyu Zhang,Hongyu Meng,Bin Cui,Yingying Zhang,Wenli Hou,Junhao Li,Langdi Zhong,Xiaoxiao Chen,Xiaoyu Xu,Changjin Zuo,Chao Cheng,Nan-Jie Gong*

Main category: cs.CV

TL;DR: AutoLugano：首个全自动端到端深度学习系统，可从FDG-PET/CT扫描自动完成淋巴瘤病灶分割、解剖定位和Lugano分期，用于治疗分层和临床决策支持。


<details>
  <summary>Details</summary>
Motivation: 开发全自动系统，将基线FDG-PET/CT扫描转化为完整的Lugano分期，以辅助淋巴瘤的初始分期、治疗分层和临床决策制定。

Method: 系统包含三个顺序模块：1）基于3D nnU-Net的解剖感知病灶分割；2）利用TotalSegmentator工具包进行图谱式解剖定位，将病灶映射到21个预定义淋巴结区域；3）自动Lugano分期，根据受累区域空间分布确定分期和治疗分组（局限期vs.进展期）。

Result: 在外部验证集上，区域受累检测总体准确率88.31%，敏感性74.47%，特异性94.21%，F1分数80.80%。关键的治疗分层任务（局限期vs.进展期）准确率达85.07%，特异性90.48%，敏感性82.61%。

Conclusion: AutoLugano是首个全自动端到端系统，可将单次基线FDG-PET/CT扫描转化为完整Lugano分期，在初始分期、治疗分层和临床决策支持方面具有强大潜力。

Abstract: Purpose: To develop a fully automated deep learning system, AutoLugano, for end-to-end lymphoma classification by performing lesion segmentation, anatomical localization, and automated Lugano staging from baseline FDG-PET/CT scans. Methods: The AutoLugano system processes baseline FDG-PET/CT scans through three sequential modules:(1) Anatomy-Informed Lesion Segmentation, a 3D nnU-Net model, trained on multi-channel inputs, performs automated lesion detection (2) Atlas-based Anatomical Localization, which leverages the TotalSegmentator toolkit to map segmented lesions to 21 predefined lymph node regions using deterministic anatomical rules; and (3) Automated Lugano Staging, where the spatial distribution of involved regions is translated into Lugano stages and therapeutic groups (Limited vs. Advanced Stage).The system was trained on the public autoPET dataset (n=1,007) and externally validated on an independent cohort of 67 patients. Performance was assessed using accuracy, sensitivity, specificity, F1-scorefor regional involvement detection and staging agreement. Results: On the external validation set, the proposed model demonstrated robust performance, achieving an overall accuracy of 88.31%, sensitivity of 74.47%, Specificity of 94.21% and an F1-score of 80.80% for regional involvement detection,outperforming baseline models. Most notably, for the critical clinical task of therapeutic stratification (Limited vs. Advanced Stage), the system achieved a high accuracy of 85.07%, with a specificity of 90.48% and a sensitivity of 82.61%.Conclusion: AutoLugano represents the first fully automated, end-to-end pipeline that translates a single baseline FDG-PET/CT scan into a complete Lugano stage. This study demonstrates its strong potential to assist in initial staging, treatment stratification, and supporting clinical decision-making.

</details>


### [220] [Object Pose Distribution Estimation for Determining Revolution and Reflection Uncertainty in Point Clouds](https://arxiv.org/abs/2512.07211)
*Frederik Hagelskjær,Dimitrios Arapis,Steffen Madsen,Thorbjørn Mosekjær Iversen*

Main category: cs.CV

TL;DR: 首个仅使用3D无色数据的深度学习物体姿态不确定性估计方法，适用于工业场景


<details>
  <summary>Details</summary>
Motivation: 传统单姿态估计无法捕捉视觉模糊性带来的不确定性，现有方法依赖颜色信息，而工业场景中颜色信息往往不可用

Method: 提出基于神经网络的物体姿态不确定性估计方法，仅使用3D无色数据，专注于反射和旋转对称性，但框架可扩展到完整的SE(3)姿态分布估计

Result: 在真实世界箱拣选场景中验证了方法有效性，处理了具有不同几何模糊性的物体

Conclusion: 这是首个不依赖RGB输入的深度学习姿态分布估计方法，为工业应用中的姿态不确定性估计提供了实用解决方案

Abstract: Object pose estimation is crucial to robotic perception and typically provides a single-pose estimate. However, a single estimate cannot capture pose uncertainty deriving from visual ambiguity, which can lead to unreliable behavior. Existing pose distribution methods rely heavily on color information, often unavailable in industrial settings.
  We propose a novel neural network-based method for estimating object pose uncertainty using only 3D colorless data. To the best of our knowledge, this is the first approach that leverages deep learning for pose distribution estimation without relying on RGB input. We validate our method in a real-world bin picking scenario with objects of varying geometric ambiguity. Our current implementation focuses on symmetries in reflection and revolution, but the framework is extendable to full SE(3) pose distribution estimation. Source code available at opde3d.github.io

</details>


### [221] [VFM-VLM: Vision Foundation Model and Vision Language Model based Visual Comparison for 3D Pose Estimation](https://arxiv.org/abs/2512.07215)
*Md Selim Sarowar,Sungho Kim*

Main category: cs.CV

TL;DR: 比较CLIP和DINOv2在抓取场景3D姿态估计中的表现：CLIP语义理解强，DINOv2几何特征优


<details>
  <summary>Details</summary>
Motivation: 视觉基础模型(VFMs)和视觉语言模型(VLMs)为计算机视觉提供了丰富的语义和几何表示，但它们在3D姿态估计任务中的表现差异尚未系统研究，特别是在手物抓取场景中。

Method: 对基于CLIP和DINOv2的方法进行全面的视觉比较，评估它们在6D物体姿态估计任务上的表现，分析两种模型的互补优势。

Result: CLIP在语义理解方面表现优异，通过语言接地实现更好的语义一致性；DINOv2提供更优的密集几何特征，在几何精度方面具有竞争力。

Conclusion: 两种模型各有优势：CLIP适合语义相关任务，DINOv2适合几何精度要求高的场景，为机器人操作和抓取应用提供了模型选择指导。

Abstract: Vision Foundation Models (VFMs) and Vision Language Models (VLMs) have revolutionized computer vision by providing rich semantic and geometric representations. This paper presents a comprehensive visual comparison between CLIP based and DINOv2 based approaches for 3D pose estimation in hand object grasping scenarios. We evaluate both models on the task of 6D object pose estimation and demonstrate their complementary strengths: CLIP excels in semantic understanding through language grounding, while DINOv2 provides superior dense geometric features. Through extensive experiments on benchmark datasets, we show that CLIP based methods achieve better semantic consistency, while DINOv2 based approaches demonstrate competitive performance with enhanced geometric precision. Our analysis provides insights for selecting appropriate vision models for robotic manipulation and grasping, picking applications.

</details>


### [222] [Towards Robust Protective Perturbation against DeepFake Face Swapping](https://arxiv.org/abs/2512.07228)
*Hengyang Yao,Lin Li,Ke Sun,Jianing Qiu,Huiping Chen*

Main category: cs.CV

TL;DR: 提出EOLT框架，通过学习变换分布而非固定采样，显著提升DeepFake防护的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有DeepFake防护方法通过在图像中嵌入不可见扰动来防御，但这些扰动对压缩、调整大小等基本变换非常脆弱。传统均匀采样的期望变换(EOT)方法存在根本性缺陷

Method: 提出期望学习变换分布(EOLT)框架，将变换分布作为可学习组件而非固定设计。使用策略网络通过强化学习自动优先处理关键变换，生成实例特定的扰动，显式建模防御瓶颈同时保持广泛可迁移性

Result: 在广泛实验中，该方法相比最先进方法取得显著改进：平均鲁棒性提高26%，在具有挑战性的变换类别上增益高达30%

Conclusion: EOLT框架通过将变换分布作为可学习组件，显著提升了DeepFake防护的鲁棒性，为解决现有防护方法的脆弱性问题提供了有效方案

Abstract: DeepFake face swapping enables highly realistic identity forgeries, posing serious privacy and security risks. A common defence embeds invisible perturbations into images, but these are fragile and often destroyed by basic transformations such as compression or resizing. In this paper, we first conduct a systematic analysis of 30 transformations across six categories and show that protection robustness is highly sensitive to the choice of training transformations, making the standard Expectation over Transformation (EOT) with uniform sampling fundamentally suboptimal. Motivated by this, we propose Expectation Over Learned distribution of Transformation (EOLT), the framework to treat transformation distribution as a learnable component rather than a fixed design choice. Specifically, EOLT employs a policy network that learns to automatically prioritize critical transformations and adaptively generate instance-specific perturbations via reinforcement learning, enabling explicit modeling of defensive bottlenecks while maintaining broad transferability. Extensive experiments demonstrate that our method achieves substantial improvements over state-of-the-art approaches, with 26% higher average robustness and up to 30% gains on challenging transformation categories.

</details>


### [223] [ReLKD: Inter-Class Relation Learning with Knowledge Distillation for Generalized Category Discovery](https://arxiv.org/abs/2512.07229)
*Fang Zhou,Zhiqiang Chen,Martin Pavlovski,Yizhong Zhang*

Main category: cs.CV

TL;DR: ReLKD是一个端到端框架，通过利用隐式类间关系来增强广义类别发现中新颖类别的分类性能，特别适用于标注数据有限的场景。


<details>
  <summary>Details</summary>
Motivation: 广义类别发现（GCD）面临在只有已知类别标签的情况下对包含已知和未知类别的未标注数据进行分类的挑战。现有方法通常独立处理每个类别，忽略了固有的类间关系，而直接获取这些关系在现实场景中具有显著挑战。

Method: ReLKD包含三个关键模块：1）目标粒度模块学习判别性表示；2）粗粒度模块捕获层次化类间关系；3）蒸馏模块将知识从粗粒度模块转移到目标粒度模块，以优化表示学习。

Result: 在四个数据集上的广泛实验证明了ReLKD的有效性，特别是在标注数据有限的场景下表现优异。

Conclusion: ReLKD通过有效利用隐式类间关系并转移知识来增强新颖类别的分类，为广义类别发现问题提供了一个有效的端到端解决方案。

Abstract: Generalized Category Discovery (GCD) faces the challenge of categorizing unlabeled data containing both known and novel classes, given only labels for known classes. Previous studies often treat each class independently, neglecting the inherent inter-class relations. Obtaining such inter-class relations directly presents a significant challenge in real-world scenarios. To address this issue, we propose ReLKD, an end-to-end framework that effectively exploits implicit inter-class relations and leverages this knowledge to enhance the classification of novel classes. ReLKD comprises three key modules: a target-grained module for learning discriminative representations, a coarse-grained module for capturing hierarchical class relations, and a distillation module for transferring knowledge from the coarse-grained module to refine the target-grained module's representation learning. Extensive experiments on four datasets demonstrate the effectiveness of ReLKD, particularly in scenarios with limited labeled data. The code for ReLKD is available at https://github.com/ZhouF-ECNU/ReLKD.

</details>


### [224] [STRinGS: Selective Text Refinement in Gaussian Splatting](https://arxiv.org/abs/2512.07230)
*Abhinav Raundhal,Gaurav Behera,P J Narayanan,Ravi Kiran Sarvadevabhatla,Makarand Tapaswi*

Main category: cs.CV

TL;DR: STRinGS是一个针对3D高斯泼溅（3DGS）的文本感知选择性优化框架，通过分别处理文本和非文本区域，显著提升3D重建中文本的可读性。


<details>
  <summary>Details</summary>
Motivation: 现实场景中的文本（如标志、标签、说明）包含重要上下文信息，但现有3D表示方法（如3DGS）难以保留细粒度文本细节，文本重建的小错误会导致显著的语义损失。

Method: 提出STRinGS框架，将文本和非文本区域分开处理：先优化文本区域，然后与优化后的非文本区域合并进行全场景优化。还引入了文本可读性评估指标OCR字符错误率（CER）和STRinGS-360数据集。

Result: STRinGS在仅7K次迭代下，相比3DGS在文本区域实现了63.6%的相对改进，能生成清晰可读的文本，即使在具有挑战性的配置下也是如此。

Conclusion: STRinGS方法和STRinGS-360数据集共同推动了文本丰富环境中3D场景理解的边界，为更鲁棒的文本感知重建方法铺平了道路。

Abstract: Text as signs, labels, or instructions is a critical element of real-world scenes as they can convey important contextual information. 3D representations such as 3D Gaussian Splatting (3DGS) struggle to preserve fine-grained text details, while achieving high visual fidelity. Small errors in textual element reconstruction can lead to significant semantic loss. We propose STRinGS, a text-aware, selective refinement framework to address this issue for 3DGS reconstruction. Our method treats text and non-text regions separately, refining text regions first and merging them with non-text regions later for full-scene optimization. STRinGS produces sharp, readable text even in challenging configurations. We introduce a text readability measure OCR Character Error Rate (CER) to evaluate the efficacy on text regions. STRinGS results in a 63.6% relative improvement over 3DGS at just 7K iterations. We also introduce a curated dataset STRinGS-360 with diverse text scenarios to evaluate text readability in 3D reconstruction. Our method and dataset together push the boundaries of 3D scene understanding in text-rich environments, paving the way for more robust text-aware reconstruction methods.

</details>


### [225] [Dropout Prompt Learning: Towards Robust and Adaptive Vision-Language Models](https://arxiv.org/abs/2512.07234)
*Biao Chen,Lin Zuo,Mengmeng Jing,Kunbin He,Yuchen Wang*

Main category: cs.CV

TL;DR: 提出Dropout Prompt Learning方法，通过评估token重要性并应用差异化dropout概率来提升视觉语言模型的鲁棒性，同时在15个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: Dropout作为广泛使用的正则化技术能提升模型泛化能力，但传统dropout方法在视觉语言模型中应用有限。本文旨在通过改进dropout策略来增强视觉语言模型的鲁棒性，特别是在低样本学习、长尾分类和分布外泛化等挑战性场景中。

Method: 提出Dropout Prompt Learning方法：1）在文本和视觉分支的token上应用dropout；2）考虑模态内上下文和模态间对齐来评估token重要性，为每个token设置灵活的dropout概率；3）引入残差熵正则化，在保持语义对齐的同时鼓励dropout带来的多样化表示。

Result: 在15个基准测试中验证了方法的有效性，特别是在低样本学习、长尾分类和分布外泛化等挑战性场景中表现优异。在base-to-novel泛化任务中，性能超过正则化方法KgCoOp 5.10%，超过PromptSRC 2.13%。

Conclusion: Dropout Prompt Learning通过智能化的token级dropout策略和残差熵正则化，有效提升了视觉语言模型的鲁棒性和泛化能力，在多种挑战性场景中展现出显著优势。

Abstract: Dropout is a widely used regularization technique which improves the generalization ability of a model by randomly dropping neurons. In light of this, we propose Dropout Prompt Learning, which aims for applying dropout to improve the robustness of the vision-language models. Different from the vanilla dropout, we apply dropout on the tokens of the textual and visual branches, where we evaluate the token significance considering both intra-modal context and inter-modal alignment, enabling flexible dropout probabilities for each token. Moreover, to maintain semantic alignment for general knowledge transfer while encouraging the diverse representations that dropout introduces, we further propose residual entropy regularization. Experiments on 15 benchmarks show our method's effectiveness in challenging scenarios like low-shot learning, long-tail classification, and out-of-distribution generalization. Notably, our method surpasses regularization-based methods including KgCoOp by 5.10% and PromptSRC by 2.13% in performance on base-to-novel generalization.

</details>


### [226] [Unified Camera Positional Encoding for Controlled Video Generation](https://arxiv.org/abs/2512.07237)
*Cheng Zhang,Boying Li,Meng Wei,Yan-Pei Cao,Camilo Cruz Gambardella,Dinh Phung,Jianfei Cai*

Main category: cs.CV

TL;DR: 提出UCPE（统一相机位置编码），通过相对光线编码和绝对方向编码，在视频扩散Transformer中实现精确的相机控制，仅增加不到1%的可训练参数。


<details>
  <summary>Details</summary>
Motivation: 现有相机编码方法通常基于简化的针孔模型假设，限制了在真实世界相机多样内参和镜头畸变情况下的泛化能力。需要一种几何一致的表示方法来统一完整的相机信息。

Method: 提出相对光线编码（Relative Ray Encoding）统一相机姿态、内参和镜头畸变信息；识别俯仰和横滚作为绝对方向编码的有效组件；构建UCPE集成到预训练视频扩散Transformer中，通过轻量级空间注意力适配器实现。

Result: UCPE在相机可控视频生成任务中实现了最先进的相机控制能力和视觉保真度；构建了包含广泛相机运动和镜头类型的大规模视频数据集；验证了UCPE作为Transformer通用相机表示的潜力。

Conclusion: UCPE提供了一种几何一致的相机表示方法，在视频生成中实现了精确的相机控制，并有望成为未来多视角、视频和3D任务中Transformer的通用相机表示。

Abstract: Transformers have emerged as a universal backbone across 3D perception, video generation, and world models for autonomous driving and embodied AI, where understanding camera geometry is essential for grounding visual observations in three-dimensional space. However, existing camera encoding methods often rely on simplified pinhole assumptions, restricting generalization across the diverse intrinsics and lens distortions in real-world cameras. We introduce Relative Ray Encoding, a geometry-consistent representation that unifies complete camera information, including 6-DoF poses, intrinsics, and lens distortions. To evaluate its capability under diverse controllability demands, we adopt camera-controlled text-to-video generation as a testbed task. Within this setting, we further identify pitch and roll as two components effective for Absolute Orientation Encoding, enabling full control over the initial camera orientation. Together, these designs form UCPE (Unified Camera Positional Encoding), which integrates into a pretrained video Diffusion Transformer through a lightweight spatial attention adapter, adding less than 1% trainable parameters while achieving state-of-the-art camera controllability and visual fidelity. To facilitate systematic training and evaluation, we construct a large video dataset covering a wide range of camera motions and lens types. Extensive experiments validate the effectiveness of UCPE in camera-controllable video generation and highlight its potential as a general camera representation for Transformers across future multi-view, video, and 3D tasks. Code will be available at https://github.com/chengzhag/UCPE.

</details>


### [227] [Squeezed-Eff-Net: Edge-Computed Boost of Tomography Based Brain Tumor Classification leveraging Hybrid Neural Network Architecture](https://arxiv.org/abs/2512.07241)
*Md. Srabon Chowdhury,Syeda Fahmida Tanzim,Sheekar Banerjee,Ishtiak Al Mamoon,AKM Muzahidul Islam*

Main category: cs.CV

TL;DR: 提出结合SqueezeNet v1和EfficientNet-B0的混合深度学习模型，加入手工放射组学特征，用于脑肿瘤MRI分类，达到98.93%准确率。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤诊断需要及时准确，但MRI肿瘤勾画过程困难、耗时且易受观察者间差异影响，需要自动化解决方案。

Method: 结合轻量级SqueezeNet v1和高性能EfficientNet-B0的混合深度学习模型，增强手工放射组学特征（HOG、LBP、Gabor滤波器和小波变换），在Nickparvar脑肿瘤MRI数据集上训练测试。

Result: 测试准确率达98.93%，使用测试时间增强后达99.08%，模型参数少于210万，计算量小于1.2 GFLOPs，具有良好泛化能力。

Conclusion: 该混合模型在计算效率和诊断准确性之间取得良好平衡，手工特征增强纹理敏感性，具有临床可靠性，可用于临床决策支持系统。

Abstract: Brain tumors are one of the most common and dangerous neurological diseases which require a timely and correct diagnosis to provide the right treatment procedures. Even with the promotion of magnetic resonance imaging (MRI), the process of tumor delineation is difficult and time-consuming, which is prone to inter-observer error. In order to overcome these limitations, this work proposes a hybrid deep learning model based on SqueezeNet v1 which is a lightweight model, and EfficientNet-B0, which is a high-performing model, and is enhanced with handcrafted radiomic descriptors, including Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), Gabor filters and Wavelet transforms. The framework was trained and tested only on publicly available Nickparvar Brain Tumor MRI dataset, which consisted of 7,023 contrast-enhanced T1-weighted axial MRI slices which were categorized into four groups: glioma, meningioma, pituitary tumor, and no tumor. The testing accuracy of the model was 98.93% that reached a level of 99.08% with Test Time Augmentation (TTA) showing great generalization and power. The proposed hybrid network offers a compromise between computation efficiency and diagnostic accuracy compared to current deep learning structures and only has to be trained using fewer than 2.1 million parameters and less than 1.2 GFLOPs. The handcrafted feature addition allowed greater sensitivity in texture and the EfficientNet-B0 backbone represented intricate hierarchical features. The resulting model has almost clinical reliability in automated MRI-based classification of tumors highlighting its possibility of use in clinical decision-support systems.

</details>


### [228] [Zero-Shot Textual Explanations via Translating Decision-Critical Features](https://arxiv.org/abs/2512.07245)
*Toshinori Yamauchi,Hiroshi Kera,Kazuhiko Kawamoto*

Main category: cs.CV

TL;DR: TEXTER通过隔离决策关键特征来生成更忠实、可解释的图像分类器文本解释，相比现有方法能更好地反映模型推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有零样本解释方法通常将全局图像特征与语言对齐，只能描述可见内容而非驱动预测的关键因素。大型视觉语言模型虽然能生成字幕，但并非针对分类器特定推理设计。

Method: TEXTER首先识别对预测有贡献的神经元，强调这些神经元编码的决策关键特征，然后将这些强调的特征映射到CLIP特征空间以检索反映模型推理的文本解释。稀疏自编码器进一步提高了Transformer架构的可解释性。

Result: 大量实验表明，TEXTER生成的解释比现有方法更忠实、更可解释。

Conclusion: TEXTER通过隔离决策关键特征的方法，能够生成更准确地反映图像分类器推理过程的文本解释，提高了透明度和可解释性。

Abstract: Textual explanations make image classifier decisions transparent by describing the prediction rationale in natural language. Large vision-language models can generate captions but are designed for general visual understanding, not classifier-specific reasoning. Existing zero-shot explanation methods align global image features with language, producing descriptions of what is visible rather than what drives the prediction. We propose TEXTER, which overcomes this limitation by isolating decision-critical features before alignment. TEXTER identifies the neurons contributing to the prediction and emphasizes the features encoded in those neurons -- i.e., the decision-critical features. It then maps these emphasized features into the CLIP feature space to retrieve textual explanations that reflect the model's reasoning. A sparse autoencoder further improves interpretability, particularly for Transformer architectures. Extensive experiments show that TEXTER generates more faithful and interpretable explanations than existing methods. The code will be publicly released.

</details>


### [229] [AdLift: Lifting Adversarial Perturbations to Safeguard 3D Gaussian Splatting Assets Against Instruction-Driven Editing](https://arxiv.org/abs/2512.07247)
*Ziming Hong,Tianyu Huang,Runnan Chen,Shanshan Ye,Mingming Gong,Bo Han,Tongliang Liu*

Main category: cs.CV

TL;DR: AdLift：首个3D高斯泼溅（3DGS）编辑保护方法，通过将严格约束的2D对抗扰动提升为3D高斯表示，防止任意视角和维度的指令驱动编辑


<details>
  <summary>Details</summary>
Motivation: 随着基于扩散模型的指令驱动2D图像编辑扩展到3DGS，虽然促进了3D内容创作，但也使3DGS资产面临未经授权编辑和恶意篡改的风险。现有2D图像的对抗扰动保护方法难以直接应用于3DGS，面临视角泛化保护和可见性与保护能力平衡两大挑战

Method: 提出AdLift方法：1）将严格约束的2D对抗扰动提升为3D高斯表示的保护层；2）采用定制的Lifted PGD进行渐进优化，通过梯度截断和投影梯度严格约束图像级扰动；3）通过图像到高斯的拟合操作将扰动反向传播到保护高斯参数；4）交替进行梯度截断和图像-高斯拟合，实现跨视角一致的对抗保护

Result: 实验结果表明，AdLift能有效保护3DGS资产免受最先进的指令驱动2D图像和3DGS编辑方法的攻击，在不同视角下提供一致的对抗保护性能，并能泛化到新视角

Conclusion: AdLift是首个针对3DGS的编辑保护方法，成功解决了视角泛化保护和可见性-保护能力平衡的挑战，为3DGS资产提供了有效的安全防护

Abstract: Recent studies have extended diffusion-based instruction-driven 2D image editing pipelines to 3D Gaussian Splatting (3DGS), enabling faithful manipulation of 3DGS assets and greatly advancing 3DGS content creation. However, it also exposes these assets to serious risks of unauthorized editing and malicious tampering. Although imperceptible adversarial perturbations against diffusion models have proven effective for protecting 2D images, applying them to 3DGS encounters two major challenges: view-generalizable protection and balancing invisibility with protection capability. In this work, we propose the first editing safeguard for 3DGS, termed AdLift, which prevents instruction-driven editing across arbitrary views and dimensions by lifting strictly bounded 2D adversarial perturbations into 3D Gaussian-represented safeguard. To ensure both adversarial perturbations effectiveness and invisibility, these safeguard Gaussians are progressively optimized across training views using a tailored Lifted PGD, which first conducts gradient truncation during back-propagation from the editing model at the rendered image and applies projected gradients to strictly constrain the image-level perturbation. Then, the resulting perturbation is backpropagated to the safeguard Gaussian parameters via an image-to-Gaussian fitting operation. We alternate between gradient truncation and image-to-Gaussian fitting, yielding consistent adversarial-based protection performance across different viewpoints and generalizes to novel views. Empirically, qualitative and quantitative results demonstrate that AdLift effectively protects against state-of-the-art instruction-driven 2D image and 3DGS editing.

</details>


### [230] [See More, Change Less: Anatomy-Aware Diffusion for Contrast Enhancement](https://arxiv.org/abs/2512.07251)
*Junqi Liu,Zejun Wu,Pedro R. A. S. Bassi,Xinze Zhou,Wenxuan Li,Ibrahim E. Hamamci,Sezgin Er,Tianyu Lin,Yi Luo,Szymon Płotka,Bjoern Menze,Daguang Xu,Kai Ding,Kang Wang,Yang Yang,Yucheng Tang,Alan L. Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: SMILE是一种解剖感知的扩散模型，用于医学图像增强，能理解器官形状和对比度动态，只在临床相关区域进行增强，避免过度编辑。


<details>
  <summary>Details</summary>
Motivation: 当前医学图像增强模型经常过度编辑，导致器官变形、产生虚假发现并遗漏小肿瘤，因为它们不理解解剖结构或对比度动态。

Method: 提出SMILE模型，包含三个关键创新：(1)结构感知监督，遵循真实器官边界和对比度模式；(2)无需配准的学习，直接处理未对齐的多期相CT扫描；(3)统一推理，在所有对比度期相提供快速一致的增强。

Result: 在六个外部数据集上，SMILE在图像质量方面优于现有方法（SSIM提高14.2%，PSNR提高20.6%，FID改善50%），并能产生解剖准确且具有诊断意义的图像。还能提高非对比CT的癌症检测能力，F1分数提升高达10%。

Conclusion: SMILE通过理解解剖结构和对比度动态，实现了临床相关区域的精确增强，避免了过度编辑问题，显著提升了医学图像增强的质量和临床实用性。

Abstract: Image enhancement improves visual quality and helps reveal details that are hard to see in the original image. In medical imaging, it can support clinical decision-making, but current models often over-edit. This can distort organs, create false findings, and miss small tumors because these models do not understand anatomy or contrast dynamics. We propose SMILE, an anatomy-aware diffusion model that learns how organs are shaped and how they take up contrast. It enhances only clinically relevant regions while leaving all other areas unchanged. SMILE introduces three key ideas: (1) structure-aware supervision that follows true organ boundaries and contrast patterns; (2) registration-free learning that works directly with unaligned multi-phase CT scans; (3) unified inference that provides fast and consistent enhancement across all contrast phases. Across six external datasets, SMILE outperforms existing methods in image quality (14.2% higher SSIM, 20.6% higher PSNR, 50% better FID) and in clinical usefulness by producing anatomically accurate and diagnostically meaningful images. SMILE also improves cancer detection from non-contrast CT, raising the F1 score by up to 10 percent.

</details>


### [231] [DGGAN: Degradation Guided Generative Adversarial Network for Real-time Endoscopic Video Enhancement](https://arxiv.org/abs/2512.07253)
*Handing Xu,Zhenguo Nie,Tairan Peng,Huimin Pan,Xin-Jun Liu*

Main category: cs.CV

TL;DR: 提出一种基于退化感知的实时内窥镜视频增强框架，通过跨帧传播退化表示实现高效高质量增强


<details>
  <summary>Details</summary>
Motivation: 内窥镜手术依赖术中视频，但视频常受光照不均、组织散射、遮挡和运动模糊等退化影响，现有深度学习方法计算量大难以实时应用

Method: 使用对比学习提取退化表示，通过融合机制调制图像特征，采用单帧增强模型并引入循环一致性约束训练

Result: 在性能与效率之间达到优越平衡，优于多种先进方法，验证了退化感知建模的有效性

Conclusion: 隐式学习和传播退化表示为临床实时应用提供了实用途径

Abstract: Endoscopic surgery relies on intraoperative video, making image quality a decisive factor for surgical safety and efficacy. Yet, endoscopic videos are often degraded by uneven illumination, tissue scattering, occlusions, and motion blur, which obscure critical anatomical details and complicate surgical manipulation. Although deep learning-based methods have shown promise in image enhancement, most existing approaches remain too computationally demanding for real-time surgical use. To address this challenge, we propose a degradation-aware framework for endoscopic video enhancement, which enables real-time, high-quality enhancement by propagating degradation representations across frames. In our framework, degradation representations are first extracted from images using contrastive learning. We then introduce a fusion mechanism that modulates image features with these representations to guide a single-frame enhancement model, which is trained with a cycle-consistency constraint between degraded and restored images to improve robustness and generalization. Experiments demonstrate that our framework achieves a superior balance between performance and efficiency compared with several state-of-the-art methods. These results highlight the effectiveness of degradation-aware modeling for real-time endoscopic video enhancement. Nevertheless, our method suggests that implicitly learning and propagating degradation representation offer a practical pathway for clinical application.

</details>


### [232] [A graph generation pipeline for critical infrastructures based on heuristics, images and depth data](https://arxiv.org/abs/2512.07269)
*Mike Diessner,Yannick Tarant*

Main category: cs.CV

TL;DR: 提出基于摄影测量和深度学习的低成本图生成管道，用于关键基础设施的虚拟表示，替代昂贵的激光扫描方法


<details>
  <summary>Details</summary>
Motivation: 传统基于激光扫描的3D点云方法成本高且需要专业知识，需要更经济易用的替代方案来创建关键基础设施的数字孪生

Method: 使用立体相机获取RGB图像和深度数据，通过深度学习进行物体检测和实例分割，结合用户定义的启发式规则推断物体关系，生成图结构表示

Result: 在两个液压系统上的实验表明，该方法能生成接近真实情况的图结构，同时保持灵活性和透明度

Conclusion: 提出的摄影测量图生成管道为关键基础设施数字孪生提供了一种成本效益高、灵活且透明的替代方案，适用于高风险决策场景

Abstract: Virtual representations of physical critical infrastructures, such as water or energy plants, are used for simulations and digital twins to ensure resilience and continuity of their services. These models usually require 3D point clouds from laser scanners that are expensive to acquire and require specialist knowledge to use. In this article, we present a graph generation pipeline based on photogrammetry. The pipeline detects relevant objects and predicts their relation using RGB images and depth data generated by a stereo camera. This more cost-effective approach uses deep learning for object detection and instance segmentation of the objects, and employs user-defined heuristics or rules to infer their relations. Results of two hydraulic systems show that this strategy can produce graphs close to the ground truth while its flexibility allows the method to be tailored to specific applications and its transparency qualifies it to be used in the high stakes decision-making that is required for critical infrastructures.

</details>


### [233] [RVLF: A Reinforcing Vision-Language Framework for Gloss-Free Sign Language Translation](https://arxiv.org/abs/2512.07273)
*Zhi Rao,Yucheng Zhou,Benjia Zhou,Yiqing Huang,Sergio Escalera,Jun Wan*

Main category: cs.CV

TL;DR: 提出RVLF框架解决手语翻译中视觉表示不足和语义对齐问题，通过融合运动与视觉特征，结合GRPO强化学习优化，在多个数据集上显著提升BLEU分数


<details>
  <summary>Details</summary>
Motivation: 当前无注释手语翻译面临两大挑战：1）手语表示不足，难以捕捉细微视觉线索；2）基于LLM的方法存在句子级语义错位，限制翻译质量

Method: 提出三阶段强化视觉语言框架RVLF：1）构建专门的手语大视觉语言模型，融合骨架运动线索和DINOv2提取的视觉特征；2）指令微调获得SLT-SFT基线；3）引入GRPO优化策略，结合BLEU和ROUGE奖励函数微调模型

Result: 在CSL-Daily、PHOENIX-2014T、How2Sign和OpenASL数据集上，BLEU-4分数分别提升+5.1、+1.11、+1.4和+1.61，无需外部大规模手语数据集预训练

Conclusion: 首次将GRPO应用于手语翻译，通过强化学习有效提升翻译质量和语义一致性，为无注释手语翻译提供了创新解决方案

Abstract: Gloss-free sign language translation (SLT) is hindered by two key challenges: **inadequate sign representation** that fails to capture nuanced visual cues, and **sentence-level semantic misalignment** in current LLM-based methods, which limits translation quality. To address these issues, we propose a three-stage **r**einforcing **v**ision-**l**anguage **f**ramework (**RVLF**). We build a large vision-language model (LVLM) specifically designed for sign language, and then combine it with reinforcement learning (RL) to adaptively enhance translation performance. First, for a sufficient representation of sign language, RVLF introduces an effective semantic representation learning mechanism that fuses skeleton-based motion cues with semantically rich visual features extracted via DINOv2, followed by instruction tuning to obtain a strong SLT-SFT baseline. Then, to improve sentence-level semantic misalignment, we introduce a GRPO-based optimization strategy that fine-tunes the SLT-SFT model with a reward function combining translation fidelity (BLEU) and sentence completeness (ROUGE), yielding the optimized model termed SLT-GRPO. Our conceptually simple framework yields substantial gains under the gloss-free SLT setting without pre-training on any external large-scale sign language datasets, improving BLEU-4 scores by +5.1, +1.11, +1.4, and +1.61 on the CSL-Daily, PHOENIX-2014T, How2Sign, and OpenASL datasets, respectively. To the best of our knowledge, this is the first work to incorporate GRPO into SLT. Extensive experiments and ablation studies validate the effectiveness of GRPO-based optimization in enhancing both translation quality and semantic consistency.

</details>


### [234] [Effective Attention-Guided Multi-Scale Medical Network for Skin Lesion Segmentation](https://arxiv.org/abs/2512.07275)
*Siyu Wang,Hua Wang,Huiyu Li,Fan Zhang*

Main category: cs.CV

TL;DR: 提出一种用于皮肤病变分割的新型编码器-解码器网络，通过多尺度残差结构、MRCF模块、CMAM注意力模块和EAB桥接模块，有效解决不规则形状和低对比度问题，在多个数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 在医疗领域，精确的皮肤病变分割对早期检测和准确诊断至关重要。现有深度学习方法难以有效处理不规则病变形状和低对比度问题，需要更有效的解决方案。

Method: 提出基于多尺度残差结构的编码器-解码器网络架构，包含：1) MRCF模块捕获跨尺度特征；2) CMAM注意力模块重新定义注意力范围并动态计算多上下文权重；3) EAB桥接模块解决传统U-Net跳跃连接的信息损失问题。

Result: 在多个皮肤病变分割数据集上的广泛实验评估表明，该模型显著优于现有的基于transformer和卷积神经网络的方法，展现出卓越的分割精度和鲁棒性。

Conclusion: 提出的方法通过创新的多尺度特征提取、注意力机制和桥接模块，有效解决了皮肤病变分割中的挑战，为医疗图像分析提供了更准确和鲁棒的解决方案。

Abstract: In the field of healthcare, precise skin lesion segmentation is crucial for the early detection and accurate diagnosis of skin diseases. Despite significant advances in deep learning for image processing, existing methods have yet to effectively address the challenges of irregular lesion shapes and low contrast. To address these issues, this paper proposes an innovative encoder-decoder network architecture based on multi-scale residual structures, capable of extracting rich feature information from different receptive fields to effectively identify lesion areas. By introducing a Multi-Resolution Multi-Channel Fusion (MRCF) module, our method captures cross-scale features, enhancing the clarity and accuracy of the extracted information. Furthermore, we propose a Cross-Mix Attention Module (CMAM), which redefines the attention scope and dynamically calculates weights across multiple contexts, thus improving the flexibility and depth of feature capture and enabling deeper exploration of subtle features. To overcome the information loss caused by skip connections in traditional U-Net, an External Attention Bridge (EAB) is introduced, facilitating the effective utilization of information in the decoder and compensating for the loss during upsampling. Extensive experimental evaluations on several skin lesion segmentation datasets demonstrate that the proposed model significantly outperforms existing transformer and convolutional neural network-based models, showcasing exceptional segmentation accuracy and robustness.

</details>


### [235] [Geo3DVQA: Evaluating Vision-Language Models for 3D Geospatial Reasoning from Aerial Imagery](https://arxiv.org/abs/2512.07276)
*Mai Tsujimoto,Junjue Wang,Weihao Xuan,Naoto Yokoya*

Main category: cs.CV

TL;DR: Geo3DVQA是一个用于评估视觉语言模型在仅使用RGB遥感图像进行3D地理空间推理能力的基准测试，包含11万个问题-答案对，涵盖16个任务类别和3个复杂度级别。


<details>
  <summary>Details</summary>
Motivation: 当前3D地理空间分析方法依赖昂贵的专业传感器（如LiDAR和多光谱），限制了全球可访问性。现有方法难以整合多个3D线索、处理多样化查询并提供可解释的推理。

Method: 创建Geo3DVQA基准测试，包含110k个精心策划的问题-答案对，涵盖16个任务类别和三个复杂度级别：单特征推理、多特征推理和应用级空间分析。使用RGB遥感图像评估视觉语言模型的3D推理能力。

Result: 评估10个最先进的视觉语言模型显示RGB到3D推理的困难性：GPT-4o准确率28.6%，Gemini-2.5-Flash准确率33.0%。领域特定的Qwen2.5-VL-7B微调达到49.6%准确率（提升24.8个百分点）。

Conclusion: Geo3DVQA揭示了当前视觉语言模型的局限性以及领域适应的有效性，为可扩展、可访问和全面的3D地理空间分析引入了新的挑战前沿。

Abstract: Three-dimensional geospatial analysis is critical to applications in urban planning, climate adaptation, and environmental assessment. Current methodologies depend on costly, specialized sensors (e.g., LiDAR and multispectral), which restrict global accessibility. Existing sensor-based and rule-driven methods further struggle with tasks requiring the integration of multiple 3D cues, handling diverse queries, and providing interpretable reasoning. We hereby present Geo3DVQA, a comprehensive benchmark for evaluating vision-language models (VLMs) in height-aware, 3D geospatial reasoning using RGB-only remote sensing imagery. Unlike conventional sensor-based frameworks, Geo3DVQA emphasizes realistic scenarios that integrate elevation, sky view factors, and land cover patterns. The benchmark encompasses 110k curated question-answer pairs spanning 16 task categories across three complexity levels: single-feature inference, multi-feature reasoning, and application-level spatial analysis. The evaluation of ten state-of-the-art VLMs highlights the difficulty of RGB-to-3D reasoning. GPT-4o and Gemini-2.5-Flash achieved only 28.6% and 33.0% accuracy respectively, while domain-specific fine-tuning of Qwen2.5-VL-7B achieved 49.6% (+24.8 points). These results reveal both the limitations of current VLMs and the effectiveness of domain adaptation. Geo3DVQA introduces new challenge frontiers for scalable, accessible, and holistic 3D geospatial analysis. The dataset and code will be released upon publication at https://github.com/mm1129/Geo3DVQA.

</details>


### [236] [Towards Accurate UAV Image Perception: Guiding Vision-Language Models with Stronger Task Prompts](https://arxiv.org/abs/2512.07302)
*Mingning Guo,Mengwei Wu,Shaoxian Li,Haifeng Li,Chao Tao*

Main category: cs.CV

TL;DR: AerialVP是一个用于无人机图像感知的任务提示增强代理框架，通过提取多维辅助信息来增强任务提示，克服传统VLM方法在复杂无人机图像处理中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型（VLM）的图像感知方法在处理无人机图像时面临目标混淆、尺度变化和复杂背景等挑战。当任务提示过于简单而图像内容复杂时，视觉和文本标记之间的语义对齐变得困难，限制了模型聚焦任务相关信息的能力。

Method: AerialVP框架通过三个阶段增强任务提示：1）分析任务提示以确定任务类型和增强需求；2）从工具库中选择适当工具；3）基于分析和所选工具生成增强的任务提示。同时引入了AerialSense基准测试集，包含无人机视觉推理、视觉问答和视觉定位任务。

Result: 实验结果表明，AerialVP显著增强了任务提示的指导能力，在开源和专有VLM中都带来了稳定且显著的性能提升。

Conclusion: AerialVP通过主动提取无人机图像的多维辅助信息来增强任务提示，有效解决了传统VLM方法在处理复杂无人机图像时的局限性，为无人机图像感知提供了新的解决方案。

Abstract: Existing image perception methods based on VLMs generally follow a paradigm wherein models extract and analyze image content based on user-provided textual task prompts. However, such methods face limitations when applied to UAV imagery, which presents challenges like target confusion, scale variations, and complex backgrounds. These challenges arise because VLMs' understanding of image content depends on the semantic alignment between visual and textual tokens. When the task prompt is simplistic and the image content is complex, achieving effective alignment becomes difficult, limiting the model's ability to focus on task-relevant information. To address this issue, we introduce AerialVP, the first agent framework for task prompt enhancement in UAV image perception. AerialVP proactively extracts multi-dimensional auxiliary information from UAV images to enhance task prompts, overcoming the limitations of traditional VLM-based approaches. Specifically, the enhancement process includes three stages: (1) analyzing the task prompt to identify the task type and enhancement needs, (2) selecting appropriate tools from the tool repository, and (3) generating enhanced task prompts based on the analysis and selected tools. To evaluate AerialVP, we introduce AerialSense, a comprehensive benchmark for UAV image perception that includes Aerial Visual Reasoning, Aerial Visual Question Answering, and Aerial Visual Grounding tasks. AerialSense provides a standardized basis for evaluating model generalization and performance across diverse resolutions, lighting conditions, and both urban and natural scenes. Experimental results demonstrate that AerialVP significantly enhances task prompt guidance, leading to stable and substantial performance improvements in both open-source and proprietary VLMs. Our work will be available at https://github.com/lostwolves/AerialVP.

</details>


### [237] [Reevaluating Automated Wildlife Species Detection: A Reproducibility Study on a Custom Image Dataset](https://arxiv.org/abs/2512.07305)
*Tobias Abraham Haider*

Main category: cs.CV

TL;DR: 重新评估预训练CNN模型在野生动物物种识别中的表现，使用不同数据集验证原研究的可重复性和泛化能力


<details>
  <summary>Details</summary>
Motivation: 验证Carl等人研究的可重复性和泛化性，评估预训练模型在不同野生动物数据集上的表现

Method: 使用开源资源从零开始重新实现实验，采用包含900张图像、90个物种的不同数据集，进行最小预处理

Result: 总体分类准确率达到62%，与原研究的71%相近；宏平均F1分数为0.28，显示不同类别间性能差异显著

Conclusion: 预训练CNN可作为野生动物物种识别的基础方法，但需要物种特定的适应或迁移学习才能获得一致的高质量预测

Abstract: This study revisits the findings of Carl et al., who evaluated the pre-trained Google Inception-ResNet-v2 model for automated detection of European wild mammal species in camera trap images. To assess the reproducibility and generalizability of their approach, we reimplemented the experiment from scratch using openly available resources and a different dataset consisting of 900 images spanning 90 species. After minimal preprocessing, we obtained an overall classification accuracy of 62%, closely aligning with the 71% reported in the original work despite differences in datasets. As in the original study, per-class performance varied substantially, as indicated by a macro F1 score of 0.28,highlighting limitations in generalization when labels do not align directly with ImageNet classes. Our results confirm that pretrained convolutional neural networks can provide a practical baseline for wildlife species identification but also reinforce the need for species-specific adaptation or transfer learning to achieve consistent, high-quality predictions.

</details>


### [238] [ContextAnyone: Context-Aware Diffusion for Character-Consistent Text-to-Video Generation](https://arxiv.org/abs/2512.07328)
*Ziyang Mai,Yu-Wing Tai*

Main category: cs.CV

TL;DR: ContextAnyone是一个上下文感知的扩散框架，通过单张参考图像实现角色一致性的文本到视频生成，解决了现有方法在保持发型、服装、体型等上下文特征方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成方法在保持角色一致性方面存在局限，通常只关注面部特征而忽略了发型、服装、体型等关键上下文线索，导致视觉连贯性不足。

Method: 提出上下文感知扩散框架，通过联合重建参考图像和生成新视频帧，使模型充分感知参考信息。采用Emphasize-Attention模块选择性增强参考感知特征，防止身份漂移；使用双引导损失结合扩散和参考重建目标；提出Gap-RoPE位置嵌入分离参考和视频token以稳定时序建模。

Result: 实验表明ContextAnyone在身份一致性和视觉质量方面优于现有参考到视频方法，能够生成跨多样动作和场景的连贯且保持上下文的角色视频。

Conclusion: ContextAnyone通过上下文感知的扩散框架有效解决了角色一致性的文本到视频生成问题，在保持角色身份和视觉连贯性方面取得了显著改进。

Abstract: Text-to-video (T2V) generation has advanced rapidly, yet maintaining consistent character identities across scenes remains a major challenge. Existing personalization methods often focus on facial identity but fail to preserve broader contextual cues such as hairstyle, outfit, and body shape, which are critical for visual coherence. We propose \textbf{ContextAnyone}, a context-aware diffusion framework that achieves character-consistent video generation from text and a single reference image. Our method jointly reconstructs the reference image and generates new video frames, enabling the model to fully perceive and utilize reference information. Reference information is effectively integrated into a DiT-based diffusion backbone through a novel Emphasize-Attention module that selectively reinforces reference-aware features and prevents identity drift across frames. A dual-guidance loss combines diffusion and reference reconstruction objectives to enhance appearance fidelity, while the proposed Gap-RoPE positional embedding separates reference and video tokens to stabilize temporal modeling. Experiments demonstrate that ContextAnyone outperforms existing reference-to-video methods in identity consistency and visual quality, generating coherent and context-preserving character videos across diverse motions and scenes. Project page: \href{https://github.com/ziyang1106/ContextAnyone}{https://github.com/ziyang1106/ContextAnyone}.

</details>


### [239] [The Inductive Bottleneck: Data-Driven Emergence of Representational Sparsity in Vision Transformers](https://arxiv.org/abs/2512.07331)
*Kanishk Awadhiya*

Main category: cs.CV

TL;DR: ViTs自發形成U形熵分佈，這不是架構缺陷而是數據依賴的適應性調整，瓶頸深度與任務語義抽象需求相關


<details>
  <summary>Details</summary>
Motivation: 研究ViTs為何會自發形成"U形"熵分佈（中間層壓縮信息後再擴展），探索這是否為架構缺陷還是數據依賴的適應性現象

Method: 通過分析DINO訓練的ViTs在不同複雜度數據集（UC Merced、Tiny ImageNet、CIFAR-100）上的層級有效編碼維度(EED)，研究瓶頸深度與語義抽象需求的關係

Result: 發現瓶頸深度與任務所需語義抽象強相關：紋理主導數據集保持高秩表示，而物體中心數據集驅動網絡在中間層抑制高頻信息，形成瓶頸來隔離語義特徵

Conclusion: ViTs的"歸納瓶頸"不是架構偽影，而是數據依賴的適應性調整，網絡根據數據語義複雜度自發學習壓縮策略來提取相關特徵

Abstract: Vision Transformers (ViTs) lack the hierarchical inductive biases inherent to Convolutional Neural Networks (CNNs), theoretically allowing them to maintain high-dimensional representations throughout all layers. However, recent observations suggest ViTs often spontaneously manifest a "U-shaped" entropy profile-compressing information in middle layers before expanding it for the final classification. In this work, we demonstrate that this "Inductive Bottleneck" is not an architectural artifact, but a data-dependent adaptation. By analyzing the layer-wise Effective Encoding Dimension (EED) of DINO-trained ViTs across datasets of varying compositional complexity (UC Merced, Tiny ImageNet, and CIFAR-100), we show that the depth of the bottleneck correlates strongly with the semantic abstraction required by the task. We find that while texture-heavy datasets preserve high-rank representations throughout, object-centric datasets drive the network to dampen high-frequency information in middle layers, effectively "learning" a bottleneck to isolate semantic features.

</details>


### [240] [Generalized Referring Expression Segmentation on Aerial Photos](https://arxiv.org/abs/2512.07338)
*Luís Marnoto,Alexandre Bernardino,Bruno Martins*

Main category: cs.CV

TL;DR: 提出了Aerial-D，一个用于航空影像的大规模指代表达分割数据集，包含37,288张图像和1,522,523个指代表达，覆盖259,709个标注目标，涵盖21个类别。通过自动流水线构建，结合规则生成和LLM增强，并模拟历史成像条件。使用RSRefSeg架构训练模型，在当代基准测试中表现竞争性，同时在历史航空摄影的退化条件下保持强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 航空影像的指代表达分割面临独特挑战：空间分辨率差异大、色彩使用不一致、目标像素少、场景物体密度高、部分遮挡。现有数据集不足以应对这些挑战，特别是对于历史航空影像的处理。

Method: 1) 构建Aerial-D数据集：通过自动流水线结合规则生成和LLM增强指代表达，增加语言多样性和视觉细节关注；2) 使用过滤器模拟历史成像条件；3) 采用RSRefSeg架构，在Aerial-D和先前航空数据集上联合训练，实现文本驱动的实例和语义分割。

Result: 联合训练在当代基准测试中达到竞争性性能，同时在单色、棕褐色和颗粒状退化条件下（历史航空摄影常见）保持强准确性。数据集、训练模型和完整软件流水线已公开。

Conclusion: Aerial-D数据集和训练模型为航空影像的指代表达分割提供了全面解决方案，特别针对历史航空摄影的挑战，推动了该领域的发展。

Abstract: Referring expression segmentation is a fundamental task in computer vision that integrates natural language understanding with precise visual localization of target regions. Considering aerial imagery (e.g., modern aerial photos collected through drones, historical photos from aerial archives, high-resolution satellite imagery, etc.) presents unique challenges because spatial resolution varies widely across datasets, the use of color is not consistent, targets often shrink to only a few pixels, and scenes contain very high object densities and objects with partial occlusions. This work presents Aerial-D, a new large-scale referring expression segmentation dataset for aerial imagery, comprising 37,288 images with 1,522,523 referring expressions that cover 259,709 annotated targets, spanning across individual object instances, groups of instances, and semantic regions covering 21 distinct classes that range from vehicles and infrastructure to land coverage types. The dataset was constructed through a fully automatic pipeline that combines systematic rule-based expression generation with a Large Language Model (LLM) enhancement procedure that enriched both the linguistic variety and the focus on visual details within the referring expressions. Filters were additionally used to simulate historic imaging conditions for each scene. We adopted the RSRefSeg architecture, and trained models on Aerial-D together with prior aerial datasets, yielding unified instance and semantic segmentation from text for both modern and historical images. Results show that the combined training achieves competitive performance on contemporary benchmarks, while maintaining strong accuracy under monochrome, sepia, and grainy degradations that appear in archival aerial photography. The dataset, trained models, and complete software pipeline are publicly available at https://luispl77.github.io/aerial-d .

</details>


### [241] [Debiasing Diffusion Priors via 3D Attention for Consistent Gaussian Splatting](https://arxiv.org/abs/2512.07345)
*Shilong Jin,Haoran Duan,Litao Hua,Wentao Huang,Yuan Zhou*

Main category: cs.CV

TL;DR: TD-Attn通过3D感知注意力引导和分层注意力调制解决T2I模型中的先验视角偏差，提升3D任务的多视角一致性


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型在3D任务中存在先验视角偏差，导致不同视角下物体外观冲突，限制了3D生成和编辑的质量

Method: 提出TD-Attn框架，包含两个核心组件：1) 3D感知注意力引导模块构建视角一致的3D注意力高斯分布；2) 分层注意力调制模块通过语义引导树和语义响应分析器定位并调制对视角条件敏感的交叉注意力层

Result: 实验证明TD-Attn能显著提升多视角一致性，可作为通用插件增强各种3D任务

Conclusion: TD-Attn通过数学分析揭示了T2I模型先验视角偏差的根源，并提出有效解决方案，为3D任务提供了可靠的通用增强工具

Abstract: Versatile 3D tasks (e.g., generation or editing) that distill from Text-to-Image (T2I) diffusion models have attracted significant research interest for not relying on extensive 3D training data. However, T2I models exhibit limitations resulting from prior view bias, which produces conflicting appearances between different views of an object. This bias causes subject-words to preferentially activate prior view features during cross-attention (CA) computation, regardless of the target view condition. To overcome this limitation, we conduct a comprehensive mathematical analysis to reveal the root cause of the prior view bias in T2I models. Moreover, we find different UNet layers show different effects of prior view in CA. Therefore, we propose a novel framework, TD-Attn, which addresses multi-view inconsistency via two key components: (1) the 3D-Aware Attention Guidance Module (3D-AAG) constructs a view-consistent 3D attention Gaussian for subject-words to enforce spatial consistency across attention-focused regions, thereby compensating for the limited spatial information in 2D individual view CA maps; (2) the Hierarchical Attention Modulation Module (HAM) utilizes a Semantic Guidance Tree (SGT) to direct the Semantic Response Profiler (SRP) in localizing and modulating CA layers that are highly responsive to view conditions, where the enhanced CA maps further support the construction of more consistent 3D attention Gaussians. Notably, HAM facilitates semantic-specific interventions, enabling controllable and precise 3D editing. Extensive experiments firmly establish that TD-Attn has the potential to serve as a universal plugin, significantly enhancing multi-view consistency across 3D tasks.

</details>


### [242] [MICo-150K: A Comprehensive Dataset Advancing Multi-Image Composition](https://arxiv.org/abs/2512.07348)
*Xinyu Wei,Kangrui Cen,Hongyang Wei,Zhen Guo,Bairui Li,Zeqing Wang,Jinrui Zhang,Lei Zhang*

Main category: cs.CV

TL;DR: 论文提出了MICo-150K数据集、MICo-Bench基准和Qwen-MICo基线模型，用于解决多图像合成（MICo）任务中高质量训练数据缺乏的问题。


<details>
  <summary>Details</summary>
Motivation: 多图像合成（MICo）任务面临高质量训练数据缺乏的挑战，阻碍了模型从多个参考输入合成一致图像的能力发展。

Method: 1. 将MICo系统分类为7个代表性任务；2. 构建MICo-150K数据集（包含人工筛选的合成图像和De&Re子集）；3. 创建MICo-Bench评估基准和Weighted-Ref-VIEScore指标；4. 在MICo-150K上微调多个模型。

Result: MICo-150K能有效提升模型的MICo能力，基线模型Qwen-MICo在3图像合成上匹配Qwen-Image-2509，且支持任意多图像输入，超越了后者的限制。

Conclusion: 论文提供了多图像合成研究的有价值资源，包括数据集、基准和基线模型，为MICo任务的进一步发展奠定了基础。

Abstract: In controllable image generation, synthesizing coherent and consistent images from multiple reference inputs, i.e., Multi-Image Composition (MICo), remains a challenging problem, partly hindered by the lack of high-quality training data. To bridge this gap, we conduct a systematic study of MICo, categorizing it into 7 representative tasks and curate a large-scale collection of high-quality source images and construct diverse MICo prompts. Leveraging powerful proprietary models, we synthesize a rich amount of balanced composite images, followed by human-in-the-loop filtering and refinement, resulting in MICo-150K, a comprehensive dataset for MICo with identity consistency. We further build a Decomposition-and-Recomposition (De&Re) subset, where 11K real-world complex images are decomposed into components and recomposed, enabling both real and synthetic compositions. To enable comprehensive evaluation, we construct MICo-Bench with 100 cases per task and 300 challenging De&Re cases, and further introduce a new metric, Weighted-Ref-VIEScore, specifically tailored for MICo evaluation. Finally, we fine-tune multiple models on MICo-150K and evaluate them on MICo-Bench. The results show that MICo-150K effectively equips models without MICo capability and further enhances those with existing skills. Notably, our baseline model, Qwen-MICo, fine-tuned from Qwen-Image-Edit, matches Qwen-Image-2509 in 3-image composition while supporting arbitrary multi-image inputs beyond the latter's limitation. Our dataset, benchmark, and baseline collectively offer valuable resources for further research on Multi-Image Composition.

</details>


### [243] [DeepAgent: A Dual Stream Multi Agent Fusion for Robust Multimodal Deepfake Detection](https://arxiv.org/abs/2512.07351)
*Sayeem Been Zaman,Wasimul Karim,Arefin Ittesafun Abian,Reem E. Mohamed,Md Rafiqul Islam,Asif Karim,Sami Azam*

Main category: cs.CV

TL;DR: DeepAgent：基于多智能体协作的深度伪造检测框架，通过视觉和音频双模态分析，结合随机森林元分类器提升检测性能


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法通常将视听信息集成在单一模型中，容易受到模态不匹配、噪声和操纵的影响。需要更鲁棒的框架来应对多样化的深度伪造攻击。

Method: 提出DeepAgent多智能体协作框架：Agent-1使用AlexNet-based CNN检测视觉伪造痕迹；Agent-2结合声学特征、Whisper音频转录和EasyOCR图像序列分析检测视听不一致性；最后通过随机森林元分类器融合两个智能体的决策。

Result: 在多个基准数据集上验证：Agent-1在Celeb-DF和FakeAVCeleb数据集上达到94.35%准确率；Agent-2在FakeAVCeleb上达到93.69%；元分类器在FakeAVCeleb上81.56%，在DeepFakeTIMIT跨数据集验证中达到97.49%准确率。

Conclusion: 基于层次融合的多智能体方法能够缓解单模态弱点，增强鲁棒性，有效应对多样化的深度伪造操纵类型，证明了多智能体协作框架在深度伪造检测中的有效性。

Abstract: The increasing use of synthetic media, particularly deepfakes, is an emerging challenge for digital content verification. Although recent studies use both audio and visual information, most integrate these cues within a single model, which remains vulnerable to modality mismatches, noise, and manipulation. To address this gap, we propose DeepAgent, an advanced multi-agent collaboration framework that simultaneously incorporates both visual and audio modalities for the effective detection of deepfakes. DeepAgent consists of two complementary agents. Agent-1 examines each video with a streamlined AlexNet-based CNN to identify the symbols of deepfake manipulation, while Agent-2 detects audio-visual inconsistencies by combining acoustic features, audio transcriptions from Whisper, and frame-reading sequences of images through EasyOCR. Their decisions are fused through a Random Forest meta-classifier that improves final performance by taking advantage of the different decision boundaries learned by each agent. This study evaluates the proposed framework using three benchmark datasets to demonstrate both component-level and fused performance. Agent-1 achieves a test accuracy of 94.35% on the combined Celeb-DF and FakeAVCeleb datasets. On the FakeAVCeleb dataset, Agent-2 and the final meta-classifier attain accuracies of 93.69% and 81.56%, respectively. In addition, cross-dataset validation on DeepFakeTIMIT confirms the robustness of the meta-classifier, which achieves a final accuracy of 97.49%, and indicates a strong capability across diverse datasets. These findings confirm that hierarchy-based fusion enhances robustness by mitigating the weaknesses of individual modalities and demonstrate the effectiveness of a multi-agent approach in addressing diverse types of manipulations in deepfakes.

</details>


### [244] [Structure-Aware Feature Rectification with Region Adjacency Graphs for Training-Free Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2512.07360)
*Qiming Huang,Hao Ai,Jianbo Jiao*

Main category: cs.CV

TL;DR: 提出一种结构感知的特征校正方法，通过构建区域邻接图来利用图像的低级特征，以增强CLIP特征的局部判别能力，改善开放词汇语义分割中的噪声和不一致问题。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在图像-文本对预训练中主要关注全局语义对齐，导致在细粒度视觉区域与文本关联时表现不佳，产生噪声和不一致的预测，特别是在局部区域。这源于对比训练范式带来的分散偏差，仅使用CLIP特征难以缓解。

Method: 提出结构感知的特征校正方法：1）基于低级特征（颜色、纹理等）构建区域邻接图（RAG）来捕捉局部结构关系；2）利用该图来细化CLIP特征，增强局部判别能力；3）直接从图像中获取实例特定的先验信息。

Result: 在多个开放词汇分割基准测试中，该方法有效抑制了分割噪声，提高了区域级一致性，并实现了强大的性能表现。

Conclusion: 通过引入基于低级特征的结构先验来校正CLIP特征，能够有效解决开放词汇语义分割中的局部不一致问题，提升分割质量。

Abstract: Benefiting from the inductive biases learned from large-scale datasets, open-vocabulary semantic segmentation (OVSS) leverages the power of vision-language models, such as CLIP, to achieve remarkable progress without requiring task-specific training. However, due to CLIP's pre-training nature on image-text pairs, it tends to focus on global semantic alignment, resulting in suboptimal performance when associating fine-grained visual regions with text. This leads to noisy and inconsistent predictions, particularly in local areas. We attribute this to a dispersed bias stemming from its contrastive training paradigm, which is difficult to alleviate using CLIP features alone. To address this, we propose a structure-aware feature rectification approach that incorporates instance-specific priors derived directly from the image. Specifically, we construct a region adjacency graph (RAG) based on low-level features (e.g., colour and texture) to capture local structural relationships and use it to refine CLIP features by enhancing local discrimination. Extensive experiments show that our method effectively suppresses segmentation noise, improves region-level consistency, and achieves strong performance on multiple open-vocabulary segmentation benchmarks.

</details>


### [245] [Enhancing Small Object Detection with YOLO: A Novel Framework for Improved Accuracy and Efficiency](https://arxiv.org/abs/2512.07379)
*Mahila Moghadami,Mohammad Ali Keyvanrad,Melika Sabaghian*

Main category: cs.CV

TL;DR: 本文提出了一种改进的SW-YOLO方法，通过优化滑动窗口裁剪策略和网络架构增强，显著提升了大尺度航拍图像中小目标检测的精度。


<details>
  <summary>Details</summary>
Motivation: 随着航拍图像在关键工业和实际应用中的重要性日益增长，需要开发鲁棒的小目标检测框架。现有方法通常采用图像裁剪和网络架构修改，但仍有改进空间。

Method: 基于SW-YOLO方法，优化滑动窗口的裁剪尺寸和重叠策略，并在网络架构中引入改进：在骨干网络中集成CBAM注意力机制以保留空间和通道信息，在颈部添加高级特征提取模块增强特征图，并设计新的检测头提升小目标检测精度。

Result: 在VisDrone2019数据集上，提出的模型将mAP .5:.5精度从YOLOv5L的35.5提升到61.2，显著优于SAHI和CZDet（58.36）等现有方法。

Conclusion: 通过优化滑动窗口策略和网络架构增强，本文提出的方法在大尺度航拍图像小目标检测任务上取得了显著精度提升，证明了该框架的有效性。

Abstract: This paper investigates and develops methods for detecting small objects in large-scale aerial images. Current approaches for detecting small objects in aerial images often involve image cropping and modifications to detector network architectures. Techniques such as sliding window cropping and architectural enhancements, including higher-resolution feature maps and attention mechanisms, are commonly employed. Given the growing importance of aerial imagery in various critical and industrial applications, the need for robust frameworks for small object detection becomes imperative. To address this need, we adopted the base SW-YOLO approach to enhance speed and accuracy in small object detection by refining cropping dimensions and overlap in sliding window usage and subsequently enhanced it through architectural modifications. we propose a novel model by modifying the base model architecture, including advanced feature extraction modules in the neck for feature map enhancement, integrating CBAM in the backbone to preserve spatial and channel information, and introducing a new head to boost small object detection accuracy. Finally, we compared our method with SAHI, one of the most powerful frameworks for processing large-scale images, and CZDet, which is also based on image cropping, achieving significant improvements in accuracy. The proposed model achieves significant accuracy gains on the VisDrone2019 dataset, outperforming baseline YOLOv5L detection by a substantial margin. Specifically, the final proposed model elevates the mAP .5.5 accuracy on the VisDrone2019 dataset from the base accuracy of 35.5 achieved by the YOLOv5L detector to 61.2. Notably, the accuracy of CZDet, which is another classic method applied to this dataset, is 58.36. This research demonstrates a significant improvement, achieving an increase in accuracy from 35.5 to 61.2.

</details>


### [246] [Tessellation GS: Neural Mesh Gaussians for Robust Monocular Reconstruction of Dynamic Objects](https://arxiv.org/abs/2512.07381)
*Shuohan Tao,Boyao Zhou,Hanzhang Tu,Yuwang Wang,Yebin Liu*

Main category: cs.CV

TL;DR: 提出Tessellation GS方法，通过将2D高斯约束在网格面上，结合分层神经特征和自适应细分策略，显著改善了3D高斯泼溅在动态场景重建中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅(3D GS)在姿态图像序列重建中能产生高度逼真的场景，但在视角外推方面存在困难，特别是在稀疏视图和动态场景重建中容易过拟合、泛化能力差。

Method: 提出Tessellation GS方法：1) 将2D高斯约束在网格面上；2) 通过网格面上的分层神经特征推断高斯属性；3) 使用细节感知损失函数驱动的自适应面细分策略指导高斯细分；4) 利用重建基础模型的先验初始化高斯变形。

Result: 方法显著优于先前SOTA方法，在表观和网格重建任务上，LPIPS降低了29.1%，Chamfer距离降低了49.2%。能够从单个静态相机重建一般动态物体，这在基于优化的方法中以前极具挑战性。

Conclusion: Tessellation GS通过结构化约束和自适应细分策略，有效解决了3D高斯泼溅在动态场景重建中的泛化问题，实现了从单个相机对动态场景的高质量重建。

Abstract: 3D Gaussian Splatting (GS) enables highly photorealistic scene reconstruction from posed image sequences but struggles with viewpoint extrapolation due to its anisotropic nature, leading to overfitting and poor generalization, particularly in sparse-view and dynamic scene reconstruction. We propose Tessellation GS, a structured 2D GS approach anchored on mesh faces, to reconstruct dynamic scenes from a single continuously moving or static camera. Our method constrains 2D Gaussians to localized regions and infers their attributes via hierarchical neural features on mesh faces. Gaussian subdivision is guided by an adaptive face subdivision strategy driven by a detail-aware loss function. Additionally, we leverage priors from a reconstruction foundation model to initialize Gaussian deformations, enabling robust reconstruction of general dynamic objects from a single static camera, previously extremely challenging for optimization-based methods. Our method outperforms previous SOTA method, reducing LPIPS by 29.1% and Chamfer distance by 49.2% on appearance and mesh reconstruction tasks.

</details>


### [247] [LogicCBMs: Logic-Enhanced Concept-Based Learning](https://arxiv.org/abs/2512.07383)
*Deepika SN Vemuri,Gautham Bellamkonda,Aditya Pola,Vineeth N Balasubramanian*

Main category: cs.CV

TL;DR: 论文提出LogicCBM，在概念瓶颈模型基础上引入可微分逻辑模块，通过逻辑运算组合概念，提升模型表达能力和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统概念瓶颈模型仅通过线性组合概念进行预测，表达能力有限。需要更强大的概念组合方式来捕捉概念间关系，提升模型性能。

Method: 在概念瓶颈模型基础上引入可微分逻辑模块，使用逻辑运算符（如与、或、非等）连接学习到的概念，保持端到端可学习性。

Result: 在知名基准测试和合成数据集上，LogicCBM展现出更好的准确性、有效的干预能力和高度可解释性。

Conclusion: 通过逻辑运算增强概念瓶颈模型，能够超越简单的加权概念组合，捕捉概念间关系，提高模型表达能力和性能。

Abstract: Concept Bottleneck Models (CBMs) provide a basis for semantic abstractions within a neural network architecture. Such models have primarily been seen through the lens of interpretability so far, wherein they offer transparency by inferring predictions as a linear combination of semantic concepts. However, a linear combination is inherently limiting. So we propose the enhancement of concept-based learning models through propositional logic. We introduce a logic module that is carefully designed to connect the learned concepts from CBMs through differentiable logic operations, such that our proposed LogicCBM can go beyond simple weighted combinations of concepts to leverage various logical operations to yield the final predictions, while maintaining end-to-end learnability. Composing concepts using a set of logic operators enables the model to capture inter-concept relations, while simultaneously improving the expressivity of the model in terms of logic operations. Our empirical studies on well-known benchmarks and synthetic datasets demonstrate that these models have better accuracy, perform effective interventions and are highly interpretable.

</details>


### [248] [How Far are Modern Trackers from UAV-Anti-UAV? A Million-Scale Benchmark and New Baseline](https://arxiv.org/abs/2512.07385)
*Chunhui Zhang,Li Liu,Zhipeng Zhang,Yong Wang,Hao Wen,Xi Zhou,Shiming Ge,Yanfeng Wang*

Main category: cs.CV

TL;DR: 提出新的无人机反无人机视觉跟踪任务(UAV-Anti-UAV)，构建百万级数据集，并提出基于Mamba的基线方法MambaSTS


<details>
  <summary>Details</summary>
Motivation: 当前反无人机研究主要关注固定地面摄像头采集的RGB/红外视频，缺乏从移动无人机平台跟踪目标无人机的研究，需要填补这一空白

Method: 提出MambaSTS方法，结合Mamba和Transformer分别学习全局语义和空间特征，利用状态空间模型的长序列建模能力，通过时间令牌传播机制建立视频级长期上下文

Result: 构建了包含1,810个视频的百万级数据集，实验验证MambaSTS方法的有效性，对50种现代深度跟踪算法的评估表明该领域仍有很大改进空间

Conclusion: UAV-Anti-UAV是一个具有挑战性的新任务，提出的数据集和基线方法为该领域研究提供了基础，未来有显著改进空间

Abstract: Unmanned Aerial Vehicles (UAVs) offer wide-ranging applications but also pose significant safety and privacy violation risks in areas like airport and infrastructure inspection, spurring the rapid development of Anti-UAV technologies in recent years. However, current Anti-UAV research primarily focuses on RGB, infrared (IR), or RGB-IR videos captured by fixed ground cameras, with little attention to tracking target UAVs from another moving UAV platform. To fill this gap, we propose a new multi-modal visual tracking task termed UAV-Anti-UAV, which involves a pursuer UAV tracking a target adversarial UAV in the video stream. Compared to existing Anti-UAV tasks, UAV-Anti-UAV is more challenging due to severe dual-dynamic disturbances caused by the rapid motion of both the capturing platform and the target. To advance research in this domain, we construct a million-scale dataset consisting of 1,810 videos, each manually annotated with bounding boxes, a language prompt, and 15 tracking attributes. Furthermore, we propose MambaSTS, a Mamba-based baseline method for UAV-Anti-UAV tracking, which enables integrated spatial-temporal-semantic learning. Specifically, we employ Mamba and Transformer models to learn global semantic and spatial features, respectively, and leverage the state space model's strength in long-sequence modeling to establish video-level long-term context via a temporal token propagation mechanism. We conduct experiments on the UAV-Anti-UAV dataset to validate the effectiveness of our method. A thorough experimental evaluation of 50 modern deep tracking algorithms demonstrates that there is still significant room for improvement in the UAV-Anti-UAV domain. The dataset and codes will be available at {\color{magenta}https://github.com/983632847/Awesome-Multimodal-Object-Tracking}.

</details>


### [249] [GlimmerNet: A Lightweight Grouped Dilated Depthwise Convolutions for UAV-Based Emergency Monitoring](https://arxiv.org/abs/2512.07391)
*Đorđe Nedeljković*

Main category: cs.CV

TL;DR: GlimmerNet：一种超轻量级卷积网络，通过分组扩张深度卷积实现多尺度特征提取，无需额外参数，在无人机紧急监测任务中达到新的精度-效率平衡前沿。


<details>
  <summary>Details</summary>
Motivation: 虽然CNN在边缘和移动视觉任务中计算效率高，但现有方法试图通过自注意力机制增强全局上下文理解时引入了显著计算开销。本文旨在保留强大全局感知能力的同时避免依赖计算昂贵的组件。

Method: 提出GlimmerNet，基于"将感受野多样性与特征重组分离"的原则。引入分组扩张深度卷积(GDBlocks)，将通道划分为具有不同扩张率的组，实现无额外参数的多尺度特征提取。设计新颖的聚合器模块，使用分组逐点卷积重组跨组表示，显著降低参数开销。

Result: 仅31K参数，比最新基线减少29% FLOPs，在无人机聚焦的AIDERv2数据集上达到新的最先进加权F1分数0.966。

Conclusion: 为资源受限的无人机平台上的实时紧急监测建立了新的精度-效率平衡前沿，证明了无需计算昂贵组件也能保持强大全局感知能力。

Abstract: Convolutional Neural Networks (CNNs) have proven highly effective for edge and mobile vision tasks due to their computational efficiency. While many recent works seek to enhance CNNs with global contextual understanding via self-attention-based Vision Transformers, these approaches often introduce significant computational overhead. In this work, we demonstrate that it is possible to retain strong global perception without relying on computationally expensive components. We present GlimmerNet, an ultra-lightweight convolutional network built on the principle of separating receptive field diversity from feature recombination. GlimmerNet introduces Grouped Dilated Depthwise Convolutions(GDBlocks), which partition channels into groups with distinct dilation rates, enabling multi-scale feature extraction at no additional parameter cost. To fuse these features efficiently, we design a novel Aggregator module that recombines cross-group representations using grouped pointwise convolution, significantly lowering parameter overhead. With just 31K parameters and 29% fewer FLOPs than the most recent baseline, GlimmerNet achieves a new state-of-the-art weighted F1-score of 0.966 on the UAV-focused AIDERv2 dataset. These results establish a new accuracy-efficiency trade-off frontier for real-time emergency monitoring on resource-constrained UAV platforms. Our implementation is publicly available at https://github.com/djordjened92/gdd-cnn.

</details>


### [250] [Reconstructing Objects along Hand Interaction Timelines in Egocentric Video](https://arxiv.org/abs/2512.07394)
*Zhifan Zhu,Siddhant Bansal,Shashank Tripathi,Dima Damen*

Main category: cs.CV

TL;DR: 提出ROHIT任务，通过手交互时间线(HIT)建模物体姿态约束，利用约束优化传播(COP)框架提升物体重建质量


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏对物体在手交互过程中姿态变化的系统性建模，特别是在稳定抓握场景下，需要一种无需3D真值就能评估重建质量的方法

Method: 定义手交互时间线(HIT)，建模物体从静态到被抓握、使用、再到释放的完整姿态变化过程；提出约束优化传播(COP)框架，利用HIT中的姿态约束传播物体姿态信息

Result: 在两个第一人称数据集(HOT3D和EPIC-Kitchens)上验证，COP框架将稳定抓握重建提升6.2-11.3%，HIT重建提升达24.5%

Conclusion: ROHIT任务和COP框架能有效利用手交互过程中的姿态约束，显著提升物体重建质量，为无3D真值的视频物体重建提供了新方法

Abstract: We introduce the task of Reconstructing Objects along Hand Interaction Timelines (ROHIT). We first define the Hand Interaction Timeline (HIT) from a rigid object's perspective. In a HIT, an object is first static relative to the scene, then is held in hand following contact, where its pose changes. This is usually followed by a firm grip during use, before it is released to be static again w.r.t. to the scene. We model these pose constraints over the HIT, and propose to propagate the object's pose along the HIT enabling superior reconstruction using our proposed Constrained Optimisation and Propagation (COP) framework. Importantly, we focus on timelines with stable grasps - i.e. where the hand is stably holding an object, effectively maintaining constant contact during use. This allows us to efficiently annotate, study, and evaluate object reconstruction in videos without 3D ground truth. We evaluate our proposed task, ROHIT, over two egocentric datasets, HOT3D and in-the-wild EPIC-Kitchens. In HOT3D, we curate 1.2K clips of stable grasps. In EPIC-Kitchens, we annotate 2.4K clips of stable grasps including 390 object instances across 9 categories from videos of daily interactions in 141 environments. Without 3D ground truth, we utilise 2D projection error to assess the reconstruction. Quantitatively, COP improves stable grasp reconstruction by 6.2-11.3% and HIT reconstruction by up to 24.5% with constrained pose propagation.

</details>


### [251] [InterAgent: Physics-based Multi-agent Command Execution via Diffusion on Interaction Graphs](https://arxiv.org/abs/2512.07410)
*Bin Li,Ruichi Zhang,Han Liang,Jingyan Zhang,Juze Zhang,Xin Chen,Lan Xu,Jingyi Yu,Jingya Wang*

Main category: cs.CV

TL;DR: InterAgent：首个端到端文本驱动的物理多智能体人形控制框架，通过自回归扩散变换器和交互图外感受表示实现多智能体协调


<details>
  <summary>Details</summary>
Motivation: 现有方法主要局限于单智能体场景，忽略了多智能体交互中必需的物理合理相互作用，需要开发能够模拟人类社交行为复杂协调的多智能体控制框架

Method: 1）提出自回归扩散变换器，配备多流块解耦本体感受、外感受和动作以避免跨模态干扰；2）引入交互图外感受表示，显式捕捉细粒度关节间空间依赖；3）设计稀疏边注意力机制，动态剪枝冗余连接并强调关键智能体间空间关系

Result: 在广泛实验中，InterAgent持续优于多个强基线，达到最先进性能，能够仅从文本提示生成连贯、物理合理且语义忠实的多智能体行为

Conclusion: InterAgent是首个端到端文本驱动的物理多智能体人形控制框架，通过创新的架构设计实现了多智能体协调，为未来研究提供了基础

Abstract: Humanoid agents are expected to emulate the complex coordination inherent in human social behaviors. However, existing methods are largely confined to single-agent scenarios, overlooking the physically plausible interplay essential for multi-agent interactions. To bridge this gap, we propose InterAgent, the first end-to-end framework for text-driven physics-based multi-agent humanoid control. At its core, we introduce an autoregressive diffusion transformer equipped with multi-stream blocks, which decouples proprioception, exteroception, and action to mitigate cross-modal interference while enabling synergistic coordination. We further propose a novel interaction graph exteroception representation that explicitly captures fine-grained joint-to-joint spatial dependencies to facilitate network learning. Additionally, within it we devise a sparse edge-based attention mechanism that dynamically prunes redundant connections and emphasizes critical inter-agent spatial relations, thereby enhancing the robustness of interaction modeling. Extensive experiments demonstrate that InterAgent consistently outperforms multiple strong baselines, achieving state-of-the-art performance. It enables producing coherent, physically plausible, and semantically faithful multi-agent behaviors from only text prompts. Our code and data will be released to facilitate future research.

</details>


### [252] [Data-driven Exploration of Mobility Interaction Patterns](https://arxiv.org/abs/2512.07415)
*Gabriele Galatolo,Mirco Nanni*

Main category: cs.CV

TL;DR: 提出一种从数据出发的数据挖掘方法，用于发现个体间移动行为的相互影响模式，以改进人群模拟模型


<details>
  <summary>Details</summary>
Motivation: 现有解决方案通常基于预设的行为模型，但需要更直接地从数据中捕捉个体间相互影响的方法，这对人群模拟和应急管理至关重要

Method: 采用数据挖掘视角，从数据中搜索可能反映个体间相互作用的移动事件，并在此基础上寻找复杂、持久的事件模式和随时间演化的配置

Result: 在两个真实案例研究（汽车和行人）上进行了完整的实验评估，包括性能、参数敏感性和样本结果解释

Conclusion: 该方法能够提供关于个体间移动交互机制的新见解，有助于改进现有的模拟模型

Abstract: Understanding the movement behaviours of individuals and the way they react to the external world is a key component of any problem that involves the modelling of human dynamics at a physical level. In particular, it is crucial to capture the influence that the presence of an individual can have on the others. Important examples of applications include crowd simulation and emergency management, where the simulation of the mass of people passes through the simulation of the individuals, taking into consideration the others as part of the general context. While existing solutions basically start from some preconceived behavioural model, in this work we propose an approach that starts directly from the data, adopting a data mining perspective. Our method searches the mobility events in the data that might be possible evidences of mutual interactions between individuals, and on top of them looks for complex, persistent patterns and time evolving configurations of events. The study of these patterns can provide new insights on the mechanics of mobility interactions between individuals, which can potentially help in improving existing simulation models. We instantiate the general methodology on two real case studies, one on cars and one on pedestrians, and a full experimental evaluation is performed, both in terms of performances, parameter sensitivity and interpretation of sample results.

</details>


### [253] [When normalization hallucinates: unseen risks in AI-powered whole slide image processing](https://arxiv.org/abs/2512.07426)
*Karel Moens,Matthew B. Blaschko,Tinne Tuytelaars,Bart Diricx,Jonas De Vylder,Mustafa Yousif*

Main category: cs.CV

TL;DR: WSI归一化模型在真实临床数据上会产生难以察觉的幻觉伪影，现有评估方法无法检测，本文提出新指标揭示这一问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的全切片图像归一化方法倾向于输出平均化结果，可能掩盖诊断特征，更严重的是会产生看似真实但实际不存在的幻觉内容，这对下游分析构成严重威胁。这些幻觉在视觉上几乎无法检测，现有评估方法往往忽视这一问题。

Method: 提出一种新颖的图像比较度量方法，专门用于自动检测归一化输出中的幻觉伪影。使用该度量系统评估多个在真实世界临床数据上重新训练的知名归一化方法。

Result: 在真实临床数据上重新训练的模型显示出令人担忧的幻觉频率，而传统指标未能捕捉到这些严重的不一致性和失败情况。新提出的度量方法成功揭示了这些被忽视的问题。

Conclusion: 研究结果强调需要开发更鲁棒、可解释的归一化技术，并在临床部署中采用更严格的验证协议，以应对幻觉伪影带来的风险。

Abstract: Whole slide image (WSI) normalization remains a vital preprocessing step in computational pathology. Increasingly driven by deep learning, these models learn to approximate data distributions from training examples. This often results in outputs that gravitate toward the average, potentially masking diagnostically important features. More critically, they can introduce hallucinated content, artifacts that appear realistic but are not present in the original tissue, posing a serious threat to downstream analysis. These hallucinations are nearly impossible to detect visually, and current evaluation practices often overlook them. In this work, we demonstrate that the risk of hallucinations is real and underappreciated. While many methods perform adequately on public datasets, we observe a concerning frequency of hallucinations when these same models are retrained and evaluated on real-world clinical data. To address this, we propose a novel image comparison measure designed to automatically detect hallucinations in normalized outputs. Using this measure, we systematically evaluate several well-cited normalization methods retrained on real-world data, revealing significant inconsistencies and failures that are not captured by conventional metrics. Our findings underscore the need for more robust, interpretable normalization techniques and stricter validation protocols in clinical deployment.

</details>


### [254] [Unified Video Editing with Temporal Reasoner](https://arxiv.org/abs/2512.07469)
*Xiangpeng Yang,Ji Xie,Yiyuan Yang,Yan Huang,Min Xu,Qiang Wu*

Main category: cs.CV

TL;DR: VideoCoF提出了一种新的视频编辑框架，通过类似思维链的"帧链"方法，让视频扩散模型先预测编辑区域潜在表示，再进行视频生成，无需用户提供掩码即可实现精确的指令到区域对齐。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法面临关键权衡：专家模型精确但依赖任务特定先验（如掩码），难以统一；而统一的时序上下文学习模型无需掩码但缺乏显式空间线索，导致指令到区域映射不精确。需要解决这一冲突。

Method: 提出VideoCoF（Chain-of-Frames）方法，强制视频扩散模型遵循"观察、推理、编辑"流程：先预测推理标记（编辑区域潜在表示），再生成目标视频标记。同时引入RoPE对齐策略，利用推理标记确保运动对齐并支持超出训练时长的长度外推。

Result: 仅使用5万个视频对的最小数据成本，VideoCoF在VideoCoF-Bench上实现了最先进的性能，验证了方法的效率和有效性。

Conclusion: VideoCoF通过显式推理步骤解决了视频编辑中精确性与统一性的权衡问题，无需用户提供掩码即可实现精确的指令到区域对齐和细粒度视频编辑，同时支持运动对齐和长度外推。

Abstract: Existing video editing methods face a critical trade-off: expert models offer precision but rely on task-specific priors like masks, hindering unification; conversely, unified temporal in-context learning models are mask-free but lack explicit spatial cues, leading to weak instruction-to-region mapping and imprecise localization. To resolve this conflict, we propose VideoCoF, a novel Chain-of-Frames approach inspired by Chain-of-Thought reasoning. VideoCoF enforces a ``see, reason, then edit" procedure by compelling the video diffusion model to first predict reasoning tokens (edit-region latents) before generating the target video tokens. This explicit reasoning step removes the need for user-provided masks while achieving precise instruction-to-region alignment and fine-grained video editing. Furthermore, we introduce a RoPE alignment strategy that leverages these reasoning tokens to ensure motion alignment and enable length extrapolation beyond the training duration. We demonstrate that with a minimal data cost of only 50k video pairs, VideoCoF achieves state-of-the-art performance on VideoCoF-Bench, validating the efficiency and effectiveness of our approach. Our code, weight, data are available at https://github.com/knightyxp/VideoCoF.

</details>


### [255] [Single-step Diffusion-based Video Coding with Semantic-Temporal Guidance](https://arxiv.org/abs/2512.07480)
*Naifu Xue,Zhaoyang Jia,Jiahao Li,Bin Li,Zihan Zheng,Yuan Zhang,Yan Lu*

Main category: cs.CV

TL;DR: S2VC是一个基于单步扩散的视频编解码器，通过条件编码框架和高效的单步扩散生成器，在低码率下实现高质量重建，同时大幅降低采样复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统和神经视频编解码器在低码率下的感知质量仍有不足，现有方法要么存在伪影问题，要么依赖复杂的扩散模型采样过程，计算成本高。需要一种既能提高感知质量又能降低计算复杂度的解决方案。

Method: 1) 提出S2VC单步扩散视频编解码器，结合条件编码框架和高效单步扩散生成器；2) 引入上下文语义指导，从缓冲特征中提取帧自适应语义，替代文本描述；3) 加入时间一致性指导，在扩散U-Net中强制帧间时序一致性。

Result: S2VC在感知质量上达到最先进水平，相比之前的感知方法平均节省52.73%的码率，证明了单步扩散在高效高质量视频压缩中的潜力。

Conclusion: 单步扩散模型能够有效平衡视频压缩的感知质量和计算效率，通过语义指导和时序一致性机制，在低码率下实现高质量重建，为高效视频压缩提供了有前景的方向。

Abstract: While traditional and neural video codecs (NVCs) have achieved remarkable rate-distortion performance, improving perceptual quality at low bitrates remains challenging. Some NVCs incorporate perceptual or adversarial objectives but still suffer from artifacts due to limited generation capacity, whereas others leverage pretrained diffusion models to improve quality at the cost of heavy sampling complexity. To overcome these challenges, we propose S2VC, a Single-Step diffusion based Video Codec that integrates a conditional coding framework with an efficient single-step diffusion generator, enabling realistic reconstruction at low bitrates with reduced sampling cost. Recognizing the importance of semantic conditioning in single-step diffusion, we introduce Contextual Semantic Guidance to extract frame-adaptive semantics from buffered features. It replaces text captions with efficient, fine-grained conditioning, thereby improving generation realism. In addition, Temporal Consistency Guidance is incorporated into the diffusion U-Net to enforce temporal coherence across frames and ensure stable generation. Extensive experiments show that S2VC delivers state-of-the-art perceptual quality with an average 52.73% bitrate saving over prior perceptual methods, underscoring the promise of single-step diffusion for efficient, high-quality video compression.

</details>


### [256] [Towards Robust DeepFake Detection under Unstable Face Sequences: Adaptive Sparse Graph Embedding with Order-Free Representation and Explicit Laplacian Spectral Prior](https://arxiv.org/abs/2512.07498)
*Chih-Chung Hsu,Shao-Ning Chen,Chia-Ming Lee,Yi-Fang Wang,Yi-Shiuan Chou*

Main category: cs.CV

TL;DR: 提出LR-GCN方法，通过构建无时序约束的图结构来检测DeepFake视频，对噪声、遮挡和对抗攻击具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有DeepFake检测器假设面部序列时序一致且干净，但现实场景中压缩伪影、遮挡和对抗攻击会破坏面部检测，导致无效或误检的面部，需要更鲁棒的检测方法。

Method: 提出Laplacian正则化图卷积网络(LR-GCN)，构建无时序时序图嵌入(OF-TGE)，基于语义相似性将帧级CNN特征组织成自适应稀疏图，引入双重稀疏机制和图拉普拉斯谱先验，实现任务驱动的谱带通机制。

Result: 在FF++、Celeb-DFv2和DFDC数据集上实现SOTA性能，在严重全局和局部干扰（包括缺失面部、遮挡和对抗性扰动）下表现出显著改进的鲁棒性。

Conclusion: LR-GCN通过图结构和谱域处理有效应对现实世界中的DeepFake检测挑战，为噪声和干扰环境下的视频真实性验证提供了鲁棒解决方案。

Abstract: Ensuring the authenticity of video content remains challenging as DeepFake generation becomes increasingly realistic and robust against detection. Most existing detectors implicitly assume temporally consistent and clean facial sequences, an assumption that rarely holds in real-world scenarios where compression artifacts, occlusions, and adversarial attacks destabilize face detection and often lead to invalid or misdetected faces. To address these challenges, we propose a Laplacian-Regularized Graph Convolutional Network (LR-GCN) that robustly detects DeepFakes from noisy or unordered face sequences, while being trained only on clean facial data. Our method constructs an Order-Free Temporal Graph Embedding (OF-TGE) that organizes frame-wise CNN features into an adaptive sparse graph based on semantic affinities. Unlike traditional methods constrained by strict temporal continuity, OF-TGE captures intrinsic feature consistency across frames, making it resilient to shuffled, missing, or heavily corrupted inputs. We further impose a dual-level sparsity mechanism on both graph structure and node features to suppress the influence of invalid faces. Crucially, we introduce an explicit Graph Laplacian Spectral Prior that acts as a high-pass operator in the graph spectral domain, highlighting structural anomalies and forgery artifacts, which are then consolidated by a low-pass GCN aggregation. This sequential design effectively realizes a task-driven spectral band-pass mechanism that suppresses background information and random noise while preserving manipulation cues. Extensive experiments on FF++, Celeb-DFv2, and DFDC demonstrate that LR-GCN achieves state-of-the-art performance and significantly improved robustness under severe global and local disruptions, including missing faces, occlusions, and adversarially perturbed face detections.

</details>


### [257] [MultiMotion: Multi Subject Video Motion Transfer via Video Diffusion Transformer](https://arxiv.org/abs/2512.07500)
*Penghui Liu,Jiangshan Wang,Yutong Shen,Shanhui Mo,Chenyang Qi,Yue Ma*

Main category: cs.CV

TL;DR: MultiMotion：基于DiT的多对象视频运动迁移框架，通过掩码感知注意力运动流实现多对象运动解耦与控制，使用高阶预测校正器进行高效采样，并构建首个多对象运动迁移基准数据集。


<details>
  <summary>Details</summary>
Motivation: 当前Diffusion Transformer架构在多对象视频运动迁移中存在运动纠缠和缺乏对象级控制的问题，难以实现多个独立对象的精确运动控制。

Method: 提出Mask-aware Attention Motion Flow（AMF），利用SAM2掩码在DiT流程中显式解耦和控制多个对象的运动特征；引入RectPC高阶预测校正器进行高效采样；构建首个DiT多对象运动迁移基准数据集。

Result: MultiMotion实现了精确、语义对齐且时序一致的多对象运动迁移，保持了DiT的高质量和可扩展性，在多对象控制方面显著优于现有方法。

Conclusion: MultiMotion为多对象视频运动迁移提供了一个统一框架，通过显式运动解耦和高效采样机制，解决了DiT架构中的运动纠缠问题，推动了多对象可控视频生成的发展。

Abstract: Multi-object video motion transfer poses significant challenges for Diffusion Transformer (DiT) architectures due to inherent motion entanglement and lack of object-level control. We present MultiMotion, a novel unified framework that overcomes these limitations. Our core innovation is Maskaware Attention Motion Flow (AMF), which utilizes SAM2 masks to explicitly disentangle and control motion features for multiple objects within the DiT pipeline. Furthermore, we introduce RectPC, a high-order predictor-corrector solver for efficient and accurate sampling, particularly beneficial for multi-entity generation. To facilitate rigorous evaluation, we construct the first benchmark dataset specifically for DiT-based multi-object motion transfer. MultiMotion demonstrably achieves precise, semantically aligned, and temporally coherent motion transfer for multiple distinct objects, maintaining DiT's high quality and scalability. The code is in the supp.

</details>


### [258] [SJD++: Improved Speculative Jacobi Decoding for Training-free Acceleration of Discrete Auto-regressive Text-to-Image Generation](https://arxiv.org/abs/2512.07503)
*Yao Teng,Zhihuan Jiang,Han Shi,Xian Liu,Xuefei Ning,Guohao Dai,Yu Wang,Zhenguo Li,Xihui Liu*

Main category: cs.CV

TL;DR: SJD++是一种无需训练的概率并行解码算法，通过多令牌预测和验证机制，将自回归文本到图像生成的推理延迟减少2-3倍，步骤压缩2-7倍，同时保持视觉质量。


<details>
  <summary>Details</summary>
Motivation: 大型自回归模型虽然能生成高质量、高分辨率图像，但由于需要数百到数千次顺序前向传递进行下一个令牌预测，导致生成速度缓慢。需要加速自回归文本到图像生成过程。

Method: 提出Speculative Jacobi Decoding++ (SJD++)算法，结合Jacobi解码的迭代多令牌预测机制和推测采样的概率起草-验证机制。关键创新是在每次验证阶段后重用高置信度起草令牌，而不是全部重新采样。

Result: 在多个代表性自回归文本到图像生成模型上的实验表明，SJD++实现了2-3倍的推理延迟减少和2-7倍的步骤压缩，同时保持视觉质量，没有可观察的退化。

Conclusion: SJD++是一种有效的训练免费加速方法，显著提升自回归文本到图像生成的效率，为实际应用提供了可行的解决方案。

Abstract: Large autoregressive models can generate high-quality, high-resolution images but suffer from slow generation speed, because these models require hundreds to thousands of sequential forward passes for next-token prediction during inference. To accelerate autoregressive text-to-image generation, we propose Speculative Jacobi Decoding++ (SJD++), a training-free probabilistic parallel decoding algorithm. Unlike traditional next-token prediction, SJD++ performs multi-token prediction in each forward pass, drastically reducing generation steps. Specifically, it integrates the iterative multi-token prediction mechanism from Jacobi decoding, with the probabilistic drafting-and-verification mechanism from speculative sampling. More importantly, for further acceleration, SJD++ reuses high-confidence draft tokens after each verification phase instead of resampling them all. We conduct extensive experiments on several representative autoregressive text-to-image generation models and demonstrate that SJD++ achieves $2\times$ to $3\times$ inference latency reduction and $2\times$ to $7\times$ step compression, while preserving visual quality with no observable degradation.

</details>


### [259] [ControlVP: Interactive Geometric Refinement of AI-Generated Images with Consistent Vanishing Points](https://arxiv.org/abs/2512.07504)
*Ryota Okumura,Kaede Shiohara,Toshihiko Yamasaki*

Main category: cs.CV

TL;DR: ControlVP：通过用户引导的消失点校正框架，解决文本到图像生成中的几何不一致问题，提升场景结构真实性


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型（如Stable Diffusion）在视觉质量上表现优异，但经常出现几何不一致问题，特别是消失点不一致，导致平行线在2D空间中无法正确收敛，降低了场景（尤其是建筑场景）的结构真实感

Method: 扩展预训练扩散模型，引入基于建筑轮廓的结构引导，并添加几何约束来显式鼓励图像边缘与透视线索的对齐

Result: 方法增强了全局几何一致性，同时保持了与基线相当的视觉保真度，特别适用于需要准确空间结构的应用（如图像到3D重建）

Conclusion: ControlVP通过用户引导的消失点校正，有效解决了文本到图像生成中的几何不一致问题，提升了场景的结构真实性和空间准确性

Abstract: Recent text-to-image models, such as Stable Diffusion, have achieved impressive visual quality, yet they often suffer from geometric inconsistencies that undermine the structural realism of generated scenes. One prominent issue is vanishing point inconsistency, where projections of parallel lines fail to converge correctly in 2D space. This leads to structurally implausible geometry that degrades spatial realism, especially in architectural scenes. We propose ControlVP, a user-guided framework for correcting vanishing point inconsistencies in generated images. Our approach extends a pre-trained diffusion model by incorporating structural guidance derived from building contours. We also introduce geometric constraints that explicitly encourage alignment between image edges and perspective cues. Our method enhances global geometric consistency while maintaining visual fidelity comparable to the baselines. This capability is particularly valuable for applications that require accurate spatial structure, such as image-to-3D reconstruction. The dataset and source code are available at https://github.com/RyotaOkumura/ControlVP .

</details>


### [260] [MeshRipple: Structured Autoregressive Generation of Artist-Meshes](https://arxiv.org/abs/2512.07514)
*Junkai Lin,Hang Long,Huipeng Guo,Jielei Zhang,JiaYi Yang,Tianle Guo,Yang Yang,Jianwen Li,Wenxiao Zhang,Matthias Nießner,Wei Yang*

Main category: cs.CV

TL;DR: MeshRipple：一种新的网格生成方法，通过前沿感知的BFS标记化和扩展预测策略，解决自回归网格生成中长距离几何依赖断裂的问题，生成具有高表面保真度和拓扑完整性的网格。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归网格生成方法将面序列化为序列，并使用滑动窗口推理来应对内存限制，但这种不匹配会破坏长距离几何依赖关系，导致生成网格中出现孔洞和碎片化组件。需要解决这一关键限制。

Method: MeshRipple采用三种关键技术：1) 前沿感知的BFS标记化，使生成顺序与表面拓扑对齐；2) 扩展预测策略，保持连贯、连接的表面增长；3) 稀疏注意力全局内存，提供有效无界的感受野以解决长距离拓扑依赖。

Result: MeshRipple能够生成具有高表面保真度和拓扑完整性的网格，在实验中优于近期强基线方法。

Conclusion: MeshRipple通过集成设计解决了自回归网格生成中的长距离依赖问题，实现了更高质量的网格生成，为3D资产表示提供了改进方案。

Abstract: Meshes serve as a primary representation for 3D assets. Autoregressive mesh generators serialize faces into sequences and train on truncated segments with sliding-window inference to cope with memory limits. However, this mismatch breaks long-range geometric dependencies, producing holes and fragmented components. To address this critical limitation, we introduce MeshRipple, which expands a mesh outward from an active generation frontier, akin to a ripple on a surface.MeshRipple rests on three key innovations: a frontier-aware BFS tokenization that aligns the generation order with surface topology; an expansive prediction strategy that maintains coherent, connected surface growth; and a sparse-attention global memory that provides an effectively unbounded receptive field to resolve long-range topological dependencies.This integrated design enables MeshRipple to generate meshes with high surface fidelity and topological completeness, outperforming strong recent baselines.

</details>


### [261] [From Orbit to Ground: Generative City Photogrammetry from Extreme Off-Nadir Satellite Images](https://arxiv.org/abs/2512.07527)
*Fei Yu,Yu Liu,Luyang Tang,Mingchao Sun,Zengye Ge,Rui Bu,Yuchao Jin,Haisen Zhao,He Sun,Yangyan Li,Mu Xu,Wenzheng Chen,Baoquan Chen*

Main category: cs.CV

TL;DR: 提出一种从稀疏卫星图像重建城市规模3D模型的方法，通过2.5D高度图建模和纹理恢复网络，解决极端视角外推问题，实现从轨道图像合成逼真的地面视角。


<details>
  <summary>Details</summary>
Motivation: 从卫星图像进行城市规模3D重建面临极端视角外推的挑战，需要从稀疏的轨道图像（视角差异近90度）合成地面视角。现有方法如NeRF和3DGS在处理严重透视缩短和纹理缺陷的卫星图像时会失败。

Method: 1. 将城市几何建模为2.5D高度图，采用Z单调符号距离场（SDF）匹配城市建筑布局；2. 通过可微分渲染技术从卫星图像绘制网格外观；3. 训练生成式纹理恢复网络增强外观，从退化输入中恢复高频纹理细节。

Result: 方法在大规模城市重建实验中表现出可扩展性和鲁棒性，例如从仅几张卫星图像重建4km²真实区域，在合成逼真地面视图方面达到最先进性能，生成高质量、可直接应用的资产。

Conclusion: 提出的方法成功解决了从稀疏卫星图像进行城市规模3D重建的极端视角外推问题，通过几何建模和纹理恢复的结合，生成了视觉逼真且可用于城市规划等下游任务的高保真模型。

Abstract: City-scale 3D reconstruction from satellite imagery presents the challenge of extreme viewpoint extrapolation, where our goal is to synthesize ground-level novel views from sparse orbital images with minimal parallax. This requires inferring nearly $90^\circ$ viewpoint gaps from image sources with severely foreshortened facades and flawed textures, causing state-of-the-art reconstruction engines such as NeRF and 3DGS to fail.
  To address this problem, we propose two design choices tailored for city structures and satellite inputs. First, we model city geometry as a 2.5D height map, implemented as a Z-monotonic signed distance field (SDF) that matches urban building layouts from top-down viewpoints. This stabilizes geometry optimization under sparse, off-nadir satellite views and yields a watertight mesh with crisp roofs and clean, vertically extruded facades. Second, we paint the mesh appearance from satellite images via differentiable rendering techniques. While the satellite inputs may contain long-range, blurry captures, we further train a generative texture restoration network to enhance the appearance, recovering high-frequency, plausible texture details from degraded inputs.
  Our method's scalability and robustness are demonstrated through extensive experiments on large-scale urban reconstruction. For example, in our teaser figure, we reconstruct a $4\,\mathrm{km}^2$ real-world region from only a few satellite images, achieving state-of-the-art performance in synthesizing photorealistic ground views. The resulting models are not only visually compelling but also serve as high-fidelity, application-ready assets for downstream tasks like urban planning and simulation.

</details>


### [262] [Dual-Stream Cross-Modal Representation Learning via Residual Semantic Decorrelation](https://arxiv.org/abs/2512.07568)
*Xuecheng Li,Weikuan Jia,Alisher Kurbonaliev,Qurbonaliev Alisher,Khudzhamkulov Rustam,Ismoilov Shuhratjon,Eshmatov Javhariddin,Yuanjie Zheng*

Main category: cs.CV

TL;DR: 提出DSRSD-Net框架，通过残差分解和语义解相关约束来解耦模态特定和模态共享信息，解决多模态学习中模态主导、冗余耦合和虚假相关等问题。


<details>
  <summary>Details</summary>
Motivation: 多模态表示常面临模态主导、冗余信息耦合和虚假跨模态相关性问题，导致次优泛化和有限可解释性。高方差模态会掩盖较弱但语义重要的信号，而简单融合策略会以不受控方式纠缠模态共享和模态特定因素。

Method: 提出双流残差语义解相关网络(DSRSD-Net)，包含：1) 双流表示学习模块，通过残差投影分离模态内(私有)和模态间(共享)潜在因子；2) 残差语义对齐头，使用对比和回归目标将不同模态的共享因子映射到共同空间；3) 解相关和正交性损失，正则化共享空间的协方差结构，同时强制共享流和私有流之间的正交性。

Result: 在两个大规模教育基准测试上的实验结果表明，DSRSD-Net在下一步预测和最终结果预测方面持续优于强单模态、早期融合、晚期融合和协同注意力基线。

Conclusion: DSRSD-Net通过解耦模态特定和模态共享信息，有效解决了多模态学习中的模态主导和冗余耦合问题，提高了预测性能和模型可解释性。

Abstract: Cross-modal learning has become a fundamental paradigm for integrating heterogeneous information sources such as images, text, and structured attributes. However, multimodal representations often suffer from modality dominance, redundant information coupling, and spurious cross-modal correlations, leading to suboptimal generalization and limited interpretability. In particular, high-variance modalities tend to overshadow weaker but semantically important signals, while naïve fusion strategies entangle modality-shared and modality-specific factors in an uncontrolled manner. This makes it difficult to understand which modality actually drives a prediction and to maintain robustness when some modalities are noisy or missing. To address these challenges, we propose a Dual-Stream Residual Semantic Decorrelation Network (DSRSD-Net), a simple yet effective framework that disentangles modality-specific and modality-shared information through residual decomposition and explicit semantic decorrelation constraints. DSRSD-Net introduces: (1) a dual-stream representation learning module that separates intra-modal (private) and inter-modal (shared) latent factors via residual projection; (2) a residual semantic alignment head that maps shared factors from different modalities into a common space using a combination of contrastive and regression-style objectives; and (3) a decorrelation and orthogonality loss that regularizes the covariance structure of the shared space while enforcing orthogonality between shared and private streams, thereby suppressing cross-modal redundancy and preventing feature collapse. Experimental results on two large-scale educational benchmarks demonstrate that DSRSD-Net consistently improves next-step prediction and final outcome prediction over strong single-modality, early-fusion, late-fusion, and co-attention baselines.

</details>


### [263] [All You Need Are Random Visual Tokens? Demystifying Token Pruning in VLLMs](https://arxiv.org/abs/2512.07580)
*Yahong Wang,Juncheng Wu,Zhangkai Ni,Longzhen Yang,Yihang Liu,Chengmei Yang,Ying Wen,Xianfeng Tang,Hui Liu,Yuyin Zhou,Lianghua He*

Main category: cs.CV

TL;DR: 视觉大语言模型(VLLMs)因使用数百个视觉token表示图像而产生高计算成本。研究发现深层视觉token信息会"消失"，提出"信息地平线"概念，并证明在深层使用随机剪枝能达到性能与效率的最佳平衡。


<details>
  <summary>Details</summary>
Motivation: VLLMs依赖大量视觉token导致计算成本高昂，现有训练无关的token剪枝方法在深层表现不佳，甚至不如随机剪枝。需要探究深层视觉token信息消失的原因并找到更有效的剪枝策略。

Method: 提出量化token信息含量的方法：通过移除token后模型输出概率的变化来衡量。分析发现视觉token信息随网络深度逐渐均匀化并最终消失，提出"信息地平线"概念。基于此发现，在深层使用随机剪枝，并与现有方法结合。

Result: 1) 发现视觉token信息在深层逐渐消失，存在"信息地平线"；2) 地平线位置随任务视觉强度变化；3) 地平线与模型能力相关。结合随机剪枝的DivPrune方法在剪除50%视觉token时仍保持Qwen-2.5-VL-7B 96.9%的性能，达到SOTA。

Conclusion: 视觉token信息在深层会消失，导致现有剪枝方法失效。在深层使用随机剪枝是高效且有效的策略，能显著提升VLLMs的推理效率而不损害性能。

Abstract: Vision Large Language Models (VLLMs) incur high computational costs due to their reliance on hundreds of visual tokens to represent images. While token pruning offers a promising solution for accelerating inference, this paper, however, identifies a key observation: in deeper layers (e.g., beyond the 20th), existing training-free pruning methods perform no better than random pruning. We hypothesize that this degradation is caused by "vanishing token information", where visual tokens progressively lose their salience with increasing network depth. To validate this hypothesis, we quantify a token's information content by measuring the change in the model output probabilities upon its removal. Using this proposed metric, our analysis of the information of visual tokens across layers reveals three key findings: (1) As layers deepen, the information of visual tokens gradually becomes uniform and eventually vanishes at an intermediate layer, which we term as "information horizon", beyond which the visual tokens become redundant; (2) The position of this horizon is not static; it extends deeper for visually intensive tasks, such as Optical Character Recognition (OCR), compared to more general tasks like Visual Question Answering (VQA); (3) This horizon is also strongly correlated with model capacity, as stronger VLLMs (e.g., Qwen2.5-VL) employ deeper visual tokens than weaker models (e.g., LLaVA-1.5). Based on our findings, we show that simple random pruning in deep layers efficiently balances performance and efficiency. Moreover, integrating random pruning consistently enhances existing methods. Using DivPrune with random pruning achieves state-of-the-art results, maintaining 96.9% of Qwen-2.5-VL-7B performance while pruning 50% of visual tokens. The code will be publicly available at https://github.com/YahongWang1/Information-Horizon.

</details>


### [264] [LongCat-Image Technical Report](https://arxiv.org/abs/2512.07584)
*Meituan LongCat Team,Hanghang Ma,Haoxian Tan,Jiale Huang,Junqiang Wu,Jun-Yan He,Lishuai Gao,Songlin Xiao,Xiaoming Wei,Xiaoqi Ma,Xunliang Cai,Yayong Guan,Jie Hu*

Main category: cs.CV

TL;DR: LongCat-Image是一个开源的英中双语图像生成基础模型，在文本渲染、真实感、部署效率和开发者可访问性方面取得突破，采用6B参数紧凑设计，提供完整开源生态系统。


<details>
  <summary>Details</summary>
Motivation: 解决当前主流模型在多语言文本渲染、照片真实感、部署效率和开发者可访问性方面的核心挑战，特别是中文文本渲染的行业痛点。

Method: 1) 在预训练、中期训练和SFT阶段采用严格的数据筛选策略，并在RL阶段协调使用精心设计的奖励模型；2) 采用紧凑的6B参数扩散模型架构，显著小于常见的20B+ MoE架构；3) 建立完整的开源生态系统，包括多个模型版本和完整训练工具链。

Result: 1) 在多语言文本渲染和照片真实感方面达到新的SOTA水平，显著提升美学质量；2) 在中文字符渲染方面设定新的行业标准，支持复杂生僻字，在覆盖率和准确性上超越开源和商业方案；3) 实现高效部署，VRAM使用最小化，推理速度快；4) 在图像编辑任务上也达到SOTA结果，编辑一致性优于其他开源工作。

Conclusion: LongCat-Image通过创新的训练策略和紧凑架构，在多语言图像生成和编辑方面取得突破性进展，其完整的开源生态系统将为开发者和研究者提供强大支持，推动视觉内容创作的前沿发展。

Abstract: We introduce LongCat-Image, a pioneering open-source and bilingual (Chinese-English) foundation model for image generation, designed to address core challenges in multilingual text rendering, photorealism, deployment efficiency, and developer accessibility prevalent in current leading models. 1) We achieve this through rigorous data curation strategies across the pre-training, mid-training, and SFT stages, complemented by the coordinated use of curated reward models during the RL phase. This strategy establishes the model as a new state-of-the-art (SOTA), delivering superior text-rendering capabilities and remarkable photorealism, and significantly enhancing aesthetic quality. 2) Notably, it sets a new industry standard for Chinese character rendering. By supporting even complex and rare characters, it outperforms both major open-source and commercial solutions in coverage, while also achieving superior accuracy. 3) The model achieves remarkable efficiency through its compact design. With a core diffusion model of only 6B parameters, it is significantly smaller than the nearly 20B or larger Mixture-of-Experts (MoE) architectures common in the field. This ensures minimal VRAM usage and rapid inference, significantly reducing deployment costs. Beyond generation, LongCat-Image also excels in image editing, achieving SOTA results on standard benchmarks with superior editing consistency compared to other open-source works. 4) To fully empower the community, we have established the most comprehensive open-source ecosystem to date. We are releasing not only multiple model versions for text-to-image and image editing, including checkpoints after mid-training and post-training stages, but also the entire toolchain of training procedure. We believe that the openness of LongCat-Image will provide robust support for developers and researchers, pushing the frontiers of visual content creation.

</details>


### [265] [Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation](https://arxiv.org/abs/2512.07590)
*Kaili Qi,Zhongyi Huang,Wenli Yang*

Main category: cs.CV

TL;DR: 提出VM_TUNet的鲁棒版本，结合变分方法和深度学习，通过物理先验、边缘检测器和平均曲率项改进Cahn-Hilliard方程，在噪声图像分割中实现性能与计算效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 针对噪声图像中边界模糊或断裂的分割挑战，传统CNN模型在边界处理上存在不足，而纯变分方法计算效率低。需要结合变分PDE的边界平滑优势与深度学习的强大表示能力。

Method: 提出鲁棒VM_TUNet框架：1) 将物理先验、边缘检测器和平均曲率项融入改进的Cahn-Hilliard方程；2) 设计F模块进行频域预处理缓解局部极小值问题；3) T模块确保准确稳定的局部计算，配有稳定性估计；4) 两个模块协同工作。

Result: 在三个基准数据集上的实验表明：1) 相比纯CNN模型获得竞争性定量结果和更好的视觉质量；2) 达到接近transformer方法的性能但计算成本合理；3) 在性能与计算效率间取得良好平衡。

Conclusion: 提出的鲁棒VM_TUNet成功结合了变分PDE的边界平滑优势和深度学习的表示能力，为噪声图像分割提供了一种高效且性能优异的混合框架，在计算成本和分割质量间实现了良好折衷。

Abstract: To address the challenge of segmenting noisy images with blurred or fragmented boundaries, this paper presents a robust version of Variational Model Based Tailored UNet (VM_TUNet), a hybrid framework that integrates variational methods with deep learning. The proposed approach incorporates physical priors, an edge detector and a mean curvature term, into a modified Cahn-Hilliard equation, aiming to combine the interpretability and boundary-smoothing advantages of variational partial differential equations (PDEs) with the strong representational ability of deep neural networks. The architecture consists of two collaborative modules: an F module, which conducts efficient frequency domain preprocessing to alleviate poor local minima, and a T module, which ensures accurate and stable local computations, backed by a stability estimate. Extensive experiments on three benchmark datasets indicate that the proposed method achieves a balanced trade-off between performance and computational efficiency, which yields competitive quantitative results and improved visual quality compared to pure convolutional neural network (CNN) based models, while achieving performance close to that of transformer-based method with reasonable computational expense.

</details>


### [266] [More than Segmentation: Benchmarking SAM 3 for Segmentation, 3D Perception, and Reconstruction in Robotic Surgery](https://arxiv.org/abs/2512.07596)
*Wenzhen Dong,Jieming Yu,Yiming Huang,Hongqiu Wang,Lei Zhu,Albert C. S. Chung,Hongliang Ren,Long Bai*

Main category: cs.CV

TL;DR: SAM 3在机器人辅助手术中评估，相比SAM和SAM 2在空间提示的图像和视频分割上有改进，语言提示在手术领域表现欠佳，3D重建能力展示但复杂动态场景仍有局限


<details>
  <summary>Details</summary>
Motivation: 评估SAM 3在机器人辅助手术中的性能，特别是其零样本分割能力（点、边界框和语言提示）以及3D感知能力，探索其在动态手术场景中的应用潜力

Method: 在MICCAI EndoVis 2017和EndoVis 2018基准上进行综合测试，评估图像和视频分割性能；在SCARED、StereoMIS和EndoNeRF上进行零样本评估，测试单目深度估计和3D器械重建能力

Result: SAM 3在空间提示（点和边界框）的图像和视频分割上明显优于SAM和SAM 2；语言提示在手术领域表现不佳；3D重建能力展示但复杂动态手术场景仍有局限性

Conclusion: SAM 3在机器人辅助手术中展现出改进的空间提示分割能力，但语言提示需要领域特定训练，3D重建能力有潜力但复杂动态场景仍需改进

Abstract: The recent Segment Anything Model (SAM) 3 has introduced significant advancements over its predecessor, SAM 2, particularly with the integration of language-based segmentation and enhanced 3D perception capabilities. SAM 3 supports zero-shot segmentation across a wide range of prompts, including point, bounding box, and language-based prompts, allowing for more flexible and intuitive interactions with the model. In this empirical evaluation, we assess the performance of SAM 3 in robot-assisted surgery, benchmarking its zero-shot segmentation with point and bounding box prompts and exploring its effectiveness in dynamic video tracking, alongside its newly introduced language prompt segmentation. While language prompts show potential, their performance in the surgical domain is currently suboptimal, highlighting the need for further domain-specific training. Additionally, we investigate SAM 3's 3D reconstruction abilities, demonstrating its capacity to process surgical scene data and reconstruct 3D anatomical structures from 2D images. Through comprehensive testing on the MICCAI EndoVis 2017 and EndoVis 2018 benchmarks, SAM 3 shows clear improvements over SAM and SAM 2 in both image and video segmentation under spatial prompts, while zero-shot evaluations on SCARED, StereoMIS, and EndoNeRF indicate strong monocular depth estimation and realistic 3D instrument reconstruction, yet also reveal remaining limitations in complex, highly dynamic surgical scenes.

</details>


### [267] [Online Segment Any 3D Thing as Instance Tracking](https://arxiv.org/abs/2512.07599)
*Hanshi Wang,Zijian Cai,Jin Gao,Yiwei Zhang,Weiming Hu,Ke Wang,Zhipeng Zhang*

Main category: cs.CV

TL;DR: AutoSeg3D将在线3D分割重构为实例跟踪问题，通过对象查询进行时空信息传播，在多个数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有基于查询的3D分割方法主要关注空间信息传播，忽视了感知的动态性和时间维度理解。在具身智能体环境中，视角变化导致物体部分可见，需要时间信息来建立完整的物体理解

Method: 将在线3D分割重构为实例跟踪问题，使用对象查询进行时间信息传播：长期实例关联保持特征和身份一致性，短期实例更新丰富即时观测。同时引入空间一致性学习来缓解VFMs的碎片化问题

Result: 在ScanNet200上超过ESAM 2.8 AP，在ScanNet、SceneNN和3RScan数据集上均取得一致性能提升，建立新的SOTA

Conclusion: 通过时间信息传播和空间一致性学习，AutoSeg3D显著提升了具身智能体的时空环境感知能力，稀疏对象查询机制既增强了空间理解又避免了密集点云交互的计算负担

Abstract: Online, real-time, and fine-grained 3D segmentation constitutes a fundamental capability for embodied intelligent agents to perceive and comprehend their operational environments. Recent advancements employ predefined object queries to aggregate semantic information from Vision Foundation Models (VFMs) outputs that are lifted into 3D point clouds, facilitating spatial information propagation through inter-query interactions. Nevertheless, perception is an inherently dynamic process, rendering temporal understanding a critical yet overlooked dimension within these prevailing query-based pipelines. Therefore, to further unlock the temporal environmental perception capabilities of embodied agents, our work reconceptualizes online 3D segmentation as an instance tracking problem (AutoSeg3D). Our core strategy involves utilizing object queries for temporal information propagation, where long-term instance association promotes the coherence of features and object identities, while short-term instance update enriches instant observations. Given that viewpoint variations in embodied robotics often lead to partial object visibility across frames, this mechanism aids the model in developing a holistic object understanding beyond incomplete instantaneous views. Furthermore, we introduce spatial consistency learning to mitigate the fragmentation problem inherent in VFMs, yielding more comprehensive instance information for enhancing the efficacy of both long-term and short-term temporal learning. The temporal information exchange and consistency learning facilitated by these sparse object queries not only enhance spatial comprehension but also circumvent the computational burden associated with dense temporal point cloud interactions. Our method establishes a new state-of-the-art, surpassing ESAM by 2.8 AP on ScanNet200 and delivering consistent gains on ScanNet, SceneNN, and 3RScan datasets.

</details>


### [268] [Decomposition Sampling for Efficient Region Annotations in Active Learning](https://arxiv.org/abs/2512.07606)
*Jingna Qiu,Frauke Wilm,Mathias Öttl,Jonas Utz,Maja Schlereth,Moritz Schillinger,Marc Aubreville,Katharina Breininger*

Main category: cs.CV

TL;DR: DECOMP是一种新的主动学习采样策略，专门针对密集预测任务（如医学图像分割），通过将图像分解为类别特定组件并采样每个类别的区域，提高标注多样性和少数类性能。


<details>
  <summary>Details</summary>
Motivation: 密集预测任务（特别是医学图像分析）的标注成本高、时间密集。现有区域级标注方法存在计算内存成本高、区域选择不相关、过度依赖不确定性采样等问题，需要更高效的主动学习策略。

Method: DECOMP（分解采样）策略：1）使用伪标签将图像分解为类别特定组件；2）从每个类别中采样区域；3）利用类别预测置信度指导采样过程，确保困难类别获得更多标注。

Result: 在ROI分类、2D分割和3D分割任务中，DECOMP始终优于基线方法，能更好地采样少数类区域，并在这些具有挑战性的类别上提升性能。

Conclusion: DECOMP通过分解图像和类别平衡采样，解决了密集预测任务中主动学习的核心挑战，为医学图像分析等标注成本高的领域提供了高效的标注策略。

Abstract: Active learning improves annotation efficiency by selecting the most informative samples for annotation and model training. While most prior work has focused on selecting informative images for classification tasks, we investigate the more challenging setting of dense prediction, where annotations are more costly and time-intensive, especially in medical imaging. Region-level annotation has been shown to be more efficient than image-level annotation for these tasks. However, existing methods for representative annotation region selection suffer from high computational and memory costs, irrelevant region choices, and heavy reliance on uncertainty sampling. We propose decomposition sampling (DECOMP), a new active learning sampling strategy that addresses these limitations. It enhances annotation diversity by decomposing images into class-specific components using pseudo-labels and sampling regions from each class. Class-wise predictive confidence further guides the sampling process, ensuring that difficult classes receive additional annotations. Across ROI classification, 2-D segmentation, and 3-D segmentation, DECOMP consistently surpasses baseline methods by better sampling minority-class regions and boosting performance on these challenging classes. Code is in https://github.com/JingnaQiu/DECOMP.git.

</details>


### [269] [MoCA: Mixture-of-Components Attention for Scalable Compositional 3D Generation](https://arxiv.org/abs/2512.07628)
*Zhiqi Li,Wenhuan Li,Tengfei Wang,Zhenwei Wang,Junta Wu,Haoyuan Wang,Yunhan Yang,Zehuan Huang,Yang Li,Peidong Liu,Chunchao Guo*

Main category: cs.CV

TL;DR: MoCA提出了一种高效的可组合3D生成模型，通过重要性组件路由和未重要组件压缩技术，解决了现有方法因全局注意力计算成本过高而难以扩展的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的部分感知3D生成方法在增加组件数量时，由于全局注意力计算的二次方成本导致可扩展性差，限制了细粒度组合式3D资产创建的能力。

Method: MoCA采用两种关键设计：1）基于重要性的组件路由，选择前k个相关组件进行稀疏全局注意力计算；2）未重要组件压缩，在降低全局注意力计算复杂度的同时保留未选择组件的上下文先验。

Result: 大量实验表明，MoCA在组合式物体和场景生成任务上均优于基线方法，能够实现高效、细粒度的组合式3D资产创建。

Conclusion: MoCA通过创新的注意力机制设计，成功解决了组合式3D生成中的可扩展性问题，为大规模组件组合的3D资产创建提供了有效解决方案。

Abstract: Compositionality is critical for 3D object and scene generation, but existing part-aware 3D generation methods suffer from poor scalability due to quadratic global attention costs when increasing the number of components. In this work, we present MoCA, a compositional 3D generative model with two key designs: (1) importance-based component routing that selects top-k relevant components for sparse global attention, and (2) unimportant components compression that preserve contextual priors of unselected components while reducing computational complexity of global attention. With these designs, MoCA enables efficient, fine-grained compositional 3D asset creation with scalable number of components. Extensive experiments show MoCA outperforms baselines on both compositional object and scene generation tasks. Project page: https://lizhiqi49.github.io/MoCA

</details>


### [270] [Liver Fibrosis Quantification and Analysis: The LiQA Dataset and Baseline Method](https://arxiv.org/abs/2512.07651)
*Yuanye Liu,Hanxiao Zhang,Nannan Shi,Yuxin Shi,Arif Mahmood,Murtaza Taj,Xiahai Zhuang*

Main category: cs.CV

TL;DR: LiQA数据集包含440名患者的多期相、多中心MRI扫描，用于肝脏分割和肝纤维化分期算法的基准测试，挑战中最佳方法采用半监督学习和多视图共识方法。


<details>
  <summary>Details</summary>
Motivation: 肝纤维化是全球重大健康负担，需要准确分期进行有效临床管理。现有算法在真实世界复杂条件下（如域偏移、模态缺失、空间错位）的鲁棒性需要评估。

Method: 建立LiQA数据集作为CARE 2024挑战基准；最佳方法整合半监督学习框架进行鲁棒分割，采用多视图共识方法和基于CAM的正则化进行分期。

Result: 评估显示，利用多源数据和解剖约束能显著增强模型在临床环境中的鲁棒性。

Conclusion: LiQA数据集为肝脏分割和肝纤维化分期提供了有价值的基准，多源数据和解剖约束的整合是提高临床环境下模型鲁棒性的有效策略。

Abstract: Liver fibrosis represents a significant global health burden, necessitating accurate staging for effective clinical management. This report introduces the LiQA (Liver Fibrosis Quantification and Analysis) dataset, established as part of the CARE 2024 challenge. Comprising $440$ patients with multi-phase, multi-center MRI scans, the dataset is curated to benchmark algorithms for Liver Segmentation (LiSeg) and Liver Fibrosis Staging (LiFS) under complex real-world conditions, including domain shifts, missing modalities, and spatial misalignment. We further describe the challenge's top-performing methodology, which integrates a semi-supervised learning framework with external data for robust segmentation, and utilizes a multi-view consensus approach with Class Activation Map (CAM)-based regularization for staging. Evaluation of this baseline demonstrates that leveraging multi-source data and anatomical constraints significantly enhances model robustness in clinical settings.

</details>


### [271] [An AI-Powered Autonomous Underwater System for Sea Exploration and Scientific Research](https://arxiv.org/abs/2512.07652)
*Hamad Almazrouei,Mariam Al Nasseri,Maha Alzaabi*

Main category: cs.CV

TL;DR: 提出AI驱动的自主水下航行器系统，整合YOLOv12 Nano实时检测、CNN特征提取、PCA降维、K-Means++聚类和LLM生成报告，用于海洋探索自动化。


<details>
  <summary>Details</summary>
Motivation: 传统海洋探索面临极端条件、有限能见度和高成本等挑战，导致大量海洋区域未被探索。需要自动化系统来克服这些限制，减少人类潜水风险，提高任务效率。

Method: 集成YOLOv12 Nano进行实时物体检测，ResNet50 CNN进行特征提取，PCA降维保留98%方差，K-Means++聚类基于视觉特征分组，GPT-4o Mini LLM生成结构化报告。使用超过55,000张DeepFish和OzFish数据集图像进行训练评估。

Result: 系统检测海洋物体达到mAP@0.5为0.512，精度0.535，召回率0.438。PCA有效降维同时保留98%方差，K-Means聚类成功基于视觉相似性分组物体。LLM集成有效生成检测和聚类的洞察性总结。

Conclusion: 该集成方法显著减少人类潜水风险，提高任务效率，增强水下数据分析的速度和深度，为挑战性海洋环境中的科学研究开辟新途径。

Abstract: Traditional sea exploration faces significant challenges due to extreme conditions, limited visibility, and high costs, resulting in vast unexplored ocean regions. This paper presents an innovative AI-powered Autonomous Underwater Vehicle (AUV) system designed to overcome these limitations by automating underwater object detection, analysis, and reporting. The system integrates YOLOv12 Nano for real-time object detection, a Convolutional Neural Network (CNN) (ResNet50) for feature extraction, Principal Component Analysis (PCA) for dimensionality reduction, and K-Means++ clustering for grouping marine objects based on visual characteristics. Furthermore, a Large Language Model (LLM) (GPT-4o Mini) is employed to generate structured reports and summaries of underwater findings, enhancing data interpretation. The system was trained and evaluated on a combined dataset of over 55,000 images from the DeepFish and OzFish datasets, capturing diverse Australian marine environments. Experimental results demonstrate the system's capability to detect marine objects with a mAP@0.5 of 0.512, a precision of 0.535, and a recall of 0.438. The integration of PCA effectively reduced feature dimensionality while preserving 98% variance, facilitating K-Means clustering which successfully grouped detected objects based on visual similarities. The LLM integration proved effective in generating insightful summaries of detections and clusters, supported by location data. This integrated approach significantly reduces the risks associated with human diving, increases mission efficiency, and enhances the speed and depth of underwater data analysis, paving the way for more effective scientific research and discovery in challenging marine environments.

</details>


### [272] [Optimization-Guided Diffusion for Interactive Scene Generation](https://arxiv.org/abs/2512.07661)
*Shiaho Li,Naisheng Ye,Tianyu Li,Kashyap Chitta,Tuo An,Peng Su,Boyang Wang,Haiou Liu,Chen Lv,Hongyang Li*

Main category: cs.CV

TL;DR: OMEGA是一个基于优化的无训练框架，通过约束优化引导扩散采样，生成物理合理且行为一致的驾驶场景，特别针对安全关键事件生成。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶评估需要真实多样的多智能体驾驶场景，但现有数据集缺乏安全关键事件。数据驱动的场景生成方法要么缺乏可控性，要么违反物理或社会约束。

Method: 提出OMEGA框架：在扩散模型的反向采样步骤中引入约束优化，确保结构一致性和交互感知。将ego-attacker交互建模为分布空间的博弈论优化，近似纳什均衡来生成安全关键对抗场景。

Result: 在nuPlan和Waymo数据集上，OMEGA将物理和行为有效场景比例从32.35%提升到72.27%（自由探索），从11%提升到80%（可控生成）。能生成5倍多的近碰撞帧（TTC<3秒）同时保持场景真实性。

Conclusion: OMEGA通过优化引导的扩散采样显著提升了驾驶场景生成的物理合理性、行为一致性和可控性，特别适用于生成安全关键的对抗场景用于自动驾驶评估。

Abstract: Realistic and diverse multi-agent driving scenes are crucial for evaluating autonomous vehicles, but safety-critical events which are essential for this task are rare and underrepresented in driving datasets. Data-driven scene generation offers a low-cost alternative by synthesizing complex traffic behaviors from existing driving logs. However, existing models often lack controllability or yield samples that violate physical or social constraints, limiting their usability. We present OMEGA, an optimization-guided, training-free framework that enforces structural consistency and interaction awareness during diffusion-based sampling from a scene generation model. OMEGA re-anchors each reverse diffusion step via constrained optimization, steering the generation towards physically plausible and behaviorally coherent trajectories. Building on this framework, we formulate ego-attacker interactions as a game-theoretic optimization in the distribution space, approximating Nash equilibria to generate realistic, safety-critical adversarial scenarios. Experiments on nuPlan and Waymo show that OMEGA improves generation realism, consistency, and controllability, increasing the ratio of physically and behaviorally valid scenes from 32.35% to 72.27% for free exploration capabilities, and from 11% to 80% for controllability-focused generation. Our approach can also generate $5\times$ more near-collision frames with a time-to-collision under three seconds while maintaining the overall scene realism.

</details>


### [273] [EgoCampus: Egocentric Pedestrian Eye Gaze Model and Dataset](https://arxiv.org/abs/2512.07668)
*Ronan John,Aditya Kesari,Vincenzo DiMatteo,Kristin Dana*

Main category: cs.CV

TL;DR: 提出了EgoCampus数据集和EgoCampusNet方法，用于预测行人在户外校园环境中导航时的视觉注意力（眼动注视点）。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数自我中心数据集主要关注室内任务或缺乏眼动注视信息，而真实世界户外导航中的视觉注意力预测是一个重要但尚未充分研究的挑战。

Method: 收集了EgoCampus数据集，使用Meta的Project Aria眼镜记录80多名行人在25条不同户外路径上的眼动注视、RGB视频、惯性传感器和GPS数据。基于此数据开发了EgoCampusNet方法来预测导航行人的眼动注视。

Result: 创建了一个包含多样化眼动注视标注视频的数据集，覆盖6公里校园路径，为研究真实世界注意力提供了新资源，并提出了相应的注视预测方法。

Conclusion: 这项工作为研究真实世界视觉注意力和开发导航注视预测模型提供了新的数据集和方法资源，填补了户外自我中心眼动注视数据的空白。

Abstract: We address the challenge of predicting human visual attention during real-world navigation by measuring and modeling egocentric pedestrian eye gaze in an outdoor campus setting. We introduce the EgoCampus dataset, which spans 25 unique outdoor paths over 6 km across a university campus with recordings from more than 80 distinct human pedestrians, resulting in a diverse set of gaze-annotated videos. The system used for collection, Meta's Project Aria glasses, integrates eye tracking, front-facing RGB cameras, inertial sensors, and GPS to provide rich data from the human perspective. Unlike many prior egocentric datasets that focus on indoor tasks or exclude eye gaze information, our work emphasizes visual attention while subjects walk in outdoor campus paths. Using this data, we develop EgoCampusNet, a novel method to predict eye gaze of navigating pedestrians as they move through outdoor environments. Our contributions provide both a new resource for studying real-world attention and a resource for future work in gaze prediction models for navigation. Dataset and code are available upon request, and will be made publicly available at a later date at https://github.com/ComputerVisionRutgers/EgoCampus .

</details>


### [274] [DIST-CLIP: Arbitrary Metadata and Image Guided MRI Harmonization via Disentangled Anatomy-Contrast Representations](https://arxiv.org/abs/2512.07674)
*Mehmet Yigit Avci,Pedro Borges,Virginia Fernandez,Paul Wright,Mehmet Yigitsoy,Sebastien Ourselin,Jorge Cardoso*

Main category: cs.CV

TL;DR: DIST-CLIP：基于CLIP指导的解耦风格迁移框架，用于MRI图像标准化，可灵活使用目标图像或DICOM元数据进行指导，显著提升风格转换保真度和解剖结构保持能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习在医学影像分析中应用受限，主要障碍是数据异质性。MRI中扫描仪硬件差异、采集协议多样和序列参数变化导致显著的域偏移，现有标准化方法不足：基于图像的方法需要目标图像，基于文本的方法依赖简单标签且无法处理真实临床环境的复杂性。

Method: 提出DIST-CLIP框架，显式解耦解剖内容和图像对比度。使用预训练CLIP编码器提取对比度表示，通过新颖的自适应风格迁移模块将对比度嵌入整合到解剖内容中。可灵活使用目标图像或DICOM元数据进行指导。

Result: 在多样化真实临床数据集上训练和评估，相比最先进方法在风格转换保真度和解剖结构保持方面均有显著提升，为MRI数据标准化提供了灵活解决方案。

Conclusion: DIST-CLIP为MRI标准化提供了统一框架，能有效处理真实临床环境中的异质性，代码和权重将公开发布。

Abstract: Deep learning holds immense promise for transforming medical image analysis, yet its clinical generalization remains profoundly limited. A major barrier is data heterogeneity. This is particularly true in Magnetic Resonance Imaging, where scanner hardware differences, diverse acquisition protocols, and varying sequence parameters introduce substantial domain shifts that obscure underlying biological signals. Data harmonization methods aim to reduce these instrumental and acquisition variability, but existing approaches remain insufficient. When applied to imaging data, image-based harmonization approaches are often restricted by the need for target images, while existing text-guided methods rely on simplistic labels that fail to capture complex acquisition details or are typically restricted to datasets with limited variability, failing to capture the heterogeneity of real-world clinical environments. To address these limitations, we propose DIST-CLIP (Disentangled Style Transfer with CLIP Guidance), a unified framework for MRI harmonization that flexibly uses either target images or DICOM metadata for guidance. Our framework explicitly disentangles anatomical content from image contrast, with the contrast representations being extracted using pre-trained CLIP encoders. These contrast embeddings are then integrated into the anatomical content via a novel Adaptive Style Transfer module. We trained and evaluated DIST-CLIP on diverse real-world clinical datasets, and showed significant improvements in performance when compared against state-of-the-art methods in both style translation fidelity and anatomical preservation, offering a flexible solution for style transfer and standardizing MRI data. Our code and weights will be made publicly available upon publication.

</details>


### [275] [sim2art: Accurate Articulated Object Modeling from a Single Video using Synthetic Training Data Only](https://arxiv.org/abs/2512.07698)
*Arslan Artykov,Corentin Sautier,Vincent Lepetit*

Main category: cs.CV

TL;DR: 首个数据驱动方法，从自由移动单目视频中联合预测部件分割和关节参数，仅用合成数据训练，在真实物体上表现良好


<details>
  <summary>Details</summary>
Motivation: 理解铰接物体对机器人和数字孪生至关重要，但先前工作多依赖多视角系统、物体扫描或静态相机，缺乏从自由移动单目视频中恢复部件分割和关节参数的方法

Method: 提出首个数据驱动方法，从自由移动相机拍摄的单目视频中联合预测部件分割和关节参数，仅使用合成数据进行训练

Result: 方法在真实世界物体上表现出强大的泛化能力，为铰接物体理解提供了可扩展且实用的解决方案

Conclusion: 该方法可直接处理随意录制的视频，适合动态环境中的实时应用，为铰接物体理解提供了实用的单目视频解决方案

Abstract: Understanding articulated objects is a fundamental challenge in robotics and digital twin creation. To effectively model such objects, it is essential to recover both part segmentation and the underlying joint parameters. Despite the importance of this task, previous work has largely focused on setups like multi-view systems, object scanning, or static cameras. In this paper, we present the first data-driven approach that jointly predicts part segmentation and joint parameters from monocular video captured with a freely moving camera. Trained solely on synthetic data, our method demonstrates strong generalization to real-world objects, offering a scalable and practical solution for articulated object understanding. Our approach operates directly on casually recorded video, making it suitable for real-time applications in dynamic environments. Project webpage: https://aartykov.github.io/sim2art/

</details>


### [276] [Guiding What Not to Generate: Automated Negative Prompting for Text-Image Alignment](https://arxiv.org/abs/2512.07702)
*Sangha Park,Eunji Kim,Yeongtak Oh,Jooyoung Choi,Sungroh Yoon*

Main category: cs.CV

TL;DR: NPC提出了一种自动化的负提示生成管道，通过识别和应用负提示来抑制不想要的内容，从而改善文本到图像生成的精确对齐。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到图像生成取得了显著进展，但对于具有丰富组合结构或想象元素的提示，实现精确的文本-图像对齐仍然具有挑战性。现有方法在处理复杂提示时往往会产生与文本描述不符的内容。

Method: NPC采用自动化管道，首先分析交叉注意力模式来解释目标负提示（与对齐错误直接相关）和非目标负提示（与提示无关但出现在生成图像中的标记）如何增强对齐。通过验证器-描述器-提议器框架生成候选负提示，并使用显著的文本空间评分对它们进行排序，实现无需额外图像合成的有效选择。

Result: 在GenEval++和Imagine-Bench基准测试中，NPC优于强基线方法，在GenEval++上达到0.571 vs 0.371，在Imagine-Bench上获得最佳整体性能。

Conclusion: 通过指导模型不生成什么内容，NPC为扩散模型中的文本-图像对齐提供了一种原则性、完全自动化的方法，显著提高了生成质量。

Abstract: Despite substantial progress in text-to-image generation, achieving precise text-image alignment remains challenging, particularly for prompts with rich compositional structure or imaginative elements. To address this, we introduce Negative Prompting for Image Correction (NPC), an automated pipeline that improves alignment by identifying and applying negative prompts that suppress unintended content. We begin by analyzing cross-attention patterns to explain why both targeted negatives-those directly tied to the prompt's alignment error-and untargeted negatives-tokens unrelated to the prompt but present in the generated image-can enhance alignment. To discover useful negatives, NPC generates candidate prompts using a verifier-captioner-proposer framework and ranks them with a salient text-space score, enabling effective selection without requiring additional image synthesis. On GenEval++ and Imagine-Bench, NPC outperforms strong baselines, achieving 0.571 vs. 0.371 on GenEval++ and the best overall performance on Imagine-Bench. By guiding what not to generate, NPC provides a principled, fully automated route to stronger text-image alignment in diffusion models. Code is released at https://github.com/wiarae/NPC.

</details>


### [277] [PVeRA: Probabilistic Vector-Based Random Matrix Adaptation](https://arxiv.org/abs/2512.07703)
*Leo Fillioux,Enzo Ferrante,Paul-Henry Cournède,Maria Vakalopoulou,Stergios Christodoulidis*

Main category: cs.CV

TL;DR: PVeRA是一种概率版本的VeRA适配器，通过概率化修改低秩矩阵来处理输入中的固有模糊性，并在训练和测试时支持不同采样配置，在参数高效适应任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型需要大量数据和计算资源进行训练或微调，成本高昂。适应方法通过将可训练模块附加到冻结骨干网络上来提供计算高效的解决方案，但现有方法在处理输入模糊性方面存在局限。

Method: 提出PVeRA（概率VeRA适配器），对VeRA的低秩矩阵进行概率化修改。该方法利用跨层共享的冻结随机低秩矩阵对，通过概率方式处理输入中的固有模糊性，并允许在训练和测试时使用不同的采样配置。

Result: 在VTAB-1k基准测试中，PVeRA在七个适配器比较中表现优异，超越了VeRA和其他适配器方法。

Conclusion: PVeRA通过概率化方法有效处理输入模糊性，在参数高效适应任务中取得了更好的性能，为大型基础模型的轻量化适应提供了新的解决方案。

Abstract: Large foundation models have emerged in the last years and are pushing performance boundaries for a variety of tasks. Training or even finetuning such models demands vast datasets and computational resources, which are often scarce and costly. Adaptation methods provide a computationally efficient solution to address these limitations by allowing such models to be finetuned on small amounts of data and computing power. This is achieved by appending new trainable modules to frozen backbones with only a fraction of the trainable parameters and fitting only these modules on novel tasks. Recently, the VeRA adapter was shown to excel in parameter-efficient adaptations by utilizing a pair of frozen random low-rank matrices shared across all layers. In this paper, we propose PVeRA, a probabilistic version of the VeRA adapter, which modifies the low-rank matrices of VeRA in a probabilistic manner. This modification naturally allows handling inherent ambiguities in the input and allows for different sampling configurations during training and testing. A comprehensive evaluation was performed on the VTAB-1k benchmark and seven adapters, with PVeRA outperforming VeRA and other adapters. Our code for training models with PVeRA and benchmarking all adapters is available https://github.com/leofillioux/pvera.

</details>


### [278] [UnCageNet: Tracking and Pose Estimation of Caged Animal](https://arxiv.org/abs/2512.07712)
*Sayak Dutta,Harish Katti,Shashikant Verma,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: 提出三阶段预处理流程，通过笼子分割、修复和评估，解决动物追踪与姿态估计在笼子遮挡下的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有动物追踪与姿态估计系统（如STEP、ViTPose）在处理带有笼子结构和系统性遮挡的图像视频时性能大幅下降，需要解决笼子遮挡对算法性能的影响。

Method: 三阶段预处理流程：1) 使用Gabor增强的ResNet-UNet架构进行笼子分割，含72个方向核；2) 使用CRFill进行笼子修复，实现内容感知重建；3) 在修复后的帧上评估姿态估计与追踪性能。

Result: 实验验证表明，通过该流程去除笼子遮挡后，姿态估计与追踪性能达到与无遮挡环境相当的水平，关键点检测精度和轨迹一致性均有显著提升。

Conclusion: 提出的三阶段预处理流程能有效解决笼子遮挡问题，使动物追踪与姿态估计系统在复杂遮挡环境下仍能保持高性能，为相关应用提供了实用解决方案。

Abstract: Animal tracking and pose estimation systems, such as STEP (Simultaneous Tracking and Pose Estimation) and ViTPose, experience substantial performance drops when processing images and videos with cage structures and systematic occlusions. We present a three-stage preprocessing pipeline that addresses this limitation through: (1) cage segmentation using a Gabor-enhanced ResNet-UNet architecture with tunable orientation filters, (2) cage inpainting using CRFill for content-aware reconstruction of occluded regions, and (3) evaluation of pose estimation and tracking on the uncaged frames. Our Gabor-enhanced segmentation model leverages orientation-aware features with 72 directional kernels to accurately identify and segment cage structures that severely impair the performance of existing methods. Experimental validation demonstrates that removing cage occlusions through our pipeline enables pose estimation and tracking performance comparable to that in environments without occlusions. We also observe significant improvements in keypoint detection accuracy and trajectory consistency.

</details>


### [279] [ViSA: 3D-Aware Video Shading for Real-Time Upper-Body Avatar Creation](https://arxiv.org/abs/2512.07720)
*Fan Yang,Heyuan Li,Peihao Li,Weihao Yuan,Lingteng Qiu,Chaoyue Song,Cheng Chen,Yisheng He,Shifeng Zhang,Xiaoguang Han,Steven Hoi,Guosheng Lin*

Main category: cs.CV

TL;DR: 提出结合3D重建模型和视频扩散模型的方法，从单张图像生成高质量上身3D虚拟形象，解决现有方法纹理模糊、动作僵硬或结构不稳定等问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D虚拟形象生成方法存在矛盾：基于重建的方法能产生稳定结构但纹理模糊、动作僵硬；基于视频生成的方法能产生逼真动态效果但结构不稳定、身份漂移。需要结合两者优势。

Method: 使用3D重建模型提供结构和外观先验，引导实时自回归视频扩散模型进行渲染。结合几何稳定性和生成能力，实现实时高质量虚拟形象生成。

Result: 实验表明该方法显著减少伪影，在视觉质量上大幅超越领先方法，能生成具有逼真外观和连贯动态的高保真数字虚拟形象。

Conclusion: 通过结合3D重建的几何稳定性和视频模型的生成能力，实现了实时生成高质量上身3D虚拟形象的鲁棒高效解决方案，适用于游戏和虚拟现实等应用。

Abstract: Generating high-fidelity upper-body 3D avatars from one-shot input image remains a significant challenge. Current 3D avatar generation methods, which rely on large reconstruction models, are fast and capable of producing stable body structures, but they often suffer from artifacts such as blurry textures and stiff, unnatural motion. In contrast, generative video models show promising performance by synthesizing photorealistic and dynamic results, but they frequently struggle with unstable behavior, including body structural errors and identity drift. To address these limitations, we propose a novel approach that combines the strengths of both paradigms. Our framework employs a 3D reconstruction model to provide robust structural and appearance priors, which in turn guides a real-time autoregressive video diffusion model for rendering. This process enables the model to synthesize high-frequency, photorealistic details and fluid dynamics in real time, effectively reducing texture blur and motion stiffness while preventing the structural inconsistencies common in video generation methods. By uniting the geometric stability of 3D reconstruction with the generative capabilities of video models, our method produces high-fidelity digital avatars with realistic appearance and dynamic, temporally coherent motion. Experiments demonstrate that our approach significantly reduces artifacts and achieves substantial improvements in visual quality over leading methods, providing a robust and efficient solution for real-time applications such as gaming and virtual reality. Project page: https://lhyfst.github.io/visa

</details>


### [280] [Improving action classification with brain-inspired deep networks](https://arxiv.org/abs/2512.07729)
*Aidas Aglinskas,Stefano Anzellotti*

Main category: cs.CV

TL;DR: 本文研究了深度神经网络与人类在动作识别中对身体和背景信息的利用差异，并提出了受大脑领域特异性启发的双流架构来改进性能。


<details>
  <summary>Details</summary>
Motivation: 动作识别在机器人和医疗监测等应用中至关重要，但深度神经网络如何利用身体信息和背景信息尚不明确。由于这两种信息在训练数据中可能相关，DNN可能过度依赖其中一种而忽略另一种。相比之下，人类大脑有专门处理身体和场景的区域，可能更有效地整合两种信息。

Method: 1) 使用HAA500数据集训练DNN，测试其在三种刺激版本（完整、仅背景、仅身体）上的性能；2) 招募28名人类参与者进行相同测试；3) 设计受大脑领域特异性启发的双流架构，分别处理身体和背景信息，并评估其性能。

Result: DNN在完整和仅背景刺激上表现良好，但在仅身体刺激上接近随机水平。人类在所有三种刺激版本上都能准确识别动作，且在仅身体刺激上的表现显著优于仅背景刺激。双流架构不仅提高了动作识别性能，其在不同刺激版本上的准确率模式也更接近人类表现。

Conclusion: 人类比DNN更有效地整合身体和背景信息进行动作识别。受大脑领域特异性启发的双流架构能够改善DNN性能，使其表现更接近人类，这为开发更类人的计算机视觉系统提供了方向。

Abstract: Action recognition is also key for applications ranging from robotics to healthcare monitoring. Action information can be extracted from the body pose and movements, as well as from the background scene. However, the extent to which deep neural networks (DNNs) make use of information about the body and information about the background remains unclear. Since these two sources of information may be correlated within a training dataset, DNNs might learn to rely predominantly on one of them, without taking full advantage of the other. Unlike DNNs, humans have domain-specific brain regions selective for perceiving bodies, and regions selective for perceiving scenes. The present work tests whether humans are thus more effective at extracting information from both body and background, and whether building brain-inspired deep network architectures with separate domain-specific streams for body and scene perception endows them with more human-like performance. We first demonstrate that DNNs trained using the HAA500 dataset perform almost as accurately on versions of the stimuli that show both body and background and on versions of the stimuli from which the body was removed, but are at chance-level for versions of the stimuli from which the background was removed. Conversely, human participants (N=28) can recognize the same set of actions accurately with all three versions of the stimuli, and perform significantly better on stimuli that show only the body than on stimuli that show only the background. Finally, we implement and test a novel architecture patterned after domain specificity in the brain with separate streams to process body and background information. We show that 1) this architecture improves action recognition performance, and 2) its accuracy across different versions of the stimuli follows a pattern that matches more closely the pattern of accuracy observed in human participants.

</details>


### [281] [SAVE: Sparse Autoencoder-Driven Visual Information Enhancement for Mitigating Object Hallucination](https://arxiv.org/abs/2512.07730)
*Sangha Park,Seungryong Yoo,Jisoo Mok,Sungroh Yoon*

Main category: cs.CV

TL;DR: SAVE框架通过稀疏自编码器特征引导，增强MLLMs的视觉理解能力，有效减少物体幻觉问题


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型存在物体幻觉问题，主要源于语言先验和视觉信息丢失，需要有效方法来增强模型的视觉理解能力

Method: 提出SAVE框架：1）使用二元物体存在问答探针识别稀疏自编码器中的视觉理解特征；2）沿这些特征引导模型，强化基于视觉的理解

Result: 在CHAIR_S上提升10个百分点，在POPE和MMHal-Bench上持续改进，优于现有免训练方法；能抑制不确定物体标记生成，增加对图像标记的关注

Conclusion: SAVE通过稀疏自编码器特征引导有效减少多模态大语言模型的物体幻觉，方法简单但效果显著，具有鲁棒性和泛化性

Abstract: Although Multimodal Large Language Models (MLLMs) have advanced substantially, they remain vulnerable to object hallucination caused by language priors and visual information loss. To address this, we propose SAVE (Sparse Autoencoder-Driven Visual Information Enhancement), a framework that mitigates hallucination by steering the model along Sparse Autoencoder (SAE) latent features. A binary object-presence question-answering probe identifies the SAE features most indicative of the model's visual information processing, referred to as visual understanding features. Steering the model along these identified features reinforces grounded visual understanding and effectively reduces hallucination. With its simple design, SAVE outperforms state-of-the-art training-free methods on standard benchmarks, achieving a 10\%p improvement in CHAIR\_S and consistent gains on POPE and MMHal-Bench. Extensive evaluations across multiple models and layers confirm the robustness and generalizability of our approach. Further analysis reveals that steering along visual understanding features suppresses the generation of uncertain object tokens and increases attention to image tokens, mitigating hallucination. Code is released at https://github.com/wiarae/SAVE.

</details>


### [282] [SpatialDreamer: Incentivizing Spatial Reasoning via Active Mental Imagery](https://arxiv.org/abs/2512.07733)
*Meng Cao,Xingyu Li,Xue Liu,Ian Reid,Xiaodan Liang*

Main category: cs.CV

TL;DR: SpatialDreamer是一个强化学习框架，通过主动探索、视觉想象和证据推理的闭环过程，提升多模态大语言模型在复杂空间推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在需要心理模拟的复杂空间推理任务上表现有限，现有方法主要依赖被动观察空间数据，缺乏主动的心理意象过程。

Method: 提出SpatialDreamer强化学习框架，包含主动探索、世界模型视觉想象和证据推理的闭环过程。为解决长序列推理任务中细粒度奖励监督不足的问题，提出几何策略优化（GeoPO），引入树结构采样和具有几何一致性约束的步骤级奖励估计。

Result: 在多个具有挑战性的基准测试中，SpatialDreamer取得了极具竞争力的结果，标志着MLLMs在类人主动空间心理模拟方面的关键进展。

Conclusion: SpatialDreamer通过强化学习和主动心理模拟机制，显著提升了多模态大语言模型在复杂空间推理任务中的能力，为解决需要心理意象的认知任务提供了有效框架。

Abstract: Despite advancements in Multi-modal Large Language Models (MLLMs) for scene understanding, their performance on complex spatial reasoning tasks requiring mental simulation remains significantly limited. Current methods often rely on passive observation of spatial data, failing to internalize an active mental imagery process. To bridge this gap, we propose SpatialDreamer, a reinforcement learning framework that enables spatial reasoning through a closedloop process of active exploration, visual imagination via a world model, and evidence-grounded reasoning. To address the lack of fine-grained reward supervision in longhorizontal reasoning tasks, we propose Geometric Policy Optimization (GeoPO), which introduces tree-structured sampling and step-level reward estimation with geometric consistency constraints. Extensive experiments demonstrate that SpatialDreamer delivers highly competitive results across multiple challenging benchmarks, signifying a critical advancement in human-like active spatial mental simulation for MLLMs.

</details>


### [283] [HLTCOE Evaluation Team at TREC 2025: VQA Track](https://arxiv.org/abs/2512.07738)
*Dengjia Zhang,Charles Weng,Katherine Guerrerio,Yi Lu,Kenton Murray,Alexander Martin,Reno Kriz,Benjamin Van Durme*

Main category: cs.CV

TL;DR: HLTCOE团队提出了一种列表式学习框架，通过结合生成式模型和判别式排序，提高视频问答中答案生成的语义精度和排序一致性。


<details>
  <summary>Details</summary>
Motivation: 传统的视频问答系统在生成答案时往往缺乏语义精度和排序一致性，特别是在需要时间推理和语义消歧的复杂问题上表现不佳。需要一种能够同时优化生成质量和排序稳定性的方法。

Method: 采用两阶段方法：1) 基础多模态模型生成多个候选答案；2) 使用新颖的Masked Pointer Cross-Entropy Loss with Rank Weights训练模型对候选答案进行重排序。该损失函数结合了指针式候选选择、排名依赖权重和词汇限制下的掩码交叉熵。

Result: 实验显示该方法在准确性和排序稳定性方面取得了一致性提升，特别是在需要时间推理和语义消歧的问题上效果显著。

Conclusion: 通过将生成式建模与判别式排序相结合，该方法能够产生连贯、细粒度的答案列表，为视频问答系统的性能提升提供了有效途径。

Abstract: The HLTCOE Evaluation team participated in TREC VQA's Answer Generation (AG) task, for which we developed a listwise learning framework that aims to improve semantic precision and ranking consistency in answer generation. Given a video-question pair, a base multimodal model first generates multiple candidate answers, which are then reranked using a model trained with a novel Masked Pointer Cross-Entropy Loss with Rank Weights. This objective integrates pointer-based candidate selection, rank-dependent weighting, and masked cross-entropy under vocabulary restriction, enabling stable and interpretable listwise optimization. By bridging generative modeling with discriminative ranking, our method produces coherent, fine-grained answer lists. Experiments reveal consistent gains in accuracy and ranking stability, especially for questions requiring temporal reasoning and semantic disambiguation.

</details>


### [284] [DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving](https://arxiv.org/abs/2512.07745)
*Jialv Zou,Shaoyu Chen,Bencheng Liao,Zhiyu Zheng,Yuehao Song,Lefei Zhang,Qian Zhang,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: DiffusionDriveV2使用强化学习改进端到端自动驾驶扩散模型，解决模式坍塌问题，在保持多样性的同时提升轨迹质量


<details>
  <summary>Details</summary>
Motivation: 现有生成扩散模型在端到端自动驾驶中存在模式坍塌问题，倾向于生成保守和同质化的行为。虽然DiffusionDrive使用预定义锚点来划分动作空间并生成多样轨迹，但其基于模仿学习的方法缺乏足够约束，导致多样性和一致高质量之间的困境

Method: 提出DiffusionDriveV2，利用强化学习约束低质量模式并探索更优轨迹。采用尺度自适应乘性噪声促进广泛探索；使用锚内GRPO管理单个锚点内样本的优势估计，以及锚间截断GRPO在不同锚点间融入全局视角，防止不同意图间的不当优势比较

Result: 在NAVSIM v1数据集上达到91.2 PDMS，在NAVSIM v2数据集上达到85.5 EPDMS（使用对齐的ResNet-34骨干网络），创下新记录。实验验证该方法解决了截断扩散模型中多样性和一致高质量之间的困境，实现了最佳权衡

Conclusion: DiffusionDriveV2通过强化学习显著提升了端到端自动驾驶扩散模型的整体输出质量，同时保持了其核心高斯混合模型固有的多模态特性，解决了模式坍塌问题

Abstract: Generative diffusion models for end-to-end autonomous driving often suffer from mode collapse, tending to generate conservative and homogeneous behaviors. While DiffusionDrive employs predefined anchors representing different driving intentions to partition the action space and generate diverse trajectories, its reliance on imitation learning lacks sufficient constraints, resulting in a dilemma between diversity and consistent high quality. In this work, we propose DiffusionDriveV2, which leverages reinforcement learning to both constrain low-quality modes and explore for superior trajectories. This significantly enhances the overall output quality while preserving the inherent multimodality of its core Gaussian Mixture Model. First, we use scale-adaptive multiplicative noise, ideal for trajectory planning, to promote broad exploration. Second, we employ intra-anchor GRPO to manage advantage estimation among samples generated from a single anchor, and inter-anchor truncated GRPO to incorporate a global perspective across different anchors, preventing improper advantage comparisons between distinct intentions (e.g., turning vs. going straight), which can lead to further mode collapse. DiffusionDriveV2 achieves 91.2 PDMS on the NAVSIM v1 dataset and 85.5 EPDMS on the NAVSIM v2 dataset in closed-loop evaluation with an aligned ResNet-34 backbone, setting a new record. Further experiments validate that our approach resolves the dilemma between diversity and consistent high quality for truncated diffusion models, achieving the best trade-off. Code and model will be available at https://github.com/hustvl/DiffusionDriveV2

</details>


### [285] [Unison: A Fully Automatic, Task-Universal, and Low-Cost Framework for Unified Understanding and Generation](https://arxiv.org/abs/2512.07747)
*Shihao Zhao,Yitong Chen,Zeyinzi Jiang,Bojia Zi,Shaozhe Hao,Yu Liu,Chaojie Mao,Kwan-Yee K. Wong*

Main category: cs.CV

TL;DR: Unison是一个低成本的多模态统一理解与生成模型，通过两阶段方案实现多种任务覆盖，并能自动解析用户意图和任务参数。


<details>
  <summary>Details</summary>
Motivation: 现有多模态统一方法存在两大问题：自回归方法需要大量计算资源，两阶段方法任务覆盖有限且生成质量差。两者都需要手动配置参数，缺乏智能性。

Method: 采用两阶段方案，在保持预训练模型能力的同时，通过极低成本训练（仅50万样本和50GPU小时），覆盖多种理解与生成任务，并自动解析用户意图和任务参数。

Result: 实验表明，Unison能准确自动识别任务和提取相关参数，在各种理解和生成任务上取得优异性能，包括文本、图像、视频理解和文本到视觉内容生成等任务。

Conclusion: Unison证明了在极低成本下实现多模态统一理解与生成的可行性，并能实现任务自动解析，为多模态学习提供了高效实用的解决方案。

Abstract: Unified understanding and generation is a highly appealing research direction in multimodal learning. There exist two approaches: one trains a transformer via an auto-regressive paradigm, and the other adopts a two-stage scheme connecting pre-trained understanding and generative models for alignment fine-tuning. The former demands massive data and computing resources unaffordable for ordinary researchers. Though the latter requires a lower training cost, existing works often suffer from limited task coverage or poor generation quality. Both approaches lack the ability to parse input meta-information (such as task type, image resolution, video duration, etc.) and require manual parameter configuration that is tedious and non-intelligent. In this paper, we propose Unison which adopts the two-stage scheme while preserving the capabilities of the pre-trained models well. With an extremely low training cost, we cover a variety of multimodal understanding tasks, including text, image, and video understanding, as well as diverse generation tasks, such as text-to-visual content generation, editing, controllable generation, and IP-based reference generation. We also equip our model with the ability to automatically parse user intentions, determine the target task type, and accurately extract the meta-information required for the corresponding task. This enables full automation of various multimodal tasks without human intervention. Experiments demonstrate that, under a low-cost setting of only 500k training samples and 50 GPU hours, our model can accurately and automatically identify tasks and extract relevant parameters, and achieve superior performance across a variety of understanding and generation tasks.

</details>


### [286] [UltrasODM: A Dual Stream Optical Flow Mamba Network for 3D Freehand Ultrasound Reconstruction](https://arxiv.org/abs/2512.07756)
*Mayank Anand,Ujair Alam,Surya Prakash,Priya Shukla,Gora Chand Nandi,Domenec Puig*

Main category: cs.CV

TL;DR: UltrasODM是一个用于临床超声采集的双流框架，通过校准的逐帧不确定性、显著性诊断和可操作提示来辅助超声医师，减少重建误差并提高临床可靠性。


<details>
  <summary>Details</summary>
Motivation: 临床超声采集高度依赖操作者，快速探头运动和亮度波动常导致重建误差，降低信任度和临床效用。需要一种能够提供实时反馈和不确定性评估的系统来辅助超声医师。

Method: 提出UltrasODM双流框架：1) 基于运动相似性的对比排序模块对帧进行分组；2) 融合Dual-Mamba时序模块的光流流进行鲁棒的6自由度位姿估计；3) 人机交互层结合贝叶斯不确定性、临床校准阈值和显著性图，在不确定性超过阈值时发出非侵入性警报并提供纠正建议。

Result: 在临床自由手超声数据集上评估，相比UltrasOM，漂移减少15.2%，距离误差减少12.1%，Hausdorff距离减少10.1%，同时生成逐帧不确定性和显著性输出。

Conclusion: UltrasODM通过强调透明度和临床医师反馈，提高了重建可靠性，支持更安全、更可信的临床工作流程。该系统为超声采集提供了实用的辅助工具。

Abstract: Clinical ultrasound acquisition is highly operator-dependent, where rapid probe motion and brightness fluctuations often lead to reconstruction errors that reduce trust and clinical utility. We present UltrasODM, a dual-stream framework that assists sonographers during acquisition through calibrated per-frame uncertainty, saliency-based diagnostics, and actionable prompts. UltrasODM integrates (i) a contrastive ranking module that groups frames by motion similarity, (ii) an optical-flow stream fused with Dual-Mamba temporal modules for robust 6-DoF pose estimation, and (iii) a Human-in-the-Loop (HITL) layer combining Bayesian uncertainty, clinician-calibrated thresholds, and saliency maps highlighting regions of low confidence. When uncertainty exceeds the threshold, the system issues unobtrusive alerts suggesting corrective actions such as re-scanning highlighted regions or slowing the sweep. Evaluated on a clinical freehand ultrasound dataset, UltrasODM reduces drift by 15.2%, distance error by 12.1%, and Hausdorff distance by 10.1% relative to UltrasOM, while producing per-frame uncertainty and saliency outputs. By emphasizing transparency and clinician feedback, UltrasODM improves reconstruction reliability and supports safer, more trustworthy clinical workflows. Our code is publicly available at https://github.com/AnandMayank/UltrasODM.

</details>


### [287] [Modality-Aware Bias Mitigation and Invariance Learning for Unsupervised Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2512.07760)
*Menglin Wang,Xiaojin Gong,Jiachen Li,Genlin Ji*

Main category: cs.CV

TL;DR: 提出一种无监督可见光-红外行人重识别方法，通过模态感知Jaccard距离缓解模态差异，结合"分割-对比"策略学习模态不变表示，在基准数据集上取得SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 无监督可见光-红外行人重识别面临跨模态关联不可靠的挑战。现有方法使用最优传输关联模态内聚类，容易传播局部聚类错误，且忽略了全局实例级关系。

Method: 1) 提出模态感知Jaccard距离缓解模态差异引起的距离偏差，通过全局聚类估计更可靠的跨模态关联；2) 设计"分割-对比"策略获取模态特定全局原型，在全局关联指导下显式对齐这些原型。

Result: 在基准VI-ReID数据集上获得最先进的性能，显著优于现有方法，验证了方法的有效性。

Conclusion: 通过挖掘和关注可见光-红外模态偏差，从偏差缓解的全局关联和模态不变表示学习两方面解决跨模态学习问题，方法简单但有效。

Abstract: Unsupervised visible-infrared person re-identification (USVI-ReID) aims to match individuals across visible and infrared cameras without relying on any annotation. Given the significant gap across visible and infrared modality, estimating reliable cross-modality association becomes a major challenge in USVI-ReID. Existing methods usually adopt optimal transport to associate the intra-modality clusters, which is prone to propagating the local cluster errors, and also overlooks global instance-level relations. By mining and attending to the visible-infrared modality bias, this paper focuses on addressing cross-modality learning from two aspects: bias-mitigated global association and modality-invariant representation learning. Motivated by the camera-aware distance rectification in single-modality re-ID, we propose modality-aware Jaccard distance to mitigate the distance bias caused by modality discrepancy, so that more reliable cross-modality associations can be estimated through global clustering. To further improve cross-modality representation learning, a `split-and-contrast' strategy is designed to obtain modality-specific global prototypes. By explicitly aligning these prototypes under global association guidance, modality-invariant yet ID-discriminative representation learning can be achieved. While conceptually simple, our method obtains state-of-the-art performance on benchmark VI-ReID datasets and outperforms existing methods by a significant margin, validating its effectiveness.

</details>


### [288] [GorillaWatch: An Automated System for In-the-Wild Gorilla Re-Identification and Population Monitoring](https://arxiv.org/abs/2512.07776)
*Maximilian Schall,Felix Leonard Knöfel,Noah Elias König,Jan Jonas Kubeler,Maximilian von Klinski,Joan Wilhelm Linnemann,Xiaoshi Liu,Iven Jelle Schlegelmilch,Ole Woyciniuk,Alexandra Schild,Dante Wasmuht,Magdalena Bermejo Espinet,German Illera Basas,Gerard de Melo*

Main category: cs.CV

TL;DR: 提出了GorillaWatch系统，通过三个新数据集和端到端流程实现濒危西部低地大猩猩的自动化重识别，利用多帧自监督预训练和注意力解释性验证，在种群计数方面也有创新。


<details>
  <summary>Details</summary>
Motivation: 目前监测濒危西部低地大猩猩面临巨大挑战，需要从大量相机陷阱视频中手动重识别个体，自动化过程缺乏大规模野外视频数据集来训练深度学习模型。

Method: 1) 创建三个新数据集：Gorilla-SPAC-Wild（最大野外灵长类重识别数据集）、Gorilla-Berlin-Zoo（跨域泛化评估）、Gorilla-SPAC-MoT（多目标跟踪评估）；2) 开发GorillaWatch端到端流程，集成检测、跟踪和重识别；3) 提出多帧自监督预训练策略，利用轨迹一致性学习领域特征；4) 使用可微分的AttnLRP验证模型依赖生物特征而非背景；5) 将时空约束集成到标准聚类中以解决无监督种群计数。

Result: 大规模图像骨干网络的特征聚合优于专用视频架构；提出的方法在重识别和种群计数方面表现优异；所有代码和数据集已公开，支持濒危物种的可扩展非侵入式监测。

Conclusion: 该研究通过创建大规模数据集和端到端系统，显著推进了濒危大猩猩的自动化监测，自监督学习和解释性验证确保了科学有效性，公开资源将促进保护生物学的发展。

Abstract: Monitoring critically endangered western lowland gorillas is currently hampered by the immense manual effort required to re-identify individuals from vast archives of camera trap footage. The primary obstacle to automating this process has been the lack of large-scale, "in-the-wild" video datasets suitable for training robust deep learning models. To address this gap, we introduce a comprehensive benchmark with three novel datasets: Gorilla-SPAC-Wild, the largest video dataset for wild primate re-identification to date; Gorilla-Berlin-Zoo, for assessing cross-domain re-identification generalization; and Gorilla-SPAC-MoT, for evaluating multi-object tracking in camera trap footage. Building on these datasets, we present GorillaWatch, an end-to-end pipeline integrating detection, tracking, and re-identification. To exploit temporal information, we introduce a multi-frame self-supervised pretraining strategy that leverages consistency in tracklets to learn domain-specific features without manual labels. To ensure scientific validity, a differentiable adaptation of AttnLRP verifies that our model relies on discriminative biometric traits rather than background correlations. Extensive benchmarking subsequently demonstrates that aggregating features from large-scale image backbones outperforms specialized video architectures. Finally, we address unsupervised population counting by integrating spatiotemporal constraints into standard clustering to mitigate over-segmentation. We publicly release all code and datasets to facilitate scalable, non-invasive monitoring of endangered species

</details>


### [289] [Distribution Matching Variational AutoEncoder](https://arxiv.org/abs/2512.07778)
*Sen Ye,Jianning Pei,Mengde Xu,Shuyang Gu,Chunyu Wang,Liwei Wang,Han Hu*

Main category: cs.CV

TL;DR: DMVAE通过显式匹配任意参考分布来优化VAE的潜在空间，发现自监督学习特征分布能平衡重建保真度和建模效率，在ImageNet上仅用64个训练周期就达到gFID=3.2。


<details>
  <summary>Details</summary>
Motivation: 现有视觉生成模型（如VAE和基础模型对齐编码器）隐式约束潜在空间而不显式塑造其分布，导致不清楚哪种分布最适合建模。需要明确研究哪种潜在分布结构对建模更有利。

Method: 提出Distribution-Matching VAE (DMVAE)，通过分布匹配约束显式将编码器的潜在分布与任意参考分布对齐，超越传统VAE的高斯先验，可与自监督特征、扩散噪声或其他先验分布对齐。

Result: 自监督学习（SSL）导出的分布在重建保真度和建模效率之间提供了最佳平衡，在ImageNet上仅用64个训练周期就达到gFID=3.2，优于传统方法。

Conclusion: 选择合适的潜在分布结构（通过分布级对齐实现）而非依赖固定先验，是弥合易于建模的潜在空间和高保真图像合成之间差距的关键。

Abstract: Most visual generative models compress images into a latent space before applying diffusion or autoregressive modelling. Yet, existing approaches such as VAEs and foundation model aligned encoders implicitly constrain the latent space without explicitly shaping its distribution, making it unclear which types of distributions are optimal for modeling. We introduce \textbf{Distribution-Matching VAE} (\textbf{DMVAE}), which explicitly aligns the encoder's latent distribution with an arbitrary reference distribution via a distribution matching constraint. This generalizes beyond the Gaussian prior of conventional VAEs, enabling alignment with distributions derived from self-supervised features, diffusion noise, or other prior distributions. With DMVAE, we can systematically investigate which latent distributions are more conducive to modeling, and we find that SSL-derived distributions provide an excellent balance between reconstruction fidelity and modeling efficiency, reaching gFID equals 3.2 on ImageNet with only 64 training epochs. Our results suggest that choosing a suitable latent distribution structure (achieved via distribution-level alignment), rather than relying on fixed priors, is key to bridging the gap between easy-to-model latents and high-fidelity image synthesis. Code is avaliable at https://github.com/sen-ye/dmvae.

</details>


### [290] [OneStory: Coherent Multi-Shot Video Generation with Adaptive Memory](https://arxiv.org/abs/2512.07802)
*Zhaochong An,Menglin Jia,Haonan Qiu,Zijian Zhou,Xiaoke Huang,Zhiheng Liu,Weiming Ren,Kumara Kahatapitiya,Ding Liu,Sen He,Chenyang Zhang,Tao Xiang,Fanny Yang,Serge Belongie,Tian Xie*

Main category: cs.CV

TL;DR: OneStory提出了一种新的多镜头视频生成方法，通过全局跨镜头上下文建模实现连贯的叙事生成，将MSV重构为下一个镜头生成任务，并引入帧选择和自适应条件模块来构建紧凑的全局记忆。


<details>
  <summary>Details</summary>
Motivation: 现有多镜头视频生成方法难以有效建模长距离跨镜头上下文，因为它们依赖有限的时间窗口或单关键帧条件，导致在复杂叙事下性能下降。需要一种能够全局建模跨镜头上下文的方法来实现一致且可扩展的叙事生成。

Method: 将多镜头视频生成重构为下一个镜头生成任务，利用预训练图像到视频模型进行视觉条件化。引入两个关键模块：1) 帧选择模块：基于先前镜头中的信息丰富帧构建语义相关的全局记忆；2) 自适应条件模块：执行重要性引导的块化处理，生成用于直接条件化的紧凑上下文。此外，策划了高质量的多镜头数据集并设计了有效的训练策略。

Result: 在策划的60K数据集上从预训练I2V模型微调后，OneStory在文本和图像条件设置下，在多样化和复杂场景中实现了最先进的叙事连贯性，能够进行可控且沉浸式的长视频叙事。

Conclusion: OneStory通过全局而紧凑的跨镜头上下文建模，实现了连贯且可扩展的叙事生成，解决了现有方法在复杂叙事中的局限性，为长视频叙事提供了有效的解决方案。

Abstract: Storytelling in real-world videos often unfolds through multiple shots -- discontinuous yet semantically connected clips that together convey a coherent narrative. However, existing multi-shot video generation (MSV) methods struggle to effectively model long-range cross-shot context, as they rely on limited temporal windows or single keyframe conditioning, leading to degraded performance under complex narratives. In this work, we propose OneStory, enabling global yet compact cross-shot context modeling for consistent and scalable narrative generation. OneStory reformulates MSV as a next-shot generation task, enabling autoregressive shot synthesis while leveraging pretrained image-to-video (I2V) models for strong visual conditioning. We introduce two key modules: a Frame Selection module that constructs a semantically-relevant global memory based on informative frames from prior shots, and an Adaptive Conditioner that performs importance-guided patchification to generate compact context for direct conditioning. We further curate a high-quality multi-shot dataset with referential captions to mirror real-world storytelling patterns, and design effective training strategies under the next-shot paradigm. Finetuned from a pretrained I2V model on our curated 60K dataset, OneStory achieves state-of-the-art narrative coherence across diverse and complex scenes in both text- and image-conditioned settings, enabling controllable and immersive long-form video storytelling.

</details>


### [291] [Multi-view Pyramid Transformer: Look Coarser to See Broader](https://arxiv.org/abs/2512.07806)
*Gyeongjin Kang,Seungkwon Yang,Seungtae Nam,Younggeun Lee,Jungwoo Kim,Eunbyung Park*

Main category: cs.CV

TL;DR: MVP是一种可扩展的多视角Transformer架构，能够一次性处理数十到数百张图像直接重建大型3D场景，通过局部到全局的层次结构实现高效且高质量的重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理大规模多视角图像重建大型3D场景时面临计算效率和可扩展性挑战，需要一种能够同时处理大量输入图像并保持高质量重建的方法。

Method: 提出多视角金字塔Transformer（MVP），基于两个核心设计原则：1）局部到全局的视图间层次结构，从局部视图逐步扩展到组视图再到完整场景；2）细粒度到粗粒度的视图内层次结构，从详细空间表示逐步聚合为紧凑的信息密集token。

Result: MVP在多个数据集上验证，当与3D高斯泼溅作为底层3D表示结合时，实现了最先进的可泛化重建质量，同时在各种视图配置下保持高效率和可扩展性。

Conclusion: MVP通过双层次结构设计成功解决了大规模3D场景重建中的计算效率和表示丰富性之间的平衡问题，为高效处理大量多视角图像提供了有效解决方案。

Abstract: We propose Multi-view Pyramid Transformer (MVP), a scalable multi-view transformer architecture that directly reconstructs large 3D scenes from tens to hundreds of images in a single forward pass. Drawing on the idea of ``looking broader to see the whole, looking finer to see the details," MVP is built on two core design principles: 1) a local-to-global inter-view hierarchy that gradually broadens the model's perspective from local views to groups and ultimately the full scene, and 2) a fine-to-coarse intra-view hierarchy that starts from detailed spatial representations and progressively aggregates them into compact, information-dense tokens. This dual hierarchy achieves both computational efficiency and representational richness, enabling fast reconstruction of large and complex scenes. We validate MVP on diverse datasets and show that, when coupled with 3D Gaussian Splatting as the underlying 3D representation, it achieves state-of-the-art generalizable reconstruction quality while maintaining high efficiency and scalability across a wide range of view configurations.

</details>


### [292] [Lang3D-XL: Language Embedded 3D Gaussians for Large-scale Scenes](https://arxiv.org/abs/2512.07807)
*Shai Krakovsky,Gal Fiebelman,Sagie Benaim,Hadar Averbuch-Elor*

Main category: cs.CV

TL;DR: 提出一种在3D高斯表示中嵌入语言场的方法，通过极低维语义瓶颈特征和多分辨率哈希编码器提高效率，并引入衰减下采样器和正则化解决语义特征对齐问题。


<details>
  <summary>Details</summary>
Motivation: 在3D表示中嵌入语言场可以实现更丰富的空间环境语义理解，连接几何与描述性意义，支持自然语言查询和编辑场景，改善场景检索、导航和多模态推理等任务。但现有特征蒸馏方法在处理大规模互联网数据时面临语义特征错位和内存运行时效率低下的挑战。

Method: 1. 在底层3D高斯表示中引入极低维语义瓶颈特征；2. 通过渲染和多分辨率基于特征的哈希编码器处理这些特征，显著提高运行时和GPU内存效率；3. 引入衰减下采样器模块并提出多种正则化方法解决真实2D特征的语义对齐问题。

Result: 在真实世界HolyScenes数据集上评估，该方法在性能和效率方面均超越现有方法。

Conclusion: 提出的方法有效解决了大规模场景中语言场嵌入的语义特征对齐和效率问题，为更直观的人机交互和丰富的空间语义理解提供了可行方案。

Abstract: Embedding a language field in a 3D representation enables richer semantic understanding of spatial environments by linking geometry with descriptive meaning. This allows for a more intuitive human-computer interaction, enabling querying or editing scenes using natural language, and could potentially improve tasks like scene retrieval, navigation, and multimodal reasoning. While such capabilities could be transformative, in particular for large-scale scenes, we find that recent feature distillation approaches cannot effectively learn over massive Internet data due to challenges in semantic feature misalignment and inefficiency in memory and runtime. To this end, we propose a novel approach to address these challenges. First, we introduce extremely low-dimensional semantic bottleneck features as part of the underlying 3D Gaussian representation. These are processed by rendering and passing them through a multi-resolution, feature-based, hash encoder. This significantly improves efficiency both in runtime and GPU memory. Second, we introduce an Attenuated Downsampler module and propose several regularizations addressing the semantic misalignment of ground truth 2D features. We evaluate our method on the in-the-wild HolyScenes dataset and demonstrate that it surpasses existing approaches in both performance and efficiency.

</details>


### [293] [WorldReel: 4D Video Generation with Consistent Geometry and Motion Modeling](https://arxiv.org/abs/2512.07821)
*Shaoheng Fang,Hanwen Jiang,Yunpeng Bai,Niloy J. Mitra,Qixing Huang*

Main category: cs.CV

TL;DR: WorldReel是一个4D视频生成器，通过联合生成RGB帧和4D场景表示（点云图、相机轨迹、密集流映射），实现原生时空一致性，解决了现有视频生成器在3D不一致性的问题。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成器虽然实现了逼真的视觉效果，但在3D一致性方面存在根本性不足。需要开发能够保持时空一致性的视频生成方法，以实现更真实的动态场景和相机运动。

Method: 提出WorldReel框架，联合生成RGB帧和4D场景表示（点云图、相机轨迹、密集流映射）。通过显式的4D表示强制保持底层场景的一致性。训练时结合合成数据（提供精确的4D监督）和真实视频数据（提供视觉多样性和真实感）。

Result: WorldReel在动态场景和移动相机视频生成方面达到了新的最先进水平，显著改善了几何一致性、运动连贯性指标，并减少了视角-时间伪影。能够泛化到野外拍摄的视频，同时保持强大的几何保真度。

Conclusion: WorldReel将视频生成推向4D一致的世界建模，使智能体能够通过单一稳定的时空表示来渲染、交互和推理场景，为实现更真实的视频生成和场景理解奠定了基础。

Abstract: Recent video generators achieve striking photorealism, yet remain fundamentally inconsistent in 3D. We present WorldReel, a 4D video generator that is natively spatio-temporally consistent. WorldReel jointly produces RGB frames together with 4D scene representations, including pointmaps, camera trajectory, and dense flow mapping, enabling coherent geometry and appearance modeling over time. Our explicit 4D representation enforces a single underlying scene that persists across viewpoints and dynamic content, yielding videos that remain consistent even under large non-rigid motion and significant camera movement. We train WorldReel by carefully combining synthetic and real data: synthetic data providing precise 4D supervision (geometry, motion, and camera), while real videos contribute visual diversity and realism. This blend allows WorldReel to generalize to in-the-wild footage while preserving strong geometric fidelity. Extensive experiments demonstrate that WorldReel sets a new state-of-the-art for consistent video generation with dynamic scenes and moving cameras, improving metrics of geometric consistency, motion coherence, and reducing view-time artifacts over competing methods. We believe that WorldReel brings video generation closer to 4D-consistent world modeling, where agents can render, interact, and reason about scenes through a single and stable spatiotemporal representation.

</details>


### [294] [OpenVE-3M: A Large-Scale High-Quality Dataset for Instruction-Guided Video Editing](https://arxiv.org/abs/2512.07826)
*Haoyang He,Jie Wang,Jiangning Zhang,Zhucun Xue,Xingyuan Bu,Qiangpeng Yang,Shilei Wen,Lei Xie*

Main category: cs.CV

TL;DR: OpenVE-3M是一个开源的大规模高质量视频编辑指令数据集，包含空间对齐和非空间对齐两类编辑任务，并构建了OpenVE-Bench基准测试，训练出的OpenVE-Edit模型在基准测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 当前基于指令的图像编辑数据集质量和多样性不断提升，但大规模、高质量的视频编辑指令数据集仍然稀缺，需要填补这一空白。

Method: 1. 构建OpenVE-3M数据集：包含空间对齐编辑（全局风格、背景变化、局部变化/移除/添加、字幕编辑）和非空间对齐编辑（相机多镜头编辑、创意编辑）；2. 通过精心设计的数据流水线生成所有编辑类型并进行严格质量过滤；3. 构建OpenVE-Bench基准测试，包含431个视频编辑对，涵盖多样化编辑任务；4. 训练OpenVE-Edit模型（5B参数）。

Result: 1. OpenVE-3M在规模、编辑类型多样性、指令长度和整体质量上超越现有开源数据集；2. OpenVE-Bench提供了统一的评估基准；3. OpenVE-Edit模型在OpenVE-Bench上达到新的SOTA，超越了包括14B基线在内的所有先前开源模型。

Conclusion: OpenVE-3M填补了视频编辑指令数据集的空白，OpenVE-Bench为领域提供了统一评估标准，OpenVE-Edit模型展示了卓越的效率和效果，为视频编辑研究提供了重要资源。

Abstract: The quality and diversity of instruction-based image editing datasets are continuously increasing, yet large-scale, high-quality datasets for instruction-based video editing remain scarce. To address this gap, we introduce OpenVE-3M, an open-source, large-scale, and high-quality dataset for instruction-based video editing. It comprises two primary categories: spatially-aligned edits (Global Style, Background Change, Local Change, Local Remove, Local Add, and Subtitles Edit) and non-spatially-aligned edits (Camera Multi-Shot Edit and Creative Edit). All edit types are generated via a meticulously designed data pipeline with rigorous quality filtering. OpenVE-3M surpasses existing open-source datasets in terms of scale, diversity of edit types, instruction length, and overall quality. Furthermore, to address the lack of a unified benchmark in the field, we construct OpenVE-Bench, containing 431 video-edit pairs that cover a diverse range of editing tasks with three key metrics highly aligned with human judgment. We present OpenVE-Edit, a 5B model trained on our dataset that demonstrates remarkable efficiency and effectiveness by setting a new state-of-the-art on OpenVE-Bench, outperforming all prior open-source models including a 14B baseline. Project page is at https://github.com/lewandofskee/OpenVE.

</details>


### [295] [One Layer Is Enough: Adapting Pretrained Visual Encoders for Image Generation](https://arxiv.org/abs/2512.07829)
*Yuan Gao,Chen Chen,Tianrong Chen,Jiatao Gu*

Main category: cs.CV

TL;DR: FAE提出了一种简单有效的框架，将预训练视觉表征适配到适合生成的低维潜在空间，仅需单个注意力层，同时保持重建和理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以将理解导向的预训练视觉表征适配到生成友好的潜在空间，因为表征编码器需要高维潜在空间来捕捉多样假设，而生成模型需要低维潜在空间来保持注入噪声的保真度。

Method: FAE使用两个独立的深度解码器：一个训练用于重建原始特征空间，另一个将重建特征作为输入进行图像生成。该方法通用，可与多种自监督编码器和生成模型结合。

Result: 在ImageNet 256x256上，FAE扩散模型在800轮训练后达到接近SOTA的FID 1.29（使用CFG）和SOTA的FID 1.48（不使用CFG），在80轮训练后也表现优异。

Conclusion: FAE提供了一种简单而有效的方法来桥接理解导向特征和生成友好潜在空间之间的差距，在保持高质量的同时实现快速学习。

Abstract: Visual generative models (e.g., diffusion models) typically operate in compressed latent spaces to balance training efficiency and sample quality. In parallel, there has been growing interest in leveraging high-quality pre-trained visual representations, either by aligning them inside VAEs or directly within the generative model. However, adapting such representations remains challenging due to fundamental mismatches between understanding-oriented features and generation-friendly latent spaces. Representation encoders benefit from high-dimensional latents that capture diverse hypotheses for masked regions, whereas generative models favor low-dimensional latents that must faithfully preserve injected noise. This discrepancy has led prior work to rely on complex objectives and architectures. In this work, we propose FAE (Feature Auto-Encoder), a simple yet effective framework that adapts pre-trained visual representations into low-dimensional latents suitable for generation using as little as a single attention layer, while retaining sufficient information for both reconstruction and understanding. The key is to couple two separate deep decoders: one trained to reconstruct the original feature space, and a second that takes the reconstructed features as input for image generation. FAE is generic; it can be instantiated with a variety of self-supervised encoders (e.g., DINO, SigLIP) and plugged into two distinct generative families: diffusion models and normalizing flows. Across class-conditional and text-to-image benchmarks, FAE achieves strong performance. For example, on ImageNet 256x256, our diffusion model with CFG attains a near state-of-the-art FID of 1.29 (800 epochs) and 1.70 (80 epochs). Without CFG, FAE reaches the state-of-the-art FID of 1.48 (800 epochs) and 2.08 (80 epochs), demonstrating both high quality and fast learning.

</details>


### [296] [UnityVideo: Unified Multi-Modal Multi-Task Learning for Enhancing World-Aware Video Generation](https://arxiv.org/abs/2512.07831)
*Jiehui Huang,Yuechen Zhang,Xu He,Yuan Gao,Zhi Cen,Bin Xia,Yan Zhou,Xin Tao,Pengfei Wan,Jiaya Jia*

Main category: cs.CV

TL;DR: UnityVideo是一个统一的多模态视频生成框架，通过联合学习多种模态（分割掩码、人体骨架、DensePose、光流、深度图）和训练范式，提升世界感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型受限于单模态条件，缺乏跨模态交互和模态多样性，限制了其对世界的全面理解能力。

Method: 提出两个核心组件：1）动态加噪统一异构训练范式；2）模态切换器和上下文学习器，通过模块化参数和上下文学习实现统一处理。构建了130万样本的大规模统一数据集。

Result: 联合优化加速了收敛，显著提升了零样本泛化能力。UnityVideo在视频质量、一致性和物理世界约束对齐方面表现优异。

Conclusion: UnityVideo通过统一多模态学习框架，解决了现有视频生成模型的世界感知限制，实现了更全面、更一致的世界感知视频生成。

Abstract: Recent video generation models demonstrate impressive synthesis capabilities but remain limited by single-modality conditioning, constraining their holistic world understanding. This stems from insufficient cross-modal interaction and limited modal diversity for comprehensive world knowledge representation. To address these limitations, we introduce UnityVideo, a unified framework for world-aware video generation that jointly learns across multiple modalities (segmentation masks, human skeletons, DensePose, optical flow, and depth maps) and training paradigms. Our approach features two core components: (1) dynamic noising to unify heterogeneous training paradigms, and (2) a modality switcher with an in-context learner that enables unified processing via modular parameters and contextual learning. We contribute a large-scale unified dataset with 1.3M samples. Through joint optimization, UnityVideo accelerates convergence and significantly enhances zero-shot generalization to unseen data. We demonstrate that UnityVideo achieves superior video quality, consistency, and improved alignment with physical world constraints. Code and data can be found at: https://github.com/dvlab-research/UnityVideo

</details>


### [297] [Relational Visual Similarity](https://arxiv.org/abs/2512.07833)
*Thao Nguyen,Sicheng Mo,Krishna Kumar Singh,Yilin Wang,Jing Shi,Nicholas Kolkin,Eli Shechtman,Yong Jae Lee,Yuheng Li*

Main category: cs.CV

TL;DR: 该论文提出了关系相似性（relational similarity）的概念，指出现有视觉相似性度量只关注感知属性相似性，而人类还能识别图像之间的深层关系结构相似性。作者构建了匿名化描述关系逻辑的数据集，并微调视觉语言模型来测量图像间的关系相似性。


<details>
  <summary>Details</summary>
Motivation: 人类不仅能感知属性相似性（如颜色、形状），还能识别关系相似性（如地球与桃子的层次结构对应）。现有视觉相似性度量（LPIPS、CLIP、DINO等）只关注表面属性相似性，无法捕捉人类感知的丰富关系相似性。这揭示了视觉计算中的一个关键差距。

Method: 1. 将关系图像相似性形式化为可测量问题：当两幅图像的视觉元素之间的内部关系或功能对应时，即使视觉属性不同，它们也具有关系相似性。
2. 构建包含114k图像-标题的数据集，其中标题经过匿名化处理，描述场景的底层关系逻辑而非表面内容。
3. 使用该数据集微调视觉语言模型，以测量图像间的关系相似性。

Result: 开发了首个能够测量图像关系相似性的模型，该模型基于图像底层关系结构而非可见外观来连接图像。研究表明，关系相似性具有许多实际应用，但现有图像相似性模型无法捕捉它。

Conclusion: 关系相似性是视觉理解的一个重要维度，现有视觉相似性度量存在显著局限。通过构建关系相似性数据集和微调模型，该研究为基于关系结构而非表面外观的图像相似性评估迈出了第一步，揭示了视觉计算中需要填补的关键空白。

Abstract: Humans do not just see attribute similarity -- we also see relational similarity. An apple is like a peach because both are reddish fruit, but the Earth is also like a peach: its crust, mantle, and core correspond to the peach's skin, flesh, and pit. This ability to perceive and recognize relational similarity, is arguable by cognitive scientist to be what distinguishes humans from other species. Yet, all widely used visual similarity metrics today (e.g., LPIPS, CLIP, DINO) focus solely on perceptual attribute similarity and fail to capture the rich, often surprising relational similarities that humans perceive. How can we go beyond the visible content of an image to capture its relational properties? How can we bring images with the same relational logic closer together in representation space? To answer these questions, we first formulate relational image similarity as a measurable problem: two images are relationally similar when their internal relations or functions among visual elements correspond, even if their visual attributes differ. We then curate 114k image-caption dataset in which the captions are anonymized -- describing the underlying relational logic of the scene rather than its surface content. Using this dataset, we finetune a Vision-Language model to measure the relational similarity between images. This model serves as the first step toward connecting images by their underlying relational structure rather than their visible appearance. Our study shows that while relational similarity has a lot of real-world applications, existing image similarity models fail to capture it -- revealing a critical gap in visual computing.

</details>


### [298] [Voxify3D: Pixel Art Meets Volumetric Rendering](https://arxiv.org/abs/2512.07834)
*Yi-Chuan Huang,Jiewen Chan,Hao-Jen Chien,Yu-Lun Liu*

Main category: cs.CV

TL;DR: Voxify3D：一个可微分的两阶段框架，通过正交像素艺术监督、基于补丁的CLIP对齐和调色板约束的Gumbel-Softmax量化，从3D网格生成高质量体素艺术


<details>
  <summary>Details</summary>
Motivation: 体素艺术在游戏和数字媒体中广泛应用，但从3D网格自动生成面临几何抽象、语义保持和离散颜色一致性之间的冲突。现有方法要么过度简化几何，要么无法达到像素级精确、调色板约束的体素艺术美学。

Method: 提出Voxify3D框架，包含三个核心组件：1）正交像素艺术监督消除透视畸变，实现体素-像素精确对齐；2）基于补丁的CLIP对齐在不同离散化级别保持语义；3）调色板约束的Gumbel-Softmax量化，在离散颜色空间上进行可微分优化，支持可控调色板策略。

Result: 实验显示优越性能（37.12 CLIP-IQA，77.90%用户偏好），适用于多样化角色和可控抽象（2-8种颜色，20x-50x分辨率）。

Conclusion: Voxify3D通过协同整合三个组件，解决了极端离散化下的语义保持、通过体积渲染实现像素艺术美学以及端到端离散优化等基本挑战，实现了高质量的体素艺术生成。

Abstract: Voxel art is a distinctive stylization widely used in games and digital media, yet automated generation from 3D meshes remains challenging due to conflicting requirements of geometric abstraction, semantic preservation, and discrete color coherence. Existing methods either over-simplify geometry or fail to achieve the pixel-precise, palette-constrained aesthetics of voxel art. We introduce Voxify3D, a differentiable two-stage framework bridging 3D mesh optimization with 2D pixel art supervision. Our core innovation lies in the synergistic integration of three components: (1) orthographic pixel art supervision that eliminates perspective distortion for precise voxel-pixel alignment; (2) patch-based CLIP alignment that preserves semantics across discretization levels; (3) palette-constrained Gumbel-Softmax quantization enabling differentiable optimization over discrete color spaces with controllable palette strategies. This integration addresses fundamental challenges: semantic preservation under extreme discretization, pixel-art aesthetics through volumetric rendering, and end-to-end discrete optimization. Experiments show superior performance (37.12 CLIP-IQA, 77.90\% user preference) across diverse characters and controllable abstraction (2-8 colors, 20x-50x resolutions). Project page: https://yichuanh.github.io/Voxify-3D/

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [299] [Vec-LUT: Vector Table Lookup for Parallel Ultra-Low-Bit LLM Inference on Edge Devices](https://arxiv.org/abs/2512.06443)
*Xiangyu Li,Chengyu Yin,Weijun Wang,Jianyu Wei,Ting Cao,Yunxin Liu*

Main category: cs.DC

TL;DR: 提出向量查找表（Vec-LUT）方法，解决标量LUT在并行推理中内存带宽利用不足的问题，在边缘设备上实现高达4.2倍的性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型部署到边缘设备，量化技术已发展到1.58位。虽然基于查找表（LUT）的推理使CPU运行超低位模型比NPU更快，但标量LUT范式在并行推理（如预填充、测试时缩放等场景）中存在内存带宽利用不足的问题，因为每个token都需要重复且非连续的内存访问。

Method: 提出向量查找表（Vec-LUT）新范式：1）构建跨并行token的统一查找表，执行单次1→N查找；2）引入向量LUT中心张量布局；3）采用缓存感知流式查找技术。该方法已集成到llama.cpp中。

Result: 在5个边缘设备和3个大语言模型上的评估显示，Vec-LUT比现有最优基线方法性能提升高达4.2倍。

Conclusion: 向量查找表范式有效解决了标量LUT在并行推理中的内存带宽利用不足问题，为边缘设备上的大语言模型部署提供了更高效的推理方案。

Abstract: Large language models (LLMs) are increasingly deployed on edge devices. To meet strict resource constraints, real-world deployment has pushed LLM quantization from 8-bit to 4-bit, 2-bit, and now 1.58-bit. Combined with lookup table (LUT)-based inference, CPUs run these ultra-low-bit LLMs even faster than NPUs, opening new opportunities for ubiquitous on-device intelligence.
  However, this paper identifies that LUT-based inference underutilizes memory bandwidth during parallel inference, which is required for prefilling, test-time scaling, and other multi-token scenarios. The root cause is the scalar LUT paradigm, which performs repetitive and non-contiguous memory accesses for each token.
  To solve the issue, we propose vector LUT, a new lookup paradigm that constructs a unified LUT across parallel tokens, and performs a single $1 \rightarrow N$ lookup per index. To realize it efficiently, we further introduce (1) Vector LUT-Centric Tensor Layout, and (2) Cache-Aware Streamed Lookup techniques. Evaluations on 5 edge devices across 3 LLMs show that Vec-LUT outperforms state-of-the-art baselines by up to $4.2\times$. Our implementation is integrated into llama.cpp. The code is available at https://github.com/Cipherxzc/vlut.cpp.

</details>


### [300] [Stable-MoE: Lyapunov-based Token Routing for Distributed Mixture-of-Experts Training over Edge Networks](https://arxiv.org/abs/2512.06784)
*Long Shi,Bingyan Ou,Kang Wei,Weihao Zhu,Zhe Wang,Zhiyong Chen*

Main category: cs.DC

TL;DR: 提出基于Lyapunov优化的令牌路由框架Stable-MoE，用于资源异构边缘网络中的分布式MoE训练，解决传统方法在资源受限边缘环境中的工作负载积压、资源效率低下和性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 传统MoE模型的令牌路由在分布式训练中面临资源受限边缘网络的挑战，包括异构计算能力和随机令牌到达，导致工作负载积压、资源效率低下和性能下降。

Method: 提出Lyapunov-based令牌路由框架Stable-MoE，将长期随机优化问题转化为可处理的每时隙子问题，在线决策令牌路由和计算频率利用，无需未来系统状态知识。

Result: 在SVHN和CIFAR-100数据集上的实验结果表明，Stable-MoE在系统吞吐量和测试准确率上分别比基线方法至少提升40%和5%。

Conclusion: Stable-MoE框架有效解决了资源异构边缘网络中分布式MoE训练的挑战，通过Lyapunov优化实现了系统吞吐量和门控一致性的最大化，同时保证了边缘设备令牌和能量队列的长期稳定性。

Abstract: The sparse activation mechanism of mixture of experts (MoE) model empowers edge intelligence with enhanced training efficiency and reduced computational resource consumption. However, traditional token routing in distributed MoE training faces significant challenges in resource-constrained edge networks characterized by heterogeneous computing capabilities and stochastic token arrivals, which inevitably suffer from workload backlog, resource inefficiency, and performance degradation. To address this issue, we propose a novel Lyapunov-based token routing framework for distributed MoE training over resource-heterogeneous edge networks, termed Stable-MoE. Specifically, we formulate a stochastic optimization problem to maximize both system throughput and gating consistency via optimizing the token routing strategy and computational resource allocation, while ensuring long-term stability of both token and energy queues at the edge devices. Using the Lyapunov optimization, we transform the intractable long-term optimization problem into tractable per-slot subproblems by enabling online decision-making of token routing and computation frequency utilization without the knowledge of future system states. Experimental results on the SVHN and CIFAR-100 datasets demonstrate that Stable-MoE outperforms the baselines with at least 40% and 5% gains in system throughput and test accuracy, respectively.

</details>


### [301] [Cloud Revolution: Tracing the Origins and Rise of Cloud Computing](https://arxiv.org/abs/2512.06800)
*Deepa Gurung,S M Zia Ur Rashid,Zain ul Abdeen,Suman Rath*

Main category: cs.DC

TL;DR: 本文重新审视云计算的历史演变，从虚拟化、分布式系统等技术发展到现代全球云生态系统，分析技术经济力量如何改变组织计算习惯，并探讨当前局限性与未来趋势。


<details>
  <summary>Details</summary>
Motivation: 重新审视云计算领域的历史演变，理解其从基础技术发展到广泛应用的完整历程，分析技术经济力量如何塑造现代计算范式，并识别当前挑战与未来发展方向。

Method: 采用历史分析方法，追溯云计算从资源共享、效用计算到超大规模数据中心和全球联邦云生态系统的发展历程，结合技术经济力量分析，并考察当前局限性与新兴趋势。

Result: 云计算经历了数十年技术演进，从虚拟化、分布式系统等技术基础发展为改变组织计算习惯的全球生态系统，降低了数据密集和计算密集型应用的门槛，但也带来了安全配置、监管依赖和供应商锁定等挑战。

Conclusion: 云计算是一个快速变化的范式，其未来发展方向需要在可扩展性、开放性和信任之间取得平衡，边缘计算与云基础设施融合、AI优化架构和量子计算服务等新兴趋势将重塑云环境。

Abstract: The history behind the development of cloud computing is more than several decades of technological progress in the fields of virtualization, distributed systems, and high-speed networking, but its current application is much broader than the underlying technologies that made it possible. This paper reexamines the historical evolution of the field, including the initial ideas of resource sharing and utility-based computing approaches and the development of hyperscale data centers and modern globally federated cloud ecosystems. We also analyze the technological and economic forces and point to the way cloud platforms altered the organizational computing habits, decreasing the entrance-level to the data-intensive and computation-heavy apps. The study also takes into account the ongoing limitations which have come with the large-scale adoption of clouds which include exposure to security due to the weaknesses in configuration, particular establishment regulations, and structural reliance on the single vendors. Lastly, we address some of the new trends that are transforming the cloud environment, including the convergence of edge and cloud infrastructure, the increased prominence of AI-optimised architectures and the initial adoption of quantum computing services. Collectively, the developments above describe an emerging but quickly changing paradigm with its future direction being determined by a strike of balancing between scalability, openness, and trust.

</details>


### [302] [Optimizing video analytics inference pipelines: a case study](https://arxiv.org/abs/2512.07009)
*Saeid Ghafouri,Yuming Ding,Katerine Diaz Chito,Jesús Martinez del Rincón,Niamh O'Connell,Hans Vandierendonck*

Main category: cs.DC

TL;DR: 通过系统级优化（多级并行化、GPU加速、向量化聚类、内存高效后处理）实现家禽福利监测系统2倍加速，不损失准确性


<details>
  <summary>Details</summary>
Motivation: 商业农场的高分辨率视频和近实时监测需求产生巨大计算负载，需要成本效益高且可扩展的视频分析解决方案

Method: 在检测、跟踪、聚类和行为分析模块进行系统级改进，包括多级并行化、CPU代码替换为GPU加速代码、向量化聚类和内存高效后处理

Result: 在真实农场视频数据上评估，优化使整个流水线获得高达2倍的速度提升，且不损害模型准确性

Conclusion: 研究为构建高吞吐量、低延迟的视频推理系统提供了实用策略，可降低农业和智能传感部署以及其他大规模视频分析应用的基础设施需求

Abstract: Cost-effective and scalable video analytics are essential for precision livestock monitoring, where high-resolution footage and near-real-time monitoring needs from commercial farms generates substantial computational workloads. This paper presents a comprehensive case study on optimizing a poultry welfare monitoring system through system-level improvements across detection, tracking, clustering, and behavioral analysis modules. We introduce a set of optimizations, including multi-level parallelization, Optimizing code with substituting CPU code with GPU-accelerated code, vectorized clustering, and memory-efficient post-processing. Evaluated on real-world farm video footage, these changes deliver up to a 2x speedup across pipelines without compromising model accuracy. Our findings highlight practical strategies for building high-throughput, low-latency video inference systems that reduce infrastructure demands in agricultural and smart sensing deployments as well as other large-scale video analytics applications.

</details>


### [303] [PIR-DSN: A Decentralized Storage Network Supporting Private Information Retrieval](https://arxiv.org/abs/2512.07189)
*Jiahao Zhang,Minghui Xu,Hechuan Guo,Xiuzhen Cheng*

Main category: cs.DC

TL;DR: PIR-DSN：首个在去中心化存储网络中集成私有信息检索（PIR）的协议，通过安全映射和文件复制技术，在保证文件操作公开可验证的同时实现高效隐私检索。


<details>
  <summary>Details</summary>
Motivation: 去中心化存储网络（DSNs）作为Web 3.0的基础设施，在文件检索过程中存在用户隐私泄露风险，当前系统未能有效保护敏感信息。

Method: 提出PIR-DSN协议，集成私有信息检索技术，包括：1）创新的安全映射方法，将稀疏文件标识符转换为紧凑整数索引；2）通过跨多个矿工的文件复制实现拜占庭容错的私有检索。

Result: 与三个主流工业DSN系统对比，PIR-DSN在文件上传和删除方面开销相当。虽然PIR引入额外计算成本导致检索延迟增加，但吞吐量保持可比水平。

Conclusion: PIR-DSN在DSN环境中具有实际可行性，特别适用于隐私敏感应用，为去中心化存储网络提供了有效的隐私保护解决方案。

Abstract: Decentralized Storage Networks (DSNs) are emerging as a foundational infrastructure for Web 3.0, offering global peer-to-peer storage. However, a critical vulnerability persists: user privacy during file retrieval remains largely unaddressed, risking the exposure of sensitive information. To overcome this, we introduce PIR-DSN, the first DSN protocol to integrate Private Information Retrieval (PIR) for both single and multi-server settings. Our key innovations include a novel secure mapping method that transforms sparse file identifiers into compact integer indexes, enabling both public verifiability of file operations and efficient private retrieval. Furthermore, PIR-DSN guarantees Byzantine-robust private retrieval through file replication across multiple miners. We implement and rigorously evaluate PIR-DSN against three prominent industrial DSN systems. Experimental results demonstrate that PIR-DSN achieves comparable overhead for file upload and deletion. While PIR inherently introduces an additional computational cost leading to higher retrieval latency, PIR-DSN maintains comparable throughput. These findings underscore PIR-DSN's practical viability for privacy-sensitive applications within DSN environments.

</details>


### [304] [ContinuumConductor : Decentralized Process Mining on the Edge-Cloud Continuum](https://arxiv.org/abs/2512.07280)
*Hendrik Reiter,Janick Edinger,Martin Kabierski,Agnes Koschmider,Olaf Landsiedel,Arvid Lepsien,Xixi Lu,Andrea Marrella,Estefania Serral,Stefan Schulte,Florian Tschorsch,Matthias Weidlich,Wilhelm Hasselbring*

Main category: cs.DC

TL;DR: 提出ContinuumConductor框架，在边缘-云连续体中实现去中心化流程挖掘，平衡隐私、响应性和资源效率


<details>
  <summary>Details</summary>
Motivation: 传统流程挖掘假设集中式事件数据收集与分析，但现代工业物联网系统运行在分布式、资源受限的边缘-云基础设施上，需要新的去中心化方法

Method: 提出ContinuumConductor分层决策框架，指导何时在流程挖掘任务（预处理、关联、发现）中采用集中或去中心化方式，分析各层权衡并提出决策标准

Result: 在内河港口流程优化的真实用例中演示了ContinuumConductor框架，为网络物理系统和工业物联网中的计算感知流程挖掘奠定基础

Conclusion: ContinuumConductor为边缘-云连续体中的去中心化流程挖掘提供了结构化方法，实现了隐私保护、响应性和资源效率的平衡

Abstract: Process mining traditionally assumes centralized event data collection and analysis. However, modern Industrial Internet of Things systems increasingly operate over distributed, resource-constrained edge-cloud infrastructures. This paper proposes a structured approach for decentralizing process mining by enabling event data to be mined directly within the IoT systems edge-cloud continuum. We introduce ContinuumConductor a layered decision framework that guides when to perform process mining tasks such as preprocessing, correlation, and discovery centrally or decentrally. Thus, enabling privacy, responsive and resource-efficient process mining. For each step in the process mining pipeline, we analyze the trade-offs of decentralization versus centralization across these layers and propose decision criteria. We demonstrate ContinuumConductor at a real-world use-case of process optimazition in inland ports. Our contributions lay the foundation for computing-aware process mining in cyber-physical and IIoT systems.

</details>


### [305] [Venus: An Efficient Edge Memory-and-Retrieval System for VLM-based Online Video Understanding](https://arxiv.org/abs/2512.07344)
*Shengyuan Ye,Bei Ouyang,Tianyi Qian,Liekang Zeng,Mu Yuan,Xiaowen Chu,Weijie Hong,Xu Chen*

Main category: cs.DC

TL;DR: Venus是一个面向在线视频理解的高效边缘-云分离内存检索系统，通过边缘处理视频流、构建分层内存和自适应关键帧选择，实现实时响应并大幅降低延迟。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在在线视频理解应用中部署时存在系统开销过大的问题，现有研究主要关注提升模型推理能力而忽略了实际部署约束。

Method: 提出边缘-云分离架构，包含两个阶段：1) 摄取阶段：边缘端通过场景分割和聚类处理视频流，使用多模态嵌入模型构建分层内存；2) 查询阶段：索引查询并使用基于阈值的渐进采样算法进行关键帧选择，平衡系统成本和推理精度。

Result: 相比最先进方法，Venus实现了15-131倍的总响应延迟加速，能在数秒内提供实时响应，同时保持相当甚至更优的推理精度。

Conclusion: Venus通过边缘-云分离架构和高效的内存检索系统，成功解决了在线视频理解中的部署约束问题，实现了实时高效的视频理解服务。

Abstract: Vision-language models (VLMs) have demonstrated impressive multimodal comprehension capabilities and are being deployed in an increasing number of online video understanding applications. While recent efforts extensively explore advancing VLMs' reasoning power in these cases, deployment constraints are overlooked, leading to overwhelming system overhead in real-world deployments. To address that, we propose Venus, an on-device memory-and-retrieval system for efficient online video understanding. Venus proposes an edge-cloud disaggregated architecture that sinks memory construction and keyframe retrieval from cloud to edge, operating in two stages. In the ingestion stage, Venus continuously processes streaming edge videos via scene segmentation and clustering, where the selected keyframes are embedded with a multimodal embedding model to build a hierarchical memory for efficient storage and retrieval. In the querying stage, Venus indexes incoming queries from memory, and employs a threshold-based progressive sampling algorithm for keyframe selection that enhances diversity and adaptively balances system cost and reasoning accuracy. Our extensive evaluation shows that Venus achieves a 15x-131x speedup in total response latency compared to state-of-the-art methods, enabling real-time responses within seconds while maintaining comparable or even superior reasoning accuracy.

</details>


### [306] [Communication-Efficient Serving for Video Diffusion Models with Latent Parallelism](https://arxiv.org/abs/2512.07350)
*Zhiyuan Wu,Shuai Wang,Li Chen,Kaihui Gao,Dan Li,Yanyu Ren,Qiming Zhang,Yong Wang*

Main category: cs.DC

TL;DR: 本文提出Latent Parallelism (LP)，一种针对视频扩散模型服务优化的并行策略，通过动态旋转潜在空间分区维度来减少97%通信开销，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 视频扩散模型在3D时空域进行注意力计算，内存消耗呈立方级增长，需要多GPU并行服务。传统并行策略需要频繁传输高维激活数据，造成严重的通信瓶颈。

Method: 提出Latent Parallelism (LP)：1) 利用扩散去噪过程的局部时空依赖性；2) 在扩散时间步中动态旋转潜在空间的分区维度（时间、高度、宽度）；3) 设计补丁对齐的重叠分区策略和位置感知的潜在重建机制确保生成质量。

Result: 在三个基准测试中，LP相比基线方法减少了高达97%的通信开销，同时保持可比的生成质量。LP可作为非侵入式插件与现有并行策略无缝集成。

Conclusion: LP是首个针对视频扩散模型服务的并行策略，通过动态维度旋转和精心设计的重建机制，显著降低通信开销，实现高效可扩展的视频生成服务。

Abstract: Video diffusion models (VDMs) perform attention computation over the 3D spatio-temporal domain. Compared to large language models (LLMs) processing 1D sequences, their memory consumption scales cubically, necessitating parallel serving across multiple GPUs. Traditional parallelism strategies partition the computational graph, requiring frequent high-dimensional activation transfers that create severe communication bottlenecks. To tackle this issue, we exploit the local spatio-temporal dependencies inherent in the diffusion denoising process and propose Latent Parallelism (LP), the first parallelism strategy tailored for VDM serving. \textcolor{black}{LP decomposes the global denoising problem into parallelizable sub-problems by dynamically rotating the partitioning dimensions (temporal, height, and width) within the compact latent space across diffusion timesteps, substantially reducing the communication overhead compared to prevailing parallelism strategies.} To ensure generation quality, we design a patch-aligned overlapping partition strategy that matches partition boundaries with visual patches and a position-aware latent reconstruction mechanism for smooth stitching. Experiments on three benchmarks demonstrate that LP reduces communication overhead by up to 97\% over baseline methods while maintaining comparable generation quality. As a non-intrusive plug-in paradigm, LP can be seamlessly integrated with existing parallelism strategies, enabling efficient and scalable video generation services.

</details>


### [307] [Otus Supercomputer](https://arxiv.org/abs/2512.07401)
*Sadaf Ehtesabi,Manoar Hossain,Tobias Kenter,Andreas Krawinkel,Holger Nitsche,Lukas Ostermann,Christian Plessl,Heinrich Riebler,Stefan Rohde,Robert Schade,Michael Schwarz,Jens Simon,Nils Winnwa,Alex Wiens,Xin Wu*

Main category: cs.DC

TL;DR: Otus是德国帕德博恩大学PC2中心于2025年推出的高性能计算集群，作为NHR计划的一部分，补充了Noctua 2系统，提供约两倍计算能力，在Top500中CPU分区排名164、GPU分区排名255，在Green500中GPU分区排名第5。


<details>
  <summary>Details</summary>
Motivation: 本文旨在详细介绍Otus超级计算机的系统架构，包括硬件、软件、系统集成和数据中心整合，为使用该系统的科学家和运营HPC集群的其他中心提供独特见解，并持续更新以反映最新系统配置和测量结果。

Method: 文章提供了Otus系统的全面概述，涵盖硬件配置（三种节点类型：CPU计算节点、高端GPU节点、HPC级FPGA节点）、软件环境、系统集成方法，以及为确保能源高效运行而进行的数据中心建筑整体集成方案。

Result: Otus系统在性能方面表现出色：在Top500榜单中，CPU分区排名第164位，GPU分区排名第255位；在衡量能源效率的Green500榜单中，GPU分区排名第5位，显示出卓越的能效表现。

Conclusion: Otus作为NHR计划的一部分，成功补充了Noctua 2系统，提供了约两倍的计算能力，同时保持了三种节点类型的架构特点，在性能和能效方面都取得了显著成就，为科学研究和HPC中心运营提供了有价值的参考。

Abstract: Otus is a high-performance computing cluster that was launched in 2025 and is operated by the Paderborn Center for Parallel Computing (PC2) at Paderborn University in Germany. The system is part of the National High Performance Computing (NHR) initiative. Otus complements the previous supercomputer Noctua 2, offering approximately twice the computing power while retaining the three node types that were characteristic of Noctua 2: 1) CPU compute nodes with different memory capacities, 2) high-end GPU nodes, and 3) HPC-grade FPGA nodes. On the Top500 list, which ranks the 500 most powerful supercomputers in the world, Otus is in position 164 with the CPU partition and in position 255 with the GPU partition (June 2025). On the Green500 list, ranking the 500 most energy-efficient supercomputers in the world, Otus is in position 5 with the GPU partition (June 2025).
  This article provides a comprehensive overview of the system in terms of its hardware, software, system integration, and its overall integration into the data center building to ensure energy-efficient operation. The article aims to provide unique insights for scientists using the system and for other centers operating HPC clusters. The article will be continuously updated to reflect the latest system setup and measurements.

</details>


### [308] [Bandwidth-Aware Network Topology Optimization for Decentralized Learning](https://arxiv.org/abs/2512.07536)
*Yipeng Shen,Zehan Zhu,Yan Huang,Changzhi Yan,Cheng Zhuo,Jinming Xu*

Main category: cs.DC

TL;DR: 提出带宽感知的网络拓扑优化框架，在边数约束下最大化共识速度，通过ADMM方法求解混合整数SDP问题，实验显示在去中心化学习中显著提升训练速度


<details>
  <summary>Details</summary>
Motivation: 现有网络拓扑设计大多忽略带宽限制，而带宽对分布式学习中的参数同步效率至关重要。需要设计考虑带宽约束的网络拓扑来提升共识速度。

Method: 提出带宽感知的网络拓扑优化框架，将问题转化为混合整数SDP问题，采用ADMM方法高效求解，在ADMM子步中使用共轭梯度法处理大规模线性方程以提升可扩展性。针对异构带宽场景引入最大带宽分配策略。

Result: 实验结果表明，所得到的网络拓扑在共识速度上优于基准拓扑，在真实数据集上去中心化学习任务中，为达到目标测试精度，同构和异构带宽设置下的训练时间分别减少了1.11倍和1.21倍以上。

Conclusion: 带宽感知的网络拓扑优化能显著提升分布式学习的参数同步效率，提出的ADMM求解方法具有良好可扩展性，为实际网络环境中的去中心化学习提供了有效的拓扑设计解决方案。

Abstract: Network topology is critical for efficient parameter synchronization in distributed learning over networks. However, most existing studies do not account for bandwidth limitations in network topology design. In this paper, we propose a bandwidth-aware network topology optimization framework to maximize consensus speed under edge cardinality constraints. For heterogeneous bandwidth scenarios, we introduce a maximum bandwidth allocation strategy for the edges to ensure efficient communication among nodes. By reformulating the problem into an equivalent Mixed-Integer SDP problem, we leverage a computationally efficient ADMM-based method to obtain topologies that yield the maximum consensus speed. Within the ADMM substep, we adopt the conjugate gradient method to efficiently solve large-scale linear equations to achieve better scalability. Experimental results demonstrate that the resulting network topologies outperform the benchmark topologies in terms of consensus speed, and reduce the training time required for decentralized learning tasks on real-world datasets to achieve the target test accuracy, exhibiting speedups of more than $1.11\times$ and $1.21\times$ for homogeneous and heterogeneous bandwidth settings, respectively.

</details>


### [309] [A Performance Analyzer for a Public Cloud's ML-Augmented VM Allocator](https://arxiv.org/abs/2512.07750)
*Roozbeh Bostandoost,Pooria Namyar,Siva Kesava Reddy Kakarla,Ryan Beckett,Santiago Segarra,Eli Cortez,Ankur Mallick,Kevin Hsieh,Rodrigo Fonseca,Mohammad Hajiesmaili,Behnaz Arzani*

Main category: cs.DC

TL;DR: SANJESH是一个帮助云系统操作员理解多个机器学习模型如何影响端到端系统性能的工具，通过双层优化支持多种性能查询，并能发现传统仿真方法无法检测的性能问题。


<details>
  <summary>Details</summary>
Motivation: 当前云系统使用多个机器学习模型来提高效率和性能，但操作员缺乏工具来理解每个模型以及模型间交互如何影响整体系统性能，需要专门的工具来解决这个问题。

Method: SANJESH通过双层优化来回答性能相关查询，并发明了新颖的机制来加速优化求解过程，这些技术使其能够解决先前工作24小时都无法解决的优化问题。

Result: 在虚拟机放置的生产系统应用中，SANJESH发现了机器学习模型导致性能比基于仿真的方法检测到的差约4倍的情况，证明了其有效性。

Conclusion: SANJESH是一个有效的工具，能够帮助云系统操作员理解多个机器学习模型对系统性能的影响，并能发现传统方法无法检测的性能问题。

Abstract: Many operational cloud systems use one or more machine learning models that help them achieve better efficiency and performance. But operators do not have tools to help them understand how each model and the interaction between them affect the end-to-end system performance. SANJESH is such a tool. SANJESH supports a diverse set of performance-related queries which we answer through a bi-level optimization. We invent novel mechanisms to solve this optimization more quickly. These techniques allow us to solve an optimization which prior work failed to solve even after $24$ hours.
  As a proof of concept, we apply SANJESH to an example production system that uses multiple ML models to optimize virtual machine (VM) placement. These models impact how many servers the operators uses to host VMs and the frequency with which it has to live-migrate them because the servers run out of resources. SANJESH finds scenarios where these models cause $~4\times$ worse performance than what simulation-based approaches detect.

</details>


### [310] [Designing Co-operation in Systems of Hierarchical, Multi-objective Schedulers for Stream Processing](https://arxiv.org/abs/2512.07792)
*Animesh Dangwal,Yufeng Jiang,Charlie Arnold,Jun Fan,Mohamed Bassem,Aish Rajagopal*

Main category: cs.DC

TL;DR: Meta开发了一个用于流处理系统的分层负载均衡架构，能够处理TB级数据，通过集成新调度器到现有层次结构中，在多计算资源上实现更鲁棒的负载均衡。


<details>
  <summary>Details</summary>
Motivation: 随着Meta流处理应用复杂性和用户需求的增长，原本负载均衡需求较低的基础设施部分现在需要更鲁棒和主动的负载均衡机制，以应对不断增长的计算资源需求。

Method: 设计了一个分层负载均衡系统，专注于关键计算资源和应用特性的负载均衡，并将新调度器集成到现有调度器层次结构中，使多个调度器能够在各自基础设施层级协同工作。

Result: 该系统能够处理TB级数据，在几秒钟内完成处理，通过高效调度器和多层基础设施实现跨各种计算资源的工作负载分配。

Conclusion: 提出的分层负载均衡架构能够有效应对流处理系统日益增长的复杂性，通过多调度器协同工作实现更鲁棒和主动的负载均衡，满足Meta大规模AI和用户服务的需求。

Abstract: Stream processing is a computing paradigm that supports real-time data processing for a wide variety of applications. At Meta, it's used across the company for various tasks such as deriving product insights, providing and improving user services, and enabling AI at scale for our ever-growing user base. Meta's current stream processing framework supports processing TerraBytes(TBs) of data in mere seconds. This is enabled by our efficient schedulers and multi-layered infrastructure, which allocate workloads across various compute resources, working together in hierarchies across various parts of the infrastructure. But with the ever growing complexity of applications, and user needs, areas of the infrastructure that previously required minimal load balancing, now must be made more robust and proactive to application load. In our work we explore how to build and design such a system that focuses on load balancing over key compute resources and properties of these applications. We also showcase how to integrate new schedulers into the hierarchy of the existing ones, allowing multiple schedulers to work together and perform load balancing, at their infrastructure level, effectively.

</details>


### [311] [Quantifying the Carbon Reduction of DAG Workloads: A Job Shop Scheduling Perspective](https://arxiv.org/abs/2512.07799)
*Roozbeh Bostandoost,Adam Lechowicz,Walid A. Hanafy,Prashant Shenoy,Mohammad Hajiesmaili*

Main category: cs.DC

TL;DR: 该论文研究依赖感知的碳感知调度器，通过考虑作业内部任务依赖关系，相比传统单任务调度可降低高达25%的碳排放，但面临碳减排、能耗和作业完成时间之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有碳感知调度器大多将工作负载视为单一整体任务，忽略了视频编码、离线推理等作业由具有特定依赖关系的小任务组成。利用这种结构知识可以创造更大的碳效率机会。

Method: 将问题建模为灵活的作业车间调度变体，使用离线求解器计算碳和能源节省的上限。量化依赖感知方法对批处理工作负载的最大效益。

Result: 结果显示平均可降低25%的碳排放，且不增加最优作业完成时间。在异构服务器设置中，这些调度可能比能耗最优调度使用更多能量。允许两倍最优完成时间可使碳节省几乎翻倍。

Conclusion: 依赖感知调度能显著降低数据中心碳足迹，但需要在碳减排、能耗和作业完成时间之间权衡。作业结构和服务器数量是影响碳减排潜力的关键因素。

Abstract: Carbon-aware schedulers aim to reduce the operational carbon footprint of data centers by running flexible workloads during periods of low carbon intensity. Most schedulers treat workloads as single monolithic tasks, ignoring that many jobs, like video encoding or offline inference, consist of smaller tasks with specific dependencies and resource needs; however, knowledge of this structure enables opportunities for greater carbon efficiency.
  We quantify the maximum benefit of a dependency-aware approach for batch workloads. We model the problem as a flexible job-shop scheduling variant and use an offline solver to compute upper bounds on carbon and energy savings. Results show up to $25\%$ lower carbon emissions on average without increasing the optimal makespan (total job completion time) compared to a makespan-only baseline. Although in heterogeneous server setup, these schedules may use more energy than energy-optimal ones. Our results also show that allowing twice the optimal makespan nearly doubles the carbon savings, underscoring the tension between carbon, energy, and makespan. We also highlight key factors such as job structure and server count influence the achievable carbon reductions.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [312] [Compass: Mapping Space Exploration for Multi-Chiplet Accelerators Targeting LLM Inference Serving Workloads](https://arxiv.org/abs/2512.06093)
*Boyu Li,Zongwei Zhu,Yi Xiong,Qianyue Cao,Jiawei Geng,Xiaonan Zhang,Xi Li*

Main category: cs.AR

TL;DR: 提出Compass框架，通过细粒度映射编码和遗传算法搜索，为多芯片LLM推理加速器优化动态负载的映射策略，相比现有方法平均EDP降低63.12%


<details>
  <summary>Details</summary>
Motivation: 现有多芯片加速器映射方法主要针对传统CNN/Transformer工作负载，无法有效支持真实LLM推理服务中混合请求类型和可变序列长度的动态行为

Method: 1) 提出基于计算执行图的映射编码方案，解耦微批次和层，实现异构芯片上的细粒度执行控制；2) 开发Compass框架，集成评估引擎和基于遗传算法的映射生成引擎

Result: 相比最先进方法，平均EDP（能耗延迟积）降低63.12%

Conclusion: Compass框架通过创新的映射编码和搜索算法，有效解决了多芯片LLM推理加速器在动态工作负载下的映射优化问题，显著提升了能效

Abstract: Large Language Models (LLMs) impose massive computational demands, driving the need for scalable multi-chiplet accelerators. However, existing mapping space exploration efforts for such accelerators primarily focus on traditional CNN/Transformer workloads and fail to adequately support the dynamic behaviors of mixed request types and variable sequence lengths in real-world LLM inference serving. To bridge this gap, we first propose a computation execution graph-based mapping encoding scheme that decouples micro-batches and layers, enabling fine-grained execution control on heterogeneous chiplets and flexibly representing various parallelism strategies. Second, building upon this scheme, we develop the Compass framework, which integrates an evaluation engine and a genetic algorithm-based mapping generation engine to achieve efficient mapping search. Compared to state-of-the-art works, our solution achieves an average EDP reduction of 63.12%.

</details>


### [313] [Hardware Software Optimizations for Fast Model Recovery on Reconfigurable Architectures](https://arxiv.org/abs/2512.06113)
*Bin Xu,Ayan Banerjee,Sandeep Gupta*

Main category: cs.AR

TL;DR: MERINDA是一个FPGA加速的模型恢复框架，通过流式数据流管道重构计算，相比GPU方案减少了迭代依赖和内核启动开销，相比FPGA基准实现了6.3倍的周期减少。


<details>
  <summary>Details</summary>
Motivation: 模型恢复是物理AI和实时数字孪生的核心原语，但GPU执行效率低下，存在迭代依赖、内核启动开销、内存带宽未充分利用和高数据移动延迟等问题。

Method: 将计算重构为流式数据流管道，利用BRAM分块、定点内核、LUT结构和进位链加法器的并发使用，暴露细粒度空间并行性，同时最小化片外通信。

Result: 在代表性模型恢复工作负载上，MERINDA比基于FPGA的LTC基准减少了高达6.3倍的周期，为时间关键物理系统实现了实时性能。

Conclusion: 硬件感知的MERINDA框架消除了同步瓶颈，在模型恢复的迭代更新中维持高吞吐量，为物理AI和数字孪生应用提供了高效的FPGA加速解决方案。

Abstract: Model Recovery (MR) is a core primitive for physical AI and real-time digital twins, but GPUs often execute MR inefficiently due to iterative dependencies, kernel-launch overheads, underutilized memory bandwidth, and high data-movement latency. We present MERINDA, an FPGA-accelerated MR framework that restructures computation as a streaming dataflow pipeline. MERINDA exploits on-chip locality through BRAM tiling, fixed-point kernels, and the concurrent use of LUT fabric and carry-chain adders to expose fine-grained spatial parallelism while minimizing off-chip traffic. This hardware-aware formulation removes synchronization bottlenecks and sustains high throughput across the iterative updates in MR. On representative MR workloads, MERINDA delivers up to 6.3x fewer cycles than an FPGA-based LTC baseline, enabling real-time performance for time-critical physical systems.

</details>


### [314] [From PyTorch to Calyx: An Open-Source Compiler Toolchain for ML Accelerators](https://arxiv.org/abs/2512.06177)
*Jiahan Xie,Evan Williams,Adrian Sampson*

Main category: cs.AR

TL;DR: 开发了一个从PyTorch ML模型到可综合SystemVerilog的开源端到端编译器工具链，性能接近商业工具Vitis HLS


<details>
  <summary>Details</summary>
Motivation: 为机器学习模型提供开源硬件编译工具链，替代昂贵的商业工具，实现从PyTorch模型到FPGA可部署硬件的自动化流程

Method: 基于Allo加速器设计语言、Calyx硬件中间表示和LLVM的CIRCT项目构建工具链，实现内存分区等编译器优化

Result: 能够有效生成优化的FPGA可部署硬件设计，性能与Vitis HLS等闭源工业级工具相当

Conclusion: 成功开发了开源端到端ML硬件编译器，为ML硬件加速提供了可行的开源替代方案

Abstract: We present an end-to-end open-source compiler toolchain that targets synthesizable SystemVerilog from ML models written in PyTorch. Our toolchain leverages the accelerator design language Allo, the hardware intermediate representation (IR) Calyx, and the CIRCT project under LLVM. We also implement a set of compiler passes for memory partitioning, enabling effective parallelism in memory-intensive ML workloads. Experimental results demonstrate that our compiler can effectively generate optimized FPGA-implementable hardware designs that perform reasonably well against closed-source industry-grade tools such as Vitis HLS.

</details>


### [315] [SparsePixels: Efficient Convolution for Sparse Data on FPGAs](https://arxiv.org/abs/2512.06208)
*Ho Fung Tsoi,Dylan Rankin,Vladimir Loncar,Philip Harris*

Main category: cs.AR

TL;DR: SparsePixels：针对空间稀疏图像数据的FPGA高效卷积框架，通过仅计算活跃像素实现73倍推理加速


<details>
  <summary>Details</summary>
Motivation: 传统CNN在FPGA上进行推理时，由于需要对每个输入像素进行密集卷积计算，导致高延迟和长启动间隔。然而，某些图像数据（如物理实验数据）具有空间稀疏特性，大部分计算浪费在空区域上。

Method: 提出SparsePixels框架，实现一类特殊的CNN，仅选择性地保留和计算活跃像素子集，忽略其余像素。开发了支持稀疏CNN构建的库（包含量化感知训练）和用于FPGA部署的HLS实现。

Result: 在包含约4k输入像素的中微子物理数据集上，标准CNN推理延迟为48.665μs，而稀疏CNN仅计算不到1%的输入像素，实现73倍加速至0.665μs，资源利用率在片上预算内，仅带来小幅度性能损失。

Conclusion: 该工作为现代实验（如CERN大型强子对撞机的触发和数据采集系统）的快速高效数据读出算法发展提供了支持，在具有稀疏图像模式的类似数据集中也展示了至少一个数量级的加速效果。

Abstract: Inference of standard CNNs on FPGAs often incurs high latency and a long initiation interval due to the deep nested loops required to densely convolve every input pixel regardless of its feature value, especially when the image size is large. However, in some image data, input features can be spatially sparse, and semantic information may occupy only a small fraction of the input pixels. In this case most computation would be wasted on empty regions. In this work, we introduce SparsePixels, a framework for efficient convolution for spatially sparse image data on FPGAs, targeting fast inference applications in constrained environments with latency requirements of microseconds or below. Our approach implements a special class of CNNs that selectively retain and compute on a small subset of pixels that are active while ignoring the rest. We show that, for example, in a neutrino physics dataset for identifying neutrino interactions in LArTPC images that have around 4k input pixels but are naturally very sparse, a standard CNN with a compact size of 4k parameters incurs an inference latency of 48.665 $μ$s on an FPGA, whereas a sparse CNN of the same base architecture computing on less than 1% of the input pixels results in a $\times 73$ inference speedup to 0.665 $μ$s, with resource utilization well within on-chip budgets, trading only a small percent-level performance loss. At least one-order-of magnitude speedups with comparable performance are also demonstrated in similar datasets with sparse image patterns. This work aims to benefit future algorithm developments for fast and efficient data readout in modern experiments such as the trigger and data acquisition systems at the CERN Large Hadron Collider. For easy adoption, we have developed a library to support building sparse CNNs with quantization-aware training, as well as an HLS implementation for FPGA deployment.

</details>


### [316] [A 33.6-136.2 TOPS/W Nonlinear Analog Computing-In-Memory Macro for Multi-bit LSTM Accelerator in 65 nm CMOS](https://arxiv.org/abs/2512.06362)
*Junyi Yang,Xinyu Luo,Ye Ke,Zheng Wang,Hongyang Shang,Shuai Dong,Zhengnan Fu,Xiaofeng Yang,Hongjie Liu,Arindam Basu*

Main category: cs.AR

TL;DR: 提出一种结合可重构非线性内存ADC的LSTM加速器，直接在模拟域计算非线性激活，显著提升能效和面积效率


<details>
  <summary>Details</summary>
Motivation: 传统模拟内存计算加速器在处理RNN/LSTM时，非线性操作通常需要数字计算，限制了能效提升

Method: 采用可重构(1-5位)非线性内存ADC，包含：1)双9T位单元支持有符号输入和三元权重；2)RUDC技术提升读取动态范围；3)双电源6T-SRAM阵列减少位单元数量和延迟

Result: 5位NLIM ADC实现平均误差<1 LSB，在12类关键词检测任务中达到92.0%片上推理准确率，系统级能效提升2.2倍，面积效率提升1.6倍

Conclusion: 提出的NLIM ADC方法能有效在模拟域计算LSTM非线性激活，显著提升ACIM加速器的能效和面积效率

Abstract: The energy efficiency of analog computing-in-memory (ACIM) accelerator for recurrent neural networks, particularly long short-term memory (LSTM) network, is limited by the high proportion of nonlinear (NL) operations typically executed digitally. To address this, we propose an LSTM accelerator incorporating an ACIM macro with reconfigurable (1-5 bit) nonlinear in-memory (NLIM) analog-to-digital converter (ADC) to compute NL activations directly in the analog domain using: 1) a dual 9T bitcell with decoupled read/write paths for signed inputs and ternary weight operations; 2) a read-word-line underdrive Cascode (RUDC) technique achieving 2.8X higher read-bitline dynamic range than single-transistor designs (1.4X better over conventional Cascode structure with 7X lower current variation); 3) a dual-supply 6T-SRAM array for efficient multi-bit weight operations and reducing both bitcell count (7.8X) and latency (4X) for 5-bit weight operations. We experimentally demonstrate 5-bit NLIM ADC for approximating NL activations in LSTM cells, achieving average error <1 LSB. Simulation confirms the robustness of NLIM ADC against temperature variations thanks to the replica bias strategy. Our design achieves 92.0% on-chip inference accuracy for a 12-class keyword-spotting task while demonstrating 2.2X higher system-level normalized energy efficiency and 1.6X better normalized area efficiency than state-of-the-art works. The results combine physical measurements of a macro unit-accounting for the majority of LSTM operations (99% linear and 80% nonlinear operations)-with simulations of the remaining components, including additional LSTM and fully connected layers.

</details>


### [317] [Approximate Multiplier Induced Error Propagation in Deep Neural Networks](https://arxiv.org/abs/2512.06537)
*A. M. H. H. Alahakoon,Hassaan Saadat,Darshana Jayasinghe,Sri Parameswaran*

Main category: cs.AR

TL;DR: 提出分析框架连接近似乘法器误差统计特性与DNN精度影响，发现误差均值主导失真，提供轻量级评估方法替代硬件仿真


<details>
  <summary>Details</summary>
Motivation: 深度神经网络依赖密集算术运算，近似乘法器可降低能耗，但缺乏数学分析其误差分布如何影响DNN精度

Method: 开发分析框架连接AxM误差统计矩与GEMM失真，使用Frobenius范数推导闭式表达式，通过误差注入实验验证

Result: 失真主要由乘法器误差均值主导，预测失真与实际精度下降强相关，FPGA实现验证分析趋势

Conclusion: 该框架为快速评估近似乘法器对DNN推理质量影响提供轻量级替代方案，无需行为或硬件级仿真

Abstract: Deep Neural Networks (DNNs) rely heavily on dense arithmetic operations, motivating the use of Approximate Multipliers (AxMs) to reduce energy consumption in hardware accelerators. However, a rigorous mathematical characterization of how AxMs error distributions influence DNN accuracy remains underdeveloped. This work presents an analytical framework that connects the statistical error moments of an AxM to the induced distortion in General Matrix Multiplication (GEMM). Using the Frobenius norm of the resulting error matrix, we derive a closed form expression for practical DNN dimensions that demonstrates the distortion is predominantly governed by the multiplier mean error (bias). To evaluate this model in realistic settings, we incorporate controlled error injection into GEMM and convolution layers and examine its effect on ImageNet scale networks. The predicted distortion correlates strongly with the observed accuracy degradation, and an error configurable AxM case study implemented on an FPGA further confirms the analytical trends. By providing a lightweight alternative to behavioral or hardware level simulations, this framework enables rapid estimation of AxM impact on DNN inference quality.

</details>


### [318] [ArchPower: Dataset for Architecture-Level Power Modeling of Modern CPU Design](https://arxiv.org/abs/2512.06854)
*Qijun Zhang,Yao Lu,Mengming Li,Shang Liu,Zhiyao Xie*

Main category: cs.AR

TL;DR: ArchPower是首个开源架构级处理器功耗建模数据集，包含200个CPU数据样本，涵盖25种CPU配置和8种工作负载，提供超过100个架构特征和细粒度功耗标签。


<details>
  <summary>Details</summary>
Motivation: 当前CPU功耗评估需要耗时的IC实现流程，早期设计阶段的传统功耗模型不准确，ML模型缺乏数据支持，且没有开源数据集。现有数据集生成困难，无法反映真实CPU设计场景。

Method: 通过复杂真实的设计流程收集CPU架构信息作为特征，模拟功耗作为标签。数据集包含200个样本，来自25种CPU配置执行8种工作负载，每个样本有100多个架构特征（硬件和事件参数）。

Result: 创建了首个开源架构级处理器功耗建模数据集ArchPower，提供细粒度功耗信息：总设计功耗和11个组件功耗，每个功耗值进一步分解为组合逻辑、时序逻辑、存储器和时钟功耗四类。

Conclusion: ArchPower填补了架构级处理器功耗建模开源数据集的空白，为ML功耗模型研究提供了重要资源，有助于提升早期设计阶段的功耗评估准确性。

Abstract: Power is the primary design objective of large-scale integrated circuits (ICs), especially for complex modern processors (i.e., CPUs). Accurate CPU power evaluation requires designers to go through the whole time-consuming IC implementation process, easily taking months. At the early design stage (e.g., architecture-level), classical power models are notoriously inaccurate. Recently, ML-based architecture-level power models have been proposed to boost accuracy, but the data availability is a severe challenge. Currently, there is no open-source dataset for this important ML application. A typical dataset generation process involves correct CPU design implementation and repetitive execution of power simulation flows, requiring significant design expertise, engineering effort, and execution time. Even private in-house datasets often fail to reflect realistic CPU design scenarios. In this work, we propose ArchPower, the first open-source dataset for architecture-level processor power modeling. We go through complex and realistic design flows to collect the CPU architectural information as features and the ground-truth simulated power as labels. Our dataset includes 200 CPU data samples, collected from 25 different CPU configurations when executing 8 different workloads. There are more than 100 architectural features in each data sample, including both hardware and event parameters. The label of each sample provides fine-grained power information, including the total design power and the power for each of the 11 components. Each power value is further decomposed into four fine-grained power groups: combinational logic power, sequential logic power, memory power, and clock power. ArchPower is available at https://github.com/hkust-zhiyao/ArchPower.

</details>


### [319] [DCO: Dynamic Cache Orchestration for LLM Accelerators through Predictive Management](https://arxiv.org/abs/2512.07312)
*Zhongchun Zhou,Chengtao Lai,Yuhang Gu,Wei Zhang*

Main category: cs.AR

TL;DR: 论文提出了一种面向AI加速器的共享系统级缓存架构，通过软件栈数据流信息指导缓存替换和旁路决策，显著提升性能，面积仅0.064mm²。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速采用，AI加速器设计日益复杂，特别是深度层次化的暂存器内存及其异步管理增加了软件开发难度。本文探索相反的设计方向：采用共享系统级缓存和应用程序感知管理策略，保持编程简单性。

Method: 设计多核AI加速器，配备共享系统级缓存，利用软件栈中的数据流信息指导缓存替换（包括死块预测），结合旁路决策和缓解缓存颠簸的机制。

Result: 相比传统缓存架构，性能提升显著（最高1.80倍加速比）。建立了考虑实际重叠行为的分析模型，验证了策略在更大规模工作负载上的有效性。RTL实现面积仅0.064mm²（15nm工艺），时钟频率2GHz。

Conclusion: 共享缓存设计展示了协助未来AI加速器系统开发的潜力，通过应用程序感知管理策略在保持编程简单性的同时实现高性能。

Abstract: The rapid adoption of large language models (LLMs) is pushing AI accelerators toward increasingly powerful and specialized designs. Instead of further complicating software development with deeply hierarchical scratchpad memories (SPMs) and their asynchronous management, we investigate the opposite point of the design spectrum: a multi-core AI accelerator equipped with a shared system-level cache and application-aware management policies, which keeps the programming effort modest. Our approach exploits dataflow information available in the software stack to guide cache replacement (including dead-block prediction), in concert with bypass decisions and mechanisms that alleviate cache thrashing.
  We assess the proposal using a cycle-accurate simulator and observe substantial performance gains (up to 1.80x speedup) compared with conventional cache architectures. In addition, we build and validate an analytical model that takes into account the actual overlapping behaviors to extend the measurement results of our policies to real-world larger-scale workloads. Experiment results show that when functioning together, our bypassing and thrashing mitigation strategies can handle scenarios both with and without inter-core data sharing and achieve remarkable speedups.
  Finally, we implement the design in RTL and the area of our design is $\mathbf{0.064mm^2}$ with 15nm process, which can run at 2 GHz clock frequency. Our findings explore the potential of the shared cache design to assist the development of future AI accelerator systems.

</details>


### [320] [aLEAKator: HDL Mixed-Domain Simulation for Masked Hardware \& Software Formal Verification](https://arxiv.org/abs/2512.07520)
*Noé Amiot,Quentin L. Meunier,Karine Heydemann,Emmanuelle Encrenaz*

Main category: cs.AR

TL;DR: aLEAKator是一个开源框架，用于从硬件描述语言自动形式化验证掩码加密加速器和CPU上运行的软件，支持多种泄漏模型和信号粒度


<details>
  <summary>Details</summary>
Motivation: 现有验证方法存在局限性：要么仅限于小型硬件模块或CPU上的小程序（如S盒），要么受限于泄漏模型，或者需要硬件特定的先验知识。在考虑毛刺、转换和CPU微架构特性的高级泄漏模型下，验证掩码硬件和软件实现的安全性仍然是一个重大挑战

Method: 提出aLEAKator框架，采用混合域仿真方法，能够精确建模和验证各种（包括鲁棒和松弛的）1探测泄漏模型，支持可变信号粒度而不限于1位线。该框架还支持查找表存在下的验证，且不需要目标CPU架构的先验知识

Result: aLEAKator已通过现有工具和实际测量进行验证，同时提供了创新性结果，如验证了在各种CPU上完整的一阶掩码AES实现

Conclusion: aLEAKator为掩码加密硬件和软件的自动化形式化验证提供了一个强大而灵活的开源解决方案，克服了现有方法的局限性，能够处理更复杂的实现和更广泛的泄漏模型

Abstract: Verifying the security of masked hardware and software implementations, under advanced leakage models, remains a significant challenge, especially then accounting for glitches, transitions and CPU micro-architectural specifics. Existing verification approaches are either restricted to small hardware gadgets, small programs on CPUs such as Sboxes, limited leakage models, or require hardware-specific prior knowledge. In this work, we present aLEAKator, an open-source framework for the automated formal verification of masked cryptographic accelerators and software running on CPUs from their HDL descriptions. Our method introduces mixed-domain simulation, enabling precise modeling and verification under various (including robust and relaxed) 1-probing leakage models, and supports variable signal granularity without being restricted to 1-bit wires. aLEAKator also supports verification in the presence of lookup tables, and does not require prior knowledge of the target CPU architecture. Our approach is validated against existing tools and real-world measurements while providing innovative results such as the verification of a full, first-order masked AES on various CPUs

</details>


### [321] [Análisis de rendimiento y eficiencia energética en el cluster Raspberry Pi Cronos](https://arxiv.org/abs/2512.07622)
*Martha Semken,Mariano Vargas,Ignacio Tula,Giuliana Zorzoli,Andrés Rojas Paredes*

Main category: cs.AR

TL;DR: 评估由Raspberry Pi4和3b微计算机构成的Cronos集群在计算性能和能效方面的表现，使用HPL基准测试，分析不同节点配置下的可扩展性、稳定性和功耗。


<details>
  <summary>Details</summary>
Motivation: 为教育目的设计和评估低成本ARM集群的性能和能效，为教育研究环境中的集群设计和使用提供具体参考。

Method: 使用High Performance Linpack (HPL)基准测试，在配置Slurm资源管理和Open MPI并行通信的环境中进行实验测试，分析不同节点配置（同构和异构）下的性能表现。

Result: 6个Raspberry Pi 4节点的同构配置最高达到6.91 GFLOPS性能；异构节点（包含Raspberry Pi 3b）会负面影响稳定性和效率；测量了系统总功耗并计算了性能功耗比(GFLOPS/W)。

Conclusion: 该研究为教育研究环境中低成本ARM集群的设计、评估和使用提供了具体贡献，展示了同构配置在性能和稳定性方面的优势。

Abstract: This article presents an evaluation of the computational performance and energy efficiency of the Cronos cluster, composed of Raspberry Pi4 and 3b microcomputers designed for educational purposes. Experimental tests were performed using the High Performance Linpack (HPL) benchmark, under a resource management environment configured with Slurm and parallel communication via Open MPI. The study focuses on analyzing scalability, stability, and power consumption during the execution of computationally intensive workloads, considering different node configurations. The results show that the cluster achieves a performance of up to 6.91 GFLOPS in homogeneous configurations of 6 Raspberry Pi 4 nodes, and that the use of heterogeneous nodes (including Raspberry Pi 3b) can negatively impact stability and efficiency. Additionally, the total electrical consumption of the system was measured during the runs, allowing for the estimation of the performance-to-consumption ratio (GFLOPS/W) as a comparative metric. This study constitutes a concrete contribution to the design, evaluation, and utilization of low-cost ARM clusters in educational and research contexts.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [322] [An Adaptive Multi-Layered Honeynet Architecture for Threat Behavior Analysis via Deep Learning](https://arxiv.org/abs/2512.07827)
*Lukas Johannes Möller*

Main category: cs.CR

TL;DR: ADLAH是一个自适应深度学习异常检测蜜网系统，通过强化学习智能体实时决定何时将会话从低交互传感器节点升级到动态配置的高交互蜜罐，旨在以低成本捕获高价值威胁情报。


<details>
  <summary>Details</summary>
Motivation: 网络威胁日益复杂多样，静态蜜罐已无法满足需求，需要自适应、智能驱动的欺骗技术来有效应对自动化攻击流量。

Method: 提出端到端AI驱动欺骗平台架构，核心是强化学习决策机制，实时判断何时将低交互传感器会话升级到高交互蜜罐，并实现攻击链的自动提取、聚类和版本管理。

Result: 开发了核心决策机制的功能原型，但缺乏大规模现场验证。详细分析了设计权衡和限制，并提供了严格的规模化实证评估路线图。

Conclusion: ADLAH架构为实现低成本捕获高价值对手行为、系统化僵尸网络版本管理和生成可操作威胁情报提供了实用路径。

Abstract: The escalating sophistication and variety of cyber threats have rendered static honeypots inadequate, necessitating adaptive, intelligence-driven deception. In this work, ADLAH is introduced: an Adaptive Deep Learning Anomaly Detection Honeynet designed to maximize high-fidelity threat intelligence while minimizing cost through autonomous orchestration of infrastructure. The principal contribution is offered as an end-to-end architectural blueprint and vision for an AI-driven deception platform. Feasibility is evidenced by a functional prototype of the central decision mechanism, in which a reinforcement learning (RL) agent determines, in real time, when sessions should be escalated from low-interaction sensor nodes to dynamically provisioned, high-interaction honeypots. Because sufficient live data were unavailable, field-scale validation is not claimed; instead, design trade-offs and limitations are detailed, and a rigorous roadmap toward empirical evaluation at scale is provided. Beyond selective escalation and anomaly detection, the architecture pursues automated extraction, clustering, and versioning of bot attack chains, a core capability motivated by the empirical observation that exposed services are dominated by automated traffic. Together, these elements delineate a practical path toward cost-efficient capture of high-value adversary behavior, systematic bot versioning, and the production of actionable threat intelligence.

</details>


### [323] [The Road of Adaptive AI for Precision in Cybersecurity](https://arxiv.org/abs/2512.06048)
*Sahil Garg*

Main category: cs.CR

TL;DR: 该论文分享了在网络安全领域设计、构建和运营生产级生成式AI管道的实践经验，重点关注如何通过持续适应机制应对快速变化的知识库、工具和威胁。


<details>
  <summary>Details</summary>
Motivation: 网络安全日益复杂，为AI研究和实践带来了独特挑战和机遇。作者希望通过分享实际部署经验，为AI从业者和行业利益相关者提供可操作的指导，帮助他们应对生成式AI在网络安全应用中的前沿问题。

Method: 基于真实世界部署的实践经验，提出结合检索级和模型级适应机制的端到端系统设计方法。论文分享了从设计、构建到运营生产级生成式AI管道的具体实践，重点关注不同适应机制如何相互补充。

Result: 提供了从实际部署中得出的实用指导，提出了利用检索级和模型级适应机制的最佳实践，并强调了使生成式AI在网络防御中更加鲁棒、精确和可审计的研究方向。

Conclusion: 生成式AI在网络安全中的应用需要持续的适应机制来应对快速变化的环境。论文为从业者提供了实用的指导框架，并指出了未来研究的关键方向，包括提高系统的鲁棒性、精确性和可审计性。

Abstract: Cybersecurity's evolving complexity presents unique challenges and opportunities for AI research and practice. This paper shares key lessons and insights from designing, building, and operating production-grade GenAI pipelines in cybersecurity, with a focus on the continual adaptation required to keep pace with ever-shifting knowledge bases, tooling, and threats. Our goal is to provide an actionable perspective for AI practitioners and industry stakeholders navigating the frontier of GenAI for cybersecurity, with particular attention to how different adaptation mechanisms complement each other in end-to-end systems. We present practical guidance derived from real-world deployments, propose best practices for leveraging retrieval- and model-level adaptation, and highlight open research directions for making GenAI more robust, precise, and auditable in cyber defense.

</details>


### [324] [Look Twice before You Leap: A Rational Agent Framework for Localized Adversarial Anonymization](https://arxiv.org/abs/2512.06713)
*Donghang Duan,Xu Zheng*

Main category: cs.CR

TL;DR: 论文提出RLAA框架，通过引入仲裁者机制解决本地小模型在文本匿名化中的效用崩溃问题，实现更好的隐私-效用权衡。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的文本匿名化框架依赖远程API服务，存在"隐私悖论"：用户需要向不可信的第三方披露数据以获得隐私保护。直接将现有框架迁移到本地小模型会导致效用灾难性崩溃。

Method: 提出Rational Localized Adversarial Anonymization (RLAA)框架，采用攻击者-仲裁者-匿名化器(A-A-A)架构。仲裁者作为理性守门人，验证攻击者的推理，过滤对隐私保护益处微小的反馈，强制执行理性早停标准。

Result: 在不同数据集上的实验表明，RLAA实现了最佳的隐私-效用权衡，在某些情况下甚至优于现有最优方法。该框架完全本地化且无需训练。

Conclusion: RLAA通过引入仲裁者机制解决了本地小模型匿名化中的理性问题，避免了效用崩溃，为完全本地化的隐私保护提供了有效解决方案。

Abstract: Current LLM-based text anonymization frameworks usually rely on remote API services from powerful LLMs, which creates an inherent "privacy paradox": users must somehow disclose data to untrusted third parties for superior privacy preservation. Moreover, directly migrating these frameworks to local small-scale models (LSMs) offers a suboptimal solution with catastrophic collapse in utility based on our core findings. Our work argues that this failure stems not merely from the capability deficits of LSMs, but from the inherent irrationality of the greedy adversarial strategies employed by current state-of-the-art (SoTA) methods. We model the anonymization process as a trade-off between Marginal Privacy Gain (MPG) and Marginal Utility Cost (MUC), and demonstrate that greedy strategies inevitably drift into an irrational state. To address this, we propose Rational Localized Adversarial Anonymization (RLAA), a fully localized and training-free framework featuring an Attacker-Arbitrator-Anonymizer (A-A-A) architecture. RLAA introduces an arbitrator that acts as a rationality gatekeeper, validating the attacker's inference to filter out feedback providing negligible benefits on privacy preservation. This mechanism enforces a rational early-stopping criterion, and systematically prevents utility collapse. Extensive experiments on different datasets demonstrate that RLAA achieves the best privacy-utility trade-off, and in some cases even outperforms SoTA on the Pareto principle. Our code and datasets will be released upon acceptance.

</details>


### [325] [OmniSafeBench-MM: A Unified Benchmark and Toolbox for Multimodal Jailbreak Attack-Defense Evaluation](https://arxiv.org/abs/2512.06589)
*Xiaojun Jia,Jie Liao,Qi Guo,Teng Ma,Simeng Qin,Ranjie Duan,Tianlin Li,Yihao Huang,Zhitao Zeng,Dongxian Wu,Yiming Li,Wenqi Ren,Xiaochun Cao,Yang Liu*

Main category: cs.CR

TL;DR: OmniSafeBench-MM是一个全面的多模态越狱攻击防御评估工具箱，集成了13种攻击方法、15种防御策略和多样化数据集，建立了三维评估协议来衡量危害性、意图对齐和响应细节水平。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型存在安全漏洞，容易受到越狱攻击，但现有基准测试存在局限性：攻击场景有限、缺乏标准化防御评估、没有统一可复现的工具箱。

Method: 开发了OmniSafeBench-MM工具箱，集成13种代表性攻击方法和15种防御策略，构建包含9个主要风险领域和50个细粒度类别的多样化数据集，建立三维评估协议（危害性、意图对齐、响应细节水平）。

Result: 通过对10个开源和8个闭源MLLM进行广泛实验，揭示了它们对多模态越狱攻击的脆弱性，提供了标准化的评估平台。

Conclusion: OmniSafeBench-MM通过统一数据、方法和评估，为未来研究提供了标准化的基础，有助于推进多模态AI安全研究。

Abstract: Recent advances in multi-modal large language models (MLLMs) have enabled unified perception-reasoning capabilities, yet these systems remain highly vulnerable to jailbreak attacks that bypass safety alignment and induce harmful behaviors. Existing benchmarks such as JailBreakV-28K, MM-SafetyBench, and HADES provide valuable insights into multi-modal vulnerabilities, but they typically focus on limited attack scenarios, lack standardized defense evaluation, and offer no unified, reproducible toolbox. To address these gaps, we introduce OmniSafeBench-MM, which is a comprehensive toolbox for multi-modal jailbreak attack-defense evaluation. OmniSafeBench-MM integrates 13 representative attack methods, 15 defense strategies, and a diverse dataset spanning 9 major risk domains and 50 fine-grained categories, structured across consultative, imperative, and declarative inquiry types to reflect realistic user intentions. Beyond data coverage, it establishes a three-dimensional evaluation protocol measuring (1) harmfulness, distinguished by a granular, multi-level scale ranging from low-impact individual harm to catastrophic societal threats, (2) intent alignment between responses and queries, and (3) response detail level, enabling nuanced safety-utility analysis. We conduct extensive experiments on 10 open-source and 8 closed-source MLLMs to reveal their vulnerability to multi-modal jailbreak. By unifying data, methodology, and evaluation into an open-source, reproducible platform, OmniSafeBench-MM provides a standardized foundation for future research. The code is released at https://github.com/jiaxiaojunQAQ/OmniSafeBench-MM.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [326] [DUET: Agentic Design Understanding via Experimentation and Testing](https://arxiv.org/abs/2512.06247)
*Gus Henry Smith,Sandesh Adhikary,Vineet Thumuluri,Karthik Suresh,Vivek Pandit,Kartik Hegde,Hamid Shojaei,Chandra Bhagavatula*

Main category: cs.SE

TL;DR: DUET提出了一种通过实验和测试来理解硬件设计的方法，让AI代理通过迭代生成假设、使用EDA工具测试并整合结果来理解复杂的RTL代码，显著提升了形式验证的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在解决复杂软件工程任务方面表现出色，但在硬件设计任务上表现不佳。RTL代码使用SystemVerilog的低级语言特性编码复杂、动态、时间演化的行为，LLMs仅从RTL语法难以推断这些复杂行为，限制了其在代码补全、文档生成和验证等下游任务的能力。

Method: DUET方法模仿硬件设计专家理解复杂设计的方式：通过迭代实验而非一次性阅读RTL。该方法迭代生成假设，使用EDA工具（如仿真、波形检查和形式验证）进行测试，并整合结果以构建自底向上的设计理解。

Result: 评估显示，与没有实验的基线流程相比，DUET显著提高了AI代理在形式验证任务上的性能。

Conclusion: DUET通过实验和测试的方法有效解决了LLMs在理解复杂RTL代码方面的局限性，为AI代理在硬件设计任务中的性能提升提供了有效途径。

Abstract: AI agents powered by large language models (LLMs) are being used to solve increasingly complex software engineering challenges, but struggle with hardware design tasks. Register Transfer Level (RTL) code presents a unique challenge for LLMs, as it encodes complex, dynamic, time-evolving behaviors using the low-level language features of SystemVerilog. LLMs struggle to infer these complex behaviors from the syntax of RTL alone, which limits their ability to complete all downstream tasks like code completion, documentation, or verification. In response to this issue, we present DUET: a general methodology for developing Design Understanding via Experimentation and Testing. DUET mimics how hardware design experts develop an understanding of complex designs: not just via a one-off readthrough of the RTL, but via iterative experimentation using a number of tools. DUET iteratively generates hypotheses, tests them with EDA tools (e.g., simulation, waveform inspection, and formal verification), and integrates the results to build a bottom-up understanding of the design. In our evaluations, we show that DUET improves AI agent performance on formal verification, when compared to a baseline flow without experimentation.

</details>


<div id='cs.MS'></div>

# cs.MS [[Back]](#toc)

### [327] [Accurate Models of NVIDIA Tensor Cores](https://arxiv.org/abs/2512.07004)
*Faizan A. Khattak,Mantas Mikaitis*

Main category: cs.MS

TL;DR: 开发软件模型来模拟V100、A100、H100和B200数据中心GPU中低精度和混合精度矩阵乘法器的内积行为，以解决不同GPU架构间数值特性不一致导致的非可重现结果问题。


<details>
  <summary>Details</summary>
Motivation: GPU矩阵乘法器在AI训练和推理中至关重要，但不同厂商的硬件实现不符合IEEE 754浮点算术标准，导致跨GPU架构的结果不可重现。现有测试向量方法难以可靠地区分不同硬件模型，且硬件可用性有限。

Method: 开发软件模型来模拟V100、A100、H100和B200数据中心GPU中低精度和混合精度矩阵乘法器的内积行为，支持8位、16位和19位浮点格式，这些格式对混合精度算法开发者具有重要意义。

Result: 提出了能够模拟NVIDIA数据中心GPU矩阵乘法器数值特性的软件模型，包括V100、A100、H100和B200架构，覆盖了混合精度算法开发中常用的输入格式。

Conclusion: 通过软件模型模拟GPU矩阵乘法器的内积行为，为研究不同硬件平台的数值特性提供了可靠工具，有助于解决跨架构结果不可重现的问题，支持混合精度算法的开发和验证。

Abstract: Matrix multiplication is a fundamental operation in for both training of neural networks and inference. To accelerate matrix multiplication, Graphical Processing Units (GPUs) provide it implemented in hardware. Due to the increased throughput over the software-based matrix multiplication, the multipliers are increasingly used outside of AI, to accelerate various applications in scientific computing. However, matrix multipliers targeted at AI are at present not compliant with IEEE 754 floating-point arithmetic behaviour, with different vendors offering different numerical features. This leads to non-reproducible results across different generations of GPU architectures, at the matrix multiply-accumulate instruction level. To study numerical characteristics of matrix multipliers-such as rounding behaviour, accumulator width, normalization points, extra carry bits, and others-test vectors are typically constructed. Yet, these vectors may or may not distinguish between different hardware models, and due to limited hardware availability, their reliability across many different platforms remains largely untested. We present software models for emulating the inner product behavior of low- and mixed-precision matrix multipliers in the V100, A100, H100 and B200 data center GPUs in most supported input formats of interest to mixed-precision algorithm developers: 8-, 16-, and 19-bit floating point.

</details>


<div id='physics.ed-ph'></div>

# physics.ed-ph [[Back]](#toc)

### [328] [Small Language Models Reshape Higher Education: Courses, Textbooks, and Teaching](https://arxiv.org/abs/2512.06001)
*Jian Zhang,Jia Shao*

Main category: physics.ed-ph

TL;DR: 该研究以"大气物理学"为例，利用小型语言模型构建专业语料库和图像库，重新设计课程体系，将传统静态教材转变为动态数字资源库，实现从被动知识传授到主动认知发展的教学范式转变。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在高等教育中存在准确性不足和计算需求高的限制，无法满足高等教育对准确可靠知识的严格要求。相比之下，小型语言模型具有轻量级和精确检索的优势，更适合专业教育场景。

Method: 1. 收集130多个国际知名地球与环境科学期刊的55万篇全文PDF，构建专业语料库和图像库；2. 提取超过1亿个高质量句子级语料和300万张高分辨率学术图像；3. 使用小型语言模型将这些资源组织成高维向量库，实现精确检索；4. 基于小型语言模型系统性地重新设计"大气物理学"的课程、教材和教学策略。

Result: 成功构建了包含大规模专业语料和图像资源的数字资源库，设计了"跨学科-前沿"课程体系，打破了大气科学、空间科学、水文学和遥感之间的传统界限，实现了教学材料从静态滞后文本到动态数字资源库的转变，并设计了基于问题的学习路径。

Conclusion: 小型语言模型驱动的"大气物理学"课程展示了"人工智能赋能教育"的具体途径，通过精确检索和高效利用大规模教育资源，促进了从被动知识传授到主动认知发展的教学范式转变，为高等教育中AI应用提供了可行方案。

Abstract: While large language models (LLMs) have introduced novel paradigms in science and education, their adoption in higher education is constrained by inherent limitations. These include a tendency to produce inaccuracies and high computational requirements, which compromise the strict demands for accurate and reliable knowledge essential in higher education. Small language models (MiniLMs), by contrast, offer distinct advantages in professional education due to their lightweight nature and precise retrieval capabilities. This research takes "Atmospheric Physics" as an example. We established a specialized corpus and image repository by gathering over 550,000 full-text PDFs from over 130 international well-respected journals in Earth and environmental science. From this collection, we extracted over 100 million high-quality sentence-level corpus and more than 3 million high-resolution academic images. Using MiniLMs, these resources were organized into a high-dimensional vector library for precise retrieval and efficient utilization of extensive educational content. Consequently, we systematically redesigned the courses, textbooks, and teaching strategies for "Atmospheric Physics" based on MiniLMs. The course is designed as a "interdisciplinary-frontier" system, breaking down traditional boundaries between atmospheric science, space science, hydrology, and remote sensing. Teaching materials are transformed from static, lagging text formats into a dynamic digital resource library powered by MiniLM. For teaching methods, we have designed a question-based learning pathway. This paradigm promotes a shift from passive knowledge transfer to active cognitive development. Consequently, this MiniLM-driven "Atmospheric Physics" course demonstrates a specific avenue for "AI for education".

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [329] [KidSpeak: A General Multi-purpose LLM for Kids' Speech Recognition and Screening](https://arxiv.org/abs/2512.05994)
*Rohan Sharma,Dancheng Liu,Jingchen Sun,Shijie Zhou,Jiayu Qin,Jinjun Xiong,Changyou Chen*

Main category: eess.AS

TL;DR: KidSpeak：首个专为儿童语音设计的多任务语音增强基础模型，结合FASA自动对齐工具，解决现有AI模型在儿童语音处理上的不足，特别针对早期发育和语言障碍儿童。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型主要基于清晰、成人口语设计的数据集，无法有效处理儿童语音，特别是早期发育阶段或有语言障碍的儿童。现有模型在儿童语音领域存在明显不足，需要专门解决方案。

Method: 1. 提出KidSpeak多任务语音增强基础模型，采用两阶段训练过程，将语音学知识融入语音编码器；2. 开发FASA（灵活自动语音对齐器）工具，用于构建高质量训练数据集；3. 在CHILDES数据集上验证方法有效性。

Result: 1. KidSpeak在四个独立任务上平均准确率达到87%；2. FASA工具相比人工标注，将嘈杂儿童语音数据的对齐质量提升了13.6倍；3. 构建了高质量的儿童语音训练和评估数据集。

Conclusion: KidSpeak和FASA代表了首个针对儿童语音和语言治疗的全面解决方案，提供了多功能语音大模型和强大的对齐工具，填补了儿童语音AI领域的空白。

Abstract: With the rapid advancement of conversational and diffusion-based AI, there is a growing adoption of AI in educational services, ranging from grading and assessment tools to personalized learning systems that provide targeted support for students. However, this adaptability has yet to fully extend to the domain of children's speech, where existing models often fail due to their reliance on datasets designed for clear, articulate adult speech. Children, particularly those in early developmental stages or with speech and language pathologies, present unique challenges that current AI models and datasets are ill-equipped to handle. To address this, we introduce KidSpeak, a multi-task speech-enhanced Foundation Model capable of both generative and discriminative tasks specifically tailored to children's speech patterns. Our framework employs a two-stage training process that incorporates phonetic knowledge into the speech encoder, achieving an average accuracy of 87% across four separate tasks. Furthermore, recognizing the limitations of scalable human annotation and existing speech alignment tools, we propose the Flexible and Automatic Speech Aligner (FASA) and leverage the method to construct high quality datasets for training and evaluation. This novel alignment tool significantly improves the quality of aligned children's speech from noisy data, enhancing data quality by 13.6x compared to human annotations, as demonstrated on the CHILDES dataset. To the best of our knowledge, KidSpeak and FASA represent the first comprehensive solution designed for speech and language therapy in children, offering both a multi-purpose speech LLM and a robust alignment tool.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [330] [AI-Generated Compromises for Coalition Formation: Modeling, Simulation, and a Textual Case Study](https://arxiv.org/abs/2512.05983)
*Eyal Briman,Ehud Shapiro,Nimrod Talmon*

Main category: cs.MA

TL;DR: 论文提出使用AI和NLP技术，在文本编辑的语义空间中寻找多数支持的妥协提案，以促进大规模民主文本协作（如宪法起草）。


<details>
  <summary>Details</summary>
Motivation: 在AI的论证、调解和谈判等领域，寻找代理人提案之间的妥协方案是一个核心挑战。Elkind等人（2021）提出了基于度量空间的联盟形成过程，但如何有效找到妥协提案仍是一个开放问题。特别是在协作编写文本文档（如民主制定社区宪法）的领域，传统工具存在局限。

Method: 1. 形式化一个包含代理人有限理性和不确定性的整体模型；2. 应用NLP技术和LLMs创建文本的语义度量空间；3. 开发算法来生成合适的妥协点；4. 通过模拟各种联盟形成过程来评估算法效果。

Result: 展示了AI在促进大规模民主文本编辑（如协作起草宪法）方面的潜力，证明了所开发算法在寻找多数支持的妥协提案方面的有效性。

Conclusion: AI模型和NLP技术能够有效支持在语义空间中寻找妥协提案，为解决传统工具难以处理的大规模民主文本协作问题提供了新途径。

Abstract: The challenge of finding compromises between agent proposals is fundamental to AI sub-fields such as argumentation, mediation, and negotiation. Building on this tradition, Elkind et al. (2021) introduced a process for coalition formation that seeks majority-supported proposals preferable to the status quo, using a metric space where each agent has an ideal point. The crucial step in this iterative process involves identifying compromise proposals around which agent coalitions can unite. How to effectively find such compromise proposals, however, remains an open question. We address this gap by formalizing a holistic model that encompasses agent bounded rationality and uncertainty and developing AI models to generate such compromise proposals. We focus on the domain of collaboratively writing text documents -- e.g., to enable the democratic creation of a community constitution. We apply NLP (Natural Language Processing) techniques and utilize LLMs (Large Language Models) to create a semantic metric space for text and develop algorithms to suggest suitable compromise points. To evaluate the effectiveness of our algorithms, we simulate various coalition formation processes and demonstrate the potential of AI to facilitate large-scale democratic text editing, such as collaboratively drafting a constitution, an area where traditional tools are limited.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [331] [Human Geometry Distribution for 3D Animation Generation](https://arxiv.org/abs/2512.07459)
*Xiangjun Tang,Biao Zhang,Peter Wonka*

Main category: cs.GR

TL;DR: 提出两阶段框架：第一阶段学习紧凑的分布式潜在表示，实现高质量人体几何生成；第二阶段在潜在空间中生成多样化动画，保持短期动态细节和长期一致性。


<details>
  <summary>Details</summary>
Motivation: 生成逼真的人体几何动画面临挑战：需要建模自然的服装动态和精细几何细节，同时数据有限。现有方法在SMPL与化身几何映射、有限运动数据利用方面存在不足。

Method: 1. 提出紧凑的分布式潜在表示，建立更均匀的SMPL与化身几何映射；2. 提出生成动画模型，通过身份条件设计在利用有限运动数据多样性的同时，保持短期过渡和长期一致性。两阶段框架：第一阶段学习潜在空间，第二阶段在潜在空间中生成动画。

Result: 潜在空间生成的人体几何质量超越先前方法（Chamfer距离降低90%）；动画模型合成的动画具有详细自然的动态（用户研究评分提高2.2倍），在所有评估指标上取得最佳结果。

Conclusion: 提出的两阶段框架成功解决了有限数据下生成逼真人体几何动画的挑战，通过改进的潜在表示和生成动画模型，实现了高质量的几何生成和自然动态的动画合成。

Abstract: Generating realistic human geometry animations remains a challenging task, as it requires modeling natural clothing dynamics with fine-grained geometric details under limited data. To address these challenges, we propose two novel designs. First, we propose a compact distribution-based latent representation that enables efficient and high-quality geometry generation. We improve upon previous work by establishing a more uniform mapping between SMPL and avatar geometries. Second, we introduce a generative animation model that fully exploits the diversity of limited motion data. We focus on short-term transitions while maintaining long-term consistency through an identity-conditioned design. These two designs formulate our method as a two-stage framework: the first stage learns a latent space, while the second learns to generate animations within this latent space. We conducted experiments on both our latent space and animation model. We demonstrate that our latent space produces high-fidelity human geometry surpassing previous methods ($90\%$ lower Chamfer Dist.). The animation model synthesizes diverse animations with detailed and natural dynamics ($2.2 \times$ higher user study score), achieving the best results across all evaluation metrics.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [332] [MATEX: A Multi-Agent Framework for Explaining Ethereum Transactions](https://arxiv.org/abs/2512.06933)
*Zifan Peng*

Main category: cs.CE

TL;DR: 论文提出了matex框架，通过多智能体协作生成以太坊交易的忠实解释，结合链上证据和协议语义来帮助用户理解复杂交易。


<details>
  <summary>Details</summary>
Motivation: 理解复杂的以太坊交易具有挑战性：多跳代币流、嵌套合约调用和不透明的执行路径导致用户盲目签名。通过对普通用户、开发者和审计人员的访谈，发现需要基于链上证据和真实世界协议语义的忠实、逐步解释。

Method: 提出matex认知多智能体框架，将交易理解建模为协作调查过程，结合快速假设生成、动态链下知识检索、证据感知合成和对抗验证来生成忠实解释。

Result: 论文介绍了matex框架的设计，但没有提供具体的实验结果数据。框架旨在通过多智能体协作解决以太坊交易理解问题。

Conclusion: matex框架通过模拟人类调查过程的多智能体协作，能够生成基于证据和协议语义的以太坊交易解释，帮助用户避免盲目签名。

Abstract: Understanding a complicated Ethereum transaction remains challenging: multi-hop token flows, nested contract calls, and opaque execution paths routinely lead users to blind signing. Based on interviews with everyday users, developers, and auditors, we identify the need for faithful, step-wise explanations grounded in both on-chain evidence and real-world protocol semantics. To meet this need, we introduce (matex, a cognitive multi-agent framework that models transaction understanding as a collaborative investigation-combining rapid hypothesis generation, dynamic off-chain knowledge retrieval, evidence-aware synthesis, and adversarial validation to produce faithful explanations.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [333] [Proof of Concept for Mammography Classification with Enhanced Compactness and Separability Modules](https://arxiv.org/abs/2512.06575)
*Fariza Dahes*

Main category: eess.IV

TL;DR: 验证并扩展了医学图像分类方法框架，将改进的ConvNeXt Tiny架构应用于乳腺X光分类，评估了GAGM和SEVector模块的有效性，但发现FSL损失在乳腺X光分类中效果不明显。


<details>
  <summary>Details</summary>
Motivation: 验证先前在阿尔茨海默症MRI分类中表现良好的方法框架（包含GAGM、SEVector和FSL）是否可迁移到乳腺X光分类任务中，并扩展该框架的功能。

Method: 使用Kaggle数据集（整合INbreast、MIAS、DDSM），比较基线CNN、ConvNeXt Tiny和InceptionV3骨干网络，并集成GAGM和SEVector模块。进行多指标评估、特征可解释性分析（Grad-CAM），并开发交互式临床探索仪表板。

Result: GAGM和SEVector模块能有效增强特征区分能力并减少假阴性（特别是恶性病例），但特征平滑损失（FSL）在乳腺X光分类条件下未显示可测量的改进。扩展了多指标评估和可解释性分析工具。

Conclusion: 成功验证了GAGM和SEVector模块在乳腺X光分类中的有效性，但FSL的效果可能依赖于特定架构和计算假设。未来需要探索改进类内紧凑性和类间分离性的方法，以更好区分恶性和良性病例。

Abstract: This study presents a validation and extension of a recent methodological framework for medical image classification. While an improved ConvNeXt Tiny architecture, integrating Global Average and Max Pooling fusion (GAGM), lightweight channel attention (SEVector), and Feature Smoothing Loss (FSL), demonstrated promising results on Alzheimer MRI under CPU friendly conditions, our work investigates its transposability to mammography classification. Using a Kaggle dataset that consolidates INbreast, MIAS, and DDSM mammography collections, we compare a baseline CNN, ConvNeXt Tiny, and InceptionV3 backbones enriched with GAGM and SEVector modules. Results confirm the effectiveness of GAGM and SEVector in enhancing feature discriminability and reducing false negatives, particularly for malignant cases. In our experiments, however, the Feature Smoothing Loss did not yield measurable improvements under mammography classification conditions, suggesting that its effectiveness may depend on specific architectural and computational assumptions. Beyond validation, our contribution extends the original framework through multi metric evaluation (macro F1, per class recall variance, ROC/AUC), feature interpretability analysis (Grad CAM), and the development of an interactive dashboard for clinical exploration. As a perspective, we highlight the need to explore alternative approaches to improve intra class compactness and inter class separability, with the specific goal of enhancing the distinction between malignant and benign cases in mammography classification.

</details>


### [334] [Stronger is not better: Better Augmentations in Contrastive Learning for Medical Image Segmentation](https://arxiv.org/abs/2512.05992)
*Azeez Idris,Abdurahman Ali Mohammed,Samuel Fanijo*

Main category: eess.IV

TL;DR: 本文评估了强数据增强在医学图像语义分割任务中的效果，发现现有增强方法并不总是提升性能，并探索了更有效的增强策略。


<details>
  <summary>Details</summary>
Motivation: 自监督对比学习在语义分割等下游任务中表现出色，其中强数据增强是关键组件。然而，现有研究表明这些增强方法在医学图像分割中可能并不总是有效，需要探索更适合医学图像的增强策略。

Method: 通过实验评估现有强数据增强方法（多种增强技术的组合应用）在医学图像语义分割中的效果，并尝试其他增强技术来寻找性能更好的方案。

Result: 研究发现，现有的数据增强方法并不总是能提升医学图像语义分割的性能，但通过实验发现了其他能够提供改进性能的增强方法。

Conclusion: 对于医学图像语义分割任务，需要针对性地设计和选择数据增强方法，而不是简单套用通用的强数据增强策略。

Abstract: Self-supervised contrastive learning is among the recent representation learning methods that have shown performance gains in several downstream tasks including semantic segmentation. This paper evaluates strong data augmentation, one of the most important components for self-supervised contrastive learning's improved performance. Strong data augmentation involves applying the composition of multiple augmentation techniques on images. Surprisingly, we find that the existing data augmentations do not always improve performance for semantic segmentation for medical images. We experiment with other augmentations that provide improved performance.

</details>


### [335] [Semantic Temporal Single-photon LiDAR](https://arxiv.org/abs/2512.06008)
*Fang Li,Tonglin Mu,Shuling Li,Junran Guo,Keyuan Li,Jianing Li,Ziyang Luo,Xiaodong Fan,Ye Chen,Yunfeng Liu,Hong Cai,Lip Ket Chin,Jinbei Zhang,Shihai Sun*

Main category: eess.IV

TL;DR: 提出基于自更新语义知识库的语义TSP-LiDAR，将目标识别建模为语义通信问题，显著提升低信噪比和短采集时间下的性能，并能动态适应未知目标


<details>
  <summary>Details</summary>
Motivation: 现有TSP-LiDAR方法无法处理开放集场景中的未知目标，且在低信噪比和短采集时间下性能显著下降，需要更鲁棒和自适应的解决方案

Method: 将TSP-LiDAR目标识别过程建模为语义通信问题，构建自更新语义知识库（SKB），通过语义特征动态更新机制适应新目标，无需大规模神经网络重训练

Result: 仿真和实验结果表明，该方法在低信噪比和有限采集时间条件下优于传统方法；自更新SKB机制对九种未知目标的识别准确率达到89%（无更新机制为66%）

Conclusion: 该框架在复杂动态环境中具有自适应和鲁棒的目标识别潜力，通过语义通信和自更新知识库解决了开放集场景和恶劣条件下的识别挑战

Abstract: Temporal single-photon (TSP-) LiDAR presents a promising solution for imaging-free target recognition over long distances with reduced size, cost, and power consumption. However, existing TSP-LiDAR approaches are ineffective in handling open-set scenarios where unknown targets emerge, and they suffer significant performance degradation under low signal-to-noise ratio (SNR) and short acquisition times (fewer photons). Here, inspired by semantic communication, we propose a semantic TSP-LiDAR based on a self-updating semantic knowledge base (SKB), in which the target recognition processing of TSP-LiDAR is formulated as a semantic communication. The results, both simulation and experiment, demonstrate that our approach surpasses conventional methods, particularly under challenging conditions of low SNR and limited acquisition time. More importantly, our self-updating SKB mechanism can dynamically update the semantic features of newly encountered targets in the SKB, enabling continuous adaptation without the need for extensive retraining of the neural network. In fact, a recognition accuracy of 89% is achieved on nine types of unknown targets in real-world experiments, compared to 66% without the updating mechanism. These findings highlight the potential of our framework for adaptive and robust target recognition in complex and dynamic environments.

</details>


### [336] [Clinical Interpretability of Deep Learning Segmentation Through Shapley-Derived Agreement and Uncertainty Metrics](https://arxiv.org/abs/2512.07224)
*Tianyi Ren,Daniel Low,Pittra Jaengprajak,Juampablo Heras Rivera,Jacob Ruzevick,Mehmet Kurt*

Main category: eess.IV

TL;DR: 该研究提出使用对比度级Shapley值来解释医学图像分割模型，通过评估不同MRI对比度对模型性能的重要性，提供临床可解释的模型可靠性指标。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习模型在医学图像分割中表现出色，但其可解释性对于临床实践中的接受和整合至关重要。现有研究多关注梯度方法识别影响区域，但缺乏对模型性能如何公平归因于不同成像对比度的系统性解释。

Method: 使用对比度级Shapley值系统扰动模型输入以评估特征重要性。在BraTS 2024数据集上，为四种MRI对比度和四种模型架构生成Shapley值排名。提出两个指标：模型与"临床"成像排名的吻合度，以及通过交叉验证折叠中Shapley排名方差量化的不确定性。

Result: 高性能病例（Dice >0.6）与临床排名吻合度显著更高。Shapley排名方差增加与性能下降相关（U-Net: r=-0.581）。这些指标为模型可靠性提供了临床可解释的代理。

Conclusion: 对比度级Shapley值提供了一种临床对齐的方法来解释分割模型，提出的指标帮助临床医生更好地理解最先进的分割模型，为模型可靠性评估提供了实用工具。

Abstract: Segmentation is the identification of anatomical regions of interest, such as organs, tissue, and lesions, serving as a fundamental task in computer-aided diagnosis in medical imaging. Although deep learning models have achieved remarkable performance in medical image segmentation, the need for explainability remains critical for ensuring their acceptance and integration in clinical practice, despite the growing research attention in this area. Our approach explored the use of contrast-level Shapley values, a systematic perturbation of model inputs to assess feature importance. While other studies have investigated gradient-based techniques through identifying influential regions in imaging inputs, Shapley values offer a broader, clinically aligned approach, explaining how model performance is fairly attributed to certain imaging contrasts over others. Using the BraTS 2024 dataset, we generated rankings for Shapley values for four MRI contrasts across four model architectures. Two metrics were proposed from the Shapley ranking: agreement between model and ``clinician" imaging ranking, and uncertainty quantified through Shapley ranking variance across cross-validation folds. Higher-performing cases (Dice \textgreater0.6) showed significantly greater agreement with clinical rankings. Increased Shapley ranking variance correlated with decreased performance (U-Net: $r=-0.581$). These metrics provide clinically interpretable proxies for model reliability, helping clinicians better understand state-of-the-art segmentation models.

</details>


### [337] [Affine Subspace Models and Clustering for Patch-Based Image Denoising](https://arxiv.org/abs/2512.07259)
*Tharindu Wickremasinghe,Marco F. Duarte*

Main category: eess.IV

TL;DR: 该论文提出使用仿射子空间模型替代线性子空间进行图像块聚类，以更好地匹配图像块向量空间的几何结构，并展示了一个基于仿射子空间聚类的简单去噪算法。


<details>
  <summary>Details</summary>
Motivation: 线性子空间模型不适用于图像块聚类，因为图像是非负的，在向量空间中不围绕原点分布。需要更好的模型来匹配图像块向量空间的几何结构。

Method: 使用仿射子空间模型进行图像块聚类，并提出基于最小二乘投影的仿射子空间聚类去噪算法。回顾了多种解决仿射子空间聚类问题的算法方法。

Result: 实验结果显示，仿射子空间聚类在聚类和去噪性能上都有显著改进。

Conclusion: 仿射子空间模型比线性子空间模型更适合图像块聚类，能更好地匹配图像数据的几何特性，在图像处理应用中表现出更好的性能。

Abstract: Image tile-based approaches are popular in many image processing applications such as denoising (e.g., non-local means). A key step in their use is grouping the images into clusters, which usually proceeds iteratively splitting the images into clusters and fitting a model for the images in each cluster. Linear subspaces have emerged as a suitable model for tile clusters; however, they are not well matched to images patches given that images are non-negative and thus not distributed around the origin in the tile vector space. We study the use of affine subspace models for the clusters to better match the geometric structure of the image tile vector space. We also present a simple denoising algorithm that relies on the affine subspace clustering model using least squares projection. We review several algorithmic approaches to solve the affine subspace clustering problem and show experimental results that highlight the performance improvements in clustering and denoising.

</details>


### [338] [Precise Liver Tumor Segmentation in CT Using a Hybrid Deep Learning-Radiomics Framework](https://arxiv.org/abs/2512.07574)
*Xuecheng Li,Weikuan Jia,Komildzhon Sharipov,Alimov Ruslan,Lutfuloev Mazbutdzhon,Ismoilov Shuhratjon,Yuanjie Zheng*

Main category: eess.IV

TL;DR: 提出混合框架結合注意力增強級聯U-Net、手工放射組學特徵和3D CNN細化，用於肝臟和肝腫瘤聯合分割，解決CT影像中腫瘤邊界模糊、對比度低等挑戰。


<details>
  <summary>Details</summary>
Motivation: 手動勾畫肝腫瘤輪廓耗時、觀察者依賴且難以標準化，而自動分割面臨腫瘤-實質對比度低、邊界模糊、增強模式異質性及血管等混淆結構的挑戰。

Method: 1) 2.5D兩階段網絡(密集連接編碼器、亞像素卷積解碼器、多尺度注意力門)生成初始概率圖；2) 三切片細化規則增強層間一致性；3) 提取728個放射組學特徵並篩選至20個，隨機森林分類器去除假陽性；4) 基於AlexNet的緊湊3D CNN在腫瘤邊界窄帶進行體素級重標記和輪廓平滑。

Result: 方法能夠恢復薄層和小病灶同時抑制孤立噪聲，通過放射組學特徵選擇有效去除假陽性區域，最終實現精確的肝臟和肝腫瘤分割。

Conclusion: 提出的混合框架結合深度學習和傳統特徵工程，有效解決肝腫瘤分割的多重挑戰，為治療規劃、導航和療效評估提供可靠的自動化解決方案。

Abstract: Accurate three-dimensional delineation of liver tumors on contrast-enhanced CT is a prerequisite for treatment planning, navigation and response assessment, yet manual contouring is slow, observer-dependent and difficult to standardise across centres. Automatic segmentation is complicated by low lesion-parenchyma contrast, blurred or incomplete boundaries, heterogeneous enhancement patterns, and confounding structures such as vessels and adjacent organs. We propose a hybrid framework that couples an attention-enhanced cascaded U-Net with handcrafted radiomics and voxel-wise 3D CNN refinement for joint liver and liver-tumor segmentation. First, a 2.5D two-stage network with a densely connected encoder, sub-pixel convolution decoders and multi-scale attention gates produces initial liver and tumor probability maps from short stacks of axial slices. Inter-slice temporal consistency is then enforced by a simple three-slice refinement rule along the cranio-caudal direction, which restores thin and tiny lesions while suppressing isolated noise. Next, 728 radiomic descriptors spanning intensity, texture, shape, boundary and wavelet feature groups are extracted from candidate lesions and reduced to 20 stable, highly informative features via multi-strategy feature selection; a random forest classifier uses these features to reject false-positive regions. Finally, a compact 3D patch-based CNN derived from AlexNet operates in a narrow band around the tumor boundary to perform voxel-level relabelling and contour smoothing.

</details>


### [339] [R2MF-Net: A Recurrent Residual Multi-Path Fusion Network for Robust Multi-directional Spine X-ray Segmentation](https://arxiv.org/abs/2512.07576)
*Xuecheng Li,Weikuan Jia,Komildzhon Sharipov,Sharipov Hotam Beknazarovich,Farzona S. Ataeva,Qurbonaliev Alisher,Yuanjie Zheng*

Main category: eess.IV

TL;DR: R2MF-Net：用于多方向脊柱X光图像自动分割的循环残差多路径编码器-解码器网络，通过级联粗-细分割、改进的Inception特征提取器和跨阶段多尺度跳跃连接，提高在低对比度图像中的分割精度。


<details>
  <summary>Details</summary>
Motivation: 脊柱X光图像分割是定量脊柱侧弯评估（如Cobb角测量、椎体平移估计和曲率分类）的先决条件。目前临床实践中，医生需要获取冠状位、左屈和右屈X光片来联合评估畸形严重程度和脊柱灵活性，但分割步骤仍然高度依赖手动操作，耗时且不可重复，特别是在低对比度图像、存在肋骨阴影或组织重叠的情况下。

Method: 提出R2MF-Net网络，采用级联结构：粗分割网络和细分割网络。两个阶段都采用改进的Inception风格多分支特征提取器，在跳跃路径中插入循环残差跳跃连接（R2-Jump）模块来逐步对齐编码器和解码器语义。通过多尺度跨阶段跳跃（MC-Skip）机制，细网络可以重用粗网络多个解码器层次的特征表示。在瓶颈处使用轻量级空间-通道挤压-激励块（SCSE-Lite）来增强脊柱相关激活并抑制无关结构和背景噪声。

Result: 在包含228组冠状位、左屈和右屈脊柱X光图像的临床多视角放射影像数据集上进行评估，该数据集带有专家标注。

Conclusion: R2MF-Net是针对多方向脊柱X光图像自动分割的专门网络，通过级联结构、多路径特征提取、语义对齐机制和跨阶段特征重用，旨在解决传统手动分割在低对比度、存在干扰结构情况下的局限性，提高分割的准确性和稳定性。

Abstract: Accurate segmentation of spinal structures in X-ray images is a prerequisite for quantitative scoliosis assessment, including Cobb angle measurement, vertebral translation estimation and curvature classification. In routine practice, clinicians acquire coronal, left-bending and right-bending radiographs to jointly evaluate deformity severity and spinal flexibility. However, the segmentation step remains heavily manual, time-consuming and non-reproducible, particularly in low-contrast images and in the presence of rib shadows or overlapping tissues. To address these limitations, this paper proposes R2MF-Net, a recurrent residual multi-path encoder--decoder network tailored for automatic segmentation of multi-directional spine X-ray images. The overall design consists of a coarse segmentation network and a fine segmentation network connected in cascade. Both stages adopt an improved Inception-style multi-branch feature extractor, while a recurrent residual jump connection (R2-Jump) module is inserted into skip paths to gradually align encoder and decoder semantics. A multi-scale cross-stage skip (MC-Skip) mechanism allows the fine network to reuse hierarchical representations from multiple decoder levels of the coarse network, thereby strengthening the stability of segmentation across imaging directions and contrast conditions. Furthermore, a lightweight spatial-channel squeeze-and-excitation block (SCSE-Lite) is employed at the bottleneck to emphasize spine-related activations and suppress irrelevant structures and background noise. We evaluate R2MF-Net on a clinical multi-view radiograph dataset comprising 228 sets of coronal, left-bending and right-bending spine X-ray images with expert annotations.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [340] [GPU-Accelerated Optimization Solver for Unit Commitment in Large-Scale Power Grids](https://arxiv.org/abs/2512.06715)
*Hussein Sharadga,Javad Mohammadi*

Main category: math.OC

TL;DR: 提出基于GPU加速的PDHG算法求解大规模电网机组组合问题，相比传统CPU方法显著减少计算时间


<details>
  <summary>Details</summary>
Motivation: 大规模电网机组组合问题计算复杂度高，传统CPU方法求解时间长，需要更高效的计算方法

Method: 使用GPU加速的原始-对偶混合梯度算法求解松弛线性子问题，结合分支定界法

Result: 在4224、6049和6717节点的大规模系统上验证，保持解质量的同时获得显著加速

Conclusion: GPU加速的PDHG算法能有效解决大规模机组组合问题，显著提升计算效率

Abstract: This work presents a GPU-accelerated solver for the unit commitment (UC) problem in large-scale power grids. The solver uses the Primal-Dual Hybrid Gradient (PDHG) algorithm to efficiently solve the relaxed linear subproblem, achieving faster bound estimation and improved crossover and branch-and-bound convergence compared to conventional CPU-based methods. These improvements significantly reduce the total computation time for the mixed-integer linear UC problem. The proposed approach is validated on large-scale systems, including 4224-, 6049-, and 6717-bus networks with long control horizons and computationally intensive problems, demonstrating substantial speed-ups while maintaining solution quality.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [341] [An Index-based Approach for Efficient and Effective Web Content Extraction](https://arxiv.org/abs/2512.06641)
*Yihan Chen,Benfeng Xu,Xiaorui Wang,Zhendong Mao*

Main category: cs.IR

TL;DR: 提出Index-based Web Content Extraction方法，将网页内容提取从缓慢的生成式任务转变为高效的索引预测任务，显著提升提取速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着Web代理（如Deep Research）消耗大量网页进行信息收集和分析，LLM上下文管理成为重要挑战。现有解决方案存在不足：生成式提取模型延迟高，基于规则的启发式方法缺乏适应性，分块重排序方法忽略网页结构。

Method: 将HTML分割为结构感知、可寻址的片段，仅提取与查询相关内容的位罝索引。这种方法将提取延迟与内容长度解耦，实现快速、查询相关的提取。

Result: 作为RAG QA系统中的后检索处理组件，该方法提高了QA准确性。在主内容提取（ME）和查询相关提取（QE）两种场景下，实验结果显示该方法在准确性和速度上都优于现有工作。

Conclusion: Index-based Web Content Extraction方法有效弥合了LLM与海量网页之间的差距，通过将提取过程重构为高效的判别性索引预测任务，实现了效果和效率的双重提升。

Abstract: As web agents (e.g., Deep Research) routinely consume massive volumes of web pages to gather and analyze information, LLM context management -- under large token budgets and low signal density -- emerges as a foundational, high-importance, and technically challenging problem for agentic and RAG pipelines. Existing solutions for extracting relevant content are inadequate: generative extraction models suffer from high latency, rule-based heuristics lack adaptability, and chunk-and-rerank methods are blind to webpage structure. To overcome these issues, we introduce Index-based Web Content Extraction to reframe the extraction process from slow, token-by-token generation into a highly efficient, discriminative task of index prediction, achieving both effectiveness and efficiency. We partition HTML into structure-aware, addressable segments, and extract only the positional indices of content relevant to a given query. This method decouples extraction latency from content length, enabling rapid, query-relevant extraction. We first evaluate our method as a post-retrieval processing component within an RAG QA system and find that it improves QA accuracy. Then we directly measure its match rate with the target content in two scenarios: main content extraction (ME) and query-relevant extraction (QE). Experimental results show that our method outperforms existing works in both accuracy and speed, effectively bridging the gap between LLMs and the vast webpages.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [342] [A-3PO: Accelerating Asynchronous LLM Training with Staleness-aware Proximal Policy Approximation](https://arxiv.org/abs/2512.06547)
*Xiaocan Li,Shiliang Wu,Zheng Shen*

Main category: cs.LG

TL;DR: A-3PO通过近似计算近端策略来消除异步强化学习中解耦损失的计算瓶颈，减少18%训练时间同时保持性能


<details>
  <summary>Details</summary>
Motivation: 解耦损失在异步强化学习中能处理数据陈旧性问题，但近端策略需要在每个训练步骤中进行额外的前向传播，对大型语言模型造成计算瓶颈

Method: 提出A-3PO（近似近端策略优化），通过简单插值近似近端策略，避免显式计算，消除额外前向传播开销

Result: A-3PO减少18%训练时间，同时保持与原始解耦损失方法相当的性能表现

Conclusion: 通过近似近端策略可以有效消除异步强化学习中的计算瓶颈，在保持稳定性的同时显著提升训练效率

Abstract: Decoupled loss has been a successful reinforcement learning (RL) algorithm to deal with the high data staleness under the asynchronous RL setting. Decoupled loss improves coupled-loss style of algorithms' (e.g., PPO, GRPO) learning stability by introducing a proximal policy to decouple the off-policy corrections (importance weight) from the controlling policy updates (trust region). However, the proximal policy requires an extra forward pass through the network at each training step, creating a computational bottleneck for large language models. We observe that since the proximal policy only serves as a trust region anchor between the behavior and target policies, we can approximate it through simple interpolation without explicit computation. We call this approach A-3PO (APproximated Proximal Policy Optimization). A-3PO eliminates this overhead, reducing training time by 18% while maintaining comparable performance. Code & off-the-shelf example are available at: https://github.com/inclusionAI/AReaL/blob/main/docs/algorithms/prox_approx.md

</details>


### [343] [When Distance Distracts: Representation Distance Bias in BT-Loss for Reward Models](https://arxiv.org/abs/2512.06343)
*Tong Xie,Andrew Bai,Yuanhao Ban,Yunqi Hong,Haoyu Li,Cho-jui Hsieh*

Main category: cs.LG

TL;DR: 本文分析了Bradley-Terry损失函数的梯度特性，发现其梯度范数受预测误差和表示距离双重影响，导致小距离对的梯度被抑制而大距离对梯度被放大。作者提出NormBT方法，通过自适应归一化平衡表示距离效应，专注于预测误差。


<details>
  <summary>Details</summary>
Motivation: Bradley-Terry损失函数是LLM对齐中奖励模型的核心目标函数，但其梯度分析显示存在一个关键限制：梯度范数不仅取决于预测误差（选择的响应与拒绝的响应之间的奖励差异），还受表示距离（在最后一层输出空间中的距离）的影响。这导致小距离对的梯度更新过弱，即使它们被错误排序，而大距离对的梯度更新过强，从而扭曲了学习过程。

Method: 提出NormBT方法，这是一种自适应成对归一化方案。它通过归一化处理来平衡表示距离的影响，使学习信号更集中于预测误差。NormBT是一个轻量级的、可直接替换BT损失的方案，计算开销可忽略不计。

Result: 在各种LLM骨干网络和数据集上，NormBT一致地提高了奖励模型的性能。在RewardBench的推理类别中，性能提升超过5%，该类别包含大量小距离对。

Conclusion: 这项工作揭示了广泛使用的BT目标函数的一个关键限制，并提供了一个简单有效的修正方案。NormBT通过平衡表示距离效应，使奖励模型能够更好地学习细粒度区分，特别是在小距离对的情况下。

Abstract: Reward models are central to Large Language Model (LLM) alignment within the framework of RLHF. The standard objective used in reward modeling is the Bradley-Terry (BT) loss, which learns from pairwise data consisting of a pair of chosen and rejected responses. In this work, we analyze the per-sample gradient of BT-loss and show that its norm scales with two distinct components: (1) the difference in predicted rewards between chosen and rejected responses, which reflects the prediction error, and critically, (2) representation distance between the pair measured in the output space of the final layer. While the first term captures the intended training signal, we show that the second term can significantly impact the update magnitude and misalign learning. Specifically, pairs with small representation distance often receive vanishingly weak updates, even when misranked, while pairs with large distance receive disproportionately strong updates. This leads to gradients from large-distance pairs to overshadow those from small-distance pairs, where fine-grained distinctions are especially important. To overcome this limitation, we propose NormBT, an adaptive pair-wise normalization scheme that balances representation-driven effects and focuses learning signals on prediction error. NormBT is a lightweight, drop-in integration to BT loss with negligible overhead. Across various LLM backbones and datasets, NormBT improves reward model performance consistently, with notable gains of over 5% on the Reasoning category of RewardBench, which contains numerous small-distance pairs. This work reveals a key limitation in the widely used BT objective and provides a simple, effective correction.

</details>


### [344] [LLM-Upgraded Graph Reinforcement Learning for Carbon-Aware Job Scheduling in Smart Manufacturing](https://arxiv.org/abs/2512.06351)
*Zhiying Yang,Fang Liu,Wei Zhang,Xin Lou,Malcolm Yoke Hean Low,Boon Ping Gan*

Main category: cs.LG

TL;DR: LUCA是一个结合大语言模型和图强化学习的碳感知柔性作业车间调度框架，通过融合图神经网络和LLM嵌入来优化制造时间和碳排放目标。


<details>
  <summary>Details</summary>
Motivation: 智能制造系统中存在动态和可持续调度的挑战，需要同时优化制造时间和碳排放目标，传统方法难以有效处理结构特征和上下文语义的融合。

Method: 提出LUCA框架，集成图神经网络和大语言模型，通过精心设计的提示策略生成融合嵌入，捕捉调度状态的结构特征和上下文语义，然后由深度强化学习策略网络生成实时调度决策。

Result: 在合成数据集上，相比最佳对比算法平均降低4.1%制造时间（最高12.2%），同时保持相同排放水平；在公共数据集上，制造时间和排放都有额外改善。

Conclusion: LUCA在碳感知调度方面有效且实用，能够为智能制造提供可持续的调度解决方案。

Abstract: This paper presents \textsc{Luca}, a \underline{l}arge language model (LLM)-\underline{u}pgraded graph reinforcement learning framework for \underline{c}arbon-\underline{a}ware flexible job shop scheduling. \textsc{Luca} addresses the challenges of dynamic and sustainable scheduling in smart manufacturing systems by integrating a graph neural network and an LLM, guided by a carefully designed in-house prompting strategy, to produce a fused embedding that captures both structural characteristics and contextual semantics of the latest scheduling state. This expressive embedding is then processed by a deep reinforcement learning policy network, which generates real-time scheduling decisions optimized for both makespan and carbon emission objectives. To support sustainability goals, \textsc{Luca} incorporates a dual-objective reward function that encourages both energy efficiency and scheduling timeliness. Experimental results on both synthetic and public datasets demonstrate that \textsc{Luca} consistently outperforms comparison algorithms. For instance, on the synthetic dataset, it achieves an average of 4.1\% and up to 12.2\% lower makespan compared to the best-performing comparison algorithm while maintaining the same emission level. On public datasets, additional gains are observed for both makespan and emission. These results demonstrate that \textsc{Luca} is effective and practical for carbon-aware scheduling in smart manufacturing.

</details>


### [345] [A Fast and Effective Solution to the Problem of Look-ahead Bias in LLMs](https://arxiv.org/abs/2512.06607)
*Humzah Merchant,Bradford Levy*

Main category: cs.LG

TL;DR: 提出一种通过调整大模型logits来消除前瞻性偏差的方法，使用一对小模型分别学习应遗忘和保留的信息，在推理时引导生成


<details>
  <summary>Details</summary>
Motivation: 将LLMs应用于金融预测任务时面临前瞻性偏差挑战，因为模型在长时间序列数据上训练，无法进行金融领域常用的回测，而从头重新训练前沿模型成本过高

Method: 在推理时通过调整大基础模型的logits来引导生成，使用一对较小的专用模型：一个在应遗忘信息上微调，另一个在应保留信息上微调

Result: 该方法能有效消除字面和语义知识，纠正偏差，并且优于先前的方法

Conclusion: 提出了一种快速、有效且低成本的替代方案，解决了LLMs在金融预测中的前瞻性偏差问题，无需重新训练大模型

Abstract: Applying LLMs to predictive tasks in finance is challenging due to look-ahead bias resulting from their training on long time-series data. This precludes the backtests typically employed in finance since retraining frontier models from scratch with a specific knowledge cutoff is prohibitive. In this paper, we introduce a fast, effective, and low-cost alternative. Our method guides generation at inference time by adjusting the logits of a large base model using a pair of smaller, specialized models -- one fine-tuned on information to be forgotten and another on information to be retained. We demonstrate that our method effectively removes both verbatim and semantic knowledge, corrects biases, and outperforms prior methods.

</details>


### [346] [Arc Gradient Descent: A Mathematically Derived Reformulation of Gradient Descent with Phase-Aware, User-Controlled Step Dynamics](https://arxiv.org/abs/2512.06737)
*Nikhil Verma,Joonas Linnosmaa,Espinosa-Leal Leonardo,Napat Vajragupta*

Main category: cs.LG

TL;DR: ArcGD优化器在非凸基准函数和真实ML数据集上均优于Adam等主流优化器，表现出更好的泛化能力和抗过拟合特性。


<details>
  <summary>Details</summary>
Motivation: 开发一种新的优化器，旨在解决现有优化器（如Adam）在非凸优化问题和深度学习任务中可能存在的收敛问题和过拟合现象。

Method: 提出了ArcGD优化器，首先在具有挑战性的Rosenbrock函数上进行基准测试（从2D到50,000D维度），然后在CIFAR-10图像分类数据集上使用8种不同的MLP架构进行评估，与Adam、AdamW、Lion、SGD等优化器进行比较。

Result: 在Rosenbrock函数测试中，ArcGD在大多数情况下优于Adam；在CIFAR-10测试中，ArcGD在20,000次迭代后达到50.7%的平均测试准确率，优于所有对比优化器，并在8种架构中的6种上获胜或持平。

Conclusion: ArcGD优化器在非凸优化和深度学习任务中表现出色，具有更好的泛化能力和抗过拟合特性，无需早停调优，且与Lion优化器存在理论联系，值得进一步探索其广泛适用性。

Abstract: The paper presents the formulation, implementation, and evaluation of the ArcGD optimiser. The evaluation is conducted initially on a non-convex benchmark function and subsequently on a real-world ML dataset. The initial comparative study using the Adam optimiser is conducted on a stochastic variant of the highly non-convex and notoriously challenging Rosenbrock function, renowned for its narrow, curved valley, across dimensions ranging from 2D to 1000D and an extreme case of 50,000D. Two configurations were evaluated to eliminate learning-rate bias: (i) both using ArcGD's effective learning rate and (ii) both using Adam's default learning rate. ArcGD consistently outperformed Adam under the first setting and, although slower under the second, achieved super ior final solutions in most cases. In the second evaluation, ArcGD is evaluated against state-of-the-art optimizers (Adam, AdamW, Lion, SGD) on the CIFAR-10 image classification dataset across 8 diverse MLP architectures ranging from 1 to 5 hidden layers. ArcGD achieved the highest average test accuracy (50.7%) at 20,000 iterations, outperforming AdamW (46.6%), Adam (46.8%), SGD (49.6%), and Lion (43.4%), winning or tying on 6 of 8 architectures. Notably, while Adam and AdamW showed strong early convergence at 5,000 iterations, but regressed with extended training, whereas ArcGD continued improving, demonstrating generalization and resistance to overfitting without requiring early stopping tuning. Strong performance on geometric stress tests and standard deep-learning benchmarks indicates broad applicability, highlighting the need for further exploration. Moreover, it is also shown that a variant of ArcGD can be interpreted as a special case of the Lion optimiser, highlighting connections between the inherent mechanisms of such optimisation methods.

</details>


### [347] [Flash Multi-Head Feed-Forward Network](https://arxiv.org/abs/2512.06989)
*Minshen Zhang,Xiang Hu,Jianguo Li,Wei Wu,Kewei Tu*

Main category: cs.LG

TL;DR: FlashMHF提出多头FFN替代传统FFN，通过融合内核和动态加权并行子网络解决内存和扩展性问题，在1.3B参数内提升性能同时减少3-5倍内存使用。


<details>
  <summary>Details</summary>
Motivation: 受多头注意力机制启发，探索多头FFN替代传统FFN。但直接应用面临两个挑战：1）内存消耗随头数线性增长；2）模型扩展时中间维度增长与头维度固定的不平衡比例会降低可扩展性和表达能力。

Method: 提出Flash Multi-Head FFN (FlashMHF)：1）类似FlashAttention的I/O感知融合内核，在SRAM中在线计算输出；2）使用动态加权并行子网络设计，保持中间维度与头维度的平衡比例。

Result: 在128M到1.3B参数模型上验证，FlashMHF相比SwiGLU FFNs持续改善困惑度和下游任务准确率，同时减少3-5倍峰值内存使用，推理加速达1.08倍。

Conclusion: 多头设计是FFN的优越架构原则，FlashMHF作为Transformer中FFN的强大、高效且可扩展的替代方案。

Abstract: We explore Multi-Head FFN (MH-FFN) as a replacement of FFN in the Transformer architecture, motivated by the structural similarity between single-head attention and FFN. While multi-head mechanisms enhance expressivity in attention, naively applying them to FFNs faces two challenges: memory consumption scaling with the head count, and an imbalanced ratio between the growing intermediate size and the fixed head dimension as models scale, which degrades scalability and expressive power. To address these challenges, we propose Flash Multi-Head FFN (FlashMHF), with two key innovations: an I/O-aware fused kernel computing outputs online in SRAM akin to FlashAttention, and a design using dynamically weighted parallel sub-networks to maintain a balanced ratio between intermediate and head dimensions. Validated on models from 128M to 1.3B parameters, FlashMHF consistently improves perplexity and downstream task accuracy over SwiGLU FFNs, while reducing peak memory usage by 3-5x and accelerating inference by up to 1.08x. Our work establishes the multi-head design as a superior architectural principle for FFNs, presenting FlashMHF as a powerful, efficient, and scalable alternative to FFNs in Transformers.

</details>


### [348] [Block Sparse Flash Attention](https://arxiv.org/abs/2512.07011)
*Daniel Ohayon,Itay Lamprecht,Itay Hubara,Israel Cohen,Daniel Soudry,Noam Elata*

Main category: cs.LG

TL;DR: BSFA是一种训练免费、基于块的稀疏注意力方法，通过计算精确的查询-键相似度选择最重要的值块，跳过约50%计算和内存传输，在保持模型质量的同时加速长上下文推理。


<details>
  <summary>Details</summary>
Motivation: 现代大语言模型需要处理长上下文，但注意力机制的二次复杂度造成严重计算瓶颈，需要高效的稀疏注意力解决方案。

Method: BSFA计算精确的查询-键相似度，通过比较每块最大分数与校准阈值，为每个查询选择top-k最重要的值块，跳过约50%计算。只需在小数据集上进行一次性阈值校准学习每层每头的注意力分数分布。

Result: 在Llama-3.1-8B上，BSFA在真实世界推理基准上实现1.10倍加速，在"大海捞针"检索任务上实现1.24倍加速，保持99%以上基线准确率，某些配置甚至通过关注最相关内容提高准确率。

Conclusion: BSFA作为FlashAttention的即插即用替代方案，在保持模型质量的同时显著加速长上下文推理，优于现有稀疏注意力方法。

Abstract: Modern large language models increasingly require long contexts for reasoning and multi-document tasks, but attention's quadratic complexity creates a severe computational bottleneck. We present Block-Sparse FlashAttention (BSFA), a drop-in replacement that accelerates long-context inference while preserving model quality. Unlike methods that predict importance before computing scores, BSFA computes exact query-key similarities to select the top-k most important value blocks for each query. By comparing per-block maximum scores against calibrated thresholds, we skip approximately 50% of the computation and memory transfers for pruned blocks. Our training-free approach requires only a one-time threshold calibration on a small dataset to learn the per-layer and per-head attention score distributions. We provide a CUDA kernel implementation that can be used as a drop-in replacement for FlashAttention. On Llama-3.1-8B, BSFA achieves up to 1.10x speedup on real-world reasoning benchmarks and up to 1.24x for needle-in-a-haystack retrieval tasks while maintaining above 99% baseline accuracy, with certain configurations even improving accuracy by focusing on the most relevant content, substantially outperforming existing sparse attention methods. The implementation is available at https://github.com/Danielohayon/Block-Sparse-Flash-Attention

</details>


### [349] [Pay Less Attention to Function Words for Free Robustness of Vision-Language Models](https://arxiv.org/abs/2512.07222)
*Qiwei Tian,Chenhao Lin,Zhengyu Zhao,Chao Shen*

Main category: cs.LG

TL;DR: 提出Function-word De-Attention (FDA)方法，通过消除功能词对跨模态对抗攻击的脆弱性，在保持性能的同时显著提升视觉语言模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有鲁棒视觉语言模型(VLM)在鲁棒性和性能之间存在权衡。研究发现功能词是VLM对跨模态对抗攻击的脆弱性来源，需要解决这一问题。

Method: 提出Function-word De-Attention (FDA)方法，类似差分放大器，计算原始跨注意力和功能词跨注意力，然后将后者从前者中差分减去，以获得更对齐和鲁棒的VLM。

Result: 在3个模型、2个下游任务、3个数据集上的综合实验显示：检索任务上平均攻击成功率(ASR)下降18/13/53%，性能仅下降0.2/0.3/0.6%；视觉定位任务上ASR下降90%，性能提升0.3%。

Conclusion: FDA方法能有效提升VLM的鲁棒性，同时保持性能，具有可扩展性、泛化能力和零样本性能，为鲁棒VLM设计提供了新思路。

Abstract: To address the trade-off between robustness and performance for robust VLM, we observe that function words could incur vulnerability of VLMs against cross-modal adversarial attacks, and propose Function-word De-Attention (FDA) accordingly to mitigate the impact of function words. Similar to differential amplifiers, our FDA calculates the original and the function-word cross-attention within attention heads, and differentially subtracts the latter from the former for more aligned and robust VLMs. Comprehensive experiments include 2 SOTA baselines under 6 different attacks on 2 downstream tasks, 3 datasets, and 3 models. Overall, our FDA yields an average 18/13/53% ASR drop with only 0.2/0.3/0.6% performance drops on the 3 tested models on retrieval, and a 90% ASR drop with a 0.3% performance gain on visual grounding. We demonstrate the scalability, generalization, and zero-shot performance of FDA experimentally, as well as in-depth ablation studies and analysis. Code will be made publicly at https://github.com/michaeltian108/FDA.

</details>


### [350] [Recover-to-Forget: Gradient Reconstruction from LoRA for Efficient LLM Unlearning](https://arxiv.org/abs/2512.07374)
*Yezi Liu,Hanning Chen,Wenjun Huang,Yang Ni,Mohsen Imani*

Main category: cs.LG

TL;DR: R2F是一种基于LoRA参数重建全模型梯度方向的高效大语言模型遗忘框架，无需全模型微调或原始训练数据


<details>
  <summary>Details</summary>
Motivation: 大型基础模型（如LLMs）需要遗忘机制来实现动态知识更新、执行数据删除权利和纠正模型行为，但现有方法通常需要全模型微调或访问原始训练数据，限制了可扩展性和实用性

Method: 基于LoRA适配器更新重建全模型梯度方向：1）使用多个改写提示计算LoRA参数的梯度；2）训练梯度解码器近似对应的全模型梯度；3）在代理模型上训练解码器并迁移到目标模型，适用于更大或黑盒模型

Result: R2F实现了有效的遗忘同时保持模型一般性能，提供了可扩展、轻量级的遗忘方案，无需全模型重训练或访问内部参数

Conclusion: R2F为大语言模型提供了一种高效、实用的遗忘框架，解决了现有方法在可扩展性和实用性方面的限制，为动态知识更新和数据权利保护提供了可行方案

Abstract: Unlearning in large foundation models (e.g., LLMs) is essential for enabling dynamic knowledge updates, enforcing data deletion rights, and correcting model behavior. However, existing unlearning methods often require full-model fine-tuning or access to the original training data, which limits their scalability and practicality. In this work, we introduce Recover-to-Forget (R2F), a novel framework for efficient unlearning in LLMs based on reconstructing full-model gradient directions from low-rank LoRA adapter updates. Rather than performing backpropagation through the full model, we compute gradients with respect to LoRA parameters using multiple paraphrased prompts and train a gradient decoder to approximate the corresponding full-model gradients. To ensure applicability to larger or black-box models, the decoder is trained on a proxy model and transferred to target models. We provide a theoretical analysis of cross-model generalization and demonstrate that our method achieves effective unlearning while preserving general model performance. Experimental results demonstrate that R2F offers a scalable and lightweight alternative for unlearning in pretrained LLMs without requiring full retraining or access to internal parameters.

</details>


### [351] [LUNE: Efficient LLM Unlearning via LoRA Fine-Tuning with Negative Examples](https://arxiv.org/abs/2512.07375)
*Yezi Liu,Hanning Chen,Wenjun Huang,Yang Ni,Mohsen Imani*

Main category: cs.LG

TL;DR: LUNE：基于LoRA的负向遗忘框架，通过仅更新低秩适配器实现高效知识遗忘，相比全微调或权重编辑降低约一个数量级计算成本


<details>
  <summary>Details</summary>
Motivation: 大语言模型难以移除特定信息，影响隐私保护、偏见缓解和知识修正。传统遗忘方法需要昂贵的微调或权重编辑，不适用于实际部署

Method: 基于LoRA的负向遗忘框架，仅更新低秩适配器而冻结主干网络，针对中间表示层抑制或替换目标知识

Result: 在多个事实遗忘任务上，LUNE达到与全微调和内存编辑方法相当的效果，同时计算成本降低约一个数量级

Conclusion: LUNE提供了一种轻量级、高效的模型遗忘方案，通过局部化编辑避免全局破坏性变化，适用于实际部署场景

Abstract: Large language models (LLMs) possess vast knowledge acquired from extensive training corpora, but they often cannot remove specific pieces of information when needed, which makes it hard to handle privacy, bias mitigation, and knowledge correction. Traditional model unlearning approaches require computationally expensive fine-tuning or direct weight editing, making them impractical for real-world deployment. In this work, we introduce LoRA-based Unlearning with Negative Examples (LUNE), a lightweight framework that performs negative-only unlearning by updating only low-rank adapters while freezing the backbone, thereby localizing edits and avoiding disruptive global changes. Leveraging Low-Rank Adaptation (LoRA), LUNE targets intermediate representations to suppress (or replace) requested knowledge with an order-of-magnitude lower compute and memory than full fine-tuning or direct weight editing. Extensive experiments on multiple factual unlearning tasks show that LUNE: (I) achieves effectiveness comparable to full fine-tuning and memory-editing methods, and (II) reduces computational cost by about an order of magnitude.

</details>


### [352] [Group Representational Position Encoding](https://arxiv.org/abs/2512.07805)
*Yifan Zhang,Zixiang Chen,Yifeng Liu,Zhen Qin,Huizhuo Yuan,Kangping Xu,Yang Yuan,Quanquan Gu,Andrew Chi-Chih Yao*

Main category: cs.LG

TL;DR: GRAPE是一个基于群作用的统一位置编码框架，包含乘法旋转（SO(d)）和加法logit偏置（GL）两种机制，统一了RoPE和ALiBi等现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有位置编码方法（如RoPE、ALiBi）虽然有效但缺乏统一的理论框架。GRAPE旨在通过群作用理论提供一个统一的位置编码设计空间，将不同方法纳入同一理论体系。

Method: 基于群作用理论，提出两种机制：1）乘法GRAPE：使用SO(d)群的旋转作用，位置n通过指数映射exp(nωL)作用，其中L是秩2斜对称生成元；2）加法GRAPE：使用GL群的幂单作用，产生加法logit偏置。两种机制分别统一了RoPE和ALiBi等现有方法。

Result: GRAPE框架严格包含了RoPE和ALiBi作为特例，同时扩展了其几何结构。乘法GRAPE通过学习的交换子空间和非交换混合捕获跨子空间特征耦合；加法GRAPE保持了精确的相对位置关系和流式缓存能力。

Conclusion: GRAPE为长上下文模型中的位置几何提供了一个原则性的设计空间，统一了现有的位置编码方法，并为未来的位置编码设计提供了理论基础和扩展可能性。

Abstract: We present GRAPE (Group RepresentAtional Position Encoding), a unified framework for positional encoding based on group actions. GRAPE brings together two families of mechanisms: (i) multiplicative rotations (Multiplicative GRAPE) in $\mathrm{SO}(d)$ and (ii) additive logit biases (Additive GRAPE) arising from unipotent actions in the general linear group $\mathrm{GL}$. In Multiplicative GRAPE, a position $n \in \mathbb{Z}$ (or $t \in \mathbb{R}$) acts as $\mathbf{G}(n)=\exp(n\,ω\,\mathbf{L})$ with a rank-2 skew generator $\mathbf{L} \in \mathbb{R}^{d \times d}$, yielding a relative, compositional, norm-preserving map with a closed-form matrix exponential. RoPE is recovered exactly when the $d/2$ planes are the canonical coordinate pairs with log-uniform spectrum. Learned commuting subspaces and compact non-commuting mixtures strictly extend this geometry to capture cross-subspace feature coupling at $O(d)$ and $O(r d)$ cost per head, respectively. In Additive GRAPE, additive logits arise as rank-1 (or low-rank) unipotent actions, recovering ALiBi and the Forgetting Transformer (FoX) as exact special cases while preserving an exact relative law and streaming cacheability. Altogether, GRAPE supplies a principled design space for positional geometry in long-context models, subsuming RoPE and ALiBi as special cases. Project Page: https://github.com/model-architectures/GRAPE.

</details>


### [353] [Vector Quantization using Gaussian Variational Autoencoder](https://arxiv.org/abs/2512.06609)
*Tongda Xu,Wendi Zheng,Jiajun He,Jose Miguel Hernandez-Lobato,Yan Wang,Ya-Qin Zhang,Jie Tang*

Main category: cs.LG

TL;DR: 提出Gaussian Quant (GQ)方法，将高斯VAE转换为VQ-VAE而无需训练，通过随机高斯噪声作为码本，并引入目标散度约束(TDC)来训练高斯VAE以获得更好的量化效果。


<details>
  <summary>Details</summary>
Motivation: VQ-VAE由于离散化难以训练，需要一种更简单有效的方法来获得离散表示。

Method: 提出Gaussian Quant (GQ)：将高斯VAE转换为VQ-VAE，使用随机高斯噪声作为码本，寻找后验均值最接近的噪声向量。提出目标散度约束(TDC)来训练高斯VAE以优化GQ效果。

Result: 理论上证明当码本大小的对数超过高斯VAE的bits-back编码率时，可保证小的量化误差。实验表明GQ在UNet和ViT架构上优于VQGAN、FSQ、LFQ、BSQ等VQ-VAE方法，TDC也优于TokenBridge等高斯VAE离散化方法。

Conclusion: GQ提供了一种简单有效的方法将高斯VAE转换为VQ-VAE，无需额外训练，通过TDC进一步优化，在多个基准测试中表现出色。

Abstract: Vector quantized variational autoencoder (VQ-VAE) is a discrete auto-encoder that compresses images into discrete tokens. It is difficult to train due to discretization. In this paper, we propose a simple yet effective technique, dubbed Gaussian Quant (GQ), that converts a Gaussian VAE with certain constraint into a VQ-VAE without training. GQ generates random Gaussian noise as a codebook and finds the closest noise to the posterior mean. Theoretically, we prove that when the logarithm of the codebook size exceeds the bits-back coding rate of the Gaussian VAE, a small quantization error is guaranteed. Practically, we propose a heuristic to train Gaussian VAE for effective GQ, named target divergence constraint (TDC). Empirically, we show that GQ outperforms previous VQ-VAEs, such as VQGAN, FSQ, LFQ, and BSQ, on both UNet and ViT architectures. Furthermore, TDC also improves upon previous Gaussian VAE discretization methods, such as TokenBridge. The source code is provided in https://github.com/tongdaxu/VQ-VAE-from-Gaussian-VAE.

</details>


### [354] [Financial Fraud Identification and Interpretability Study for Listed Companies Based on Convolutional Neural Network](https://arxiv.org/abs/2512.06648)
*Xiao Li*

Main category: cs.LG

TL;DR: 提出基于卷积神经网络的中国A股上市公司财务舞弊检测框架，通过将面板数据转换为类图像表示来捕捉跨截面和时间模式，实现提前预警，并在准确性、鲁棒性和预警性能上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 上市公司财务舞弊难以检测，传统统计模型难以处理非线性特征交互，机器学习模型缺乏可解释性，且现有方法大多仅基于当年数据判断当年舞弊，时效性有限。

Method: 设计特征工程方案，将公司年度面板数据转换为类图像表示，使用卷积神经网络捕捉跨截面和时间模式，实现提前预测；采用局部解释技术从实体、特征和时间三个维度分析模型。

Result: CNN在准确性、鲁棒性和早期预警性能上优于逻辑回归和LightGBM；发现偿债能力、比率结构、治理结构和内部控制是舞弊的通用预测因子，环境指标主要在高污染行业重要；舞弊公司表现出集中在短期时间窗口的异质性模式。

Conclusion: 基于CNN的财务舞弊检测框架能有效提前预警，通过适当的分类阈值调整和可解释性分析，可为高风险环境下的舞弊检测提供实用工具，案例研究验证了模型预测与实际舞弊行为的一致性。

Abstract: Since the emergence of joint-stock companies, financial fraud by listed firms has repeatedly undermined capital markets. Fraud is difficult to detect because of covert tactics and the high labor and time costs of audits. Traditional statistical models are interpretable but struggle with nonlinear feature interactions, while machine learning models are powerful but often opaque. In addition, most existing methods judge fraud only for the current year based on current year data, limiting timeliness.
  This paper proposes a financial fraud detection framework for Chinese A-share listed companies based on convolutional neural networks (CNNs). We design a feature engineering scheme that transforms firm-year panel data into image like representations, enabling the CNN to capture cross-sectional and temporal patterns and to predict fraud in advance. Experiments show that the CNN outperforms logistic regression and LightGBM in accuracy, robustness, and early-warning performance, and that proper tuning of the classification threshold is crucial in high-risk settings.
  To address interpretability, we analyze the model along the dimensions of entity, feature, and time using local explanation techniques. We find that solvency, ratio structure, governance structure, and internal control are general predictors of fraud, while environmental indicators matter mainly in high-pollution industries. Non-fraud firms share stable feature patterns, whereas fraud firms exhibit heterogeneous patterns concentrated in short time windows. A case study of Guanong Shares in 2022 shows that cash flow analysis, social responsibility, governance structure, and per-share indicators are the main drivers of the model's fraud prediction, consistent with the company's documented misconduct.

</details>


### [355] [Estimating Black Carbon Concentration from Urban Traffic Using Vision-Based Machine Learning](https://arxiv.org/abs/2512.06649)
*Camellia Zakaria,Aryan Sadeghi,Weaam Jaafar,Junshi Xu,Alex Mariakakis,Marianne Hatzopoulou*

Main category: cs.LG

TL;DR: 利用交通监控视频和天气数据，通过机器学习模型估计街道级黑碳浓度，填补交通环境监测数据空白


<details>
  <summary>Details</summary>
Motivation: 城市黑碳排放主要由交通驱动，但监测成本高昂导致数据匮乏，而交通监控系统广泛部署，形成数据不平衡。需要填补交通条件与环境后果之间的知识鸿沟。

Method: 提出机器学习驱动系统，从交通视频中提取车辆行为和状况的视觉信息，结合天气数据，构建街道级黑碳浓度估计模型。

Result: 模型达到R平方值0.72和RMSE 129.42 ng/m³，能够有效估计街道级黑碳浓度。

Conclusion: 该工作利用现有城市基础设施资源，为污染减排、城市规划、公共卫生和环境正义提供可操作数据支持，具有可持续发展意义。

Abstract: Black carbon (BC) emissions in urban areas are primarily driven by traffic, with hotspots near major roads disproportionately affecting marginalized communities. Because BC monitoring is typically performed using costly and specialized instruments. there is little to no available data on BC from local traffic sources that could help inform policy interventions targeting local factors. By contrast, traffic monitoring systems are widely deployed in cities around the world, highlighting the imbalance between what we know about traffic conditions and what do not know about their environmental consequences. To bridge this gap, we propose a machine learning-driven system that extracts visual information from traffic video to capture vehicles behaviors and conditions. Combining these features with weather data, our model estimates BC at street level, achieving an R-squared value of 0.72 and RMSE of 129.42 ng/m3 (nanogram per cubic meter). From a sustainability perspective, this work leverages resources already supported by urban infrastructure and established modeling techniques to generate information relevant to traffic emission. Obtaining BC concentration data provides actionable insights to support pollution reduction, urban planning, public health, and environmental justice at the local municipal level.

</details>


### [356] [Rethinking Robustness: A New Approach to Evaluating Feature Attribution Methods](https://arxiv.org/abs/2512.06665)
*Panagiota Kiourti,Anu Singh,Preeti Duraipandian,Weichao Zhou,Wenchao Li*

Main category: cs.LG

TL;DR: 本文提出了一种新的特征归因方法鲁棒性评估框架，包括新的相似输入定义、鲁棒性度量标准，以及基于生成对抗网络的输入生成方法，旨在更客观地评估归因方法而非神经网络的弱点。


<details>
  <summary>Details</summary>
Motivation: 当前的特征归因方法鲁棒性评估主要关注输入扰动对归因图的影响，但忽略了模型输出的差异，导致评估不够客观，无法准确揭示归因方法本身的弱点。

Method: 提出新的相似输入定义和鲁棒性度量标准，开发基于生成对抗网络的方法来生成这些相似输入，并对现有度量标准和最先进的归因方法进行全面评估。

Result: 研究发现现有评估方法存在局限性，新提出的框架能够更准确地揭示归因方法的弱点，而非神经网络的弱点，为归因方法鲁棒性评估提供了更客观的度量。

Conclusion: 需要更客观的度量标准来评估特征归因方法的鲁棒性，新提出的框架能够更准确地揭示归因方法本身的弱点，为未来归因方法的设计和评估提供了重要指导。

Abstract: This paper studies the robustness of feature attribution methods for deep neural networks. It challenges the current notion of attributional robustness that largely ignores the difference in the model's outputs and introduces a new way of evaluating the robustness of attribution methods. Specifically, we propose a new definition of similar inputs, a new robustness metric, and a novel method based on generative adversarial networks to generate these inputs. In addition, we present a comprehensive evaluation with existing metrics and state-of-the-art attribution methods. Our findings highlight the need for a more objective metric that reveals the weaknesses of an attribution method rather than that of the neural network, thus providing a more accurate evaluation of the robustness of attribution methods.

</details>


### [357] [Enhancing Interpretability of AR-SSVEP-Based Motor Intention Recognition via CNN-BiLSTM and SHAP Analysis on EEG Data](https://arxiv.org/abs/2512.06730)
*Lin Yang,Xiang Li,Xin Ma,Xinxin Zhao*

Main category: cs.LG

TL;DR: 提出基于增强现实的SSVEP脑机接口系统，结合多注意力机制的CNN-BiLSTM网络，用于提高运动功能障碍患者的康复训练参与度和运动意图识别


<details>
  <summary>Details</summary>
Motivation: 解决运动功能障碍患者康复训练主观参与度低的问题，以及传统SSVEP-BCI系统依赖外部视觉刺激设备、在实际应用中受限的局限性

Method: 1. 设计基于HoloLens 2的四种EEG类别并收集数据；2. 在传统CNN-BiLSTM架构基础上集成多头注意力机制；3. 提取10个时频EEG特征，通过CNN学习高层表示；4. 使用BiLSTM建模序列依赖，多头注意力机制突出运动意图相关模式；5. 应用SHAP方法可视化EEG特征对决策的贡献

Result: 系统能够增强实时运动意图识别能力，支持运动障碍患者的康复恢复

Conclusion: AR-SSVEP系统结合MACNN-BiLSTM模型能够有效提高患者康复训练参与度，增强运动意图识别的实时性和可解释性，为运动功能障碍康复提供新方法

Abstract: Patients with motor dysfunction show low subjective engagement in rehabilitation training. Traditional SSVEP-based brain-computer interface (BCI) systems rely heavily on external visual stimulus equipment, limiting their practicality in real-world settings. This study proposes an augmented reality steady-state visually evoked potential (AR-SSVEP) system to address the lack of patient initiative and the high workload on therapists. Firstly, we design four HoloLens 2-based EEG classes and collect EEG data from seven healthy subjects for analysis. Secondly, we build upon the conventional CNN-BiLSTM architecture by integrating a multi-head attention mechanism (MACNN-BiLSTM). We extract ten temporal-spectral EEG features and feed them into a CNN to learn high-level representations. Then, we use BiLSTM to model sequential dependencies and apply a multi-head attention mechanism to highlight motor-intention-related patterns. Finally, the SHAP (SHapley Additive exPlanations) method is applied to visualize EEG feature contributions to the neural network's decision-making process, enhancing the model's interpretability. These findings enhance real-time motor intention recognition and support recovery in patients with motor impairments.

</details>


### [358] [Transformation of Biological Networks into Images via Semantic Cartography for Visual Interpretation and Scalable Deep Analysis](https://arxiv.org/abs/2512.07040)
*Sakib Mostafa,Lei Xing,Md. Tauhidul Islam*

Main category: cs.LG

TL;DR: Graph2Image将大型生物网络转换为二维图像，利用CNN解决传统方法在可扩展性、长程依赖和多模态集成方面的限制，显著提升分类准确性并实现可解释可视化。


<details>
  <summary>Details</summary>
Motivation: 生物网络分析对理解健康与疾病至关重要，但现有方法（包括深度学习方法）面临可扩展性有限、长程依赖过平滑、多模态集成困难、表达能力受限和可解释性差等挑战。

Method: Graph2Image框架将大型生物网络转换为二维图像集合，通过在2D网格上空间排列代表性网络节点，将节点解耦为图像，从而能够利用具有全局感受野和多尺度金字塔的卷积神经网络。

Result: 在多个大规模生物网络数据集上，Graph2Image相比现有方法将分类准确率提高了高达67.2%，提供了可解释的可视化揭示生物学一致模式，并能在个人计算机上分析超过10亿节点的超大网络。

Conclusion: Graph2Image为生物网络分析提供了可扩展、可解释且支持多模态的方法，为疾病诊断和复杂生物系统研究开辟了新机会。

Abstract: Complex biological networks are fundamental to biomedical science, capturing interactions among molecules, cells, genes, and tissues. Deciphering these networks is critical for understanding health and disease, yet their scale and complexity represent a daunting challenge for current computational methods. Traditional biological network analysis methods, including deep learning approaches, while powerful, face inherent challenges such as limited scalability, oversmoothing long-range dependencies, difficulty in multimodal integration, expressivity bounds, and poor interpretability. We present Graph2Image, a framework that transforms large biological networks into sets of two-dimensional images by spatially arranging representative network nodes on a 2D grid. This transformation decouples the nodes as images, enabling the use of convolutional neural networks (CNNs) with global receptive fields and multi-scale pyramids, thus overcoming limitations of existing biological network analysis methods in scalability, memory efficiency, and long-range context capture. Graph2Image also facilitates seamless integration with other imaging and omics modalities and enhances interpretability through direct visualization of node-associated images. When applied to several large-scale biological network datasets, Graph2Image improved classification accuracy by up to 67.2% over existing methods and provided interpretable visualizations that revealed biologically coherent patterns. It also allows analysis of very large biological networks (nodes > 1 billion) on a personal computer. Graph2Image thus provides a scalable, interpretable, and multimodal-ready approach for biological network analysis, offering new opportunities for disease diagnosis and the study of complex biological systems.

</details>


### [359] [Winning the Lottery by Preserving Network Training Dynamics with Concrete Ticket Search](https://arxiv.org/abs/2512.07142)
*Tanay Arora,Christof Teuscher*

Main category: cs.LG

TL;DR: CTS算法通过组合优化和梯度平衡，在初始化阶段高效寻找高性能稀疏子网络，相比传统方法在计算效率和稀疏性-准确性权衡上有显著优势。


<details>
  <summary>Details</summary>
Motivation: 现有彩票票证假设方法存在计算成本高（如LTR）或准确性-稀疏性权衡差（如PaI）的问题，特别是PaI方法依赖一阶显著性指标忽略了权重间依赖关系。

Method: 提出Concrete Ticket Search (CTS)算法，将子网络发现建模为组合优化问题，使用Concrete松弛离散搜索空间，结合GRADBALANCE梯度平衡控制稀疏性，并采用基于反向KL散度的知识蒸馏式剪枝目标。

Result: CTS在图像分类任务中生成能通过基本合理性检查的子网络，性能媲美或超越LTR，计算时间大幅减少（如ResNet-20/CIFAR10：99.3%稀疏度下74.0%准确率，7.9分钟 vs LTR的68.3%准确率，95.2分钟）。

Conclusion: CTS通过整体组合优化方法解决了传统剪枝方法的局限性，在高度稀疏区域特别有效，为高效发现高性能稀疏子网络提供了新途径。

Abstract: The Lottery Ticket Hypothesis asserts the existence of highly sparse, trainable subnetworks ('winning tickets') within dense, randomly initialized neural networks. However, state-of-the-art methods of drawing these tickets, like Lottery Ticket Rewinding (LTR), are computationally prohibitive, while more efficient saliency-based Pruning-at-Initialization (PaI) techniques suffer from a significant accuracy-sparsity trade-off and fail basic sanity checks. In this work, we argue that PaI's reliance on first-order saliency metrics, which ignore inter-weight dependencies, contributes substantially to this performance gap, especially in the sparse regime. To address this, we introduce Concrete Ticket Search (CTS), an algorithm that frames subnetwork discovery as a holistic combinatorial optimization problem. By leveraging a Concrete relaxation of the discrete search space and a novel gradient balancing scheme (GRADBALANCE) to control sparsity, CTS efficiently identifies high-performing subnetworks near initialization without requiring sensitive hyperparameter tuning. Motivated by recent works on lottery ticket training dynamics, we further propose a knowledge distillation-inspired family of pruning objectives, finding that minimizing the reverse Kullback-Leibler divergence between sparse and dense network outputs (CTS-KL) is particularly effective. Experiments on varying image classification tasks show that CTS produces subnetworks that robustly pass sanity checks and achieve accuracy comparable to or exceeding LTR, while requiring only a small fraction of the computation. For example, on ResNet-20 on CIFAR10, it reaches 99.3% sparsity with 74.0% accuracy in 7.9 minutes, while LTR attains the same sparsity with 68.3% accuracy in 95.2 minutes. CTS's subnetworks outperform saliency-based methods across all sparsities, but its advantage over LTR is most pronounced in the highly sparse regime.

</details>


### [360] [FlowLPS: Langevin-Proximal Sampling for Flow-based Inverse Problem Solvers](https://arxiv.org/abs/2512.07150)
*Jonghyun Park,Jong Chul Ye*

Main category: cs.LG

TL;DR: FlowLPS：基于预训练流模型的训练免费逆问题求解框架，通过朗之万近端采样策略，在潜在空间中实现更好的后验模式收敛和流形一致性。


<details>
  <summary>Details</summary>
Motivation: 现有训练免费方法在应用于潜在流模型时，往往无法收敛到后验模式或在潜在空间中出现流形偏差，需要一种更好的逆问题求解框架。

Method: 提出FlowLPS框架，结合朗之万动力学进行流形一致性探索和近端优化进行精确模式搜索，使用预训练流模型通过朗之万近端采样策略解决逆问题。

Result: 在FFHQ和DIV2K数据集上的多个逆任务中，实现了重建保真度和感知质量之间的优越平衡，超越了现有最先进的逆问题求解器。

Conclusion: FlowLPS为基于预训练流模型的逆问题求解提供了一种有效的训练免费框架，通过朗之万近端采样策略解决了现有方法的收敛和流形偏差问题。

Abstract: Deep generative models have become powerful priors for solving inverse problems, and various training-free methods have been developed. However, when applied to latent flow models, existing methods often fail to converge to the posterior mode or suffer from manifold deviation within latent spaces. To mitigate this, here we introduce a novel training-free framework, FlowLPS, that solves inverse problems with pretrained flow models via a Langevin Proximal Sampling (LPS) strategy. Our method integrates Langevin dynamics for manifold-consistent exploration with proximal optimization for precise mode seeking, achieving a superior balance between reconstruction fidelity and perceptual quality across multiple inverse tasks on FFHQ and DIV2K, outperforming state of the art inverse solvers.

</details>


### [361] [Towards Reliable Test-Time Adaptation: Style Invariance as a Correctness Likelihood](https://arxiv.org/abs/2512.07390)
*Gilhyun Nam,Taewon Kim,Joonhyun Jeong,Eunho Yang*

Main category: cs.LG

TL;DR: SICL是一个利用风格不变性进行鲁棒不确定性估计的框架，通过测量预测在不同风格变换下的一致性来估计实例级正确性似然，无需反向传播，可与任何TTA方法兼容。


<details>
  <summary>Details</summary>
Motivation: 测试时适应（TTA）虽然能高效适应部署模型，但常常导致预测不确定性校准不佳，这在自动驾驶、金融和医疗等高风险领域是严重问题。现有校准方法通常假设固定模型或静态分布，在现实世界动态测试条件下性能下降。

Method: SICL框架利用风格不变性进行鲁棒不确定性估计，通过测量预测在不同风格变换版本下的一致性来估计实例级正确性似然，仅需模型前向传播，无需反向传播，可作为即插即用的校准模块。

Result: 在4个基线、5种TTA方法和2个现实场景、3种模型架构的综合评估中，SICL相比传统校准方法平均减少13个百分点的校准误差。

Conclusion: SICL提供了一种有效解决TTA中不确定性校准问题的方法，通过风格不变性原理实现鲁棒的不确定性估计，且具有即插即用、无需反向传播的优点，适用于各种TTA方法。

Abstract: Test-time adaptation (TTA) enables efficient adaptation of deployed models, yet it often leads to poorly calibrated predictive uncertainty - a critical issue in high-stakes domains such as autonomous driving, finance, and healthcare. Existing calibration methods typically assume fixed models or static distributions, resulting in degraded performance under real-world, dynamic test conditions. To address these challenges, we introduce Style Invariance as a Correctness Likelihood (SICL), a framework that leverages style-invariance for robust uncertainty estimation. SICL estimates instance-wise correctness likelihood by measuring prediction consistency across style-altered variants, requiring only the model's forward pass. This makes it a plug-and-play, backpropagation-free calibration module compatible with any TTA method. Comprehensive evaluations across four baselines, five TTA methods, and two realistic scenarios with three model architecture demonstrate that SICL reduces calibration error by an average of 13 percentage points compared to conventional calibration approaches.

</details>


### [362] [Revolutionizing Mixed Precision Quantization: Towards Training-free Automatic Proxy Discovery via Large Language Models](https://arxiv.org/abs/2512.07419)
*Haidong Kang,Jun Du,Lihong Lin*

Main category: cs.LG

TL;DR: 提出TAP框架，利用大语言模型自动发现混合精度量化的训练免费代理，无需人工设计或训练，通过强化学习优化提示提升LLM推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统混合精度量化方法要么依赖昂贵的可微分优化（效率低且不灵活），要么需要人工专家设计代理（劳动密集且需要专业知识）。能否设计一个无需人工专家参与和训练的代理？

Method: 提出TAP框架：1）利用大语言模型自动发现适合混合精度量化的训练免费代理；2）提出基于直接策略优化的强化学习来优化提示，增强LLM推理能力，在LLM和MPQ任务间建立正反馈循环。

Result: 在主流基准测试上的广泛实验表明，TAP实现了最先进的性能。

Conclusion: TAP为混合精度量化社区提供了LLM驱动设计算法的新视角，将显著推动该领域发展。

Abstract: Mixed-Precision Quantization (MPQ) liberates the Deep Neural Networks (DNNs) from the Out-Of-Memory (OOM) bottleneck, which garnered increasing research attention. However, conventional methods either searched from costly differentiable optimization, which is neither efficient nor flexible, or learned a quantized DNN from the proxy (i.e., HAWQ) manually designed by human experts, which is labor-intensive and requires huge expert knowledge. Can we design a proxy without involving any human experts and training? In this paper, we provide an affirmative answer by proposing a novel Large Language Models (LLMs)-driven Training-free Automatic Proxy (dubbed TAP) discovery framework, which reforms the design paradigm of MPQ by utilizing LLMs to find superior TAP tailored for MPQ, automatically. In addition, to bridge the gap between black-box LLMs and the tough MPQ task, we ingeniously propose simple Direct Policy Optimization (DPO) based reinforcement learning to enhance LLMs' reasoning by optimizing prompts, which can construct a positive feedback loop between the LLM and the MPQ task, enabling LLMs to generate better TAP in the next evolution. Extensive experiments on mainstream benchmarks demonstrate that TAP achieves state-of-the-art performance. Finally, we truly believe that our TAP will significantly contribute to the MPQ community by providing a new perspective on LLM-driven design algorithms.

</details>


### [363] [KAN-Dreamer: Benchmarking Kolmogorov-Arnold Networks as Function Approximators in World Models](https://arxiv.org/abs/2512.07437)
*Chenwei Shi,Xueyu Luan*

Main category: cs.LG

TL;DR: KAN-Dreamer：将KAN架构集成到DreamerV3中，用KAN/FastKAN替换MLP和卷积组件，在walker_walk任务上实现与原MLP架构相当的性能。


<details>
  <summary>Details</summary>
Motivation: KANs作为MLPs的替代方案，具有更好的参数效率和可解释性，但存在计算开销问题。研究将KAN架构集成到DreamerV3框架中，探索基于KAN的世界模型潜力。

Method: 提出KAN-Dreamer，在DreamerV3的三个子系统（视觉感知、潜在预测、行为学习）中用KAN和FastKAN层替换特定MLP和卷积组件。为JAX世界模型实现完全向量化版本并简化网格管理。

Result: 在DeepMind Control Suite的walker_walk任务上，使用适配的FastKAN作为奖励和继续预测器的替代方案，性能与原MLP架构相当，保持了样本效率和训练速度的同等水平。

Conclusion: 这是KAN-based世界模型的初步研究，展示了FastKAN作为DreamerV3中MLP组件的可行替代方案，为未来基于KAN的世界模型发展奠定了基础。

Abstract: DreamerV3 is a state-of-the-art online model-based reinforcement learning (MBRL) algorithm known for remarkable sample efficiency. Concurrently, Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to Multi-Layer Perceptrons (MLPs), offering superior parameter efficiency and interpretability. To mitigate KANs' computational overhead, variants like FastKAN leverage Radial Basis Functions (RBFs) to accelerate inference. In this work, we investigate integrating KAN architectures into the DreamerV3 framework. We introduce KAN-Dreamer, replacing specific MLP and convolutional components of DreamerV3 with KAN and FastKAN layers. To ensure efficiency within the JAX-based World Model, we implement a tailored, fully vectorized version with simplified grid management. We structure our investigation into three subsystems: Visual Perception, Latent Prediction, and Behavior Learning. Empirical evaluations on the DeepMind Control Suite (walker_walk) analyze sample efficiency, training time, and asymptotic performance. Experimental results demonstrate that utilizing our adapted FastKAN as a drop-in replacement for the Reward and Continue predictors yields performance on par with the original MLP-based architecture, maintaining parity in both sample efficiency and training speed. This report serves as a preliminary study for future developments in KAN-based world models.

</details>


### [364] [Exploring possible vector systems for faster training of neural networks with preconfigured latent spaces](https://arxiv.org/abs/2512.07509)
*Nikita Gabdullin*

Main category: cs.LG

TL;DR: 论文提出使用预定义向量系统（如An根系向量）作为潜在空间配置目标，无需分类层即可训练分类器，特别适用于超多类别数据集，并能显著加速训练收敛。


<details>
  <summary>Details</summary>
Motivation: 神经网络性能与潜在空间嵌入分布特性密切相关。传统方法在处理极多类别数据集时面临挑战，需要更高效的潜在空间配置方法来加速训练并减少计算资源消耗。

Method: 使用预定义向量系统（包括An根系向量）作为潜在空间配置目标，构建编码器和视觉变换器的潜在空间。研究不同向量系统的性质及构造方法，并探索最小潜在空间维度对特定类别数量的影响。

Result: 该方法显著加速了ImageNet-1K和50k-600k类别数据集的训练。使用最小潜在空间维度能实现更快收敛，同时为减少存储神经网络嵌入的向量数据库大小提供潜在优势。

Conclusion: 预定义向量系统为神经网络训练提供了有效的潜在空间配置方案，特别适用于大规模类别分类任务，能加速训练收敛并优化存储需求。

Abstract: The overall neural network (NN) performance is closely related to the properties of its embedding distribution in latent space (LS). It has recently been shown that predefined vector systems, specifically An root system vectors, can be used as targets for latent space configurations (LSC) to ensure the desired LS structure. One of the main LSC advantage is the possibility of training classifier NNs without classification layers, which facilitates training NNs on datasets with extremely large numbers of classes. This paper provides a more general overview of possible vector systems for NN training along with their properties and methods for vector system construction. These systems are used to configure LS of encoders and visual transformers to significantly speed up ImageNet-1K and 50k-600k classes LSC training. It is also shown that using the minimum number of LS dimensions for a specific number of classes results in faster convergence. The latter has potential advantages for reducing the size of vector databases used to store NN embeddings.

</details>


### [365] [ReLaX: Reasoning with Latent Exploration for Large Reasoning Models](https://arxiv.org/abs/2512.07558)
*Shimin Zhang,Xianwei Chen,Yufan Shen,Ziyuan Ye,Jibin Wu*

Main category: cs.LG

TL;DR: 提出ReLaX方法，通过分析大语言模型的潜在动态来调节探索-利用平衡，解决强化学习中验证奖励导致的熵崩溃问题


<details>
  <summary>Details</summary>
Motivation: 强化学习与验证奖励（RLVR）虽然能提升大推理模型的推理能力，但会导致熵崩溃，造成策略过早收敛和性能饱和。现有的词元级熵调控方法有限，而潜在动态编码了更丰富的计算结构，可用于指导策略优化

Method: 利用Koopman算子理论获得隐藏状态动态的线性化表示，提出动态谱分散度（DSD）指标量化潜在动态的异质性，以此作为策略探索的直接指标。基于此提出ReLaX范式，在策略优化中显式地结合潜在动态来调节探索与利用

Result: 在多种多模态和纯文本推理基准测试中，ReLaX显著缓解了过早收敛问题，并持续实现了最先进的性能

Conclusion: 通过分析大语言模型的潜在动态来调节探索-利用平衡是有效的，ReLaX方法为解决强化学习中验证奖励导致的熵崩溃问题提供了新思路

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has recently demonstrated remarkable potential in enhancing the reasoning capability of Large Reasoning Models (LRMs). However, RLVR often leads to entropy collapse, resulting in premature policy convergence and performance saturation. While manipulating token-level entropy has proven effective for promoting policy exploration, we argue that the latent dynamics underlying token generation encode a far richer computational structure for steering policy optimization toward a more effective exploration-exploitation tradeoff. To enable tractable analysis and intervention of the latent dynamics of LRMs, we leverage Koopman operator theory to obtain a linearized representation of their hidden-state dynamics. This enables us to introduce Dynamic Spectral Dispersion (DSD), a new metric to quantify the heterogeneity of the model's latent dynamics, serving as a direct indicator of policy exploration. Building upon these foundations, we propose Reasoning with Latent eXploration (ReLaX), a paradigm that explicitly incorporates latent dynamics to regulate exploration and exploitation during policy optimization. Comprehensive experiments across a wide range of multimodal and text-only reasoning benchmarks show that ReLaX significantly mitigates premature convergence and consistently achieves state-of-the-art performance.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [366] [ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment](https://arxiv.org/abs/2512.06196)
*Charlie Masters,Marta Grześkiewicz,Stefano V. Albrecht*

Main category: cs.AI

TL;DR: ARCANE框架将AI对齐问题转化为多智能体协作，通过自然语言评分标准动态表示利益相关者偏好，实现可解释、无需重新训练即可调整的奖励模型。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的智能体被部署到长期任务中，保持其与利益相关者偏好的一致性变得至关重要。需要可解释的奖励模型让利益相关者理解和审计模型目标，并且能够在交互时引导智能体，无需重新训练即可适应偏好变化。

Method: ARCANE框架将对齐问题构建为多智能体协作问题，动态地将利益相关者偏好表示为自然语言评分标准（加权可验证标准集）。受效用理论启发，将评分标准学习构建为重构问题，应用正则化的组序列策略优化(GSPO)程序，平衡可解释性、忠实性和计算效率。

Result: 使用GDPVal基准的219个标注评分标准进行评估，在需要多步推理和工具使用的挑战性任务上测试ARCANE。学习的评分标准产生紧凑、易读的评估，并支持可配置的权衡（如正确性与简洁性），无需重新训练。

Conclusion: 基于评分标准的奖励模型为复杂、长期AI系统提供了可解释、测试时自适应对齐的有前景路径。

Abstract: As agents based on large language models are increasingly deployed to long-horizon tasks, maintaining their alignment with stakeholder preferences becomes critical. Effective alignment in such settings requires reward models that are interpretable so that stakeholders can understand and audit model objectives. Moreover, reward models must be capable of steering agents at interaction time, allowing preference shifts to be incorporated without retraining. We introduce ARCANE, a framework that frames alignment as a multi-agent collaboration problem that dynamically represents stakeholder preferences as natural-language rubrics: weighted sets of verifiable criteria that can be generated on-the-fly from task context. Inspired by utility theory, we formulate rubric learning as a reconstruction problem and apply a regularized Group-Sequence Policy Optimization (GSPO) procedure that balances interpretability, faithfulness, and computational efficiency. Using a corpus of 219 labeled rubrics derived from the GDPVal benchmark, we evaluate ARCANE on challenging tasks requiring multi-step reasoning and tool use. The learned rubrics produce compact, legible evaluations and enable configurable trade-offs (e.g., correctness vs. conciseness) without retraining. Our results show that rubric-based reward models offer a promising path toward interpretable, test-time adaptive alignment for complex, long-horizon AI systems.

</details>


### [367] [On measuring grounding and generalizing grounding problems](https://arxiv.org/abs/2512.06205)
*Daniel Quigley,Eric Maynard*

Main category: cs.AI

TL;DR: 论文将符号接地问题从二元判断重构为基于评估元组（上下文、意义类型、威胁模型、参考分布）的多维度审计框架，包含真实性、保持性、忠实性、鲁棒性和组合性五个标准，并应用于四种接地模式和三个案例研究。


<details>
  <summary>Details</summary>
Motivation: 传统符号接地问题将"接地"视为二元判断（接地/未接地），这种简化无法捕捉现实系统中意义实现的复杂性和多样性。论文旨在提供一个更精细的框架来评估不同系统中符号如何获得意义。

Method: 提出一个多维度审计框架，包含五个核心标准：真实性（机制是否在智能体内部并通过学习/进化获得）、保持性（原子意义是否保持完整）、忠实性（相关性和因果性）、鲁棒性（在扰动下的优雅降级）、组合性（系统是否由部分构建）。应用该框架分析四种接地模式（符号、指称、向量、关系）和三个案例研究。

Result: 模型论语义学实现精确组合但缺乏因果保证；大语言模型在语言任务上显示相关拟合和局部鲁棒性，但在无接地交互的世界任务上缺乏成功选择；人类语言通过进化和发育获得实现强真实性。不同系统在不同标准上表现各异。

Conclusion: 通过将哲学表征问题操作化，为科学哲学家、计算机科学家、语言学家和数学家提供了一个共同语言和技术框架，用于系统研究接地和意义问题。接地不是二元属性，而是需要多维度评估的复杂现象。

Abstract: The symbol grounding problem asks how tokens like cat can be about cats, as opposed to mere shapes manipulated in a calculus. We recast grounding from a binary judgment into an audit across desiderata, each indexed by an evaluation tuple (context, meaning type, threat model, reference distribution): authenticity (mechanisms reside inside the agent and, for strong claims, were acquired through learning or evolution); preservation (atomic meanings remain intact); faithfulness, both correlational (realized meanings match intended ones) and etiological (internal mechanisms causally contribute to success); robustness (graceful degradation under declared perturbations); compositionality (the whole is built systematically from the parts). We apply this framework to four grounding modes (symbolic; referential; vectorial; relational) and three case studies: model-theoretic semantics achieves exact composition but lacks etiological warrant; large language models show correlational fit and local robustness for linguistic tasks, yet lack selection-for-success on world tasks without grounded interaction; human language meets the desiderata under strong authenticity through evolutionary and developmental acquisition. By operationalizing a philosophical inquiry about representation, we equip philosophers of science, computer scientists, linguists, and mathematicians with a common language and technical framework for systematic investigation of grounding and meaning.

</details>


### [368] [Less Is More for Multi-Step Logical Reasoning of LLM Generalisation Under Rule Removal, Paraphrasing, and Compression](https://arxiv.org/abs/2512.06393)
*Qiming Bao,Xiaoxuan Fu*

Main category: cs.AI

TL;DR: LLMs在逻辑推理中对语义保持的等价变换表现稳定，但对缺失规则和矛盾证据极度脆弱


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在自然语言任务中表现出色，但其在逻辑推理中对结构性扰动的泛化能力尚不清楚。研究者希望系统评估LLMs在逻辑推理中的鲁棒性和局限性。

Method: 构建了包含四种针对性压力测试的受控评估框架：1)规则删除（冗余vs必要规则）；2)矛盾证据注入；3)逻辑保持的重写（使用六种等价定律）；4)多定律等价堆叠（2-5个同时变换）。在BERT、Qwen2和LLaMA-like三个代表性模型家族上进行实验。

Result: 所有模型在基础任务上达到完美准确率，对冗余规则删除和所有等价重写（单或多定律）完全泛化，但在必要规则删除时准确率骤降至25%，在明确矛盾存在时完全崩溃（0%准确率）。

Conclusion: LLMs对语义保持的逻辑变换具有稳定的不变性，但对缺失或冲突证据保持根本性的脆弱。该框架为诊断推理失败模式提供了清晰工具，突显了当前LLMs在逻辑泛化能力上的持续差距。

Abstract: Large language models (LLMs) excel across many natural language tasks, yet their generalisation to structural perturbations in logical contexts remains poorly understood. We introduce a controlled evaluation framework that probes reasoning reliability through four targeted stress tests: (1) rule deletion, removing either redundant or essential rules from a multi-step inference chain; (2) contradictory evidence injection; (3) logic-preserving rewrites generated through several families of equivalence laws (contrapositive, double negation, implication, De Morgan, identity, and commutativity); and (4) multi-law equivalence stacking that introduces 2-5 simultaneous logical transformations.
  Across three representative model families: BERT, Qwen2, and LLaMA-like models. Our experiments reveal a strikingly consistent pattern: all models achieve perfect accuracy on the base tasks and remain fully generalise to redundant rule deletion and all equivalence-based rewrites (single or multi-law), but fail sharply under essential rule deletion (dropping to 25% accuracy) and collapse completely in the presence of explicit contradictions (0% accuracy). These results demonstrate that LLMs possess stable invariance to semantic-preserving logical transformations, yet remain fundamentally brittle to missing or conflicting evidence. Our framework provides a clean diagnostic tool for isolating such reasoning failure modes and highlights persistent gaps in the logical generalisation abilities of current LLMs.

</details>


### [369] [Cognitive Control Architecture (CCA): A Lifecycle Supervision Framework for Robustly Aligned AI Agents](https://arxiv.org/abs/2512.06716)
*Zhibo Liang,Tianze Hu,Zaiye Chen,Mingjie Tang*

Main category: cs.AI

TL;DR: 论文提出认知控制架构（CCA），通过意图图和分层裁决器构建双层防御系统，有效抵御间接提示注入攻击，解决安全、功能和效率的多维权衡问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型代理对间接提示注入攻击存在显著脆弱性，现有防御机制在安全与功能之间存在根本性权衡，导致防御架构碎片化，无法在整个任务执行流程中提供完整的完整性保障。

Method: 提出认知控制架构（CCA），包含两个协同支柱：1）通过预生成的"意图图"实现主动控制流和数据流完整性执行；2）创新的"分层裁决器"，在检测到偏差时基于多维评分启动深度推理，专门应对复杂的条件攻击。

Result: 在AgentDojo基准测试中，CCA不仅能有效抵御挑战其他先进防御方法的复杂攻击，还能在保持显著效率和鲁棒性的同时实现无妥协的安全，从而调和了多维权衡问题。

Conclusion: CCA通过全生命周期的认知监督，构建了高效的双层防御系统，解决了现有防御机制的碎片化问题，为LLM代理提供了完整的安全保障，同时平衡了安全、功能和效率的需求。

Abstract: Autonomous Large Language Model (LLM) agents exhibit significant vulnerability to Indirect Prompt Injection (IPI) attacks. These attacks hijack agent behavior by polluting external information sources, exploiting fundamental trade-offs between security and functionality in existing defense mechanisms. This leads to malicious and unauthorized tool invocations, diverting agents from their original objectives. The success of complex IPIs reveals a deeper systemic fragility: while current defenses demonstrate some effectiveness, most defense architectures are inherently fragmented. Consequently, they fail to provide full integrity assurance across the entire task execution pipeline, forcing unacceptable multi-dimensional compromises among security, functionality, and efficiency. Our method is predicated on a core insight: no matter how subtle an IPI attack, its pursuit of a malicious objective will ultimately manifest as a detectable deviation in the action trajectory, distinct from the expected legitimate plan. Based on this, we propose the Cognitive Control Architecture (CCA), a holistic framework achieving full-lifecycle cognitive supervision. CCA constructs an efficient, dual-layered defense system through two synergistic pillars: (i) proactive and preemptive control-flow and data-flow integrity enforcement via a pre-generated "Intent Graph"; and (ii) an innovative "Tiered Adjudicator" that, upon deviation detection, initiates deep reasoning based on multi-dimensional scoring, specifically designed to counter complex conditional attacks. Experiments on the AgentDojo benchmark substantiate that CCA not only effectively withstands sophisticated attacks that challenge other advanced defense methods but also achieves uncompromised security with notable efficiency and robustness, thereby reconciling the aforementioned multi-dimensional trade-off.

</details>


### [370] [ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems](https://arxiv.org/abs/2512.06721)
*Bufang Yang,Lilin Xu,Liekang Zeng,Yunqi Guo,Siyang Jiang,Wenrui Lu,Kaiwei Liu,Hancheng Xiang,Xiaofan Jiang,Guoliang Xing,Zhenyu Yan*

Main category: cs.AI

TL;DR: ProAgent：首个端到端主动式LLM代理系统，利用多模态感知和LLM推理提供主动协助，在AR眼镜上实现，显著提升预测准确性和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理主要采用被动响应范式，依赖用户明确指令启动服务，增加了用户的物理和认知负担。需要一种能够主动感知环境并提供协助的系统。

Method: 1）主动导向的上下文提取：采用按需分层感知技术持续感知环境，提取包含感官和人物特征的分层上下文；2）上下文感知的主动推理器：将上下文映射到用户需求和工具调用，提供主动协助。系统在AR眼镜和边缘服务器上实现。

Result: 在真实世界测试平台、公共数据集和用户研究中评估，ProAgent相比最先进基线：主动预测准确率提升33.4%，工具调用F1分数提升16.8%，用户满意度显著改善。

Conclusion: ProAgent是首个端到端主动代理系统，通过融合多模态感知和LLM推理，显著提升了主动协助能力，标志着向真正主动助手迈出了重要一步。

Abstract: Large Language Model (LLM) agents are emerging to transform daily life. However, existing LLM agents primarily follow a reactive paradigm, relying on explicit user instructions to initiate services, which increases both physical and cognitive workload. In this paper, we propose ProAgent, the first end-to-end proactive agent system that harnesses massive sensory contexts and LLM reasoning to deliver proactive assistance. ProAgent first employs a proactive-oriented context extraction approach with on-demand tiered perception to continuously sense the environment and derive hierarchical contexts that incorporate both sensory and persona cues. ProAgent then adopts a context-aware proactive reasoner to map these contexts to user needs and tool calls, providing proactive assistance. We implement ProAgent on Augmented Reality (AR) glasses with an edge server and extensively evaluate it on a real-world testbed, a public dataset, and through a user study. Results show that ProAgent achieves up to 33.4% higher proactive prediction accuracy, 16.8% higher tool-calling F1 score, and notable improvements in user satisfaction over state-of-the-art baselines, marking a significant step toward proactive assistants. A video demonstration of ProAgent is available at https://youtu.be/pRXZuzvrcVs.

</details>


### [371] [A Neural Affinity Framework for Abstract Reasoning: Diagnosing the Compositional Gap in Transformer Architectures via Procedural Task Taxonomy](https://arxiv.org/abs/2512.07109)
*Miguel Ingram,Arthur Joseph Merritt*

Main category: cs.AI

TL;DR: 该研究提出了首个包含400个任务的9类别分类法，通过CNN验证其视觉一致性，并揭示Transformer架构存在神经亲和力天花板效应，表明需要亲和力对齐的混合架构。


<details>
  <summary>Details</summary>
Motivation: 响应Hodel等人对任务相关性形式化定义的需求，为ARC-AGI任务建立系统分类框架，以诊断神经网络在抽象推理任务中的性能瓶颈。

Method: 1) 开发基于规则代码分析的9类别任务分类法；2) 使用CNN在原始网格像素上验证分类法的视觉一致性；3) 在302个任务上微调170万参数Transformer，分析组合性差距；4) 应用分类法分析独立ViTARC研究。

Result: 1) 分类法准确率达97.5%；2) CNN验证显示95.24%准确率；3) 发现69.5%任务存在组合性差距；4) 低亲和力任务性能上限为51.9%，高亲和力任务达99.8%；5) 35.3%任务对Transformer具有低神经亲和力。

Conclusion: Transformer架构存在神经亲和力天花板效应，性能受架构适用性而非训练数据限制。未来进展需要开发亲和力对齐的混合架构，分类法为诊断和设计此类系统提供了精确工具。

Abstract: Responding to Hodel et al.'s (2024) call for a formal definition of task relatedness in re-arc, we present the first 9-category taxonomy of all 400 tasks, validated at 97.5% accuracy via rule-based code analysis. We prove the taxonomy's visual coherence by training a CNN on raw grid pixels (95.24% accuracy on S3, 36.25% overall, 3.3x chance), then apply the taxonomy diagnostically to the original ARC-AGI-2 test set. Our curriculum analysis reveals 35.3% of tasks exhibit low neural affinity for Transformers--a distributional bias mirroring ARC-AGI-2. To probe this misalignment, we fine-tuned a 1.7M-parameter Transformer across 302 tasks, revealing a profound Compositional Gap: 210 of 302 tasks (69.5%) achieve >80% cell accuracy (local patterns) but <10% grid accuracy (global synthesis). This provides direct evidence for a Neural Affinity Ceiling Effect, where performance is bounded by architectural suitability, not curriculum. Applying our framework to Li et al.'s independent ViTARC study (400 specialists, 1M examples each) confirms its predictive power: Very Low affinity tasks achieve 51.9% versus 77.7% for High affinity (p<0.001), with a task at 0% despite massive data. The taxonomy enables precise diagnosis: low-affinity tasks (A2) hit hard ceilings, while high-affinity tasks (C1) reach 99.8%. These findings indicate that progress requires hybrid architectures with affinity-aligned modules. We release our validated taxonomy,

</details>


### [372] [PICKT: Practical Interlinked Concept Knowledge Tracing for Personalized Learning using Knowledge Map Concept Relations](https://arxiv.org/abs/2512.07179)
*Wonbeen Lee,Channyoung Lee,Junho Sohn,Hansam Cho*

Main category: cs.AI

TL;DR: 提出PICKT模型，通过知识图谱处理多种输入数据，解决知识追踪中的冷启动问题，提升实际应用稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有知识追踪模型存在输入格式受限、新学生/新问题冷启动问题、实际服务环境稳定性不足等局限，需要更实用的解决方案。

Method: 提出PICKT模型，利用知识图谱结构化概念间关系，结合题目和概念文本信息，有效处理多种数据类型，应对冷启动场景。

Result: 实验显示模型在真实操作环境中表现优异，在新学生注册和新题目添加两个核心冷启动挑战上显著优于现有模型。

Conclusion: PICKT模型提供了处理多样化数据、解决冷启动问题的实用知识追踪方案，为下一代智能辅导系统的实际部署奠定重要基础。

Abstract: With the recent surge in personalized learning, Intelligent Tutoring Systems (ITS) that can accurately track students' individual knowledge states and provide tailored learning paths based on this information are in demand as an essential task. This paper focuses on the core technology of Knowledge Tracing (KT) models that analyze students' sequences of interactions to predict their knowledge acquisition levels. However, existing KT models suffer from limitations such as restricted input data formats, cold start problems arising with new student enrollment or new question addition, and insufficient stability in real-world service environments. To overcome these limitations, a Practical Interlinked Concept Knowledge Tracing (PICKT) model that can effectively process multiple types of input data is proposed. Specifically, a knowledge map structures the relationships among concepts considering the question and concept text information, thereby enabling effective knowledge tracing even in cold start situations. Experiments reflecting real operational environments demonstrated the model's excellent performance and practicality. The main contributions of this research are as follows. First, a model architecture that effectively utilizes diverse data formats is presented. Second, significant performance improvements are achieved over existing models for two core cold start challenges: new student enrollment and new question addition. Third, the model's stability and practicality are validated through delicate experimental design, enhancing its applicability in real-world product environments. This provides a crucial theoretical and technical foundation for the practical implementation of next-generation ITS.

</details>


### [373] [ReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning](https://arxiv.org/abs/2512.07795)
*Nearchos Potamitis,Lars Klein,Akhil Arora*

Main category: cs.AI

TL;DR: ReasonBENCH是首个量化LLM推理不稳定性的基准，通过多轮评估协议提供统计可靠的质量和成本指标，揭示大多数推理策略存在高不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 当前LLM推理评估主要报告单次运行准确率，忽略了随机解码产生的内在不确定性，导致无法可靠评估方法的稳定性、可重复性和成本一致性。

Method: 开发ReasonBENCH基准，包含：(1)标准化推理框架、模型和任务的模块化评估库；(2)报告统计可靠质量和成本指标的多轮评估协议；(3)鼓励方差感知报告的公开排行榜。

Result: 跨不同领域任务发现，绝大多数推理策略和模型表现出高不稳定性。即使平均性能相似的策略，置信区间宽度可达四倍差异，且性能最佳的方法通常成本更高且更不稳定。

Conclusion: 推理不稳定性损害了跨运行的可重复性和报告性能的可靠性。可重复性是可靠LLM推理的关键维度，ReasonBENCH为未来推理方法和不确定性量化技术提供了基础。

Abstract: Large language models (LLMs) are increasingly deployed in settings where reasoning, such as multi-step problem solving and chain-of-thought, is essential. Yet, current evaluation practices overwhelmingly report single-run accuracy while ignoring the intrinsic uncertainty that naturally arises from stochastic decoding. This omission creates a blind spot because practitioners cannot reliably assess whether a method's reported performance is stable, reproducible, or cost-consistent. We introduce ReasonBENCH, the first benchmark designed to quantify the underlying instability in LLM reasoning. ReasonBENCH provides (i) a modular evaluation library that standardizes reasoning frameworks, models, and tasks, (ii) a multi-run protocol that reports statistically reliable metrics for both quality and cost, and (iii) a public leaderboard to encourage variance-aware reporting. Across tasks from different domains, we find that the vast majority of reasoning strategies and models exhibit high instability. Notably, even strategies with similar average performance can display confidence intervals up to four times wider, and the top-performing methods often incur higher and less stable costs. Such instability compromises reproducibility across runs and, consequently, the reliability of reported performance. To better understand these dynamics, we further analyze the impact of prompts, model families, and scale on the trade-off between solve rate and stability. Our results highlight reproducibility as a critical dimension for reliable LLM reasoning and provide a foundation for future reasoning methods and uncertainty quantification techniques. ReasonBENCH is publicly available at https://github.com/au-clan/ReasonBench .

</details>


### [374] [Utilizing Multi-Agent Reinforcement Learning with Encoder-Decoder Architecture Agents to Identify Optimal Resection Location in Glioblastoma Multiforme Patients](https://arxiv.org/abs/2512.06990)
*Krishna Arun,Moinak Bhattachrya,Paras Goel*

Main category: cs.AI

TL;DR: 开发了一个用于胶质母细胞瘤诊断和治疗规划的端到端AI系统，包含诊断阶段的序列决策框架和治疗规划阶段的强化学习系统，能显著降低计算成本、缩短推理时间并提高生存率。


<details>
  <summary>Details</summary>
Motivation: 目前医疗领域缺乏支持医生治疗异质性脑肿瘤（如胶质母细胞瘤）的AI系统。胶质母细胞瘤是最致命的人类癌症，五年生存率仅5.1%，需要创新的AI解决方案来辅助诊断和治疗规划。

Method: 系统分为两个阶段：1) 诊断阶段使用包含4个分类模型（卷积神经网络和支持向量机）的序列决策框架，逐步将患者大脑分类到更具体的类别；2) 治疗规划阶段使用包含3个生成模型的强化学习系统：切除模型（扩散模型）预测可能的切除结果，放疗模型（时空视觉Transformer）生成指定周数后的脑部MRI，化疗模型（扩散模型）生成治疗后MRI。生存率计算器（卷积神经网络）检查生成的治疗后MRI是否达到目标生存率，否则通过近端策略优化的反馈循环迭代优化切除位置。

Result: 与现有解决方案相比：1) 使用4个小诊断模型的序列决策框架将计算成本降低22.28倍；2) Transformer的回归能力将肿瘤进展推理时间减少113小时；3) 应用模拟真实情况的增强技术将整体DICE分数提高2.9%。预计能将生存率提高0.9%，可能挽救约2,250人的生命。

Conclusion: 该研究开发了一个创新的端到端AI系统，能够有效辅助胶质母细胞瘤的诊断和治疗规划，显著降低计算成本、提高效率并改善治疗效果，有望提高患者生存率。

Abstract: Currently, there is a noticeable lack of AI in the medical field to support doctors in treating heterogenous brain tumors such as Glioblastoma Multiforme (GBM), the deadliest human cancer in the world with a five-year survival rate of just 5.1%. This project develops an AI system offering the only end-to-end solution by aiding doctors with both diagnosis and treatment planning. In the diagnosis phase, a sequential decision-making framework consisting of 4 classification models (Convolutional Neural Networks and Support Vector Machine) are used. Each model progressively classifies the patient's brain into increasingly specific categories, with the final step being named diagnosis. For treatment planning, an RL system consisting of 3 generative models is used. First, the resection model (diffusion model) analyzes the diagnosed GBM MRI and predicts a possible resection outcome. Second, the radiotherapy model (Spatio-Temporal Vision Transformer) generates an MRI of the brain's progression after a user-defined number of weeks. Third, the chemotherapy model (Diffusion Model) produces the post-treatment MRI. A survival rate calculator (Convolutional Neural Network) then checks if the generated post treatment MRI has a survival rate within 15% of the user defined target. If not, a feedback loop using proximal policy optimization iterates over this system until an optimal resection location is identified. When compared to existing solutions, this project found 3 key findings: (1) Using a sequential decision-making framework consisting of 4 small diagnostic models reduced computing costs by 22.28x, (2) Transformers regression capabilities decreased tumor progression inference time by 113 hours, and (3) Applying Augmentations resembling Real-life situations improved overall DICE scores by 2.9%. These results project to increase survival rates by 0.9%, potentially saving approximately 2,250 lives.

</details>


### [375] [A Geometric Unification of Concept Learning with Concept Cones](https://arxiv.org/abs/2512.07355)
*Alexandre Rocchi--Henry,Thomas Fel,Gianni Franchi*

Main category: cs.AI

TL;DR: 该论文提出了一个统一几何框架，将监督式概念瓶颈模型（CBMs）和无监督稀疏自编码器（SAEs）联系起来，两者都学习激活空间中的线性方向形成概念锥，差异仅在于锥的选择方式。


<details>
  <summary>Details</summary>
Motivation: 传统上，概念解释性研究分为两个互不交流的流派：CBMs（规定概念应该是什么）和SAEs（发现涌现概念）。论文旨在建立这两个范式之间的桥梁，通过统一的几何视角理解它们的关系。

Method: 提出概念锥的几何框架，将CBMs和SAEs都视为学习激活空间中的线性方向，其非负组合形成概念锥。建立包含性评估框架，用CBMs提供的人类定义几何作为参考，评估SAEs学习的概念锥如何近似或包含这些参考锥。

Result: 发现了稀疏度和扩展因子的"最佳点"，能最大化与CBM概念的几何和语义对齐。提供了定量指标将SAE的归纳偏置（如稀疏度、扩展比）与合理概念的出现联系起来。

Conclusion: 通过共享的几何框架统一了监督和无监督概念发现，为衡量SAE进展和评估发现概念与人类合理概念的对齐程度提供了原则性指标。

Abstract: Two traditions of interpretability have evolved side by side but seldom spoken to each other: Concept Bottleneck Models (CBMs), which prescribe what a concept should be, and Sparse Autoencoders (SAEs), which discover what concepts emerge. While CBMs use supervision to align activations with human-labeled concepts, SAEs rely on sparse coding to uncover emergent ones. We show that both paradigms instantiate the same geometric structure: each learns a set of linear directions in activation space whose nonnegative combinations form a concept cone. Supervised and unsupervised methods thus differ not in kind but in how they select this cone. Building on this view, we propose an operational bridge between the two paradigms. CBMs provide human-defined reference geometries, while SAEs can be evaluated by how well their learned cones approximate or contain those of CBMs. This containment framework yields quantitative metrics linking inductive biases -- such as SAE type, sparsity, or expansion ratio -- to emergence of plausible\footnote{We adopt the terminology of \citet{jacovi2020towards}, who distinguish between faithful explanations (accurately reflecting model computations) and plausible explanations (aligning with human intuition and domain knowledge). CBM concepts are plausible by construction -- selected or annotated by humans -- though not necessarily faithful to the true latent factors that organise the data manifold.} concepts. Using these metrics, we uncover a ``sweet spot'' in both sparsity and expansion factor that maximizes both geometric and semantic alignment with CBM concepts. Overall, our work unifies supervised and unsupervised concept discovery through a shared geometric framework, providing principled metrics to measure SAE progress and assess how well discovered concept align with plausible human concepts.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [376] [GuideNav: User-Informed Development of a Vision-Only Robotic Navigation Assistant For Blind Travelers](https://arxiv.org/abs/2512.06147)
*Hochul Hwang,Soowan Yang,Jahir Sadik Monon,Nicholas A Giudice,Sunghoon Ivan Lee,Joydeep Biswas,Donghyun Kim*

Main category: cs.RO

TL;DR: 开发了GuideNav系统，这是一个仅使用视觉的"教学-重复"导航系统，模仿导盲犬的工作方式，能够在户外环境中实现公里级的路径跟随。


<details>
  <summary>Details</summary>
Motivation: 针对盲人和低视力人群的移动辅助系统研究中，直接指导机器人导航设计的参考很少。为了填补这一空白，研究团队进行了全面的人类研究，包括对导盲犬使用者、白杖使用者、导盲犬训练师等的访谈和观察。

Method: 1. 进行了全面的人类研究（26名导盲犬使用者、4名白杖使用者、9名导盲犬训练师等访谈，以及15+小时观察）
2. 基于研究洞察开发了GuideNav系统，这是一个仅使用视觉的"教学-重复"导航系统
3. 系统构建拓扑路径表示，结合视觉地点识别和时间滤波，使用相对姿态估计器计算导航动作
4. 不依赖昂贵、笨重、耗电的传感器如LiDAR

Result: 1. 开源了去识别化的数据集以促进以人为本的开发
2. GuideNav在五个户外环境中一致实现了公里级的路径跟随
3. 即使在教学和重复运行之间存在明显场景变化的情况下仍保持可靠性
4. 用户研究（3名导盲犬使用者和1名训练师）确认了系统的可行性
5. 这是首次展示四足移动系统以类似导盲犬的方式检索路径

Conclusion: GuideNav系统成功模仿了导盲犬的导航方式，仅使用视觉传感器实现了可靠的户外路径跟随，为盲人和低视力人群的辅助系统开发提供了新的技术方向，并开源了宝贵的人类研究数据以促进该领域的发展。

Abstract: While commendable progress has been made in user-centric research on mobile assistive systems for blind and low-vision (BLV) individuals, references that directly inform robot navigation design remain rare. To bridge this gap, we conducted a comprehensive human study involving interviews with 26 guide dog handlers, four white cane users, nine guide dog trainers, and one O\&M trainer, along with 15+ hours of observing guide dog-assisted walking. After de-identification, we open-sourced the dataset to promote human-centered development and informed decision-making for assistive systems for BLV people. Building on insights from this formative study, we developed GuideNav, a vision-only, teach-and-repeat navigation system. Inspired by how guide dogs are trained and assist their handlers, GuideNav autonomously repeats a path demonstrated by a sighted person using a robot. Specifically, the system constructs a topological representation of the taught route, integrates visual place recognition with temporal filtering, and employs a relative pose estimator to compute navigation actions - all without relying on costly, heavy, power-hungry sensors such as LiDAR. In field tests, GuideNav consistently achieved kilometer-scale route following across five outdoor environments, maintaining reliability despite noticeable scene variations between teach and repeat runs. A user study with 3 guide dog handlers and 1 guide dog trainer further confirmed the system's feasibility, marking (to our knowledge) the first demonstration of a quadruped mobile system retrieving a path in a manner comparable to guide dogs.

</details>


### [377] [MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment](https://arxiv.org/abs/2512.06628)
*Ruicheng Zhang,Mingyang Zhang,Jun Zhou,Zhangrui Guo,Xiaofan Liu,Zunnan Xu,Zhizhou Zhong,Puxin Yan,Haocheng Luo,Xiu Li*

Main category: cs.RO

TL;DR: MIND-V是一个分层框架，用于生成物理合理且逻辑连贯的长时程机器人操作视频，通过语义推理、行为语义桥接和运动视频生成三个核心组件，结合强化学习后训练来增强物理一致性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作视频生成模型只能合成简单动作的短视频，且依赖手动定义轨迹，缺乏多样化的长时程操作数据，限制了具身模仿学习的发展。

Method: MIND-V包含三个核心组件：1）语义推理中心（SRH）使用预训练视觉语言模型进行任务规划；2）行为语义桥（BSB）将抽象指令转换为领域不变表示；3）运动视频生成器（MVG）进行条件视频渲染。采用分阶段视觉未来展开策略增强长时程鲁棒性，并通过GRPO强化学习后训练和物理预见一致性（PFC）奖励来确保物理合理性。

Result: MIND-V在长时程机器人操作视频生成方面实现了最先进的性能，为具身数据合成建立了可扩展且可控的范式。

Conclusion: MIND-V通过分层框架和物理一致性约束，成功解决了长时程机器人操作视频生成的挑战，为具身人工智能提供了高质量的数据合成解决方案。

Abstract: Embodied imitation learning is constrained by the scarcity of diverse, long-horizon robotic manipulation data. Existing video generation models for this domain are limited to synthesizing short clips of simple actions and often rely on manually defined trajectories. To this end, we introduce MIND-V, a hierarchical framework designed to synthesize physically plausible and logically coherent videos of long-horizon robotic manipulation. Inspired by cognitive science, MIND-V bridges high-level reasoning with pixel-level synthesis through three core components: a Semantic Reasoning Hub (SRH) that leverages a pre-trained vision-language model for task planning; a Behavioral Semantic Bridge (BSB) that translates abstract instructions into domain-invariant representations; and a Motor Video Generator (MVG) for conditional video rendering. MIND-V employs Staged Visual Future Rollouts, a test-time optimization strategy to enhance long-horizon robustness. To align the generated videos with physical laws, we introduce a GRPO reinforcement learning post-training phase guided by a novel Physical Foresight Coherence (PFC) reward. PFC leverages the V-JEPA world model to enforce physical plausibility by aligning the predicted and actual dynamic evolutions in the feature space. MIND-V demonstrates state-of-the-art performance in long-horizon robotic manipulation video generation, establishing a scalable and controllable paradigm for embodied data synthesis.

</details>


### [378] [Dynamic Visual SLAM using a General 3D Prior](https://arxiv.org/abs/2512.06868)
*Xingguang Zhong,Liren Jin,Marija Popović,Jens Behley,Cyrill Stachniss*

Main category: cs.RO

TL;DR: 提出一种新颖的单目视觉SLAM系统，能够在动态场景中鲁棒地估计相机位姿，通过结合几何补丁束调整和前馈重建模型来处理动态区域


<details>
  <summary>Details</summary>
Motivation: 动态自然环境中的相机位姿估计和3D重建具有挑战性，因为场景动态会严重降低相机位姿估计的准确性。需要开发能够在动态场景中鲁棒工作的SLAM系统

Method: 提出一种新颖的单目视觉SLAM系统，结合几何补丁在线束调整和前馈重建模型的互补优势。使用前馈重建模型精确过滤动态区域，并利用其深度预测增强补丁视觉SLAM的鲁棒性。通过将深度预测与束调整估计的补丁对齐，处理前馈重建模型批量应用的尺度模糊问题

Result: 系统能够在动态场景中鲁棒地估计相机位姿，通过动态区域过滤和深度预测对齐，有效处理场景动态带来的挑战

Conclusion: 提出的方法通过结合几何束调整和前馈重建模型，实现了在动态自然环境中鲁棒的相机位姿估计，为机器人、交互可视化和增强现实等应用提供了可靠的基础

Abstract: Reliable incremental estimation of camera poses and 3D reconstruction is key to enable various applications including robotics, interactive visualization, and augmented reality. However, this task is particularly challenging in dynamic natural environments, where scene dynamics can severely deteriorate camera pose estimation accuracy. In this work, we propose a novel monocular visual SLAM system that can robustly estimate camera poses in dynamic scenes. To this end, we leverage the complementary strengths of geometric patch-based online bundle adjustment and recent feed-forward reconstruction models. Specifically, we propose a feed-forward reconstruction model to precisely filter out dynamic regions, while also utilizing its depth prediction to enhance the robustness of the patch-based visual SLAM. By aligning depth prediction with estimated patches from bundle adjustment, we robustly handle the inherent scale ambiguities of the batch-wise application of the feed-forward reconstruction model.

</details>


### [379] [Task adaptation of Vision-Language-Action model: 1st Place Solution for the 2025 BEHAVIOR Challenge](https://arxiv.org/abs/2512.06951)
*Ilia Larchenko,Gleb Zarin,Akash Karnatak*

Main category: cs.RO

TL;DR: 该论文提出了一种视觉-动作策略，在2025年BEHAVIOR挑战赛中荣获第一名。该挑战包含50个多样化的长时程家庭任务，需要双手操作、导航和上下文感知决策。


<details>
  <summary>Details</summary>
Motivation: BEHAVIOR挑战赛是一个大规模基准测试，包含50个多样化的长时程家庭任务，需要在逼真模拟环境中进行双手操作、导航和上下文感知决策。现有的方法在处理这些复杂任务时面临训练效率和动作序列平滑性的挑战。

Method: 基于Pi0.5架构，引入了多项创新：1）相关噪声用于流匹配，提高训练效率并实现相关感知修复以生成平滑动作序列；2）可学习的混合层注意力；3）系统2阶段跟踪用于歧义消解；4）训练时使用多样本流匹配减少方差；5）推理时使用动作压缩和挑战特定校正规则。

Result: 该方法在公开和私有排行榜上，在所有50个任务中实现了26%的q-score，在2025年BEHAVIOR挑战赛中荣获第一名。

Conclusion: 提出的相关噪声流匹配、可学习注意力机制和系统2阶段跟踪等创新方法，能够有效处理复杂的长时程家庭任务，在BEHAVIOR挑战赛中取得了最佳性能。

Abstract: We present a vision-action policy that won 1st place in the 2025 BEHAVIOR Challenge - a large-scale benchmark featuring 50 diverse long-horizon household tasks in photo-realistic simulation, requiring bimanual manipulation, navigation, and context-aware decision making.
  Building on the Pi0.5 architecture, we introduce several innovations. Our primary contribution is correlated noise for flow matching, which improves training efficiency and enables correlation-aware inpainting for smooth action sequences. We also apply learnable mixed-layer attention and System 2 stage tracking for ambiguity resolution. Training employs multi-sample flow matching to reduce variance, while inference uses action compression and challenge-specific correction rules.
  Our approach achieves 26% q-score across all 50 tasks on both public and private leaderboards.

</details>


### [380] [VideoVLA: Video Generators Can Be Generalizable Robot Manipulators](https://arxiv.org/abs/2512.06963)
*Yichao Shen,Fangyun Wei,Zhiying Du,Yaobo Liang,Yan Lu,Jiaolong Yang,Nanning Zheng,Baining Guo*

Main category: cs.RO

TL;DR: VideoVLA：将大型视频生成模型转化为机器人VLA操作器，通过联合建模视频、语言和动作模态，同时预测动作序列和未来视觉结果，实现机器人操作的强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作（VLA）模型在机器人操作中对新任务、新物体和新环境的泛化能力有限。作者探索将大型视频生成模型转化为机器人操作器，通过预测动作及其视觉后果来提升泛化性能。

Method: 基于多模态扩散变换器（Diffusion Transformer），联合建模视频、语言和动作模态。利用预训练的视频生成模型进行联合视觉和动作预测，给定语言指令和图像，同时预测动作序列和未来视觉结果。

Result: 实验表明高质量的未来视觉想象与可靠的动作预测和任务成功高度相关。VideoVLA展现出强泛化能力，包括模仿其他具身的技能和处理新物体。

Conclusion: 这种同时预测动作及其视觉后果的双重预测策略探索了机器人学习的新范式，释放了操作系统的泛化能力，强调了视觉想象在机器人操作中的重要性。

Abstract: Generalization in robot manipulation is essential for deploying robots in open-world environments and advancing toward artificial general intelligence. While recent Vision-Language-Action (VLA) models leverage large pre-trained understanding models for perception and instruction following, their ability to generalize to novel tasks, objects, and settings remains limited. In this work, we present VideoVLA, a simple approach that explores the potential of transforming large video generation models into robotic VLA manipulators. Given a language instruction and an image, VideoVLA predicts an action sequence as well as the future visual outcomes. Built on a multi-modal Diffusion Transformer, VideoVLA jointly models video, language, and action modalities, using pre-trained video generative models for joint visual and action forecasting. Our experiments show that high-quality imagined futures correlate with reliable action predictions and task success, highlighting the importance of visual imagination in manipulation. VideoVLA demonstrates strong generalization, including imitating other embodiments' skills and handling novel objects. This dual-prediction strategy - forecasting both actions and their visual consequences - explores a paradigm shift in robot learning and unlocks generalization capabilities in manipulation systems.

</details>


### [381] [Mimir: Hierarchical Goal-Driven Diffusion with Uncertainty Propagation for End-to-End Autonomous Driving](https://arxiv.org/abs/2512.07130)
*Zebin Xing,Yupeng Zheng,Qichao Zhang,Zhixing Ding,Pengxuan Yang,Songen Gu,Zhongpu Xia,Dongbin Zhao*

Main category: cs.RO

TL;DR: Mimir提出了一种新颖的分层双系统框架，通过估计目标点不确定性和多速率引导机制，在自动驾驶中实现更鲁棒的轨迹生成和更快的推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法受限于不准确的高层引导信号和复杂引导模块的计算开销，需要一种既能处理不确定性又能提高效率的解决方案。

Method: 采用分层双系统框架：1) 使用拉普拉斯分布估计目标点不确定性以增强鲁棒性；2) 引入多速率引导机制提前预测扩展目标点以加速推理。

Result: 在Navhard和Navtest基准测试中，驾驶分数EPDMS提升20%，高层模块推理速度提升1.6倍，且不损失准确性。

Conclusion: Mimir通过不确定性估计和多速率引导机制，有效解决了现有方法的局限性，在自动驾驶轨迹生成中实现了更好的鲁棒性和效率平衡。

Abstract: End-to-end autonomous driving has emerged as a pivotal direction in the field of autonomous systems. Recent works have demonstrated impressive performance by incorporating high-level guidance signals to steer low-level trajectory planners. However, their potential is often constrained by inaccurate high-level guidance and the computational overhead of complex guidance modules. To address these limitations, we propose Mimir, a novel hierarchical dual-system framework capable of generating robust trajectories relying on goal points with uncertainty estimation: (1) Unlike previous approaches that deterministically model, we estimate goal point uncertainty with a Laplace distribution to enhance robustness; (2) To overcome the slow inference speed of the guidance system, we introduce a multi-rate guidance mechanism that predicts extended goal points in advance. Validated on challenging Navhard and Navtest benchmarks, Mimir surpasses previous state-of-the-art methods with a 20% improvement in the driving score EPDMS, while achieving 1.6 times improvement in high-level module inference speed without compromising accuracy. The code and models will be released soon to promote reproducibility and further development. The code is available at https://github.com/ZebinX/Mimir-Uncertainty-Driving

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [382] [A Chunked-Object Pattern for Multi-Region Large Payload Storage in Managed NoSQL Databases](https://arxiv.org/abs/2512.06852)
*Manideep Reddy Chinthareddy*

Main category: cs.DB

TL;DR: 提出"分块对象"模式，将大型逻辑实体存储为数据库内的有序分块集合，解决NoSQL数据库严格大小限制带来的跨系统复制延迟问题


<details>
  <summary>Details</summary>
Motivation: 许多托管键值数据库和NoSQL数据库（如DynamoDB、Cosmos DB）有严格的最大项目大小限制（如400KB），这给需要低延迟、多区域访问大型对象的应用程序带来挑战。标准解决方案是将有效负载卸载到对象存储中，但这会引入网络开销和跨系统复制延迟，导致主动-主动架构中的竞态条件

Method: 提出"分块对象"模式，将大型逻辑实体持久化为数据库内的有序分块集合。提供使用Amazon DynamoDB全局表的参考实现，该设计可推广到任何具有每项大小限制和多区域复制的键值存储

Result: 使用处理超过20万笔交易/小时的生产系统遥测数据进行评估。结果表明，分块对象模式消除了跨系统复制延迟风险，并通过将数据和元数据保持在单一一致性域内，将1MB有效负载的p99跨区域一致性时间减少了

Conclusion: 分块对象模式提供了一种在数据库内存储大型对象的有效方法，避免了标准指针模式带来的跨系统复制延迟问题，特别适用于需要多区域一致性的主动-主动架构

Abstract: Many managed key-value and NoSQL databases - such as Amazon DynamoDB, Azure Cosmos DB, and Google Cloud Firestore - enforce strict maximum item sizes (e.g., 400 KB in DynamoDB). This constraint imposes significant architectural challenges for applications requiring low-latency, multi-region access to objects that exceed these limits. The standard industry recommendation is to offload payloads to object storage (e.g., Amazon S3) while retaining a pointer in the database. While cost-efficient, this "pointer pattern" introduces network overhead and exposes applications to non-deterministic replication lag between the database and the object store, creating race conditions in active-active architectures.
  This paper presents a "chunked-object" pattern that persists large logical entities as sets of ordered chunks within the database itself. We precisely define the pattern and provide a reference implementation using Amazon DynamoDB Global Tables. The design generalizes to any key-value store with per-item size limits and multi-region replication. We evaluate the approach using telemetry from a production system processing over 200,000 transactions per hour. Results demonstrate that the chunked-object pattern eliminates cross-system replication lag hazards and reduces p99 cross-region time-to-consistency for 1 MB payloads by keeping data and metadata within a single consistency domain.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [383] [Why They Disagree: Decoding Differences in Opinions about AI Risk on the Lex Fridman Podcast](https://arxiv.org/abs/2512.06350)
*Nghi Truong,Phanish Puranam,Özgecan Koçak*

Main category: cs.CY

TL;DR: 论文分析AI风险辩论中的"末日论者"与"繁荣论者"分歧，发现分歧源于对复杂系统设计vs涌现、以及历史理论适用性vs革命性变化的不同因果前提，而非道德价值观差异。


<details>
  <summary>Details</summary>
Motivation: AI技术发展引发了深刻的社会分歧，尽管各方都希望AI造福人类并避免灾难性后果，但关于AI风险的辩论仍然存在显著分歧。论文旨在系统分析这些分歧的根源，特别是"末日论者"（关注存在性风险）和"繁荣论者"（关注就业风险）之间的观点差异。

Method: 将AI风险辩论中的分歧解析为定义性、事实性、因果性和道德性前提，使用LLM集成方法大规模分析推理链条，识别关键争议点。特别关注存在性风险（X-risk）和就业风险（E-risks）两种风险类型。

Result: 发现存在性风险的分歧主要源于对复杂系统中设计vs涌现的不同因果前提，而就业风险的分歧则源于对历史理论（进化论）适用性vs不适用性（革命性）的不同因果前提。两种分歧都不涉及显著的道德价值观差异，都可以用人类理性有限性的不同观点来描述。

Conclusion: AI风险辩论中的核心分歧不是道德价值观冲突，而是对复杂系统行为和历史模式适用性的不同理解。提出的基于LLM集成的大规模推理链分析方法可应用于任何领域的公共风险辩论，帮助识别关键争议点。

Abstract: The emergence of transformative technologies often surfaces deep societal divisions, nowhere more evident than in contemporary debates about artificial intelligence (AI). A striking feature of these divisions is that they persist despite shared interests in ensuring that AI benefits humanity and avoiding catastrophic outcomes. This paper analyzes contemporary debates about AI risk, parsing the differences between the "doomer" and "boomer" perspectives into definitional, factual, causal, and moral premises to identify key points of contention. We find that differences in perspectives about existential risk ("X-risk") arise fundamentally from differences in causal premises about design vs. emergence in complex systems, while differences in perspectives about employment risks ("E-risks") pertain to different causal premises about the applicability of past theories (evolution) vs their inapplicability (revolution). Disagreements about these two forms of AI risk appear to share two properties: neither involves significant disagreements on moral values and both can be described in terms of differing views on the extent of boundedness of human rationality. Our approach to analyzing reasoning chains at scale, using an ensemble of LLMs to parse textual data, can be applied to identify key points of contention in debates about risk to the public in any arena.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [384] [Formal that "Floats" High: Formal Verification of Floating Point Arithmetic](https://arxiv.org/abs/2512.06850)
*Hansa Mohanty,Vaisakh Naduvodi Viswambharan,Deepak Narayan Gadde*

Main category: cs.LO

TL;DR: 本文提出了一种可扩展的浮点运算验证方法，采用RTL到RTL的模型检查，结合分治策略和AI驱动的属性生成，相比传统方法提高了覆盖效率。


<details>
  <summary>Details</summary>
Motivation: 浮点运算的形式验证面临非线性算术行为和控制-数据路径紧密耦合的挑战。现有方法依赖C模型进行等价检查，但存在抽象差距、转换开销大、RTL级可扩展性有限等问题。

Method: 采用直接RTL到RTL模型检查，使用分治策略将验证分解为模块化阶段，每个阶段通过辅助断言和引理证明主正确性定理。结合反例引导的细化和针对性故障注入，并扩展了基于智能体AI的形式属性生成，集成LLM驱动自动化和人机协同细化。

Result: 直接RTL到RTL模型检查比独立验证实现了更高的覆盖效率，需要更少的断言，特别是当结合经过人机协同细化的AI生成属性时效果更佳。

Conclusion: 该方法提供了一种可扩展的浮点运算验证解决方案，通过直接RTL级验证、分治策略和AI增强自动化，有效解决了传统方法的局限性。

Abstract: Formal verification of floating-point arithmetic remains challenging due to non-linear arithmetic behavior and the tight coupling between control and datapath logic. Existing approaches often rely on high-level C models for equivalence checking against Register Transfer Level (RTL) designs, but this introduces abstraction gaps, translation overhead, and limits scalability at the RTL level. To address these challenges, this paper presents a scalable methodology for verifying floating-point arithmetic using direct RTL-to-RTL model checking against a golden reference model. The approach adopts a divide-and conquer strategy that decomposes verification into modular stages, each captured by helper assertions and lemmas that collectively prove a main correctness theorem. Counterexample (CEX)-guided refinement is used to iteratively localize and resolve implementation defects, while targeted fault injection validates the robustness of the verification process against precision-critical datapath errors. To assess scalability and practicality, the methodology is extended with agentic AI-based formal property generation, integrating large language model (LLM)-driven automation with Human-in-the-Loop (HITL) refinement. Coverage analysis evaluates the effectiveness of the approach by comparing handwritten and AI-generated properties in both RTL-to-RTL model checking and standalone RTL verification settings. Results show that direct RTL-to-RTL model checking achieves higher coverage efficiency and requires fewer assertions than standalone verification, especially when combined with AI-generated properties refined through HITL guidance.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [385] [Living the Novel: A System for Generating Self-Training Timeline-Aware Conversational Agents from Novels](https://arxiv.org/abs/2512.07474)
*Yifei Huang,Tianyu Yan,Sitong Gong,Xiwei Gao,Caixin Kang,Ruicong Liu,Huchuan Lu,Bo Zheng*

Main category: cs.HC

TL;DR: Living Novel系统通过两阶段训练将文学作品转化为沉浸式多角色对话体验，解决LLM角色漂移和叙事不连贯问题，在《海底两万里》上验证效果优于GPT-4o


<details>
  <summary>Details</summary>
Motivation: 解决LLM驱动角色对话中的两个核心问题：1）通用LLM存在角色漂移问题，难以保持角色一致性；2）智能体能力超出故事世界约束，导致叙事不连贯（剧透泄露）和鲁棒性失败（框架破坏）

Method: 提出两阶段训练流程：1）深度角色对齐（DPA）阶段使用无数据强化微调确保角色保真度；2）连贯性和鲁棒性增强（CRE）阶段使用故事时间感知知识图谱和检索增强训练来强制执行叙事约束

Result: 在《海底两万里》上的多阶段评估显示：DPA管道使专用模型在角色特定指标上超越GPT-4o，CRE阶段在连贯性和鲁棒性指标上达到近乎完美的表现

Conclusion: 研究为AI驱动叙事系统提供实用设计指南：角色优先的自训练是可信度的基础，明确的故事时间约束对于维持连贯、抗中断的移动网络体验至关重要

Abstract: We present the Living Novel, an end-to-end system that transforms any literary work into an immersive, multi-character conversational experience. This system is designed to solve two fundamental challenges for LLM-driven characters. Firstly, generic LLMs suffer from persona drift, often failing to stay in character. Secondly, agents often exhibit abilities that extend beyond the constraints of the story's world and logic, leading to both narrative incoherence (spoiler leakage) and robustness failures (frame-breaking). To address these challenges, we introduce a novel two-stage training pipeline. Our Deep Persona Alignment (DPA) stage uses data-free reinforcement finetuning to instill deep character fidelity. Our Coherence and Robustness Enhancing (CRE) stage then employs a story-time-aware knowledge graph and a second retrieval-grounded training pass to architecturally enforce these narrative constraints. We validate our system through a multi-phase evaluation using Jules Verne's Twenty Thousand Leagues Under the Sea. A lab study with a detailed ablation of system components is followed by a 5-day in-the-wild diary study. Our DPA pipeline helps our specialized model outperform GPT-4o on persona-specific metrics, and our CRE stage achieves near-perfect performance in coherence and robustness measures. Our study surfaces practical design guidelines for AI-driven narrative systems: we find that character-first self-training is foundational for believability, while explicit story-time constraints are crucial for sustaining coherent, interruption-resilient mobile-web experiences.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [386] [XM-ALIGN: Unified Cross-Modal Embedding Alignment for Face-Voice Association](https://arxiv.org/abs/2512.06757)
*Zhihua Fang,Shumei Tao,Junxu Wang,Liang He*

Main category: cs.SD

TL;DR: XM-ALIGN是一个统一的跨模态嵌入对齐框架，通过结合显式和隐式对齐机制，显著提升了人脸-语音跨模态验证性能，特别是在"听过"和"未听过"语言上。


<details>
  <summary>Details</summary>
Motivation: 解决跨模态验证任务中，特别是在FAME挑战赛背景下，如何有效对齐人脸和语音两种不同模态的特征表示，以提升在已知和未知语言上的验证性能。

Method: 1. 从人脸和语音编码器提取特征嵌入；2. 使用共享分类器联合优化；3. 采用均方误差（MSE）作为嵌入对齐损失；4. 在训练过程中应用数据增强策略。

Result: 在MAV-Celeb数据集上表现出优越性能，显著提升了跨模态验证性能，特别是在"听过"和"未听过"语言上。

Conclusion: XM-ALIGN框架通过结合显式和隐式对齐机制，有效解决了跨模态验证问题，为FAME挑战赛提供了一个有效的解决方案，代码将开源。

Abstract: This paper introduces our solution, XM-ALIGN (Unified Cross-Modal Embedding Alignment Framework), proposed for the FAME challenge at ICASSP 2026. Our framework combines explicit and implicit alignment mechanisms, significantly improving cross-modal verification performance in both "heard" and "unheard" languages. By extracting feature embeddings from both face and voice encoders and jointly optimizing them using a shared classifier, we employ mean squared error (MSE) as the embedding alignment loss to ensure tight alignment between modalities. Additionally, data augmentation strategies are applied during model training to enhance generalization. Experimental results show that our approach demonstrates superior performance on the MAV-Celeb dataset. The code will be released at https://github.com/PunkMale/XM-ALIGN.

</details>
