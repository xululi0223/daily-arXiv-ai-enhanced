<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 79]
- [cs.CV](#cs.CV) [Total: 98]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.AR](#cs.AR) [Total: 4]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.LG](#cs.LG) [Total: 22]
- [eess.IV](#eess.IV) [Total: 7]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.SD](#cs.SD) [Total: 1]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.HC](#cs.HC) [Total: 2]
- [math.NA](#math.NA) [Total: 1]
- [cs.AI](#cs.AI) [Total: 6]
- [cs.CR](#cs.CR) [Total: 2]
- [q-fin.ST](#q-fin.ST) [Total: 1]
- [cs.CY](#cs.CY) [Total: 1]
- [cs.RO](#cs.RO) [Total: 1]
- [q-bio.BM](#q-bio.BM) [Total: 1]
- [cs.IR](#cs.IR) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Conservative Bias in Large Language Models: Measuring Relation Predictions](https://arxiv.org/abs/2506.08120)
*Toyin Aguda,Erik Wilson,Allan Anzagira,Simerjot Kaur,Charese Smiley*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在关系提取任务中表现出明显的保守偏见，倾向于选择“无关系”标签，导致信息丢失。研究发现保守偏见比幻觉更常见，并通过语义相似性量化了其影响。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在关系提取任务中的保守偏见行为，揭示其对信息提取的影响。

Method: 通过多种提示、数据集和关系类型系统评估保守偏见与幻觉的权衡，使用SBERT和LLM提示量化语义相似性。

Result: 保守偏见的发生频率是幻觉的两倍，且保守行为在约束提示与半约束/开放式提示生成的标签间具有语义相似性。

Conclusion: 保守偏见虽避免错误关系分配，但导致信息丢失，需在模型设计中平衡保守性与信息提取的完整性。

Abstract: Large language models (LLMs) exhibit pronounced conservative bias in relation
extraction tasks, frequently defaulting to No_Relation label when an
appropriate option is unavailable. While this behavior helps prevent incorrect
relation assignments, our analysis reveals that it also leads to significant
information loss when reasoning is not explicitly included in the output. We
systematically evaluate this trade-off across multiple prompts, datasets, and
relation types, introducing the concept of Hobson's choice to capture scenarios
where models opt for safe but uninformative labels over hallucinated ones. Our
findings suggest that conservative bias occurs twice as often as hallucination.
To quantify this effect, we use SBERT and LLM prompts to capture the semantic
similarity between conservative bias behaviors in constrained prompts and
labels generated from semi-constrained and open-ended prompts.

</details>


### [2] [QA-LIGN: Aligning LLMs through Constitutionally Decomposed QA](https://arxiv.org/abs/2506.08123)
*Jacob Dineen,Aswin RRV,Qin Liu,Zhikun Xu,Xiao Ye,Ming Shen,Zhaonan Li,Shijie Lu,Chitta Baral,Muhao Chen,Ben Zhou*

Main category: cs.CL

TL;DR: QA-LIGN是一种自动符号奖励分解方法，通过为每个原则生成独立的奖励组件，提升语言模型对齐的透明度和适应性，性能与DPO基线相当或更好。


<details>
  <summary>Details</summary>
Motivation: 现有奖励对齐方法将多样反馈压缩为单一标量奖励，导致目标不透明且难以解释。

Method: QA-LIGN通过生成原则特定评估问题，分解奖励为独立组件，替代传统黑盒奖励模型。

Result: 实验显示QA-LIGN在透明度和适应性上优于传统方法，性能与DPO基线相当或更优。

Conclusion: QA-LIGN为语言模型对齐提供了更可解释和可控的方法，且不影响任务性能。

Abstract: Alignment of large language models with explicit principles (such as
helpfulness, honesty, and harmlessness) is crucial for ensuring safe and
reliable AI systems. However, standard reward-based alignment methods typically
collapse diverse feedback into a single scalar reward, entangling multiple
objectives into one opaque training signal, which hinders interpretability. In
this work, we introduce QA-LIGN, an automatic symbolic reward decomposition
approach that preserves the structure of each constitutional principle within
the reward mechanism. Instead of training a black-box reward model that outputs
a monolithic score, QA-LIGN formulates principle-specific evaluation questions
and derives separate reward components for each principle, making it a drop-in
reward model replacement. Experiments aligning an uncensored large language
model with a set of constitutional principles demonstrate that QA-LIGN offers
greater transparency and adaptability in the alignment process. At the same
time, our approach achieves performance on par with or better than a DPO
baseline. Overall, these results represent a step toward more interpretable and
controllable alignment of language models, achieved without sacrificing
end-task performance.

</details>


### [3] [EconWebArena: Benchmarking Autonomous Agents on Economic Tasks in Realistic Web Environments](https://arxiv.org/abs/2506.08136)
*Zefang Liu,Yinzhu Quan*

Main category: cs.CL

TL;DR: EconWebArena是一个用于评估自主代理在复杂、多模态经济任务中的表现的基准，包含360个任务，覆盖多个经济领域，强调真实性和权威数据源。


<details>
  <summary>Details</summary>
Motivation: 现有基准缺乏对真实经济任务的多模态和交互式评估，EconWebArena填补了这一空白。

Method: 通过大语言模型生成候选任务，人工筛选确保可行性和可靠性，评估多模态LLM在导航、理解和交互中的表现。

Result: 评估揭示了性能差距，尤其是在多模态理解和导航方面。

Conclusion: EconWebArena为经济智能代理提供了严格的测试平台，凸显了当前技术的局限性。

Abstract: We introduce EconWebArena, a benchmark for evaluating autonomous agents on
complex, multimodal economic tasks in realistic web environments. The benchmark
comprises 360 curated tasks from 82 authoritative websites spanning domains
such as macroeconomics, labor, finance, trade, and public policy. Each task
challenges agents to navigate live websites, interpret structured and visual
content, interact with real interfaces, and extract precise, time-sensitive
data through multi-step workflows. We construct the benchmark by prompting
multiple large language models (LLMs) to generate candidate tasks, followed by
rigorous human curation to ensure clarity, feasibility, and source reliability.
Unlike prior work, EconWebArena emphasizes fidelity to authoritative data
sources and the need for grounded web-based economic reasoning. We evaluate a
diverse set of state-of-the-art multimodal LLMs as web agents, analyze failure
cases, and conduct ablation studies to assess the impact of visual grounding,
plan-based reasoning, and interaction design. Our results reveal substantial
performance gaps and highlight persistent challenges in grounding, navigation,
and multimodal understanding, positioning EconWebArena as a rigorous testbed
for economic web intelligence.

</details>


### [4] [Multilingual Hate Speech Detection in Social Media Using Translation-Based Approaches with Large Language Models](https://arxiv.org/abs/2506.08147)
*Muhammad Usman,Muhammad Ahmad,M. Shahiki Tash,Irina Gelbukh,Rolando Quintero Tellez,Grigori Sidorov*

Main category: cs.CL

TL;DR: 论文提出了一种基于注意力层和多语言数据集的仇恨言论检测方法，显著提升了英语、西班牙语和乌尔都语的检测性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上的仇恨言论威胁在线安全与包容性，而乌尔都语的仇恨言论检测研究较少，尤其是基于翻译的方法。

Method: 使用注意力层增强特征提取，结合GPT-3.5 Turbo和Qwen 2.5 72B等模型，并采用TF-IDF用于非Transformer模型。

Result: 在英语、西班牙语和乌尔都语上分别实现了8.75%、8.97%和5.19%的性能提升，多语言模型F1分数达0.88。

Conclusion: 该方法为多语言仇恨言论检测提供了有效解决方案，有助于构建更安全的数字社区。

Abstract: Social media platforms are critical spaces for public discourse, shaping
opinions and community dynamics, yet their widespread use has amplified harmful
content, particularly hate speech, threatening online safety and inclusivity.
While hate speech detection has been extensively studied in languages like
English and Spanish, Urdu remains underexplored, especially using
translation-based approaches. To address this gap, we introduce a trilingual
dataset of 10,193 tweets in English (3,834 samples), Urdu (3,197 samples), and
Spanish (3,162 samples), collected via keyword filtering, with a balanced
distribution of 4,849 Hateful and 5,344 Not-Hateful labels. Our methodology
leverages attention layers as a precursor to transformer-based models and large
language models (LLMs), enhancing feature extraction for multilingual hate
speech detection. For non-transformer models, we use TF-IDF for feature
extraction. The dataset is benchmarked using state-of-the-art models, including
GPT-3.5 Turbo and Qwen 2.5 72B, alongside traditional machine learning models
like SVM and other transformers (e.g., BERT, RoBERTa). Three annotators,
following rigorous guidelines, ensured high dataset quality, achieving a
Fleiss' Kappa of 0.821. Our approach, integrating attention layers with GPT-3.5
Turbo and Qwen 2.5 72B, achieves strong performance, with macro F1 scores of
0.87 for English (GPT-3.5 Turbo), 0.85 for Spanish (GPT-3.5 Turbo), 0.81 for
Urdu (Qwen 2.5 72B), and 0.88 for the joint multilingual model (Qwen 2.5 72B).
These results reflect improvements of 8.75% in English (over SVM baseline
0.80), 8.97% in Spanish (over SVM baseline 0.78), 5.19% in Urdu (over SVM
baseline 0.77), and 7.32% in the joint multilingual model (over SVM baseline
0.82). Our framework offers a robust solution for multilingual hate speech
detection, fostering safer digital communities worldwide.

</details>


### [5] [ETT-CKGE: Efficient Task-driven Tokens for Continual Knowledge Graph Embedding](https://arxiv.org/abs/2506.08158)
*Lijing Zhu,Qizhen Lan,Qing Tian,Wenbo Sun,Li Yang,Lu Xia,Yixin Xie,Xi Xiao,Tiehang Duan,Cui Tao,Shuteng Niu*

Main category: cs.CL

TL;DR: ETT-CKGE提出了一种高效、任务驱动的持续知识图谱嵌入方法，通过可学习的任务驱动令牌实现知识迁移，显著提升了训练效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有持续知识图谱嵌入方法在效率和可扩展性上存在不足，主要由于手动设计的节点/关系重要性评分和计算成本高的图遍历。

Method: ETT-CKGE引入可学习的任务驱动令牌，直接捕获任务相关信号，避免了显式的节点评分或遍历，通过简单的矩阵操作实现知识迁移。

Result: 在六个基准数据集上的实验表明，ETT-CKGE在预测性能上优于或与现有方法相当，同时显著提升了训练效率和可扩展性。

Conclusion: ETT-CKGE通过任务驱动令牌实现了高效且有效的知识迁移，为持续知识图谱嵌入提供了新的解决方案。

Abstract: Continual Knowledge Graph Embedding (CKGE) seeks to integrate new knowledge
while preserving past information. However, existing methods struggle with
efficiency and scalability due to two key limitations: (1) suboptimal knowledge
preservation between snapshots caused by manually designed node/relation
importance scores that ignore graph dependencies relevant to the downstream
task, and (2) computationally expensive graph traversal for node/relation
importance calculation, leading to slow training and high memory overhead. To
address these limitations, we introduce ETT-CKGE (Efficient, Task-driven,
Tokens for Continual Knowledge Graph Embedding), a novel task-guided CKGE
method that leverages efficient task-driven tokens for efficient and effective
knowledge transfer between snapshots. Our method introduces a set of learnable
tokens that directly capture task-relevant signals, eliminating the need for
explicit node scoring or traversal. These tokens serve as consistent and
reusable guidance across snapshots, enabling efficient token-masked embedding
alignment between snapshots. Importantly, knowledge transfer is achieved
through simple matrix operations, significantly reducing training time and
memory usage. Extensive experiments across six benchmark datasets demonstrate
that ETT-CKGE consistently achieves superior or competitive predictive
performance, while substantially improving training efficiency and scalability
compared to state-of-the-art CKGE methods. The code is available at:
https://github.com/lijingzhu1/ETT-CKGE/tree/main

</details>


### [6] [Can Artificial Intelligence Write Like Borges? An Evaluation Protocol for Spanish Microfiction](https://arxiv.org/abs/2506.08172)
*Gerardo Aleman Manzanarez,Nora de la Cruz Arana,Jorge Garcia Flores,Yobany Garcia Medina,Raul Monroy,Nathalie Pernelle*

Main category: cs.CL

TL;DR: 该论文提出了GrAImes协议，用于基于文学理论评估AI生成的微小说，重点关注主题一致性、文本清晰度、解释深度和美学质量。


<details>
  <summary>Details</summary>
Motivation: 尽管AI生成的短篇小说在叙事一致性和语言连贯性上有所进步，但其文学价值（尤其是美学质量）的严格评估尚未得到足够关注。

Method: 提出了GrAImes评估协议，基于文学理论，为AI生成的微小说提供客观评估框架，并通过文学专家和爱好者验证其有效性。

Result: 验证结果表明，GrAImes协议能够有效评估AI生成微小说的文学价值。

Conclusion: GrAImes协议为自动生成微小说的文学价值评估奠定了基础。

Abstract: Automated story writing has been a subject of study for over 60 years. Large
language models can generate narratively consistent and linguistically coherent
short fiction texts. Despite these advancements, rigorous assessment of such
outputs for literary merit - especially concerning aesthetic qualities - has
received scant attention. In this paper, we address the challenge of evaluating
AI-generated microfictions and argue that this task requires consideration of
literary criteria across various aspects of the text, such as thematic
coherence, textual clarity, interpretive depth, and aesthetic quality. To
facilitate this, we present GrAImes: an evaluation protocol grounded in
literary theory, specifically drawing from a literary perspective, to offer an
objective framework for assessing AI-generated microfiction. Furthermore, we
report the results of our validation of the evaluation protocol, as answered by
both literature experts and literary enthusiasts. This protocol will serve as a
foundation for evaluating automatically generated microfictions and assessing
their literary value.

</details>


### [7] [LLM-BT: Back-Translation as a Framework for Terminology Standardization and Dynamic Semantic Embedding](https://arxiv.org/abs/2506.08174)
*Li Weigang,Pedro Carvalho Brom*

Main category: cs.CL

TL;DR: LLM-BT利用大语言模型（LLMs）实现多语言术语标准化，通过跨语言语义对齐自动化验证术语一致性，支持人机协作。


<details>
  <summary>Details</summary>
Motivation: 英语技术术语快速增长，传统专家驱动的标准化方法难以应对快速发展的领域（如AI和量子计算），且手动方法难以保证多语言一致性。

Method: 提出LLM-BT框架，包括术语级一致性验证、多路径验证工作流以及将回译视为动态语义嵌入的方法。

Result: 实验显示术语一致性超过90%，跨语言鲁棒性强（BLEU>0.45，葡萄牙语准确率100%）。

Conclusion: LLM-BT将回译转化为多语言术语标准化的主动引擎，支持全球科技领域的术语治理。

Abstract: The rapid growth of English technical terms challenges traditional
expert-driven standardization, especially in fast-evolving fields like AI and
quantum computing. Manual methods struggle to ensure multilingual consistency.
We propose \textbf{LLM-BT}, a back-translation framework powered by large
language models (LLMs) to automate terminology verification and standardization
via cross-lingual semantic alignment. Our contributions are: \textbf{(1)
Term-Level Consistency Validation:} Using English $\rightarrow$ intermediate
language $\rightarrow$ English back-translation, LLM-BT achieves high term
consistency across models (e.g., GPT-4, DeepSeek, Grok), with case studies
showing over 90\% exact or semantic matches. \textbf{(2) Multi-Path
Verification Workflow:} A novel ``Retrieve--Generate--Verify--Optimize''
pipeline integrates serial (e.g., EN $\rightarrow$ ZHcn $\rightarrow$ ZHtw
$\rightarrow$ EN) and parallel (e.g., EN $\rightarrow$ Chinese/Portuguese
$\rightarrow$ EN) BT routes. BLEU and term accuracy indicate strong
cross-lingual robustness (BLEU $>$ 0.45; Portuguese accuracy 100\%).
\textbf{(3) Back-Translation as Semantic Embedding:} BT is conceptualized as
dynamic semantic embedding, revealing latent meaning trajectories. Unlike
static embeddings, LLM-BT provides transparent path-based embeddings shaped by
model evolution. LLM-BT transforms back-translation into an active engine for
multilingual terminology standardization, enabling human--AI collaboration:
machines ensure semantic fidelity, humans guide cultural interpretation. This
infrastructure supports terminology governance across scientific and
technological fields worldwide.

</details>


### [8] [Unable to forget: Proactive lnterference Reveals Working Memory Limits in LLMs Beyond Context Length](https://arxiv.org/abs/2506.08184)
*Chupei Wang,Jiaqiu Vince Sun*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型（LLM）在信息检索中受上下文干扰影响，检索准确性随干扰增加而下降，提示工程缓解效果有限。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM在信息检索中受上下文干扰的影响，揭示其工作记忆瓶颈。

Method: 采用认知科学中的主动干扰（PI）范式，设计PI-LLM评估方法，测试LLM在语义相关更新流中的检索表现。

Result: LLM检索准确性随干扰累积呈对数线性下降，错误源于检索被覆盖的旧值，提示工程效果有限。

Conclusion: LLM在信息检索中存在干扰抑制能力不足的问题，需开发新方法增强其忽略无关内容的能力。

Abstract: Information retrieval in Large Language Models (LLMs) is increasingly
recognized as intertwined with generation capabilities rather than mere lookup.
While longer contexts are often assumed to improve retrieval, the effects of
intra-context interference remain understudied. To address this, we adapt the
proactive interference (PI) paradigm from cognitive science, where earlier
information disrupts recall of newer updates. In humans, susceptibility to such
interference is inversely linked to working memory capacity. We introduce
PI-LLM, an evaluation that sequentially streams semantically related key-value
updates and queries only the final values. Although these final values are
clearly positioned just before the query, LLM retrieval accuracy declines
log-linearly toward zero as interference accumulates; errors arise from
retrieving previously overwritten values. Attempts to mitigate interference via
prompt engineering (e.g., instructing models to ignore earlier input) yield
limited success. These findings reveal a fundamental constraint on LLMs'
ability to disentangle interference and flexibly manipulate information,
suggesting a working memory bottleneck beyond mere context access. This calls
for approaches that strengthen models' ability to suppress irrelevant content
during retrieval.

</details>


### [9] ["I Wrote, I Paused, I Rewrote" Teaching LLMs to Read Between the Lines of Student Writing](https://arxiv.org/abs/2506.08221)
*Samra Zafar,Shaheer Minhas,Syed Ali Hassan Zaidi,Arfa Naeem,Zahra Ali*

Main category: cs.CL

TL;DR: 研究探讨了利用写作过程数据（如击键记录和定期快照）改进大型语言模型（LLM）对学生写作反馈的效果，发现学生更倾向于基于过程的反馈。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的反馈仅基于最终文本，缺乏对写作过程的了解，无法反映学生的思考和修改过程。

Method: 开发了一个数字写作工具，记录学生的打字内容和写作过程；20名学生使用该工具撰写限时作文，并通过LLM生成基于最终文本和写作过程的反馈，学生随后评估反馈的有用性和相关性。

Result: 学生更偏好基于过程的反馈，认为其更贴近自身思考；某些修改类型（如添加内容或重组段落）与更高的连贯性和详实性评分相关。

Conclusion: 通过让LLM更了解写作过程，可以生成更有意义、个性化和支持性的反馈。

Abstract: Large language models(LLMs) like Gemini are becoming common tools for
supporting student writing. But most of their feedback is based only on the
final essay missing important context about how that text was written. In this
paper, we explore whether using writing process data, collected through
keystroke logging and periodic snapshots, can help LLMs give feedback that
better reflects how learners think and revise while writing. We built a digital
writing tool that captures both what students type and how their essays evolve
over time. Twenty students used this tool to write timed essays, which were
then evaluated in two ways: (i) LLM generated feedback using both the final
essay and the full writing trace, and (ii) After the task, students completed
surveys about how useful and relatable they found the feedback. Early results
show that learners preferred the process-aware LLM feedback, finding it more in
tune with their own thinking. We also found that certain types of edits, like
adding new content or reorganizing paragraphs, aligned closely with higher
scores in areas like coherence and elaboration. Our findings suggest that
making LLMs more aware of the writing process can lead to feedback that feels
more meaningful, personal, and supportive.

</details>


### [10] [Compound AI Systems Optimization: A Survey of Methods, Challenges, and Future Directions](https://arxiv.org/abs/2506.08234)
*Yu-Ang Lee,Guan-Ting Yi,Mei-Yi Liu,Jui-Chao Lu,Guan-Bo Yang,Yun-Nung Chen*

Main category: cs.CL

TL;DR: 本文综述了复合AI系统优化的最新进展，包括数值和基于语言的技术，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着复合AI系统的复杂性增加，优化其组件及交互面临新挑战，需要探索新方法。

Method: 系统回顾了监督微调（SFT）、强化学习（RL）和自然语言反馈等方法，并分类现有技术。

Result: 提出了复合AI系统优化的形式化定义，并总结了现有方法的分类和局限性。

Conclusion: 指出了该领域的开放研究挑战和未来方向，相关文献列表已公开。

Abstract: Recent advancements in large language models (LLMs) and AI systems have led
to a paradigm shift in the design and optimization of complex AI workflows. By
integrating multiple components, compound AI systems have become increasingly
adept at performing sophisticated tasks. However, as these systems grow in
complexity, new challenges arise in optimizing not only individual components
but also their interactions. While traditional optimization methods such as
supervised fine-tuning (SFT) and reinforcement learning (RL) remain
foundational, the rise of natural language feedback introduces promising new
approaches, especially for optimizing non-differentiable systems. This paper
provides a systematic review of recent progress in optimizing compound AI
systems, encompassing both numerical and language-based techniques. We
formalize the notion of compound AI system optimization, classify existing
methods along several key dimensions, and highlight open research challenges
and future directions in this rapidly evolving field. A list of surveyed papers
is publicly available at https://github.com/MiuLab/AISysOpt-Survey.

</details>


### [11] [Can AI Validate Science? Benchmarking LLMs for Accurate Scientific Claim $\rightarrow$ Evidence Reasoning](https://arxiv.org/abs/2506.08235)
*Shashidhar Reddy Javaji,Yupeng Cao,Haohang Li,Yangyang Yu,Nikhil Muralidhar,Zining Zhu*

Main category: cs.CL

TL;DR: CLAIM-BENCH是一个评估大语言模型（LLMs）在科学论文中提取和验证声明与证据能力的基准测试，揭示了LLMs在处理复杂科学内容时的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LLMs是否真正理解科学论文中声明与证据之间的复杂逻辑关系。

Method: 通过系统比较三种启发式方法（分治法）在六种LLMs上的表现，评估其科学理解能力。

Result: 结果显示闭源模型（如GPT-4和Claude）在精确度和召回率上优于开源模型，且特定提示策略能显著提升性能。

Conclusion: CLAIM-BENCH为评估LLMs的科学理解能力设定了新标准，并为其在更深入、可靠的推理能力上提供了改进方向。

Abstract: Large language models (LLMs) are increasingly being used for complex research
tasks such as literature review, idea generation, and scientific paper
analysis, yet their ability to truly understand and process the intricate
relationships within complex research papers, such as the logical links between
claims and supporting evidence remains largely unexplored. In this study, we
present CLAIM-BENCH, a comprehensive benchmark for evaluating LLMs'
capabilities in scientific claim-evidence extraction and validation, a task
that reflects deeper comprehension of scientific argumentation. We
systematically compare three approaches which are inspired by divide and
conquer approaches, across six diverse LLMs, highlighting model-specific
strengths and weaknesses in scientific comprehension. Through evaluation
involving over 300 claim-evidence pairs across multiple research domains, we
reveal significant limitations in LLMs' ability to process complex scientific
content. Our results demonstrate that closed-source models like GPT-4 and
Claude consistently outperform open-source counterparts in precision and recall
across claim-evidence identification tasks. Furthermore, strategically designed
three-pass and one-by-one prompting approaches significantly improve LLMs'
abilities to accurately link dispersed evidence with claims, although this
comes at increased computational cost. CLAIM-BENCH sets a new standard for
evaluating scientific comprehension in LLMs, offering both a diagnostic tool
and a path forward for building systems capable of deeper, more reliable
reasoning across full-length papers.

</details>


### [12] [Automatic Generation of Inference Making Questions for Reading Comprehension Assessments](https://arxiv.org/abs/2506.08260)
*Wanjing Anya Ma,Michael Flor,Zuowei Wang*

Main category: cs.CL

TL;DR: 论文研究了阅读理解中的推理能力，提出了一种推理类型分类法，并利用GPT-4o生成诊断性阅读理解题目，评估其质量和适用性。


<details>
  <summary>Details</summary>
Motivation: 推理能力是阅读理解中的关键但复杂技能，诊断性题目能帮助教育者提供更有针对性的阅读指导。

Method: 提出推理类型分类法，分析题目分布；使用GPT-4o通过少量示例生成推理题目，比较有无链式思维提示的效果。

Result: GPT-4o生成93.8%高质量题目，但仅42.6%准确匹配目标推理类型。

Conclusion: 结合自动生成与人工判断，有望实现可扩展的高质量诊断评估。

Abstract: Inference making is an essential but complex skill in reading comprehension
(RC). Some inferences require resolving references across sentences, and some
rely on using prior knowledge to fill in the detail that is not explicitly
written in the text. Diagnostic RC questions can help educators provide more
effective and targeted reading instruction and interventions for school-age
students. We introduce a taxonomy of inference types for RC and use it to
analyze the distribution of items within a diagnostic RC item bank. Next, we
present experiments using GPT-4o to generate bridging-inference RC items for
given reading passages via few-shot prompting, comparing conditions with and
without chain-of-thought prompts. Generated items were evaluated on three
aspects: overall item quality, appropriate inference type, and LLM reasoning,
achieving high inter-rater agreements above 0.90. Our results show that GPT-4o
produced 93.8% good-quality questions suitable for operational use in grade
3-12 contexts; however, only 42.6% of the generated questions accurately
matched the targeted inference type. We conclude that combining automatic item
generation with human judgment offers a promising path toward scalable,
high-quality diagnostic RC assessments.

</details>


### [13] [Institutional Books 1.0: A 242B token dataset from Harvard Library's collections, refined for accuracy and usability](https://arxiv.org/abs/2506.08300)
*Matteo Cargnelutti,Catherine Brobston,John Hess,Jack Cushman,Kristi Mukk,Aristana Scourtas,Kyle Courtney,Greg Leppert,Amanda Watson,Martha Whitehead,Jonathan Zittrain*

Main category: cs.CL

TL;DR: 报告介绍了Institutional Books 1.0数据集，这是一个基于哈佛图书馆公共领域书籍的大规模数据集，旨在支持高质量语言模型的训练和推理。


<details>
  <summary>Details</summary>
Motivation: 由于高质量公开训练数据的稀缺性，以及LLMs对数据质量和多样性的依赖，需要建立可持续的数据管理实践。

Method: 与哈佛图书馆合作，提取、分析和处理了约98.3万卷公共领域书籍的OCR文本和元数据，总计242B tokens。

Result: 发布了包含原始和处理后OCR文本及元数据的数据集，覆盖多种语言和历史文本。

Conclusion: 该数据集为研究者和开发者提供了高质量的历史文本资源，支持更广泛的应用和分析。

Abstract: Large language models (LLMs) use data to learn about the world in order to
produce meaningful correlations and predictions. As such, the nature, scale,
quality, and diversity of the datasets used to train these models, or to
support their work at inference time, have a direct impact on their quality.
The rapid development and adoption of LLMs of varying quality has brought into
focus the scarcity of publicly available, high-quality training data and
revealed an urgent need to ground the stewardship of these datasets in
sustainable practices with clear provenance chains. To that end, this technical
report introduces Institutional Books 1.0, a large collection of public domain
books originally digitized through Harvard Library's participation in the
Google Books project, beginning in 2006. Working with Harvard Library, we
extracted, analyzed, and processed these volumes into an extensively-documented
dataset of historic texts. This analysis covers the entirety of Harvard
Library's collection scanned as part of that project, originally spanning
1,075,899 volumes written in over 250 different languages for a total of
approximately 250 billion tokens. As part of this initial release, the
OCR-extracted text (original and post-processed) as well as the metadata
(bibliographic, source, and generated) of the 983,004 volumes, or 242B tokens,
identified as being in the public domain have been made available. This report
describes this project's goals and methods as well as the results of the
analyses we performed, all in service of making this historical collection more
accessible and easier for humans and machines alike to filter, read and use.

</details>


### [14] [Wait, We Don't Need to "Wait"! Removing Thinking Tokens Improves Reasoning Efficiency](https://arxiv.org/abs/2506.08343)
*Chenlong Wang,Yuanning Feng,Dongping Chen,Zhaoyang Chu,Ranjay Krishna,Tianyi Zhou*

Main category: cs.CL

TL;DR: NoWait通过抑制显式自我反思标记（如“Wait”和“Hmm”）来减少推理过程中的冗余输出，显著缩短推理轨迹长度，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂推理中常产生冗余输出，影响效率。研究探讨显式自我反思是否必要。

Method: 提出NoWait方法，在推理过程中抑制自我反思标记，减少冗余。

Result: 在10个基准测试中，NoWait将推理轨迹长度缩短27%-51%，且不影响模型性能。

Conclusion: NoWait是一种即插即用的高效多模态推理解决方案。

Abstract: Recent advances in large reasoning models have enabled complex, step-by-step
reasoning but often introduce significant overthinking, resulting in verbose
and redundant outputs that hinder efficiency. In this study, we examine whether
explicit self-reflection, signaled by tokens such as "Wait" and "Hmm", is
necessary for advanced reasoning. We propose NoWait, a simple yet effective
approach that disables explicit self-reflection by suppressing these tokens
during inference. Extensive experiments on ten benchmarks across textual,
visual, and video reasoning tasks show that NoWait reduces chain-of-thought
trajectory length by up to 27%-51% in five R1-style model series, without
compromising model utility. NoWait thus offers a plug-and-play solution for
efficient and utility-preserving multimodal reasoning.

</details>


### [15] [Evaluating LLMs Across Multi-Cognitive Levels: From Medical Knowledge Mastery to Scenario-Based Problem Solving](https://arxiv.org/abs/2506.08349)
*Yuxuan Zhou,Xien Liu,Chenwei Yan,Chen Ning,Xiao Zhang,Boxun Li,Xiangling Fu,Shijin Wang,Guoping Hu,Yu Wang,Ji Wu*

Main category: cs.CL

TL;DR: 论文提出了一个基于Bloom分类法的多认知层次评估框架，用于评估大语言模型（LLMs）在医学领域的表现。研究发现，随着认知复杂度增加，模型性能显著下降，模型规模对高认知层次任务更为关键。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在不同认知层次上的能力，尤其是在医学领域的表现，以填补现有研究的空白。

Method: 提出一个多认知层次的评估框架，整合现有医学数据集，并设计针对三个认知层次的任务：基础知识掌握、综合知识应用和基于场景的问题解决。评估了六类主流LLMs。

Result: 随着认知复杂度增加，所有评估模型的性能均显著下降，模型规模在高认知层次任务中更为重要。

Conclusion: 研究强调了提升LLMs在高认知层次医学能力的必要性，并为开发适合实际医学应用的LLMs提供了见解。

Abstract: Large language models (LLMs) have demonstrated remarkable performance on
various medical benchmarks, but their capabilities across different cognitive
levels remain underexplored. Inspired by Bloom's Taxonomy, we propose a
multi-cognitive-level evaluation framework for assessing LLMs in the medical
domain in this study. The framework integrates existing medical datasets and
introduces tasks targeting three cognitive levels: preliminary knowledge grasp,
comprehensive knowledge application, and scenario-based problem solving. Using
this framework, we systematically evaluate state-of-the-art general and medical
LLMs from six prominent families: Llama, Qwen, Gemma, Phi, GPT, and DeepSeek.
Our findings reveal a significant performance decline as cognitive complexity
increases across evaluated models, with model size playing a more critical role
in performance at higher cognitive levels. Our study highlights the need to
enhance LLMs' medical capabilities at higher cognitive levels and provides
insights for developing LLMs suited to real-world medical applications.

</details>


### [16] [Low-resource domain adaptation while minimizing energy and hardware resource consumption](https://arxiv.org/abs/2506.08433)
*Hernán Maina,Nicolás Wolovick,Luciana Benotti*

Main category: cs.CL

TL;DR: 研究探讨了不同数值精度和数据并行化策略对LLM训练速度和模型准确性的影响，旨在支持低资源环境下的领域适应。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）训练成本高，且易受主流文化和价值观影响。领域适应虽能改善模型与多样化语境的匹配，但其计算成本仍是障碍，尤其是对资源有限的研究团队。

Method: 评估不同数值精度和数据并行化策略对训练速度和模型准确性的影响。

Result: 研究结果为关注能源效率、可访问性或硬件限制的场景提供了实用参考。

Conclusion: 该研究为低资源环境下的领域适应提供了可行的优化方向。

Abstract: Training Large Language Models (LLMs) is costly in terms of energy, hardware,
and annotated data, often resulting in a positionality rooted in predominant
cultures and values (Santy et al., 2023). Domain adaptation has emerged as a
promising strategy to better align models with diverse cultural and value
contexts (Hershcovich et al., 2022), but its computational cost remains a
significant barrier, particularly for research groups lacking access to
large-scale infrastructure. In this paper, we evaluate how the use of different
numerical precisions and data parallelization strategies impacts both training
speed (as a proxy to energy and hardware consumption) and model accuracy, with
the goal of facilitating domain adaptation in low-resource environments. Our
findings are relevant to any setting where energy efficiency, accessibility, or
limited hardware availability are key concerns.

</details>


### [17] [Text Embeddings Should Capture Implicit Semantics, Not Just Surface Meaning](https://arxiv.org/abs/2506.08354)
*Yiqun Sun,Qiang Huang,Anthony K. H. Tung,Jun Yu*

Main category: cs.CL

TL;DR: 本文主张文本嵌入研究应超越表层语义，将隐含语义作为核心建模目标，以更好地应对语言复杂性。


<details>
  <summary>Details</summary>
Motivation: 当前文本嵌入模型主要关注表层语义，忽视了隐含语义（如语用、说话者意图和社会文化背景），导致其在需要深层语义理解的任务中表现不佳。

Method: 通过初步研究展示现有模型在隐含语义任务上的局限性，并提出改进方向：多样化和语言学基础的数据、评估深层语义的基准、明确建模隐含语义。

Result: 初步研究表明，即使是先进模型在隐含语义任务上表现仅略优于简单基线。

Conclusion: 呼吁研究社区转变范式，将隐含语义作为核心目标，以提升嵌入模型对真实语言复杂性的适应能力。

Abstract: This position paper argues that the text embedding research community should
move beyond surface meaning and embrace implicit semantics as a central
modeling goal. Text embedding models have become foundational in modern NLP,
powering a wide range of applications and drawing increasing research
attention. Yet, much of this progress remains narrowly focused on surface-level
semantics. In contrast, linguistic theory emphasizes that meaning is often
implicit, shaped by pragmatics, speaker intent, and sociocultural context.
Current embedding models are typically trained on data that lacks such depth
and evaluated on benchmarks that reward the capture of surface meaning. As a
result, they struggle with tasks requiring interpretive reasoning, speaker
stance, or social meaning. Our pilot study highlights this gap, showing that
even state-of-the-art models perform only marginally better than simplistic
baselines on implicit semantics tasks. To address this, we call for a paradigm
shift: embedding research should prioritize more diverse and linguistically
grounded training data, design benchmarks that evaluate deeper semantic
understanding, and explicitly frame implicit meaning as a core modeling
objective, better aligning embeddings with real-world language complexity.

</details>


### [18] [DEAL: Disentangling Transformer Head Activations for LLM Steering](https://arxiv.org/abs/2506.08359)
*Li-Ming Zhan,Bo Liu,Zexin Lu,Chengqiang Xie,Jiannong Cao,Xiao-Ming Wu*

Main category: cs.CL

TL;DR: 提出了一种基于因果归因的框架，用于识别Transformer中与行为相关的注意力头，通过向量量化自编码器（VQ-AE）划分潜在空间，并评估行为相关性，实现了更准确的推理时干预。


<details>
  <summary>Details</summary>
Motivation: 当前方法依赖表面线索或临时启发式，导致模块选择不理想或产生意外结果，需要一种更原则性的方法来识别行为相关的注意力头。

Method: 训练VQ-AE对注意力头的激活进行编码，划分行为相关与无关子空间，并通过二元分类指标评估行为相关性，生成行为相关性分数。

Result: 在七个LLM和五个行为数据集上验证，方法在真实性干预任务中表现优异，所选注意力头在跨领域任务中具有零样本泛化能力。

Conclusion: 提出的框架能更准确地识别行为相关注意力头，提升推理时干预效果，并具备跨领域泛化能力。

Abstract: Inference-time steering aims to alter the response characteristics of large
language models (LLMs) without modifying their underlying parameters. A
critical step in this process is the identification of internal modules within
LLMs that are associated with the target behavior. However, current approaches
to module selection often depend on superficial cues or ad-hoc heuristics,
which can result in suboptimal or unintended outcomes. In this work, we propose
a principled causal-attribution framework for identifying behavior-relevant
attention heads in transformers. For each head, we train a vector-quantized
autoencoder (VQ-AE) on its attention activations, partitioning the latent space
into behavior-relevant and behavior-irrelevant subspaces, each quantized with a
shared learnable codebook. We assess the behavioral relevance of each head by
quantifying the separability of VQ-AE encodings for behavior-aligned versus
behavior-violating responses using a binary classification metric. This yields
a behavioral relevance score that reflects each head discriminative capacity
with respect to the target behavior, guiding both selection and importance
weighting. Experiments on seven LLMs from two model families and five
behavioral steering datasets demonstrate that our method enables more accurate
inference-time interventions, achieving superior performance on the
truthfulness-steering task. Furthermore, the heads selected by our approach
exhibit strong zero-shot generalization in cross-domain truthfulness-steering
scenarios.

</details>


### [19] [CC-RAG: Structured Multi-Hop Reasoning via Theme-Based Causal Graphs](https://arxiv.org/abs/2506.08364)
*Jash Rajesh Parekh,Pengcheng Jiang,Jiawei Han*

Main category: cs.CL

TL;DR: 论文提出了一种名为Causal-Chain RAG (CC-RAG)的新方法，通过结合零样本三元组提取和主题感知图链，改进了标准RAG在因果推理中的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在理解因果关系时面临挑战，尤其是在需要深层推理的专业领域。标准RAG缺乏对因果依赖的结构化建模。

Method: CC-RAG通过构建有向无环图（DAG）表示因果三元组，并利用前向/后向链进行结构化推理。

Result: 在比特币价格波动和高雪氏病两个领域的实验中，CC-RAG在链相似性、信息密度和词汇多样性上优于标准RAG和零样本LLMs。

Conclusion: 显式建模因果结构使LLMs能够生成更准确和可解释的响应，尤其是在标准检索失败的专业领域。

Abstract: Understanding cause and effect relationships remains a formidable challenge
for Large Language Models (LLMs), particularly in specialized domains where
reasoning requires more than surface-level correlations. Retrieval-Augmented
Generation (RAG) improves factual accuracy, but standard RAG pipelines treat
evidence as flat context, lacking the structure required to model true causal
dependencies. We introduce Causal-Chain RAG (CC-RAG), a novel approach that
integrates zero-shot triple extraction and theme-aware graph chaining into the
RAG pipeline, enabling structured multi-hop inference. Given a domain specific
corpus, CC-RAG constructs a Directed Acyclic Graph (DAG) of <cause, relation,
effect> triples and uses forward/backward chaining to guide structured answer
generation. Experiments on two real-world domains: Bitcoin price fluctuations
and Gaucher disease, show that CC-RAG outperforms standard RAG and zero-shot
LLMs in chain similarity, information density, and lexical diversity. Both
LLM-as-a-Judge and human evaluations consistently favor CC-RAG. Our results
demonstrate that explicitly modeling causal structure enables LLMs to generate
more accurate and interpretable responses, especially in specialized domains
where flat retrieval fails.

</details>


### [20] [Mitigating Posterior Salience Attenuation in Long-Context LLMs with Positional Contrastive Decoding](https://arxiv.org/abs/2506.08371)
*Zikai Xiao,Ziyang Wang,Wen Ma,Yan Zhang,Wei Shen,Yan Wang,Luqi Gong,Zuozhu Liu*

Main category: cs.CL

TL;DR: 论文提出了一种无需训练的Positional Contrastive Decoding (PCD)方法，通过对比长文本和局部注意力生成的logits，缓解了大型语言模型在长上下文中的性能退化问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在长上下文窗口中存在性能退化问题，现有解决方案训练成本高昂，统计行为和成本效益方法未被充分探索。

Method: 提出PCD方法，通过对比长文本和局部注意力生成的logits，利用大规模短到长训练的优势。

Result: 实验表明，PCD在长上下文基准测试中达到最先进性能，有效缓解注意力分数退化。

Conclusion: PCD是一种无需训练的高效方法，显著提升了LLMs在长上下文中的表现。

Abstract: While Large Language Models (LLMs) support long contexts, they struggle with
performance degradation within the context window. Current solutions incur
prohibitive training costs, leaving statistical behaviors and cost-effective
approaches underexplored. From the decoding perspective, we identify the
Posterior Salience Attenuation (PSA) phenomenon, where the salience ratio
correlates with long-text performance degradation. Notably, despite the
attenuation, gold tokens still occupy high-ranking positions in the decoding
space. Motivated by it, we propose the training-free Positional Contrastive
Decoding (PCD) that contrasts the logits derived from long-aware attention with
those from designed local-aware attention, enabling the model to focus on the
gains introduced by large-scale short-to-long training. Through the analysis of
long-term decay simulation, we demonstrate that PCD effectively alleviates
attention score degradation. Experimental results show that PCD achieves
state-of-the-art performance on long-context benchmarks.

</details>


### [21] [Draft-based Approximate Inference for LLMs](https://arxiv.org/abs/2506.08373)
*Kevin Galim,Ethan Ewer,Wonjun Kang,Minjae Lee,Hyung Il Koo,Kangwook Lee*

Main category: cs.CL

TL;DR: 提出了一种利用小型草稿模型优化长上下文大语言模型（LLM）推理的新框架，包括SpecKV和SpecPC两种方法，显著提升了准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 由于Transformer的二次计算和线性内存复杂度，优化长上下文LLM推理变得重要。现有方法依赖粗略预测，准确性不足。

Method: 引入草稿模型预测token和KV对的重要性，提出SpecKV（优化KV缓存丢弃）和SpecPC（丢弃不重要提示token）。

Result: 实验表明，新方法在准确性上优于现有基线，同时保持内存、延迟和吞吐量的改进。

Conclusion: 草稿模型首次用于近似LLM推理加速，扩展了其用途，为高效推理提供了新思路。

Abstract: Optimizing inference for long-context Large Language Models (LLMs) is
increasingly important due to the quadratic compute and linear memory
complexity of Transformers. Existing approximation methods, such as key-value
(KV) cache dropping, sparse attention, and prompt compression, typically rely
on rough predictions of token or KV pair importance. We propose a novel
framework for approximate LLM inference that leverages small draft models to
more accurately predict the importance of tokens and KV pairs. Specifically, we
introduce two instantiations of our proposed framework: (i) SpecKV, which
leverages a draft output to accurately assess the importance of each KV pair
for more effective KV cache dropping, and (ii) SpecPC, which uses the draft
model's attention activations to identify and discard unimportant prompt
tokens. To the best of our knowledge, this is the first work to use draft
models for approximate LLM inference acceleration, extending their utility
beyond traditional lossless speculative decoding. We motivate our methods with
theoretical and empirical analyses, and show a strong correlation between the
attention patterns of draft and target models. Extensive experiments on
long-context benchmarks show that our methods consistently achieve higher
accuracy than existing baselines, while preserving the same improvements in
memory usage, latency, and throughput. Our code is available at
https://github.com/furiosa-ai/draft-based-approx-llm.

</details>


### [22] [EIFBENCH: Extremely Complex Instruction Following Benchmark for Large Language Models](https://arxiv.org/abs/2506.08375)
*Tao Zou,Xinghua Zhang,Haiyang Yu,Minzheng Wang,Fei Huang,Yongbin Li*

Main category: cs.CL

TL;DR: 论文提出了EIFBENCH基准和SegPO算法，用于评估和提升大语言模型在复杂多任务场景下的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准局限于单任务环境，无法反映真实场景的复杂性，需要更全面的评估工具。

Method: 设计了EIFBENCH基准，包含多任务场景和多种约束；提出了SegPO算法优化多任务执行能力。

Result: 评估显示现有大语言模型在复杂指令下表现差异显著，需进一步优化。

Conclusion: EIFBENCH和SegPO为复杂场景下的模型评估和优化提供了有效工具。

Abstract: With the development and widespread application of large language models
(LLMs), the new paradigm of "Model as Product" is rapidly evolving, and demands
higher capabilities to address complex user needs, often requiring precise
workflow execution which involves the accurate understanding of multiple tasks.
However, existing benchmarks focusing on single-task environments with limited
constraints lack the complexity required to fully reflect real-world scenarios.
To bridge this gap, we present the Extremely Complex Instruction Following
Benchmark (EIFBENCH), meticulously crafted to facilitate a more realistic and
robust evaluation of LLMs. EIFBENCH not only includes multi-task scenarios that
enable comprehensive assessment across diverse task types concurrently, but
also integrates a variety of constraints, replicating complex operational
environments. Furthermore, we propose the Segment Policy Optimization (SegPO)
algorithm to enhance the LLM's ability to accurately fulfill multi-task
workflow. Evaluations on EIFBENCH have unveiled considerable performance
discrepancies in existing LLMs when challenged with these extremely complex
instructions. This finding underscores the necessity for ongoing optimization
to navigate the intricate challenges posed by LLM applications.

</details>


### [23] [mSTEB: Massively Multilingual Evaluation of LLMs on Speech and Text Tasks](https://arxiv.org/abs/2506.08400)
*Luel Hagos Beyene,Vivek Verma,Min Ma,Jesujoba O. Alabi,Fabian David Schmidt,Joyce Nakatumba-Nabende,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: 论文介绍了mSTEB，一个用于评估LLMs在低资源语言上表现的新基准，覆盖多种任务和模态。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs评估主要集中于英语和高资源语言，缺乏对低资源语言的标准化评估。

Method: 引入mSTEB基准，评估LLMs在语言识别、文本分类、问答和翻译等任务上的表现，涵盖语音和文本模态。

Result: 评估显示高资源与低资源语言（尤其是非洲和美洲/大洋洲语言）之间存在显著性能差距。

Conclusion: 需要更多投资以解决低资源语言在LLMs中的代表性不足问题。

Abstract: Large Language models (LLMs) have demonstrated impressive performance on a
wide range of tasks, including in multimodal settings such as speech. However,
their evaluation is often limited to English and a few high-resource languages.
For low-resource languages, there is no standardized evaluation benchmark. In
this paper, we address this gap by introducing mSTEB, a new benchmark to
evaluate the performance of LLMs on a wide range of tasks covering language
identification, text classification, question answering, and translation tasks
on both speech and text modalities. We evaluated the performance of leading
LLMs such as Gemini 2.0 Flash and GPT-4o (Audio) and state-of-the-art open
models such as Qwen 2 Audio and Gemma 3 27B. Our evaluation shows a wide gap in
performance between high-resource and low-resource languages, especially for
languages spoken in Africa and Americas/Oceania. Our findings show that more
investment is needed to address their under-representation in LLMs coverage.

</details>


### [24] [TACTIC: Translation Agents with Cognitive-Theoretic Interactive Collaboration](https://arxiv.org/abs/2506.08403)
*Weiya Li,Junjie Chen,Bei Li,Boyang Liu,Zichen Wen,Nuanqiao Shan,Xiaoqian Liu,Anping Liu,Huajie Liu,Youyan Wang,Wujiuge Yin,Hu Song,Bing Huang,Zhiyuan Xia,Jialiang Chen,Linfeng Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种名为TACTIC的认知理论驱动的多智能体翻译框架，通过模拟人类翻译的认知过程，显著提升了机器翻译的质量。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在机器翻译中取得了进展，但现有多智能体框架忽视了认知翻译研究的关键见解，限制了翻译潜力的充分发挥。

Method: TACTIC框架包含六个功能不同的智能体，分别负责起草、精炼、评估、评分、上下文推理和外部知识收集，模拟人类翻译的认知过程。

Result: 实验结果表明，TACTIC在FLORES-200和WMT24基准测试中表现优异，超越了GPT-4.1和DeepSeek-R1等模型。

Conclusion: TACTIC通过理论驱动的多智能体协作，有效提升了大语言模型在翻译任务中的性能，为未来研究提供了新方向。

Abstract: Machine translation has long been a central task in natural language
processing. With the rapid advancement of large language models (LLMs), there
has been remarkable progress in translation quality. However, fully realizing
the translation potential of LLMs remains an open challenge. Recent studies
have explored multi-agent systems to decompose complex translation tasks into
collaborative subtasks, showing initial promise in enhancing translation
quality through agent cooperation and specialization. Nevertheless, existing
multi-agent translation frameworks largely neglect foundational insights from
cognitive translation studies. These insights emphasize how human translators
employ different cognitive strategies, such as balancing literal and free
translation, refining expressions based on context, and iteratively evaluating
outputs. To address this limitation, we propose a cognitively informed
multi-agent framework called TACTIC, which stands for T ranslation A gents with
Cognitive- T heoretic Interactive Collaboration. The framework comprises six
functionally distinct agents that mirror key cognitive processes observed in
human translation behavior. These include agents for drafting, refinement,
evaluation, scoring, context reasoning, and external knowledge gathering. By
simulating an interactive and theory-grounded translation workflow, TACTIC
effectively leverages the full capacity of LLMs for high-quality translation.
Experimental results on diverse language pairs from the FLORES-200 and WMT24
benchmarks show that our method consistently achieves state-of-the-art
performance. Using DeepSeek-V3 as the base model, TACTIC surpasses GPT-4.1 by
an average of +0.6 XCOMET and +1.18 COMETKIWI-23. Compared to DeepSeek-R1, it
further improves by +0.84 XCOMET and +2.99 COMETKIWI-23. Code is available at
https://github.com/weiyali126/TACTIC.

</details>


### [25] [Large Language Models Have Intrinsic Meta-Cognition, but Need a Good Lens](https://arxiv.org/abs/2506.08410)
*Ziyang Ma,Qingyue Yuan,Zhenglin Wang,Deyu Zhou*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）的元认知能力评估，提出了AutoMeco框架和MIRA策略，以改进现有评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLMs的认知错误检测能力，而对其元认知能力（如自我意识）的研究较少，这对LLMs的可靠性至关重要。

Method: 提出AutoMeco框架用于评估现有元认知指标，并提出MIRA策略（一种无需训练的马尔可夫内在奖励调整方法）以提升这些指标。

Result: 在三个数学推理数据集和三个LLMs上的实验表明，AutoMeco的合理性，且MIRA能更好地评估LLMs的元认知能力。

Conclusion: AutoMeco和MIRA为LLMs的元认知能力评估提供了有效工具，未来可进一步优化和应用。

Abstract: Previous research has primarily focused on the cognitive error detection
capabilities of Large Language Models (LLMs), often prompting them to analyze
mistakes in reasoning chains. However, few studies have examined the
meta-cognitive abilities of LLMs (e.g., their self-awareness of step errors),
which are crucial for their reliability. While studies on LLM self-evaluation
present some measures, such as perplexity, which can reflect the answer
correctness and be viewed as the lens of meta-cognition, they lack step-level
analysis and adaptation. This paper studies the evaluation of LLM
meta-cognition using the current lenses and how to improve these lenses.
Specifically, we propose AutoMeco, an Automated Meta-cognition Evaluation
framework for benchmarking the existing lenses. Furthermore, a training-free
Markovian Intrinsic Reward Adjustment strategy, MIRA, is proposed to boost
current meta-cognition lenses. Experimental results on three mathematical
reasoning datasets and three LLMs show the reasonableness of AutoMeco by
comparing it with Best-of-N verification. Moreover, the meta-cognition ability
of LLMs can be better evaluated using MIRA.

</details>


### [26] [Know-MRI: A Knowledge Mechanisms Revealer&Interpreter for Large Language Models](https://arxiv.org/abs/2506.08427)
*Jiaxiang Liu,Boxuan Xing,Chenhao Yuan,Chenxiang Zhang,Di Wu,Xiusheng Huang,Haida Yu,Chuhan Lang,Pengfei Cao,Jun Zhao,Kang Liu*

Main category: cs.CL

TL;DR: Know-MRI是一个开源工具，旨在系统分析大型语言模型（LLMs）的知识机制，通过可扩展核心模块自动匹配输入数据与解释方法，整合输出结果。


<details>
  <summary>Details</summary>
Motivation: 当前解释方法在输入数据格式和输出结果上存在差异，工具支持有限，限制了实际应用。

Method: 开发了可扩展核心模块，自动匹配输入数据与解释方法，整合输出。

Result: Know-MRI支持用户自由选择解释方法，从多角度全面诊断模型内部知识机制。

Conclusion: Know-MRI为LLMs知识机制的系统分析提供了实用工具，代码和演示视频已公开。

Abstract: As large language models (LLMs) continue to advance, there is a growing
urgency to enhance the interpretability of their internal knowledge mechanisms.
Consequently, many interpretation methods have emerged, aiming to unravel the
knowledge mechanisms of LLMs from various perspectives. However, current
interpretation methods differ in input data formats and interpreting outputs.
The tools integrating these methods are only capable of supporting tasks with
specific inputs, significantly constraining their practical applications. To
address these challenges, we present an open-source Knowledge Mechanisms
Revealer&Interpreter (Know-MRI) designed to analyze the knowledge mechanisms
within LLMs systematically. Specifically, we have developed an extensible core
module that can automatically match different input data with interpretation
methods and consolidate the interpreting outputs. It enables users to freely
choose appropriate interpretation methods based on the inputs, making it easier
to comprehensively diagnose the model's internal knowledge mechanisms from
multiple perspectives. Our code is available at
https://github.com/nlpkeg/Know-MRI. We also provide a demonstration video on
https://youtu.be/NVWZABJ43Bs.

</details>


### [27] [CAF-I: A Collaborative Multi-Agent Framework for Enhanced Irony Detection with Large Language Models](https://arxiv.org/abs/2506.08430)
*Ziqi. Liu,Ziyang. Zhou,Mingxuan. Hu*

Main category: cs.CL

TL;DR: 本文提出了一种名为CAF-I的多代理框架，用于解决现有大型语言模型在讽刺检测中的局限性，包括单视角限制、理解不足和缺乏可解释性。CAF-I通过多维分析和协作优化，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在讽刺检测中存在单视角限制、理解不足和缺乏可解释性等问题，需要一种更全面的方法。

Method: CAF-I采用多代理系统，包括上下文、语义和修辞代理进行多维分析，决策代理整合结果，并通过优化反馈提升性能。

Result: 在基准数据集上，CAF-I实现了零样本SOTA性能，平均Macro-F1达到76.31，比之前最佳基线提高了4.98。

Conclusion: CAF-I通过模拟人类多视角分析，显著提升了讽刺检测的准确性和可解释性。

Abstract: Large language model (LLM) have become mainstream methods in the field of
sarcasm detection. However, existing LLM methods face challenges in irony
detection, including: 1. single-perspective limitations, 2. insufficient
comprehensive understanding, and 3. lack of interpretability. This paper
introduces the Collaborative Agent Framework for Irony (CAF-I), an LLM-driven
multi-agent system designed to overcome these issues. CAF-I employs specialized
agents for Context, Semantics, and Rhetoric, which perform multidimensional
analysis and engage in interactive collaborative optimization. A Decision Agent
then consolidates these perspectives, with a Refinement Evaluator Agent
providing conditional feedback for optimization. Experiments on benchmark
datasets establish CAF-I's state-of-the-art zero-shot performance. Achieving
SOTA on the vast majority of metrics, CAF-I reaches an average Macro-F1 of
76.31, a 4.98 absolute improvement over the strongest prior baseline. This
success is attained by its effective simulation of human-like multi-perspective
analysis, enhancing detection accuracy and interpretability.

</details>


### [28] [Olica: Efficient Structured Pruning of Large Language Models without Retraining](https://arxiv.org/abs/2506.08436)
*Jiujun He,Huazhen Lin*

Main category: cs.CL

TL;DR: Olica是一种无需重新训练的结构化剪枝框架，通过正交分解和线性校准压缩LLMs，保持精度和结构。


<details>
  <summary>Details</summary>
Motivation: 现有LLM剪枝方法需要大量计算和数据资源重新训练，成本高昂。

Method: 利用PCA处理MHA层的矩阵乘积，快速分解降低复杂度；线性校准解决FFN层剪枝误差累积问题。

Result: Olica在数据使用、GPU内存和运行时间上高效，且在多个基准测试中表现优异。

Conclusion: Olica提供了一种高效、无需重新训练的LLM剪枝解决方案。

Abstract: Most existing structured pruning methods for Large Language Models (LLMs)
require substantial computational and data resources for retraining to
reestablish the corrupted correlations, making them prohibitively expensive. To
address this, we propose a pruning framework for LLMs called Orthogonal
decomposition and Linear Calibration (Olica), which eliminates the need for
retraining. A key observation is that the multi-head attention (MHA) layer
depends on two types of matrix products. By treating these matrix products as
unified entities and applying principal component analysis (PCA), we extract
the most important information to compress LLMs without sacrificing accuracy or
disrupting their original structure. Consequently, retraining becomes
unnecessary. A fast decomposition method is devised, reducing the complexity of
PCA by a factor of the square of the number of attention heads. Additionally,
to mitigate error accumulation problem caused by pruning the feed-forward
network (FFN) layer, we introduce a linear calibration method to reconstruct
the residual errors of pruned layers using low-rank matrices. By leveraging
singular value decomposition (SVD) on the solution of the least-squares
problem, these matrices are obtained without requiring retraining. Extensive
experiments show that the proposed Olica is efficient in terms of data usage,
GPU memory, and running time, while delivering superior performance across
multiple benchmarks.

</details>


### [29] [Detecting Harmful Memes with Decoupled Understanding and Guided CoT Reasoning](https://arxiv.org/abs/2506.08477)
*Fengjun Pan,Anh Tuan Luu,Xiaobao Wu*

Main category: cs.CL

TL;DR: 论文提出了一种名为U-CoT+的新框架，用于高效、灵活且可解释的有害表情包检测。


<details>
  <summary>Details</summary>
Motivation: 当前的有害表情包检测方法在资源效率、灵活性和可解释性方面存在不足，限制了其在实际内容审核系统中的部署。

Method: 通过开发高保真的表情包转文本管道，将视觉表情包转换为保留细节的文本描述，并结合人类制定的可解释指南，在零样本CoT提示下指导模型推理。

Result: 在七个基准数据集上的实验验证了该框架的有效性，展示了其在小规模LLMs上实现可解释和低资源有害表情包检测的潜力。

Conclusion: U-CoT+框架为有害表情包检测提供了一种高效、灵活且可解释的解决方案，适用于不同平台、地区和时间的检测标准。

Abstract: Detecting harmful memes is essential for maintaining the integrity of online
environments. However, current approaches often struggle with resource
efficiency, flexibility, or explainability, limiting their practical deployment
in content moderation systems. To address these challenges, we introduce
U-CoT+, a novel framework for harmful meme detection. Instead of relying solely
on prompting or fine-tuning multimodal models, we first develop a high-fidelity
meme-to-text pipeline that converts visual memes into detail-preserving textual
descriptions. This design decouples meme interpretation from meme
classification, thus avoiding immediate reasoning over complex raw visual
content and enabling resource-efficient harmful meme detection with general
large language models (LLMs). Building on these textual descriptions, we
further incorporate targeted, interpretable human-crafted guidelines to guide
models' reasoning under zero-shot CoT prompting. As such, this framework allows
for easy adaptation to different harmfulness detection criteria across
platforms, regions, and over time, offering high flexibility and
explainability. Extensive experiments on seven benchmark datasets validate the
effectiveness of our framework, highlighting its potential for explainable and
low-resource harmful meme detection using small-scale LLMs. Codes and data are
available at: https://anonymous.4open.science/r/HMC-AF2B/README.md.

</details>


### [30] [Efficient Context Selection for Long-Context QA: No Tuning, No Iteration, Just Adaptive-$k$](https://arxiv.org/abs/2506.08479)
*Chihiro Taguchi,Seiji Maekawa,Nikita Bhutani*

Main category: cs.CL

TL;DR: Adaptive-$k$ retrieval是一种单次通过的方法，根据查询与候选段落相似度分数的分布动态选择段落数量，无需模型微调或额外推理，显著提升了问答效率与准确性。


<details>
  <summary>Details</summary>
Motivation: 解决固定检索大小在开放域问答中可能导致资源浪费或关键证据遗漏的问题，特别是针对聚合问答中未知且可变的上下文需求。

Method: 提出Adaptive-$k$ retrieval方法，基于查询与候选段落相似度分数的分布动态选择段落数量，无需额外模型调整或推理。

Result: 在事实性和聚合问答基准测试中，Adaptive-$k$匹配或优于固定$k$基线，同时减少高达10倍的令牌使用，并保留70%的相关段落。

Conclusion: 动态调整上下文大小能显著提升问答系统的效率和准确性，适用于多种语言模型和嵌入模型。

Abstract: Retrieval-augmented generation (RAG) and long-context language models (LCLMs)
both address context limitations of LLMs in open-domain question answering
(QA). However, optimal external context to retrieve remains an open problem:
fixing the retrieval size risks either wasting tokens or omitting key evidence.
Existing adaptive methods like Self-RAG and Self-Route rely on iterative LLM
prompting and perform well on factoid QA, but struggle with aggregation QA,
where the optimal context size is both unknown and variable. We present
Adaptive-$k$ retrieval, a simple and effective single-pass method that
adaptively selects the number of passages based on the distribution of the
similarity scores between the query and the candidate passages. It does not
require model fine-tuning, extra LLM inferences or changes to existing
retriever-reader pipelines. On both factoid and aggregation QA benchmarks,
Adaptive-$k$ matches or outperforms fixed-$k$ baselines while using up to 10x
fewer tokens than full-context input, yet still retrieves 70% of relevant
passages. It improves accuracy across five LCLMs and two embedding models,
highlighting that dynamically adjusting context size leads to more efficient
and accurate QA.

</details>


### [31] [Re-Thinking the Automatic Evaluation of Image-Text Alignment in Text-to-Image Models](https://arxiv.org/abs/2506.08480)
*Huixuan Zhang,Xiaojun Wan*

Main category: cs.CL

TL;DR: 本文指出现有文本到图像生成评估框架的不足，提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要依赖人类判断，忽略了评估框架的其他关键特性。

Method: 识别可靠评估的两个关键方面，实证分析当前主流框架的不足。

Result: 当前评估框架未能全面满足关键特性。

Conclusion: 提出改进图像-文本对齐评估的建议。

Abstract: Text-to-image models often struggle to generate images that precisely match
textual prompts. Prior research has extensively studied the evaluation of
image-text alignment in text-to-image generation. However, existing evaluations
primarily focus on agreement with human assessments, neglecting other critical
properties of a trustworthy evaluation framework. In this work, we first
identify two key aspects that a reliable evaluation should address. We then
empirically demonstrate that current mainstream evaluation frameworks fail to
fully satisfy these properties across a diverse range of metrics and models.
Finally, we propose recommendations for improving image-text alignment
evaluation.

</details>


### [32] [Fairness is Not Silence: Unmasking Vacuous Neutrality in Small Language Models](https://arxiv.org/abs/2506.08487)
*Sumanth Manduru,Carlotta Domeniconi*

Main category: cs.CL

TL;DR: 该论文首次对参数规模在0.5至50亿之间的指令调优小型语言模型（SLMs）进行了大规模伦理风险审计，揭示了能力与公平性并非对立，并分析了不同架构的偏见差异及压缩技术的影响。


<details>
  <summary>Details</summary>
Motivation: 随着小型语言模型（SLMs）在资源受限设备上的快速应用，其伦理风险尚未被充分理解。论文旨在填补这一研究空白，为公平高效的SLM部署提供指导。

Method: 使用BBQ基准在零样本提示下评估了9个开源SLM模型（来自Qwen 2.5、LLaMA 3.2、Gemma 3和Phi系列），分析了其在模糊和明确上下文中的效用和公平性。

Result: 1. Phi模型在F1分数超过90%的同时表现出最小偏见；2. Qwen 2.5模型的公平性可能源于虚假中立或逃避行为，而LLaMA 3.2模型表现出更强的刻板偏见；3. 4位AWQ量化对性能有复杂影响。

Conclusion: 论文为资源受限环境中公平高效的SLM部署提供了实用指导，特别有助于小型企业和资源受限环境。

Abstract: The rapid adoption of Small Language Models (SLMs) for on-device and
resource-constrained deployments has outpaced our understanding of their
ethical risks. To the best of our knowledge, we present the first large-scale
audit of instruction-tuned SLMs spanning 0.5 to 5 billion parameters-an
overlooked "middle tier" between BERT-class encoders and flagship LLMs. Our
evaluation includes nine open-source models from the Qwen 2.5, LLaMA 3.2, Gemma
3, and Phi families. Using the BBQ benchmark under zero-shot prompting, we
analyze both utility and fairness across ambiguous and disambiguated contexts.
This evaluation reveals three key insights. First, competence and fairness need
not be antagonistic: Phi models achieve F1 scores exceeding 90 percent while
exhibiting minimal bias, showing that efficient and ethical NLP is attainable.
Second, social bias varies significantly by architecture: Qwen 2.5 models may
appear fair, but this often reflects vacuous neutrality, random guessing, or
evasive behavior rather than genuine ethical alignment. In contrast, LLaMA 3.2
models exhibit stronger stereotypical bias, suggesting overconfidence rather
than neutrality. Third, compression introduces nuanced trade-offs: 4-bit AWQ
quantization improves F1 scores in ambiguous settings for LLaMA 3.2-3B but
increases disability-related bias in Phi-4-Mini by over 7 percentage points.
These insights provide practical guidance for the responsible deployment of
SLMs in applications demanding fairness and efficiency, particularly benefiting
small enterprises and resource-constrained environments.

</details>


### [33] [EtiCor++: Towards Understanding Etiquettical Bias in LLMs](https://arxiv.org/abs/2506.08488)
*Ashutosh Dwivedi,Siddhant Shivdutt Singh,Ashutosh Modi*

Main category: cs.CL

TL;DR: 论文介绍了EtiCor++语料库，用于评估LLMs对不同地区礼仪的理解和偏见，并提出了相关任务和指标。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs的文化敏感性，尤其是对地区礼仪的理解和偏见，目前缺乏相关资源。

Method: 引入EtiCor++语料库，设计评估任务和偏见度量指标，进行广泛实验。

Result: 实验显示LLMs对某些地区存在固有偏见。

Conclusion: EtiCor++为评估LLMs的礼仪知识和偏见提供了有效工具。

Abstract: In recent years, researchers have started analyzing the cultural sensitivity
of LLMs. In this respect, Etiquettes have been an active area of research.
Etiquettes are region-specific and are an essential part of the culture of a
region; hence, it is imperative to make LLMs sensitive to etiquettes. However,
there needs to be more resources in evaluating LLMs for their understanding and
bias with regard to etiquettes. In this resource paper, we introduce EtiCor++,
a corpus of etiquettes worldwide. We introduce different tasks for evaluating
LLMs for knowledge about etiquettes across various regions. Further, we
introduce various metrics for measuring bias in LLMs. Extensive experimentation
with LLMs shows inherent bias towards certain regions.

</details>


### [34] [Integration of Old and New Knowledge for Generalized Intent Discovery: A Consistency-driven Prototype-Prompting Framework](https://arxiv.org/abs/2506.08490)
*Xiao Wei,Xiaobao Wang,Ning Zhuang,Chenyang Wang,Longbiao Wang,Jianwu dang*

Main category: cs.CL

TL;DR: 论文提出了一种一致性驱动的原型提示框架（GID），用于整合新旧知识，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注无监督数据聚类，忽视了领域适应问题，限制了实际应用。

Method: 提出原型提示框架和分层一致性约束，整合外部旧知识和目标领域新知识。

Result: 实验表明，该方法显著优于基线方法，达到最先进水平。

Conclusion: 该方法有效且泛化性强，代码已开源。

Abstract: Intent detection aims to identify user intents from natural language inputs,
where supervised methods rely heavily on labeled in-domain (IND) data and
struggle with out-of-domain (OOD) intents, limiting their practical
applicability. Generalized Intent Discovery (GID) addresses this by leveraging
unlabeled OOD data to discover new intents without additional annotation.
However, existing methods focus solely on clustering unsupervised data while
neglecting domain adaptation. Therefore, we propose a consistency-driven
prototype-prompting framework for GID from the perspective of integrating old
and new knowledge, which includes a prototype-prompting framework for
transferring old knowledge from external sources, and a hierarchical
consistency constraint for learning new knowledge from target domains. We
conducted extensive experiments and the results show that our method
significantly outperforms all baseline methods, achieving state-of-the-art
results, which strongly demonstrates the effectiveness and generalization of
our methods. Our source code is publicly available at
https://github.com/smileix/cpp.

</details>


### [35] [DRAGged into Conflicts: Detecting and Addressing Conflicting Sources in Search-Augmented LLMs](https://arxiv.org/abs/2506.08500)
*Arie Cattan,Alon Jacovi,Ori Ram,Jonathan Herzig,Roee Aharoni,Sasha Goldshtein,Eran Ofek,Idan Szpektor,Avi Caciularu*

Main category: cs.CL

TL;DR: 本文提出了RAG中知识冲突的分类法，并创建了CONFLICTS基准测试，发现LLMs在处理冲突时表现不佳，但通过明确推理可以改善。


<details>
  <summary>Details</summary>
Motivation: 解决RAG中检索信息冲突的问题，明确模型应如何处理不同类型的冲突。

Method: 提出知识冲突分类法，构建CONFLICTS基准测试，并通过实验验证LLMs的表现。

Result: LLMs在处理冲突时表现不佳，但通过提示模型显式推理可以显著提升响应质量。

Conclusion: 未来研究仍需改进LLMs处理知识冲突的能力，显式推理是一个有潜力的方向。

Abstract: Retrieval Augmented Generation (RAG) is a commonly used approach for
enhancing large language models (LLMs) with relevant and up-to-date
information. However, the retrieved sources can often contain conflicting
information and it remains unclear how models should address such
discrepancies. In this work, we first propose a novel taxonomy of knowledge
conflict types in RAG, along with the desired model behavior for each type. We
then introduce CONFLICTS, a high-quality benchmark with expert annotations of
conflict types in a realistic RAG setting. CONFLICTS is the first benchmark
that enables tracking progress on how models address a wide range of knowledge
conflicts. We conduct extensive experiments on this benchmark, showing that
LLMs often struggle to appropriately resolve conflicts between sources. While
prompting LLMs to explicitly reason about the potential conflict in the
retrieved documents significantly improves the quality and appropriateness of
their responses, substantial room for improvement in future research remains.

</details>


### [36] [CoMuMDR: Code-mixed Multi-modal Multi-domain corpus for Discourse paRsing in conversations](https://arxiv.org/abs/2506.08504)
*Divyaksh Shukla,Ritesh Baviskar,Dwijesh Gohil,Aniket Tiwari,Atul Shree,Ashutosh Modi*

Main category: cs.CL

TL;DR: 论文介绍了CoMuMDR语料库，用于多模态多领域代码混合（印地语和英语）对话的话语解析，并展示了现有模型的性能不足。


<details>
  <summary>Details</summary>
Motivation: 当前的话语解析数据集局限于单一领域的书面英语对话，难以满足多模态和多领域的需求。

Method: 构建了包含音频和文本的多模态代码混合语料库，标注了九种话语关系，并测试了多种现有模型。

Result: 现有模型在多领域代码混合语料上表现不佳，凸显了开发更强大模型的必要性。

Conclusion: CoMuMDR语料库为多模态多领域代码混合对话的话语解析提供了新资源，并揭示了当前模型的局限性。

Abstract: Discourse parsing is an important task useful for NLU applications such as
summarization, machine comprehension, and emotion recognition. The current
discourse parsing datasets based on conversations consists of written English
dialogues restricted to a single domain. In this resource paper, we introduce
CoMuMDR: Code-mixed Multi-modal Multi-domain corpus for Discourse paRsing in
conversations. The corpus (code-mixed in Hindi and English) has both audio and
transcribed text and is annotated with nine discourse relations. We experiment
with various SoTA baseline models; the poor performance of SoTA models
highlights the challenges of multi-domain code-mixed corpus, pointing towards
the need for developing better models for such realistic settings.

</details>


### [37] [Efficient Post-Training Refinement of Latent Reasoning in Large Language Models](https://arxiv.org/abs/2506.08552)
*Xinyuan Wang,Dongjie Wang,Wangyang Ying,Haoyue Bai,Nanxu Gong,Sixun Dong,Kunpeng Liu,Yanjie Fu*

Main category: cs.CL

TL;DR: 论文提出了一种轻量级后训练框架，通过对比推理反馈和残差嵌入细化策略，优化潜在推理轨迹，显著提升了模型在推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有推理方法（如Chain-of-Thought）存在显式输出开销和固定推理路径的问题，而潜在推理虽能避免这些问题，但缺乏有效的后训练更新机制。

Method: 提出两种策略：1）对比推理反馈，通过比较强/弱基线优化嵌入方向；2）残差嵌入细化，通过历史梯度逐步稳定更新。

Result: 在五个推理基准测试中验证了框架的有效性，MathQA任务上实现了5%的准确率提升。

Conclusion: 该框架为潜在推理的后训练优化提供了高效且可控的解决方案。

Abstract: Reasoning is a key component of language understanding in Large Language
Models. While Chain-of-Thought prompting enhances performance via explicit
intermediate steps, it suffers from sufficient token overhead and a fixed
reasoning trajectory, preventing step-wise refinement. Recent advances in
latent reasoning address these limitations by refining internal reasoning
processes directly in the model's latent space, without producing explicit
outputs. However, a key challenge remains: how to effectively update reasoning
embeddings during post-training to guide the model toward more accurate
solutions. To overcome this challenge, we propose a lightweight post-training
framework that refines latent reasoning trajectories using two novel
strategies: 1) Contrastive reasoning feedback, which compares reasoning
embeddings against strong and weak baselines to infer effective update
directions via embedding enhancement; 2) Residual embedding refinement, which
stabilizes updates by progressively integrating current and historical
gradients, enabling fast yet controlled convergence. Extensive experiments and
case studies are conducted on five reasoning benchmarks to demonstrate the
effectiveness of the proposed framework. Notably, a 5\% accuracy gain on MathQA
without additional training.

</details>


### [38] [Neighbors and relatives: How do speech embeddings reflect linguistic connections across the world?](https://arxiv.org/abs/2506.08564)
*Tuukka Törö,Antti Suni,Juraj Šimko*

Main category: cs.CL

TL;DR: 该研究利用机器学习方法分析语音嵌入，探索106种语言之间的关系，发现与传统方法结果一致，并展示了大规模语言分析的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统语言关系分析方法依赖专家劳动，机器学习提供了大规模、数据驱动的替代方案，以更高效地研究语言多样性。

Method: 使用XLS-R自监督模型生成语音嵌入，通过线性判别分析（LDA）聚类，并与谱系、词汇和地理距离进行比较。

Result: 嵌入距离与传统方法结果高度一致，能有效捕捉全局和局部语言模式，但可视化动态语言关系仍具挑战。

Conclusion: 语音嵌入为语言关系研究提供了新视角，未来可扩展至低资源语言，并结合社会语言学因素以更全面理解语言多样性。

Abstract: Investigating linguistic relationships on a global scale requires analyzing
diverse features such as syntax, phonology and prosody, which evolve at varying
rates influenced by internal diversification, language contact, and
sociolinguistic factors. Recent advances in machine learning (ML) offer
complementary alternatives to traditional historical and typological
approaches. Instead of relying on expert labor in analyzing specific linguistic
features, these new methods enable the exploration of linguistic variation
through embeddings derived directly from speech, opening new avenues for
large-scale, data-driven analyses.
  This study employs embeddings from the fine-tuned XLS-R self-supervised
language identification model voxlingua107-xls-r-300m-wav2vec, to analyze
relationships between 106 world languages based on speech recordings. Using
linear discriminant analysis (LDA), language embeddings are clustered and
compared with genealogical, lexical, and geographical distances. The results
demonstrate that embedding-based distances align closely with traditional
measures, effectively capturing both global and local typological patterns.
Challenges in visualizing relationships, particularly with hierarchical
clustering and network-based methods, highlight the dynamic nature of language
change.
  The findings show potential for scalable analyses of language variation based
on speech embeddings, providing new perspectives on relationships among
languages. By addressing methodological considerations such as corpus size and
latent space dimensionality, this approach opens avenues for studying
low-resource languages and bridging macro- and micro-level linguistic
variation. Future work aims to extend these methods to underrepresented
languages and integrate sociolinguistic variation for a more comprehensive
understanding of linguistic diversity.

</details>


### [39] [CounselBench: A Large-Scale Expert Evaluation and Adversarial Benchmark of Large Language Models in Mental Health Counseling](https://arxiv.org/abs/2506.08584)
*Yahan Li,Jifan Yao,John Bosco S. Bunyi,Adam C. Frank,Angel Hwang,Ruishan Liu*

Main category: cs.CL

TL;DR: CounselBench是一个用于评估大型语言模型（LLMs）在心理健康咨询场景中的表现的基准测试，发现LLMs在质量上常优于人类治疗师，但存在安全隐患。


<details>
  <summary>Details</summary>
Motivation: 测试LLMs在真实心理健康咨询场景中的行为，填补现有研究的空白。

Method: 开发CounselBench基准测试，包含专家评估和对抗性数据集，对LLMs进行多维度评估。

Result: LLMs在质量上表现优异，但常被专家标记安全隐患；LLM评委易高估模型表现。

Conclusion: CounselBench为高风险的LLM心理健康应用提供了临床基准框架。

Abstract: Large language models (LLMs) are increasingly proposed for use in mental
health support, yet their behavior in realistic counseling scenarios remains
largely untested. We introduce CounselBench, a large-scale benchmark developed
with 100 mental health professionals to evaluate and stress-test LLMs in
single-turn counseling. The first component, CounselBench-EVAL, contains 2,000
expert evaluations of responses from GPT-4, LLaMA 3, Gemini, and online human
therapists to real patient questions. Each response is rated along six
clinically grounded dimensions, with written rationales and span-level
annotations. We find that LLMs often outperform online human therapists in
perceived quality, but experts frequently flag their outputs for safety
concerns such as unauthorized medical advice. Follow-up experiments show that
LLM judges consistently overrate model responses and overlook safety issues
identified by human experts. To probe failure modes more directly, we construct
CounselBench-Adv, an adversarial dataset of 120 expert-authored counseling
questions designed to trigger specific model issues. Evaluation across 2,880
responses from eight LLMs reveals consistent, model-specific failure patterns.
Together, CounselBench establishes a clinically grounded framework for
benchmarking and improving LLM behavior in high-stakes mental health settings.

</details>


### [40] [Dense Retrievers Can Fail on Simple Queries: Revealing The Granularity Dilemma of Embeddings](https://arxiv.org/abs/2506.08592)
*Liyan Xu,Zhenlin Su,Mo Yu,Jiangnan Li,Fandong Meng,Jie Zhou*

Main category: cs.CL

TL;DR: 本文研究了文本编码器在细粒度实体或事件识别上的局限性，提出了中文评估数据集CapRetrieval，并通过数据生成策略优化编码器性能。


<details>
  <summary>Details</summary>
Motivation: 现有文本编码器在细粒度语义匹配上表现不佳，导致密集检索失败。

Method: 引入CapRetrieval数据集，提出数据生成策略优化编码器。

Result: 优化后的编码器在CapRetrieval上表现最佳，但发现粒度困境问题。

Conclusion: 公开数据集和模型，强调细粒度语义对齐的挑战。

Abstract: This work focuses on an observed limitation of text encoders: embeddings may
not be able to recognize fine-grained entities or events within the semantics,
resulting in failed dense retrieval on even simple cases. To examine such
behaviors, we first introduce a new evaluation dataset in Chinese, named
CapRetrieval, whose passages are image captions, and queries are phrases
inquiring entities or events in various forms. Zero-shot evaluation suggests
that encoders may fail on these fine-grained matching, regardless of training
sources or model sizes. Aiming for enhancement, we proceed to finetune encoders
with our proposed data generation strategies, which obtains the best
performance on CapRetrieval. Within this process, we further identify an issue
of granularity dilemma, a challenge for embeddings to express fine-grained
salience while aligning with overall semantics. Our dataset, code and models in
this work are publicly released at https://github.com/lxucs/CapRetrieval.

</details>


### [41] [Hateful Person or Hateful Model? Investigating the Role of Personas in Hate Speech Detection by Large Language Models](https://arxiv.org/abs/2506.08593)
*Shuzhou Yuan,Ercong Nie,Mario Tawfelis,Helmut Schmid,Hinrich Schütze,Michael Färber*

Main category: cs.CL

TL;DR: 本文研究了MBTI人格特质对大型语言模型（LLMs）在仇恨言论检测中的影响，发现人格提示会导致模型输出显著差异，并提出了对公平性和人类价值观对齐的启示。


<details>
  <summary>Details</summary>
Motivation: 仇恨言论检测具有社会敏感性和主观性，但人格特质对LLMs的影响尚未充分研究。本文旨在填补这一空白。

Method: 通过人类标注调查验证MBTI特质对标注行为的影响，并在四个开源LLMs中应用MBTI人格提示，评估其在三个仇恨言论数据集上的表现。

Result: 研究发现人格提示导致模型输出显著差异，包括与真实标签的不一致、人格间分歧和逻辑层面的偏见。

Conclusion: 研究强调了在LLM标注流程中谨慎定义人格提示的重要性，以确保公平性和与人类价值观的一致性。

Abstract: Hate speech detection is a socially sensitive and inherently subjective task,
with judgments often varying based on personal traits. While prior work has
examined how socio-demographic factors influence annotation, the impact of
personality traits on Large Language Models (LLMs) remains largely unexplored.
In this paper, we present the first comprehensive study on the role of persona
prompts in hate speech classification, focusing on MBTI-based traits. A human
annotation survey confirms that MBTI dimensions significantly affect labeling
behavior. Extending this to LLMs, we prompt four open-source models with MBTI
personas and evaluate their outputs across three hate speech datasets. Our
analysis uncovers substantial persona-driven variation, including
inconsistencies with ground truth, inter-persona disagreement, and logit-level
biases. These findings highlight the need to carefully define persona prompts
in LLM-based annotation workflows, with implications for fairness and alignment
with human values.

</details>


### [42] [RAISE: Enhancing Scientific Reasoning in LLMs via Step-by-Step Retrieval](https://arxiv.org/abs/2506.08625)
*Minhae Oh,Jeonghye Kim,Nakyung Lee,Donggeon Seo,Taeuk Kim,Jungwoo Lee*

Main category: cs.CL

TL;DR: RAISE是一个逐步检索增强框架，通过问题分解、逻辑查询生成和逻辑检索三个步骤，显著优于其他基线方法。


<details>
  <summary>Details</summary>
Motivation: 科学推理需要长链推理过程、领域术语知识以及对新发现的适应能力，RAISE旨在应对这些挑战。

Method: RAISE分为三个步骤：问题分解、逻辑查询生成和逻辑检索，从开放语料库中检索逻辑相关的文档。

Result: RAISE在科学推理基准测试中表现优于其他基线方法，能够检索到逻辑更相关的文档。

Conclusion: RAISE通过逻辑相关性检索，显著提升了科学推理的效果。

Abstract: Scientific reasoning requires not only long-chain reasoning processes, but
also knowledge of domain-specific terminologies and adaptation to updated
findings. To deal with these challenges for scientific reasoning, we introduce
RAISE, a step-by-step retrieval-augmented framework which retrieves logically
relevant documents from in-the-wild corpus. RAISE is divided into three steps:
problem decomposition, logical query generation, and logical retrieval. We
observe that RAISE consistently outperforms other baselines on scientific
reasoning benchmarks. We analyze that unlike other baselines, RAISE retrieves
documents that are not only similar in terms of the domain knowledge, but also
documents logically more relevant.

</details>


### [43] [MEMETRON: Metaheuristic Mechanisms for Test-time Response Optimization of Large Language Models](https://arxiv.org/abs/2506.08643)
*Son The Nguyen,Theja Tulabandhula*

Main category: cs.CL

TL;DR: MEMETRON是一个任务无关的框架，将LLM解码视为离散黑盒优化问题，通过混合元启发式算法和奖励模型高效发现高奖励响应，无需模型重训练。


<details>
  <summary>Details</summary>
Motivation: 现有LLM解码方法（如贪婪搜索、采样或重排序）缺乏对任务目标的显式优化，限制了控制能力。

Method: MEMETRON利用GENETRON和ANNETRON两种混合元启发式算法，结合奖励模型和LLM的上下文操作，搜索响应空间。

Result: 在人类偏好对齐任务中，MEMETRON显著优于标准解码和重排序方法。

Conclusion: MEMETRON展示了在不重训练模型的情况下提升对齐效果的潜力，具有模块化和通用性。

Abstract: Large language models (LLMs) are increasingly used for both open-ended and
structured tasks, yet their inference-time behavior is still largely dictated
by heuristic decoding strategies such as greedy search, sampling, or reranking.
These methods provide limited control and do not explicitly optimize for
task-specific objectives. We introduce MEMETRON, a task-agnostic framework that
formulates LLM decoding as a discrete black-box optimization problem. MEMETRON
leverages hybrid metaheuristic algorithms, GENETRON and ANNETRON, to search the
response space, guided by reward models and contextual operations performed by
the LLM itself. This approach enables efficient discovery of high-reward
responses without requiring model retraining or gradient access. The framework
is modular and generalizes across diverse tasks, requiring only a reward
function and lightweight prompt templates. We evaluate our framework on the
critical human preference alignment task and demonstrate that it significantly
outperforms standard decoding and reranking methods, highlighting its potential
to improve alignment without model retraining.

</details>


### [44] [TableDreamer: Progressive and Weakness-guided Data Synthesis from Scratch for Table Instruction Tuning](https://arxiv.org/abs/2506.08646)
*Mingyu Zheng,Zhifan Feng,Jia Wang,Lanrui Wang,Zheng Lin,Yang Hao,Weiping Wang*

Main category: cs.CL

TL;DR: TableDreamer是一个渐进式、弱点引导的数据合成框架，用于解决LLM在表格指令调优中数据多样性和效率不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM数据合成方法在生成表格指令调优数据时存在两个问题：输入空间探索不足导致数据多样性有限，以及忽视目标LLM的弱点而盲目增加数据量。

Method: TableDreamer首先生成多样化的种子数据，然后根据新识别的弱点数据迭代探索输入空间，最终生成用于微调目标LLM的训练数据。

Result: 在10个表格基准测试中，TableDreamer将Llama3.1-8B-instruct的平均准确率提高了11.62%（49.07%至60.69%），优于使用更多训练数据的现有方法。

Conclusion: TableDreamer通过渐进式弱点引导的数据合成，显著提升了表格指令调优的效果，且数据效率更高。

Abstract: Despite the commendable progress of recent LLM-based data synthesis methods,
they face two limitations in generating table instruction tuning data. First,
they can not thoroughly explore the vast input space of table understanding
tasks, leading to limited data diversity. Second, they ignore the weaknesses in
table understanding ability of the target LLM and blindly pursue the increase
of data quantity, resulting in suboptimal data efficiency. In this paper, we
introduce a progressive and weakness-guided data synthesis framework tailored
for table instruction tuning, named TableDreamer, to mitigate the above issues.
Specifically, we first synthesize diverse tables and related instructions as
seed data, and then perform an iterative exploration of the input space under
the guidance of the newly identified weakness data, which eventually serve as
the final training data for fine-tuning the target LLM. Extensive experiments
on 10 tabular benchmarks demonstrate the effectiveness of the proposed
framework, which boosts the average accuracy of Llama3.1-8B-instruct by 11.62%
(49.07% to 60.69%) with 27K GPT-4o synthetic data and outperforms
state-of-the-art data synthesis baselines which use more training data. The
code and data is available at https://github.com/SpursGoZmy/TableDreamer

</details>


### [45] [Summarization for Generative Relation Extraction in the Microbiome Domain](https://arxiv.org/abs/2506.08647)
*Oumaima El Khettari,Solen Quiniou,Samuel Chaffron*

Main category: cs.CL

TL;DR: 生成式关系提取方法在肠道微生物组研究中表现潜力，但BERT方法仍占优。


<details>
  <summary>Details</summary>
Motivation: 研究肠道微生物组这一复杂且资源匮乏的生物医学领域中的交互关系。

Method: 利用大型语言模型（LLMs）进行摘要生成以优化上下文，再通过指令调整生成关系。

Result: 摘要生成能减少噪声并引导模型，但BERT方法仍优于生成式模型。

Conclusion: 生成式方法在低资源专业领域研究中具有潜力，但需进一步改进。

Abstract: We explore a generative relation extraction (RE) pipeline tailored to the
study of interactions in the intestinal microbiome, a complex and low-resource
biomedical domain. Our method leverages summarization with large language
models (LLMs) to refine context before extracting relations via
instruction-tuned generation. Preliminary results on a dedicated corpus show
that summarization improves generative RE performance by reducing noise and
guiding the model. However, BERT-based RE approaches still outperform
generative models. This ongoing work demonstrates the potential of generative
methods to support the study of specialized domains in low-resources setting.

</details>


### [46] [RuleReasoner: Reinforced Rule-based Reasoning via Domain-aware Dynamic Sampling](https://arxiv.org/abs/2506.08672)
*Yang Liu,Jiaqi Li,Zilong Zheng*

Main category: cs.CL

TL;DR: RuleReasoner是一种通过强化学习增强的小型推理模型，能够有效处理多样化任务和领域的规则推理问题。


<details>
  <summary>Details</summary>
Motivation: 解决小型推理模型（SRMs）在多样化任务和领域中规则推理的泛化能力问题。

Method: 提出RuleReasoner方法，结合动态采样和强化学习，无需预定义训练配方。

Result: 在ID和OOD任务中显著优于前沿大型推理模型（LRMs），且计算效率更高。

Conclusion: RuleReasoner展示了小型模型在规则推理中的潜力，具有高效性和泛化能力。

Abstract: Rule-based reasoning has been acknowledged as one of the fundamental problems
in reasoning, while deviations in rule formats, types, and complexity in
real-world applications pose severe challenges. Recent studies have shown that
large reasoning models (LRMs) have remarkable reasoning capabilities, and their
performance is substantially enhanced by reinforcement learning (RL). However,
it remains an open question whether small reasoning models (SRMs) can learn
rule-based reasoning effectively with robust generalization across diverse
tasks and domains. To address this, we introduce Reinforced Rule-based
Reasoning, a.k.a. RuleReasoner, a simple yet effective method to conduct
rule-based reasoning via a wide collection of curated tasks and a novel
domain-aware dynamic sampling approach. Specifically, RuleReasoner resamples
each training batch by updating the sampling weights of different domains based
on historical rewards. This facilitates domain augmentation and flexible online
learning schedules for RL, obviating the need for pre-hoc human-engineered
mix-training recipes used in existing methods. Empirical evaluations on
in-distribution (ID) and out-of-distribution (OOD) benchmarks reveal that
RuleReasoner outperforms frontier LRMs by a significant margin ($\Delta$4.1%
average points on eight ID tasks and $\Delta$10.4% average points on three OOD
tasks over OpenAI-o1). Notably, our approach also exhibits higher computational
efficiency compared to prior dynamic sampling methods for RL.

</details>


### [47] [Brevity is the soul of sustainability: Characterizing LLM response lengths](https://arxiv.org/abs/2506.08686)
*Soham Poddar,Paramita Koley,Janardan Misra,Sanjay Podder,Navveen Balani,Niloy Ganguly,Saptarshi Ghosh*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型（LLMs）推理过程中的能源消耗问题，提出通过输出压缩和提示工程策略减少响应长度，从而实现25-60%的能源优化。


<details>
  <summary>Details</summary>
Motivation: LLMs推理过程消耗大量能源，而输出压缩领域研究较少，因此探索高效方法至关重要。

Method: 首先对12个解码器LLMs在5个数据集上进行了基准测试，定义了LLM响应中的六类信息，并提出提示工程策略以减少冗余信息。

Result: 实验表明，通过优化提示策略，可以在保持响应质量的同时减少25-60%的能源消耗。

Conclusion: 提示工程是减少LLMs能源消耗的有效方法，未来可进一步探索其他优化策略。

Abstract: A significant portion of the energy consumed by Large Language Models (LLMs)
arises from their inference processes; hence developing energy-efficient
methods for inference is crucial. While several techniques exist for inference
optimization, output compression remains relatively unexplored, with only a few
preliminary efforts addressing this aspect. In this work, we first benchmark 12
decoder-only LLMs across 5 datasets, revealing that these models often produce
responses that are substantially longer than necessary. We then conduct a
comprehensive quality assessment of LLM responses, formally defining six
information categories present in LLM responses. We show that LLMs often tend
to include redundant or additional information besides the minimal answer. To
address this issue of long responses by LLMs, we explore several simple and
intuitive prompt-engineering strategies. Empirical evaluation shows that
appropriate prompts targeting length reduction and controlling information
content can achieve significant energy optimization between 25-60\% by reducing
the response length while preserving the quality of LLM responses.

</details>


### [48] [ClimateViz: A Benchmark for Statistical Reasoning and Fact Verification on Scientific Charts](https://arxiv.org/abs/2506.08700)
*Ruiran Su,Jiasheng Si,Zhijiang Guo,Janet B. Pierrehumbert*

Main category: cs.CL

TL;DR: ClimateViz是一个首个大规模的科学图表事实核查基准，包含49,862个与2,896个图表相关的声明，标注为支持、反驳或信息不足。现有多模态模型在图表推理上表现不佳，最佳模型准确率仅76.2%-77.8%，远低于人类水平（89.3%-92.7%）。


<details>
  <summary>Details</summary>
Motivation: 科学事实核查主要关注文本和表格，忽略了科学图表的重要性。ClimateViz填补了这一空白，为图表事实核查提供了首个大规模基准。

Method: 构建了包含49,862个声明和2,896个图表的ClimateViz数据集，每个声明标注为支持、反驳或信息不足，并附有结构化知识图谱解释。评估了多模态语言模型在零样本和少样本设置下的表现。

Result: 现有模型在图表推理上表现不佳，最佳模型准确率仅76.2%-77.8%，远低于人类水平（89.3%-92.7%）。部分模型通过解释增强输出有所提升。

Conclusion: ClimateViz为科学图表事实核查提供了重要资源，但现有模型仍需改进。数据集和代码已公开。

Abstract: Scientific fact-checking has mostly focused on text and tables, overlooking
scientific charts, which are key for presenting quantitative evidence and
statistical reasoning. We introduce ClimateViz, the first large-scale benchmark
for scientific fact-checking using expert-curated scientific charts. ClimateViz
contains 49,862 claims linked to 2,896 visualizations, each labeled as support,
refute, or not enough information. To improve interpretability, each example
includes structured knowledge graph explanations covering trends, comparisons,
and causal relations. We evaluate state-of-the-art multimodal language models,
including both proprietary and open-source systems, in zero-shot and few-shot
settings. Results show that current models struggle with chart-based reasoning:
even the best systems, such as Gemini 2.5 and InternVL 2.5, reach only 76.2 to
77.8 percent accuracy in label-only settings, far below human performance (89.3
and 92.7 percent). Explanation-augmented outputs improve performance in some
models. We released our dataset and code alongside the paper.

</details>


### [49] [ConfPO: Exploiting Policy Model Confidence for Critical Token Selection in Large Language Model Preference Optimization](https://arxiv.org/abs/2506.08712)
*Hee Suk Yoon,Eunseop Yoon,Mark A. Hasegawa-Johnson,Sungwoong Kim,Chang D. Yoo*

Main category: cs.CL

TL;DR: ConfPO是一种专注于优化偏好关键标记的偏好学习方法，无需额外模型或计算资源，通过更高效地利用KL散度预算提升对齐质量。


<details>
  <summary>Details</summary>
Motivation: 现有直接对齐算法（如DPO）对所有标记进行均匀调整，而ConfPO旨在通过优化关键标记提升效率并避免过优化。

Method: ConfPO基于训练策略的置信度识别并优化偏好关键标记，无需辅助模型或额外计算。

Result: 实验表明，ConfPO在AlpacaEval 2和Arena-Hard等基准测试中优于均匀调整的算法，且无额外计算开销。

Conclusion: ConfPO是一种简单、轻量且高效的对齐方法，显著提升了LLMs的偏好学习效果。

Abstract: We introduce ConfPO, a method for preference learning in Large Language
Models (LLMs) that identifies and optimizes preference-critical tokens based
solely on the training policy's confidence, without requiring any auxiliary
models or compute. Unlike prior Direct Alignment Algorithms (DAAs) such as
Direct Preference Optimization (DPO), which uniformly adjust all token
probabilities regardless of their relevance to preference, ConfPO focuses
optimization on the most impactful tokens. This targeted approach improves
alignment quality while mitigating overoptimization (i.e., reward hacking) by
using the KL divergence budget more efficiently. In contrast to recent
token-level methods that rely on credit-assignment models or AI annotators,
raising concerns about scalability and reliability, ConfPO is simple,
lightweight, and model-free. Experimental results on challenging alignment
benchmarks, including AlpacaEval 2 and Arena-Hard, demonstrate that ConfPO
consistently outperforms uniform DAAs across various LLMs, delivering better
alignment with zero additional computational overhead.

</details>


### [50] [Explainable Compliance Detection with Multi-Hop Natural Language Inference on Assurance Case Structure](https://arxiv.org/abs/2506.08713)
*Fariz Ikhwantri,Dusica Marijan*

Main category: cs.CL

TL;DR: 提出了一种基于自然语言推理（NLI）的合规检测方法EXCLAIM，用于自动化监管合规过程，并通过生成保证案例解决数据不足问题。


<details>
  <summary>Details</summary>
Motivation: 复杂系统合规性检查面临法律和技术文本复杂、模型解释需求高以及保证案例数据有限等挑战。

Method: 将保证案例的声明-论据-证据结构建模为多跳推理，利用大语言模型生成保证案例，并设计覆盖率和结构一致性指标。

Result: 通过GDPR要求的多跳推理任务验证了生成保证案例的有效性。

Conclusion: NLI方法在自动化监管合规过程中具有潜力。

Abstract: Ensuring complex systems meet regulations typically requires checking the
validity of assurance cases through a claim-argument-evidence framework. Some
challenges in this process include the complicated nature of legal and
technical texts, the need for model explanations, and limited access to
assurance case data. We propose a compliance detection approach based on
Natural Language Inference (NLI): EXplainable CompLiance detection with
Argumentative Inference of Multi-hop reasoning (EXCLAIM). We formulate the
claim-argument-evidence structure of an assurance case as a multi-hop inference
for explainable and traceable compliance detection. We address the limited
number of assurance cases by generating them using large language models
(LLMs). We introduce metrics that measure the coverage and structural
consistency. We demonstrate the effectiveness of the generated assurance case
from GDPR requirements in a multi-hop inference task as a case study. Our
results highlight the potential of NLI-based approaches in automating the
regulatory compliance process.

</details>


### [51] [Multi-Teacher Language-Aware Knowledge Distillation for Multilingual Speech Emotion Recognition](https://arxiv.org/abs/2506.08717)
*Mehedi Hasan Bijoy,Dejan Porjazovski,Tamás Grósz,Mikko Kurimo*

Main category: cs.CL

TL;DR: 提出了一种基于多教师知识蒸馏的多语言语音情感识别方法，显著提升了英语、芬兰语和法语的情感识别性能。


<details>
  <summary>Details</summary>
Motivation: 尽管单语言语音情感识别取得进展，但构建多语言系统仍具挑战性。目标是训练一个统一的多语言模型。

Method: 使用Wav2Vec2.0作为单语言教师模型基础，通过语言感知的多教师知识蒸馏方法训练多语言学生模型。

Result: 学生模型表现优异，英语加权召回率72.9，芬兰语未加权召回率63.4，优于基线方法。

Conclusion: 方法在识别悲伤和中性情绪上表现突出，但在愤怒和快乐情绪识别上仍有改进空间。

Abstract: Speech Emotion Recognition (SER) is crucial for improving human-computer
interaction. Despite strides in monolingual SER, extending them to build a
multilingual system remains challenging. Our goal is to train a single model
capable of multilingual SER by distilling knowledge from multiple teacher
models. To address this, we introduce a novel language-aware multi-teacher
knowledge distillation method to advance SER in English, Finnish, and French.
It leverages Wav2Vec2.0 as the foundation of monolingual teacher models and
then distills their knowledge into a single multilingual student model. The
student model demonstrates state-of-the-art performance, with a weighted recall
of 72.9 on the English dataset and an unweighted recall of 63.4 on the Finnish
dataset, surpassing fine-tuning and knowledge distillation baselines. Our
method excels in improving recall for sad and neutral emotions, although it
still faces challenges in recognizing anger and happiness.

</details>


### [52] [Improved LLM Agents for Financial Document Question Answering](https://arxiv.org/abs/2506.08726)
*Nelvin Tan,Zian Seng,Liang Zhang,Yu-Ching Shih,Dong Yang,Amol Salunkhe*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型（LLMs）在金融文档数值问答任务中的表现，发现传统批评代理在无标注数据时性能下降，并提出改进的批评代理和计算器代理，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: LLMs在金融文档的数值问答任务中表现不佳，尤其是缺乏标注数据时，传统批评代理性能下降，需要改进。

Method: 提出改进的批评代理和计算器代理，并通过实验验证其性能。

Result: 改进的代理优于现有方法（程序化思维），且更安全。同时研究了代理间的交互对性能的影响。

Conclusion: 改进的批评代理和计算器代理在无标注数据时表现更优，为LLMs在金融领域的应用提供了新思路。

Abstract: Large language models (LLMs) have shown impressive capabilities on numerous
natural language processing tasks. However, LLMs still struggle with numerical
question answering for financial documents that include tabular and textual
data. Recent works have showed the effectiveness of critic agents (i.e.,
self-correction) for this task given oracle labels. Building upon this
framework, this paper examines the effectiveness of the traditional critic
agent when oracle labels are not available, and show, through experiments, that
this critic agent's performance deteriorates in this scenario. With this in
mind, we present an improved critic agent, along with the calculator agent
which outperforms the previous state-of-the-art approach (program-of-thought)
and is safer. Furthermore, we investigate how our agents interact with each
other, and how this interaction affects their performance.

</details>


### [53] [Societal AI Research Has Become Less Interdisciplinary](https://arxiv.org/abs/2506.08738)
*Dror Kris Markus,Fabrizio Gilardi,Daria Stetsenko*

Main category: cs.CL

TL;DR: 研究分析了2014-2024年ArXiv上的10万篇AI论文，发现跨学科团队虽更倾向关注社会伦理，但纯计算机科学团队的社会导向研究占比显著增加。


<details>
  <summary>Details</summary>
Motivation: 探讨AI发展中伦理与社会价值的整合现状，验证跨学科合作是否实际推动这一趋势。

Method: 开发分类器识别论文中的社会内容，量化社会导向研究的分布与变化。

Result: 跨学科团队仍更关注社会伦理，但纯技术团队的社会导向研究占比显著增长，涉及公平、安全、医疗等多个领域。

Conclusion: 研究挑战了跨学科团队主导社会AI的假设，提出技术团队在AI伦理中的角色及社会科学如何继续贡献独特视角的问题。

Abstract: As artificial intelligence (AI) systems become deeply embedded in everyday
life, calls to align AI development with ethical and societal values have
intensified. Interdisciplinary collaboration is often championed as a key
pathway for fostering such engagement. Yet it remains unclear whether
interdisciplinary research teams are actually leading this shift in practice.
This study analyzes over 100,000 AI-related papers published on ArXiv between
2014 and 2024 to examine how ethical values and societal concerns are
integrated into technical AI research. We develop a classifier to identify
societal content and measure the extent to which research papers express these
considerations. We find a striking shift: while interdisciplinary teams remain
more likely to produce societally-oriented research, computer science-only
teams now account for a growing share of the field's overall societal output.
These teams are increasingly integrating societal concerns into their papers
and tackling a wide range of domains - from fairness and safety to healthcare
and misinformation. These findings challenge common assumptions about the
drivers of societal AI and raise important questions. First, what are the
implications for emerging understandings of AI safety and governance if most
societally-oriented research is being undertaken by exclusively technical
teams? Second, for scholars in the social sciences and humanities: in a
technical field increasingly responsive to societal demands, what distinctive
perspectives can we still offer to help shape the future of AI?

</details>


### [54] [Towards Secure and Private Language Models for Nuclear Power Plants](https://arxiv.org/abs/2506.08746)
*Muhammad Anwar,Mishca de Costa,Issam Hammad,Daniel Lau*

Main category: cs.CL

TL;DR: 本文介绍了一种专用于核能领域的特定领域大语言模型，基于公开的Essential CANDU教材构建，采用紧凑的Transformer架构，单GPU训练以保护核能操作中的敏感数据。尽管数据集较小，模型能捕捉专业核能词汇，但生成文本有时缺乏句法连贯性。


<details>
  <summary>Details</summary>
Motivation: 解决核能领域对数据保密性和网络安全的高要求，同时探索小规模数据集下构建专业领域语言模型的可行性。

Method: 使用紧凑的Transformer架构，基于Essential CANDU教材训练，单GPU实现以保护敏感数据。

Result: 模型能捕捉专业核能词汇，但生成文本的句法连贯性有待提升，初步验证了专业领域语言模型的可行性。

Conclusion: 未来需扩展数据集、优化预处理和指令微调，以提升模型在核能领域的准确性和实用性。

Abstract: This paper introduces a domain-specific Large Language Model for nuclear
applications, built from the publicly accessible Essential CANDU textbook.
Drawing on a compact Transformer-based architecture, the model is trained on a
single GPU to protect the sensitive data inherent in nuclear operations.
Despite relying on a relatively small dataset, it shows encouraging signs of
capturing specialized nuclear vocabulary, though the generated text sometimes
lacks syntactic coherence. By focusing exclusively on nuclear content, this
approach demonstrates the feasibility of in-house LLM solutions that align with
rigorous cybersecurity and data confidentiality standards. Early successes in
text generation underscore the model's utility for specialized tasks, while
also revealing the need for richer corpora, more sophisticated preprocessing,
and instruction fine-tuning to enhance domain accuracy. Future directions
include extending the dataset to cover diverse nuclear subtopics, refining
tokenization to reduce noise, and systematically evaluating the model's
readiness for real-world applications in nuclear domain.

</details>


### [55] [Unlocking the Potential of Large Language Models in the Nuclear Industry with Synthetic Data](https://arxiv.org/abs/2506.08750)
*Muhammad Anwar,Daniel Lau,Mishca de Costa,Issam Hammad*

Main category: cs.CL

TL;DR: 论文探讨了如何通过合成数据生成解决核工业中非结构化文本数据的可用性问题，以支持大型语言模型（LLM）的应用。


<details>
  <summary>Details</summary>
Motivation: 核工业中存在大量非结构化文本数据，但这些数据无法直接用于LLM的训练、微调和评估。数据稀缺和隐私问题进一步限制了LLM的应用。

Method: 利用LLM分析文本、提取关键信息、生成相关问题，并将非结构化数据转化为可用的问答对，从而创建合成数据集。

Result: 合成数据生成方法能够有效解决数据稀缺和隐私问题，为核工业中的LLM应用提供支持。

Conclusion: 合成数据为核工业中的信息检索、知识共享和决策制定提供了新的可能性，推动了LLM在该领域的应用。

Abstract: The nuclear industry possesses a wealth of valuable information locked away
in unstructured text data. This data, however, is not readily usable for
advanced Large Language Model (LLM) applications that require clean, structured
question-answer pairs for tasks like model training, fine-tuning, and
evaluation. This paper explores how synthetic data generation can bridge this
gap, enabling the development of robust LLMs for the nuclear domain. We discuss
the challenges of data scarcity and privacy concerns inherent in the nuclear
industry and how synthetic data provides a solution by transforming existing
text data into usable Q&A pairs. This approach leverages LLMs to analyze text,
extract key information, generate relevant questions, and evaluate the quality
of the resulting synthetic dataset. By unlocking the potential of LLMs in the
nuclear industry, synthetic data can pave the way for improved information
retrieval, enhanced knowledge sharing, and more informed decision-making in
this critical sector.

</details>


### [56] [Factors affecting the in-context learning abilities of LLMs for dialogue state tracking](https://arxiv.org/abs/2506.08753)
*Pradyoth Hegde,Santosh Kesiraju,Jan Švec,Šimon Sedláček,Bolaji Yusuf,Oldřich Plchot,Deepak K T,Jan Černocký*

Main category: cs.CL

TL;DR: 研究了如何利用上下文学习（ICL）解决对话状态跟踪（DST）问题，并分析了影响其效果的因素。


<details>
  <summary>Details</summary>
Motivation: 探索ICL在DST中的应用，并研究其效果的关键影响因素。

Method: 使用基于句子嵌入的k近邻方法检索适合的演示样本，结合测试样本构建模板输入到LLM中。

Result: 在MultiWoZ2.4数据集上测试了OLMo-7B-instruct等模型，提供了关于LLM在DST中上下文学习能力的见解。

Conclusion: 研究揭示了LLM在DST任务中上下文学习的关键因素和潜力。

Abstract: This study explores the application of in-context learning (ICL) to the
dialogue state tracking (DST) problem and investigates the factors that
influence its effectiveness. We use a sentence embedding based k-nearest
neighbour method to retrieve the suitable demonstrations for ICL. The selected
demonstrations, along with the test samples, are structured within a template
as input to the LLM. We then conduct a systematic study to analyse the impact
of factors related to demonstration selection and prompt context on DST
performance. This work is conducted using the MultiWoZ2.4 dataset and focuses
primarily on the OLMo-7B-instruct, Mistral-7B-Instruct-v0.3, and
Llama3.2-3B-Instruct models. Our findings provide several useful insights on
in-context learning abilities of LLMs for dialogue state tracking.

</details>


### [57] [Enhancing Accuracy and Maintainability in Nuclear Plant Data Retrieval: A Function-Calling LLM Approach Over NL-to-SQL](https://arxiv.org/abs/2506.08757)
*Mishca de Costa,Muhammad Anwar,Dave Mercier,Mark Randall,Issam Hammad*

Main category: cs.CL

TL;DR: 论文提出了一种基于函数调用的大型语言模型（LLM）方法，替代传统的自然语言转SQL（NL-to-SQL）方法，以提高核电厂数据查询的准确性和安全性。


<details>
  <summary>Details</summary>
Motivation: 传统的NL-to-SQL方法在核电厂等关键系统中存在风险，如生成的SQL查询难以验证，且复杂数据库结构增加了错误概率，降低了信任度。

Method: 通过预定义一组经过审核的专用函数，封装已验证的SQL逻辑，避免直接生成SQL查询，确保查询的准确性和安全性。

Result: 研究表明，函数调用方法在准确性和可维护性上优于直接NL-to-SQL生成。

Conclusion: 该工作平衡了用户易用性和操作安全性，为关键系统提供了一种可靠的数据检索框架。

Abstract: Retrieving operational data from nuclear power plants requires exceptional
accuracy and transparency due to the criticality of the decisions it supports.
Traditionally, natural language to SQL (NL-to-SQL) approaches have been
explored for querying such data. While NL-to-SQL promises ease of use, it poses
significant risks: end-users cannot easily validate generated SQL queries, and
legacy nuclear plant databases -- often complex and poorly structured --
complicate query generation due to decades of incremental modifications. These
challenges increase the likelihood of inaccuracies and reduce trust in the
approach. In this work, we propose an alternative paradigm: leveraging
function-calling large language models (LLMs) to address these challenges.
Instead of directly generating SQL queries, we define a set of pre-approved,
purpose-specific functions representing common use cases. Queries are processed
by invoking these functions, which encapsulate validated SQL logic. This hybrid
approach mitigates the risks associated with direct NL-to-SQL translations by
ensuring that SQL queries are reviewed and optimized by experts before
deployment. While this strategy introduces the upfront cost of developing and
maintaining the function library, we demonstrate how NL-to-SQL tools can assist
in the initial generation of function code, allowing experts to focus on
validation rather than creation. Our study includes a performance comparison
between direct NL-to-SQL generation and the proposed function-based approach,
highlighting improvements in accuracy and maintainability. This work
underscores the importance of balancing user accessibility with operational
safety and provides a novel, actionable framework for robust data retrieval in
critical systems.

</details>


### [58] [AraReasoner: Evaluating Reasoning-Based LLMs for Arabic NLP](https://arxiv.org/abs/2506.08768)
*Ahmed Hasanaath,Aisha Alansari,Ahmed Ashraf,Chafik Salmane,Hamzah Luqman,Saad Ezzini*

Main category: cs.CL

TL;DR: 本文全面评估了多款推理型大语言模型（LLMs）在阿拉伯语数据上的表现，特别关注DeepSeek模型，通过多种策略（零样本、少样本和微调）在15个阿拉伯语NLP任务上进行实验。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在推理能力和通用NLP任务上表现优异，但其在阿拉伯语数据（形态丰富、方言多样、文字复杂）上的性能尚未充分研究。

Method: 采用零样本、少样本和微调策略，在15个阿拉伯语NLP任务上评估模型性能，特别测试了DeepSeek模型的推理能力。

Result: 实验发现：1）精选3个上下文示例可显著提升分类任务性能（F1平均提升13点）；2）DeepSeek在零样本复杂推理任务中平均优于GPT o4-mini 12 F1点；3）LoRA微调比模型规模扩展带来额外8点F1和BLEU提升。

Conclusion: 研究表明，针对阿拉伯语的推理型LLMs优化策略（如精选上下文示例和LoRA微调）能显著提升性能，为未来研究提供了重要参考。

Abstract: Large language models (LLMs) have shown remarkable progress in reasoning
abilities and general natural language processing (NLP) tasks, yet their
performance on Arabic data, characterized by rich morphology, diverse dialects,
and complex script, remains underexplored. This paper presents a comprehensive
benchmarking study of multiple reasoning-focused LLMs, with a special emphasis
on the newly introduced DeepSeek models, across a suite of fifteen Arabic NLP
tasks. We experiment with various strategies, including zero-shot, few-shot,
and fine-tuning. This allows us to systematically evaluate performance on
datasets covering a range of applications to examine their capacity for
linguistic reasoning under different levels of complexity. Our experiments
reveal several key findings. First, carefully selecting just three in-context
examples delivers an average uplift of over 13 F1 points on classification
tasks-boosting sentiment analysis from 35.3% to 87.5% and paraphrase detection
from 56.1% to 87.0%. Second, reasoning-focused DeepSeek architectures
outperform a strong GPT o4-mini baseline by an average of 12 F1 points on
complex inference tasks in the zero-shot setting. Third, LoRA-based fine-tuning
yields up to an additional 8 points in F1 and BLEU compared to equivalent
increases in model scale. The code is available at
https://anonymous.4open.science/r/AraReasoner41299

</details>


### [59] [The impact of fine tuning in LLaMA on hallucinations for named entity extraction in legal documentation](https://arxiv.org/abs/2506.08827)
*Francisco Vargas,Alejandro González Coene,Gaston Escalante,Exequiel Lobón,Manuel Pulido*

Main category: cs.CL

TL;DR: 论文提出了一种两阶段方法，从法律文件中提取交通事故信息，包括伤残百分比和赔偿金额。通过文本分割和实体提取，结合多语言模型和LLMs，显著提升了提取准确率。


<details>
  <summary>Details</summary>
Motivation: 从法律文件中提取交通事故信息对保险公司成本量化至关重要，但由于法院判决的复杂性，即使是专家也难以准确提取。

Method: 采用两阶段方法：1) 文本分割（正则表达式或语义向量化）；2) 使用LLMs（如LLaMA-2、LLaMA-3、GPT-4 Turbo）进行实体提取，并对部分模型进行微调。

Result: 基于语义向量化和LLMs的方法显著优于传统方法（准确率39.5%）。微调后的LLaMA-2 70B达到79.4%，LLaMA-3 8B基础版为76.6%，GPT-4 Turbo最高达86.1%。

Conclusion: 结合语义向量化和LLMs的方法有效提升了信息提取的准确性，尤其是微调和新型模型的应用展现了显著进步。

Abstract: The extraction of information about traffic accidents from legal documents is
crucial for quantifying insurance company costs. Extracting entities such as
percentages of physical and/or psychological disability and the involved
compensation amounts is a challenging process, even for experts, due to the
subtle arguments and reasoning in the court decision. A two-step procedure is
proposed: first, segmenting the document identifying the most relevant
segments, and then extracting the entities. For text segmentation, two
methodologies are compared: a classic method based on regular expressions and a
second approach that divides the document into blocks of n-tokens, which are
then vectorized using multilingual models for semantic searches
(text-embedding-ada-002/MiniLM-L12-v2 ). Subsequently, large language models
(LLaMA-2 7b, 70b, LLaMA-3 8b, and GPT-4 Turbo) are applied with prompting to
the selected segments for entity extraction. For the LLaMA models, fine-tuning
is performed using LoRA. LLaMA-2 7b, even with zero temperature, shows a
significant number of hallucinations in extractions which are an important
contention point for named entity extraction. This work shows that these
hallucinations are substantially reduced after finetuning the model. The
performance of the methodology based on segment vectorization and subsequent
use of LLMs significantly surpasses the classic method which achieves an
accuracy of 39.5%. Among open-source models, LLaMA-2 70B with finetuning
achieves the highest accuracy 79.4%, surpassing its base version 61.7%.
Notably, the base LLaMA-3 8B model already performs comparably to the finetuned
LLaMA-2 70B model, achieving 76.6%, highlighting the rapid progress in model
development. Meanwhile, GPT-4 Turbo achieves the highest accuracy at 86.1%.

</details>


### [60] [Advancing STT for Low-Resource Real-World Speech](https://arxiv.org/abs/2506.08836)
*Flavio D'Intino,Hans-Peter Hutter*

Main category: cs.CL

TL;DR: 论文介绍了SRB-300数据集，用于提升瑞士德语（低资源语言）的语音识别性能，通过微调Whisper模型显著降低了词错误率（WER）并提高了BLEU分数。


<details>
  <summary>Details</summary>
Motivation: 瑞士德语缺乏标准化书写形式，现有数据集在自发对话语音上表现不佳，需要新的数据集和模型来提升识别效果。

Method: 使用SRB-300数据集（300小时的真实世界长音频）微调多个OpenAI Whisper模型。

Result: 微调后的模型显著提升了性能，最佳模型（large-v3）的WER为17.1%，BLEU分数为74.8%。

Conclusion: SRB-300数据集和微调方法为瑞士德语及其他低资源语言的语音识别提供了有效解决方案。

Abstract: Swiss German is a low-resource language represented by diverse dialects that
differ significantly from Standard German and from each other, lacking a
standardized written form. As a result, transcribing Swiss German involves
translating into Standard German. Existing datasets have been collected in
controlled environments, yielding effective speech-to-text (STT) models, but
these models struggle with spontaneous conversational speech.
  This paper, therefore, introduces the new SRB-300 dataset, a 300-hour
annotated speech corpus featuring real-world long-audio recordings from 39
Swiss German radio and TV stations. It captures spontaneous speech across all
major Swiss dialects recorded in various realistic environments and overcomes
the limitation of prior sentence-level corpora.
  We fine-tuned multiple OpenAI Whisper models on the SRB-300 dataset,
achieving notable enhancements over previous zero-shot performance metrics.
Improvements in word error rate (WER) ranged from 19% to 33%, while BLEU scores
increased between 8% and 40%. The best fine-tuned model, large-v3, achieved a
WER of 17.1% and a BLEU score of 74.8. This advancement is crucial for
developing effective and robust STT systems for Swiss German and other
low-resource languages in real-world contexts.

</details>


### [61] [AdversariaL attacK sAfety aLIgnment(ALKALI): Safeguarding LLMs through GRACE: Geometric Representation-Aware Contrastive Enhancement- Introducing Adversarial Vulnerability Quality Index (AVQI)](https://arxiv.org/abs/2506.08885)
*Danush Khanna,Krishna Kumar,Basab Ghosh,Vinija Jain,Vasu Sharma,Aman Chadha,Amitava Das*

Main category: cs.CL

TL;DR: 论文揭示了LLMs对抗性威胁的几何盲点，提出了ALKALI基准和GRACE框架以提升防御能力，并引入AVQI指标量化潜在对齐失败。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs的防御机制无法快速适应日益增长的对抗性威胁，尤其是对抗性提示利用潜在伪装绕过表面防御。

Method: 提出了ALKALI基准（涵盖9000个提示）和GRACE框架，通过几何表示增强和潜在空间正则化来提升模型安全性。

Result: 评估21个领先LLMs显示高攻击成功率，GRACE框架成功降低39%的攻击成功率。

Conclusion: GRACE框架和AVQI指标为LLMs安全性提供了新的解决方案，揭示了潜在伪装的结构性盲点。

Abstract: Adversarial threats against LLMs are escalating faster than current defenses
can adapt. We expose a critical geometric blind spot in alignment: adversarial
prompts exploit latent camouflage, embedding perilously close to the safe
representation manifold while encoding unsafe intent thereby evading surface
level defenses like Direct Preference Optimization (DPO), which remain blind to
the latent geometry. We introduce ALKALI, the first rigorously curated
adversarial benchmark and the most comprehensive to date spanning 9,000 prompts
across three macro categories, six subtypes, and fifteen attack families.
Evaluation of 21 leading LLMs reveals alarmingly high Attack Success Rates
(ASRs) across both open and closed source models, exposing an underlying
vulnerability we term latent camouflage, a structural blind spot where
adversarial completions mimic the latent geometry of safe ones. To mitigate
this vulnerability, we introduce GRACE - Geometric Representation Aware
Contrastive Enhancement, an alignment framework coupling preference learning
with latent space regularization. GRACE enforces two constraints: latent
separation between safe and adversarial completions, and adversarial cohesion
among unsafe and jailbreak behaviors. These operate over layerwise pooled
embeddings guided by a learned attention profile, reshaping internal geometry
without modifying the base model, and achieve up to 39% ASR reduction.
Moreover, we introduce AVQI, a geometry aware metric that quantifies latent
alignment failure via cluster separation and compactness. AVQI reveals when
unsafe completions mimic the geometry of safe ones, offering a principled lens
into how models internally encode safety. We make the code publicly available
at https://anonymous.4open.science/r/alkali-B416/README.md.

</details>


### [62] [PlantBert: An Open Source Language Model for Plant Science](https://arxiv.org/abs/2506.08897)
*Hiba Khey,Amine Lakhder,Salma Rouichi,Imane El Ghabi,Kamal Hejjaoui,Younes En-nahli,Fahd Kalloubi,Moez Amri*

Main category: cs.CL

TL;DR: PlantBert是一个基于DeBERTa架构的领域专用语言模型，专注于植物胁迫响应文献的结构化知识提取。


<details>
  <summary>Details</summary>
Motivation: 植物科学领域缺乏领域适应的语言模型工具，PlantBert旨在填补这一空白。

Method: 结合Transformer建模、规则增强的语言后处理和基于本体的实体规范化，使用专家标注的摘要进行微调。

Result: PlantBert在实体类型上表现出强大的泛化能力，适用于低资源科学领域。

Conclusion: PlantBert为农业NLP提供了可扩展的框架，推动了植物科学领域的数据驱动研究。

Abstract: The rapid advancement of transformer-based language models has catalyzed
breakthroughs in biomedical and clinical natural language processing; however,
plant science remains markedly underserved by such domain-adapted tools. In
this work, we present PlantBert, a high-performance, open-source language model
specifically tailored for extracting structured knowledge from plant
stress-response literature. Built upon the DeBERTa architecture-known for its
disentangled attention and robust contextual encoding-PlantBert is fine-tuned
on a meticulously curated corpus of expert-annotated abstracts, with a primary
focus on lentil (Lens culinaris) responses to diverse abiotic and biotic
stressors. Our methodology combines transformer-based modeling with
rule-enhanced linguistic post-processing and ontology-grounded entity
normalization, enabling PlantBert to capture biologically meaningful
relationships with precision and semantic fidelity. The underlying corpus is
annotated using a hierarchical schema aligned with the Crop Ontology,
encompassing molecular, physiological, biochemical, and agronomic dimensions of
plant adaptation. PlantBert exhibits strong generalization capabilities across
entity types and demonstrates the feasibility of robust domain adaptation in
low-resource scientific fields. By providing a scalable and reproducible
framework for high-resolution entity recognition, PlantBert bridges a critical
gap in agricultural NLP and paves the way for intelligent, data-driven systems
in plant genomics, phenomics, and agronomic knowledge discovery. Our model is
publicly released to promote transparency and accelerate cross-disciplinary
innovation in computational plant science.

</details>


### [63] [From Legal Texts to Defeasible Deontic Logic via LLMs: A Study in Automated Semantic Analysis](https://arxiv.org/abs/2506.08899)
*Elias Horner,Cristinel Mateis,Guido Governatori,Agata Ciabattoni*

Main category: cs.CL

TL;DR: 提出了一种利用大型语言模型（LLMs）自动分析法律文本语义的新方法，将其转化为可废止义务逻辑（DDL）的形式化表示。


<details>
  <summary>Details</summary>
Motivation: 旨在解决法律文本的复杂性和规范性语言的形式化表示问题，提高法律信息学的可扩展性。

Method: 采用结构化流程，将规范性语言分割为原子片段，提取义务规则，并评估其语法和语义一致性。评估了多种LLM配置，包括提示工程策略、微调模型和多阶段流程。

Result: 实验结果表明，机器生成的形式化表示与专家手工制作的结果具有良好的一致性，尤其是在有效提示的情况下，LLMs对法律信息学的可扩展性贡献显著。

Conclusion: LLMs在法律文本的形式化表示中具有潜力，特别是在优化提示策略的情况下，能够显著提升法律信息学的效率。

Abstract: We present a novel approach to the automated semantic analysis of legal texts
using large language models (LLMs), targeting their transformation into formal
representations in Defeasible Deontic Logic (DDL). We propose a structured
pipeline that segments complex normative language into atomic snippets,
extracts deontic rules, and evaluates them for syntactic and semantic
coherence. Our methodology is evaluated across various LLM configurations,
including prompt engineering strategies, fine-tuned models, and multi-stage
pipelines, focusing on legal norms from the Australian Telecommunications
Consumer Protections Code. Empirical results demonstrate promising alignment
between machine-generated and expert-crafted formalizations, showing that LLMs
- particularly when prompted effectively - can significantly contribute to
scalable legal informatics.

</details>


### [64] [Dialect Normalization using Large Language Models and Morphological Rules](https://arxiv.org/abs/2506.08907)
*Antonios Dimakis,John Pavlopoulos,Antonios Anastasopoulos*

Main category: cs.CL

TL;DR: 论文提出了一种结合规则和大型语言模型（LLM）的方言标准化方法，无需平行数据，并在希腊方言上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（包括高资源语言的方言）在自然语言理解系统中的挑战，通过方言到标准的转换提升下游工具的使用效果。

Method: 结合基于规则的语言学转换和大型语言模型（LLM）的少样本提示方法，无需平行数据。

Result: 在希腊方言数据集上验证了方法的有效性，发现此前研究仅依赖表层语言信息，而新方法能保留更多语义信息。

Conclusion: 提出的方法为方言标准化提供了新思路，且无需平行数据，具有实际应用潜力。

Abstract: Natural language understanding systems struggle with low-resource languages,
including many dialects of high-resource ones. Dialect-to-standard
normalization attempts to tackle this issue by transforming dialectal text so
that it can be used by standard-language tools downstream. In this study, we
tackle this task by introducing a new normalization method that combines
rule-based linguistically informed transformations and large language models
(LLMs) with targeted few-shot prompting, without requiring any parallel data.
We implement our method for Greek dialects and apply it on a dataset of
regional proverbs, evaluating the outputs using human annotators. We then use
this dataset to conduct downstream experiments, finding that previous results
regarding these proverbs relied solely on superficial linguistic information,
including orthographic artifacts, while new observations can still be made
through the remaining semantics.

</details>


### [65] [PropMEND: Hypernetworks for Knowledge Propagation in LLMs](https://arxiv.org/abs/2506.08920)
*Zeyu Leo Liu,Greg Durrett,Eunsol Choi*

Main category: cs.CL

TL;DR: 论文提出PropMEND方法，通过超网络学习如何修改梯度以促进知识传播，解决大语言模型知识编辑后无法推理的问题。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑技术无法让模型利用注入的知识进行推理，限制了其实际应用。

Method: 基于超网络的方法（PropMEND），通过元学习修改语言建模损失的梯度，以支持多跳推理。

Result: 在RippleEdit数据集上表现优异，多跳问题准确率提升近2倍；在新数据集Controlled RippleEdit上仍优于现有方法。

Conclusion: PropMEND在知识传播方面表现优越，但未见实体关系对的性能差距缩小，未来需进一步优化。

Abstract: Knowledge editing techniques for large language models (LLMs) can inject
knowledge that is later reproducible verbatim, but they fall short on
propagating that knowledge: models cannot answer questions that require
reasoning with the injected knowledge. We present a hypernetwork-based approach
for knowledge propagation, named PropMEND, where we meta-learn how to modify
gradients of a language modeling loss to encourage injected information to
propagate. Our approach extends the meta-objective of MEND [29] so that
gradient updates on knowledge are transformed to enable answering multi-hop
questions involving that knowledge. We show improved performance on the
RippleEdit dataset, showing almost 2x accuracy on challenging multi-hop
questions whose answers are not explicitly stated in the injected fact. We
further introduce a new dataset, Controlled RippleEdit, to evaluate the
generalization of our hypernetwork, testing knowledge propagation along
relations and entities unseen during hypernetwork training. PropMEND still
outperforms existing approaches in unseen entity-relation pairs, yet the
performance gap decreases substantially, suggesting future work in propagating
knowledge to a wide range of relations.

</details>


### [66] [Can A Gamer Train A Mathematical Reasoning Model?](https://arxiv.org/abs/2506.08935)
*Andrew Shin*

Main category: cs.CL

TL;DR: 本文展示了如何通过结合强化学习和内存优化技术，在单张普通游戏GPU（RTX 3080 Ti）上训练一个1.5B参数的数学推理模型，性能与更大模型相当。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在数学推理等任务中表现出色，但其训练通常需要高昂的计算资源。本文旨在降低高性能AI研究的门槛。

Method: 结合强化学习和内存优化技术，在资源受限环境下训练1.5B参数的数学推理模型。

Result: 在RTX 3080 Ti上训练的模型性能与更大模型相当，甚至更好。

Conclusion: 本文挑战了高性能数学推理需要大规模基础设施的范式，推动了AI研究的普及。

Abstract: While large language models (LLMs) have achieved remarkable performance in
various tasks including mathematical reasoning, their development typically
demands prohibitive computational resources. Recent advancements have reduced
costs for training capable models, yet even these approaches rely on high-end
hardware clusters. In this paper, we demonstrate that a single average gaming
GPU can train a solid mathematical reasoning model, by integrating
reinforcement learning and memory optimization techniques. Specifically, we
train a 1.5B parameter mathematical reasoning model on RTX 3080 Ti of 16GB
memory that achieves comparable or better performance on mathematical reasoning
benchmarks than models several times larger, in resource-constrained
environments. Our results challenge the paradigm that state-of-the-art
mathematical reasoning necessitates massive infrastructure, democratizing
access to high-performance AI research.
https://github.com/shinandrew/YouronMath.

</details>


### [67] [FaithfulRAG: Fact-Level Conflict Modeling for Context-Faithful Retrieval-Augmented Generation](https://arxiv.org/abs/2506.08938)
*Qinggang Zhang,Zhishang Xiang,Yilin Xiao,Le Wang,Junhui Li,Xinrun Wang,Jinsong Su*

Main category: cs.CL

TL;DR: 论文提出FaithfulRAG框架，解决检索增强语言模型在知识冲突时的忠实性问题，通过显式建模参数知识与检索上下文之间的差异，提升生成结果的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强语言模型在知识冲突时存在忠实性问题，生成结果可能忽略检索上下文或不一致地混合参数知识。现有方法通过强制抑制参数知识实现忠实性，但破坏了模型内部知识结构。

Method: 提出FaithfulRAG框架，显式建模参数知识与检索上下文的差异，设计自思考过程，让模型在生成前推理并整合冲突事实。

Result: 实验表明，FaithfulRAG优于现有方法，解决了知识冲突问题。

Conclusion: FaithfulRAG通过显式建模和自思考过程，有效提升了检索增强语言模型在知识冲突时的忠实性和准确性。

Abstract: Large language models (LLMs) augmented with retrieval systems have
demonstrated significant potential in handling knowledge-intensive tasks.
However, these models often struggle with unfaithfulness issues, generating
outputs that either ignore the retrieved context or inconsistently blend it
with the LLM`s parametric knowledge. This issue is particularly severe in cases
of knowledge conflict, where the retrieved context conflicts with the model`s
parametric knowledge. While existing faithful RAG approaches enforce strict
context adherence through well-designed prompts or modified decoding
strategies, our analysis reveals a critical limitation: they achieve
faithfulness by forcibly suppressing the model`s parametric knowledge, which
undermines the model`s internal knowledge structure and increases the risk of
misinterpreting the context. To this end, this paper proposes FaithfulRAG, a
novel framework that resolves knowledge conflicts by explicitly modeling
discrepancies between the model`s parametric knowledge and retrieved context.
Specifically, FaithfulRAG identifies conflicting knowledge at the fact level
and designs a self-thinking process, allowing LLMs to reason about and
integrate conflicting facts before generating responses. Extensive experiments
demonstrate that our method outperforms state-of-the-art methods. The code is
available at https:// github.com/DeepLearnXMU/Faithful-RAG

</details>


### [68] [Can LLMs Ground when they (Don't) Know: A Study on Direct and Loaded Political Questions](https://arxiv.org/abs/2506.08952)
*Clara Lachenmaier,Judith Sieker,Sina Zarrieß*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型（LLMs）在政治领域中如何管理共同基础，尤其是当它们（不）具备知识时，重点关注了错误信息和基础失败的案例。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在回答直接知识问题和预设错误信息的引导性问题时的表现，以评估其是否能够主动纠正用户的错误信念。

Method: 通过分析LLMs对直接知识问题和引导性问题的回答，评估其知识水平和政治偏见对其行为的影响。

Result: 研究发现LLMs在建立共同基础和拒绝用户错误信念方面存在显著挑战。

Conclusion: LLMs在政治话语中缓解错误信息的能力存在严重问题，需引起关注。

Abstract: Communication among humans relies on conversational grounding, allowing
interlocutors to reach mutual understanding even when they do not have perfect
knowledge and must resolve discrepancies in each other's beliefs. This paper
investigates how large language models (LLMs) manage common ground in cases
where they (don't) possess knowledge, focusing on facts in the political domain
where the risk of misinformation and grounding failure is high. We examine the
ability of LLMs to answer direct knowledge questions and loaded questions that
presuppose misinformation. We evaluate whether loaded questions lead LLMs to
engage in active grounding and correct false user beliefs, in connection to
their level of knowledge and their political bias. Our findings highlight
significant challenges in LLMs' ability to engage in grounding and reject false
user beliefs, raising concerns about their role in mitigating misinformation in
political discourse.

</details>


### [69] [Pre-trained Language Models Learn Remarkably Accurate Representations of Numbers](https://arxiv.org/abs/2506.08966)
*Marek Kadlčík,Michal Štefánik,Timothee Mickus,Michal Spiegel,Josef Kuchař*

Main category: cs.CL

TL;DR: 论文提出了一种新的探测技术，能够从预训练语言模型的嵌入中高精度解码数值，证明模型在预训练后能精确表示数字，并发现这种精确性与算术错误相关。


<details>
  <summary>Details</summary>
Motivation: 现有方法在探测语言模型中的数值表示时效果有限，作者观察到这些方法未能捕捉到嵌入中的正弦模式结构。

Method: 提出了一种新型探测技术，能够从输入嵌入中解码数值，并验证其在不同开源语言模型中的准确性。

Result: 发现语言模型在预训练后能高精度表示数字，且嵌入的精确性与算术错误显著相关。通过调整嵌入模式可以减少这些错误。

Conclusion: 论文证明了语言模型能够精确表示数字，并提出了一种改进算术性能的方法。

Abstract: Pretrained language models (LMs) are prone to arithmetic errors. Existing
work showed limited success in probing numeric values from models'
representations, indicating that these errors can be attributed to the inherent
unreliability of distributionally learned embeddings in representing exact
quantities. However, we observe that previous probing methods are inadequate
for the emergent structure of learned number embeddings with sinusoidal
patterns.
  In response, we propose a novel probing technique that decodes numeric values
from input embeddings with near-perfect accuracy across a range of open-source
LMs. This proves that after the sole pre-training, LMs represent numbers with
remarkable precision. Finally, we find that the embeddings' preciseness judged
by our probe's accuracy explains a large portion of LM's errors in elementary
arithmetic, and show that aligning the embeddings with the pattern discovered
by our probe can mitigate these errors.

</details>


### [70] [Atomic-to-Compositional Generalization for Mobile Agents with A New Benchmark and Scheduling System](https://arxiv.org/abs/2506.08972)
*Yuan Guo,Tingjia Miao,Zheng Wu,Pengzhou Cheng,Ming Zhou,Zhuosheng Zhang*

Main category: cs.CL

TL;DR: 论文介绍了UI-NEXUS基准测试，用于评估移动代理在组合任务上的表现，并提出了AGENT-NEXUS调度系统以提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有移动代理主要关注原子任务，而忽视了组合任务的泛化能力，这在现实应用中至关重要。

Method: 提出UI-NEXUS基准测试，包含三类组合操作任务，并在20个本地应用和30个在线服务应用中评估。随后提出AGENT-NEXUS调度系统，动态分解长时任务为原子子任务。

Result: 现有代理在组合任务上表现不佳，AGENT-NEXUS将任务成功率提升了24%至40%。

Conclusion: AGENT-NEXUS显著提升了移动代理在组合任务上的表现，且未显著增加推理开销。

Abstract: Autonomous agents powered by multimodal large language models have been
developed to facilitate task execution on mobile devices. However, prior work
has predominantly focused on atomic tasks -- such as shot-chain execution tasks
and single-screen grounding tasks -- while overlooking the generalization to
compositional tasks, which are indispensable for real-world applications. This
work introduces UI-NEXUS, a comprehensive benchmark designed to evaluate mobile
agents on three categories of compositional operations: Simple Concatenation,
Context Transition, and Deep Dive. UI-NEXUS supports interactive evaluation in
20 fully controllable local utility app environments, as well as 30 online
Chinese and English service apps. It comprises 100 interactive task templates
with an average optimal step count of 14.05. Experimental results across a
range of mobile agents with agentic workflow or agent-as-a-model show that
UI-NEXUS presents significant challenges. Specifically, existing agents
generally struggle to balance performance and efficiency, exhibiting
representative failure modes such as under-execution, over-execution, and
attention drift, causing visible atomic-to-compositional generalization gap.
Inspired by these findings, we propose AGENT-NEXUS, a lightweight and efficient
scheduling system to tackle compositional mobile tasks. AGENT-NEXUS
extrapolates the abilities of existing mobile agents by dynamically decomposing
long-horizon tasks to a series of self-contained atomic subtasks. AGENT-NEXUS
achieves 24% to 40% task success rate improvement for existing mobile agents on
compositional operation tasks within the UI-NEXUS benchmark without
significantly sacrificing inference overhead. The demo video, dataset, and code
are available on the project page at https://ui-nexus.github.io.

</details>


### [71] [FROST-EMA: Finnish and Russian Oral Speech Dataset of Electromagnetic Articulography Measurements with L1, L2 and Imitated L2 Accents](https://arxiv.org/abs/2506.08981)
*Satu Hopponen,Tomi Kinnunen,Alexandre Nikolaev,Rosa González Hautamäki,Lauri Tavi,Einar Meister*

Main category: cs.CL

TL;DR: 介绍了FROST-EMA语料库，包含18名双语者的母语、第二语言及模仿第二语言的语音数据，支持语音和技术研究。


<details>
  <summary>Details</summary>
Motivation: 研究语言变异性在语音和技术层面的表现。

Method: 构建FROST-EMA语料库，并进行两项初步案例研究：自动说话人验证系统的性能分析和发音模式分析。

Result: 展示了语料库在语音技术（如说话人验证）和发音研究中的应用潜力。

Conclusion: FROST-EMA为语言变异性研究提供了新资源，并展示了其在多领域的应用价值。

Abstract: We introduce a new FROST-EMA (Finnish and Russian Oral Speech Dataset of
Electromagnetic Articulography) corpus. It consists of 18 bilingual speakers,
who produced speech in their native language (L1), second language (L2), and
imitated L2 (fake foreign accent). The new corpus enables research into
language variability from phonetic and technological points of view.
Accordingly, we include two preliminary case studies to demonstrate both
perspectives. The first case study explores the impact of L2 and imitated L2 on
the performance of an automatic speaker verification system, while the second
illustrates the articulatory patterns of one speaker in L1, L2, and a fake
accent.

</details>


### [72] [Naturalistic Language-related Movie-Watching fMRI Task for Detecting Neurocognitive Decline and Disorder](https://arxiv.org/abs/2506.08986)
*Yuejiao Wang,Xianmin Gong,Xixin Wu,Patrick Wong,Hoi-lam Helene Fung,Man Wai Mak,Helen Meng*

Main category: cs.CL

TL;DR: 该论文提出了一种新颖的语言相关fMRI任务，用于早期检测神经认知障碍（NCD），并在97名非痴呆中国老年人中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 早期检测神经认知障碍（NCD）对于及时干预至关重要，语言相关fMRI可能是一种有前景的方法。

Method: 提出了一种自然语言相关的fMRI任务，结合机器学习和人口统计学特征进行分类。

Result: 分类模型的AUC达到0.86，特征主要来自语言处理相关脑区。

Conclusion: 该任务在早期检测衰老相关认知衰退和NCD方面具有潜力。

Abstract: Early detection is crucial for timely intervention aimed at preventing and
slowing the progression of neurocognitive disorder (NCD), a common and
significant health problem among the aging population. Recent evidence has
suggested that language-related functional magnetic resonance imaging (fMRI)
may be a promising approach for detecting cognitive decline and early NCD. In
this paper, we proposed a novel, naturalistic language-related fMRI task for
this purpose. We examined the effectiveness of this task among 97 non-demented
Chinese older adults from Hong Kong. The results showed that machine-learning
classification models based on fMRI features extracted from the task and
demographics (age, gender, and education year) achieved an average area under
the curve of 0.86 when classifying participants' cognitive status (labeled as
NORMAL vs DECLINE based on their scores on a standard neurcognitive test).
Feature localization revealed that the fMRI features most frequently selected
by the data-driven approach came primarily from brain regions associated with
language processing, such as the superior temporal gyrus, middle temporal
gyrus, and right cerebellum. The study demonstrated the potential of the
naturalistic language-related fMRI task for early detection of aging-related
cognitive decline and NCD.

</details>


### [73] [Employing self-supervised learning models for cross-linguistic child speech maturity classification](https://arxiv.org/abs/2506.08999)
*Theo Zhang,Madurya Suresh,Anne S. Warlaumont,Kasia Hitczenko,Alejandrina Cristia,Margaret Cychosz*

Main category: cs.CL

TL;DR: 论文提出了一种名为SpeechMaturity的新数据集，用于改进儿童语音分类任务，通过大规模多语言样本训练模型，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 儿童语音技术系统因训练数据少和儿童语音复杂性而表现不佳，需更有效的数据集和方法。

Method: 使用SpeechMaturity数据集，包含242,004个标记的儿童发声样本，训练Transformer模型进行分类任务。

Result: 模型在新数据集上表现优于现有方法，分类准确率接近人类水平，且在城乡环境中均表现稳健。

Conclusion: SpeechMaturity数据集和Transformer模型的结合显著提升了儿童语音分类任务的性能。

Abstract: Speech technology systems struggle with many downstream tasks for child
speech due to small training corpora and the difficulties that child speech
pose. We apply a novel dataset, SpeechMaturity, to state-of-the-art transformer
models to address a fundamental classification task: identifying child
vocalizations. Unlike previous corpora, our dataset captures maximally
ecologically-valid child vocalizations across an unprecedented sample,
comprising children acquiring 25+ languages in the U.S., Bolivia, Vanuatu,
Papua New Guinea, Solomon Islands, and France. The dataset contains 242,004
labeled vocalizations, magnitudes larger than previous work. Models were
trained to distinguish between cry, laughter, mature (consonant+vowel), and
immature speech (just consonant or vowel). Models trained on the dataset
outperform state-of-the-art models trained on previous datasets, achieved
classification accuracy comparable to humans, and were robust across rural and
urban settings.

</details>


### [74] [SWE-Flow: Synthesizing Software Engineering Data in a Test-Driven Manner](https://arxiv.org/abs/2506.09003)
*Lei Zhang,Jiaxi Yang,Min Yang,Jian Yang,Mouxiang Chen,Jiajun Zhang,Zeyu Cui,Binyuan Hui,Junyang Lin*

Main category: cs.CL

TL;DR: SWE-Flow是一个基于测试驱动开发（TDD）的数据合成框架，通过单元测试自动推断增量开发步骤，生成可验证的TDD任务。


<details>
  <summary>Details</summary>
Motivation: 现有软件工程数据依赖人工提交的问题，SWE-Flow旨在通过单元测试自动生成开发步骤，提高数据质量和效率。

Method: 构建运行时依赖图（RDG）以捕获函数交互，生成结构化的开发计划，包括部分代码库、单元测试和代码修改。

Result: 从真实GitHub项目中生成了16,061个训练实例和2,020个测试实例，实验表明该数据集显著提升了TDD编码性能。

Conclusion: SWE-Flow为TDD研究提供了高质量数据和工具，促进了进一步研究。

Abstract: We introduce **SWE-Flow**, a novel data synthesis framework grounded in
Test-Driven Development (TDD). Unlike existing software engineering data that
rely on human-submitted issues, **SWE-Flow** automatically infers incremental
development steps directly from unit tests, which inherently encapsulate
high-level requirements. The core of **SWE-Flow** is the construction of a
Runtime Dependency Graph (RDG), which precisely captures function interactions,
enabling the generation of a structured, step-by-step *development schedule*.
At each step, **SWE-Flow** produces a partial codebase, the corresponding unit
tests, and the necessary code modifications, resulting in fully verifiable TDD
tasks. With this approach, we generated 16,061 training instances and 2,020
test instances from real-world GitHub projects, creating the **SWE-Flow-Eval**
benchmark. Our experiments show that fine-tuning open model on this dataset
significantly improves performance in TDD-based coding. To facilitate further
research, we release all code, datasets, models, and Docker images at
[Github](https://github.com/Hambaobao/SWE-Flow).

</details>


### [75] [UD-KSL Treebank v1.3: A semi-automated framework for aligning XPOS-extracted units with UPOS tags](https://arxiv.org/abs/2506.09009)
*Hakyung Sung,Gyu-Ho Shin,Chanyoung Lee,You Kyung Sung,Boo Kyung Jung*

Main category: cs.CL

TL;DR: 研究扩展了第二语言韩语的通用依存标注工作，提出半自动化框架，将XPOS序列与UPOS类别对齐，并扩充了语料库。实验表明对齐数据提升了标注一致性和分析准确性。


<details>
  <summary>Details</summary>
Motivation: 扩展第二语言韩语的通用依存标注工作，解决标注一致性和数据有限的问题。

Method: 引入半自动化框架，将XPOS序列与UPOS类别对齐，并扩充语料库；使用两种NLP工具包在有无对齐的数据集上微调模型。

Result: 对齐数据集提高了标注一致性和形态句法标注、依存分析的准确性，尤其在数据有限时效果显著。

Conclusion: XPOS-UPOS对齐框架有效提升了第二语言韩语的形态句法分析性能。

Abstract: The present study extends recent work on Universal Dependencies annotations
for second-language (L2) Korean by introducing a semi-automated framework that
identifies morphosyntactic constructions from XPOS sequences and aligns those
constructions with corresponding UPOS categories. We also broaden the existing
L2-Korean corpus by annotating 2,998 new sentences from argumentative essays.
To evaluate the impact of XPOS-UPOS alignments, we fine-tune L2-Korean
morphosyntactic analysis models on datasets both with and without these
alignments, using two NLP toolkits. Our results indicate that the aligned
dataset not only improves consistency across annotation layers but also
enhances morphosyntactic tagging and dependency-parsing accuracy, particularly
in cases of limited annotated data.

</details>


### [76] [Learning to Reason Across Parallel Samples for LLM Reasoning](https://arxiv.org/abs/2506.09014)
*Jianing Qi,Xi Ye,Hao Tang,Zhigang Zhu,Eunsol Choi*

Main category: cs.CL

TL;DR: 提出了一种名为SSA的紧凑型LLM，用于聚合多个样本答案，通过强化学习优化准确性，优于其他测试时扩展方法。


<details>
  <summary>Details</summary>
Motivation: 通过聚合多个样本答案提升大型语言模型在数学领域的性能。

Method: 训练紧凑型LLM（SSA），输入多个样本的拼接序列，输出最终答案，并通过强化学习优化准确性。

Result: 在多个推理数据集上，SSA优于基于奖励模型的重新排序等方法，并展现出跨样本集大小、基础模型和任务的泛化能力。

Conclusion: SSA方法能够高效地与黑盒模型输出结合，提升性能。

Abstract: Scaling test-time compute brings substantial performance gains for large
language models (LLMs). By sampling multiple answers and heuristically
aggregate their answers (e.g., either through majority voting or using
verifiers to rank the answers), one can achieve consistent performance gains in
math domains. In this paper, we propose a new way to leverage such multiple
sample set. We train a compact LLM, called Sample Set Aggregator (SSA), that
takes a concatenated sequence of multiple samples and output the final answer,
optimizing it for the answer accuracy with reinforcement learning. Experiments
on multiple reasoning datasets show that SSA outperforms other test-time
scaling methods such as reward model-based re-ranking. Our approach also shows
a promising generalization ability, across sample set sizes, base model
families and scales, and tasks. By separating LLMs to generate answers and LLMs
to analyze and aggregate sampled answers, our approach can work with the
outputs from premier black box models easily and efficiently.

</details>


### [77] [Comparing human and LLM proofreading in L2 writing: Impact on lexical and syntactic features](https://arxiv.org/abs/2506.09021)
*Hakyung Sung,Karla Csuros,Min-Chang Sung*

Main category: cs.CL

TL;DR: 研究比较了人类和LLM（ChatGPT-4o、Llama3.1-8b、Deepseek-r1-8b）对第二语言写作的校对效果，发现两者均能提升词汇连贯性，但LLM更倾向于生成性修改。


<details>
  <summary>Details</summary>
Motivation: 探讨人类与不同LLM在第二语言写作校对中的表现差异及其一致性。

Method: 分析人类和三种LLM对相同第二语言写作的词汇和句法干预效果。

Result: 人类和LLM校对均提升词汇连贯性，LLM更倾向于多样化和复杂的修改，且三种LLM结果高度一致。

Conclusion: LLM校对在词汇和句法修改上表现一致且更具生成性，可能更适合提升写作质量。

Abstract: This study examines the lexical and syntactic interventions of human and LLM
proofreading aimed at improving overall intelligibility in identical second
language writings, and evaluates the consistency of outcomes across three LLMs
(ChatGPT-4o, Llama3.1-8b, Deepseek-r1-8b). Findings show that both human and
LLM proofreading enhance bigram lexical features, which may contribute to
better coherence and contextual connectedness between adjacent words. However,
LLM proofreading exhibits a more generative approach, extensively reworking
vocabulary and sentence structures, such as employing more diverse and
sophisticated vocabulary and incorporating a greater number of adjective
modifiers in noun phrases. The proofreading outcomes are highly consistent in
major lexical and syntactic features across the three models.

</details>


### [78] [Router-R1: Teaching LLMs Multi-Round Routing and Aggregation via Reinforcement Learning](https://arxiv.org/abs/2506.09033)
*Haozhen Zhang,Tao Feng,Jiaxuan You*

Main category: cs.CL

TL;DR: Router-R1是一个基于强化学习的框架，通过动态路由和聚合多个LLM的能力来处理复杂任务，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM路由器通常仅支持单轮、一对一的映射，无法充分利用多个LLM的互补优势。

Method: Router-R1将多LLM路由和聚合建模为序列决策过程，利用LLM的推理能力动态调用模型，并通过轻量级规则奖励优化性能与成本。

Result: 在七个通用和多跳QA基准测试中，Router-R1表现优于多个基线方法，同时保持强泛化能力和成本管理。

Conclusion: Router-R1通过强化学习实现了性能与成本的优化，为复杂任务的多LLM协作提供了有效解决方案。

Abstract: The rapid emergence of diverse large language models (LLMs) has spurred the
development of LLM routers that assign user queries to the most suitable model.
However, existing LLM routers typically perform a single-round, one-to-one
mapping (\textit{i.e.}, assigning each query to a single model in isolation),
which limits their capability to tackle complex tasks that demand the
complementary strengths of multiple LLMs. In this paper, we present
\textbf{Router-R1}, a reinforcement learning (RL)-based framework that
formulates multi-LLM routing and aggregation as a sequential decision process.
Router-R1 instantiates the router itself as a capable LLM, leveraging its
reasoning ability to interleave "think" actions (internal deliberation) with
"route" actions (dynamic model invocation), and integrates each response into
its evolving context. To guide learning, we employ a lightweight rule-based
reward comprising format rewards, final outcome rewards, and a novel cost
reward for performance and cost trade-off optimization, opening a pathway
toward optimizing performance-cost tradeoffs via RL. Router-R1 also conditions
only on simple model descriptors such as pricing, latency, and example
performance, enabling strong generalization to unseen model selection.
Experiments on seven general and multi-hop QA benchmarks show that Router-R1
outperforms over several strong baselines, achieving superior performance while
maintaining robust generalization and cost management.Code is available at
https://github.com/ulab-uiuc/Router-R1.

</details>


### [79] [Same Task, Different Circuits: Disentangling Modality-Specific Mechanisms in VLMs](https://arxiv.org/abs/2506.09047)
*Yaniv Nikankin,Dana Arad,Yossi Gandelsman,Yonatan Belinkov*

Main category: cs.CL

TL;DR: 视觉语言模型（VLM）在视觉任务（如图像计数）和文本任务（如文本计数）间存在性能差距。研究发现，两种模态的电路功能相似但数据位置处理不同，视觉数据表示在后期才与文本对齐。通过将后期视觉表征回传到早期层，性能差距减少了三分之一。


<details>
  <summary>Details</summary>
Motivation: 探究视觉语言模型在视觉和文本任务间性能差距的原因，并提出改进方法。

Method: 识别并比较不同模态的电路，分析数据位置处理差异；通过将后期视觉表征回传到早期层进行干预。

Result: 实验表明，该方法平均减少了两种模态间性能差距的三分之一。

Conclusion: 研究揭示了多模态性能差距的原因，并提出了一种无需训练的改进方法。

Abstract: Vision-Language models (VLMs) show impressive abilities to answer questions
on visual inputs (e.g., counting objects in an image), yet demonstrate higher
accuracies when performing an analogous task on text (e.g., counting words in a
text). We investigate this accuracy gap by identifying and comparing the
\textit{circuits} - the task-specific computational sub-graphs - in different
modalities. We show that while circuits are largely disjoint between
modalities, they implement relatively similar functionalities: the differences
lie primarily in processing modality-specific data positions (an image or a
text sequence). Zooming in on the image data representations, we observe they
become aligned with the higher-performing analogous textual representations
only towards later layers, too late in processing to effectively influence
subsequent positions. To overcome this, we patch the representations of visual
data tokens from later layers back into earlier layers. In experiments with
multiple tasks and models, this simple intervention closes a third of the
performance gap between the modalities, on average. Our analysis sheds light on
the multi-modal performance gap in VLMs and suggests a training-free approach
for reducing it.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [80] [Towards Reliable AR-Guided Surgical Navigation: Interactive Deformation Modeling with Data-Driven Biomechanics and Prompts](https://arxiv.org/abs/2506.08048)
*Zheng Han,Jun Zhou,Jialun Pei,Jing Qin,Yingfang Fan,Qi Dou*

Main category: cs.CV

TL;DR: 提出一种数据驱动的生物力学算法，结合人机交互机制，提升AR手术导航中变形建模的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有有限元方法计算成本高，且难以处理大范围解剖变化，导致AR导航不准确。

Method: 采用数据驱动的生物力学算法，并引入人机交互机制，允许外科医生动态修正模型。

Result: 算法在公开数据集上平均目标配准误差为3.42 mm，结合交互机制后降至2.78 mm。

Conclusion: 该框架在高效准确建模的同时增强了医工协作，为计算机辅助手术提供了更安全可靠的方案。

Abstract: In augmented reality (AR)-guided surgical navigation, preoperative organ
models are superimposed onto the patient's intraoperative anatomy to visualize
critical structures such as vessels and tumors. Accurate deformation modeling
is essential to maintain the reliability of AR overlays by ensuring alignment
between preoperative models and the dynamically changing anatomy. Although the
finite element method (FEM) offers physically plausible modeling, its high
computational cost limits intraoperative applicability. Moreover, existing
algorithms often fail to handle large anatomical changes, such as those induced
by pneumoperitoneum or ligament dissection, leading to inaccurate anatomical
correspondences and compromised AR guidance. To address these challenges, we
propose a data-driven biomechanics algorithm that preserves FEM-level accuracy
while improving computational efficiency. In addition, we introduce a novel
human-in-the-loop mechanism into the deformation modeling process. This enables
surgeons to interactively provide prompts to correct anatomical misalignments,
thereby incorporating clinical expertise and allowing the model to adapt
dynamically to complex surgical scenarios. Experiments on a publicly available
dataset demonstrate that our algorithm achieves a mean target registration
error of 3.42 mm. Incorporating surgeon prompts through the interactive
framework further reduces the error to 2.78 mm, surpassing state-of-the-art
methods in volumetric accuracy. These results highlight the ability of our
framework to deliver efficient and accurate deformation modeling while
enhancing surgeon-algorithm collaboration, paving the way for safer and more
reliable computer-assisted surgeries.

</details>


### [81] [ReCogDrive: A Reinforced Cognitive Framework for End-to-End Autonomous Driving](https://arxiv.org/abs/2506.08052)
*Yongkang Li,Kaixin Xiong,Xiangyu Guo,Fang Li,Sixu Yan,Gangwei Xu,Lijun Zhou,Long Chen,Haiyang Sun,Bing Wang,Guang Chen,Hangjun Ye,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: ReCogDrive提出了一种结合视觉语言模型（VLM）和扩散规划器的自动驾驶系统，通过三阶段训练解决领域差距、维度不匹配和模仿学习问题，显著提升了在长尾场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶在罕见和长尾场景中表现不佳，现有方法因领域差距、维度不匹配和模仿学习局限性而效果有限。

Method: 采用三阶段训练：1）用大规模驾驶问答数据集训练VLM；2）扩散规划器进行模仿学习；3）强化学习微调规划器。

Result: 在NAVSIM基准测试中达到89.6 PDMS，超越之前视觉方法5.6 PDMS。

Conclusion: ReCogDrive通过结合VLM和扩散规划器，显著提升了自动驾驶在复杂场景中的性能。

Abstract: Although end-to-end autonomous driving has made remarkable progress, its
performance degrades significantly in rare and long-tail scenarios. Recent
approaches attempt to address this challenge by leveraging the rich world
knowledge of Vision-Language Models (VLMs), but these methods suffer from
several limitations: (1) a significant domain gap between the pre-training data
of VLMs and real-world driving data, (2) a dimensionality mismatch between the
discrete language space and the continuous action space, and (3) imitation
learning tends to capture the average behavior present in the dataset, which
may be suboptimal even dangerous. In this paper, we propose ReCogDrive, an
autonomous driving system that integrates VLMs with diffusion planner, which
adopts a three-stage paradigm for training. In the first stage, we use a
large-scale driving question-answering datasets to train the VLMs, mitigating
the domain discrepancy between generic content and real-world driving
scenarios. In the second stage, we employ a diffusion-based planner to perform
imitation learning, mapping representations from the latent language space to
continuous driving actions. Finally, we fine-tune the diffusion planner using
reinforcement learning with NAVSIM non-reactive simulator, enabling the model
to generate safer, more human-like driving trajectories. We evaluate our
approach on the planning-oriented NAVSIM benchmark, achieving a PDMS of 89.6
and setting a new state-of-the-art that surpasses the previous vision-only SOTA
by 5.6 PDMS.

</details>


### [82] [CuRe: Cultural Gaps in the Long Tail of Text-to-Image Systems](https://arxiv.org/abs/2506.08071)
*Aniket Rege,Zinnia Nie,Mahesh Ramesh,Unmesh Raskar,Zhuoran Yu,Aditya Kusupati,Yong Jae Lee,Ramya Korlakai Vinayak*

Main category: cs.CV

TL;DR: CuRe是一个用于评估文本到图像（T2I）系统文化代表性的新基准，通过属性规范的边际效用作为人类判断的代理。


<details>
  <summary>Details</summary>
Motivation: 当前T2I系统训练数据偏向欧美文化，忽视全球南方文化，需量化评估这种偏见。

Method: 利用Wikimedia知识图谱构建包含300个文化实体的数据集，分为6个文化轴，通过文本条件的信息增益评估T2I系统。

Result: CuRe评分与人类对感知相似性、图文对齐和文化多样性的判断高度相关，适用于多种T2I系统和视觉语言模型。

Conclusion: CuRe为T2I系统的文化代表性提供了可扩展的评估工具，支持细粒度文化比较。

Abstract: Popular text-to-image (T2I) systems are trained on web-scraped data, which is
heavily Amero and Euro-centric, underrepresenting the cultures of the Global
South. To analyze these biases, we introduce CuRe, a novel and scalable
benchmarking and scoring suite for cultural representativeness that leverages
the marginal utility of attribute specification to T2I systems as a proxy for
human judgments. Our CuRe benchmark dataset has a novel categorical hierarchy
built from the crowdsourced Wikimedia knowledge graph, with 300 cultural
artifacts across 32 cultural subcategories grouped into six broad cultural axes
(food, art, fashion, architecture, celebrations, and people). Our dataset's
categorical hierarchy enables CuRe scorers to evaluate T2I systems by analyzing
their response to increasing the informativeness of text conditioning, enabling
fine-grained cultural comparisons. We empirically observe much stronger
correlations of our class of scorers to human judgments of perceptual
similarity, image-text alignment, and cultural diversity across image encoders
(SigLIP 2, AIMV2 and DINOv2), vision-language models (OpenCLIP, SigLIP 2,
Gemini 2.0 Flash) and state-of-the-art text-to-image systems, including three
variants of Stable Diffusion (1.5, XL, 3.5 Large), FLUX.1 [dev], Ideogram 2.0,
and DALL-E 3. The code and dataset is open-sourced and available at
https://aniketrege.github.io/cure/.

</details>


### [83] [IGraSS: Learning to Identify Infrastructure Networks from Satellite Imagery by Iterative Graph-constrained Semantic Segmentation](https://arxiv.org/abs/2506.08137)
*Oishee Bintey Hoque,Abhijin Adiga,Aniruddha Adiga,Siddharth Chaudhary,Madhav V. Marathe,S. S. Ravi,Kirti Rajagopalan,Amanda Wilson,Samarth Swarup*

Main category: cs.CV

TL;DR: IGraSS是一个结合语义分割和图优化的框架，用于改进不完整的地面真实数据，并提升运河和道路网络的映射精度。


<details>
  <summary>Details</summary>
Motivation: 现有的语义分割模型依赖于标注良好的遥感数据集，但地面真实数据的不完整性限制了其性能。基础设施网络（如运河和道路）具有图级属性（如可达性或连通性），可以利用这些属性改进地面真实数据。

Method: IGraSS结合了语义分割模块（处理RGB、NDWI和DEM数据）和图优化的地面真实数据细化模块。分割模块处理卫星图像块，细化模块将基础设施网络视为图进行操作。

Result: 实验表明，IGraSS将不可达运河段从约18%降至3%，使用细化后的地面真实数据显著提高了运河识别精度。IGraSS在道路网络中也表现出通用性。

Conclusion: IGraSS是一个强大的框架，既能细化噪声地面真实数据，又能从遥感图像中映射运河和道路网络，具有广泛的应用潜力。

Abstract: Accurate canal network mapping is essential for water management, including
irrigation planning and infrastructure maintenance. State-of-the-art semantic
segmentation models for infrastructure mapping, such as roads, rely on large,
well-annotated remote sensing datasets. However, incomplete or inadequate
ground truth can hinder these learning approaches. Many infrastructure networks
have graph-level properties such as reachability to a source (like canals) or
connectivity (roads) that can be leveraged to improve these existing ground
truth. This paper develops a novel iterative framework IGraSS, combining a
semantic segmentation module-incorporating RGB and additional modalities (NDWI,
DEM)-with a graph-based ground-truth refinement module. The segmentation module
processes satellite imagery patches, while the refinement module operates on
the entire data viewing the infrastructure network as a graph. Experiments show
that IGraSS reduces unreachable canal segments from around 18% to 3%, and
training with refined ground truth significantly improves canal identification.
IGraSS serves as a robust framework for both refining noisy ground truth and
mapping canal networks from remote sensing imagery. We also demonstrate the
effectiveness and generalizability of IGraSS using road networks as an example,
applying a different graph-theoretic constraint to complete road networks.

</details>


### [84] [Spectral Domain Neural Reconstruction for Passband FMCW Radars](https://arxiv.org/abs/2506.08163)
*Harshvardhan Takawale,Nirupam Roy*

Main category: cs.CV

TL;DR: SpINRv2是一个基于神经网络的框架，用于使用FMCW雷达进行高保真体积重建，通过频域前向模型和隐式神经表示提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决在高起始频率下相位混叠和子区间模糊问题，提升雷达重建的准确性和计算效率。

Method: 引入完全可微的频域前向模型和隐式神经表示（INR），结合稀疏性和平滑性正则化。

Result: SpINRv2在高频环境下显著优于传统和基于学习的基线方法。

Conclusion: SpINRv2为基于神经网络的雷达3D成像设定了新的基准。

Abstract: We present SpINRv2, a neural framework for high-fidelity volumetric
reconstruction using Frequency-Modulated Continuous-Wave (FMCW) radar.
Extending our prior work (SpINR), this version introduces enhancements that
allow accurate learning under high start frequencies-where phase aliasing and
sub-bin ambiguity become prominent. Our core contribution is a fully
differentiable frequency-domain forward model that captures the complex radar
response using closed-form synthesis, paired with an implicit neural
representation (INR) for continuous volumetric scene modeling. Unlike
time-domain baselines, SpINRv2 directly supervises the complex frequency
spectrum, preserving spectral fidelity while drastically reducing computational
overhead. Additionally, we introduce sparsity and smoothness regularization to
disambiguate sub-bin ambiguities that arise at fine range resolutions.
Experimental results show that SpINRv2 significantly outperforms both classical
and learning-based baselines, especially under high-frequency regimes,
establishing a new benchmark for neural radar-based 3D imaging.

</details>


### [85] [Surgeon Style Fingerprinting and Privacy Risk Quantification via Discrete Diffusion Models in a Vision-Language-Action Framework](https://arxiv.org/abs/2506.08185)
*Huixin Zhan,Jason H. Moore*

Main category: cs.CV

TL;DR: 本文提出了一种基于离散扩散框架和视觉-语言-动作（VLA）管道的方法，用于建模外科医生在机器人手术中的个性化风格指纹，同时探讨了隐私风险。


<details>
  <summary>Details</summary>
Motivation: 外科医生因训练、经验和行为差异而具有独特的操作风格，但现有AI系统常忽略这一个性化信号。本文旨在捕捉并建模这些风格差异。

Method: 通过离散扩散框架结合VLA管道，将手势预测建模为结构化序列去噪任务，输入包括内窥镜视频、手术意图语言和隐私感知的外科医生身份与技能嵌入。

Result: 在JIGSAWS数据集上验证了方法能准确重建手势序列并学习到每位外科医生的独特运动指纹，但发现更个性化的嵌入会增加身份泄露风险。

Conclusion: 个性化嵌入虽能提升性能，但也增加了隐私风险，需在手术建模中平衡个性化与隐私保护。

Abstract: Surgeons exhibit distinct operating styles due to differences in training,
experience, and motor behavior - yet current AI systems often ignore this
personalization signal. We propose a novel approach to model fine-grained,
surgeon-specific fingerprinting in robotic surgery using a discrete diffusion
framework integrated with a vision-language-action (VLA) pipeline. Our method
formulates gesture prediction as a structured sequence denoising task,
conditioned on multimodal inputs including endoscopic video, surgical intent
language, and a privacy-aware embedding of surgeon identity and skill.
Personalized surgeon fingerprinting is encoded through natural language prompts
using third-party language models, allowing the model to retain individual
behavioral style without exposing explicit identity. We evaluate our method on
the JIGSAWS dataset and demonstrate that it accurately reconstructs gesture
sequences while learning meaningful motion fingerprints unique to each surgeon.
To quantify the privacy implications of personalization, we perform membership
inference attacks and find that more expressive embeddings improve task
performance but simultaneously increase susceptibility to identity leakage.
These findings demonstrate that while personalized embeddings improve
performance, they also increase vulnerability to identity leakage, revealing
the importance of balancing personalization with privacy risk in surgical
modeling. Code is available at:
https://github.com/huixin-zhan-ai/Surgeon_style_fingerprinting.

</details>


### [86] [Open World Scene Graph Generation using Vision Language Models](https://arxiv.org/abs/2506.08189)
*Amartya Dutta,Kazi Sajeed Mehrab,Medha Sawhney,Abhilash Neog,Mridul Khurana,Sepideh Fatemi,Aanish Pradhan,M. Maruf,Ismini Lourentzou,Arka Daw,Anuj Karpatne*

Main category: cs.CV

TL;DR: Open-World SGG框架利用预训练的视觉语言模型（VLMs）进行零样本场景图生成，无需额外训练，适用于开放世界的新对象和关系。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖数据集特定监督或微调，限制了在开放世界中的适用性。Open-World SGG旨在解决这一问题。

Method: 结合多模态提示、嵌入对齐和轻量级配对优化策略，将SGG转化为零样本结构化推理问题。

Result: 在Visual Genome、Open Images V6和PSG数据集上验证了预训练VLMs的关系理解能力。

Conclusion: Open-World SGG展示了预训练VLMs在无需任务级训练的情况下进行关系理解的潜力。

Abstract: Scene-Graph Generation (SGG) seeks to recognize objects in an image and
distill their salient pairwise relationships. Most methods depend on
dataset-specific supervision to learn the variety of interactions, restricting
their usefulness in open-world settings, involving novel objects and/or
relations. Even methods that leverage large Vision Language Models (VLMs)
typically require benchmark-specific fine-tuning. We introduce Open-World SGG,
a training-free, efficient, model-agnostic framework that taps directly into
the pretrained knowledge of VLMs to produce scene graphs with zero additional
learning. Casting SGG as a zero-shot structured-reasoning problem, our method
combines multimodal prompting, embedding alignment, and a lightweight
pair-refinement strategy, enabling inference over unseen object vocabularies
and relation sets. To assess this setting, we formalize an Open-World
evaluation protocol that measures performance when no SGG-specific data have
been observed either in terms of objects and relations. Experiments on Visual
Genome, Open Images V6, and the Panoptic Scene Graph (PSG) dataset demonstrate
the capacity of pretrained VLMs to perform relational understanding without
task-level training.

</details>


### [87] [Generative Learning of Differentiable Object Models for Compositional Interpretation of Complex Scenes](https://arxiv.org/abs/2506.08191)
*Antoni Nowinowski,Krzysztof Krawiec*

Main category: cs.CV

TL;DR: 论文扩展了DVP架构，使其能处理多物体场景，并通过潜在空间采样和多种训练模式提升训练效率，在重建质量和物体分解能力上优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决原始DVP无法处理多物体场景的问题，并通过潜在空间的利用缓解图像空间重建损失中的训练困难。

Method: 扩展DVP架构，支持多物体场景；利用潜在空间采样生成额外训练样本；设计图像空间和潜在空间的多重损失函数。

Result: 在重建质量和物体分解能力上优于基线模型（MONet和LIVE），并分析了损失函数梯度对训练的影响。

Conclusion: 扩展后的DVP在多物体场景中表现优异，但可微分渲染在自编码器中仍存在局限性，需进一步研究。

Abstract: This study builds on the architecture of the Disentangler of Visual Priors
(DVP), a type of autoencoder that learns to interpret scenes by decomposing the
perceived objects into independent visual aspects of shape, size, orientation,
and color appearance. These aspects are expressed as latent parameters which
control a differentiable renderer that performs image reconstruction, so that
the model can be trained end-to-end with gradient using reconstruction loss. In
this study, we extend the original DVP so that it can handle multiple objects
in a scene. We also exploit the interpretability of its latent by using the
decoder to sample additional training examples and devising alternative
training modes that rely on loss functions defined not only in the image space,
but also in the latent space. This significantly facilitates training, which is
otherwise challenging due to the presence of extensive plateaus in the
image-space reconstruction loss. To examine the performance of this approach,
we propose a new benchmark featuring multiple 2D objects, which subsumes the
previously proposed Multi-dSprites dataset while being more parameterizable. We
compare the DVP extended in these ways with two baselines (MONet and LIVE) and
demonstrate its superiority in terms of reconstruction quality and capacity to
decompose overlapping objects. We also analyze the gradients induced by the
considered loss functions, explain how they impact the efficacy of training,
and discuss the limitations of differentiable rendering in autoencoders and the
ways in which they can be addressed.

</details>


### [88] [GIQ: Benchmarking 3D Geometric Reasoning of Vision Foundation Models with Simulated and Real Polyhedra](https://arxiv.org/abs/2506.08194)
*Mateusz Michalkiewicz,Anekha Sokhal,Tadeusz Michalkiewicz,Piotr Pawlikowski,Mahsa Baktashmotlagh,Varun Jampani,Guha Balakrishnan*

Main category: cs.CV

TL;DR: GIQ是一个评估视觉和视觉语言基础模型几何推理能力的综合基准，揭示了当前模型在几何理解上的显著不足。


<details>
  <summary>Details</summary>
Motivation: 尽管单目3D重建方法和视觉语言模型在标准基准上表现优异，但其对几何属性的真实理解尚不明确，因此需要专门的评估工具。

Method: GIQ包含224种多样多面体的合成和真实图像，通过单目3D重建、3D对称检测、心理旋转测试和零样本形状分类任务进行系统实验。

Result: 当前模型在重建基础几何形状、详细几何区分任务中表现不佳，视觉语言助手在复杂多面体上准确率极低。

Conclusion: GIQ为未来几何智能研究提供了结构化平台，有助于解决几何表示学习中的关键问题。

Abstract: Monocular 3D reconstruction methods and vision-language models (VLMs)
demonstrate impressive results on standard benchmarks, yet their true
understanding of geometric properties remains unclear. We introduce GIQ , a
comprehensive benchmark specifically designed to evaluate the geometric
reasoning capabilities of vision and vision-language foundation models. GIQ
comprises synthetic and real-world images of 224 diverse polyhedra - including
Platonic, Archimedean, Johnson, and Catalan solids, as well as stellations and
compound shapes - covering varying levels of complexity and symmetry. Through
systematic experiments involving monocular 3D reconstruction, 3D symmetry
detection, mental rotation tests, and zero-shot shape classification tasks, we
reveal significant shortcomings in current models. State-of-the-art
reconstruction algorithms trained on extensive 3D datasets struggle to
reconstruct even basic geometric forms accurately. While foundation models
effectively detect specific 3D symmetry elements via linear probing, they
falter significantly in tasks requiring detailed geometric differentiation,
such as mental rotation. Moreover, advanced vision-language assistants exhibit
remarkably low accuracy on complex polyhedra, systematically misinterpreting
basic properties like face geometry, convexity, and compound structures. GIQ is
publicly available, providing a structured platform to highlight and address
critical gaps in geometric intelligence, facilitating future progress in
robust, geometry-aware representation learning.

</details>


### [89] [A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation](https://arxiv.org/abs/2506.08210)
*Andrew Z. Wang,Songwei Ge,Tero Karras,Ming-Yu Liu,Yogesh Balaji*

Main category: cs.CV

TL;DR: 研究探讨了使用现代仅解码器LLM作为文本编码器在文本到图像扩散模型中的效果，发现层归一化平均嵌入优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型仍使用过时的T5和CLIP作为文本编码器，研究旨在评估现代LLM的潜力。

Method: 构建标准化训练和评估流程，训练27个模型，比较12种文本编码器，分析嵌入提取方法、LLM变体和模型大小的影响。

Result: 传统最后一层嵌入效果较差，层归一化平均嵌入显著提升复杂提示的对齐性，多数LLM优于T5基线。

Conclusion: 现代LLM作为文本编码器在文本到图像生成中表现更优，尤其适用于复杂视觉语言推理任务。

Abstract: Both text-to-image generation and large language models (LLMs) have made
significant advancements. However, many text-to-image models still employ the
somewhat outdated T5 and CLIP as their text encoders. In this work, we
investigate the effectiveness of using modern decoder-only LLMs as text
encoders for text-to-image diffusion models. We build a standardized training
and evaluation pipeline that allows us to isolate and evaluate the effect of
different text embeddings. We train a total of 27 text-to-image models with 12
different text encoders to analyze the critical aspects of LLMs that could
impact text-to-image generation, including the approaches to extract
embeddings, different LLMs variants, and model sizes. Our experiments reveal
that the de facto way of using last-layer embeddings as conditioning leads to
inferior performance. Instead, we explore embeddings from various layers and
find that using layer-normalized averaging across all layers significantly
improves alignment with complex prompts. Most LLMs with this conditioning
outperform the baseline T5 model, showing enhanced performance in advanced
visio-linguistic reasoning skills.

</details>


### [90] [Using Satellite Images And Self-supervised Machine Learning Networks To Detect Water Hidden Under Vegetation](https://arxiv.org/abs/2506.08214)
*Ioannis Iakovidis,Zahra Kalantari,Amir Hossein Payberah,Fernando Jaramillo,Francisco Pena Escobar*

Main category: cs.CV

TL;DR: 论文提出了一种结合深度聚类和负采样的自监督方法，用于雷达卫星图像的水陆分割，无需人工标注，并通过集成模型提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决湿地监测中人工标注数据成本高、耗时长的问题。

Method: 采用深度聚类和负采样的自监督训练方法，并实现集成模型以减少方差。

Result: 自监督集成模型在测试集上的IoU指标比全监督模型提高了0.02。

Conclusion: 自监督方法在湿地监测中具有潜力，集成策略进一步提升了性能。

Abstract: In recent years the wide availability of high-resolution radar satellite
images along with the advancement of computer vision models have enabled the
remote monitoring of the surface area of wetlands. However, these models
require large amounts of manually annotated satellite images, which are slow
and expensive to produce. To overcome this problem, self-supervised training
methods have been deployed to train models without using annotated data. In
this paper we use a combination of deep clustering and negative sampling to
train a model to segment radar satellite images into areas that separate water
from land without the use of any manual annotations. Furthermore, we implement
an ensemble version of the model to reduce variance and improve performance.
Compared to a single fully-supervised model using the same architecture, our
ensemble of self-supervised models achieves a 0.02 improvement in the
Intersection Over Union metric over our test dataset.

</details>


### [91] [Jamais Vu: Exposing the Generalization Gap in Supervised Semantic Correspondence](https://arxiv.org/abs/2506.08220)
*Octave Mariotti,Zhipeng Du,Yash Bhalgat,Oisin Mac Aodha,Hakan Bilen*

Main category: cs.CV

TL;DR: 论文提出了一种通过单目深度估计将2D关键点提升到3D空间的方法，以学习密集对应关系，并引入SPair-U数据集评估泛化能力。实验表明该方法在未见关键点上显著优于监督基线。


<details>
  <summary>Details</summary>
Motivation: 现有监督语义对应方法泛化能力有限，仅能处理稀疏标注的关键点，无法学习密集对应关系。

Method: 利用单目深度估计将2D关键点映射到3D空间，构建连续规范流形，无需3D监督或相机标注。

Result: 模型在未见关键点上显著优于监督基线，且无监督基线在跨数据集泛化中表现更优。

Conclusion: 提出的方法能有效学习鲁棒对应关系，尤其在泛化能力上表现突出。

Abstract: Semantic correspondence (SC) aims to establish semantically meaningful
matches across different instances of an object category. We illustrate how
recent supervised SC methods remain limited in their ability to generalize
beyond sparsely annotated training keypoints, effectively acting as keypoint
detectors. To address this, we propose a novel approach for learning dense
correspondences by lifting 2D keypoints into a canonical 3D space using
monocular depth estimation. Our method constructs a continuous canonical
manifold that captures object geometry without requiring explicit 3D
supervision or camera annotations. Additionally, we introduce SPair-U, an
extension of SPair-71k with novel keypoint annotations, to better assess
generalization. Experiments not only demonstrate that our model significantly
outperforms supervised baselines on unseen keypoints, highlighting its
effectiveness in learning robust correspondences, but that unsupervised
baselines outperform supervised counterparts when generalized across different
datasets.

</details>


### [92] [A Good CREPE needs more than just Sugar: Investigating Biases in Compositional Vision-Language Benchmarks](https://arxiv.org/abs/2506.08227)
*Vishaal Udandarao,Mehdi Cherti,Shyamgopal Karthik,Jenia Jitsev,Samuel Albanie,Matthias Bethge*

Main category: cs.CV

TL;DR: 论文分析了17个用于评估视觉语言模型组合理解能力的基准测试，发现其设计存在偏差，导致简单启发式方法与CLIP模型表现相当，并提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估现有视觉语言模型组合理解能力基准测试的有效性，揭示其设计中的偏差问题。

Method: 方法包括分析基准测试的数据来源和构建过程，识别偏差，并通过实验验证简单启发式方法的性能。

Result: 结果显示基准测试存在分布不对称性，导致其无法有效衡量组合理解能力。

Conclusion: 结论是提出改进基准测试设计的建议，以减少偏差并增强其鲁棒性。

Abstract: We investigate 17 benchmarks (e.g. SugarCREPE, VALSE) commonly used for
measuring compositional understanding capabilities of vision-language models
(VLMs). We scrutinize design choices in their construction, including data
source (e.g. MS-COCO) and curation procedures (e.g. constructing negative
images/captions), uncovering several inherent biases across most benchmarks. We
find that blind heuristics (e.g. token-length, log-likelihood under a language
model) perform on par with CLIP models, indicating that these benchmarks do not
effectively measure compositional understanding. We demonstrate that the
underlying factor is a distribution asymmetry between positive and negative
images/captions, induced by the benchmark construction procedures. To mitigate
these issues, we provide a few key recommendations for constructing more robust
vision-language compositional understanding benchmarks, that would be less
prone to such simple attacks.

</details>


### [93] [Highly Compressed Tokenizer Can Generate Without Training](https://arxiv.org/abs/2506.08257)
*L. Lao Beyer,T. Li,X. Chen,S. Karaman,K. He*

Main category: cs.CV

TL;DR: 1D图像标记器通过高度压缩的一维序列表示图像，支持通过启发式操作实现图像编辑和生成能力。


<details>
  <summary>Details</summary>
Motivation: 探索1D图像标记器在图像编辑和生成中的潜力，利用其高度压缩的潜在空间实现精细操作。

Method: 使用基于梯度的测试时优化和即插即用的损失函数（如重建或CLIP相似性）构建图像生成流程。

Result: 实现了无需训练生成模型的多样化和逼真样本生成，适用于修复和文本引导的图像编辑。

Conclusion: 1D图像标记器在图像编辑和生成中表现出高效性和灵活性，为未来研究提供了新方向。

Abstract: Commonly used image tokenizers produce a 2D grid of spatially arranged
tokens. In contrast, so-called 1D image tokenizers represent images as highly
compressed one-dimensional sequences of as few as 32 discrete tokens. We find
that the high degree of compression achieved by a 1D tokenizer with vector
quantization enables image editing and generative capabilities through
heuristic manipulation of tokens, demonstrating that even very crude
manipulations -- such as copying and replacing tokens between latent
representations of images -- enable fine-grained image editing by transferring
appearance and semantic attributes. Motivated by the expressivity of the 1D
tokenizer's latent space, we construct an image generation pipeline leveraging
gradient-based test-time optimization of tokens with plug-and-play loss
functions such as reconstruction or CLIP similarity. Our approach is
demonstrated for inpainting and text-guided image editing use cases, and can
generate diverse and realistic samples without requiring training of any
generative model.

</details>


### [94] [Seeing Voices: Generating A-Roll Video from Audio with Mirage](https://arxiv.org/abs/2506.08279)
*Aditi Sundararaman,Amogh Adishesha,Andrew Jaegle,Dan Bigioi,Hyoung-Kyu Song,Jon Kyl,Justin Mao,Kevin Lan,Mojtaba Komeili,ShahRukh Athar,Sheila Babayan,Stanislau Beliasau,William Buchwalter*

Main category: cs.CV

TL;DR: Mirage是一个音频到视频的基础模型，能够根据音频输入生成逼真、富有表现力的视频。它结合语音合成技术，实现多模态视频生成。


<details>
  <summary>Details</summary>
Motivation: 视频创作中音频与视觉的和谐整合至关重要，但现有方法要么忽略音频，要么局限于特定领域（如重新配音）。Mirage旨在解决这一问题。

Method: 提出一种统一的训练方法，基于自注意力机制，支持从零开始或基于现有权重的音频到视频生成模型训练。

Result: Mirage生成的视频在主观质量上优于其他方法，且保持了音频到视频生成的通用性。

Conclusion: Mirage为音频驱动的视频生成提供了高质量、通用的解决方案，鼓励读者体验其生成效果。

Abstract: From professional filmmaking to user-generated content, creators and
consumers have long recognized that the power of video depends on the
harmonious integration of what we hear (the video's audio track) with what we
see (the video's image sequence). Current approaches to video generation either
ignore sound to focus on general-purpose but silent image sequence generation
or address both visual and audio elements but focus on restricted application
domains such as re-dubbing. We introduce Mirage, an audio-to-video foundation
model that excels at generating realistic, expressive output imagery from
scratch given an audio input. When integrated with existing methods for speech
synthesis (text-to-speech, or TTS), Mirage results in compelling multimodal
video. When trained on audio-video footage of people talking (A-roll) and
conditioned on audio containing speech, Mirage generates video of people
delivering a believable interpretation of the performance implicit in input
audio. Our central technical contribution is a unified method for training
self-attention-based audio-to-video generation models, either from scratch or
given existing weights. This methodology allows Mirage to retain generality as
an approach to audio-to-video generation while producing outputs of superior
subjective quality to methods that incorporate audio-specific architectures or
loss components specific to people, speech, or details of how images or audio
are captured. We encourage readers to watch and listen to the results of Mirage
for themselves (see paper and comments for links).

</details>


### [95] [SEMA: a Scalable and Efficient Mamba like Attention via Token Localization and Averaging](https://arxiv.org/abs/2506.08297)
*Nhat Thanh Tran,Fanghui Xue,Shuai Zhang,Jiancheng Lyu,Yunling Zheng,Yingyong Qi,Jack Xin*

Main category: cs.CV

TL;DR: 论文提出了一种名为SEMA的新型注意力机制，解决了传统线性注意力无法聚焦的问题，并在图像分类任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统注意力机制在计算复杂度和聚焦能力上存在不足，尤其是线性注意力无法有效聚焦。论文通过数学定义广义注意力，并基于其分散特性设计了SEMA。

Method: 提出SEMA，利用令牌定位避免分散，并通过算术平均捕获全局注意力特性，结合Mamba形式的注意力设计。

Result: 在Imagenet-1k上，SEMA在更大规模的图像上表现优于现有视觉Mamba模型，且参数规模相近。

Conclusion: SEMA是一种可扩展且高效的注意力机制，为计算机视觉任务提供了新的解决方案。

Abstract: Attention is the critical component of a transformer. Yet the quadratic
computational complexity of vanilla full attention in the input size and the
inability of its linear attention variant to focus have been challenges for
computer vision tasks. We provide a mathematical definition of generalized
attention and formulate both vanilla softmax attention and linear attention
within the general framework. We prove that generalized attention disperses,
that is, as the number of keys tends to infinity, the query assigns equal
weights to all keys. Motivated by the dispersion property and recent
development of Mamba form of attention, we design Scalable and Efficient Mamba
like Attention (SEMA) which utilizes token localization to avoid dispersion and
maintain focusing, complemented by theoretically consistent arithmetic
averaging to capture global aspect of attention. We support our approach on
Imagenet-1k where classification results show that SEMA is a scalable and
effective alternative beyond linear attention, outperforming recent vision
Mamba models on increasingly larger scales of images at similar model parameter
sizes.

</details>


### [96] [OpenRR-1k: A Scalable Dataset for Real-World Reflection Removal](https://arxiv.org/abs/2506.08299)
*Kangning Yang,Ling Ouyang,Huiming Sun,Jie Cai,Lan Fu,Jiaming Ding,Chiu Man Ho,Zibo Meng*

Main category: cs.CV

TL;DR: 论文提出了一种新颖的反射数据集收集方法，构建了高质量、对齐且多样化的OpenRR-1k数据集，并通过实验验证了其对反射去除技术的提升效果。


<details>
  <summary>Details</summary>
Motivation: 现有反射去除技术因缺乏高质量的真实场景数据集而受限。

Method: 提出了一种便捷、经济且可扩展的数据收集范式，构建了包含1,000对高质量图像的OpenRR-1k数据集。

Result: 实验表明，该数据集能显著提升反射去除方法在真实复杂环境中的鲁棒性。

Conclusion: OpenRR-1k数据集为反射去除技术提供了高质量的真实场景数据支持。

Abstract: Reflection removal technology plays a crucial role in photography and
computer vision applications. However, existing techniques are hindered by the
lack of high-quality in-the-wild datasets. In this paper, we propose a novel
paradigm for collecting reflection datasets from a fresh perspective. Our
approach is convenient, cost-effective, and scalable, while ensuring that the
collected data pairs are of high quality, perfectly aligned, and represent
natural and diverse scenarios. Following this paradigm, we collect a
Real-world, Diverse, and Pixel-aligned dataset (named OpenRR-1k dataset), which
contains 1,000 high-quality transmission-reflection image pairs collected in
the wild. Through the analysis of several reflection removal methods and
benchmark evaluation experiments on our dataset, we demonstrate its
effectiveness in improving robustness in challenging real-world environments.
Our dataset is available at https://github.com/caijie0620/OpenRR-1k.

</details>


### [97] [Hyperspectral Image Classification via Transformer-based Spectral-Spatial Attention Decoupling and Adaptive Gating](https://arxiv.org/abs/2506.08324)
*Guandong Li,Mengxia Ye*

Main category: cs.CV

TL;DR: STNet提出了一种新型网络架构，通过空间-光谱Transformer模块的创新设计，有效解决了高光谱图像分类中的过拟合和泛化能力问题。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像分类面临高维数据、地物稀疏分布和光谱冗余等挑战，导致过拟合和泛化能力受限。

Method: STNet采用空间-光谱Transformer模块，通过显式解耦空间和光谱注意力，并结合两种功能不同的门控机制（自适应注意力融合门控和GFFN）。

Result: STNet在IN、UP和KSC数据集上表现优于主流方法，提升了特征提取和融合能力，同时减少了小样本和高噪声场景的过拟合风险。

Conclusion: STNet在不增加网络深度或宽度的情况下，显著提升了模型表示能力，为高光谱图像分类提供了高效解决方案。

Abstract: Deep neural networks face several challenges in hyperspectral image
classification, including high-dimensional data, sparse distribution of ground
objects, and spectral redundancy, which often lead to classification
overfitting and limited generalization capability. To more effectively extract
and fuse spatial context with fine spectral information in hyperspectral image
(HSI) classification, this paper proposes a novel network architecture called
STNet. The core advantage of STNet stems from the dual innovative design of its
Spatial-Spectral Transformer module: first, the fundamental explicit decoupling
of spatial and spectral attention ensures targeted capture of key information
in HSI; second, two functionally distinct gating mechanisms perform intelligent
regulation at both the fusion level of attention flows (adaptive attention
fusion gating) and the internal level of feature transformation (GFFN). This
characteristic demonstrates superior feature extraction and fusion capabilities
compared to traditional convolutional neural networks, while reducing
overfitting risks in small-sample and high-noise scenarios. STNet enhances
model representation capability without increasing network depth or width. The
proposed method demonstrates superior performance on IN, UP, and KSC datasets,
outperforming mainstream hyperspectral image classification approaches.

</details>


### [98] [Locating Tennis Ball Impact on the Racket in Real Time Using an Event Camera](https://arxiv.org/abs/2506.08327)
*Yuto Kase,Kai Ishibe,Ryoma Yasuda,Yudai Washida,Sakiko Hashimoto*

Main category: cs.CV

TL;DR: 提出了一种使用事件相机实时定位网球拍击球位置的方法，解决了高速相机内存消耗大和手动数字化耗时的问题。


<details>
  <summary>Details</summary>
Motivation: 在网球等球拍运动中，准确测量击球位置对分析球员表现和个性化装备设计至关重要，但现有方法存在内存消耗大和人工误差问题。

Method: 采用事件相机，结合传统计算机视觉技术和原创的事件处理（PATS），通过三个步骤识别击球时间、球拍轮廓和球的位置。

Result: 实验结果在测量网球运动员表现的允许范围内，计算时间足够短，适合实时应用。

Conclusion: 该方法高效、低内存消耗，适用于长时间实时监测球员表现。

Abstract: In racket sports, such as tennis, locating the ball's position at impact is
important in clarifying player and equipment characteristics, thereby aiding in
personalized equipment design. High-speed cameras are used to measure the
impact location; however, their excessive memory consumption limits prolonged
scene capture, and manual digitization for position detection is time-consuming
and prone to human error. These limitations make it difficult to effectively
capture the entire playing scene, hindering the ability to analyze the player's
performance. We propose a method for locating the tennis ball impact on the
racket in real time using an event camera. Event cameras efficiently measure
brightness changes (called `events') with microsecond accuracy under high-speed
motion while using lower memory consumption. These cameras enable users to
continuously monitor their performance over extended periods. Our method
consists of three identification steps: time range of swing, timing at impact,
and contours of ball and racket. Conventional computer vision techniques are
utilized along with an original event-based processing to detect the timing at
impact (PATS: the amount of polarity asymmetry in time symmetry). The results
of the experiments were within the permissible range for measuring tennis
players' performance. Moreover, the computation time was sufficiently short for
real-time applications.

</details>


### [99] [How Much To Guide: Revisiting Adaptive Guidance in Classifier-Free Guidance Text-to-Vision Diffusion Models](https://arxiv.org/abs/2506.08351)
*Huixuan Zhang,Junzhe Zhang,Xiaojun Wan*

Main category: cs.CV

TL;DR: 提出了一种名为Step AG的自适应引导策略，通过限制分类器自由引导在前几个去噪步骤中应用，显著提升了生成速度，同时保持了图像质量和文本对齐。


<details>
  <summary>Details</summary>
Motivation: 分类器自由引导方法虽然流行，但其需要两倍于无条件生成的步骤，成本较高。现有自适应引导方法缺乏分析和实证支持，无法通用。

Method: 提出Step AG策略，限制分类器自由引导在前几个去噪步骤中应用，适用于多种扩散模型。

Result: 实验表明，Step AG在图像质量和文本对齐方面表现良好，平均提速20%至30%，且在不同设置和模型中一致有效。

Conclusion: Step AG是一种简单通用的自适应引导策略，显著提升了生成效率，适用于多种扩散模型。

Abstract: With the rapid development of text-to-vision generation diffusion models,
classifier-free guidance has emerged as the most prevalent method for
conditioning. However, this approach inherently requires twice as many steps
for model forwarding compared to unconditional generation, resulting in
significantly higher costs. While previous study has introduced the concept of
adaptive guidance, it lacks solid analysis and empirical results, making
previous method unable to be applied to general diffusion models. In this work,
we present another perspective of applying adaptive guidance and propose Step
AG, which is a simple, universally applicable adaptive guidance strategy. Our
evaluations focus on both image quality and image-text alignment. whose results
indicate that restricting classifier-free guidance to the first several
denoising steps is sufficient for generating high-quality, well-conditioned
images, achieving an average speedup of 20% to 30%. Such improvement is
consistent across different settings such as inference steps, and various
models including video generation models, highlighting the superiority of our
method.

</details>


### [100] [MedMoE: Modality-Specialized Mixture of Experts for Medical Vision-Language Understanding](https://arxiv.org/abs/2506.08356)
*Shivang Chopra,Lingchao Mao,Gabriela Sanchez-Rodriguez,Andrew J Feola,Jing Li,Zsolt Kira*

Main category: cs.CV

TL;DR: MedMoE是一个动态适应不同医学成像模态的视觉语言处理框架，通过Mixture-of-Experts模块和多尺度特征提取，提升模态对齐和检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言框架采用统一的局部特征提取策略，忽视了不同模态的特定需求，导致诊断信息提取不足。

Method: MedMoE基于Swin Transformer提取多尺度图像特征，通过条件Mixture-of-Experts模块动态路由特征到专门的分支，捕获模态特定的视觉语义。

Result: 实验表明，MedMoE在多种医学基准测试中提升了模态对齐和检索性能。

Conclusion: MedMoE证明了模态专用视觉表征在临床视觉语言系统中的价值，无需推理时的模态特定监督。

Abstract: Different medical imaging modalities capture diagnostic information at
varying spatial resolutions, from coarse global patterns to fine-grained
localized structures. However, most existing vision-language frameworks in the
medical domain apply a uniform strategy for local feature extraction,
overlooking the modality-specific demands. In this work, we present MedMoE, a
modular and extensible vision-language processing framework that dynamically
adapts visual representation based on the diagnostic context. MedMoE
incorporates a Mixture-of-Experts (MoE) module conditioned on the report type,
which routes multi-scale image features through specialized expert branches
trained to capture modality-specific visual semantics. These experts operate
over feature pyramids derived from a Swin Transformer backbone, enabling
spatially adaptive attention to clinically relevant regions. This framework
produces localized visual representations aligned with textual descriptions,
without requiring modality-specific supervision at inference. Empirical results
on diverse medical benchmarks demonstrate that MedMoE improves alignment and
retrieval performance across imaging modalities, underscoring the value of
modality-specialized visual representations in clinical vision-language
systems.

</details>


### [101] [Image Demoiréing Using Dual Camera Fusion on Mobile Phones](https://arxiv.org/abs/2506.08361)
*Yanting Mei,Zhilu Zhang,Xiaohe Wu,Wangmeng Zuo*

Main category: cs.CV

TL;DR: 论文提出了一种利用双摄像头融合进行图像去摩尔纹的方法（DCID），通过超广角图像辅助广角图像去除摩尔纹，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现代智能手机通常配备双摄像头，且超广角图像在广角图像出现摩尔纹时能提供正常的颜色和纹理。

Method: 提出了一种高效的DCID方法，包括轻量级超广角图像编码器和快速两阶段图像对齐方式，并构建了一个包含约9,000个样本的真实世界数据集。

Result: 实验表明，该方法在去摩尔纹任务上优于现有最先进方法。

Conclusion: DCID方法通过双摄像头融合有效解决了大范围摩尔纹问题，代码和数据集已开源。

Abstract: When shooting electronic screens, moir\'e patterns usually appear in captured
images, which seriously affects the image quality. Existing image demoir\'eing
methods face great challenges in removing large and heavy moir\'e. To address
the issue, we propose to utilize Dual Camera fusion for Image Demoir\'eing
(DCID), \ie, using the ultra-wide-angle (UW) image to assist the moir\'e
removal of wide-angle (W) image. This is inspired by two motivations: (1) the
two lenses are commonly equipped with modern smartphones, (2) the UW image
generally can provide normal colors and textures when moir\'e exists in the W
image mainly due to their different focal lengths. In particular, we propose an
efficient DCID method, where a lightweight UW image encoder is integrated into
an existing demoir\'eing network and a fast two-stage image alignment manner is
present. Moreover, we construct a large-scale real-world dataset with diverse
mobile phones and monitors, containing about 9,000 samples. Experiments on the
dataset show our method performs better than state-of-the-art methods. Code and
dataset are available at https://github.com/Mrduckk/DCID.

</details>


### [102] [SECOND: Mitigating Perceptual Hallucination in Vision-Language Models via Selective and Contrastive Decoding](https://arxiv.org/abs/2506.08391)
*Woohyeon Park,Woojin Kim,Jaeik Kim,Jaeyoung Do*

Main category: cs.CV

TL;DR: SECOND是一种通过选择性对比解码减少视觉语言模型中物体幻觉的新方法，利用多尺度视觉信息提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型因物体幻觉问题性能受限，需更准确视觉理解。

Method: 提出SECOND方法，通过选择性对比解码和多尺度视觉信息整合，减少幻觉。

Result: SECOND显著减少幻觉，在多个基准测试中表现优异。

Conclusion: 多尺度视觉信息应用潜力巨大，SECOND方法优于现有技术。

Abstract: Despite significant advancements in Vision-Language Models (VLMs), the
performance of existing VLMs remains hindered by object hallucination, a
critical challenge to achieving accurate visual understanding. To address this
issue, we propose SECOND: Selective and Contrastive Decoding, a novel approach
that enables VLMs to effectively leverage multi-scale visual information with
an object-centric manner, closely aligning with human visual perception. SECOND
progressively selects and integrates multi-scale visual information,
facilitating a more precise interpretation of images. By contrasting these
visual information iteratively, SECOND significantly reduces perceptual
hallucinations and outperforms a wide range of benchmarks. Our theoretical
analysis and experiments highlight the largely unexplored potential of
multi-scale application in VLMs, showing that prioritizing and contrasting
across scales outperforms existing methods.

</details>


### [103] [RadioDUN: A Physics-Inspired Deep Unfolding Network for Radio Map Estimation](https://arxiv.org/abs/2506.08418)
*Taiqin Chen,Zikun Zhou,Zheng Fang,Wenzhen Zou,Kanjun Liu,Ke Chen,Yongbing Zhang,Yaowei Wang*

Main category: cs.CV

TL;DR: 论文提出了一种基于稀疏信号恢复的无线电地图估计方法，结合物理传播模型和深度学习，通过动态重加权模块和阴影损失提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以结合无线电地图的物理特性，稀疏样本下构建密集无线电地图具有挑战性。

Method: 将无线电地图估计建模为稀疏信号恢复问题，结合物理传播模型分解优化子问题，提出RadioDUN网络和动态重加权模块（DRM），并设计阴影损失。

Result: 实验表明，该方法优于现有技术。

Conclusion: 提出的RadioDUN方法有效结合物理特性，显著提升了无线电地图估计性能。

Abstract: The radio map represents the spatial distribution of spectrum resources
within a region, supporting efficient resource allocation and interference
mitigation. However, it is difficult to construct a dense radio map as a
limited number of samples can be measured in practical scenarios. While
existing works have used deep learning to estimate dense radio maps from sparse
samples, they are hard to integrate with the physical characteristics of the
radio map. To address this challenge, we cast radio map estimation as the
sparse signal recovery problem. A physical propagation model is further
incorporated to decompose the problem into multiple factor optimization
sub-problems, thereby reducing recovery complexity. Inspired by the existing
compressive sensing methods, we propose the Radio Deep Unfolding Network
(RadioDUN) to unfold the optimization process, achieving adaptive parameter
adjusting and prior fitting in a learnable manner. To account for the radio
propagation characteristics, we develop a dynamic reweighting module (DRM) to
adaptively model the importance of each factor for the radio map. Inspired by
the shadowing factor in the physical propagation model, we integrate
obstacle-related factors to express the obstacle-induced signal stochastic
decay. The shadowing loss is further designed to constrain the factor
prediction and act as a supplementary supervised objective, which enhances the
performance of RadioDUN. Extensive experiments have been conducted to
demonstrate that the proposed method outperforms the state-of-the-art methods.
Our code will be made publicly available upon publication.

</details>


### [104] [Better Reasoning with Less Data: Enhancing VLMs Through Unified Modality Scoring](https://arxiv.org/abs/2506.08429)
*Mingjie Xu,Andrew Estornell,Hongzheng Yang,Yuzhi Zhao,Zhaowei Zhu,Qi Xuan,Jiaheng Wei*

Main category: cs.CV

TL;DR: 论文提出SCALE方法，通过跨模态评估框架提升视觉语言模型的数据质量，解决图像与文本对齐噪声和文本模糊问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型的效果依赖高质量数据集，但现有数据集存在图像与文本对齐噪声和文本模糊问题，影响模型性能。

Method: SCALE方法结合跨模态评估框架，为数据条目分配任务、生成多类型标题，并评估对齐、清晰度等指标。

Result: 研究发现现有单模态评估方法低估任务关键样本，而生成标题能有效将多模态任务转化为统一文本模态。

Conclusion: SCALE通过数据质量驱动选择，提升视觉语言模型的训练效果和鲁棒性。

Abstract: The application of visual instruction tuning and other post-training
techniques has significantly enhanced the capabilities of Large Language Models
(LLMs) in visual understanding, enriching Vision-Language Models (VLMs) with
more comprehensive visual language datasets. However, the effectiveness of VLMs
is highly dependent on large-scale, high-quality datasets that ensure precise
recognition and accurate reasoning. Two key challenges hinder progress: (1)
noisy alignments between images and the corresponding text, which leads to
misinterpretation, and (2) ambiguous or misleading text, which obscures visual
content. To address these challenges, we propose SCALE (Single modality data
quality and Cross modality Alignment Evaluation), a novel quality-driven data
selection pipeline for VLM instruction tuning datasets. Specifically, SCALE
integrates a cross-modality assessment framework that first assigns each data
entry to its appropriate vision-language task, generates general and
task-specific captions (covering scenes, objects, style, etc.), and evaluates
the alignment, clarity, task rarity, text coherence, and image clarity of each
entry based on the generated captions. We reveal that: (1) current unimodal
quality assessment methods evaluate one modality while overlooking the rest,
which can underestimate samples essential for specific tasks and discard the
lower-quality instances that help build model robustness; and (2) appropriately
generated image captions provide an efficient way to transfer the image-text
multimodal task into a unified text modality.

</details>


### [105] [Enhancing Motion Dynamics of Image-to-Video Models via Adaptive Low-Pass Guidance](https://arxiv.org/abs/2506.08456)
*June Suk Choi,Kyungmin Lee,Sihyun Yu,Yisol Choi,Jinwoo Shin,Kimin Lee*

Main category: cs.CV

TL;DR: 论文提出了一种自适应低通引导（ALG）方法，解决了图像到视频（I2V）生成中动态性不足的问题，显著提升了视频的动态表现。


<details>
  <summary>Details</summary>
Motivation: 现有I2V方法在微调预训练T2V模型时，常导致生成的视频动态性不足，原因是输入图像的高频细节过早影响采样过程。

Method: 提出ALG方法，通过在去噪早期阶段自适应地调制输入图像的频率内容，应用低通滤波。

Result: 实验表明，ALG显著提升了视频的动态性（VBench-I2V测试中动态度平均提升36%），同时保持了图像质量和文本对齐。

Conclusion: ALG是一种简单有效的解决方案，能够在I2V生成中平衡动态性和图像质量。

Abstract: Recent text-to-video (T2V) models have demonstrated strong capabilities in
producing high-quality, dynamic videos. To improve the visual controllability,
recent works have considered fine-tuning pre-trained T2V models to support
image-to-video (I2V) generation. However, such adaptation frequently suppresses
motion dynamics of generated outputs, resulting in more static videos compared
to their T2V counterparts. In this work, we analyze this phenomenon and
identify that it stems from the premature exposure to high-frequency details in
the input image, which biases the sampling process toward a shortcut trajectory
that overfits to the static appearance of the reference image. To address this,
we propose adaptive low-pass guidance (ALG), a simple fix to the I2V model
sampling procedure to generate more dynamic videos without compromising
per-frame image quality. Specifically, ALG adaptively modulates the frequency
content of the conditioning image by applying low-pass filtering at the early
stage of denoising. Extensive experiments demonstrate that ALG significantly
improves the temporal dynamics of generated videos, while preserving image
fidelity and text alignment. Especially, under VBench-I2V test suite, ALG
achieves an average improvement of 36% in dynamic degree without a significant
drop in video quality or image fidelity.

</details>


### [106] [MARMOT: Masked Autoencoder for Modeling Transient Imaging](https://arxiv.org/abs/2506.08470)
*Siyuan Shen,Ziheng Wang,Xingyue Peng,Suan Xia,Ruiqian Li,Shiying Li,Jingyi Yu*

Main category: cs.CV

TL;DR: 提出了一种名为MARMOT的掩码自编码器，用于非视距（NLOS）瞬态成像，通过自监督预训练和Transformer架构提升隐藏物体重建效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法未充分利用数据集中的先验知识，且多为优化体积密度或表面重建，缺乏通用性。

Method: 使用Transformer编码器-解码器架构，通过扫描模式掩码（SPM）自监督预训练，预测完整测量。

Result: 在合成数据集TransVerse上预训练的MARMOT，在下游任务中表现优于现有方法。

Conclusion: MARMOT通过自监督学习和特征迁移，显著提升了NLOS瞬态成像的效率和效果。

Abstract: Pretrained models have demonstrated impressive success in many modalities
such as language and vision. Recent works facilitate the pretraining paradigm
in imaging research. Transients are a novel modality, which are captured for an
object as photon counts versus arrival times using a precisely time-resolved
sensor. In particular for non-line-of-sight (NLOS) scenarios, transients of
hidden objects are measured beyond the sensor's direct line of sight. Using
NLOS transients, the majority of previous works optimize volume density or
surfaces to reconstruct the hidden objects and do not transfer priors learned
from datasets. In this work, we present a masked autoencoder for modeling
transient imaging, or MARMOT, to facilitate NLOS applications. Our MARMOT is a
self-supervised model pretrianed on massive and diverse NLOS transient
datasets. Using a Transformer-based encoder-decoder, MARMOT learns features
from partially masked transients via a scanning pattern mask (SPM), where the
unmasked subset is functionally equivalent to arbitrary sampling, and predicts
full measurements. Pretrained on TransVerse-a synthesized transient dataset of
500K 3D models-MARMOT adapts to downstream imaging tasks using direct feature
transfer or decoder finetuning. Comprehensive experiments are carried out in
comparisons with state-of-the-art methods. Quantitative and qualitative results
demonstrate the efficiency of our MARMOT.

</details>


### [107] [Context-aware TFL: A Universal Context-aware Contrastive Learning Framework for Temporal Forgery Localization](https://arxiv.org/abs/2506.08493)
*Qilin Yin,Wei Lu,Xiangyang Luo,Xiaochun Cao*

Main category: cs.CV

TL;DR: 提出了一种通用上下文感知对比学习框架（UniCaCLF），用于解决视频中部分片段被篡改的时域伪造定位问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究多将深度伪造检测视为分类任务，忽略了视频中部分片段被篡改的情况，而时域伪造定位（TFL）更符合实际应用需求。

Method: 采用监督对比学习，通过异常检测识别伪造片段，并提出上下文感知感知层和自适应上下文更新器，构建上下文感知对比目标。

Result: 在五个公开数据集上的实验表明，UniCaCLF显著优于现有算法。

Conclusion: UniCaCLF通过上下文感知对比学习，有效提升了时域伪造定位的精确性。

Abstract: Most research efforts in the multimedia forensics domain have focused on
detecting forgery audio-visual content and reached sound achievements. However,
these works only consider deepfake detection as a classification task and
ignore the case where partial segments of the video are tampered with. Temporal
forgery localization (TFL) of small fake audio-visual clips embedded in real
videos is still challenging and more in line with realistic application
scenarios. To resolve this issue, we propose a universal context-aware
contrastive learning framework (UniCaCLF) for TFL. Our approach leverages
supervised contrastive learning to discover and identify forged instants by
means of anomaly detection, allowing for the precise localization of temporal
forged segments. To this end, we propose a novel context-aware perception layer
that utilizes a heterogeneous activation operation and an adaptive context
updater to construct a context-aware contrastive objective, which enhances the
discriminability of forged instant features by contrasting them with genuine
instant features in terms of their distances to the global context. An
efficient context-aware contrastive coding is introduced to further push the
limit of instant feature distinguishability between genuine and forged instants
in a supervised sample-by-sample manner, suppressing the cross-sample influence
to improve temporal forgery localization performance. Extensive experimental
results over five public datasets demonstrate that our proposed UniCaCLF
significantly outperforms the state-of-the-art competing algorithms.

</details>


### [108] [MLVTG: Mamba-Based Feature Alignment and LLM-Driven Purification for Multi-Modal Video Temporal Grounding](https://arxiv.org/abs/2506.08512)
*Zhiyi Zhu,Xiaoyu Wu,Zihao Liu,Linlin Yang*

Main category: cs.CV

TL;DR: MLVTG提出了一种新的视频时序定位框架，通过MambaAligner和LLMRefiner模块解决了现有Transformer方法的冗余注意力和多模态对齐问题，实现了更精确的定位。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的视频时序定位方法存在冗余注意力和多模态对齐不足的问题，影响了定位的准确性。

Method: MLVTG框架包含MambaAligner和LLMRefiner两个模块：前者用Vision Mamba块替代Transformer建模时序依赖，后者利用预训练LLM的特定层增强多模态对齐。

Result: 在QVHighlights、Charades-STA和TVSum数据集上，MLVTG实现了最先进的性能，显著优于现有基线。

Conclusion: MLVTG通过双对齐策略（时序建模和语义净化）显著提升了视频时序定位的精度，为多模态对齐提供了新思路。

Abstract: Video Temporal Grounding (VTG), which aims to localize video clips
corresponding to natural language queries, is a fundamental yet challenging
task in video understanding. Existing Transformer-based methods often suffer
from redundant attention and suboptimal multi-modal alignment. To address these
limitations, we propose MLVTG, a novel framework that integrates two key
modules: MambaAligner and LLMRefiner. MambaAligner uses stacked Vision Mamba
blocks as a backbone instead of Transformers to model temporal dependencies and
extract robust video representations for multi-modal alignment. LLMRefiner
leverages the specific frozen layer of a pre-trained Large Language Model (LLM)
to implicitly transfer semantic priors, enhancing multi-modal alignment without
fine-tuning. This dual alignment strategy, temporal modeling via structured
state-space dynamics and semantic purification via textual priors, enables more
precise localization. Extensive experiments on QVHighlights, Charades-STA, and
TVSum demonstrate that MLVTG achieves state-of-the-art performance and
significantly outperforms existing baselines.

</details>


### [109] [Robust Visual Localization via Semantic-Guided Multi-Scale Transformer](https://arxiv.org/abs/2506.08526)
*Zhongtao Tian,Wenhao Huang,Zhidong Chen,Xiao Wei Sun*

Main category: cs.CV

TL;DR: 提出了一种结合多尺度特征学习和语义场景理解的框架，用于动态环境中的视觉定位，通过分层Transformer和跨尺度注意力提升性能。


<details>
  <summary>Details</summary>
Motivation: 动态环境中光照变化、恶劣天气和移动物体会破坏外观线索，现有绝对姿态回归方法难以保持一致。

Method: 采用分层Transformer与跨尺度注意力融合几何细节和上下文线索，结合语义监督学习视图不变特征。

Result: 在TartanAir数据集上，该方法在动态物体、光照变化和遮挡等挑战性场景中优于现有姿态回归方法。

Conclusion: 多尺度处理与语义指导的结合为动态环境中的鲁棒视觉定位提供了有效策略。

Abstract: Visual localization remains challenging in dynamic environments where
fluctuating lighting, adverse weather, and moving objects disrupt appearance
cues. Despite advances in feature representation, current absolute pose
regression methods struggle to maintain consistency under varying conditions.
To address this challenge, we propose a framework that synergistically combines
multi-scale feature learning with semantic scene understanding. Our approach
employs a hierarchical Transformer with cross-scale attention to fuse geometric
details and contextual cues, preserving spatial precision while adapting to
environmental changes. We improve the performance of this architecture with
semantic supervision via neural scene representation during training, guiding
the network to learn view-invariant features that encode persistent structural
information while suppressing complex environmental interference. Experiments
on TartanAir demonstrate that our approach outperforms existing pose regression
methods in challenging scenarios with dynamic objects, illumination changes,
and occlusions. Our findings show that integrating multi-scale processing with
semantic guidance offers a promising strategy for robust visual localization in
real-world dynamic environments.

</details>


### [110] [LiftVSR: Lifting Image Diffusion to Video Super-Resolution via Hybrid Temporal Modeling with Only 4$\times$RTX 4090s](https://arxiv.org/abs/2506.08529)
*Xijun Wang,Xin Li,Bingchen Li,Zhibo Chen*

Main category: cs.CV

TL;DR: LiftVSR是一种高效的视频超分辨率框架，通过结合动态时间注意力和注意力记忆缓存，显著提升了时间一致性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长时间视频中时间一致性不足且计算成本过高，需要改进。

Method: 提出混合时间建模机制，包括动态时间注意力（DTA）和注意力记忆缓存（AMC），并引入非对称采样策略。

Result: 在多个VSR基准测试中表现优异，计算成本显著降低。

Conclusion: LiftVSR在保持高性能的同时，大幅降低了计算资源需求。

Abstract: Diffusion models have significantly advanced video super-resolution (VSR) by
enhancing perceptual quality, largely through elaborately designed temporal
modeling to ensure inter-frame consistency. However, existing methods usually
suffer from limited temporal coherence and prohibitively high computational
costs (e.g., typically requiring over 8 NVIDIA A100-80G GPUs), especially for
long videos. In this work, we propose LiftVSR, an efficient VSR framework that
leverages and elevates the image-wise diffusion prior from PixArt-$\alpha$,
achieving state-of-the-art results using only 4$\times$RTX 4090 GPUs. To
balance long-term consistency and efficiency, we introduce a hybrid temporal
modeling mechanism that decomposes temporal learning into two complementary
components: (i) Dynamic Temporal Attention (DTA) for fine-grained temporal
modeling within short frame segment ($\textit{i.e.}$, low complexity), and (ii)
Attention Memory Cache (AMC) for long-term temporal modeling across segments
($\textit{i.e.}$, consistency). Specifically, DTA identifies multiple token
flows across frames within multi-head query and key tokens to warp inter-frame
contexts in the value tokens. AMC adaptively aggregates historical segment
information via a cache unit, ensuring long-term coherence with minimal
overhead. To further stabilize the cache interaction during inference, we
introduce an asymmetric sampling strategy that mitigates feature mismatches
arising from different diffusion sampling steps. Extensive experiments on
several typical VSR benchmarks have demonstrated that LiftVSR achieves
impressive performance with significantly lower computational costs.

</details>


### [111] [TrajFlow: Multi-modal Motion Prediction via Flow Matching](https://arxiv.org/abs/2506.08541)
*Qi Yan,Brian Zhang,Yutong Zhang,Daniel Yang,Joshua White,Di Chen,Jiachao Liu,Langechuan Liu,Binnan Zhuang,Shaoshuai Shi,Renjie Liao*

Main category: cs.CV

TL;DR: TrajFlow是一种基于流匹配的运动预测框架，通过单次推理预测多模态轨迹，显著降低计算开销，并在大规模实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中高效准确的运动预测对安全和决策至关重要，现有生成方法在多模态预测和计算效率上存在不足。

Method: 提出TrajFlow框架，结合流匹配技术和Plackett-Luce分布的排序损失，设计自条件训练技术以提升泛化能力。

Result: 在Waymo Open Motion Dataset上实现最先进性能，验证了其在安全关键应用中的有效性。

Conclusion: TrajFlow通过创新方法解决了多模态预测的效率和准确性问题，适用于自动驾驶领域。

Abstract: Efficient and accurate motion prediction is crucial for ensuring safety and
informed decision-making in autonomous driving, particularly under dynamic
real-world conditions that necessitate multi-modal forecasts. We introduce
TrajFlow, a novel flow matching-based motion prediction framework that
addresses the scalability and efficiency challenges of existing generative
trajectory prediction methods. Unlike conventional generative approaches that
employ i.i.d. sampling and require multiple inference passes to capture diverse
outcomes, TrajFlow predicts multiple plausible future trajectories in a single
pass, significantly reducing computational overhead while maintaining coherence
across predictions. Moreover, we propose a ranking loss based on the
Plackett-Luce distribution to improve uncertainty estimation of predicted
trajectories. Additionally, we design a self-conditioning training technique
that reuses the model's own predictions to construct noisy inputs during a
second forward pass, thereby improving generalization and accelerating
inference. Extensive experiments on the large-scale Waymo Open Motion Dataset
(WOMD) demonstrate that TrajFlow achieves state-of-the-art performance across
various key metrics, underscoring its effectiveness for safety-critical
autonomous driving applications. The code and other details are available on
the project website https://traj-flow.github.io/.

</details>


### [112] [Convergence of Spectral Principal Paths: How Deep Networks Distill Linear Representations from Noisy Inputs](https://arxiv.org/abs/2506.08543)
*Bowei Tian,Xuntao Lyu,Meng Liu,Hongyi Wang,Ang Li*

Main category: cs.CV

TL;DR: 论文提出Input-Space Linearity Hypothesis (ISLH)，认为概念对齐的方向源于输入空间，并随深度选择性增强。通过Spectral Principal Path (SPP)框架，展示了深度网络如何沿主导谱方向逐步提炼线性表示，并在Vision-Language Models (VLMs)中验证其多模态鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 提升AI的透明性和控制性，从神经元或电路转向结构化语义方向，以对齐人类可解释概念。

Method: 提出ISLH假设，并引入SPP框架，理论结合实证验证深度网络中表示的形成。

Result: SPP框架展示了深度网络沿谱方向逐步提炼线性表示的能力，并在VLMs中验证了多模态鲁棒性。

Conclusion: 研究为深度网络中表示形成的结构化理论提供了基础，有助于提升AI的鲁棒性、公平性和透明性。

Abstract: High-level representations have become a central focus in enhancing AI
transparency and control, shifting attention from individual neurons or
circuits to structured semantic directions that align with human-interpretable
concepts. Motivated by the Linear Representation Hypothesis (LRH), we propose
the Input-Space Linearity Hypothesis (ISLH), which posits that concept-aligned
directions originate in the input space and are selectively amplified with
increasing depth. We then introduce the Spectral Principal Path (SPP)
framework, which formalizes how deep networks progressively distill linear
representations along a small set of dominant spectral directions. Building on
this framework, we further demonstrate the multimodal robustness of these
representations in Vision-Language Models (VLMs). By bridging theoretical
insights with empirical validation, this work advances a structured theory of
representation formation in deep networks, paving the way for improving AI
robustness, fairness, and transparency.

</details>


### [113] [From Pixels to Graphs: using Scene and Knowledge Graphs for HD-EPIC VQA Challenge](https://arxiv.org/abs/2506.08553)
*Agnese Taluzzi,Davide Gesualdi,Riccardo Santambrogio,Chiara Plizzari,Francesca Palermo,Simone Mentasti,Matteo Matteucci*

Main category: cs.CV

TL;DR: SceneNet和KnowledgeNet是用于HD-EPIC VQA Challenge 2025的方法，分别利用场景图和外部常识知识提升视觉问答性能，组合后达到44.21%的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决复杂的第一人称视觉问答任务，需要捕捉细粒度对象交互、空间关系和引入高层次语义连接。

Method: SceneNet使用多模态大语言模型生成场景图；KnowledgeNet结合ConceptNet的常识知识。

Result: 在HD-EPIC基准的七个类别中表现优异，组合方法准确率达44.21%。

Conclusion: 两种方法的结合有效提升了复杂第一人称视觉问答任务的性能。

Abstract: This report presents SceneNet and KnowledgeNet, our approaches developed for
the HD-EPIC VQA Challenge 2025. SceneNet leverages scene graphs generated with
a multi-modal large language model (MLLM) to capture fine-grained object
interactions, spatial relationships, and temporally grounded events. In
parallel, KnowledgeNet incorporates ConceptNet's external commonsense knowledge
to introduce high-level semantic connections between entities, enabling
reasoning beyond directly observable visual evidence. Each method demonstrates
distinct strengths across the seven categories of the HD-EPIC benchmark, and
their combination within our framework results in an overall accuracy of 44.21%
on the challenge, highlighting its effectiveness for complex egocentric VQA
tasks.

</details>


### [114] [Towards Cross-Subject EMG Pattern Recognition via Dual-Branch Adversarial Feature Disentanglement](https://arxiv.org/abs/2506.08555)
*Xinyue Niu,Akira Furui*

Main category: cs.CV

TL;DR: 提出一种通过特征解耦消除校准需求的跨主体肌电图（EMG）模式识别方法，实现无需模型校准的跨主体泛化。


<details>
  <summary>Details</summary>
Motivation: 跨主体EMG模式识别因主体间肌肉解剖、电极放置和信号特征的差异面临挑战，传统方法依赖主体特定校准数据，耗时且不实用。

Method: 提出端到端双分支对抗神经网络，将EMG特征解耦为模式特定和主体特定成分，实现模式识别和个体识别的同步。

Result: 实验表明，模型在未见用户数据上表现稳健，优于多种基线方法。

Conclusion: 该方法为无需校准的跨主体EMG模式识别提供了新视角，并展示了其在任务无关生物识别系统中的潜力。

Abstract: Cross-subject electromyography (EMG) pattern recognition faces significant
challenges due to inter-subject variability in muscle anatomy, electrode
placement, and signal characteristics. Traditional methods rely on
subject-specific calibration data to adapt models to new users, an approach
that is both time-consuming and impractical for large-scale, real-world
deployment. This paper presents an approach to eliminate calibration
requirements through feature disentanglement, enabling effective cross-subject
generalization. We propose an end-to-end dual-branch adversarial neural network
that simultaneously performs pattern recognition and individual identification
by disentangling EMG features into pattern-specific and subject-specific
components. The pattern-specific components facilitate robust pattern
recognition for new users without model calibration, while the subject-specific
components enable downstream applications such as task-invariant biometric
identification. Experimental results demonstrate that the proposed model
achieves robust performance on data from unseen users, outperforming various
baseline methods in cross-subject scenarios. Overall, this study offers a new
perspective for cross-subject EMG pattern recognition without model calibration
and highlights the proposed model's potential for broader applications, such as
task-independent biometric systems.

</details>


### [115] [Hierarchical Neural Collapse Detection Transformer for Class Incremental Object Detection](https://arxiv.org/abs/2506.08562)
*Duc Thanh Pham,Hong Dang Nguyen,Nhat Minh Nguyen Quoc,Linh Ngo Van,Sang Dinh Viet,Duc Anh Nguyen*

Main category: cs.CV

TL;DR: Hier-DETR是一个新颖的增量目标检测框架，结合了神经崩溃和层次标签关系，以提高效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中新物体不断出现，需要检测模型持续学习而不受灾难性遗忘影响，现有IOD模型性能不足且推理时间长。

Method: 利用神经崩溃处理不平衡数据集，并结合类别标签的层次关系。

Result: 提出的Hier-DETR框架在效率和性能上具有竞争力。

Conclusion: Hier-DETR为增量目标检测提供了一种高效且性能优越的解决方案。

Abstract: Recently, object detection models have witnessed notable performance
improvements, particularly with transformer-based models. However, new objects
frequently appear in the real world, requiring detection models to continually
learn without suffering from catastrophic forgetting. Although Incremental
Object Detection (IOD) has emerged to address this challenge, these existing
models are still not practical due to their limited performance and prolonged
inference time. In this paper, we introduce a novel framework for IOD, called
Hier-DETR: Hierarchical Neural Collapse Detection Transformer, ensuring both
efficiency and competitive performance by leveraging Neural Collapse for
imbalance dataset and Hierarchical relation of classes' labels.

</details>


### [116] [Generating Vision-Language Navigation Instructions Incorporated Fine-Grained Alignment Annotations](https://arxiv.org/abs/2506.08566)
*Yibo Cui,Liang Xie,Yu Zhao,Jiawei Sun,Erwei Yin*

Main category: cs.CV

TL;DR: FCA-NIG框架通过自动生成具有细粒度跨模态标注的导航指令，解决了现有数据集中子指令和实体级对齐不足的问题，显著提升了VLN智能体的导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLN数据集缺乏细粒度的跨模态对齐标注（如子指令和实体级对齐），限制了智能体在复杂导航任务中的准确性。

Method: 提出FCA-NIG框架，通过子轨迹分割、地标检测、指令生成和实体选择等步骤，自动生成带有子指令-轨迹和实体-地标对齐标注的FCA-R2R数据集。

Result: 实验表明，使用FCA-R2R训练的VLN智能体（如SF、EnvDrop等）性能显著提升，子指令和实体对齐分别增强了状态感知和导航泛化能力。

Conclusion: FCA-NIG无需人工标注即可生成高质量、可扩展的训练数据，推动了复杂导航任务中细粒度跨模态学习的发展。

Abstract: Vision-Language Navigation (VLN) enables intelligent agents to navigate
environments by integrating visual perception and natural language
instructions, yet faces significant challenges due to the scarcity of
fine-grained cross-modal alignment annotations. Existing datasets primarily
focus on global instruction-trajectory matching, neglecting
sub-instruction-level and entity-level alignments critical for accurate
navigation action decision-making. To address this limitation, we propose
FCA-NIG, a generative framework that automatically constructs navigation
instructions with dual-level fine-grained cross-modal annotations. In this
framework, an augmented trajectory is first divided into sub-trajectories,
which are then processed through GLIP-based landmark detection, crafted
instruction construction, OFA-Speaker based R2R-like instruction generation,
and CLIP-powered entity selection, generating sub-instruction-trajectory pairs
with entity-landmark annotations. Finally, these sub-pairs are aggregated to
form a complete instruction-trajectory pair. The framework generates the
FCA-R2R dataset, the first large-scale augmentation dataset featuring precise
sub-instruction-sub-trajectory and entity-landmark alignments. Extensive
experiments demonstrate that training with FCA-R2R significantly improves the
performance of multiple state-of-the-art VLN agents, including SF, EnvDrop,
RecBERT, and HAMT. Incorporating sub-instruction-trajectory alignment enhances
agents' state awareness and decision accuracy, while entity-landmark alignment
further boosts navigation performance and generalization. These results
highlight the effectiveness of FCA-NIG in generating high-quality, scalable
training data without manual annotation, advancing fine-grained cross-modal
learning in complex navigation tasks.

</details>


### [117] [Diversity-Guided MLP Reduction for Efficient Large Vision Transformers](https://arxiv.org/abs/2506.08591)
*Chengchao Shen,Hourun Zhu,Gongfan Fang,Jianxin Wang,Xinchao Wang*

Main category: cs.CV

TL;DR: 论文提出了一种多样性引导的MLP缩减方法（DGMR），通过Gram-Schmidt权重剪枝策略显著减少大型视觉Transformer的参数，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 大型Transformer模型参数过多导致计算和内存成本高昂，研究发现MLP模块占据大部分参数，因此需要一种高效压缩方法。

Method: 采用Gram-Schmidt权重剪枝策略消除MLP隐藏层的冗余神经元，同时保留权重多样性以在蒸馏过程中恢复性能。

Result: 实验表明，DGMR方法在多个大型视觉Transformer上实现了超过57%的参数和FLOPs减少，且性能损失极小。EVA-CLIP-E（4.4B）模型参数和FLOPs减少71.5%，性能无下降。

Conclusion: DGMR方法高效压缩大型视觉Transformer，显著减少计算资源需求，同时保持性能，为大规模模型部署提供了实用解决方案。

Abstract: Transformer models achieve excellent scaling property, where the performance
is improved with the increment of model capacity. However, large-scale model
parameters lead to an unaffordable cost of computing and memory. We analyze
popular transformer architectures and find that multilayer perceptron (MLP)
modules take up the majority of model parameters. To this end, we focus on the
recoverability of the compressed models and propose a Diversity-Guided MLP
Reduction (DGMR) method to significantly reduce the parameters of large vision
transformers with only negligible performance degradation. Specifically, we
conduct a Gram-Schmidt weight pruning strategy to eliminate redundant neurons
of MLP hidden layer, while preserving weight diversity for better performance
recover during distillation. Compared to the model trained from scratch, our
pruned model only requires 0.06\% data of LAION-2B (for the training of large
vision transformers) without labels (ImageNet-1K) to recover the original
performance. Experimental results on several state-of-the-art large vision
transformers demonstrate that our method achieves a more than 57.0\% parameter
and FLOPs reduction in a near lossless manner. Notably, for EVA-CLIP-E (4.4B),
our method accomplishes a 71.5\% parameter and FLOPs reduction without
performance degradation. The source code and trained weights are available at
https://github.com/visresearch/DGMR.

</details>


### [118] [Transformers Meet Hyperspectral Imaging: A Comprehensive Study of Models, Challenges and Open Problems](https://arxiv.org/abs/2506.08596)
*Guyang Zhang,Waleed Abdulla*

Main category: cs.CV

TL;DR: 本文是第一篇专注于基于Transformer的高光谱图像分类的端到端综述，总结了300多篇论文，分析了Transformer在HSI中的应用及其挑战。


<details>
  <summary>Details</summary>
Motivation: Transformer在长距离依赖学习中表现出色，但在高光谱成像（HSI）中的应用仍处于起步阶段，需要系统性的综述来指导研究。

Method: 通过分析300多篇论文，对HSI分类流程的每个阶段（如预处理、特征提取、自注意力变体等）进行分类，并对比不同设计选择。

Result: 总结了HSI领域的进展与挑战，如标注数据稀缺、计算开销大等，并提出了未来的研究方向。

Conclusion: 本文旨在帮助研究者选择适合下一代HSI应用的Transformer组件，并提出了轻量化、鲁棒性和可解释性等研究重点。

Abstract: Transformers have become the architecture of choice for learning long-range
dependencies, yet their adoption in hyperspectral imaging (HSI) is still
emerging. We reviewed more than 300 papers published up to 2025 and present the
first end-to-end survey dedicated to Transformer-based HSI classification. The
study categorizes every stage of a typical pipeline-pre-processing, patch or
pixel tokenization, positional encoding, spatial-spectral feature extraction,
multi-head self-attention variants, skip connections, and loss design-and
contrasts alternative design choices with the unique spatial-spectral
properties of HSI. We map the field's progress against persistent obstacles:
scarce labeled data, extreme spectral dimensionality, computational overhead,
and limited model explainability. Finally, we outline a research agenda
prioritizing valuable public data sets, lightweight on-edge models,
illumination and sensor shifts robustness, and intrinsically interpretable
attention mechanisms. Our goal is to guide researchers in selecting, combining,
or extending Transformer components that are truly fit for purpose for
next-generation HSI applications.

</details>


### [119] [Towards Class-wise Fair Adversarial Training via Anti-Bias Soft Label Distillation](https://arxiv.org/abs/2506.08611)
*Shiji Zhao,Chi Chen,Ranjie Duan,Xizhe Wang,Xingxing Wei*

Main category: cs.CV

TL;DR: 论文提出了一种名为ABSLD的方法，通过调整教师模型软标签的平滑度，提升对抗鲁棒性的公平性。


<details>
  <summary>Details</summary>
Motivation: 对抗训练（AT）和对抗鲁棒性蒸馏（ARD）存在鲁棒公平性问题，即模型对某些类别的对抗鲁棒性较强，而对其他类别较弱。本文旨在探索这一问题的原因并提出解决方案。

Method: 提出了Anti-Bias Soft Label Distillation（ABSLD），通过为不同类别分配不同温度值，调整教师模型软标签的平滑度，从而减少学生模型在不同类别上的误差风险差距。

Result: 实验表明，ABSLD在鲁棒性和公平性的综合表现上优于现有方法。

Conclusion: ABSLD是一种有效的提升对抗鲁棒性公平性的方法，且易于与其他样本级方法结合。

Abstract: Adversarial Training (AT) is widely recognized as an effective approach to
enhance the adversarial robustness of Deep Neural Networks. As a variant of AT,
Adversarial Robustness Distillation (ARD) has shown outstanding performance in
enhancing the robustness of small models. However, both AT and ARD face robust
fairness issue: these models tend to display strong adversarial robustness
against some classes (easy classes) while demonstrating weak adversarial
robustness against others (hard classes). This paper explores the underlying
factors of this problem and points out the smoothness degree of soft labels for
different classes significantly impacts the robust fairness from both empirical
observation and theoretical analysis. Based on the above exploration, we
propose Anti-Bias Soft Label Distillation (ABSLD) within the Knowledge
Distillation framework to enhance the adversarial robust fairness.
Specifically, ABSLD adaptively reduces the student's error risk gap between
different classes, which is accomplished by adjusting the class-wise smoothness
degree of teacher's soft labels during the training process, and the adjustment
is managed by assigning varying temperatures to different classes.
Additionally, as a label-based approach, ABSLD is highly adaptable and can be
integrated with the sample-based methods. Extensive experiments demonstrate
ABSLD outperforms state-of-the-art methods on the comprehensive performance of
robustness and fairness.

</details>


### [120] [Data-Efficient Challenges in Visual Inductive Priors: A Retrospective](https://arxiv.org/abs/2506.08612)
*Robert-Jan Bruintjes,Attila Lengyel,Osman Semih Kayhan,Davide Zambrano,Nergis Tömen,Hadi Jamali-Rad,Jan van Gemert*

Main category: cs.CV

TL;DR: 论文探讨了在数据不足情况下提升深度学习模型性能的方法，通过组织数据受限挑战赛，发现模型集成和数据增强是关键。


<details>
  <summary>Details</summary>
Motivation: 研究在数据不足情况下如何通过先验知识提升深度学习模型的性能。

Method: 组织四届数据受限挑战赛，限制参与者使用少量样本从头训练模型，禁止迁移学习。

Result: 成功参赛方案采用Transformer与CNN的模型集成及数据增强，部分方案基于先验知识。

Conclusion: 先验知识和模型集成能有效提升数据不足时的深度学习性能。

Abstract: Deep Learning requires large amounts of data to train models that work well.
In data-deficient settings, performance can be degraded. We investigate which
Deep Learning methods benefit training models in a data-deficient setting, by
organizing the "VIPriors: Visual Inductive Priors for Data-Efficient Deep
Learning" workshop series, featuring four editions of data-impaired challenges.
These challenges address the problem of training deep learning models for
computer vision tasks with limited data. Participants are limited to training
models from scratch using a low number of training samples and are not allowed
to use any form of transfer learning. We aim to stimulate the development of
novel approaches that incorporate prior knowledge to improve the data
efficiency of deep learning models. Successful challenge entries make use of
large model ensembles that mix Transformers and CNNs, as well as heavy data
augmentation. Novel prior knowledge-based methods contribute to success in some
entries.

</details>


### [121] [SAMSelect: A Spectral Index Search for Marine Debris Visualization using Segment Anything](https://arxiv.org/abs/2506.08613)
*Joost van Dalen,Yuki M. Asano,Marc Russwurm*

Main category: cs.CV

TL;DR: SAMSelect是一种算法，用于从多光谱图像中选择最佳的三通道可视化组合，以帮助海洋科学家更准确地识别海洋漂浮物。


<details>
  <summary>Details</summary>
Motivation: 海洋漂浮物在中分辨率图像中难以可视化，专家通常依赖经验和启发式方法选择波段组合。SAMSelect旨在通过自动化选择最佳波段组合，提高可视化效果和分类准确性。

Method: SAMSelect利用Segment Anything Model在小规模标注数据集上评估波段或光谱指数组合的分类准确性，选择表现最佳的三通道组合。

Result: 在加纳阿克拉和南非德班的Sentinel-2场景中测试，SAMSelect发现了新的波段组合（如B8和B2的归一化差异指数），性能优于文献中的传统指数。

Conclusion: SAMSelect为海洋科学家提供了一种有效的可视化工具，其开源代码库可支持更广泛的视觉解译应用。

Abstract: This work proposes SAMSelect, an algorithm to obtain a salient three-channel
visualization for multispectral images. We develop SAMSelect and show its use
for marine scientists visually interpreting floating marine debris in
Sentinel-2 imagery. These debris are notoriously difficult to visualize due to
their compositional heterogeneity in medium-resolution imagery. Out of these
difficulties, a visual interpretation of imagery showing marine debris remains
a common practice by domain experts, who select bands and spectral indices on a
case-by-case basis informed by common practices and heuristics. SAMSelect
selects the band or index combination that achieves the best classification
accuracy on a small annotated dataset through the Segment Anything Model. Its
central assumption is that the three-channel visualization achieves the most
accurate segmentation results also provide good visual information for
photo-interpretation.
  We evaluate SAMSelect in three Sentinel-2 scenes containing generic marine
debris in Accra, Ghana, and Durban, South Africa, and deployed plastic targets
from the Plastic Litter Project. This reveals the potential of new previously
unused band combinations (e.g., a normalized difference index of B8, B2), which
demonstrate improved performance compared to literature-based indices. We
describe the algorithm in this paper and provide an open-source code repository
that will be helpful for domain scientists doing visual photo interpretation,
especially in the marine field.

</details>


### [122] [A Probability-guided Sampler for Neural Implicit Surface Rendering](https://arxiv.org/abs/2506.08619)
*Gonçalo Dias Pais,Valter Piedade,Moitreya Chatterjee,Marcus Greiff,Pedro Miraldo*

Main category: cs.CV

TL;DR: 该论文提出了一种改进的NeRF方法，通过隐式表面表示和3D图像投影空间的概率密度函数，实现了更有针对性的采样和更准确的渲染。


<details>
  <summary>Details</summary>
Motivation: 现有NeRF方法因可扩展性问题无法对所有输入数据进行训练，导致采样效率低下。本文旨在通过更有效的采样策略和损失函数提升渲染和重建精度。

Method: 利用隐式表面表示和3D图像投影空间的概率密度函数进行针对性采样，并提出新的表面重建损失函数，结合近表面和空空间信息。

Result: 实验表明，该方法在3D重建和图像渲染方面显著提升了准确性和细节表现，尤其在感兴趣区域。

Conclusion: 论文提出的采样策略和损失函数有效提升了NeRF的性能，为3D场景重建和渲染提供了更优解决方案。

Abstract: Several variants of Neural Radiance Fields (NeRFs) have significantly
improved the accuracy of synthesized images and surface reconstruction of 3D
scenes/objects. In all of these methods, a key characteristic is that none can
train the neural network with every possible input data, specifically, every
pixel and potential 3D point along the projection rays due to scalability
issues. While vanilla NeRFs uniformly sample both the image pixels and 3D
points along the projection rays, some variants focus only on guiding the
sampling of the 3D points along the projection rays. In this paper, we leverage
the implicit surface representation of the foreground scene and model a
probability density function in a 3D image projection space to achieve a more
targeted sampling of the rays toward regions of interest, resulting in improved
rendering. Additionally, a new surface reconstruction loss is proposed for
improved performance. This new loss fully explores the proposed 3D image
projection space model and incorporates near-to-surface and empty space
components. By integrating our novel sampling strategy and novel loss into
current state-of-the-art neural implicit surface renderers, we achieve more
accurate and detailed 3D reconstructions and improved image rendering,
especially for the regions of interest in any given scene.

</details>


### [123] [ECMNet:Lightweight Semantic Segmentation with Efficient CNN-Mamba Network](https://arxiv.org/abs/2506.08629)
*Feixiang Du,Shengkun Wu*

Main category: cs.CV

TL;DR: 提出了一种轻量级的CNN-Mamba网络（ECMNet）用于语义分割，结合CNN和Mamba的优势，通过增强的双注意力块和多尺度注意力单元提升性能。


<details>
  <summary>Details</summary>
Motivation: 尽管CNN和Transformer在语义分割中表现优异，但全局上下文建模仍不足。Mamba在视觉任务中展现出长距离依赖建模的潜力，因此结合两者以弥补各自弱点。

Method: 设计了增强的双注意力块（EDAB）和多尺度注意力单元（MSAU），并引入Mamba增强的特征融合模块（FFM）来整合多尺度特征。

Result: 在Cityscapes和CamVid数据集上分别达到70.6%和73.6%的mIoU，参数仅0.87M，计算量为8.27G FLOPs。

Conclusion: ECMNet在精度和效率上取得了平衡，验证了CNN与Mamba结合的有效性。

Abstract: In the past decade, Convolutional Neural Networks (CNNs) and Transformers
have achieved wide applicaiton in semantic segmentation tasks. Although CNNs
with Transformer models greatly improve performance, the global context
modeling remains inadequate. Recently, Mamba achieved great potential in vision
tasks, showing its advantages in modeling long-range dependency. In this paper,
we propose a lightweight Efficient CNN-Mamba Network for semantic segmentation,
dubbed as ECMNet. ECMNet combines CNN with Mamba skillfully in a capsule-based
framework to address their complementary weaknesses. Specifically, We design a
Enhanced Dual-Attention Block (EDAB) for lightweight bottleneck. In order to
improve the representations ability of feature, We devise a Multi-Scale
Attention Unit (MSAU) to integrate multi-scale feature aggregation, spatial
aggregation and channel aggregation. Moreover, a Mamba enhanced Feature Fusion
Module (FFM) merges diverse level feature, significantly enhancing segmented
accuracy. Extensive experiments on two representative datasets demonstrate that
the proposed model excels in accuracy and efficiency balance, achieving 70.6%
mIoU on Cityscapes and 73.6% mIoU on CamVid test datasets, with 0.87M
parameters and 8.27G FLOPs on a single RTX 3090 GPU platform.

</details>


### [124] [RoboSwap: A GAN-driven Video Diffusion Framework For Unsupervised Robot Arm Swapping](https://arxiv.org/abs/2506.08632)
*Yang Bai,Liudi Yang,George Eskandar,Fengyi Shen,Dong Chen,Mohammad Altillawi,Ziyuan Liu,Gitta Kutyniok*

Main category: cs.CV

TL;DR: RoboSwap是一种新型视频编辑框架，结合GAN和扩散模型，用于在多样环境中交换视频中的机械臂，无需配对数据。


<details>
  <summary>Details</summary>
Motivation: 解决视频条件下机器人学习中的数据稀缺问题，特别是跨平台泛化的挑战。

Method: 提出RoboSwap框架，通过GAN翻译机械臂并扩散模型增强视频连贯性，独立训练两阶段。

Result: 在三个基准测试中表现优于现有视频和图像编辑模型，提供结构连贯性和运动一致性。

Conclusion: RoboSwap为机器人学习生成可靠的跨平台数据提供了有效解决方案。

Abstract: Recent advancements in generative models have revolutionized video synthesis
and editing. However, the scarcity of diverse, high-quality datasets continues
to hinder video-conditioned robotic learning, limiting cross-platform
generalization. In this work, we address the challenge of swapping a robotic
arm in one video with another: a key step for crossembodiment learning. Unlike
previous methods that depend on paired video demonstrations in the same
environmental settings, our proposed framework, RoboSwap, operates on unpaired
data from diverse environments, alleviating the data collection needs. RoboSwap
introduces a novel video editing pipeline integrating both GANs and diffusion
models, combining their isolated advantages. Specifically, we segment robotic
arms from their backgrounds and train an unpaired GAN model to translate one
robotic arm to another. The translated arm is blended with the original video
background and refined with a diffusion model to enhance coherence, motion
realism and object interaction. The GAN and diffusion stages are trained
independently. Our experiments demonstrate that RoboSwap outperforms
state-of-the-art video and image editing models on three benchmarks in terms of
both structural coherence and motion consistency, thereby offering a robust
solution for generating reliable, cross-embodiment data in robotic learning.

</details>


### [125] [SurfR: Surface Reconstruction with Multi-scale Attention](https://arxiv.org/abs/2506.08635)
*Siddhant Ranade,Gonçalo Dias Pais,Ross Tyler Whitaker,Jacinto C. Nascimento,Pedro Miraldo,Srikumar Ramalingam*

Main category: cs.CV

TL;DR: 提出了一种基于隐式表示的快速、准确的无组织点云表面重建算法，通过懒查询、多尺度网格表示和跨尺度注意力机制，实现了速度与精度的最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法在单对象表示和小模型下能保留高细节但需逐对象训练，而通用表示虽能泛化但模型大且推理慢，缺乏细节。本文旨在解决这一问题。

Method: 提出新的隐式表示，采用懒查询加速特征提取，并行多尺度网格表示处理噪声和分辨率差异，跨尺度注意力提升重建效果。

Result: 算法在所有基线的最优分辨率下更快，性能损失极小，实现了最佳的速度-精度权衡。

Conclusion: 通过三项关键贡献，新方法在速度和精度上均优于现有技术，适用于通用3D形状重建。

Abstract: We propose a fast and accurate surface reconstruction algorithm for
unorganized point clouds using an implicit representation. Recent learning
methods are either single-object representations with small neural models that
allow for high surface details but require per-object training or generalized
representations that require larger models and generalize to newer shapes but
lack details, and inference is slow. We propose a new implicit representation
for general 3D shapes that is faster than all the baselines at their optimum
resolution, with only a marginal loss in performance compared to the
state-of-the-art. We achieve the best accuracy-speed trade-off using three key
contributions. Many implicit methods extract features from the point cloud to
classify whether a query point is inside or outside the object. First, to speed
up the reconstruction, we show that this feature extraction does not need to
use the query point at an early stage (lazy query). Second, we use a parallel
multi-scale grid representation to develop robust features for different noise
levels and input resolutions. Finally, we show that attention across scales can
provide improved reconstruction results.

</details>


### [126] [Orientation Matters: Making 3D Generative Models Orientation-Aligned](https://arxiv.org/abs/2506.08640)
*Yichong Lu,Yuzhuo Tian,Zijin Jiang,Yikun Zhao,Yuanbo Yang,Hao Ouyang,Haoji Hu,Huimin Yu,Yujun Shen,Yiyi Liao*

Main category: cs.CV

TL;DR: 论文提出了一种方向对齐的3D物体生成任务，并构建了Objaverse-OA数据集，通过微调现有模型实现跨类别一致性。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成模型因训练数据不一致导致结果方向错位，限制了其在下游任务中的应用。

Method: 构建Objaverse-OA数据集，基于多视图扩散和3D变分自编码器框架微调模型。

Result: 实验表明，该方法优于后处理对齐方法，并支持零样本方向估计和高效旋转操作。

Conclusion: 方向对齐的3D生成提升了模型在下游任务中的实用性。

Abstract: Humans intuitively perceive object shape and orientation from a single image,
guided by strong priors about canonical poses. However, existing 3D generative
models often produce misaligned results due to inconsistent training data,
limiting their usability in downstream tasks. To address this gap, we introduce
the task of orientation-aligned 3D object generation: producing 3D objects from
single images with consistent orientations across categories. To facilitate
this, we construct Objaverse-OA, a dataset of 14,832 orientation-aligned 3D
models spanning 1,008 categories. Leveraging Objaverse-OA, we fine-tune two
representative 3D generative models based on multi-view diffusion and 3D
variational autoencoder frameworks to produce aligned objects that generalize
well to unseen objects across various categories. Experimental results
demonstrate the superiority of our method over post-hoc alignment approaches.
Furthermore, we showcase downstream applications enabled by our aligned object
generation, including zero-shot object orientation estimation via
analysis-by-synthesis and efficient arrow-based object rotation manipulation.

</details>


### [127] [Enhancing Video Memorability Prediction with Text-Motion Cross-modal Contrastive Loss and Its Application in Video Summarization](https://arxiv.org/abs/2506.08649)
*Zhiyi Zhu,Xiaoyu Wu,Youwei Lu*

Main category: cs.CV

TL;DR: 本文提出了一种新的多模态视频记忆性预测模型TMCCL，通过文本-运动跨模态对比损失增强运动特征表示，并在两个数据集上取得最佳性能。同时，提出MWCVS方法，利用视频记忆性预测减少视频摘要标签的主观性。


<details>
  <summary>Details</summary>
Motivation: 现有视频记忆性预测模型未能充分利用运动线索，且运动特征表示在微调阶段因缺乏标注数据而受损。

Method: 引入文本-运动跨模态对比损失（TMCCL），利用视频间文本描述相似性构建正负运动样本集，提升运动特征表示。

Result: 模型在两个视频记忆性预测数据集上达到最优性能，并验证了MWCVS在视频摘要任务中的有效性。

Conclusion: TMCCL显著提升了视频记忆性预测的准确性，MWCVS展示了视频记忆性预测在视频摘要中的潜在应用价值。

Abstract: Video memorability refers to the ability of videos to be recalled after
viewing, playing a crucial role in creating content that remains memorable.
Existing models typically focus on extracting multimodal features to predict
video memorability scores but often fail to fully utilize motion cues. The
representation of motion features is compromised during the fine-tuning phase
of the motion feature extractor due to a lack of labeled data. In this paper,
we introduce the Text-Motion Cross-modal Contrastive Loss (TMCCL), a multimodal
video memorability prediction model designed to enhance the representation of
motion features. We tackle the challenge of improving motion feature
representation by leveraging text description similarities across videos to
establish positive and negative motion sample sets for a given target. This
enhancement allows the model to learn similar feature representations for
semantically related motion content, resulting in more accurate memorability
predictions. Our model achieves state-of-the-art performance on two video
memorability prediction datasets. Moreover, the potential applications of video
memorability prediction have been underexplored. To address this gap, we
present Memorability Weighted Correction for Video Summarization (MWCVS), using
video memorability prediction to reduce subjectivity in video summarization
labels. Experimental results on two video summarization datasets demonstrate
the effectiveness of MWCVS, showcasing the promising applications of video
memorability prediction.

</details>


### [128] [Beyond Calibration: Physically Informed Learning for Raw-to-Raw Mapping](https://arxiv.org/abs/2506.08650)
*Peter Grönquist,Stepan Tulyakov,Dengxin Dai*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级的神经物理模型（NPM），用于解决多相机间颜色一致性问题，适应不同光照条件，并在公开数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多相机系统中颜色一致性对图像融合和ISP兼容性至关重要，但现有方法在适应性、计算成本或实际需求上存在局限。

Method: 提出神经物理模型（NPM），通过模拟特定光照下的原始图像来估计设备间的转换，支持物理测量初始化和无配对数据训练。

Result: 在NUS和BeyondRGB等数据集上，NPM表现优于现有方法，实现了跨传感器和光学系统的鲁棒颜色一致性。

Conclusion: NPM是一种高效且适应性强的解决方案，显著提升了多相机系统的颜色一致性表现。

Abstract: Achieving consistent color reproduction across multiple cameras is essential
for seamless image fusion and Image Processing Pipeline (ISP) compatibility in
modern devices, but it is a challenging task due to variations in sensors and
optics. Existing raw-to-raw conversion methods face limitations such as poor
adaptability to changing illumination, high computational costs, or impractical
requirements such as simultaneous camera operation and overlapping
fields-of-view. We introduce the Neural Physical Model (NPM), a lightweight,
physically-informed approach that simulates raw images under specified
illumination to estimate transformations between devices. The NPM effectively
adapts to varying illumination conditions, can be initialized with physical
measurements, and supports training with or without paired data. Experiments on
public datasets like NUS and BeyondRGB demonstrate that NPM outperforms recent
state-of-the-art methods, providing robust chromatic consistency across
different sensors and optical systems.

</details>


### [129] [LLaVA-c: Continual Improved Visual Instruction Tuning](https://arxiv.org/abs/2506.08666)
*Wenzhuo Liu,Fei Zhu,Haiyang Guo,Longhui Wei,Cheng-Lin Liu*

Main category: cs.CV

TL;DR: 论文提出了一种改进LLaVA-1.5的方法，通过谱感知巩固和无监督查询正则化，解决了多任务学习中的任务平衡和基础模型退化问题，实现了持续学习性能的提升。


<details>
  <summary>Details</summary>
Motivation: 多任务学习存在任务平衡和扩展成本问题，持续学习虽能增量获取知识但易导致基础模型退化。

Method: 在LLaVA-1.5基础上引入谱感知巩固和无监督查询正则化。

Result: LLaVA-c在持续预训练和微调中提升了基准性能并保留了通用能力。

Conclusion: 首次证明任务级持续学习可匹敌或多任务联合学习，代码将公开。

Abstract: Multimodal models like LLaVA-1.5 achieve state-of-the-art visual
understanding through visual instruction tuning on multitask datasets, enabling
strong instruction-following and multimodal performance. However, multitask
learning faces challenges such as task balancing, requiring careful adjustment
of data proportions, and expansion costs, where new tasks risk catastrophic
forgetting and need costly retraining. Continual learning provides a promising
alternative to acquiring new knowledge incrementally while preserving existing
capabilities. However, current methods prioritize task-specific performance,
neglecting base model degradation from overfitting to specific instructions,
which undermines general capabilities. In this work, we propose a simple but
effective method with two modifications on LLaVA-1.5: spectral-aware
consolidation for improved task balance and unsupervised inquiry regularization
to prevent base model degradation. We evaluate both general and task-specific
performance across continual pretraining and fine-tuning. Experiments
demonstrate that LLaVA-c consistently enhances standard benchmark performance
and preserves general capabilities. For the first time, we show that
task-by-task continual learning can achieve results that match or surpass
multitask joint learning. The code will be publicly released.

</details>


### [130] [ATAS: Any-to-Any Self-Distillation for Enhanced Open-Vocabulary Dense Prediction](https://arxiv.org/abs/2506.08678)
*Juan Yeo,Soonwoo Cha,Jiwoo Song,Hyunbin Jin,Taesup Kim*

Main category: cs.CV

TL;DR: 论文提出了一种名为ATAS的自蒸馏方法，通过同时增强语义一致性和细粒度对齐，提升了CLIP模型在开放词汇密集预测任务中的性能。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在细粒度和区域级理解上表现不足，影响了其在密集预测任务中的效果。论文旨在解决这一问题，同时保持语义一致性和细粒度对齐。

Method: 提出了Any-to-Any Self-Distillation (ATAS)方法，利用模型自身的知识通过自蒸馏过程优化CLIP视觉编码器的表示，无需额外模块或有监督微调。

Result: 在开放词汇目标检测和语义分割任务中，ATAS显著优于基线CLIP模型，验证了其有效性。

Conclusion: ATAS方法通过联合保持语义一致性和细粒度对齐，为开放词汇密集预测任务提供了有效的解决方案。

Abstract: Vision-language models such as CLIP have recently propelled open-vocabulary
dense prediction tasks by enabling recognition of a broad range of visual
concepts. However, CLIP still struggles with fine-grained, region-level
understanding, hindering its effectiveness on these dense prediction tasks. We
identify two pivotal factors required to address this limitation: semantic
coherence and fine-grained vision-language alignment. Current adaptation
methods often improve fine-grained alignment at the expense of semantic
coherence, and often rely on extra modules or supervised fine-tuning. To
overcome these issues, we propose Any-to-Any Self-Distillation (ATAS), a novel
approach that simultaneously enhances semantic coherence and fine-grained
alignment by leveraging own knowledge of a model across all representation
levels. Unlike prior methods, ATAS uses only unlabeled images and an internal
self-distillation process to refine representations of CLIP vision encoders,
preserving local semantic consistency while sharpening local detail
recognition. On open-vocabulary object detection and semantic segmentation
benchmarks, ATAS achieves substantial performance gains, outperforming baseline
CLIP models. These results validate the effectiveness of our approach and
underscore the importance of jointly maintaining semantic coherence and
fine-grained alignment for advanced open-vocabulary dense prediction.

</details>


### [131] [CanadaFireSat: Toward high-resolution wildfire forecasting with multiple modalities](https://arxiv.org/abs/2506.08690)
*Hugo Porta,Emanuele Dalsasso,Jessica L. McCarty,Devis Tuia*

Main category: cs.CV

TL;DR: 加拿大2023年经历了近年来最严重的野火季节，造成生态系统破坏、社区损毁和大量CO2排放。本文提出高分辨率野火预测方法，利用多模态数据和深度学习模型，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 气候变化导致野火季节延长和加剧，亟需更好的野火管理工具。高分辨率野火概率图是关键，但现有方法依赖低分辨率数据，限制了预测精度。

Method: 提出CanadaFireSat基准数据集，结合高分辨率（Sentinel-2）、中分辨率（MODIS）卫星数据和环境因素（ERA5），采用多模态深度学习模型进行预测。

Result: 多模态输入显著优于单模态输入，在2023年野火季节的F1分数达到60.3%，验证了高分辨率和大陆尺度预测的潜力。

Conclusion: 多模态深度学习模型在高分辨率野火预测中表现优异，为未来野火管理提供了有效工具。

Abstract: Canada experienced in 2023 one of the most severe wildfire seasons in recent
history, causing damage across ecosystems, destroying communities, and emitting
large quantities of CO2. This extreme wildfire season is symptomatic of a
climate-change-induced increase in the length and severity of the fire season
that affects the boreal ecosystem. Therefore, it is critical to empower
wildfire management in boreal communities with better mitigation solutions.
Wildfire probability maps represent an important tool for understanding the
likelihood of wildfire occurrence and the potential severity of future
wildfires. The massive increase in the availability of Earth observation data
has enabled the development of deep learning-based wildfire forecasting models,
aiming at providing precise wildfire probability maps at different spatial and
temporal scales. A main limitation of such methods is their reliance on
coarse-resolution environmental drivers and satellite products, leading to
wildfire occurrence prediction of reduced resolution, typically around $\sim
0.1${\deg}. This paper presents a benchmark dataset: CanadaFireSat, and
baseline methods for high-resolution: 100 m wildfire forecasting across Canada,
leveraging multi-modal data from high-resolution multi-spectral satellite
images (Sentinel-2 L1C), mid-resolution satellite products (MODIS), and
environmental factors (ERA5 reanalysis data). Our experiments consider two
major deep learning architectures. We observe that using multi-modal temporal
inputs outperforms single-modal temporal inputs across all metrics, achieving a
peak performance of 60.3% in F1 score for the 2023 wildfire season, a season
never seen during model training. This demonstrates the potential of
multi-modal deep learning models for wildfire forecasting at high-resolution
and continental scale.

</details>


### [132] [VReST: Enhancing Reasoning in Large Vision-Language Models through Tree Search and Self-Reward Mechanism](https://arxiv.org/abs/2506.08691)
*Congzhi Zhang,Jiawei Peng,Zhenglin Wang,Yilong Lai,Haowen Sun,Heng Chang,Fei Ma,Weijiang Yu*

Main category: cs.CV

TL;DR: VReST是一种无需训练的方法，通过蒙特卡洛树搜索和自奖励机制提升大型视觉语言模型在复杂视觉推理中的表现。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在多模态任务中表现优异，但在复杂视觉推理中仍受限，尤其是使用思维链提示技术时。

Method: 提出VReST，通过蒙特卡洛树搜索建立推理路径，结合自奖励机制评估推理步骤质量。

Result: VReST在三个多模态数学推理基准测试中超越现有方法，取得最优性能。

Conclusion: VReST验证了多模态任务中测试时间扩展律的有效性，为未来研究提供了方向。

Abstract: Large Vision-Language Models (LVLMs) have shown exceptional performance in
multimodal tasks, but their effectiveness in complex visual reasoning is still
constrained, especially when employing Chain-of-Thought prompting techniques.
In this paper, we propose VReST, a novel training-free approach that enhances
Reasoning in LVLMs through Monte Carlo Tree Search and Self-Reward mechanisms.
VReST meticulously traverses the reasoning landscape by establishing a search
tree, where each node encapsulates a reasoning step, and each path delineates a
comprehensive reasoning sequence. Our innovative multimodal Self-Reward
mechanism assesses the quality of reasoning steps by integrating the utility of
sub-questions, answer correctness, and the relevance of vision-language clues,
all without the need for additional models. VReST surpasses current prompting
methods and secures state-of-the-art performance across three multimodal
mathematical reasoning benchmarks. Furthermore, it substantiates the efficacy
of test-time scaling laws in multimodal tasks, offering a promising direction
for future research.

</details>


### [133] [MoSiC: Optimal-Transport Motion Trajectory for Dense Self-Supervised Learning](https://arxiv.org/abs/2506.08694)
*Mohammadreza Salehi,Shashanka Venkataramanan,Ioana Simion,Efstratios Gavves,Cees G. M. Snoek,Yuki M Asano*

Main category: cs.CV

TL;DR: 提出了一种基于运动引导的自监督学习框架，通过聚类密集点轨迹学习时空一致的表示，提升了动态场景中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖静态增强，难以处理物体变形、遮挡和相机运动，导致特征学习不一致。

Method: 利用现有点跟踪器提取长程运动轨迹，通过动量编码器优化特征聚类，并沿跟踪点传播聚类分配以确保时序一致性。

Result: 在六个图像和视频数据集及四个评估基准上，性能提升1%至6%。

Conclusion: 通过运动作为隐式监督信号，该方法在动态场景中表现出色，并公开了实现代码。

Abstract: Dense self-supervised learning has shown great promise for learning pixel-
and patch-level representations, but extending it to videos remains challenging
due to the complexity of motion dynamics. Existing approaches struggle as they
rely on static augmentations that fail under object deformations, occlusions,
and camera movement, leading to inconsistent feature learning over time. We
propose a motion-guided self-supervised learning framework that clusters dense
point tracks to learn spatiotemporally consistent representations. By
leveraging an off-the-shelf point tracker, we extract long-range motion
trajectories and optimize feature clustering through a momentum-encoder-based
optimal transport mechanism. To ensure temporal coherence, we propagate cluster
assignments along tracked points, enforcing feature consistency across views
despite viewpoint changes. Integrating motion as an implicit supervisory
signal, our method learns representations that generalize across frames,
improving robustness in dynamic scenes and challenging occlusion scenarios. By
initializing from strong image-pretrained models and leveraging video data for
training, we improve state-of-the-art by 1% to 6% on six image and video
datasets and four evaluation benchmarks. The implementation is publicly
available at our GitHub repository: https://github.com/SMSD75/MoSiC/tree/main

</details>


### [134] [ArrowPose: Segmentation, Detection, and 5 DoF Pose Estimation Network for Colorless Point Clouds](https://arxiv.org/abs/2506.08699)
*Frederik Hagelskjaer*

Main category: cs.CV

TL;DR: 本文提出了一种针对无色点云的快速检测和5自由度姿态估计网络，通过神经网络预测物体的中心和顶部点来计算姿态。


<details>
  <summary>Details</summary>
Motivation: 无色点云的姿态估计在计算机视觉中具有重要应用，但现有方法在速度和精度上仍有不足。

Method: 使用合成数据训练神经网络，通过预测物体的中心和顶部点进行5自由度姿态估计。

Result: 在基准数据集上表现优于所有无色方法，推理时间仅需250毫秒。

Conclusion: 该方法在速度和精度上均达到先进水平，适用于多种实际场景。

Abstract: This paper presents a fast detection and 5 DoF (Degrees of Freedom) pose
estimation network for colorless point clouds. The pose estimation is
calculated from center and top points of the object, predicted by the neural
network. The network is trained on synthetic data, and tested on a benchmark
dataset, where it demonstrates state-of-the-art performance and outperforms all
colorless methods. The network is able to run inference in only 250
milliseconds making it usable in many scenarios. Project page with code at
arrowpose.github.io

</details>


### [135] [TraGraph-GS: Trajectory Graph-based Gaussian Splatting for Arbitrary Large-Scale Scene Rendering](https://arxiv.org/abs/2506.08704)
*Xiaohan Zhang,Sitong Wang,Yushen Yan,Yi Yang,Mingda Xu,Qi Liu*

Main category: cs.CV

TL;DR: 论文提出TraGraph-GS方法，通过轨迹图解决大规模场景中高质量新视角合成的挑战，显著提升了渲染精度和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理大规模场景时存在空间分区不灵活和高斯重叠导致纹理失真的问题。

Method: 提出基于轨迹图的空间分区方法，结合正则化约束和渐进渲染策略。

Result: 在多个数据集上表现优异，PSNR平均提升1.86 dB（空中）和1.62 dB（地面）。

Conclusion: TraGraph-GS方法有效解决了大规模场景渲染的挑战，性能优于现有技术。

Abstract: High-quality novel view synthesis for large-scale scenes presents a
challenging dilemma in 3D computer vision. Existing methods typically partition
large scenes into multiple regions, reconstruct a 3D representation using
Gaussian splatting for each region, and eventually merge them for novel view
rendering. They can accurately render specific scenes, yet they do not
generalize effectively for two reasons: (1) rigid spatial partition techniques
struggle with arbitrary camera trajectories, and (2) the merging of regions
results in Gaussian overlap to distort texture details. To address these
challenges, we propose TraGraph-GS, leveraging a trajectory graph to enable
high-precision rendering for arbitrarily large-scale scenes. We present a
spatial partitioning method for large-scale scenes based on graphs, which
incorporates a regularization constraint to enhance the rendering of textures
and distant objects, as well as a progressive rendering strategy to mitigate
artifacts caused by Gaussian overlap. Experimental results demonstrate its
superior performance both on four aerial and four ground datasets and highlight
its remarkable efficiency: our method achieves an average improvement of 1.86
dB in PSNR on aerial datasets and 1.62 dB on ground datasets compared to
state-of-the-art approaches.

</details>


### [136] [SceneSplat++: A Large Dataset and Comprehensive Benchmark for Language Gaussian Splatting](https://arxiv.org/abs/2506.08710)
*Mengjiao Ma,Qi Ma,Yue Li,Jiahuan Cheng,Runyi Yang,Bin Ren,Nikola Popovic,Mingqiang Wei,Nicu Sebe,Luc Van Gool,Theo Gevers,Martin R. Oswald,Danda Pani Paudel*

Main category: cs.CV

TL;DR: 论文提出了一个大规模基准测试，评估三种3D高斯溅射方法，并引入GaussianWorld-49K数据集，证明通用方法在3D场景理解中的优势。


<details>
  <summary>Details</summary>
Motivation: 当前3D高斯溅射方法主要在2D视图上评估，缺乏对整体3D理解的深入分析，需要系统性3D空间评估。

Method: 提出首个大规模基准测试，评估三类方法（基于优化、无优化、通用方法），并在1060个场景上测试。

Result: 通用方法在放松场景限制、快速推理和分割性能上表现优越。

Conclusion: 通用方法结合大数据集（GaussianWorld-49K）能显著提升3D场景理解，代码和数据集将公开以推动研究。

Abstract: 3D Gaussian Splatting (3DGS) serves as a highly performant and efficient
encoding of scene geometry, appearance, and semantics. Moreover, grounding
language in 3D scenes has proven to be an effective strategy for 3D scene
understanding. Current Language Gaussian Splatting line of work fall into three
main groups: (i) per-scene optimization-based, (ii) per-scene
optimization-free, and (iii) generalizable approach. However, most of them are
evaluated only on rendered 2D views of a handful of scenes and viewpoints close
to the training views, limiting ability and insight into holistic 3D
understanding. To address this gap, we propose the first large-scale benchmark
that systematically assesses these three groups of methods directly in 3D
space, evaluating on 1060 scenes across three indoor datasets and one outdoor
dataset. Benchmark results demonstrate a clear advantage of the generalizable
paradigm, particularly in relaxing the scene-specific limitation, enabling fast
feed-forward inference on novel scenes, and achieving superior segmentation
performance. We further introduce GaussianWorld-49K a carefully curated 3DGS
dataset comprising around 49K diverse indoor and outdoor scenes obtained from
multiple sources, with which we demonstrate the generalizable approach could
harness strong data priors. Our codes, benchmark, and datasets will be made
public to accelerate research in generalizable 3DGS scene understanding.

</details>


### [137] [Geometric deep learning for local growth prediction on abdominal aortic aneurysm surfaces](https://arxiv.org/abs/2506.08729)
*Dieuwertje Alblas,Patryk Rygiel,Julian Suk,Kaj O. Kappe,Marieke Hofman,Christoph Brune,Kak Khee Yeung,Jelmer M. Wolterink*

Main category: cs.CV

TL;DR: 该论文提出了一种基于SE(3)-对称变换器模型的方法，用于预测腹主动脉瘤（AAA）的生长，通过保留血管表面的解剖结构和几何保真度，实现了比传统直径监测更个性化的预测。


<details>
  <summary>Details</summary>
Motivation: 目前AAA监测依赖于最大直径，忽略了3D形状与生长的复杂关系，可能导致监测策略不准确。个性化生长预测可优化监测。

Method: 使用SE(3)-对称变换器模型，直接在血管模型表面结合局部多物理特征预测AAA生长。训练数据为24名患者的113次CTA扫描。

Result: 模型预测下一次扫描时的AAA生长，中位直径误差为1.18 mm，并能以93%的准确率识别患者是否在两年内需手术修复。外部验证集表现良好。

Conclusion: 局部方向性AAA生长预测可行，可为个性化监测策略提供支持。

Abstract: Abdominal aortic aneurysms (AAAs) are progressive focal dilatations of the
abdominal aorta. AAAs may rupture, with a survival rate of only 20\%. Current
clinical guidelines recommend elective surgical repair when the maximum AAA
diameter exceeds 55 mm in men or 50 mm in women. Patients that do not meet
these criteria are periodically monitored, with surveillance intervals based on
the maximum AAA diameter. However, this diameter does not take into account the
complex relation between the 3D AAA shape and its growth, making standardized
intervals potentially unfit. Personalized AAA growth predictions could improve
monitoring strategies. We propose to use an SE(3)-symmetric transformer model
to predict AAA growth directly on the vascular model surface enriched with
local, multi-physical features. In contrast to other works which have
parameterized the AAA shape, this representation preserves the vascular
surface's anatomical structure and geometric fidelity. We train our model using
a longitudinal dataset of 113 computed tomography angiography (CTA) scans of 24
AAA patients at irregularly sampled intervals. After training, our model
predicts AAA growth to the next scan moment with a median diameter error of
1.18 mm. We further demonstrate our model's utility to identify whether a
patient will become eligible for elective repair within two years (acc = 0.93).
Finally, we evaluate our model's generalization on an external validation set
consisting of 25 CTAs from 7 AAA patients from a different hospital. Our
results show that local directional AAA growth prediction from the vascular
surface is feasible and may contribute to personalized surveillance strategies.

</details>


### [138] [InceptionMamba: An Efficient Hybrid Network with Large Band Convolution and Bottleneck Mamba](https://arxiv.org/abs/2506.08735)
*Yuhang Wang,Jun Li,Zhijian Wu,Jianhua Xu*

Main category: cs.CV

TL;DR: InceptionMamba是一种新型的卷积神经网络架构，通过正交带卷积和Mamba模块解决了InceptionNeXt在空间依赖性和全局上下文建模上的不足，实现了更优的分类和下游任务性能。


<details>
  <summary>Details</summary>
Motivation: InceptionNeXt在图像分类和下游任务中表现优异，但其一维条带卷积限制了空间依赖性的捕捉和局部邻域的空间建模能力，且卷积操作的局部性约束不利于全局上下文建模。

Method: 提出InceptionMamba架构，用正交带卷积替换传统一维条带卷积以实现空间建模，并通过瓶颈Mamba模块实现全局上下文建模和跨通道信息融合。

Result: 在分类和多种下游任务中，InceptionMamba表现出最先进的性能，且具有更高的参数和计算效率。

Conclusion: InceptionMamba通过改进的空间建模和全局上下文建模，显著提升了性能，是一种高效且竞争力强的架构。

Abstract: Within the family of convolutional neural networks, InceptionNeXt has shown
excellent competitiveness in image classification and a number of downstream
tasks. Built on parallel one-dimensional strip convolutions, however, it
suffers from limited ability of capturing spatial dependencies along different
dimensions and fails to fully explore spatial modeling in local neighborhood.
Besides, inherent locality constraints of convolution operations are
detrimental to effective global context modeling. To overcome these
limitations, we propose a novel backbone architecture termed InceptionMamba in
this study. More specifically, the traditional one-dimensional strip
convolutions are replaced by orthogonal band convolutions in our InceptionMamba
to achieve cohesive spatial modeling. Furthermore, global contextual modeling
can be achieved via a bottleneck Mamba module, facilitating enhanced
cross-channel information fusion and enlarged receptive field. Extensive
evaluations on classification and various downstream tasks demonstrate that the
proposed InceptionMamba achieves state-of-the-art performance with superior
parameter and computational efficiency. The source code will be available at
https://github.com/Wake1021/InceptionMamba.

</details>


### [139] [RS-MTDF: Multi-Teacher Distillation and Fusion for Remote Sensing Semi-Supervised Semantic Segmentation](https://arxiv.org/abs/2506.08772)
*Jiayi Song,Kaiyu Li,Xiangyong Cao,Deyu Meng*

Main category: cs.CV

TL;DR: 论文提出了一种名为RS-MTDF的半监督语义分割框架，利用预训练的视觉基础模型（VFMs）作为多教师，通过特征级蒸馏和知识融合提升遥感图像分割的性能。


<details>
  <summary>Details</summary>
Motivation: 遥感图像的语义分割需要大量标注数据，但标注成本高昂。现有的半监督方法在有限标注数据和大量未标注数据之间存在分布不匹配问题，导致泛化能力不足。

Method: RS-MTDF框架利用多个冻结的VFMs（如DINOv2和CLIP）作为教师模型，通过特征级蒸馏将学生模型的特征与教师模型的鲁棒表示对齐，并在解码器中融合蒸馏知识。

Result: 在ISPRS Potsdam、LoveDA和DeepGlobe三个数据集上的实验表明，RS-MTDF在多种标注比例下均达到最优性能，尤其在LoveDA数据集上表现突出。

Conclusion: 多教师VFM指导显著提升了遥感图像分割的泛化能力和语义理解能力，消融实验验证了各模块的有效性。

Abstract: Semantic segmentation in remote sensing images is crucial for various
applications, yet its performance is heavily reliant on large-scale,
high-quality pixel-wise annotations, which are notoriously expensive and
time-consuming to acquire. Semi-supervised semantic segmentation (SSS) offers a
promising alternative to mitigate this data dependency. However, existing SSS
methods often struggle with the inherent distribution mismatch between limited
labeled data and abundant unlabeled data, leading to suboptimal generalization.
We propose that Vision Foundation Models (VFMs), pre-trained on vast and
diverse datasets, possess robust generalization capabilities that can
effectively bridge this distribution gap and provide strong semantic priors for
SSS. Inspired by this, we introduce RS-MTDF (Multi-Teacher Distillation and
Fusion), a novel framework that leverages the powerful semantic knowledge
embedded in VFMs to guide semi-supervised learning in remote sensing.
Specifically, RS-MTDF employs multiple frozen VFMs (\textit{e.g.}, DINOv2 and
CLIP) as expert teachers, utilizing feature-level distillation to align student
features with their robust representations. To further enhance discriminative
power, the distilled knowledge is seamlessly fused into the student decoder.
Extensive experiments on three challenging remote sensing datasets (ISPRS
Potsdam, LoveDA, and DeepGlobe) demonstrate that RS-MTDF consistently achieves
state-of-the-art performance. Notably, our method outperforms existing
approaches across various label ratios on LoveDA and secures the highest IoU in
the majority of semantic categories. These results underscore the efficacy of
multi-teacher VFM guidance in significantly enhancing both generalization and
semantic understanding for remote sensing segmentation. Ablation studies
further validate the contribution of each proposed module.

</details>


### [140] [Gaussian2Scene: 3D Scene Representation Learning via Self-supervised Learning with 3D Gaussian Splatting](https://arxiv.org/abs/2506.08777)
*Keyi Liu,Weidong Yang,Ben Fei,Ying He*

Main category: cs.CV

TL;DR: 提出了一种基于3D高斯点云的场景级自监督学习框架Gaussian2Scene，通过两阶段训练策略提升几何和跨模态学习能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖隐式场景表示和高内存需求，且重建目标仅适用于2D空间，难以捕捉3D几何结构。

Method: 采用3D高斯点云（3DGS）进行预训练，分两阶段：双分支掩码自编码器学习2D和3D表示，再通过高斯基元几何位置和RGB图像监督学习。

Result: 在多个3D目标检测任务中表现优于现有预训练方法。

Conclusion: Gaussian2Scene通过显式3D表示和高效训练策略，显著提升了场景级自监督学习的效果。

Abstract: Self-supervised learning (SSL) for point cloud pre-training has become a
cornerstone for many 3D vision tasks, enabling effective learning from
large-scale unannotated data. At the scene level, existing SSL methods often
incorporate volume rendering into the pre-training framework, using RGB-D
images as reconstruction signals to facilitate cross-modal learning. This
strategy promotes alignment between 2D and 3D modalities and enables the model
to benefit from rich visual cues in the RGB-D inputs. However, these approaches
are limited by their reliance on implicit scene representations and high memory
demands. Furthermore, since their reconstruction objectives are applied only in
2D space, they often fail to capture underlying 3D geometric structures. To
address these challenges, we propose Gaussian2Scene, a novel scene-level SSL
framework that leverages the efficiency and explicit nature of 3D Gaussian
Splatting (3DGS) for pre-training. The use of 3DGS not only alleviates the
computational burden associated with volume rendering but also supports direct
3D scene reconstruction, thereby enhancing the geometric understanding of the
backbone network. Our approach follows a progressive two-stage training
strategy. In the first stage, a dual-branch masked autoencoder learns both 2D
and 3D scene representations. In the second stage, we initialize training with
reconstructed point clouds and further supervise learning using the geometric
locations of Gaussian primitives and rendered RGB images. This process
reinforces both geometric and cross-modal learning. We demonstrate the
effectiveness of Gaussian2Scene across several downstream 3D object detection
tasks, showing consistent improvements over existing pre-training methods.

</details>


### [141] [Landsat-Bench: Datasets and Benchmarks for Landsat Foundation Models](https://arxiv.org/abs/2506.08780)
*Isaac Corley,Lakshay Sharma,Ruth Crasto*

Main category: cs.CV

TL;DR: Landsat-Bench是一套基于Landsat影像的基准测试，旨在推动Landsat地理空间基础模型（GFM）的发展。


<details>
  <summary>Details</summary>
Motivation: Landsat数据缺乏基准测试，限制了基于Landsat的地理空间基础模型的进展。

Method: 引入三个基准测试（EuroSAT-L、BigEarthNet-L和LC100-L），并基于SSL4EO-L数据集预训练的GFM进行标准化评估。

Result: SSL4EO-L预训练的GFM在下游任务中表现优于ImageNet，性能提升分别为+4% OA和+5.1% mAP。

Conclusion: Landsat-Bench为Landsat数据提供了有效的基准测试，证明了SSL4EO-L预训练模型的优越性。

Abstract: The Landsat program offers over 50 years of globally consistent Earth
imagery. However, the lack of benchmarks for this data constrains progress
towards Landsat-based Geospatial Foundation Models (GFM). In this paper, we
introduce Landsat-Bench, a suite of three benchmarks with Landsat imagery that
adapt from existing remote sensing datasets -- EuroSAT-L, BigEarthNet-L, and
LC100-L. We establish baseline and standardized evaluation methods across both
common architectures and Landsat foundation models pretrained on the SSL4EO-L
dataset. Notably, we provide evidence that SSL4EO-L pretrained GFMs extract
better representations for downstream tasks in comparison to ImageNet,
including performance gains of +4% OA and +5.1% mAP on EuroSAT-L and
BigEarthNet-L.

</details>


### [142] [HomographyAD: Deep Anomaly Detection Using Self Homography Learning](https://arxiv.org/abs/2506.08784)
*Jongyub Seok,Chanjin Kang*

Main category: cs.CV

TL;DR: 论文提出了一种名为HomographyAD的新方法，针对工业环境中的异常检测问题，通过深度单应性估计和自学习优化性能。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法仅适用于完全对齐的数据集，而实际工业环境中的数据往往未对齐，因此需要一种更适应实际场景的方法。

Method: 1. 使用深度单应性估计方法对齐输入前景；2. 通过自单应性学习微调模型，从正常样本中学习形状信息；3. 基于测试样本特征与正常特征分布的距离进行异常检测。

Result: 通过将HomographyAD应用于多种现有方法，实验表明其显著提升了性能。

Conclusion: HomographyAD是一种针对实际工业数据集的创新方法，能够有效解决未对齐数据的异常检测问题。

Abstract: Anomaly detection (AD) is a task that distinguishes normal and abnormal data,
which is important for applying automation technologies of the manufacturing
facilities. For MVTec dataset that is a representative AD dataset for
industrial environment, many recent works have shown remarkable performances.
However, the existing anomaly detection works have a limitation of showing good
performance for fully-aligned datasets only, unlike real-world industrial
environments. To solve this limitation, we propose HomographyAD, a novel deep
anomaly detection methodology based on the ImageNet-pretrained network, which
is specially designed for actual industrial dataset. Specifically, we first
suggest input foreground alignment using the deep homography estimation method.
In addition, we fine-tune the model by self homography learning to learn
additional shape information from normal samples. Finally, we conduct anomaly
detection based on the measure of how far the feature of test sample is from
the distribution of the extracted normal features. By applying our proposed
method to various existing AD approaches, we show performance enhancement
through extensive experiments.

</details>


### [143] [A PDE-Based Image Dehazing Method via Atmospheric Scattering Theory](https://arxiv.org/abs/2506.08793)
*Zhuoran Zheng*

Main category: cs.CV

TL;DR: 提出了一种基于偏微分方程（PDE）的单幅图像去雾方法，结合大气散射模型、非局部正则化和暗通道先验，改进PDE框架，并通过理论证明和实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决单幅图像去雾问题，通过改进PDE框架提升去雾效果，并探索其在深度学习模型中的泛化能力。

Method: 提出改进的PDE框架，结合大气散射模型、非局部正则化和暗通道先验；理论证明弱解的存在唯一性；采用固定点迭代加速计算。

Result: 实验结果表明该方法是一种有效的去雾解决方案，并具备在深度学习模型中泛化的潜力。

Conclusion: 改进的PDE框架在单幅图像去雾中表现优异，未来可进一步探索其在深度学习中的应用。

Abstract: This paper presents a novel partial differential equation (PDE) framework for
single-image dehazing. By integrating the atmospheric scattering model with
nonlocal regularization and dark channel prior, we propose the improved PDE: \[
-\text{div}\left(D(\nabla u)\nabla u\right) + \lambda(t) G(u) = \Phi(I,t,A) \]
where $D(\nabla u) = (|\nabla u| + \epsilon)^{-1}$ is the edge-preserving
diffusion coefficient, $G(u)$ is the Gaussian convolution operator, and
$\lambda(t)$ is the adaptive regularization parameter based on transmission map
$t$. We prove the existence and uniqueness of weak solutions in $H_0^1(\Omega)$
using Lax-Milgram theorem, and implement an efficient fixed-point iteration
scheme accelerated by PyTorch GPU computation. The experimental results
demonstrate that this method is a promising deghazing solution that can be
generalized to the deep model paradigm.

</details>


### [144] [Flow Diverse and Efficient: Learning Momentum Flow Matching via Stochastic Velocity Field Sampling](https://arxiv.org/abs/2506.08796)
*Zhiyuan Ma,Ruixun Liu,Sixian Liu,Jianjun Li,Bowen Zhou*

Main category: cs.CV

TL;DR: 本文提出了一种新的离散化整流流（Discretized-RF）方法，通过将直线路径分解为多个可变速度子路径，提升了多样性和多尺度噪声建模能力。


<details>
  <summary>Details</summary>
Motivation: 传统的整流流（RF）虽然高效，但在多样性和多尺度噪声建模方面存在局限性。

Method: 提出离散化整流流，将直线路径分解为多个可变速度子路径，并在速度上引入噪声以改变方向。

Result: 实验表明，该方法能生成多样且高效的轨迹，并持续产生高质量和多样化的结果。

Conclusion: 离散化整流流在提升多样性和噪声建模能力方面表现优异，代码已开源。

Abstract: Recently, the rectified flow (RF) has emerged as the new state-of-the-art
among flow-based diffusion models due to its high efficiency advantage in
straight path sampling, especially with the amazing images generated by a
series of RF models such as Flux 1.0 and SD 3.0. Although a straight-line
connection between the noisy and natural data distributions is intuitive, fast,
and easy to optimize, it still inevitably leads to: 1) Diversity concerns,
which arise since straight-line paths only cover a fairly restricted sampling
space. 2) Multi-scale noise modeling concerns, since the straight line flow
only needs to optimize the constant velocity field $\bm v$ between the two
distributions $\bm\pi_0$ and $\bm\pi_1$. In this work, we present
Discretized-RF, a new family of rectified flow (also called momentum flow
models since they refer to the previous velocity component and the random
velocity component in each diffusion step), which discretizes the straight path
into a series of variable velocity field sub-paths (namely ``momentum fields'')
to expand the search space, especially when close to the distribution
$p_\text{noise}$. Different from the previous case where noise is directly
superimposed on $\bm x$, we introduce noise on the velocity $\bm v$ of the
sub-path to change its direction in order to improve the diversity and
multi-scale noise modeling abilities. Experimental results on several
representative datasets demonstrate that learning momentum flow matching by
sampling random velocity fields will produce trajectories that are both diverse
and efficient, and can consistently generate high-quality and diverse results.
Code is available at https://github.com/liuruixun/momentum-fm.

</details>


### [145] [HunyuanVideo-HOMA: Generic Human-Object Interaction in Multimodal Driven Human Animation](https://arxiv.org/abs/2506.08797)
*Ziyao Huang,Zixiang Zhou,Juan Cao,Yifeng Ma,Yi Chen,Zejing Rao,Zhiyong Xu,Hongmei Wang,Qin Lin,Yuan Zhou,Qinglin Lu,Fan Tang*

Main category: cs.CV

TL;DR: HunyuanVideo-HOMA是一个弱条件多模态驱动框架，用于解决人类-物体交互（HOI）视频生成中的关键限制，如依赖精选运动数据、泛化能力不足和可访问性受限。


<details>
  <summary>Details</summary>
Motivation: 解决HOI视频生成中对精选运动数据的依赖、对新物体/场景的泛化能力有限以及可访问性受限的问题。

Method: 通过稀疏解耦的运动指导增强可控性，将外观和运动信号编码到多模态扩散变换器（MMDiT）的双输入空间，并在共享上下文空间中融合以合成时间一致且物理合理的交互。

Result: 实验表明，在弱监督下，HunyuanVideo-HOMA在交互自然性和泛化能力方面达到最先进水平。

Conclusion: HunyuanVideo-HOMA在文本条件生成和交互式物体操作中表现出多功能性，并提供了用户友好的演示界面。

Abstract: To address key limitations in human-object interaction (HOI) video generation
-- specifically the reliance on curated motion data, limited generalization to
novel objects/scenarios, and restricted accessibility -- we introduce
HunyuanVideo-HOMA, a weakly conditioned multimodal-driven framework.
HunyuanVideo-HOMA enhances controllability and reduces dependency on precise
inputs through sparse, decoupled motion guidance. It encodes appearance and
motion signals into the dual input space of a multimodal diffusion transformer
(MMDiT), fusing them within a shared context space to synthesize temporally
consistent and physically plausible interactions. To optimize training, we
integrate a parameter-space HOI adapter initialized from pretrained MMDiT
weights, preserving prior knowledge while enabling efficient adaptation, and a
facial cross-attention adapter for anatomically accurate audio-driven lip
synchronization. Extensive experiments confirm state-of-the-art performance in
interaction naturalness and generalization under weak supervision. Finally,
HunyuanVideo-HOMA demonstrates versatility in text-conditioned generation and
interactive object manipulation, supported by a user-friendly demo interface.
The project page is at https://anonymous.4open.science/w/homa-page-0FBE/.

</details>


### [146] [HiSin: Efficient High-Resolution Sinogram Inpainting via Resolution-Guided Progressive Inference](https://arxiv.org/abs/2506.08809)
*Jiaze E,Srutarshi Banerjee,Tekin Bicer,Guannan Wang,Yanfu Zhang,Bin Ren*

Main category: cs.CV

TL;DR: HiSin是一种基于扩散模型的高效正弦图修复框架，通过分辨率引导的渐进推理减少内存和计算需求，同时保持修复精度。


<details>
  <summary>Details</summary>
Motivation: 高分辨率正弦图修复对CT重建至关重要，但现有扩散模型因内存和计算需求过高而受限。

Method: HiSin采用分辨率引导的渐进推理，先在低分辨率提取全局结构，再在高分辨率处理小片段，并结合频率感知片段跳过和结构自适应步长分配以减少冗余计算。

Result: 实验显示，HiSin峰值内存使用减少31.25%，推理时间减少18.15%，且在不同数据集、分辨率和掩码条件下保持修复精度。

Conclusion: HiSin通过高效推理策略解决了扩散模型在高分辨率正弦图修复中的内存和计算问题，具有实用价值。

Abstract: High-resolution sinogram inpainting is essential for computed tomography
reconstruction, as missing high-frequency projections can lead to visible
artifacts and diagnostic errors. Diffusion models are well-suited for this task
due to their robustness and detail-preserving capabilities, but their
application to high-resolution inputs is limited by excessive memory and
computational demands. To address this limitation, we propose HiSin, a novel
diffusion based framework for efficient sinogram inpainting via
resolution-guided progressive inference. It progressively extracts global
structure at low resolution and defers high-resolution inference to small
patches, enabling memory-efficient inpainting. It further incorporates
frequency-aware patch skipping and structure-adaptive step allocation to reduce
redundant computation. Experimental results show that HiSin reduces peak memory
usage by up to 31.25% and inference time by up to 18.15%, and maintains
inpainting accuracy across datasets, resolutions, and mask conditions.

</details>


### [147] [Video-CoT: A Comprehensive Dataset for Spatiotemporal Understanding of Videos Based on Chain-of-Thought](https://arxiv.org/abs/2506.08817)
*Shuyi Zhang,Xiaoshuai Hao,Yingbo Tang,Lingfeng Zhang,Pengwei Wang,Zhongyuan Wang,Hongxuan Ma,Shanghang Zhang*

Main category: cs.CV

TL;DR: Video-CoT是一个新数据集，用于提升视频内容理解的时空细节分析能力，包含大量问题和答案对，并提供了评估基准。实验显示现有模型在此任务上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模视觉语言模型在视频分析中难以捕捉时空细节，因此需要新的数据集和方法来填补这一空白。

Method: 引入Video-CoT数据集，包含192,000个时空问题-答案对和23,000个高质量CoT注释样本，并提供评估基准。

Result: 实验表明现有模型在时空理解任务上表现不佳，突显了该任务的挑战性。

Conclusion: Video-CoT为多媒体理解和智能系统研究提供了新方向，并公开资源以促进进一步探索。

Abstract: Video content comprehension is essential for various applications, ranging
from video analysis to interactive systems. Despite advancements in large-scale
vision-language models (VLMs), these models often struggle to capture the
nuanced, spatiotemporal details essential for thorough video analysis. To
address this gap, we introduce Video-CoT, a groundbreaking dataset designed to
enhance spatiotemporal understanding using Chain-of-Thought (CoT)
methodologies. Video-CoT contains 192,000 fine-grained spa-tiotemporal
question-answer pairs and 23,000 high-quality CoT-annotated samples, providing
a solid foundation for evaluating spatiotemporal understanding in video
comprehension. Additionally, we provide a comprehensive benchmark for assessing
these tasks, with each task featuring 750 images and tailored evaluation
metrics. Our extensive experiments reveal that current VLMs face significant
challenges in achieving satisfactory performance, high-lighting the
difficulties of effective spatiotemporal understanding. Overall, the Video-CoT
dataset and benchmark open new avenues for research in multimedia understanding
and support future innovations in intelligent systems requiring advanced video
analysis capabilities. By making these resources publicly available, we aim to
encourage further exploration in this critical area. Project
website:https://video-cot.github.io/ .

</details>


### [148] [CulturalFrames: Assessing Cultural Expectation Alignment in Text-to-Image Models and Evaluation Metrics](https://arxiv.org/abs/2506.08835)
*Shravan Nayak,Mehar Bhatia,Xiaofeng Zhang,Verena Rieser,Lisa Anne Hendricks,Sjoerd van Steenkiste,Yash Goyal,Karolina Stańczak,Aishwarya Agrawal*

Main category: cs.CV

TL;DR: 研究发现，文本到图像（T2I）模型在表现多样文化背景时存在显著不足，无论是显性还是隐性文化期望，模型均未能满足。


<details>
  <summary>Details</summary>
Motivation: 随着T2I模型在视觉内容生成中的广泛应用，其是否能准确反映多样文化背景成为关注焦点。

Method: 研究引入CulturalFrames基准，涵盖10个国家、5个社会文化领域，通过983个提示、3637张图像和10k+人工标注，系统评估T2I模型的文化表现。

Result: T2I模型平均44%的情况下未能满足文化期望，显性期望失败率高达68%，隐性期望为49%。现有评估指标与人类判断相关性低。

Conclusion: 研究揭示了T2I模型在文化表现上的严重缺陷，为开发更具文化敏感性的模型和评估方法提供了方向。

Abstract: The increasing ubiquity of text-to-image (T2I) models as tools for visual
content generation raises concerns about their ability to accurately represent
diverse cultural contexts. In this work, we present the first study to
systematically quantify the alignment of T2I models and evaluation metrics with
respect to both explicit as well as implicit cultural expectations. To this
end, we introduce CulturalFrames, a novel benchmark designed for rigorous human
evaluation of cultural representation in visual generations. Spanning 10
countries and 5 socio-cultural domains, CulturalFrames comprises 983 prompts,
3637 corresponding images generated by 4 state-of-the-art T2I models, and over
10k detailed human annotations. We find that T2I models not only fail to meet
the more challenging implicit expectations but also the less challenging
explicit expectations. Across models and countries, cultural expectations are
missed an average of 44% of the time. Among these failures, explicit
expectations are missed at a surprisingly high average rate of 68%, while
implicit expectation failures are also significant, averaging 49%. Furthermore,
we demonstrate that existing T2I evaluation metrics correlate poorly with human
judgments of cultural alignment, irrespective of their internal reasoning.
Collectively, our findings expose critical gaps, providing actionable
directions for developing more culturally informed T2I models and evaluation
methodologies.

</details>


### [149] [Adapting Vision-Language Foundation Model for Next Generation Medical Ultrasound Image Analysis](https://arxiv.org/abs/2506.08849)
*Jingguo Qu,Xinyang Han,Tonghuan Xiao,Jia Ai,Juan Wu,Tong Zhao,Jing Qin,Ann Dorothy King,Winnie Chiu-Wing Chu,Jing Cai,Michael Tin-Cheung Yingınst*

Main category: cs.CV

TL;DR: 该研究通过领域适应方法优化视觉-语言基础模型，提升超声图像分析的性能，在分割和分类任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 超声图像的手动标注耗时且结果不一致，视觉-语言基础模型在医学图像领域表现受限，需克服领域差异。

Method: 利用大语言模型作为文本细化器，结合特殊设计的适应策略和任务驱动头，对视觉-语言基础模型进行微调。

Result: 在六个超声数据集上的实验表明，该方法显著提升了模型性能，优于现有视觉-语言和纯基础模型。

Conclusion: 提出的方法有效解决了视觉-语言基础模型在医学图像领域的适应问题，为超声图像分析提供了新工具。

Abstract: Medical ultrasonography is an essential imaging technique for examining
superficial organs and tissues, including lymph nodes, breast, and thyroid. It
employs high-frequency ultrasound waves to generate detailed images of the
internal structures of the human body. However, manually contouring regions of
interest in these images is a labor-intensive task that demands expertise and
often results in inconsistent interpretations among individuals.
Vision-language foundation models, which have excelled in various computer
vision applications, present new opportunities for enhancing ultrasound image
analysis. Yet, their performance is hindered by the significant differences
between natural and medical imaging domains. This research seeks to overcome
these challenges by developing domain adaptation methods for vision-language
foundation models. In this study, we explore the fine-tuning pipeline for
vision-language foundation models by utilizing large language model as text
refiner with special-designed adaptation strategies and task-driven heads. Our
approach has been extensively evaluated on six ultrasound datasets and two
tasks: segmentation and classification. The experimental results show that our
method can effectively improve the performance of vision-language foundation
models for ultrasound image analysis, and outperform the existing
state-of-the-art vision-language and pure foundation models. The source code of
this study is available at
\href{https://github.com/jinggqu/NextGen-UIA}{GitHub}.

</details>


### [150] [Spatial Transcriptomics Expression Prediction from Histopathology Based on Cross-Modal Mask Reconstruction and Contrastive Learning](https://arxiv.org/abs/2506.08854)
*Junzhuo Liu,Markus Eckstein,Zhixiang Wang,Friedrich Feuerhake,Dorit Merhof*

Main category: cs.CV

TL;DR: 本研究提出了一种基于对比学习的深度学习方法，用于从全切片图像预测空间转录组数据，显著提高了基因表达的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 空间转录组技术成本高昂，大规模数据难以获取，因此需要一种高效的方法从现有图像数据中预测基因表达。

Method: 采用对比学习框架的深度学习方法，从全切片图像预测空间转录组数据。

Result: 在六个疾病数据集上评估，预测高表达基因、高变异基因和标记基因的Pearson相关系数分别提高了6.27%、6.11%和11.26%。

Conclusion: 该方法不仅保留了基因间相关性，还适用于小样本数据集，并在癌症组织定位中显示出潜力。

Abstract: Spatial transcriptomics is a technology that captures gene expression levels
at different spatial locations, widely used in tumor microenvironment analysis
and molecular profiling of histopathology, providing valuable insights into
resolving gene expression and clinical diagnosis of cancer. Due to the high
cost of data acquisition, large-scale spatial transcriptomics data remain
challenging to obtain. In this study, we develop a contrastive learning-based
deep learning method to predict spatially resolved gene expression from
whole-slide images. Evaluation across six different disease datasets
demonstrates that, compared to existing studies, our method improves Pearson
Correlation Coefficient (PCC) in the prediction of highly expressed genes,
highly variable genes, and marker genes by 6.27%, 6.11%, and 11.26%
respectively. Further analysis indicates that our method preserves gene-gene
correlations and applies to datasets with limited samples. Additionally, our
method exhibits potential in cancer tissue localization based on biomarker
expression.

</details>


### [151] [StreamSplat: Towards Online Dynamic 3D Reconstruction from Uncalibrated Video Streams](https://arxiv.org/abs/2506.08862)
*Zike Wu,Qi Yan,Xuanyu Yi,Lele Wang,Renjie Liao*

Main category: cs.CV

TL;DR: StreamSplat是一个实时处理未校准视频流并重建动态3D场景的框架，解决了实时性、动态建模和长期稳定性的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时处理未校准输入的实时性、动态场景建模和长期稳定性。

Method: 提出StreamSplat框架，包含静态编码器的概率采样机制和动态解码器的双向变形场。

Result: 在静态和动态基准测试中表现优异，支持任意长度视频流的在线重建。

Conclusion: StreamSplat在重建质量和动态建模上优于现有方法，适用于长期视频流的实时处理。

Abstract: Real-time reconstruction of dynamic 3D scenes from uncalibrated video streams
is crucial for numerous real-world applications. However, existing methods
struggle to jointly address three key challenges: 1) processing uncalibrated
inputs in real time, 2) accurately modeling dynamic scene evolution, and 3)
maintaining long-term stability and computational efficiency. To this end, we
introduce StreamSplat, the first fully feed-forward framework that transforms
uncalibrated video streams of arbitrary length into dynamic 3D Gaussian
Splatting (3DGS) representations in an online manner, capable of recovering
scene dynamics from temporally local observations. We propose two key technical
innovations: a probabilistic sampling mechanism in the static encoder for 3DGS
position prediction, and a bidirectional deformation field in the dynamic
decoder that enables robust and efficient dynamic modeling. Extensive
experiments on static and dynamic benchmarks demonstrate that StreamSplat
consistently outperforms prior works in both reconstruction quality and dynamic
scene modeling, while uniquely supporting online reconstruction of arbitrarily
long video streams. Code and models are available at
https://github.com/nickwzk/StreamSplat.

</details>


### [152] [DiscoVLA: Discrepancy Reduction in Vision, Language, and Alignment for Parameter-Efficient Video-Text Retrieval](https://arxiv.org/abs/2506.08887)
*Leqi Shen,Guoqiang Gong,Tianxiang Hao,Tao He,Yifeng Zhang,Pengzhang Liu,Sicheng Zhao,Jungong Han,Guiguang Ding*

Main category: cs.CV

TL;DR: 论文提出DiscoVLA方法，通过同时减少视觉、语言和对齐的差异，提升视频-文本检索性能。


<details>
  <summary>Details</summary>
Motivation: CLIP模型专注于图像级视觉-语言匹配，而视频-文本检索需要视频级的全面理解，现有方法主要关注视觉差异，忽略了语言和对齐。

Method: 提出Image-Video Features Fusion整合图像级和视频级特征，生成伪图像标题学习细粒度对齐，并通过Image-to-Video Alignment Distillation增强视频级对齐。

Result: 在MSRVTT数据集上，DiscoVLA以CLIP（ViT-B/16）为基础，R@1达到50.5%，优于之前方法1.5%。

Conclusion: DiscoVLA通过综合解决视觉、语言和对齐差异，显著提升了视频-文本检索性能。

Abstract: The parameter-efficient adaptation of the image-text pretraining model CLIP
for video-text retrieval is a prominent area of research. While CLIP is focused
on image-level vision-language matching, video-text retrieval demands
comprehensive understanding at the video level. Three key discrepancies emerge
in the transfer from image-level to video-level: vision, language, and
alignment. However, existing methods mainly focus on vision while neglecting
language and alignment. In this paper, we propose Discrepancy Reduction in
Vision, Language, and Alignment (DiscoVLA), which simultaneously mitigates all
three discrepancies. Specifically, we introduce Image-Video Features Fusion to
integrate image-level and video-level features, effectively tackling both
vision and language discrepancies. Additionally, we generate pseudo image
captions to learn fine-grained image-level alignment. To mitigate alignment
discrepancies, we propose Image-to-Video Alignment Distillation, which
leverages image-level alignment knowledge to enhance video-level alignment.
Extensive experiments demonstrate the superiority of our DiscoVLA. In
particular, on MSRVTT with CLIP (ViT-B/16), DiscoVLA outperforms previous
methods by 1.5% in R@1, reaching a final score of 50.5% R@1. The code is
available at https://github.com/LunarShen/DsicoVLA.

</details>


### [153] [Product of Experts for Visual Generation](https://arxiv.org/abs/2506.08894)
*Yunzhi Zhang,Carson Murtuza-Lanier,Zizhang Li,Yilun Du,Jiajun Wu*

Main category: cs.CV

TL;DR: 提出了一种基于专家乘积（PoE）的框架，用于在推理时组合异构模型的知识，通过退火重要性采样（AIS）实现，在图像和视频合成任务中表现出更好的可控性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 现代神经模型具有丰富的先验知识，但如何整合来自不同来源（如生成模型、语言模型、图形引擎等）的多样化知识仍未被充分探索。

Method: 采用专家乘积（PoE）框架，通过退火重要性采样（AIS）从异构模型中组合知识，无需额外训练。

Result: 在图像和视频合成任务中表现出更好的可控性，并提供灵活的用户界面以指定生成目标。

Conclusion: 该框架为异构知识整合提供了一种高效且灵活的方法，具有实际应用潜力。

Abstract: Modern neural models capture rich priors and have complementary knowledge
over shared data domains, e.g., images and videos. Integrating diverse
knowledge from multiple sources -- including visual generative models, visual
language models, and sources with human-crafted knowledge such as graphics
engines and physics simulators -- remains under-explored. We propose a Product
of Experts (PoE) framework that performs inference-time knowledge composition
from heterogeneous models. This training-free approach samples from the product
distribution across experts via Annealed Importance Sampling (AIS). Our
framework shows practical benefits in image and video synthesis tasks, yielding
better controllability than monolithic methods and additionally providing
flexible user interfaces for specifying visual generation goals.

</details>


### [154] [WetCat: Automating Skill Assessment in Wetlab Cataract Surgery Videos](https://arxiv.org/abs/2506.08896)
*Negin Ghamsarian,Raphael Sznitman,Klaus Schoeffmann,Jens Kowal*

Main category: cs.CV

TL;DR: WetCat是首个专为自动化技能评估设计的湿实验室白内障手术视频数据集，旨在解决传统手动评估的低效和主观性问题。


<details>
  <summary>Details</summary>
Motivation: 传统湿实验室训练依赖手动评估，效率低且主观性强，计算机视觉技术为自动化技能评估提供了新途径。

Method: 构建WetCat数据集，包含高分辨率视频、详细阶段标注和关键解剖结构分割，聚焦于囊膜撕开和超声乳化阶段。

Result: WetCat为开发可解释的AI评估工具奠定了基础，支持客观、可扩展的手术教育。

Conclusion: WetCat推动了眼科手术培训的自动化和标准化，为未来研究设定了新基准。

Abstract: To meet the growing demand for systematic surgical training, wetlab
environments have become indispensable platforms for hands-on practice in
ophthalmology. Yet, traditional wetlab training depends heavily on manual
performance evaluations, which are labor-intensive, time-consuming, and often
subject to variability. Recent advances in computer vision offer promising
avenues for automated skill assessment, enhancing both the efficiency and
objectivity of surgical education. Despite notable progress in ophthalmic
surgical datasets, existing resources predominantly focus on real surgeries or
isolated tasks, falling short of supporting comprehensive skill evaluation in
controlled wetlab settings. To address these limitations, we introduce WetCat,
the first dataset of wetlab cataract surgery videos specifically curated for
automated skill assessment. WetCat comprises high-resolution recordings of
surgeries performed by trainees on artificial eyes, featuring comprehensive
phase annotations and semantic segmentations of key anatomical structures.
These annotations are meticulously designed to facilitate skill assessment
during the critical capsulorhexis and phacoemulsification phases, adhering to
standardized surgical skill assessment frameworks. By focusing on these
essential phases, WetCat enables the development of interpretable, AI-driven
evaluation tools aligned with established clinical metrics. This dataset lays a
strong foundation for advancing objective, scalable surgical education and sets
a new benchmark for automated workflow analysis and skill assessment in
ophthalmology training. The dataset and annotations are publicly available in
Synapse https://www.synapse.org/Synapse:syn66401174/files.

</details>


### [155] [MIRAGE: Multimodal foundation model and benchmark for comprehensive retinal OCT image analysis](https://arxiv.org/abs/2506.08900)
*José Morano,Botond Fazekas,Emese Sükei,Ronald Fecso,Taha Emre,Markus Gumpinger,Georg Faustmann,Marzieh Oghbaie,Ursula Schmidt-Erfurth,Hrvoje Bogunović*

Main category: cs.CV

TL;DR: MIRAGE是一种新型多模态基础模型，用于分析OCT和SLO图像，并在分类和分割任务中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型在眼科图像分析中依赖大量标注数据且泛化能力不足，基础模型虽有望解决这些问题，但缺乏验证和多模态支持。

Method: 提出MIRAGE多模态基础模型，并设计新的评估基准，涵盖OCT/SLO分类和分割任务。

Result: MIRAGE在分类和分割任务中优于通用和专用基础模型及分割方法。

Conclusion: MIRAGE适合作为开发稳健眼科AI系统的基础，模型和评估基准已公开。

Abstract: Artificial intelligence (AI) has become a fundamental tool for assisting
clinicians in analyzing ophthalmic images, such as optical coherence tomography
(OCT). However, developing AI models often requires extensive annotation, and
existing models tend to underperform on independent, unseen data. Foundation
models (FMs), large AI models trained on vast unlabeled datasets, have shown
promise in overcoming these challenges. Nonetheless, available FMs for
ophthalmology lack extensive validation, especially for segmentation tasks, and
focus on a single imaging modality. In this context, we propose MIRAGE, a novel
multimodal FM for the analysis of OCT and scanning laser ophthalmoscopy (SLO)
images. Additionally, we propose a new evaluation benchmark with OCT/SLO
classification and segmentation tasks. The comparison with general and
specialized FMs and segmentation methods shows the superiority of MIRAGE in
both types of tasks, highlighting its suitability as a basis for the
development of robust AI systems for retinal OCT image analysis. Both MIRAGE
and the evaluation benchmark are publicly available:
https://github.com/j-morano/MIRAGE.

</details>


### [156] [Hyperbolic Dual Feature Augmentation for Open-Environment](https://arxiv.org/abs/2506.08906)
*Peilin Yu,Yuwei Wu,Zhi Gao,Xiaomeng Fan,Shuo Yang,Yunde Jia*

Main category: cs.CV

TL;DR: 提出了一种双曲双特征增强方法，用于开放环境中的特征增强，包括已知和未知类别，通过神经ODE模块和元学习优化特征分布估计，并引入正则化器保持层次结构。


<details>
  <summary>Details</summary>
Motivation: 现有双曲特征增强方法局限于封闭环境，仅针对已知类别生成特征，无法适应开放环境中的未知类别需求。

Method: 1. 使用神经ODE模块和元学习估计特征分布；2. 引入正则化器保持数据层次结构；3. 推导双曲双增强损失的上界。

Result: 在五种开放环境任务（类增量学习、少样本开放集识别等）中显著提升了双曲算法的性能。

Conclusion: 该方法有效增强了双曲算法在开放环境中的泛化能力。

Abstract: Feature augmentation generates novel samples in the feature space, providing
an effective way to enhance the generalization ability of learning algorithms
with hyperbolic geometry. Most hyperbolic feature augmentation is confined to
closed-environment, assuming the number of classes is fixed (\emph{i.e.}, seen
classes) and generating features only for these classes. In this paper, we
propose a hyperbolic dual feature augmentation method for open-environment,
which augments features for both seen and unseen classes in the hyperbolic
space. To obtain a more precise approximation of the real data distribution for
efficient training, (1) we adopt a neural ordinary differential equation
module, enhanced by meta-learning, estimating the feature distributions of both
seen and unseen classes; (2) we then introduce a regularizer to preserve the
latent hierarchical structures of data in the hyperbolic space; (3) we also
derive an upper bound for the hyperbolic dual augmentation loss, allowing us to
train a hyperbolic model using infinite augmentations for seen and unseen
classes. Extensive experiments on five open-environment tasks:
class-incremental learning, few-shot open-set recognition, few-shot learning,
zero-shot learning, and general image classification, demonstrate that our
method effectively enhances the performance of hyperbolic algorithms in
open-environment.

</details>


### [157] [SkipVAR: Accelerating Visual Autoregressive Modeling via Adaptive Frequency-Aware Skipping](https://arxiv.org/abs/2506.08908)
*Jiajun Li,Yue Ma,Xinyu Zhang,Qingyan Wei,Songhua Liu,Linfeng Zhang*

Main category: cs.CV

TL;DR: 论文提出SkipVAR框架，通过动态跳过冗余步骤和替换无条件分支，显著加速VAR模型的推理过程，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 研究发现VAR模型的高频组件或后期步骤对推理延迟贡献过大，但相关计算冗余尚未深入探讨。

Method: 提出自动跳过步骤策略和替换无条件分支技术，并基于频率信息动态选择加速策略。

Result: SkipVAR在保持0.88平均SSIM的同时，实现1.81倍整体加速和2.62倍GenEval基准速度提升。

Conclusion: 频率感知的自适应加速策略有效提升了自回归图像生成的可扩展性。

Abstract: Recent studies on Visual Autoregressive (VAR) models have highlighted that
high-frequency components, or later steps, in the generation process contribute
disproportionately to inference latency. However, the underlying computational
redundancy involved in these steps has yet to be thoroughly investigated. In
this paper, we conduct an in-depth analysis of the VAR inference process and
identify two primary sources of inefficiency: step redundancy and unconditional
branch redundancy. To address step redundancy, we propose an automatic
step-skipping strategy that selectively omits unnecessary generation steps to
improve efficiency. For unconditional branch redundancy, we observe that the
information gap between the conditional and unconditional branches is minimal.
Leveraging this insight, we introduce unconditional branch replacement, a
technique that bypasses the unconditional branch to reduce computational cost.
Notably, we observe that the effectiveness of acceleration strategies varies
significantly across different samples. Motivated by this, we propose SkipVAR,
a sample-adaptive framework that leverages frequency information to dynamically
select the most suitable acceleration strategy for each instance. To evaluate
the role of high-frequency information, we introduce high-variation benchmark
datasets that test model sensitivity to fine details. Extensive experiments
show SkipVAR achieves over 0.88 average SSIM with up to 1.81x overall
acceleration and 2.62x speedup on the GenEval benchmark, maintaining model
quality. These results confirm the effectiveness of frequency-aware,
training-free adaptive acceleration for scalable autoregressive image
generation. Our code is available at https://github.com/fakerone-li/SkipVAR and
has been publicly released.

</details>


### [158] [Inherently Faithful Attention Maps for Vision Transformers](https://arxiv.org/abs/2506.08915)
*Ananthu Aniraj,Cassio F. Dantas,Dino Ienco,Diego Marcos*

Main category: cs.CV

TL;DR: 提出了一种基于注意力机制的两阶段框架，通过二进制注意力掩码确保预测仅受关注区域影响，显著提升对虚假相关性和分布外背景的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 上下文可能强烈影响对象感知，导致偏差表示，尤其是对象出现在分布外背景时。同时，许多图像级任务需要识别相关区域，通常依赖上下文。

Method: 采用两阶段框架：第一阶段处理完整图像以发现对象部分和任务相关区域；第二阶段利用注意力掩码限制感受野至这些区域，过滤潜在虚假信息。两阶段联合训练，第二阶段可优化第一阶段。

Result: 在多个基准测试中，该方法显著提升了对虚假相关性和分布外背景的鲁棒性。

Conclusion: 提出的两阶段框架通过注意力掩码有效解决了上下文依赖与偏差问题，提升了任务性能。

Abstract: We introduce an attention-based method that uses learned binary attention
masks to ensure that only attended image regions influence the prediction.
Context can strongly affect object perception, sometimes leading to biased
representations, particularly when objects appear in out-of-distribution
backgrounds. At the same time, many image-level object-centric tasks require
identifying relevant regions, often requiring context. To address this
conundrum, we propose a two-stage framework: stage 1 processes the full image
to discover object parts and identify task-relevant regions, while stage 2
leverages input attention masking to restrict its receptive field to these
regions, enabling a focused analysis while filtering out potentially spurious
information. Both stages are trained jointly, allowing stage 2 to refine stage
1. Extensive experiments across diverse benchmarks demonstrate that our
approach significantly improves robustness against spurious correlations and
out-of-distribution backgrounds.

</details>


### [159] [Socratic-MCTS: Test-Time Visual Reasoning by Asking the Right Questions](https://arxiv.org/abs/2506.08927)
*David Acuna,Ximing Lu,Jaehun Jung,Hyunwoo Kim,Amlan Kar,Sanja Fidler,Yejin Choi*

Main category: cs.CV

TL;DR: 论文探讨了如何通过蒙特卡洛树搜索（MCTS）算法，在不额外训练或监督的情况下，从非推理视觉语言模型中提取隐藏知识并生成长推理链。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索是否可以通过搜索机制从已部署的非推理模型中提取知识，而不需要放弃这些模型或进行额外训练。

Method: 采用蒙特卡洛树搜索（MCTS）算法，通过注入子问题-子答案对来引导模型生成推理链。

Result: 在三个基准测试中表现一致提升，其中MMMU-PRO基准上整体提升2%，文科领域提升显著（9%）。

Conclusion: 研究表明，将推理视为搜索过程可以有效帮助非推理模型连接碎片化知识并生成长推理链。

Abstract: Recent research in vision-language models (VLMs) has centered around the
possibility of equipping them with implicit long-form chain-of-thought
reasoning -- akin to the success observed in language models -- via
distillation and reinforcement learning. But what about the non-reasoning
models already trained and deployed across the internet? Should we simply
abandon them, or is there hope for a search mechanism that can elicit hidden
knowledge and induce long reasoning traces -- without any additional training
or supervision? In this paper, we explore this possibility using a Monte Carlo
Tree Search (MCTS)-inspired algorithm, which injects subquestion-subanswer
pairs into the model's output stream. We show that framing reasoning as a
search process -- where subquestions act as latent decisions within a broader
inference trajectory -- helps the model "connect the dots" between fragmented
knowledge and produce extended reasoning traces in non-reasoning models. We
evaluate our method across three benchmarks and observe consistent
improvements. Notably, our approach yields a 2% overall improvement on
MMMU-PRO, including a significant 9% gain in Liberal Arts.

</details>


### [160] [What Limits Virtual Agent Application? OmniBench: A Scalable Multi-Dimensional Benchmark for Essential Virtual Agent Capabilities](https://arxiv.org/abs/2506.08933)
*Wendong Bu,Yang Wu,Qifan Yu,Minghe Gao,Bingchen Miao,Zhenkui Zhang,Kaihang Pan,Yunfei Li,Mengze Li,Wei Ji,Juncheng Li,Siliang Tang,Yueting Zhuang*

Main category: cs.CV

TL;DR: OmniBench是一个自生成、跨平台的基于图的基准测试，通过子任务组合合成可控复杂度的任务，解决了现有基准测试的局限性。OmniEval是一个多维评估框架，用于评估虚拟代理的多样化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试存在任务复杂度不可控、人工标注场景有限、缺乏多维评估等问题，需要一种更高效、全面的评估方法。

Method: 提出OmniBench和OmniEval，前者通过子任务组合生成可控复杂度的任务，后者提供多维评估框架，包括子任务级评估、基于图的指标和10种能力的综合测试。

Result: 合成的数据集包含20个场景中的36k个图结构任务，人类接受率达91%。图结构数据比人工标注数据更高效地指导代理。多维评估揭示了开源和闭源模型在不同能力上的表现。

Conclusion: OmniBench和OmniEval为虚拟代理的评估提供了高效、全面的解决方案，为未来研究奠定了基础。

Abstract: As multimodal large language models (MLLMs) advance, MLLM-based virtual
agents have demonstrated remarkable performance. However, existing benchmarks
face significant limitations, including uncontrollable task complexity,
extensive manual annotation with limited scenarios, and a lack of
multidimensional evaluation. In response to these challenges, we introduce
OmniBench, a self-generating, cross-platform, graph-based benchmark with an
automated pipeline for synthesizing tasks of controllable complexity through
subtask composition. To evaluate the diverse capabilities of virtual agents on
the graph, we further present OmniEval, a multidimensional evaluation framework
that includes subtask-level evaluation, graph-based metrics, and comprehensive
tests across 10 capabilities. Our synthesized dataset contains 36k
graph-structured tasks across 20 scenarios, achieving a 91\% human acceptance
rate. Training on our graph-structured data shows that it can more efficiently
guide agents compared to manually annotated data. We conduct multidimensional
evaluations for various open-source and closed-source models, revealing their
performance across various capabilities and paving the way for future
advancements. Our project is available at https://omni-bench.github.io/.

</details>


### [161] [SSS: Semi-Supervised SAM-2 with Efficient Prompting for Medical Imaging Segmentation](https://arxiv.org/abs/2506.08949)
*Hongjie Zhu,Xiwei Liu,Rundong Xue,Zeyu Zhang,Yong Xu,Daji Ergu,Ying Cai,Yang Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种名为SSS的半监督学习方法，利用SAM-2的强大特征提取能力，结合多视图数据增强和特征增强机制，显著提升了医学图像分割的性能。


<details>
  <summary>Details</summary>
Motivation: 在医学图像分析中，减少对高质量标注数据的依赖并充分利用无标注数据是一个关键挑战。半监督学习通过知识迁移提升模型性能，而SAM-2等视觉基础模型提供了丰富的先验知识。

Method: 基于单流'弱到强'一致性正则化框架，引入判别性特征增强（DFE）机制，利用多尺度数据增强的特征差异优化显著区域。同时设计了提示生成器，结合物理约束和滑动窗口机制为无标注数据生成输入提示。

Result: 在ACDC和BHSD数据集上的实验表明，SSS方法显著优于现有方法，BHSD上的平均Dice分数达到53.15，比之前最优方法提升了3.65。

Conclusion: SSS方法通过结合SAM-2的特征提取能力和半监督学习框架，有效提升了医学图像分割的性能，为减少标注依赖提供了新思路。

Abstract: In the era of information explosion, efficiently leveraging large-scale
unlabeled data while minimizing the reliance on high-quality pixel-level
annotations remains a critical challenge in the field of medical imaging.
Semi-supervised learning (SSL) enhances the utilization of unlabeled data by
facilitating knowledge transfer, significantly improving the performance of
fully supervised models and emerging as a highly promising research direction
in medical image analysis. Inspired by the ability of Vision Foundation Models
(e.g., SAM-2) to provide rich prior knowledge, we propose SSS (Semi-Supervised
SAM-2), a novel approach that leverages SAM-2's robust feature extraction
capabilities to uncover latent knowledge in unlabeled medical images, thus
effectively enhancing feature support for fully supervised medical image
segmentation. Specifically, building upon the single-stream "weak-to-strong"
consistency regularization framework, this paper introduces a Discriminative
Feature Enhancement (DFE) mechanism to further explore the feature
discrepancies introduced by various data augmentation strategies across
multiple views. By leveraging feature similarity and dissimilarity across
multi-scale augmentation techniques, the method reconstructs and models the
features, thereby effectively optimizing the salient regions. Furthermore, a
prompt generator is developed that integrates Physical Constraints with a
Sliding Window (PCSW) mechanism to generate input prompts for unlabeled data,
fulfilling SAM-2's requirement for additional prompts. Extensive experiments
demonstrate the superiority of the proposed method for semi-supervised medical
image segmentation on two multi-label datasets, i.e., ACDC and BHSD. Notably,
SSS achieves an average Dice score of 53.15 on BHSD, surpassing the previous
state-of-the-art method by +3.65 Dice. Code will be available at
https://github.com/AIGeeksGroup/SSS.

</details>


### [162] [Cross-Spectral Body Recognition with Side Information Embedding: Benchmarks on LLCM and Analyzing Range-Induced Occlusions on IJB-MDF](https://arxiv.org/abs/2506.08953)
*Anirudh Nanduri,Siyuan Huang,Rama Chellappa*

Main category: cs.CV

TL;DR: 本文研究了如何将预训练的ViT模型应用于跨光谱人体识别任务，通过引入Side Information Embedding（SIE）提升性能，并发现仅编码相机信息即可达到最佳效果。同时，探讨了可见-红外（VI）Re-ID中遮挡问题的研究空白。


<details>
  <summary>Details</summary>
Motivation: 跨光谱人体识别（如可见光与红外图像匹配）是一个具有挑战性的任务，现有方法在遮挡处理方面研究不足，尤其是在VI-Re-ID领域。

Method: 通过引入Side Information Embedding（SIE）编码相机和域信息，并利用预训练的ViT模型进行跨光谱匹配。实验在LLCM和IJB-MDF数据集上进行。

Result: 仅编码相机信息（不显式包含域信息）在LLCM数据集上达到了最先进的性能。同时，利用IJB-MDF数据集分析了跨范围、跨光谱的遮挡问题。

Conclusion: 研究表明，相机信息对跨光谱匹配至关重要，而VI-Re-ID中的遮挡问题仍需进一步研究。

Abstract: Vision Transformers (ViTs) have demonstrated impressive performance across a
wide range of biometric tasks, including face and body recognition. In this
work, we adapt a ViT model pretrained on visible (VIS) imagery to the
challenging problem of cross-spectral body recognition, which involves matching
images captured in the visible and infrared (IR) domains. Recent ViT
architectures have explored incorporating additional embeddings beyond
traditional positional embeddings. Building on this idea, we integrate Side
Information Embedding (SIE) and examine the impact of encoding domain and
camera information to enhance cross-spectral matching. Surprisingly, our
results show that encoding only camera information - without explicitly
incorporating domain information - achieves state-of-the-art performance on the
LLCM dataset. While occlusion handling has been extensively studied in
visible-spectrum person re-identification (Re-ID), occlusions in
visible-infrared (VI) Re-ID remain largely underexplored - primarily because
existing VI-ReID datasets, such as LLCM, SYSU-MM01, and RegDB, predominantly
feature full-body, unoccluded images. To address this gap, we analyze the
impact of range-induced occlusions using the IARPA Janus Benchmark Multi-Domain
Face (IJB-MDF) dataset, which provides a diverse set of visible and infrared
images captured at various distances, enabling cross-range, cross-spectral
evaluations.

</details>


### [163] [Segment Concealed Objects with Incomplete Supervision](https://arxiv.org/abs/2506.08955)
*Chunming He,Kai Li,Yachao Zhang,Ziyun Yang,Youwei Pang,Longxiang Tang,Chengyu Fang,Yulun Zhang,Linghe Kong,Xiu Li,Sina Farsiu*

Main category: cs.CV

TL;DR: 论文提出了一种统一方法SEE，用于不完全监督的隐蔽物体分割（ISCOS），通过结合SAM生成伪标签和混合粒度特征分组模块，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 隐蔽物体分割任务面临不完全标注数据和物体与背景相似性高的挑战，现有方法难以有效解决。

Method: 提出SEE框架，利用SAM生成伪标签，并设计伪标签生成、存储和监督策略；引入混合粒度特征分组模块提升分割一致性。

Result: 实验表明，SEE在多个ISCOS任务中达到最优性能，并可作为即插即用方案提升现有模型。

Conclusion: SEE通过统一框架和特征分组模块，有效解决了ISCOS任务中的监督不足和相似性问题，具有广泛应用潜力。

Abstract: Incompletely-Supervised Concealed Object Segmentation (ISCOS) involves
segmenting objects that seamlessly blend into their surrounding environments,
utilizing incompletely annotated data, such as weak and semi-annotations, for
model training. This task remains highly challenging due to (1) the limited
supervision provided by the incompletely annotated training data, and (2) the
difficulty of distinguishing concealed objects from the background, which
arises from the intrinsic similarities in concealed scenarios. In this paper,
we introduce the first unified method for ISCOS to address these challenges. To
tackle the issue of incomplete supervision, we propose a unified mean-teacher
framework, SEE, that leverages the vision foundation model, ``\emph{Segment
Anything Model (SAM)}'', to generate pseudo-labels using coarse masks produced
by the teacher model as prompts. To mitigate the effect of low-quality
segmentation masks, we introduce a series of strategies for pseudo-label
generation, storage, and supervision. These strategies aim to produce
informative pseudo-labels, store the best pseudo-labels generated, and select
the most reliable components to guide the student model, thereby ensuring
robust network training. Additionally, to tackle the issue of intrinsic
similarity, we design a hybrid-granularity feature grouping module that groups
features at different granularities and aggregates these results. By clustering
similar features, this module promotes segmentation coherence, facilitating
more complete segmentation for both single-object and multiple-object images.
We validate the effectiveness of our approach across multiple ISCOS tasks, and
experimental results demonstrate that our method achieves state-of-the-art
performance. Furthermore, SEE can serve as a plug-and-play solution, enhancing
the performance of existing models.

</details>


### [164] [Data Augmentation For Small Object using Fast AutoAugment](https://arxiv.org/abs/2506.08956)
*DaeEun Yoon,Semin Kim,SangWook Yoo,Jongha Lee*

Main category: cs.CV

TL;DR: 论文提出了一种基于Fast AutoAugment的数据增强方法，显著提升了小目标检测性能，在DOTA数据集上实现了20%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 尽管目标检测整体性能有所提升，但小目标检测性能仍显著落后于大目标检测，这是计算机视觉中的重要挑战。

Method: 采用Fast AutoAugment技术，快速找到最优的数据增强策略，以克服小目标检测中的性能退化问题。

Result: 在DOTA数据集上实现了20%的性能提升。

Conclusion: 提出的数据增强方法有效解决了小目标检测性能不足的问题，具有实际应用价值。

Abstract: In recent years, there has been tremendous progress in object detection
performance. However, despite these advances, the detection performance for
small objects is significantly inferior to that of large objects. Detecting
small objects is one of the most challenging and important problems in computer
vision. To improve the detection performance for small objects, we propose an
optimal data augmentation method using Fast AutoAugment. Through our proposed
method, we can quickly find optimal augmentation policies that can overcome
degradation when detecting small objects, and we achieve a 20% performance
improvement on the DOTA dataset.

</details>


### [165] [ORIDa: Object-centric Real-world Image Composition Dataset](https://arxiv.org/abs/2506.08964)
*Jinwoo Kim,Sangmin Han,Jinho Jeong,Jiwoo Choi,Dongyoung Kim,Seon Joo Kim*

Main category: cs.CV

TL;DR: ORIDa是一个大规模真实世界图像合成数据集，包含30,000多张图像和200个独特对象，支持多样化的场景和位置。


<details>
  <summary>Details</summary>
Motivation: 现有数据集缺乏多样性和规模，无法全面探索真实世界场景。

Method: ORIDa包含事实-反事实集和事实场景两种数据类型，前者展示对象在不同位置和背景中的变化，后者扩展环境多样性。

Result: ORIDa是首个公开的大规模复杂数据集，为对象合成研究提供了重要资源。

Conclusion: ORIDa通过其规模和复杂性，推动了对象合成领域的进一步研究。

Abstract: Object compositing, the task of placing and harmonizing objects in images of
diverse visual scenes, has become an important task in computer vision with the
rise of generative models. However, existing datasets lack the diversity and
scale required to comprehensively explore real-world scenarios. We introduce
ORIDa (Object-centric Real-world Image Composition Dataset), a large-scale,
real-captured dataset containing over 30,000 images featuring 200 unique
objects, each of which is presented across varied positions and scenes. ORIDa
has two types of data: factual-counterfactual sets and factual-only scenes. The
factual-counterfactual sets consist of four factual images showing an object in
different positions within a scene and a single counterfactual (or background)
image of the scene without the object, resulting in five images per scene. The
factual-only scenes include a single image containing an object in a specific
context, expanding the variety of environments. To our knowledge, ORIDa is the
first publicly available dataset with its scale and complexity for real-world
image composition. Extensive analysis and experiments highlight the value of
ORIDa as a resource for advancing further research in object compositing.

</details>


### [166] [ADAM: Autonomous Discovery and Annotation Model using LLMs for Context-Aware Annotations](https://arxiv.org/abs/2506.08968)
*Amirreza Rouhi,Solmaz Arezoomandan,Knut Peterson,Joseph T. Woods,David K. Han*

Main category: cs.CV

TL;DR: ADAM是一种无需训练的自发现和标注模型，利用LLM和CLIP生成未知对象的标签，并通过自优化框架提升标注一致性。


<details>
  <summary>Details</summary>
Motivation: 解决传统目标检测模型依赖预定义类别、无法识别开放世界中新对象的问题。

Method: 结合LLM生成候选标签和CLIP视觉嵌入构建ELR，通过频率投票和跨模态重排序分配标签，并引入自优化循环提升一致性。

Result: 在COCO和PASCAL数据集上，ADAM无需微调即可有效标注新类别。

Conclusion: ADAM为开放世界目标标注提供了一种无需训练的高效解决方案。

Abstract: Object detection models typically rely on predefined categories, limiting
their ability to identify novel objects in open-world scenarios. To overcome
this constraint, we introduce ADAM: Autonomous Discovery and Annotation Model,
a training-free, self-refining framework for open-world object labeling. ADAM
leverages large language models (LLMs) to generate candidate labels for unknown
objects based on contextual information from known entities within a scene.
These labels are paired with visual embeddings from CLIP to construct an
Embedding-Label Repository (ELR) that enables inference without category
supervision. For a newly encountered unknown object, ADAM retrieves visually
similar instances from the ELR and applies frequency-based voting and
cross-modal re-ranking to assign a robust label. To further enhance
consistency, we introduce a self-refinement loop that re-evaluates repository
labels using visual cohesion analysis and k-nearest-neighbor-based majority
re-labeling. Experimental results on the COCO and PASCAL datasets demonstrate
that ADAM effectively annotates novel categories using only visual and
contextual signals, without requiring any fine-tuning or retraining.

</details>


### [167] [Rethinking Range-View LiDAR Segmentation in Adverse Weather](https://arxiv.org/abs/2506.08979)
*Longyu Yang,Ping Hu,Lu Zhang,Jun Liu,Yap-Peng Tan,Heng Tao Shen,Xiaofeng Zhu*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级模块化框架，通过改进标准范围视图网络的初始模块，增强LiDAR分割在恶劣天气下的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 范围视图方法在恶劣天气下的泛化性能不足，限制了其在实际环境中的可靠性。

Method: 将初始模块分为两个分支，分别处理几何属性和反射强度，并引入GAS和RDC模块抑制噪声和校准失真。

Result: 实验表明，该方法显著提升了恶劣天气下的分割性能，且推理开销极小。

Conclusion: 该框架为实际LiDAR分割提供了一种实用且高效的解决方案。

Abstract: LiDAR segmentation has emerged as an important task to enrich multimedia
experiences and analysis. Range-view-based methods have gained popularity due
to their high computational efficiency and compatibility with real-time
deployment. However, their generalized performance under adverse weather
conditions remains underexplored, limiting their reliability in real-world
environments. In this work, we identify and analyze the unique challenges that
affect the generalization of range-view LiDAR segmentation in severe weather.
To address these challenges, we propose a modular and lightweight framework
that enhances robustness without altering the core architecture of existing
models. Our method reformulates the initial stem block of standard range-view
networks into two branches to process geometric attributes and reflectance
intensity separately. Specifically, a Geometric Abnormality Suppression (GAS)
module reduces the influence of weather-induced spatial noise, and a
Reflectance Distortion Calibration (RDC) module corrects reflectance
distortions through memory-guided adaptive instance normalization. The
processed features are then fused and passed to the original segmentation
pipeline. Extensive experiments on different benchmarks and baseline models
demonstrate that our approach significantly improves generalization to adverse
weather with minimal inference overhead, offering a practical and effective
solution for real-world LiDAR segmentation.

</details>


### [168] [Efficient Medical Vision-Language Alignment Through Adapting Masked Vision Models](https://arxiv.org/abs/2506.08990)
*Chenyu Lian,Hong-Yu Zhou,Dongyun Liang,Jing Qin,Liansheng Wang*

Main category: cs.CV

TL;DR: ALTA提出了一种高效的医学视觉-语言对齐方法，通过适应预训练的视觉模型，显著提升了跨模态匹配任务的性能。


<details>
  <summary>Details</summary>
Motivation: 传统跨模态对比学习方法在视觉表示能力上表现不佳，而多模态掩码建模方法虽视觉表示能力强，但跨模态匹配效果差。ALTA旨在解决这一矛盾。

Method: ALTA通过适应预训练的视觉模型（来自掩码记录建模），结合时间多视图放射图像输入，提升视觉-语言对齐效果。

Result: ALTA在文本到图像和图像到文本检索任务中分别比最佳对比方法高出4%和6%的绝对准确率。

Conclusion: ALTA不仅高效，还促进了视觉和语言理解的提升，代码已开源。

Abstract: Medical vision-language alignment through cross-modal contrastive learning
shows promising performance in image-text matching tasks, such as retrieval and
zero-shot classification. However, conventional cross-modal contrastive
learning (CLIP-based) methods suffer from suboptimal visual representation
capabilities, which also limits their effectiveness in vision-language
alignment. In contrast, although the models pretrained via multimodal masked
modeling struggle with direct cross-modal matching, they excel in visual
representation. To address this contradiction, we propose ALTA (ALign Through
Adapting), an efficient medical vision-language alignment method that utilizes
only about 8% of the trainable parameters and less than 1/5 of the
computational consumption required for masked record modeling. ALTA achieves
superior performance in vision-language matching tasks like retrieval and
zero-shot classification by adapting the pretrained vision model from masked
record modeling. Additionally, we integrate temporal-multiview radiograph
inputs to enhance the information consistency between radiographs and their
corresponding descriptions in reports, further improving the vision-language
alignment. Experimental evaluations show that ALTA outperforms the
best-performing counterpart by over 4% absolute points in text-to-image
accuracy and approximately 6% absolute points in image-to-text retrieval
accuracy. The adaptation of vision-language models during efficient alignment
also promotes better vision and language understanding. Code is publicly
available at https://github.com/DopamineLcy/ALTA.

</details>


### [169] [Do Concept Replacement Techniques Really Erase Unacceptable Concepts?](https://arxiv.org/abs/2506.08991)
*Anudeep Das,Gurjot Singh,Prach Chantasantitam,N. Asokan*

Main category: cs.CV

TL;DR: 本文探讨了生成模型中概念替换技术（CRTs）的局限性，尤其是在图像到图像（I2I）场景中的失效问题，并提出了一种新的技术AntiMirror以提升效果和保真度。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散式文本到图像（T2I）模型在生成内容方面表现出色，但如何避免生成不可接受的内容（如冒犯性或受版权保护的内容）仍是一个挑战。现有的CRTs在T2I中有效，但在新兴的I2I场景中表现不佳。

Method: 作者首先通过实验证明现有CRTs在I2I模型中无法真正擦除不可接受的概念，随后提出CRTs应具备保真度（fidelity），即在替换不可接受概念时保留其他输入内容。最后，提出了一种名为AntiMirror的针对性图像编辑技术。

Result: 实验表明，现有CRTs在I2I场景中无效，而AntiMirror技术在替换不可接受概念的同时保持了高保真度。

Conclusion: 本文揭示了CRTs在T2I与I2I场景中的差异，提出保真度的重要性，并通过AntiMirror技术展示了解决方案的可行性。

Abstract: Generative models, particularly diffusion-based text-to-image (T2I) models,
have demonstrated astounding success. However, aligning them to avoid
generating content with unacceptable concepts (e.g., offensive or copyrighted
content, or celebrity likenesses) remains a significant challenge. Concept
replacement techniques (CRTs) aim to address this challenge, often by trying to
"erase" unacceptable concepts from models. Recently, model providers have
started offering image editing services which accept an image and a text prompt
as input, to produce an image altered as specified by the prompt. These are
known as image-to-image (I2I) models. In this paper, we first use an I2I model
to empirically demonstrate that today's state-of-the-art CRTs do not in fact
erase unacceptable concepts. Existing CRTs are thus likely to be ineffective in
emerging I2I scenarios, despite their proven ability to remove unwanted
concepts in T2I pipelines, highlighting the need to understand this discrepancy
between T2I and I2I settings. Next, we argue that a good CRT, while replacing
unacceptable concepts, should preserve other concepts specified in the inputs
to generative models. We call this fidelity. Prior work on CRTs have neglected
fidelity in the case of unacceptable concepts. Finally, we propose the use of
targeted image-editing techniques to achieve both effectiveness and fidelity.
We present such a technique, AntiMirror, and demonstrate its viability.

</details>


### [170] [SDTagNet: Leveraging Text-Annotated Navigation Maps for Online HD Map Construction](https://arxiv.org/abs/2506.08997)
*Fabian Immel,Jan-Hendrik Pauls,Richard Fehler,Frank Bieder,Jonas Merkert,Christoph Stiller*

Main category: cs.CV

TL;DR: SDTagNet是一种利用标准定义（SD）地图（如OpenStreetMap）在线构建高精地图的方法，通过引入文本注释和点级编码器，显著提升了远距离检测精度和地图感知性能。


<details>
  <summary>Details</summary>
Motivation: 高精地图维护成本高，现有在线构建方法受限于车载传感器的短感知范围，SDTagNet旨在利用广泛可用的SD地图信息解决这一问题。

Method: 结合SD地图的折线数据和文本注释，引入NLP特征；采用点级SD地图编码器和正交元素标识符，统一整合各类地图元素。

Result: 在Argoverse 2和nuScenes数据集上，相比无先验方法提升5.9 mAP（45%），比已有SD先验方法提升3.2 mAP（20%）。

Conclusion: SDTagNet通过充分利用SD地图信息，显著提升了在线高精地图构建的性能和实用性。

Abstract: Autonomous vehicles rely on detailed and accurate environmental information
to operate safely. High definition (HD) maps offer a promising solution, but
their high maintenance cost poses a significant barrier to scalable deployment.
This challenge is addressed by online HD map construction methods, which
generate local HD maps from live sensor data. However, these methods are
inherently limited by the short perception range of onboard sensors. To
overcome this limitation and improve general performance, recent approaches
have explored the use of standard definition (SD) maps as prior, which are
significantly easier to maintain. We propose SDTagNet, the first online HD map
construction method that fully utilizes the information of widely available SD
maps, like OpenStreetMap, to enhance far range detection accuracy. Our approach
introduces two key innovations. First, in contrast to previous work, we
incorporate not only polyline SD map data with manually selected classes, but
additional semantic information in the form of textual annotations. In this
way, we enrich SD vector map tokens with NLP-derived features, eliminating the
dependency on predefined specifications or exhaustive class taxonomies. Second,
we introduce a point-level SD map encoder together with orthogonal element
identifiers to uniformly integrate all types of map elements. Experiments on
Argoverse 2 and nuScenes show that this boosts map perception performance by up
to +5.9 mAP (+45%) w.r.t. map construction without priors and up to +3.2 mAP
(+20%) w.r.t. previous approaches that already use SD map priors. Code is
available at https://github.com/immel-f/SDTagNet

</details>


### [171] [Do MIL Models Transfer?](https://arxiv.org/abs/2506.09022)
*Daniel Shao,Richard J. Chen,Andrew H. Song,Joel Runevic,Ming Y. Lu,Tong Ding,Faisal Mahmood*

Main category: cs.CV

TL;DR: 本文研究了多实例学习（MIL）模型在计算病理学中的迁移学习能力，发现预训练MIL模型即使在不同器官上训练也能显著优于从头训练的模型，并展示了泛癌数据集预训练的强大泛化能力。


<details>
  <summary>Details</summary>
Motivation: 计算病理学中MIL模型在数据稀缺和小规模弱监督数据集上的表现不佳，迁移学习的潜力尚未充分探索。

Method: 系统评估了11个MIL模型在21个预训练任务中的表现，用于形态学和分子亚型预测。

Result: 预训练MIL模型在不同器官和目标任务上表现优于从头训练模型，泛癌数据集预训练展现出强大泛化能力。

Conclusion: MIL模型具有强大的适应能力，迁移学习可显著提升计算病理学任务性能，并提供了标准化实现和预训练模型资源。

Abstract: Multiple Instance Learning (MIL) is a cornerstone approach in computational
pathology (CPath) for generating clinically meaningful slide-level embeddings
from gigapixel tissue images. However, MIL often struggles with small, weakly
supervised clinical datasets. In contrast to fields such as NLP and
conventional computer vision, where transfer learning is widely used to address
data scarcity, the transferability of MIL models remains poorly understood. In
this study, we systematically evaluate the transfer learning capabilities of
pretrained MIL models by assessing 11 models across 21 pretraining tasks for
morphological and molecular subtype prediction. Our results show that
pretrained MIL models, even when trained on different organs than the target
task, consistently outperform models trained from scratch. Moreover,
pretraining on pancancer datasets enables strong generalization across organs
and tasks, outperforming slide foundation models while using substantially less
pretraining data. These findings highlight the robust adaptability of MIL
models and demonstrate the benefits of leveraging transfer learning to boost
performance in CPath. Lastly, we provide a resource which standardizes the
implementation of MIL models and collection of pretrained model weights on
popular CPath tasks, available at https://github.com/mahmoodlab/MIL-Lab

</details>


### [172] [DIsoN: Decentralized Isolation Networks for Out-of-Distribution Detection in Medical Imaging](https://arxiv.org/abs/2506.09024)
*Felix Wagner,Pramit Saha,Harry Anthony,J. Alison Noble,Konstantinos Kamnitsas*

Main category: cs.CV

TL;DR: 论文提出了一种名为Decentralized Isolation Networks (DIsoN)的框架，用于在无法共享训练数据的情况下检测分布外（OOD）样本，适用于医疗影像等安全关键领域。


<details>
  <summary>Details</summary>
Motivation: 在医疗影像等安全关键领域部署机器学习模型时，需要检测训练中未见的输入（OOD样本），以防止不可靠的预测。现有方法通常无法在部署后访问训练数据或假设数据集中存储，这在现实中难以实现。

Method: 提出了Isolation Network框架，通过解决二分类任务量化测试样本与训练数据的分离难度。进一步提出DIsoN，在不共享数据的情况下通过交换模型参数实现训练与测试数据的比较，并扩展了类条件化的版本。

Result: 在四个医疗影像数据集（皮肤病学、胸部X光、乳腺超声、组织病理学）的12个OOD检测任务中，DIsoN表现优于现有方法，同时保护数据隐私。

Conclusion: DIsoN为机器学习开发者提供了一种新的服务模式，即在保护隐私的前提下，远程安全地利用训练数据进行OOD检测。

Abstract: Safe deployment of machine learning (ML) models in safety-critical domains
such as medical imaging requires detecting inputs with characteristics not seen
during training, known as out-of-distribution (OOD) detection, to prevent
unreliable predictions. Effective OOD detection after deployment could benefit
from access to the training data, enabling direct comparison between test
samples and the training data distribution to identify differences.
State-of-the-art OOD detection methods, however, either discard training data
after deployment or assume that test samples and training data are centrally
stored together, an assumption that rarely holds in real-world settings. This
is because shipping training data with the deployed model is usually impossible
due to the size of training databases, as well as proprietary or privacy
constraints. We introduce the Isolation Network, an OOD detection framework
that quantifies the difficulty of separating a target test sample from the
training data by solving a binary classification task. We then propose
Decentralized Isolation Networks (DIsoN), which enables the comparison of
training and test data when data-sharing is impossible, by exchanging only
model parameters between the remote computational nodes of training and
deployment. We further extend DIsoN with class-conditioning, comparing a target
sample solely with training data of its predicted class. We evaluate DIsoN on
four medical imaging datasets (dermatology, chest X-ray, breast ultrasound,
histopathology) across 12 OOD detection tasks. DIsoN performs favorably against
existing methods while respecting data-privacy. This decentralized OOD
detection framework opens the way for a new type of service that ML developers
could provide along with their models: providing remote, secure utilization of
their training data for OOD detection services. Code will be available upon
acceptance at: *****

</details>


### [173] [Diffuse and Disperse: Image Generation with Representation Regularization](https://arxiv.org/abs/2506.09027)
*Runqian Wang,Kaiming He*

Main category: cs.CV

TL;DR: 提出了一种名为Dispersive Loss的简单正则化方法，用于改进扩散生成模型，无需额外数据或预训练。


<details>
  <summary>Details</summary>
Motivation: 扩散生成模型通常缺乏显式正则化，且与表示学习进展独立发展，因此需要一种简单有效的方法来改进模型性能。

Method: 提出Dispersive Loss，通过鼓励隐藏空间中的表示分散来正则化模型，无需正样本对，不影响回归采样过程。

Result: 在ImageNet数据集上测试，Dispersive Loss在多种模型中均表现优于基线方法。

Conclusion: Dispersive Loss为生成模型与表示学习之间的桥梁提供了一种简单有效的解决方案。

Abstract: The development of diffusion-based generative models over the past decade has
largely proceeded independently of progress in representation learning. These
diffusion models typically rely on regression-based objectives and generally
lack explicit regularization. In this work, we propose \textit{Dispersive
Loss}, a simple plug-and-play regularizer that effectively improves
diffusion-based generative models. Our loss function encourages internal
representations to disperse in the hidden space, analogous to contrastive
self-supervised learning, with the key distinction that it requires no positive
sample pairs and therefore does not interfere with the sampling process used
for regression. Compared to the recent method of representation alignment
(REPA), our approach is self-contained and minimalist, requiring no
pre-training, no additional parameters, and no external data. We evaluate
Dispersive Loss on the ImageNet dataset across a range of models and report
consistent improvements over widely used and strong baselines. We hope our work
will help bridge the gap between generative modeling and representation
learning.

</details>


### [174] [Princeton365: A Diverse Dataset with Accurate Camera Pose](https://arxiv.org/abs/2506.09035)
*Karhan Kayan,Stamatis Alexandropoulos,Rishabh Jain,Yiming Zuo,Erich Liang,Jia Deng*

Main category: cs.CV

TL;DR: Princeton365是一个包含365个视频的大规模多样化数据集，提供精确的相机位姿，填补了当前SLAM基准测试中精度与数据多样性之间的差距。


<details>
  <summary>Details</summary>
Motivation: 解决当前SLAM基准测试中数据多样性不足和精度有限的问题，同时提供新的评估指标和挑战性任务。

Method: 通过校准板和360相机收集多样化的室内、室外及物体扫描视频，包含单目、立体RGB视频和IMU数据，并提出基于光流的新评估指标。

Result: 数据集和评估指标为SLAM研究提供了更全面的分析工具，支持跨场景性能比较和失败模式分析。

Conclusion: Princeton365为SLAM和NVS研究提供了新的基准和挑战，推动了相关领域的发展。

Abstract: We introduce Princeton365, a large-scale diverse dataset of 365 videos with
accurate camera pose. Our dataset bridges the gap between accuracy and data
diversity in current SLAM benchmarks by introducing a novel ground truth
collection framework that leverages calibration boards and a 360-camera. We
collect indoor, outdoor, and object scanning videos with synchronized monocular
and stereo RGB video outputs as well as IMU. We further propose a new scene
scale-aware evaluation metric for SLAM based on the the optical flow induced by
the camera pose estimation error. In contrast to the current metrics, our new
metric allows for comparison between the performance of SLAM methods across
scenes as opposed to existing metrics such as Average Trajectory Error (ATE),
allowing researchers to analyze the failure modes of their methods. We also
propose a challenging Novel View Synthesis benchmark that covers cases not
covered by current NVS benchmarks, such as fully non-Lambertian scenes with
360-degree camera trajectories. Please visit
https://princeton365.cs.princeton.edu for the dataset, code, videos, and
submission.

</details>


### [175] [Autoregressive Semantic Visual Reconstruction Helps VLMs Understand Better](https://arxiv.org/abs/2506.09040)
*Dianyi Wang,Wei Song,Yikun Wang,Siyuan Wang,Kaicheng Yu,Zhongyu Wei,Jiaqi Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为ASVR的方法，通过自回归框架联合学习视觉和文本模态，解决了当前大型视觉语言模型（LVLMs）仅依赖文本监督的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前LVLMs仅对文本序列进行自回归监督，未能充分利用视觉模态，导致无法处理无标注图像、遗漏视觉细节及难以表达视觉中心内容等问题。

Method: 引入ASVR，在统一的自回归框架中联合学习视觉和文本模态，通过自回归重建图像的语义表示而非原始外观。

Result: 实验表明，ASVR在多种多模态理解基准测试中表现稳定且显著提升，例如将LLaVA-1.5的平均分数提高了5%。

Conclusion: ASVR通过自回归语义视觉重建，有效提升了多模态理解能力，适用于不同数据规模和LLM骨干模型。

Abstract: Typical large vision-language models (LVLMs) apply autoregressive supervision
solely to textual sequences, without fully incorporating the visual modality
into the learning process. This results in three key limitations: (1) an
inability to utilize images without accompanying captions, (2) the risk that
captions omit critical visual details, and (3) the challenge that certain
vision-centric content cannot be adequately conveyed through text. As a result,
current LVLMs often prioritize vision-to-language alignment while potentially
overlooking fine-grained visual information. While some prior works have
explored autoregressive image generation, effectively leveraging autoregressive
visual supervision to enhance image understanding remains an open challenge. In
this paper, we introduce Autoregressive Semantic Visual Reconstruction (ASVR),
which enables joint learning of visual and textual modalities within a unified
autoregressive framework. We show that autoregressively reconstructing the raw
visual appearance of images does not enhance and may even impair multimodal
understanding. In contrast, autoregressively reconstructing the semantic
representation of images consistently improves comprehension. Notably, we find
that even when models are given continuous image features as input, they can
effectively reconstruct discrete semantic tokens, resulting in stable and
consistent improvements across a wide range of multimodal understanding
benchmarks. Our approach delivers significant performance gains across varying
data scales (556k-2M) and types of LLM bacbones. Specifically, ASVR improves
LLaVA-1.5 by 5% in average scores across 14 multimodal benchmarks. The code is
available at https://github.com/AlenjandroWang/ASVR.

</details>


### [176] [Cosmos-Drive-Dreams: Scalable Synthetic Driving Data Generation with World Foundation Models](https://arxiv.org/abs/2506.09042)
*Xuanchi Ren,Yifan Lu,Tianshi Cao,Ruiyuan Gao,Shengyu Huang,Amirmojtaba Sabour,Tianchang Shen,Tobias Pfaff,Jay Zhangjie Wu,Runjian Chen,Seung Wook Kim,Jun Gao,Laura Leal-Taixe,Mike Chen,Sanja Fidler,Huan Ling*

Main category: cs.CV

TL;DR: 论文提出了一种名为Cosmos-Drive-Dreams的合成数据生成（SDG）管道，用于生成具有挑战性的驾驶场景，以解决真实数据收集和标注的高成本问题。


<details>
  <summary>Details</summary>
Motivation: 为自动驾驶系统（AV）收集和标注真实数据耗时且昂贵，尤其是捕捉罕见的边缘案例。

Method: 利用NVIDIA Cosmos世界基础模型，开发了Cosmos-Drive模型套件，支持可控、高保真、多视角且时空一致的驾驶视频生成。

Result: 实验表明，生成的数据有助于缓解长尾分布问题，并提升3D车道检测、3D目标检测和驾驶策略学习等下游任务的泛化能力。

Conclusion: Cosmos-Drive-Dreams为自动驾驶领域提供了一种高效的数据生成工具，并开源了相关资源。

Abstract: Collecting and annotating real-world data for safety-critical physical AI
systems, such as Autonomous Vehicle (AV), is time-consuming and costly. It is
especially challenging to capture rare edge cases, which play a critical role
in training and testing of an AV system. To address this challenge, we
introduce the Cosmos-Drive-Dreams - a synthetic data generation (SDG) pipeline
that aims to generate challenging scenarios to facilitate downstream tasks such
as perception and driving policy training. Powering this pipeline is
Cosmos-Drive, a suite of models specialized from NVIDIA Cosmos world foundation
model for the driving domain and are capable of controllable, high-fidelity,
multi-view, and spatiotemporally consistent driving video generation. We
showcase the utility of these models by applying Cosmos-Drive-Dreams to scale
the quantity and diversity of driving datasets with high-fidelity and
challenging scenarios. Experimentally, we demonstrate that our generated data
helps in mitigating long-tail distribution problems and enhances generalization
in downstream tasks such as 3D lane detection, 3D object detection and driving
policy learning. We open source our pipeline toolkit, dataset and model weights
through the NVIDIA's Cosmos platform.
  Project page: https://research.nvidia.com/labs/toronto-ai/cosmos_drive_dreams

</details>


### [177] [MagCache: Fast Video Generation with Magnitude-Aware Cache](https://arxiv.org/abs/2506.09045)
*Zehong Ma,Longhui Wei,Feng Wang,Shiliang Zhang,Qi Tian*

Main category: cs.CV

TL;DR: 论文提出了一种基于统一幅度定律的Magnitude-aware Cache（MagCache）方法，用于自适应跳过不重要的时间步，显著提升视频扩散模型的加速效果。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型加速技术通常依赖均匀启发式或时间嵌入变体，需要大量校准且易因提示特定过拟合导致输出不一致。

Method: 发现统一幅度定律，提出MagCache方法，通过误差建模机制和自适应缓存策略跳过不重要时间步，仅需单个样本校准。

Result: MagCache在Open-Sora和Wan 2.1上分别实现2.1x和2.68x加速，视觉保真度优于现有方法，LPIPS、SSIM和PSNR表现更优。

Conclusion: MagCache是一种高效且鲁棒的加速方法，显著优于现有技术，适用于多种模型和提示。

Abstract: Existing acceleration techniques for video diffusion models often rely on
uniform heuristics or time-embedding variants to skip timesteps and reuse
cached features. These approaches typically require extensive calibration with
curated prompts and risk inconsistent outputs due to prompt-specific
overfitting. In this paper, we introduce a novel and robust discovery: a
unified magnitude law observed across different models and prompts.
Specifically, the magnitude ratio of successive residual outputs decreases
monotonically and steadily in most timesteps while rapidly in the last several
steps. Leveraging this insight, we introduce a Magnitude-aware Cache (MagCache)
that adaptively skips unimportant timesteps using an error modeling mechanism
and adaptive caching strategy. Unlike existing methods requiring dozens of
curated samples for calibration, MagCache only requires a single sample for
calibration. Experimental results show that MagCache achieves 2.1x and 2.68x
speedups on Open-Sora and Wan 2.1, respectively, while preserving superior
visual fidelity. It significantly outperforms existing methods in LPIPS, SSIM,
and PSNR, under comparable computational budgets.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [178] [PerfTracker: Online Performance Troubleshooting for Large-scale Model Training in Production](https://arxiv.org/abs/2506.08528)
*Yu Guan,Zhiyu Yin,Haoyu Chen,Sheng Cheng,Chaojie Yang,Tianyin Xu,Yang Zhang,Hanyu Zhao,Yong Li,Dennis Cai,Ennan Zhai*

Main category: cs.DC

TL;DR: PerfTracker是一个在线性能诊断系统，用于解决大规模模型训练中的性能问题，支持硬件和软件的故障排查，适用于现代GPU集群。


<details>
  <summary>Details</summary>
Motivation: 大规模模型训练（LMT）的性能问题排查极为复杂，现有方法难以应对现代GPU集群的规模和软硬件交互的复杂性。

Method: PerfTracker通过细粒度在线分析和差分可观测性，诊断硬件（如GPU及其互连）和软件（如Python函数和GPU操作）的性能问题。

Result: PerfTracker已在生产环境中部署，支持O(10,000)规模的GPU集群，并成功诊断多种复杂性能问题。

Conclusion: PerfTracker为大规模模型训练提供了高效的性能诊断工具，填补了现有方法的不足。

Abstract: Troubleshooting performance problems of large model training (LMT) is
immensely challenging, due to unprecedented scales of modern GPU clusters, the
complexity of software-hardware interactions, and the data intensity of the
training process. Existing troubleshooting approaches designed for traditional
distributed systems or datacenter networks fall short and can hardly apply to
real-world training systems. In this paper, we present PerfTracker, the first
online troubleshooting system utilizing fine-grained profiling, to diagnose
performance issues of large-scale model training in production. PerfTracker can
diagnose performance issues rooted in both hardware (e.g., GPUs and their
interconnects) and software (e.g., Python functions and GPU operations). It
scales to LMT on modern GPU clusters. PerfTracker effectively summarizes
runtime behavior patterns of fine-grained LMT functions via online profiling,
and leverages differential observability to localize the root cause with
minimal production impact. PerfTracker has been deployed as a production
service for large-scale GPU clusters of O(10, 000) GPUs (product homepage
https://help.aliyun.com/zh/pai/user-guide/perftracker-online-performance-analysis-diagnostic-tool).
It has been used to diagnose a variety of difficult performance issues.

</details>


### [179] [Towards Provenance-Aware Earth Observation Workflows: the openEO Case Study](https://arxiv.org/abs/2506.08597)
*H. Omidi,L. Sacco,V. Hutter,G. Irsiegler,M. Claus,M. Schobben,A. Jacob,M. Schramm,S. Fiore*

Main category: cs.DC

TL;DR: 本文提出了一种通过将数据溯源库yProv4WFs集成到openEO平台中，以改进地球观测（EO）工作流中操作和活动历史记录的方法。


<details>
  <summary>Details</summary>
Motivation: 地球观测工作流中记录操作和活动历史的重要性，以及数据溯源在收集数据产品元数据中的作用。

Method: 将数据溯源库yProv4WFs集成到openEO平台中，以统一和简化用户与地球观测云后端的连接。

Result: 展示了数据溯源概念在EO处理链中的集成如何帮助研究人员和利益相关者更好地理解分析工作流中的流程、依赖关系和转换。

Conclusion: 通过集成数据溯源库，openEO平台能够更有效地记录和追踪地球观测工作流中的操作历史，提升数据产品的透明度和可追溯性。

Abstract: Capturing the history of operations and activities during a computational
workflow is significantly important for Earth Observation (EO). The data
provenance helps to collect the metadata that records the lineage of data
products, providing information about how data are generated, transferred,
manipulated, by whom all these operations are performed and through which
processes, parameters, and datasets. This paper presents an approach to improve
those aspects, by integrating the data provenance library yProv4WFs within
openEO, a platform to let users connect to Earth Observation cloud back-ends in
a simple and unified way. In addition, it is demonstrated how the integration
of data provenance concepts across EO processing chains enables researchers and
stakeholders to better understand the flow, the dependencies, and the
transformations involved in analytical workflows.

</details>


### [180] [Blockchain and Edge Computing Nexus: A Large-scale Systematic Literature Review](https://arxiv.org/abs/2506.08636)
*Zeinab Nezami,Zhuolun Li,Chuhao Qin,Fatemeh Banaie,Rabiya Khalid,Evangelos Pournaras*

Main category: cs.DC

TL;DR: 本文通过系统文献综述，探讨区块链与边缘计算的结合如何推动创新，解决研究挑战，并提出了包含22个特征和287个属性的分类法。


<details>
  <summary>Details</summary>
Motivation: 区块链与边缘计算作为分散式计算的两大范式，虽在智能城市应用中具有重要影响，但技术和研究领域仍显碎片化。本文旨在揭示两者结合如何推动创新。

Method: 通过收集和分析近6000篇论文，筛选出近1000篇进行深入研究，构建了包含22个特征和287个属性的分类法，并采用定量和机器学习方法进行分析。

Result: 研究揭示了区块链与边缘计算之间的4种交互模式，并发现区块链辅助边缘计算在提升隐私和安全性（尤其是移动计算应用）方面占主导地位。

Conclusion: 区块链与边缘计算的结合为解决长期研究挑战提供了新思路，尤其在隐私和安全性方面具有显著潜力。

Abstract: Blockchain and edge computing are two instrumental paradigms of decentralized
computation, driving key advancements in Smart Cities applications such as
supply chain, energy and mobility. Despite their unprecedented impact on
society, they remain significantly fragmented as technologies and research
areas, while they share fundamental principles of distributed systems and
domains of applicability. This paper introduces a novel and large-scale
systematic literature review on the nexus of blockchain and edge computing with
the aim to unravel a new understanding of how the interfacing of the two
computing paradigms can boost innovation to provide solutions to timely but
also long-standing research challenges. By collecting almost 6000 papers from 3
databases and putting under scrutiny almost 1000 papers, we build a novel
taxonomy and classification consisting of 22 features with 287 attributes that
we study using quantitative and machine learning methods. They cover a broad
spectrum of technological, design, epistemological and sustainability aspects.
Results reveal 4 distinguishing patterns of interplay between blockchain and
edge computing with key determinants the public (permissionless) vs. private
(permissioned) design, technology and proof of concepts. They also demonstrate
the prevalence of blockchain-assisted edge computing for improving privacy and
security, in particular for mobile computing applications.

</details>


### [181] [Parallel FFTW on RISC-V: A Comparative Study including OpenMP, MPI, and HPX](https://arxiv.org/abs/2506.08653)
*Alexander Strack,Christopher Taylor,Dirk Pflüger*

Main category: cs.DC

TL;DR: 论文研究了RISC-V处理器上FFTW库的并行扩展性能，并与x86-64架构的AMD EPYC 7742进行了对比，发现RISC-V在双精度2D FFT上性能差距为8倍。


<details>
  <summary>Details</summary>
Motivation: 随着RISC-V硬件的发展，高效并行化变得至关重要，尤其是对于多核处理器如SOPHON SG2042。

Method: 评估了FFTW库在RISC-V上使用MPI和OpenMP的并行扩展性能，并与x86-64架构的AMD EPYC 7742进行了对比。同时研究了HPX-FFT库在RISC-V上的内存优化效果。

Result: RISC-V在双精度2D FFT上性能落后x86-64 8倍，HPX-FFT的内存优化在RISC-V上无效。FFTW的MPI版本在两种架构上均表现良好，而OpenMP版本需要优化规划。

Conclusion: 研究为RISC-V上大规模并行应用的开发提供了早期参考。

Abstract: Rapid advancements in RISC-V hardware development shift the focus from
low-level optimizations to higher-level parallelization. Recent RISC-V
processors, such as the SOPHON SG2042, have 64 cores. RISC-V processors with
core counts comparable to the SG2042, make efficient parallelization as crucial
for RISC-V as the more established processors such as x86-64. In this work, we
evaluate the parallel scaling of the widely used FFTW library on RISC-V for MPI
and OpenMP. We compare it to a 64-core AMD EPYC 7742 CPU side by side for
different types of FFTW planning. Additionally, we investigate the effect of
memory optimization on RISC-V in HPX-FFT, a parallel FFT library based on the
asynchronous many-task runtime HPX using an FFTW backend. We generally observe
a performance delta between the x86-64 and RISC-V chips of factor eight for
double-precision 2D FFT. Effective memory optimizations in HPX-FFT on x86-64 do
not translate to the RISC-V chip. FFTW with MPI shows good scaling up to 64
cores on x86-64 and RISC-V regardless of planning. In contrast, FFTW with
OpenMP requires measured planning on both architectures to achieve good scaling
up to 64 cores. The results of our study mark an early step on the journey to
large-scale parallel applications running on RISC-V.

</details>


### [182] [Synchronization in Anonymous Networks Under Continuous Dynamics](https://arxiv.org/abs/2506.08661)
*Rida Bazzi,Anya Chaturvedi,Andréa W. Richa,Peter Vargas*

Main category: cs.DC

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present the $\kappa$-Synchronizer that works in non-synchronous dynamic
networks under minimal assumptions. Our model allows continuous topological
changes without any guarantee of eventual global or partial stabilization and
assumes that nodes are anonymous. This deterministic synchronizer is the first
to enable nodes to simulate a dynamic network synchronous algorithm for
executions in a semi-synchronous dynamic environment under a weakly-fair node
activation scheduler, despite the absence of a global clock, node ids,
persistent connectivity or any assumptions about the edge dynamics (in both the
synchronous and semi-synchronous environments). In summary, we make the
following contributions: (1) we extend the definition of synchronizers to
networks with continuous arbitrary edge dynamics; (2) we present the first
synchronizer from the semi-synchronous to the synchronous model in a network
with continuous arbitrary edge dynamics; and (3) we present non-trivial
applications of the proposed synchronizer to existing algorithms. We assume an
extension of the Pull communication model by adding a single 1-bit multi-writer
atomic register at each edge-port of a node, since we show that the standard
Pull model is not sufficient to allow for non-trivial synchronization in our
scenario. The $\kappa$-Synchronizer operates with memory overhead at the nodes
that is linear on the maximum node degree and logarithmic on the runtime of the
underlying synchronous algorithm being simulated.

</details>


### [183] [Balancing Fixed Number of Nodes Among Multiple Fixed Clusters](https://arxiv.org/abs/2506.08715)
*Paritosh Ranjan,Surajit Majumder,Prodip Roy,Bhuban Padhan*

Main category: cs.DC

TL;DR: 提出了一种动态节点再平衡系统，通过实时资源利用率阈值优化多集群间的节点分配，减少资源浪费。


<details>
  <summary>Details</summary>
Motivation: 解决固定节点分配导致的资源利用率低下问题，提升云计算资源效率和成本效益。

Method: 引入节点平衡集群组（NBCG），通过节点平衡集群均衡器和调整规则引擎动态共享节点，基于阈值参数识别并重新分配节点。

Result: 优化资源利用率和运营成本，支持跨集群节点共享，同时确保集群稳定性。

Conclusion: 该系统显著减少资源浪费，提升IBM Cloud服务的效率和竞争力。

Abstract: Cloud infrastructure users often allocate a fixed number of nodes to
individual container clusters (e.g., Kubernetes, OpenShift), resulting in
underutilization of computing resources due to asynchronous and variable
workload peaks across clusters. This research proposes a novel system and
method for dynamic rebalancing of a fixed total number of nodes among multiple
fixed clusters based on real-time resource utilization thresholds. By
introducing a Node Balancing Cluster Group (NBCG), clusters are grouped and
allowed to dynamically share nodes through a controlled reallocation mechanism,
managed by a Node Balancing Cluster Balancer and a Resizing Rule Engine. The
system identifies overutilized and underutilized clusters using threshold
parameters, and reassigns nodes without incurring additional provisioning
costs. If reallocation causes a violation of utilization thresholds, the system
reverses the operation to maintain cluster stability. The proposed architecture
not only optimizes resource utilization and operational cost but also
introduces a strategic advantage for cloud service providers like IBM Cloud.
Unlike existing solutions, this approach enables intra-account node sharing
across clusters with strict adherence to user-defined constraints and ensures
consistent cluster state management. This invention has the potential to
significantly reduce computing resource waste and position IBM Cloud services
as more efficient and competitive.

</details>


### [184] [Mycelium: A Transformation-Embedded LSM-Tree](https://arxiv.org/abs/2506.08923)
*Holly Casaletto,Jeff Lefevre,Aldrin Montana,Peter Alvaro*

Main category: cs.DC

TL;DR: TE-LSM（Transformation-Embedded LSM-trees）是一种在LSM-tree的压缩过程中嵌入数据转换的新方法，通过Mycelium原型实现，显著降低了读写开销并提升了性能。


<details>
  <summary>Details</summary>
Motivation: LSM-tree的压缩过程成本高，但也是数据重组的必要步骤。TE-LSM利用这一过程嵌入数据转换，以分摊IO成本并提升效率。

Method: 提出TE-LSM方法，通过Mycelium原型在RocksDB上实现跨列族合并机制，支持数据分割、格式转换和索引构建等转换。

Result: Mycelium在写入吞吐量上仅增加20%开销（低于传统方法的35%-60%），同时读取延迟最高提升425%。

Conclusion: TE-LSM通过嵌入数据转换优化了LSM-tree的压缩过程，显著提升了性能，为未来数据访问模式提供了更好的支持。

Abstract: Compaction is a necessary, but often costly background process in
write-optimized data structures like LSM-trees that reorganizes incoming data
that is sequentially appended to logs. In this paper, we introduce
Transformation-Embedded LSM-trees (TE-LSM), a novel approach that transparently
embeds a variety of data transformations into the compaction process. While
many others have sought to reduce the high cost of compaction, TE-LSMs leverage
the opportunity to embed other useful work to amortize IO costs and
amplification. We illustrate the use of a TE-LSM in Mycelium, our prototype
built on top of RocksDB that extends the compaction process through a
cross-column-family merging mechanism. Mycelium enables seamless integration of
a transformer interface and aims to better prepare data for future accesses
based on access patterns. We use Mycelium to explore three types of
transformations: splitting column groups, converting data formats, and index
building. In addition to providing a cost model analysis, we evaluate
Mycelium's write and read performance using YCSB workloads. Our results show
that Mycelium incurs a 20% write throughput overhead - significantly lower than
the 35% to 60% overhead observed in naive approaches that perform data
transformations outside of compaction-while achieving up to 425% improvements
in read latency compared to RocksDB baseline.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [185] [ABC-FHE : A Resource-Efficient Accelerator Enabling Bootstrappable Parameters for Client-Side Fully Homomorphic Encryption](https://arxiv.org/abs/2506.08461)
*Sungwoong Yune,Hyojeong Lee,Adiwena Putra,Hyunjun Cho,Cuong Duong Manh,Jaeho Jeon,Joo-Young Kim*

Main category: cs.AR

TL;DR: ABC-FHE是一种高效的全同态加密加速器，针对客户端计算瓶颈提出优化方案，显著提升性能并降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 全同态加密（FHE）在隐私保护计算中至关重要，但其计算开销大，客户端计算成为瓶颈，尤其是在可自举参数配置下。

Method: ABC-FHE采用流式架构，支持可自举参数，包括可重构傅里叶引擎、片上伪随机数生成器和统一即时旋转因子生成器，优化任务调度。

Result: ABC-FHE在28纳米工艺下占用28.638 mm²面积，功耗5.654 W，编码和加密速度提升1112倍（相比CPU）和214倍（相比现有加速器），解码和解密速度提升963倍和82倍。

Conclusion: ABC-FHE显著提升了客户端FHE计算的效率和性能，为隐私保护计算提供了可行的解决方案。

Abstract: As the demand for privacy-preserving computation continues to grow, fully
homomorphic encryption (FHE)-which enables continuous computation on encrypted
data-has become a critical solution. However, its adoption is hindered by
significant computational overhead, requiring 10000-fold more computation
compared to plaintext processing. Recent advancements in FHE accelerators have
successfully improved server-side performance, but client-side computations
remain a bottleneck, particularly under bootstrappable parameter
configurations, which involve combinations of encoding, encrypt, decoding, and
decrypt for large-sized parameters. To address this challenge, we propose
ABC-FHE, an area- and power-efficient FHE accelerator that supports
bootstrappable parameters on the client side. ABC-FHE employs a streaming
architecture to maximize performance density, minimize area usage, and reduce
off-chip memory access. Key innovations include a reconfigurable Fourier engine
capable of switching between NTT and FFT modes. Additionally, an on-chip
pseudo-random number generator and a unified on-the-fly twiddle factor
generator significantly reduce memory demands, while optimized task scheduling
enhances the CKKS client-side processing, achieving reduced latency. Overall,
ABC-FHE occupies a die area of 28.638 mm2 and consumes 5.654 W of power in 28
nm technology. It delivers significant performance improvements, achieving a
1112x speed-up in encoding and encryption execution time compared to a CPU, and
214x over the state-of-the-art client-side accelerator. For decoding and
decryption, it achieves a 963x speed-up over the CPU and 82x over the
state-of-the-art accelerator.

</details>


### [186] [CoQMoE: Co-Designed Quantization and Computation Orchestration for Mixture-of-Experts Vision Transformer on FPGA](https://arxiv.org/abs/2506.08496)
*Jiale Dong,Hao Wu,Zihao Wang,Wenqi Lou,Zhendong Zheng,Lei Gong,Chao Wang,Xuehai Zhou*

Main category: cs.AR

TL;DR: 本文提出了一种新颖的FPGA加速器，用于高效实现量化MoE-ViT模型，通过双阶段量化方案和资源感知架构，显著提升了性能并降低了能耗。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers（ViTs）在计算机视觉任务中表现优异，但在资源受限设备上部署时面临高计算/内存需求的问题。MoE-ViTs虽能缓解这一问题，但其在FPGA上的硬件实现仍受资源限制。

Method: 提出双阶段量化方案（结合精度保持的复杂量化器和硬件友好的简化量化器）和资源感知加速器架构（包括延迟优化的流式注意力内核和可重用的线性算子）。

Result: 实验结果显示，加速器在保持准确率损失小于1%的同时，实现了155帧/秒的吞吐量，比现有FPGA MoE加速器提升了5.35倍，能耗降低80%以上。

Conclusion: 该加速器为资源受限设备上的高效MoE-ViT部署提供了可行方案，显著提升了性能和能效。

Abstract: Vision Transformers (ViTs) exhibit superior performance in computer vision
tasks but face deployment challenges on resource-constrained devices due to
high computational/memory demands. While Mixture-of-Experts Vision Transformers
(MoE-ViTs) mitigate this through a scalable architecture with sub-linear
computational growth, their hardware implementation on FPGAs remains
constrained by resource limitations. This paper proposes a novel accelerator
for efficiently implementing quantized MoE models on FPGAs through two key
innovations: (1) A dual-stage quantization scheme combining
precision-preserving complex quantizers with hardware-friendly simplified
quantizers via scale reparameterization, with only 0.28 $\%$ accuracy loss
compared to full precision; (2) A resource-aware accelerator architecture
featuring latency-optimized streaming attention kernels and reusable linear
operators, effectively balancing performance and resource consumption.
Experimental results demonstrate that our accelerator achieves nearly 155
frames per second, a 5.35$\times$ improvement in throughput, and over $80\%$
energy reduction compared to state-of-the-art (SOTA) FPGA MoE accelerators,
while maintaining $<1\%$ accuracy loss across vision benchmarks. Our
implementation is available at https://github.com/DJ000011/CoQMoE.

</details>


### [187] [POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration](https://arxiv.org/abs/2506.08785)
*Mukul Lokhande,Santosh Kumar Vishvakarma*

Main category: cs.AR

TL;DR: PARV-CE是一种支持多精度格式的SIMD MAC引擎，通过硬件-软件协同设计优化性能和能耗，适用于边缘AI加速。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型复杂度的增加，边缘平台需要灵活的硬件支持多样化的精度格式，以满足能耗限制和计算需求。

Method: PARV-CE采用统一数据路径支持4/8/16位定点、浮点和posit格式，结合层自适应精度策略和可重构SIMD流水线。

Result: 相比现有技术，PARV-CE在PDP上提升2倍，资源使用减少3倍，精度损失控制在1.8%以内。

Conclusion: PARV-CE是一种可扩展且高能效的边缘AI加速解决方案，适用于多种模型训练和推理。

Abstract: The increasing complexity of AI models requires flexible hardware capable of
supporting diverse precision formats, particularly for energy-constrained edge
platforms. This work presents PARV-CE, a SIMD-enabled, multi-precision MAC
engine that performs efficient multiply-accumulate operations using a unified
data-path for 4/8/16-bit fixed-point, floating point, and posit formats. The
architecture incorporates a layer adaptive precision strategy to align
computational accuracy with workload sensitivity, optimizing both performance
and energy usage. PARV-CE integrates quantization-aware execution with a
reconfigurable SIMD pipeline, enabling high-throughput processing with minimal
overhead through hardware-software co-design. The results demonstrate up to 2x
improvement in PDP and 3x reduction in resource usage compared to SoTA designs,
while retaining accuracy within 1.8% FP32 baseline. The architecture supports
both on-device training and inference across a range of workloads, including
DNNs, RNNs, RL, and Transformer models. The empirical analysis establish PARVCE
incorporated POLARON as a scalable and energy-efficient solution for
precision-adaptive AI acceleration at edge.

</details>


### [188] [STI-SNN: A 0.14 GOPS/W/PE Single-Timestep Inference FPGA-based SNN Accelerator with Algorithm and Hardware Co-Design](https://arxiv.org/abs/2506.08842)
*Kainan Wang,Chengyi Yang,Chengting Yu,Yee Sin Ang,Bo Wang,Aili Wang*

Main category: cs.AR

TL;DR: STI-SNN是一种高效、灵活且低延迟的SNN加速器，通过算法与硬件协同设计解决SNN的时序依赖性和不规则性问题。


<details>
  <summary>Details</summary>
Motivation: 解决SNN因时序依赖性和不规则性导致的硬件并行处理和数据复用问题，提升能效和处理延迟。

Method: 采用算法与硬件协同设计，包括单时间步推理、基于TET损失函数的时序剪枝、OS数据流、压缩排序的脉冲表示，以及支持多种卷积方法和并行处理。

Result: STI-SNN显著提升了能效和灵活性，同时降低了处理延迟。

Conclusion: STI-SNN为资源受限应用提供了一种高效、灵活的SNN加速解决方案。

Abstract: Brain-inspired Spiking Neural Networks (SNNs) have attracted attention for
their event-driven characteristics and high energy efficiency. However, the
temporal dependency and irregularity of spikes present significant challenges
for hardware parallel processing and data reuse, leading to some existing
accelerators falling short in processing latency and energy efficiency. To
overcome these challenges, we introduce the STI-SNN accelerator, designed for
resource-constrained applications with high energy efficiency, flexibility, and
low latency. The accelerator is designed through algorithm and hardware
co-design. Firstly, STI-SNN can perform inference in a single timestep. At the
algorithm level, we introduce a temporal pruning approach based on the temporal
efficient training (TET) loss function. This approach alleviates spike
disappearance during timestep reduction, maintains inference accuracy, and
expands TET's application. In hardware design, we analyze data access patterns
and adopt the output stationary (OS) dataflow, eliminating the need to store
membrane potentials and access memory operations. Furthermore, based on the OS
dataflow, we propose a compressed and sorted representation of spikes, then
cached in the line buffer to reduce the memory access cost and improve reuse
efficiency. Secondly, STI-SNN supports different convolution methods. By
adjusting the computation mode of processing elements (PEs) and parameterizing
the computation array, STI-SNN can accommodate lightweight models based on
depthwise separable convolutions (DSCs), further enhancing hardware
flexibility. Lastly, STI-SNN also supports both inter-layer and intra-layer
parallel processing. For inter-layer parallelism, we ...

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [189] [Approaching Dialogue State Tracking via Aligning Speech Encoders and LLMs](https://arxiv.org/abs/2506.08633)
*Šimon Sedláček,Bolaji Yusuf,Ján Švec,Pradyoth Hegde,Santosh Kesiraju,Oldřich Plchot,Jan Černocký*

Main category: eess.AS

TL;DR: 该论文通过连接语音编码器和LLM的表示空间，提出了一种用于口语对话状态跟踪（DST）的方法，并在开源数据和组件上进行了实验，取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 研究口语对话状态跟踪（DST）的挑战，通过结合语音编码器和大型语言模型（LLM）的表示空间，探索完全开源的数据和组件的可行性。

Method: 使用WavLM-large和OLMo等开源组件，通过小型连接模块桥接语音编码器和LLM的表示空间，研究了全微调/LoRA适配器微调、对话历史中代理轮次的影响以及基于模糊匹配的输出后处理。

Result: 在SpokenWOZ数据集上，WavLM + connector + OLMo-1B模型达到了34.66%的JGA（联合目标准确率），而Gemma-2-9B-instruct系统进一步提升了性能，达到42.17%的JGA。

Conclusion: 通过结合语音编码器和LLM的表示空间，并利用开源组件，该方法在口语对话状态跟踪任务中取得了最佳性能，展示了开源解决方案的潜力。

Abstract: In this work, we approach spoken Dialogue State Tracking (DST) by bridging
the representation spaces of speech encoders and LLMs via a small connector
module, with a focus on fully open-sourced and open-data components
(WavLM-large, OLMo). We focus on ablating different aspects of such systems
including full/LoRA adapter fine-tuning, the effect of agent turns in the
dialogue history, as well as fuzzy matching-based output post-processing, which
greatly improves performance of our systems on named entities in the dialogue
slot values. We conduct our experiments on the SpokenWOZ dataset, and
additionally utilize the Speech-Aware MultiWOZ dataset to augment our training
data. Ultimately, our best-performing WavLM + connector + OLMo-1B aligned
models achieve state of the art on the SpokenWOZ test set (34.66% JGA), and our
system with Gemma-2-9B-instruct further surpasses this result, reaching 42.17%
JGA on SpokenWOZ test.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [190] [GradSkip: Communication-Accelerated Local Gradient Methods with Better Computational Complexity](https://arxiv.org/abs/2210.16402)
*Artavazd Maranjyan,Mher Safaryan,Peter Richtárik*

Main category: cs.LG

TL;DR: 论文提出了一种改进的分布式优化算法GradSkip，允许数据重要性较低的客户端减少本地训练步数，同时保持通信复杂度和收敛性。


<details>
  <summary>Details</summary>
Motivation: 解决现有ProxSkip方法中所有客户端需执行相同本地训练步数的限制，提升灵活性。

Method: 重新设计ProxSkip方法，引入GradSkip和GradSkip+，支持动态调整本地训练步数，并扩展了随机性和正则化。

Result: GradSkip在相同假设下线性收敛，通信复杂度不变，且本地梯度步数可减少。

Conclusion: 改进方法在理论和实验中均表现良好，为分布式优化提供了更灵活高效的解决方案。

Abstract: We study a class of distributed optimization algorithms that aim to alleviate
high communication costs by allowing clients to perform multiple local
gradient-type training steps before communication. In a recent breakthrough,
Mishchenko et al. (2022) proved that local training, when properly executed,
leads to provable communication acceleration, and this holds in the strongly
convex regime without relying on any data similarity assumptions. However,
their ProxSkip method requires all clients to take the same number of local
training steps in each communication round. We propose a redesign of the
ProxSkip method, allowing clients with ``less important'' data to get away with
fewer local training steps without impacting the overall communication
complexity of the method. In particular, we prove that our modified method,
GradSkip, converges linearly under the same assumptions and has the same
accelerated communication complexity, while the number of local gradient steps
can be reduced relative to a local condition number. We further generalize our
method by extending the randomness of probabilistic alternations to arbitrary
unbiased compression operators and by considering a generic proximable
regularizer. This generalization, which we call GradSkip+, recovers several
related methods in the literature as special cases. Finally, we present an
empirical study on carefully designed toy problems that confirm our theoretical
claims.

</details>


### [191] [Recipes for Pre-training LLMs with MXFP8](https://arxiv.org/abs/2506.08027)
*Asit Mishra,Dusan Stosic,Simon Layton*

Main category: cs.LG

TL;DR: 论文探讨了在预训练中使用MXFP8格式的精度缩放技术，提出了一种改进的舍入模式以避免模型发散。


<details>
  <summary>Details</summary>
Motivation: 研究MX格式在预训练中的数值稳定性问题，解决传统舍入模式导致的模型发散问题。

Method: 提出了一种改进的舍入模式，使用round-to-infinity计算缩放因子。

Result: 成功在MXFP8格式下预训练了一个8B参数的模型，使用了15T tokens的数据集。

Conclusion: 改进的舍入模式能够有效提升MX格式在预训练中的稳定性。

Abstract: Precision scaling - using fewer bits to represent model parameters and
related tensors during pre-training - has emerged as a compelling technique for
improving GPU efficiency without sacrificing accuracy. Microscaling (MX)
formats in NVIDIA's latest Blackwell GPUs represent a major leap in enabling
this precision scaling aspect. These formats combine narrow floating-point data
types with per-block scaling factors, offering a fine-grained approach to
quantizing tensors.
  Although MX-formats offer the promise of improved numeric stability compared
to other reduced-precision representations, in practice they must be used
carefully in order to successfully converge an LLM on a multi-trillion token
dataset. In this paper, we show that the rounding mode suggested in OCP
specification can lead to divergence when pre-training an LLM. We show an
improved rounding mode, which uses round-to-infinity to compute scaling
factors, enables successful pre-training in MXFP8 for an 8B model on 15T
tokens.

</details>


### [192] [UniVarFL: Uniformity and Variance Regularized Federated Learning for Heterogeneous Data](https://arxiv.org/abs/2506.08167)
*Sunny Gupta,Nikita Jangid,Amit Sethi*

Main category: cs.LG

TL;DR: UniVarFL是一种新的联邦学习框架，通过客户端级别的IID模拟训练动态，解决了非IID数据导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 非IID数据导致联邦学习性能下降，传统方法计算成本高或适应性差。

Method: UniVarFL采用两种正则化策略：分类器方差正则化和超球面均匀性正则化。

Result: 在多个基准数据集上，UniVarFL在准确性上优于现有方法。

Conclusion: UniVarFL是一种高效、可扩展的解决方案，适用于资源受限的实际部署。

Abstract: Federated Learning (FL) often suffers from severe performance degradation
when faced with non-IID data, largely due to local classifier bias. Traditional
remedies such as global model regularization or layer freezing either incur
high computational costs or struggle to adapt to feature shifts. In this work,
we propose UniVarFL, a novel FL framework that emulates IID-like training
dynamics directly at the client level, eliminating the need for global model
dependency. UniVarFL leverages two complementary regularization strategies
during local training: Classifier Variance Regularization, which aligns
class-wise probability distributions with those expected under IID conditions,
effectively mitigating local classifier bias; and Hyperspherical Uniformity
Regularization, which encourages a uniform distribution of feature
representations across the hypersphere, thereby enhancing the model's ability
to generalize under diverse data distributions. Extensive experiments on
multiple benchmark datasets demonstrate that UniVarFL outperforms existing
methods in accuracy, highlighting its potential as a highly scalable and
efficient solution for real-world FL deployments, especially in
resource-constrained settings. Code: https://github.com/sunnyinAI/UniVarFL

</details>


### [193] [Federated Learning on Stochastic Neural Networks](https://arxiv.org/abs/2506.08169)
*Jingqiao Tang,Ryan Bausback,Feng Bao,Richard Archibald*

Main category: cs.LG

TL;DR: 联邦学习中引入随机神经网络作为本地模型，以处理潜在噪声并量化其影响。


<details>
  <summary>Details</summary>
Motivation: 联邦学习依赖客户端数据，但数据可能存在潜在噪声（如测量误差或人为错误），影响模型性能。

Method: 提出在联邦学习框架中使用随机神经网络作为本地模型，估计数据真实状态并量化噪声。

Result: 数值实验表明，该方法在处理非独立同分布数据时表现优异。

Conclusion: 联邦随机神经网络能有效应对数据噪声，提升联邦学习性能。

Abstract: Federated learning is a machine learning paradigm that leverages edge
computing on client devices to optimize models while maintaining user privacy
by ensuring that local data remains on the device. However, since all data is
collected by clients, federated learning is susceptible to latent noise in
local datasets. Factors such as limited measurement capabilities or human
errors may introduce inaccuracies in client data. To address this challenge, we
propose the use of a stochastic neural network as the local model within the
federated learning framework. Stochastic neural networks not only facilitate
the estimation of the true underlying states of the data but also enable the
quantification of latent noise. We refer to our federated learning approach,
which incorporates stochastic neural networks as local models, as Federated
stochastic neural networks. We will present numerical experiments demonstrating
the performance and effectiveness of our method, particularly in handling
non-independent and identically distributed data.

</details>


### [194] [HASFL: Heterogeneity-aware Split Federated Learning over Edge Computing Systems](https://arxiv.org/abs/2506.08426)
*Zheng Lin,Zhe Chen,Xianhao Chen,Wei Ni,Yue Gao*

Main category: cs.LG

TL;DR: HASFL框架通过自适应控制批次大小和模型分割，解决了边缘设备异构性导致的性能问题，显著提升了学习效率。


<details>
  <summary>Details</summary>
Motivation: 现有分割联邦学习（SFL）方法因边缘设备异构性导致性能下降，亟需一种能适应资源差异的解决方案。

Method: 提出HASFL框架，基于收敛边界理论，自适应调整批次大小和模型分割，平衡通信计算延迟与训练收敛。

Result: 实验验证HASFL在多种数据集上优于现有方法，显著提升了学习性能。

Conclusion: HASFL有效解决了边缘设备异构性问题，为分割联邦学习提供了高效解决方案。

Abstract: Split federated learning (SFL) has emerged as a promising paradigm to
democratize machine learning (ML) on edge devices by enabling layer-wise model
partitioning. However, existing SFL approaches suffer significantly from the
straggler effect due to the heterogeneous capabilities of edge devices. To
address the fundamental challenge, we propose adaptively controlling batch
sizes (BSs) and model splitting (MS) for edge devices to overcome resource
heterogeneity. We first derive a tight convergence bound of SFL that quantifies
the impact of varied BSs and MS on learning performance. Based on the
convergence bound, we propose HASFL, a heterogeneity-aware SFL framework
capable of adaptively controlling BS and MS to balance communication-computing
latency and training convergence in heterogeneous edge networks. Extensive
experiments with various datasets validate the effectiveness of HASFL and
demonstrate its superiority over state-of-the-art benchmarks.

</details>


### [195] [Modality-Balancing Preference Optimization of Large Multimodal Models by Adversarial Negative Mining](https://arxiv.org/abs/2506.08022)
*Chenxi Liu,Tianyi Xiong,Ruibo Chen,Yihan Wu,Junfeng Guo,Tianyi Zhou,Heng Huang*

Main category: cs.LG

TL;DR: MBPO提出了一种新的偏好学习框架，通过生成硬负样本和在线验证奖励，解决LMM中的模态不平衡问题，提升性能并减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有LMM在推理中存在模态不平衡问题，语言先验偏置过强，导致泛化能力受限和幻觉现象。现有偏好优化方法未有效抑制LLM内部偏置，且依赖离线数据。

Method: MBPO通过对抗性扰动生成硬负样本构建离线偏好数据集，并利用闭端任务生成在线验证奖励数据，结合GRPO进行训练。

Result: 实验表明MBPO能显著提升LMM在视觉语言任务中的性能，并有效减少幻觉。

Conclusion: MBPO通过平衡模态偏好和混合数据训练，为LMM的优化提供了新思路。

Abstract: The task adaptation and alignment of Large Multimodal Models (LMMs) have been
significantly advanced by instruction tuning and further strengthened by recent
preference optimization. Yet, most LMMs still suffer from severe modality
imbalance during reasoning, i.e., outweighing language prior biases over visual
inputs, which bottlenecks their generalization to downstream tasks and causes
hallucinations. However, existing preference optimization approaches for LMMs
do not focus on restraining the internal biases of their Large Language Model
(LLM) backbones when curating the training data. Moreover, they heavily rely on
offline data and lack the capacity to explore diverse responses adaptive to
dynamic distributional shifts during training. Meanwhile, Group Relative Policy
Optimization (GRPO), a recent method using online-generated data and verified
rewards to improve reasoning capabilities, remains largely underexplored in LMM
alignment. In this paper, we propose a novel preference learning framework,
Modality-Balancing Preference Optimization (MBPO), to address the modality
imbalance in LMMs. MBPO constructs a more effective offline preference dataset
by generating hard negatives, i.e., rejected responses misled by LLM biases due
to limited usage of visual information, through adversarial perturbation of
input images. Moreover, MBPO leverages the easy-to-verify nature of close-ended
tasks to generate online responses with verified rewards. GRPO is then employed
to train the model with offline-online hybrid data. Extensive experiments
demonstrate that MBPO can enhance LMM performance on challenging
vision-language tasks and effectively reduce hallucinations.

</details>


### [196] [Bingo: Boosting Efficient Reasoning of LLMs via Dynamic and Significance-based Reinforcement Learning](https://arxiv.org/abs/2506.08125)
*Hanbing Liu,Lang Cao,Yuanyi Ren,Mengyu Zhou,Haoyu Dong,Xiaojun Ma,Shi Han,Dongmei Zhang*

Main category: cs.LG

TL;DR: Bingo是一种强化学习框架，通过改进基于长度的奖励设计，提升语言模型的高效推理能力，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理能力上表现优异，但常因冗长或冗余输出导致效率低下。现有方法多关注准确性，对推理效率关注不足。

Method: Bingo引入两种机制：显著性感知长度奖励（逐步减少无关标记）和动态长度奖励（初期鼓励详细推理，后期提高效率）。

Result: 实验表明，Bingo在多个推理基准上优于其他基于长度的奖励方法，实现了准确性与效率的良好平衡。

Conclusion: Bingo展示了通过显式训练提升语言模型高效推理的潜力。

Abstract: Large language models have demonstrated impressive reasoning capabilities,
yet they often suffer from inefficiencies due to unnecessarily verbose or
redundant outputs. While many works have explored reinforcement learning (RL)
to enhance reasoning abilities, most primarily focus on improving accuracy,
with limited attention to reasoning efficiency. Some existing approaches
introduce direct length-based rewards to encourage brevity, but this often
leads to noticeable drops in accuracy. In this paper, we propose Bingo, an RL
framework that advances length-based reward design to boost efficient
reasoning. Bingo incorporates two key mechanisms: a significance-aware length
reward, which gradually guides the model to reduce only insignificant tokens,
and a dynamic length reward, which initially encourages elaborate reasoning for
hard questions but decays over time to improve overall efficiency. Experiments
across multiple reasoning benchmarks show that Bingo improves both accuracy and
efficiency. It outperforms the vanilla reward and several other length-based
reward baselines in RL, achieving a favorable trade-off between accuracy and
efficiency. These results underscore the potential of training LLMs explicitly
for efficient reasoning.

</details>


### [197] [AutoSDT: Scaling Data-Driven Discovery Tasks Toward Open Co-Scientists](https://arxiv.org/abs/2506.08140)
*Yifei Li,Hanane Nour Moussa,Ziru Chen,Shijie Chen,Botao Yu,Mingyi Xue,Benjamin Burns,Tzu-Yao Chiu,Vishal Dey,Zitong Lu,Chen Wei,Qianheng Zhang,Tianyu Zhang,Song Gao,Xuhui Huang,Xia Ning,Nesreen K. Ahmed,Ali Payani,Huan Sun*

Main category: cs.LG

TL;DR: AutoSDT是一个自动收集高质量编码任务的管道，用于解决数据稀缺问题，并构建了AutoSDT-5K数据集。基于该数据集训练的AutoSDT-Coder模型在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 加速科学发现需要AI辅助，但高质量数据稀缺限制了AI的发展。

Method: 利用LLM的编码能力和参数化知识，自动搜索、筛选和合成任务及代码解决方案。

Result: 构建了AutoSDT-5K数据集，包含5,404个任务，专家验证显示93%的任务有效，92.2%的代码正确。AutoSDT-Coder模型在基准测试中表现显著提升。

Conclusion: AutoSDT解决了数据稀缺问题，并显著提升了AI在科学发现中的表现。

Abstract: Despite long-standing efforts in accelerating scientific discovery with AI,
building AI co-scientists remains challenging due to limited high-quality data
for training and evaluation. To tackle this data scarcity issue, we present
AutoSDT, an automatic pipeline that collects high-quality coding tasks in
real-world data-driven discovery workflows. AutoSDT leverages the coding
capabilities and parametric knowledge of LLMs to search for diverse sources,
select ecologically valid tasks, and synthesize accurate task instructions and
code solutions. Using our pipeline, we construct AutoSDT-5K, a dataset of 5,404
coding tasks for data-driven discovery that covers four scientific disciplines
and 756 unique Python packages. To the best of our knowledge, AutoSDT-5K is the
only automatically collected and the largest open dataset for data-driven
scientific discovery. Expert feedback on a subset of 256 tasks shows the
effectiveness of AutoSDT: 93% of the collected tasks are ecologically valid,
and 92.2% of the synthesized programs are functionally correct. Trained on
AutoSDT-5K, the Qwen2.5-Coder-Instruct LLM series, dubbed AutoSDT-Coder, show
substantial improvement on two challenging data-driven discovery benchmarks,
ScienceAgentBench and DiscoveryBench. Most notably, AutoSDT-Coder-32B reaches
the same level of performance as GPT-4o on ScienceAgentBench with a success
rate of 7.8%, doubling the performance of its base model. On DiscoveryBench, it
lifts the hypothesis matching score to 8.1, bringing a 17.4% relative
improvement and closing the gap between open-weight models and GPT-4o.

</details>


### [198] [Reinforcement Learning from Human Feedback with High-Confidence Safety Constraints](https://arxiv.org/abs/2506.08266)
*Yaswanth Chittepu,Blossom Metevier,Will Schwarzer,Austin Hoag,Scott Niekum,Philip S. Thomas*

Main category: cs.LG

TL;DR: HC-RLHF是一种新方法，通过高置信度安全强化学习从人类反馈中确保语言模型的安全性和有用性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在安全性和有用性之间存在权衡，可能导致敏感领域的不当响应，因此需要一种更可靠的方法。

Method: HC-RLHF将人类偏好分解为有用性和安全性，分别训练奖励模型和成本模型，并通过悲观约束优化和安全测试两步确保安全。

Result: 实验表明，HC-RLHF能以高概率生成安全模型，并在无害性和有用性上优于现有方法。

Conclusion: HC-RLHF提供了一种可靠的方法，确保语言模型在敏感领域的安全性和有用性。

Abstract: Existing approaches to language model alignment often treat safety as a
tradeoff against helpfulness, which can lead to unacceptable responses in
sensitive domains. To ensure reliable performance in such settings, we propose
High-Confidence Safe Reinforcement Learning from Human Feedback (HC-RLHF), a
method that provides high-confidence safety guarantees while maximizing
helpfulness. Similar to previous methods, HC-RLHF explicitly decouples human
preferences into helpfulness and harmlessness (safety), which are learned by
training a reward model and a cost model, respectively. It then employs a
two-step process to find safe solutions. In the first step, it optimizes the
reward function under an intentionally pessimistic version of the cost
constraint. In the second step, the trained model undergoes a safety test to
verify whether its performance stays within an upper-confidence bound of the
actual cost constraint. We provide a theoretical analysis of HC-RLHF, including
proof that it will not return an unsafe solution with a probability greater
than a user-specified threshold. For our empirical analysis, we apply HC-RLHF
to align three different language models (Qwen2-1.5B, Qwen2.5-3B, and
LLaMa3.2-3B) with human preferences. Our results demonstrate that HC-RLHF
produces safe models with high probability and can improve harmlessness and
helpfulness compared to previous methods.

</details>


### [199] [From Debate to Equilibrium: Belief-Driven Multi-Agent LLM Reasoning via Bayesian Nash Equilibrium](https://arxiv.org/abs/2506.08292)
*Xie Yi,Zhanke Zhou,Chentao Cao,Qiyu Niu,Tongliang Liu,Bo Han*

Main category: cs.LG

TL;DR: ECON提出了一种基于贝叶斯纳什均衡的多LLM协调框架，通过分层强化学习实现高效协作，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多智能体框架能增强LLM的推理能力，但存在计算成本高和缺乏收敛保证的问题。

Method: 将多LLM协调建模为不完全信息博弈，通过贝叶斯纳什均衡和分层强化学习实现分布式推理与集中输出。

Result: ECON在六个基准测试中平均表现优于现有方法11.2%，并证明了其可扩展性。

Conclusion: ECON为更强大、可扩展的多LLM协作提供了有效解决方案。

Abstract: Multi-agent frameworks can substantially boost the reasoning power of large
language models (LLMs), but they typically incur heavy computational costs and
lack convergence guarantees. To overcome these challenges, we recast multi-LLM
coordination as an incomplete-information game and seek a Bayesian Nash
equilibrium (BNE), in which each agent optimally responds to its probabilistic
beliefs about the strategies of others. We introduce Efficient Coordination via
Nash Equilibrium (ECON), a hierarchical reinforcement-learning paradigm that
marries distributed reasoning with centralized final output. Under ECON, each
LLM independently selects responses that maximize its expected reward,
conditioned on its beliefs about co-agents, without requiring costly
inter-agent exchanges. We mathematically prove that ECON attains a markedly
tighter regret bound than non-equilibrium multi-agent schemes. Empirically,
ECON outperforms existing multi-LLM approaches by 11.2% on average across six
benchmarks spanning complex reasoning and planning tasks. Further experiments
demonstrate ECON's ability to flexibly incorporate additional models,
confirming its scalability and paving the way toward larger, more powerful
multi-LLM ensembles. The code is publicly available at:
https://github.com/tmlr-group/ECON.

</details>


### [200] [From Passive to Active Reasoning: Can Large Language Models Ask the Right Questions under Incomplete Information?](https://arxiv.org/abs/2506.08295)
*Zhanke Zhou,Xiao Feng,Zhaocheng Zhu,Jiangchao Yao,Sanmi Koyejo,Bo Han*

Main category: cs.LG

TL;DR: AR-Bench是一个新的基准测试，专门评估大型语言模型（LLM）的主动推理能力，发现当前模型在主动推理方面表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要测试被动推理，而主动推理（需要与外部系统交互获取信息）缺乏系统性研究。

Method: AR-Bench包含三类任务（侦探案件、情境谜题和猜数字），模拟真实场景并测试常识、逻辑和符号推理能力。

Result: 实验表明，当前LLM在主动推理中表现较差，即使采用高级策略（如树搜索或后训练方法）改进有限。

Conclusion: 研究强调需改进主动推理方法，如引入交互学习、实时反馈和环境感知目标。

Abstract: While existing benchmarks probe the reasoning abilities of large language
models (LLMs) across diverse domains, they predominantly assess passive
reasoning, providing models with all the information needed to reach a
solution. By contrast, active reasoning-where an LLM must interact with
external systems to acquire missing evidence or data-has received little
systematic attention. To address this shortfall, we present AR-Bench, a novel
benchmark designed explicitly to evaluate an LLM's active reasoning skills.
AR-Bench comprises three task families-detective cases, situation puzzles, and
guessing numbers-that together simulate real-world, agentic scenarios and
measure performance across commonsense, logical, and symbolic reasoning
challenges. Empirical evaluation on AR-Bench demonstrates that contemporary
LLMs exhibit pronounced difficulties with active reasoning: they frequently
fail to acquire or leverage the information needed to solve tasks. This gap
highlights a stark divergence between their passive and active reasoning
abilities. Moreover, ablation studies indicate that even advanced strategies,
such as tree-based searching or post-training approaches, yield only modest
gains and fall short of the levels required for real-world deployment.
Collectively, these findings highlight the critical need to advance methodology
for active reasoning, e.g., incorporating interactive learning, real-time
feedback loops, and environment-aware objectives for training. The benchmark is
publicly available at: https://github.com/tmlr-group/AR-Bench.

</details>


### [201] [Reinforce LLM Reasoning through Multi-Agent Reflection](https://arxiv.org/abs/2506.08379)
*Yurun Yuan,Tengyang Xie*

Main category: cs.LG

TL;DR: 论文提出DPSDP算法，通过强化学习优化LLM的多轮答案精炼过程，提升推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在反馈空间和协调训练方面存在不足，限制了性能提升。

Method: 将多轮精炼建模为马尔可夫决策过程，提出DPSDP算法，通过直接偏好学习训练actor-critic系统。

Result: 在MATH 500基准上，五轮精炼将准确率从58.2%提升至63.2%。

Conclusion: DPSDP有效提升LLM推理能力，支持多智能体协作和分布外泛化。

Abstract: Leveraging more test-time computation has proven to be an effective way to
boost the reasoning capabilities of large language models (LLMs). Among various
methods, the verify-and-improve paradigm stands out for enabling dynamic
solution exploration and feedback incorporation. However, existing approaches
often suffer from restricted feedback spaces and lack of coordinated training
of different parties, leading to suboptimal performance. To address this, we
model this multi-turn refinement process as a Markov Decision Process and
introduce DPSDP (Direct Policy Search by Dynamic Programming), a reinforcement
learning algorithm that trains an actor-critic LLM system to iteratively refine
answers via direct preference learning on self-generated data. Theoretically,
DPSDP can match the performance of any policy within the training distribution.
Empirically, we instantiate DPSDP with various base models and show
improvements on both in- and out-of-distribution benchmarks. For example, on
benchmark MATH 500, majority voting over five refinement steps increases
first-turn accuracy from 58.2% to 63.2% with Ministral-based models. An
ablation study further confirms the benefits of multi-agent collaboration and
out-of-distribution generalization.

</details>


### [202] [Reinforcement Learning Teachers of Test Time Scaling](https://arxiv.org/abs/2506.08388)
*Edoardo Cetin,Tianyu Zhao,Yujin Tang*

Main category: cs.LG

TL;DR: 论文提出了一种名为RLT（Reinforcement-Learned Teachers）的新框架，通过避免强化学习的探索挑战，专注于生成最有效的下游蒸馏模型。RLT通过提供详细解释来训练学生模型，并在实践中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习训练推理语言模型依赖于初始探索能力，且模型主要用于蒸馏新学生而非直接部署。因此，需要一种更高效的方法来生成适合蒸馏的教师模型。

Method: 引入RLT框架，教师模型通过问题和解决方案生成详细解释，并使用密集奖励训练，奖励基于学生对解释的理解效果。

Result: 7B规模的RLT在竞赛和研究生级任务中表现优于现有蒸馏方法，且适用于更大规模学生模型和零样本任务。

Conclusion: RLT框架显著提升了推理语言模型的效率和可重用性，为强化学习推理提供了新方向。

Abstract: Training reasoning language models (LMs) with reinforcement learning (RL) for
one-hot correctness inherently relies on the LM being able to explore and solve
its task with some chance at initialization. Furthermore, a key use case of
reasoning LMs is to act as teachers for distilling new students and
cold-starting future RL iterations rather than being deployed themselves. From
these considerations, we introduce a new framework that avoids RL's exploration
challenge by training a new class of Reinforcement-Learned Teachers (RLTs)
focused on yielding the most effective downstream distillation. RLTs are
prompted with both the question and solution to each problem, and tasked to
simply "connect-the-dots" with detailed explanations tailored for their
students. We train RLTs with dense rewards obtained by feeding each explanation
to the student and testing its understanding of the problem's solution. In
practice, the raw outputs of a 7B RLT provide higher final performance on
competition and graduate-level tasks than existing distillation and
cold-starting pipelines that collect and postprocess the reasoning traces of
orders of magnitude larger LMs. Furthermore, RLTs maintain their effectiveness
when training larger students and when applied zero-shot to out-of-distribution
tasks, unlocking new levels of efficiency and re-usability for the RL reasoning
framework.

</details>


### [203] [The Geometries of Truth Are Orthogonal Across Tasks](https://arxiv.org/abs/2506.08572)
*Waiss Azizian,Michael Kirchhof,Eugene Ndiaye,Louis Bethune,Michal Klein,Pierre Ablin,Marco Cuturi*

Main category: cs.LG

TL;DR: 研究发现，尽管大语言模型（LLMs）的激活模式可用于区分答案正确性，但这种“真理几何”方法因任务依赖性而无法跨任务迁移。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs激活模式在评估答案正确性时的可靠性，尤其是跨任务时的局限性。

Method: 通过线性分类器分析不同任务中激活模式的相似性，并尝试使用稀疏正则化和混合方法改进。

Result: 线性分类器在不同任务间相似性低，稀疏正则化后支持集几乎不重叠，混合方法也无法克服任务依赖性。

Conclusion: LLMs的“真理几何”方法受限于任务依赖性，跨任务迁移效果不佳。

Abstract: Large Language Models (LLMs) have demonstrated impressive generalization
capabilities across various tasks, but their claim to practical relevance is
still mired by concerns on their reliability. Recent works have proposed
examining the activations produced by an LLM at inference time to assess
whether its answer to a question is correct. Some works claim that a "geometry
of truth" can be learned from examples, in the sense that the activations that
generate correct answers can be distinguished from those leading to mistakes
with a linear classifier. In this work, we underline a limitation of these
approaches: we observe that these "geometries of truth" are intrinsically
task-dependent and fail to transfer across tasks. More precisely, we show that
linear classifiers trained across distinct tasks share little similarity and,
when trained with sparsity-enforcing regularizers, have almost disjoint
supports. We show that more sophisticated approaches (e.g., using mixtures of
probes and tasks) fail to overcome this limitation, likely because activation
vectors commonly used to classify answers form clearly separated clusters when
examined across tasks.

</details>


### [204] [Gridding Forced Displacement using Semi-Supervised Learning](https://arxiv.org/abs/2506.08019)
*Andrew Wells,Geraldine Henningsen,Brice Bolane Tchinde Kengne*

Main category: cs.LG

TL;DR: 论文提出了一种半监督方法，将难民的统计数据从行政边界分解到0.5度的网格单元，覆盖25个撒哈拉以南非洲国家。


<details>
  <summary>Details</summary>
Motivation: 传统的难民统计数据通常局限于区域和国家层面，难以揭示局部化的流离失所模式。

Method: 结合UNHCR的ProGres注册数据、Google Open Buildings的卫星建筑足迹和OpenStreetMap的地点坐标，采用标签传播算法生成高精度的空间难民统计数据。

Result: 该方法在将1000多万难民观测数据分配到网格单元时，平均准确率达到92.9%，成功识别了之前被掩盖的局部流离失所模式。

Conclusion: 高分辨率的数据集为深入理解流离失所的驱动因素提供了基础。

Abstract: We present a semi-supervised approach that disaggregates refugee statistics
from administrative boundaries to 0.5-degree grid cells across 25 Sub-Saharan
African countries. By integrating UNHCR's ProGres registration data with
satellite-derived building footprints from Google Open Buildings and location
coordinates from OpenStreetMap Populated Places, our label spreading algorithm
creates spatially explicit refugee statistics at high granularity.This
methodology achieves 92.9% average accuracy in placing over 10 million refugee
observations into appropriate grid cells, enabling the identification of
localized displacement patterns previously obscured in broader regional and
national statistics. The resulting high-resolution dataset provides a
foundation for a deeper understanding of displacement drivers.

</details>


### [205] [Bi-level Unbalanced Optimal Transport for Partial Domain Adaptation](https://arxiv.org/abs/2506.08020)
*Zi-Ying Chen,Chuan-Xian Ren,Hong Yan*

Main category: cs.LG

TL;DR: 提出了一种双层次不平衡最优传输模型（BUOT），通过同时表征样本级和类别级关系，解决了部分域适应（PDA）问题中的异常类别识别和跨域对齐问题。


<details>
  <summary>Details</summary>
Motivation: 部分域适应（PDA）问题中，现有权重框架仅能表征样本级关系，对异常类别的识别不足且易受预测误差影响。

Method: 提出BUOT模型，通过样本级和类别级传输的合作机制，统一表征样本和类别关系，并引入标签感知传输成本以提高效率和局部结构。

Result: 在基准数据集上的实验验证了BUOT的竞争力。

Conclusion: BUOT通过双层次传输框架有效解决了PDA问题，提升了异常类别的识别和跨域对齐的准确性。

Abstract: Partial domain adaptation (PDA) problem requires aligning cross-domain
samples while distinguishing the outlier classes for accurate knowledge
transfer. The widely used weighting framework tries to address the outlier
classes by introducing the reweighed source domain with a similar label
distribution to the target domain. However, the empirical modeling of weights
can only characterize the sample-wise relations, which leads to insufficient
exploration of cluster structures, and the weights could be sensitive to the
inaccurate prediction and cause confusion on the outlier classes. To tackle
these issues, we propose a Bi-level Unbalanced Optimal Transport (BUOT) model
to simultaneously characterize the sample-wise and class-wise relations in a
unified transport framework. Specifically, a cooperation mechanism between
sample-level and class-level transport is introduced, where the sample-level
transport provides essential structure information for the class-level
knowledge transfer, while the class-level transport supplies discriminative
information for the outlier identification. The bi-level transport plan
provides guidance for the alignment process. By incorporating the label-aware
transport cost, the local transport structure is ensured and a fast computation
formulation is derived to improve the efficiency. Extensive experiments on
benchmark datasets validate the competitiveness of BUOT.

</details>


### [206] [SwS: Self-aware Weakness-driven Problem Synthesis in Reinforcement Learning for LLM Reasoning](https://arxiv.org/abs/2506.08989)
*Xiao Liang,Zhong-Zhi Li,Yeyun Gong,Yang Wang,Hengyuan Zhang,Yelong Shen,Ying Nian Wu,Weizhu Chen*

Main category: cs.LG

TL;DR: 论文提出了一种自我感知弱点驱动的问题合成框架（SwS），通过识别模型在强化学习中的弱点并针对性生成问题，显著提升了模型在复杂推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在训练大型语言模型时，依赖高质量问题集，但人工标注问题和合成数据集的局限性限制了其效果。此外，问题合成策略往往忽视模型能力，导致效率低下。

Method: 提出SwS框架，通过识别模型在训练中持续失败的问题（弱点），提取核心概念并合成新问题，针对性增强模型弱项。

Result: 在不依赖外部知识蒸馏的情况下，SwS框架在7B和32B模型上平均性能提升10.0%和7.7%，覆盖八个主流推理基准。

Conclusion: SwS框架通过自我识别和解决弱点，显著提升了强化学习在复杂推理任务中的效果，为模型训练提供了高效的新方法。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective
for training large language models (LLMs) on complex reasoning tasks, such as
mathematical problem solving. A prerequisite for the scalability of RLVR is a
high-quality problem set with precise and verifiable answers. However, the
scarcity of well-crafted human-labeled math problems and limited-verification
answers in existing distillation-oriented synthetic datasets limit their
effectiveness in RL. Additionally, most problem synthesis strategies
indiscriminately expand the problem set without considering the model's
capabilities, leading to low efficiency in generating useful questions. To
mitigate this issue, we introduce a Self-aware Weakness-driven problem
Synthesis framework (SwS) that systematically identifies model deficiencies and
leverages them for problem augmentation. Specifically, we define weaknesses as
questions that the model consistently fails to learn through its iterative
sampling during RL training. We then extract the core concepts from these
failure cases and synthesize new problems to strengthen the model's weak areas
in subsequent augmented training, enabling it to focus on and gradually
overcome its weaknesses. Without relying on external knowledge distillation,
our framework enables robust generalization byempowering the model to
self-identify and address its weaknesses in RL, yielding average performance
gains of 10.0% and 7.7% on 7B and 32B models across eight mainstream reasoning
benchmarks.

</details>


### [207] [e3: Learning to Explore Enables Extrapolation of Test-Time Compute for LLMs](https://arxiv.org/abs/2506.09026)
*Amrith Setlur,Matthew Y. R. Yang,Charlie Snell,Jeremy Greer,Ian Wu,Virginia Smith,Max Simchowitz,Aviral Kumar*

Main category: cs.LG

TL;DR: 论文提出了一种通过训练LLM进行上下文探索（e3方法）来改善推理性能的方法，包括技能链、负梯度利用和课程设计，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有推理模型在推断时难以有效扩展性能，尤其是在超出训练预算的难题上。

Method: 提出e3方法，包括技能链（如验证与生成结合）、负梯度强化探索、以及基于课程设计的训练预算分配。

Result: e3-1.7B模型在AIME'25和HMMT'25上表现最佳，并能扩展到2倍训练预算，显著提升pass@1和pass@k分数。

Conclusion: 通过上下文探索训练LLM可显著提升推理性能，尤其是在超出训练预算的场景下。

Abstract: Test-time scaling offers a promising path to improve LLM reasoning by
utilizing more compute at inference time; however, the true promise of this
paradigm lies in extrapolation (i.e., improvement in performance on hard
problems as LLMs keep "thinking" for longer, beyond the maximum token budget
they were trained on). Surprisingly, we find that most existing reasoning
models do not extrapolate well. We show that one way to enable extrapolation is
by training the LLM to perform in-context exploration: training the LLM to
effectively spend its test time budget by chaining operations (such as
generation, verification, refinement, etc.), or testing multiple hypotheses
before it commits to an answer. To enable in-context exploration, we identify
three key ingredients as part of our recipe e3: (1) chaining skills that the
base LLM has asymmetric competence in, e.g., chaining verification (easy) with
generation (hard), as a way to implement in-context search; (2) leveraging
"negative" gradients from incorrect traces to amplify exploration during RL,
resulting in longer search traces that chains additional asymmetries; and (3)
coupling task difficulty with training token budget during training via a
specifically-designed curriculum to structure in-context exploration. Our
recipe e3 produces the best known 1.7B model according to AIME'25 and HMMT'25
scores, and extrapolates to 2x the training token budget. Our e3-1.7B model not
only attains high pass@1 scores, but also improves pass@k over the base model.

</details>


### [208] [An Adaptive Method Stabilizing Activations for Enhanced Generalization](https://arxiv.org/abs/2506.08353)
*Hyunseok Seung,Jaewoo Lee,Hyunsuk Ko*

Main category: cs.LG

TL;DR: AdaAct是一种新颖的优化算法，通过根据激活方差调整学习率，提升神经元输出的稳定性，从而改善泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统激活正则化方法存在局限性，AdaAct旨在通过神经元自适应性提升训练稳定性与泛化性能。

Method: AdaAct在训练过程中动态调整学习率，基于激活方差实现神经元级别的适应性优化。

Result: 在CIFAR和ImageNet等标准图像分类基准测试中，AdaAct表现优异，兼具Adam的快速收敛和SGD的强泛化能力。

Conclusion: AdaAct是一种高效的优化算法，能够平衡收敛速度与泛化性能，代码已开源。

Abstract: We introduce AdaAct, a novel optimization algorithm that adjusts learning
rates according to activation variance. Our method enhances the stability of
neuron outputs by incorporating neuron-wise adaptivity during the training
process, which subsequently leads to better generalization -- a complementary
approach to conventional activation regularization methods. Experimental
results demonstrate AdaAct's competitive performance across standard image
classification benchmarks. We evaluate AdaAct on CIFAR and ImageNet, comparing
it with other state-of-the-art methods. Importantly, AdaAct effectively bridges
the gap between the convergence speed of Adam and the strong generalization
capabilities of SGD, all while maintaining competitive execution times. Code is
available at https://github.com/hseung88/adaact.

</details>


### [209] [Boosting Gradient Leakage Attacks: Data Reconstruction in Realistic FL Settings](https://arxiv.org/abs/2506.08435)
*Mingyuan Fan,Fuyi Wang,Cen Chen,Jianying Zhou*

Main category: cs.LG

TL;DR: 本文通过实证研究证明，即使在现实的联邦学习环境中，梯度泄漏攻击（GLAs）仍能有效重建客户端数据，并提出FedLeak方法以解决性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）的隐私保护能力备受争议，现有研究对梯度泄漏攻击（GLAs）的实际风险存在分歧。本文旨在填补这一空白，证明GLAs在现实FL环境中仍具威胁。

Method: 提出FedLeak方法，包含部分梯度匹配和梯度正则化两种新技术，并设计了一个基于文献和行业实践的实际评估协议。

Result: FedLeak在现实FL环境中仍能实现高保真数据重建，揭示了FL系统的重大漏洞。

Conclusion: FL系统存在显著隐私风险，亟需更有效的防御方法。

Abstract: Federated learning (FL) enables collaborative model training among multiple
clients without the need to expose raw data. Its ability to safeguard privacy,
at the heart of FL, has recently been a hot-button debate topic. To elaborate,
several studies have introduced a type of attacks known as gradient leakage
attacks (GLAs), which exploit the gradients shared during training to
reconstruct clients' raw data. On the flip side, some literature, however,
contends no substantial privacy risk in practical FL environments due to the
effectiveness of such GLAs being limited to overly relaxed conditions, such as
small batch sizes and knowledge of clients' data distributions.
  This paper bridges this critical gap by empirically demonstrating that
clients' data can still be effectively reconstructed, even within realistic FL
environments. Upon revisiting GLAs, we recognize that their performance
failures stem from their inability to handle the gradient matching problem. To
alleviate the performance bottlenecks identified above, we develop FedLeak,
which introduces two novel techniques, partial gradient matching and gradient
regularization. Moreover, to evaluate the performance of FedLeak in real-world
FL environments, we formulate a practical evaluation protocol grounded in a
thorough review of extensive FL literature and industry practices. Under this
protocol, FedLeak can still achieve high-fidelity data reconstruction, thereby
underscoring the significant vulnerability in FL systems and the urgent need
for more effective defense methods.

</details>


### [210] [HSG-12M: A Large-Scale Spatial Multigraph Dataset](https://arxiv.org/abs/2506.08618)
*Xianquan Yan,Hakan Akgün,Kenji Kawaguchi,N. Duane Loh,Ching Hua Lee*

Main category: cs.LG

TL;DR: HSG-12M是首个大规模空间多重图数据集，包含静态和动态的哈密顿谱图，用于几何感知图学习。


<details>
  <summary>Details</summary>
Motivation: 现有图基准假设边是非空间且简单的，忽略了物理上不同的路径。HSG-12M填补了这一空白。

Method: 通过Poly2Graph管道将一维晶体哈密顿量映射为谱图，生成多样化的物理拓扑结构。

Result: HSG-12M包含1160万静态和510万动态谱图，展示了多边几何学习的新挑战。

Conclusion: 谱图作为多项式、向量和矩阵的通用拓扑指纹，为数据驱动的科学发现提供了新机会。

Abstract: Existing graph benchmarks assume non-spatial, simple edges, collapsing
physically distinct paths into a single link. We introduce HSG-12M, the first
large-scale dataset of $\textbf{spatial multigraphs}-$graphs embedded in a
metric space where multiple geometrically distinct trajectories between two
nodes are retained as separate edges. HSG-12M contains 11.6 million static and
5.1 million dynamic $\textit{Hamiltonian spectral graphs}$ across 1401
characteristic-polynomial classes, derived from 177 TB of spectral potential
data. Each graph encodes the full geometry of a 1-D crystal's energy spectrum
on the complex plane, producing diverse, physics-grounded topologies that
transcend conventional node-coordinate datasets. To enable future extensions,
we release $\texttt{Poly2Graph}$: a high-performance, open-source pipeline that
maps arbitrary 1-D crystal Hamiltonians to spectral graphs. Benchmarks with
popular GNNs expose new challenges in learning from multi-edge geometry at
scale. Beyond its practical utility, we show that spectral graphs serve as
universal topological fingerprints of polynomials, vectors, and matrices,
forging a new algebra-to-graph link. HSG-12M lays the groundwork for
geometry-aware graph learning and new opportunities of data-driven scientific
discovery in condensed matter physics and beyond.

</details>


### [211] [Time Series Representations for Classification Lie Hidden in Pretrained Vision Transformers](https://arxiv.org/abs/2506.08641)
*Simon Roschmann,Quentin Bouniot,Vasilii Feofanov,Ievgen Redko,Zeynep Akata*

Main category: cs.LG

TL;DR: TiViT将时间序列转换为图像，利用预训练的视觉Transformer（ViT）提升时间序列分类性能，并在标准基准测试中达到最优表现。


<details>
  <summary>Details</summary>
Motivation: 时间序列分类在医疗和工业中很重要，但公开数据集稀缺限制了时间序列基础模型（TSFM）的发展。

Method: 提出TiViT框架，将时间序列转换为图像，利用预训练的ViT模型（如OpenCLIP）的隐藏表示进行分类。

Result: TiViT在标准时间序列分类基准测试中表现最优，且中间层的高内在维度对分类最有效。

Conclusion: TiViT展示了视觉表示在非视觉领域的新应用方向，并与TSFM表示空间互补，进一步提升性能。

Abstract: Time series classification is a fundamental task in healthcare and industry,
yet the development of time series foundation models (TSFMs) remains limited by
the scarcity of publicly available time series datasets. In this work, we
propose Time Vision Transformer (TiViT), a framework that converts time series
into images to leverage the representational power of frozen Vision
Transformers (ViTs) pretrained on large-scale image datasets. First, we
theoretically motivate our approach by analyzing the 2D patching of ViTs for
time series, showing that it can increase the number of label-relevant tokens
and reduce the sample complexity. Second, we empirically demonstrate that TiViT
achieves state-of-the-art performance on standard time series classification
benchmarks by utilizing the hidden representations of large OpenCLIP models. We
explore the structure of TiViT representations and find that intermediate
layers with high intrinsic dimension are the most effective for time series
classification. Finally, we assess the alignment between TiViT and TSFM
representation spaces and identify a strong complementarity, with further
performance gains achieved by combining their features. Our findings reveal yet
another direction for reusing vision representations in a non-visual domain.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [212] [A System for Accurate Tracking and Video Recordings of Rodent Eye Movements using Convolutional Neural Networks for Biomedical Image Segmentation](https://arxiv.org/abs/2506.08183)
*Isha Puri,David Cox*

Main category: eess.IV

TL;DR: 本文提出了一种灵活、鲁棒且高精度的模型，用于啮齿类动物的瞳孔和角膜反射识别，以解决现有眼动追踪技术未考虑啮齿类动物眼睛独特特性的问题。


<details>
  <summary>Details</summary>
Motivation: 啮齿类动物是神经科学和视觉科学研究的常用对象，但现有眼动追踪技术主要针对人类眼睛设计，未考虑啮齿类动物眼睛的特殊性（如参数变化、周围毛发多、眼睛小等）。

Method: 采用基于卷积神经网络（CNN）的生物医学图像分割方法，开发了一种可增量训练的模型，用于瞳孔和角膜反射识别。

Result: 该方法结合自动化红外视频眼动记录系统，实现了高精度和实用性的啮齿类动物眼动追踪技术。

Conclusion: 本文提出的方法是首个针对啮齿类动物眼睛的高精度眼动追踪技术，为神经科学和视觉科学研究提供了先进工具。

Abstract: Research in neuroscience and vision science relies heavily on careful
measurements of animal subject's gaze direction. Rodents are the most widely
studied animal subjects for such research because of their economic advantage
and hardiness. Recently, video based eye trackers that use image processing
techniques have become a popular option for gaze tracking because they are easy
to use and are completely noninvasive. Although significant progress has been
made in improving the accuracy and robustness of eye tracking algorithms,
unfortunately, almost all of the techniques have focused on human eyes, which
does not account for the unique characteristics of the rodent eye images, e.g.,
variability in eye parameters, abundance of surrounding hair, and their small
size. To overcome these unique challenges, this work presents a flexible,
robust, and highly accurate model for pupil and corneal reflection
identification in rodent gaze determination that can be incrementally trained
to account for variability in eye parameters encountered in the field. To the
best of our knowledge, this is the first paper that demonstrates a highly
accurate and practical biomedical image segmentation based convolutional neural
network architecture for pupil and corneal reflection identification in eye
images. This new method, in conjunction with our automated infrared videobased
eye recording system, offers the state of the art technology in eye tracking
for neuroscience and vision science research for rodents.

</details>


### [213] [Snap-and-tune: combining deep learning and test-time optimization for high-fidelity cardiovascular volumetric meshing](https://arxiv.org/abs/2506.08280)
*Daniel H. Pak,Shubh Thaker,Kyle Baylous,Xiaoran Zhang,Danny Bluestein,James S. Duncan*

Main category: eess.IV

TL;DR: 提出了一种结合深度学习和测试时优化的“snap-and-tune”策略，用于医学图像的高质量体积网格生成，显著提升了空间精度和网格质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度学习方法在高曲率区域灵活性不足和部件间距离不真实的问题。

Method: 采用“snap-and-tune”策略，先通过深度学习快速拟合初始形状，再通过测试时优化进行样本特定的网格修正。

Result: 方法在空间精度和网格质量上均有显著提升，且完全自动化，无需额外训练标签。

Conclusion: 该方法在两种不同软件平台上的固体力学模拟中展示了其多功能性和实用性。

Abstract: High-quality volumetric meshing from medical images is a key bottleneck for
physics-based simulations in personalized medicine. For volumetric meshing of
complex medical structures, recent studies have often utilized deep learning
(DL)-based template deformation approaches to enable fast test-time generation
with high spatial accuracy. However, these approaches still exhibit
limitations, such as limited flexibility at high-curvature areas and
unrealistic inter-part distances. In this study, we introduce a simple yet
effective snap-and-tune strategy that sequentially applies DL and test-time
optimization, which combines fast initial shape fitting with more detailed
sample-specific mesh corrections. Our method provides significant improvements
in both spatial accuracy and mesh quality, while being fully automated and
requiring no additional training labels. Finally, we demonstrate the
versatility and usefulness of our newly generated meshes via solid mechanics
simulations in two different software platforms. Our code is available at
https://github.com/danpak94/Deep-Cardiac-Volumetric-Mesh.

</details>


### [214] [Plug-and-Play Linear Attention for Pre-trained Image and Video Restoration Models](https://arxiv.org/abs/2506.08520)
*Srinivasan Kidambi,Pravin Nair*

Main category: eess.IV

TL;DR: PnP-Nystra是一种基于Nyström的线性自注意力近似方法，作为即插即用模块，无需重新训练即可集成到预训练的视觉模型中，显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 多头自注意力（MHSA）在视觉模型中广泛使用，但其二次复杂度在实时和资源受限环境中成为计算瓶颈。

Method: 提出PnP-Nystra，一种基于Nyström的线性自注意力近似方法，作为即插即用模块替换MHSA。

Result: 在图像和视频修复任务中，PnP-Nystra在GPU和CPU上分别实现2-4x和2-5x加速，PSNR最多仅下降1.5 dB。

Conclusion: PnP-Nystra是首个无需训练的线性注意力替代方案，显著提升效率且性能损失极小。

Abstract: Multi-head self-attention (MHSA) has become a core component in modern
computer vision models. However, its quadratic complexity with respect to input
length poses a significant computational bottleneck in real-time and resource
constrained environments. We propose PnP-Nystra, a Nystr\"om based linear
approximation of self-attention, developed as a plug-and-play (PnP) module that
can be integrated into the pre-trained image and video restoration models
without retraining. As a drop-in replacement for MHSA, PnP-Nystra enables
efficient acceleration in various window-based transformer architectures,
including SwinIR, Uformer, and RVRT. Our experiments across diverse image and
video restoration tasks, including denoising, deblurring, and super-resolution,
demonstrate that PnP-Nystra achieves a 2-4x speed-up on an NVIDIA RTX 4090 GPU
and a 2-5x speed-up on CPU inference. Despite these significant gains, the
method incurs a maximum PSNR drop of only 1.5 dB across all evaluated tasks. To
the best of our knowledge, we are the first to demonstrate a linear attention
functioning as a training-free substitute for MHSA in restoration models.

</details>


### [215] [DCD: A Semantic Segmentation Model for Fetal Ultrasound Four-Chamber View](https://arxiv.org/abs/2506.08534)
*Donglian Li,Hui Guo,Minglang Chen,Huizhen Chen,Jialing Chen,Bocheng Liang,Pengchen Liang,Ying Tan*

Main category: eess.IV

TL;DR: 提出了一种基于深度学习的模型DCD，用于胎儿心脏四腔心切面中关键解剖结构的自动分割，以提高分割精度并减少超声医师的工作量。


<details>
  <summary>Details</summary>
Motivation: 胎儿心脏四腔心切面的精确分割对先天性心脏病的早期诊断和产前评估至关重要，但由于超声伪影、噪声和解剖变异等因素，分割仍具挑战性。

Method: DCD模型结合了Dense ASPP模块和CBAM模块，用于多尺度特征提取和自适应特征表示，从而捕捉局部和全局上下文信息。

Result: DCD实现了精确且鲁棒的分割，有助于提升产前心脏评估的质量。

Conclusion: DCD模型通过改进特征提取和表示能力，为胎儿心脏分割提供了一种有效的解决方案。

Abstract: Accurate segmentation of anatomical structures in the apical four-chamber
(A4C) view of fetal echocardiography is essential for early diagnosis and
prenatal evaluation of congenital heart disease (CHD). However, precise
segmentation remains challenging due to ultrasound artifacts, speckle noise,
anatomical variability, and boundary ambiguity across different gestational
stages. To reduce the workload of sonographers and enhance segmentation
accuracy, we propose DCD, an advanced deep learning-based model for automatic
segmentation of key anatomical structures in the fetal A4C view. Our model
incorporates a Dense Atrous Spatial Pyramid Pooling (Dense ASPP) module,
enabling superior multi-scale feature extraction, and a Convolutional Block
Attention Module (CBAM) to enhance adaptive feature representation. By
effectively capturing both local and global contextual information, DCD
achieves precise and robust segmentation, contributing to improved prenatal
cardiac assessment.

</details>


### [216] [Biologically Inspired Deep Learning Approaches for Fetal Ultrasound Image Classification](https://arxiv.org/abs/2506.08623)
*Rinat Prochii,Elizaveta Dakhova,Pavel Birulin,Maxim Sharaev*

Main category: eess.IV

TL;DR: 本文提出了一种生物启发的深度学习集成框架，用于同时分类16种胎儿结构，解决了图像质量低、类内变异大和类别不平衡的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于胎儿超声图像质量低、类内变异大和类别不平衡，准确分类第二孕期胎儿超声图像具有挑战性。

Method: 采用生物视觉系统的分层模块化结构，设计了一个双分支模型（浅路径用于粗粒度特征，详细路径用于细粒度特征），并结合LDAM-Focal损失函数进行训练。

Result: 在5,298张临床图像上评估，模型对90%的器官分类准确率超过0.75，75%的器官超过0.85，性能优于其他复杂模型。

Conclusion: 生物启发的模块化堆叠方法在复杂临床环境中实现了鲁棒且可扩展的胎儿解剖识别。

Abstract: Accurate classification of second-trimester fetal ultrasound images remains
challenging due to low image quality, high intra-class variability, and
significant class imbalance. In this work, we introduce a simple yet powerful,
biologically inspired deep learning ensemble framework that-unlike prior
studies focused on only a handful of anatomical targets-simultaneously
distinguishes 16 fetal structures. Drawing on the hierarchical, modular
organization of biological vision systems, our model stacks two complementary
branches (a "shallow" path for coarse, low-resolution cues and a "detailed"
path for fine, high-resolution features), concatenating their outputs for final
prediction. To our knowledge, no existing method has addressed such a large
number of classes with a comparably lightweight architecture. We trained and
evaluated on 5,298 routinely acquired clinical images (annotated by three
experts and reconciled via Dawid-Skene), reflecting real-world noise and
variability rather than a "cleaned" dataset. Despite this complexity, our
ensemble (EfficientNet-B0 + EfficientNet-B6 with LDAM-Focal loss) identifies
90% of organs with accuracy > 0.75 and 75% of organs with accuracy >
0.85-performance competitive with more elaborate models applied to far fewer
categories. These results demonstrate that biologically inspired modular
stacking can yield robust, scalable fetal anatomy recognition in challenging
clinical settings.

</details>


### [217] [MAMBO: High-Resolution Generative Approach for Mammography Images](https://arxiv.org/abs/2506.08677)
*Milica Škipina,Nikola Jovišić,Nicola Dall'Asen,Vanja Švenda,Anil Osman Tur,Slobodan Ilić,Elisa Ricci,Dubravko Ćulibrk*

Main category: eess.IV

TL;DR: 论文提出了一种名为MAMBO的基于扩散模型的乳腺X光片生成方法，能够生成高分辨率图像以辅助AI训练和乳腺癌诊断。


<details>
  <summary>Details</summary>
Motivation: 由于隐私和伦理限制，获取大规模多样化的乳腺X光片数据集困难，影响了AI系统的训练效果。

Method: MAMBO采用基于块的扩散模型，结合局部和全局上下文信息，生成高达3840x3840像素的高分辨率乳腺X光片。

Result: MAMBO能够生成高度真实的乳腺X光片，并在图像生成、超分辨率和异常检测任务中表现出色。

Conclusion: MAMBO有潜力提升乳腺X光片分析的准确性，助力早期病变检测。

Abstract: Mammography is the gold standard for the detection and diagnosis of breast
cancer. This procedure can be significantly enhanced with Artificial
Intelligence (AI)-based software, which assists radiologists in identifying
abnormalities. However, training AI systems requires large and diverse
datasets, which are often difficult to obtain due to privacy and ethical
constraints. To address this issue, the paper introduces MAMmography ensemBle
mOdel (MAMBO), a novel patch-based diffusion approach designed to generate
full-resolution mammograms. Diffusion models have shown breakthrough results in
realistic image generation, yet few studies have focused on mammograms, and
none have successfully generated high-resolution outputs required to capture
fine-grained features of small lesions. To achieve this, MAMBO integrates
separate diffusion models to capture both local and global (image-level)
contexts. The contextual information is then fed into the final patch-based
model, significantly aiding the noise removal process. This thoughtful design
enables MAMBO to generate highly realistic mammograms of up to 3840x3840
pixels. Importantly, this approach can be used to enhance the training of
classification models and extended to anomaly detection. Experiments, both
numerical and radiologist validation, assess MAMBO's capabilities in image
generation, super-resolution, and anomaly detection, highlighting its potential
to enhance mammography analysis for more accurate diagnoses and earlier lesion
detection.

</details>


### [218] [Enhancing Synthetic CT from CBCT via Multimodal Fusion: A Study on the Impact of CBCT Quality and Alignment](https://arxiv.org/abs/2506.08716)
*Maximilian Tschuchnig,Lukas Lamminger,Philipp Steininger,Michael Gadermayr*

Main category: eess.IV

TL;DR: 该论文提出了一种通过多模态学习（结合术中CBCT和术前CT）来提升合成CT（sCT）生成质量的方法，显著改善了CBCT的伪影问题，并在真实临床数据中验证了其可重复性。


<details>
  <summary>Details</summary>
Motivation: CBCT虽然具有低辐射和高采集速度的优势，但其图像质量因伪影问题而低于传统CT。通过合成CT（sCT）生成技术可以缓解这一问题，但需要进一步提升其质量。

Method: 采用多模态学习方法，将术中CBCT与术前CT结合，生成高质量的sCT。通过合成数据集和真实数据集验证了方法的有效性。

Result: 多模态sCT在低质量CBCT-CT对齐情况下表现最佳，显著优于单模态基线方法，且在真实临床数据中具有高度可重复性。

Conclusion: 多模态学习能有效提升sCT生成质量，尤其在CBCT质量较差时效果显著，为临床实践提供了可靠支持。

Abstract: Cone-Beam Computed Tomography (CBCT) is widely used for real-time
intraoperative imaging due to its low radiation dose and high acquisition
speed. However, despite its high resolution, CBCT suffers from significant
artifacts and thereby lower visual quality, compared to conventional Computed
Tomography (CT). A recent approach to mitigate these artifacts is synthetic CT
(sCT) generation, translating CBCT volumes into the CT domain. In this work, we
enhance sCT generation through multimodal learning, integrating intraoperative
CBCT with preoperative CT. Beyond validation on two real-world datasets, we use
a versatile synthetic dataset, to analyze how CBCT-CT alignment and CBCT
quality affect sCT quality. The results demonstrate that multimodal sCT
consistently outperform unimodal baselines, with the most significant gains
observed in well-aligned, low-quality CBCT-CT cases. Finally, we demonstrate
that these findings are highly reproducible in real-world clinical datasets.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [219] [Neural-Augmented Kelvinlet: Real-Time Soft Tissue Deformation with Multiple Graspers](https://arxiv.org/abs/2506.08043)
*Ashkan Shahbazi,Kyvia Pereira,Jon S. Heiselman,Elaheh Akbari,Annie C. Benson,Sepehr Seifi,Xinyuan Liu,Garrison L. Johnston,Erwin Terpstra,Anne Draaisma,Jan-Jaap Severes,Jie Ying Wu,Nabil Simaan,Michael L. Miga,Soheil Kolouri*

Main category: cs.GR

TL;DR: 提出了一种基于物理信息的神经模拟器，通过整合Kelvinlet先验和数据驱动的软组织建模，实现了快速、准确的软组织变形模拟。


<details>
  <summary>Details</summary>
Motivation: 手术机器人和医学训练需要快速且准确的软组织变形模拟。

Method: 结合Kelvinlet先验和神经网络模拟器，利用大规模FEM模拟进行残差学习和正则化。

Result: 提高了神经网络预测的准确性和物理一致性，同时保持低延迟，适用于实时手术模拟。

Conclusion: Kelvinlet增强学习是一种高效且强大的策略，适用于实时、物理感知的软组织模拟。

Abstract: Fast and accurate simulation of soft tissue deformation is a critical factor
for surgical robotics and medical training. In this paper, we introduce a novel
physics-informed neural simulator that approximates soft tissue deformations in
a realistic and real-time manner. Our framework integrates Kelvinlet-based
priors into neural simulators, making it the first approach to leverage
Kelvinlets for residual learning and regularization in data-driven soft tissue
modeling. By incorporating large-scale Finite Element Method (FEM) simulations
of both linear and nonlinear soft tissue responses, our method improves neural
network predictions across diverse architectures, enhancing accuracy and
physical consistency while maintaining low latency for real-time performance.
We demonstrate the effectiveness of our approach by performing accurate
surgical maneuvers that simulate the use of standard laparoscopic tissue
grasping tools with high fidelity. These results establish Kelvinlet-augmented
learning as a powerful and efficient strategy for real-time, physics-aware soft
tissue simulation in surgical applications.

</details>


### [220] [A Real-time 3D Desktop Display](https://arxiv.org/abs/2506.08064)
*Livio Tenze,Enrique Canessa*

Main category: cs.GR

TL;DR: altiro3D库扩展版，支持从2D图像或视频实时生成3D光场，利用AI技术提升性能，并新增多平台GUI。


<details>
  <summary>Details</summary>
Motivation: 为玻璃自由全息显示提供实时3D视频流处理能力，扩展应用场景至桌面屏幕区域。

Method: 使用MiDaS CNN从单张2D图像提取深度图，结合AI优化性能，支持多平台GUI选择屏幕区域。

Result: 实现从2D图像、视频或桌面屏幕区域实时生成3D光场，兼容Looking Glass等设备。

Conclusion: 扩展版altiro3D库显著提升了3D内容生成的实时性和灵活性，适用于多样化应用场景。

Abstract: A new extended version of the altiro3D C++ Library -- initially developed to
get glass-free holographic displays starting from 2D images -- is here
introduced aiming to deal with 3D video streams from either 2D webcam images or
flat video files. These streams are processed in real-time to synthesize
light-fields (in Native format) and feed realistic 3D experiences. The core
function needed to recreate multiviews consists on the use of MiDaS
Convolutional Neural Network (CNN), which allows to extract a depth map from a
single 2D image. Artificial Intelligence (AI) computing techniques are applied
to improve the overall performance of the extended altiro3D Library. Thus,
altiro3D can now treat standard images, video streams or screen portions of a
Desktop where other apps may be also running (like web browsers, video chats,
etc) and render them into 3D. To achieve the latter, a screen region need to be
selected in order to feed the output directly into a light-field 3D device such
as Looking Glass (LG) Portrait. In order to simplify the acquisition of a
Desktop screen area by the user, a multi-platform Graphical User Interface has
been also implemented. Sources available at:
https://github.com/canessae/altiro3D/releases/tag/2.0.0

</details>


### [221] [Generalizable Articulated Object Reconstruction from Casually Captured RGBD Videos](https://arxiv.org/abs/2506.08334)
*Weikun Peng,Jun Lv,Cewu Lu,Manolis Savva*

Main category: cs.GR

TL;DR: 论文提出了一种从手持相机拍摄的RGBD视频中重建铰接物体的方法，解决了现有方法对数据采集要求高的问题。


<details>
  <summary>Details</summary>
Motivation: 铰接物体在日常生活中普遍存在，但其运动学结构的理解和重建在AI和机器人领域有广泛应用。现有方法需要精心采集的数据，限制了实际应用和推广。

Method: 采用从粗到细的框架，从动态RGBD视频中推断关节参数并分割物体的可动部分。

Result: 构建了一个更大的合成数据集进行测试，实验表明该方法在合成和真实铰接物体重建中显著优于现有方法。

Conclusion: 该方法能够从动态RGBD视频中高效重建铰接物体，具有实际应用潜力。

Abstract: Articulated objects are prevalent in daily life. Understanding their
kinematic structure and reconstructing them have numerous applications in
embodied AI and robotics. However, current methods require carefully captured
data for training or inference, preventing practical, scalable, and
generalizable reconstruction of articulated objects. We focus on reconstruction
of an articulated object from a casually captured RGBD video shot with a
hand-held camera. A casually captured video of an interaction with an
articulated object is easy to acquire at scale using smartphones. However, this
setting is quite challenging, as the object and camera move simultaneously and
there are significant occlusions as the person interacts with the object. To
tackle these challenges, we introduce a coarse-to-fine framework that infers
joint parameters and segments movable parts of the object from a dynamic RGBD
video. To evaluate our method under this new setting, we build a 20$\times$
larger synthetic dataset of 784 videos containing 284 objects across 11
categories. We compare our approach with existing methods that also take video
as input. Experiments show that our method can reconstruct synthetic and real
articulated objects across different categories from dynamic RGBD videos,
outperforming existing methods significantly.

</details>


### [222] [Complex-Valued Holographic Radiance Fields](https://arxiv.org/abs/2506.08350)
*Yicheng Zhan,Dong-Ha Shin,Seung-Hwan Baek,Kaan Akşit*

Main category: cs.GR

TL;DR: 提出了一种基于复值高斯基元的3D全息场景表示方法，显著提升了渲染速度，同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 为了支持全息显示中的物理真实渲染，需要一种能够同时建模光的振幅和相位的3D表示方法。

Method: 通过复值高斯基元重新定义3D高斯泼溅，利用RGBD多视图图像直接优化复值高斯基元作为3D全息场景表示。

Result: 相比现有方法，实现了30倍至10,000倍的速度提升，同时保持图像质量。

Conclusion: 该方法为几何对齐且物理真实的3D全息场景表示迈出了第一步。

Abstract: Modeling the full properties of light, including both amplitude and phase, in
3D representations is crucial for advancing physically plausible rendering,
particularly in holographic displays. To support these features, we propose a
novel representation that optimizes 3D scenes without relying on
intensity-based intermediaries. We reformulate 3D Gaussian splatting with
complex-valued Gaussian primitives, expanding support for rendering with light
waves. By leveraging RGBD multi-view images, our method directly optimizes
complex-valued Gaussians as a 3D holographic scene representation. This
eliminates the need for computationally expensive hologram re-optimization.
Compared with state-of-the-art methods, our method achieves 30x-10,000x speed
improvements while maintaining on-par image quality, representing a first step
towards geometrically aligned, physically plausible holographic scene
representations.

</details>


### [223] [Fine-Grained Spatially Varying Material Selection in Images](https://arxiv.org/abs/2506.09023)
*Julia Guerrero-Viu,Michael Fischer,Iliyan Georgiev,Elena Garces,Diego Gutierrez,Belen Masia,Valentin Deschaintre*

Main category: cs.GR

TL;DR: 提出了一种基于视觉Transformer（ViT）的材料选择方法，通过多分辨率处理策略提升选择精度和稳定性，并支持纹理和子纹理两级选择。


<details>
  <summary>Details</summary>
Motivation: 图像编辑中的选择步骤对后续修改至关重要，现有方法对光照和反射变化不够鲁棒，需要更高效的选择方法。

Method: 利用ViT模型的特征进行材料选择，采用多分辨率处理策略，并结合新构建的两级材料选择数据集（DuMaS）。

Result: 方法在纹理和子纹理级别上实现了更精细和稳定的选择效果，优于现有方法。

Conclusion: 该方法为图像编辑提供了高效的材料选择工具，尤其在复杂光照和反射条件下表现优异。

Abstract: Selection is the first step in many image editing processes, enabling faster
and simpler modifications of all pixels sharing a common modality. In this
work, we present a method for material selection in images, robust to lighting
and reflectance variations, which can be used for downstream editing tasks. We
rely on vision transformer (ViT) models and leverage their features for
selection, proposing a multi-resolution processing strategy that yields finer
and more stable selection results than prior methods. Furthermore, we enable
selection at two levels: texture and subtexture, leveraging a new two-level
material selection (DuMaS) dataset which includes dense annotations for over
800,000 synthetic images, both on the texture and subtexture levels.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [224] [RADAR: Benchmarking Language Models on Imperfect Tabular Data](https://arxiv.org/abs/2506.08249)
*Ken Gu,Zhihan Zhang,Kate Lin,Yuwei Zhang,Akshay Paruchuri,Hong Yu,Mehran Kazemi,Kumar Ayush,A. Ali Heydari,Maxwell A. Xu,Girish Narayanswamy,Yun Liu,Ming-Zher Poh,Yuzhe Yang,Mark Malhotra,Shwetak Patel,Hamid Palangi,Xuhai Xu,Daniel McDuff,Tim Althoff,Xin Liu*

Main category: cs.DB

TL;DR: RADAR是一个用于评估语言模型在表格数据中处理数据异常能力的基准测试，揭示了前沿模型在数据异常存在时的性能下降。


<details>
  <summary>Details</summary>
Motivation: 语言模型在自主数据分析中的应用日益增多，但其对数据异常（如缺失值、离群值等）的识别和处理能力尚未充分研究，这可能影响分析结论的有效性。

Method: 通过程序化扰动模拟数据异常，构建了包含2980个表格查询对的RADAR基准测试，涵盖9个领域和5种数据异常类型，并系统性地研究表格大小对推理性能的影响。

Result: 前沿模型在无数据异常时表现尚可，但在数据异常存在时性能显著下降，暴露了其在稳健数据分析能力上的不足。

Conclusion: RADAR作为一个灵活可扩展的基准测试，为提升表格推理能力提供了有价值的资源。

Abstract: Language models (LMs) are increasingly being deployed to perform autonomous
data analyses. However, their data awareness -- the ability to recognize,
reason over, and appropriately handle data artifacts such as missing values,
outliers, and logical inconsistencies -- remains underexplored. These artifacts
are especially common in real-world tabular data and, if mishandled, can
significantly compromise the validity of analytical conclusions. To address
this gap, we present RADAR, a benchmark for systematically evaluating
data-aware reasoning on tabular data. We develop a framework to simulate data
artifacts via programmatic perturbations to enable targeted evaluation of model
behavior. RADAR comprises 2980 table query pairs, grounded in real-world data
spanning 9 domains and 5 data artifact types. In addition to evaluating
artifact handling, RADAR systematically varies table size to study how
reasoning performance holds when increasing table size. Our evaluation reveals
that, despite decent performance on tables without data artifacts, frontier
models degrade significantly when data artifacts are introduced, exposing
critical gaps in their capacity for robust, data-aware analysis. Designed to be
flexible and extensible, RADAR supports diverse perturbation types and
controllable table sizes, offering a valuable resource for advancing tabular
reasoning.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [225] [Step-Audio-AQAA: a Fully End-to-End Expressive Large Audio Language Model](https://arxiv.org/abs/2506.08967)
*Ailin Huang,Bingxin Li,Bruce Wang,Boyong Wu,Chao Yan,Chengli Feng,Heng Wang,Hongyu Zhou,Hongyuan Wang,Jingbei Li,Jianjian Sun,Joanna Wang,Mingrui Chen,Peng Liu,Ruihang Miao,Shilei Jiang,Tian Fei,Wang You,Xi Chen,Xuerui Yang,Yechang Huang,Yuxiang Zhang,Zheng Ge,Zheng Gong,Zhewei Huang,Zixin Zhang,Bin Wang,Bo Li,Buyun Ma,Changxin Miao,Changyi Wan,Chen Xu,Dapeng Shi,Dingyuan Hu,Enle Liu,Guanzhe Huang,Gulin Yan,Hanpeng Hu,Haonan Jia,Jiahao Gong,Jiaoren Wu,Jie Wu,Jie Yang,Junzhe Lin,Kaixiang Li,Lei Xia,Longlong Gu,Ming Li,Nie Hao,Ranchen Ming,Shaoliang Pang,Siqi Liu,Song Yuan,Tiancheng Cao,Wen Li,Wenqing He,Xu Zhao,Xuelin Zhang,Yanbo Yu,Yinmin Zhong,Yu Zhou,Yuanwei Liang,Yuanwei Lu,Yuxiang Yang,Zidong Yang,Zili Zhang,Binxing Jiao,Heung-Yeung Shum,Jiansheng Chen,Jing Li,Xiangyu Zhang,Xinhao Zhang,Yibo Zhu,Daxin Jiang,Shuchang Zhou,Chen Hu*

Main category: cs.SD

TL;DR: Step-Audio-AQAA是一种端到端的大型音频语言模型，通过双码本音频分词器和1300亿参数LLM，实现了音频查询-音频回答任务的高效处理，显著提升了语音控制和语义连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有大型音频语言模型依赖文本输出，无法直接生成自然语音，限制了音频交互的流畅性。

Method: 模型采用双码本音频分词器提取特征，结合1300亿参数LLM和神经声码器，通过交错文本-音频输出和DPO优化提升性能。

Result: 在StepEval-Audio-360基准测试中，Step-Audio-AQAA在语音控制等方面优于现有最佳模型。

Conclusion: 该研究为端到端音频语言模型提供了有效解决方案，并强调了基于分词的声码器在提升性能中的关键作用。

Abstract: Large Audio-Language Models (LALMs) have significantly advanced intelligent
human-computer interaction, yet their reliance on text-based outputs limits
their ability to generate natural speech responses directly, hindering seamless
audio interactions. To address this, we introduce Step-Audio-AQAA, a fully
end-to-end LALM designed for Audio Query-Audio Answer (AQAA) tasks. The model
integrates a dual-codebook audio tokenizer for linguistic and semantic feature
extraction, a 130-billion-parameter backbone LLM and a neural vocoder for
high-fidelity speech synthesis. Our post-training approach employs interleaved
token-output of text and audio to enhance semantic coherence and combines
Direct Preference Optimization (DPO) with model merge to improve performance.
Evaluations on the StepEval-Audio-360 benchmark demonstrate that
Step-Audio-AQAA excels especially in speech control, outperforming the
state-of-art LALMs in key areas. This work contributes a promising solution for
end-to-end LALMs and highlights the critical role of token-based vocoder in
enhancing overall performance for AQAA tasks.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [226] [Instruction-Tuned Video-Audio Models Elucidate Functional Specialization in the Brain](https://arxiv.org/abs/2506.08277)
*Subba Reddy Oota,Khushbu Pahwa,Prachi Jindal,Satya Sai Srinath Namburi,Maneesh Singh,Tanmoy Chakraborty,Bapi S. Raju,Manish Gupta*

Main category: q-bio.NC

TL;DR: 研究发现，指令调优的多模态大语言模型（MLLMs）在视频和音频任务中显著优于非指令调优模型，且能更精确地预测大脑活动。


<details>
  <summary>Details</summary>
Motivation: 填补现有研究在评估MLLMs与大脑活动对齐时的空白，尤其是在多模态刺激和指令调优模型方面的不足。

Method: 使用指令调优的MLLMs生成任务特定表示，测量其对自然电影观看时记录的神经活动的预测能力。

Result: 指令调优的MLLMs在视频任务中表现优于非指令调优模型15%，优于单模态模型20%，且能分层对齐大脑区域。

Conclusion: 任务特定指令显著提升MLLMs与大脑活动的对齐，为研究大脑与模型的信息处理提供了新途径。

Abstract: Recent voxel-wise multimodal brain encoding studies have shown that
multimodal large language models (MLLMs) exhibit a higher degree of brain
alignment compared to unimodal models in both unimodal and multimodal stimulus
settings. More recently, instruction-tuned multimodal models have shown to
generate task-specific representations that align strongly with brain activity.
However, prior work evaluating the brain alignment of MLLMs has primarily
focused on unimodal settings or relied on non-instruction-tuned multimodal
models for multimodal stimuli. To address this gap, we investigated brain
alignment, that is, measuring the degree of predictivity of neural activity
recorded while participants were watching naturalistic movies (video along with
audio) with representations derived from MLLMs. We utilized
instruction-specific embeddings from six video and two audio instruction-tuned
MLLMs. Experiments with 13 video task-specific instructions show that
instruction-tuned video MLLMs significantly outperform non-instruction-tuned
multimodal (by 15%) and unimodal models (by 20%). Our evaluation of MLLMs for
both video and audio tasks using language-guided instructions shows clear
disentanglement in task-specific representations from MLLMs, leading to precise
differentiation of multimodal functional processing in the brain. We also find
that MLLM layers align hierarchically with the brain, with early sensory areas
showing strong alignment with early layers, while higher-level visual and
language regions align more with middle to late layers. These findings provide
clear evidence for the role of task-specific instructions in improving the
alignment between brain activity and MLLMs, and open new avenues for mapping
joint information processing in both the systems. We make the code publicly
available [https://github.com/subbareddy248/mllm_videos].

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [227] [SakugaFlow: A Stagewise Illustration Framework Emulating the Human Drawing Process and Providing Interactive Tutoring for Novice Drawing Skills](https://arxiv.org/abs/2506.08443)
*Kazuki Kawamura,Jun Rekimoto*

Main category: cs.HC

TL;DR: SakugaFlow是一个四阶段流程，结合扩散模型和大型语言模型，为初学者提供实时反馈，支持非线性修改和多版本分支，将黑盒生成器转化为学习工具。


<details>
  <summary>Details</summary>
Motivation: 当前AI绘图工具虽能生成高质量图像，但缺乏人类艺术家的分步过程展示，无法帮助用户学习。

Method: 采用四阶段流程，结合扩散模型和语言模型，提供实时反馈，支持非线性修改和多版本分支。

Result: 将黑盒生成器转化为支持创意探索和技能学习的教学环境。

Conclusion: SakugaFlow通过展示中间输出和嵌入教学对话，有效支持用户学习和创作。

Abstract: While current AI illustration tools can generate high-quality images from
text prompts, they rarely reveal the step-by-step procedure that human artists
follow. We present SakugaFlow, a four-stage pipeline that pairs diffusion-based
image generation with a large-language-model tutor. At each stage, novices
receive real-time feedback on anatomy, perspective, and composition, revise any
step non-linearly, and branch alternative versions. By exposing intermediate
outputs and embedding pedagogical dialogue, SakugaFlow turns a black-box
generator into a scaffolded learning environment that supports both creative
exploration and skills acquisition.

</details>


### [228] [MOSAIC-F: A Framework for Enhancing Students' Oral Presentation Skills through Personalized Feedback](https://arxiv.org/abs/2506.08634)
*Alvaro Becerra,Daniel Andres,Pablo Villegas,Roberto Daza,Ruth Cobos*

Main category: cs.HC

TL;DR: MOSAIC-F是一个多模态反馈框架，结合人类评估和多模态数据分析，为学生提供个性化反馈。


<details>
  <summary>Details</summary>
Motivation: 旨在通过整合多模态数据和人工智能，提供更准确、个性化的学习反馈。

Method: 框架包括四步：标准化评估、多模态数据收集、AI生成反馈、学生自我评估与可视化。

Result: 在提升口头表达能力的测试中，框架表现良好。

Conclusion: MOSAIC-F通过结合人类与数据评估，实现了更精准、可操作的反馈。

Abstract: In this article, we present a novel multimodal feedback framework called
MOSAIC-F, an acronym for a data-driven Framework that integrates Multimodal
Learning Analytics (MMLA), Observations, Sensors, Artificial Intelligence (AI),
and Collaborative assessments for generating personalized feedback on student
learning activities. This framework consists of four key steps. First, peers
and professors' assessments are conducted through standardized rubrics (that
include both quantitative and qualitative evaluations). Second, multimodal data
are collected during learning activities, including video recordings, audio
capture, gaze tracking, physiological signals (heart rate, motion data), and
behavioral interactions. Third, personalized feedback is generated using AI,
synthesizing human-based evaluations and data-based multimodal insights such as
posture, speech patterns, stress levels, and cognitive load, among others.
Finally, students review their own performance through video recordings and
engage in self-assessment and feedback visualization, comparing their own
evaluations with peers and professors' assessments, class averages, and
AI-generated recommendations. By combining human-based and data-based
evaluation techniques, this framework enables more accurate, personalized and
actionable feedback. We tested MOSAIC-F in the context of improving oral
presentation skills.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [229] [Normalized Radon Cumulative Distribution Transforms for Invariance and Robustness in Optimal Transport Based Image Classification](https://arxiv.org/abs/2506.08761)
*Matthias Beckmann,Robert Beinert,Jonas Bresch*

Main category: math.NA

TL;DR: 本文研究了max-normalized R-CDT在非仿射图像变形下的鲁棒性，并引入了mean-normalized R-CDT以应对更广泛的图像变形和噪声。


<details>
  <summary>Details</summary>
Motivation: 解决实际应用中图像因测量过程受到一般仿射变换影响的问题，并进一步研究R-CDT在非仿射变形下的鲁棒性。

Method: 提出max-normalized和mean-normalized R-CDT，通过控制Wasserstein距离分析其鲁棒性。

Result: 理论分析和数值实验表明，新方法在非仿射变形和脉冲噪声下仍能保持分类的线性可分性。

Conclusion: max-normalized和mean-normalized R-CDT在应对复杂图像变形和噪声时表现出色，为图像分类任务提供了有效的特征提取工具。

Abstract: The Radon cumulative distribution transform (R-CDT), is an easy-to-compute
feature extractor that facilitates image classification tasks especially in the
small data regime. It is closely related to the sliced Wasserstein distance and
provably guaranties the linear separability of image classes that emerge from
translations or scalings. In many real-world applications, like the recognition
of watermarks in filigranology, however, the data is subject to general affine
transformations originating from the measurement process. To overcome this
issue, we recently introduced the so-called max-normalized R-CDT that only
requires elementary operations and guaranties the separability under arbitrary
affine transformations. The aim of this paper is to continue our study of the
max-normalized R-CDT especially with respect to its robustness against
non-affine image deformations. Our sensitivity analysis shows that its
separability properties are stable provided the Wasserstein-infinity distance
between the samples can be controlled. Since the Wasserstein-infinity distance
only allows small local image deformations, we moreover introduce a
mean-normalized version of the R-CDT. In this case, robustness relates to the
Wasserstein-2 distance and also covers image deformations caused by impulsive
noise for instance. Our theoretical results are supported by numerical
experiments showing the effectiveness of our novel feature extractors as well
as their robustness against local non-affine deformations and impulsive noise.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [230] [A Survey on Large Language Models for Mathematical Reasoning](https://arxiv.org/abs/2506.08446)
*Peng-Yuan Wang,Tian-Shuo Liu,Chenyang Wang,Yi-Di Wang,Shu Yan,Cheng-Xing Jia,Xu-Hui Liu,Xin-Wei Chen,Jia-Cheng Xu,Ziniu Li,Yang Yu*

Main category: cs.AI

TL;DR: 该论文综述了大型语言模型（LLMs）在数学推理能力上的发展，分为理解与答案生成两个认知阶段，探讨了从训练无关提示到微调方法的多种增强技术，并指出了当前挑战与未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 数学推理是人工智能研究中的核心挑战之一，近年来LLMs在此领域取得显著进展，但仍有容量、效率和泛化等基本问题需要解决。

Method: 通过综述LLMs在数学推理中的发展，分为理解（通过多样化预训练策略）和答案生成（从直接预测到逐步推理的CoT方法），并探讨了训练无关提示、微调方法（如监督微调和强化学习）以及扩展CoT和“测试时扩展”等技术。

Result: 尽管LLMs在数学推理上取得显著进展，但仍面临容量、效率和泛化等挑战。

Conclusion: 未来研究方向包括高级预训练和知识增强技术、形式化推理框架以及通过原则性学习范式实现元泛化，为增强LLMs推理能力及应用提供指导。

Abstract: Mathematical reasoning has long represented one of the most fundamental and
challenging frontiers in artificial intelligence research. In recent years,
large language models (LLMs) have achieved significant advances in this area.
This survey examines the development of mathematical reasoning abilities in
LLMs through two high-level cognitive phases: comprehension, where models gain
mathematical understanding via diverse pretraining strategies, and answer
generation, which has progressed from direct prediction to step-by-step
Chain-of-Thought (CoT) reasoning. We review methods for enhancing mathematical
reasoning, ranging from training-free prompting to fine-tuning approaches such
as supervised fine-tuning and reinforcement learning, and discuss recent work
on extended CoT and "test-time scaling". Despite notable progress, fundamental
challenges remain in terms of capacity, efficiency, and generalization. To
address these issues, we highlight promising research directions, including
advanced pretraining and knowledge augmentation techniques, formal reasoning
frameworks, and meta-generalization through principled learning paradigms. This
survey tries to provide some insights for researchers interested in enhancing
reasoning capabilities of LLMs and for those seeking to apply these techniques
to other domains.

</details>


### [231] [Consistent Paths Lead to Truth: Self-Rewarding Reinforcement Learning for LLM Reasoning](https://arxiv.org/abs/2506.08745)
*Kongcheng Zhang,Qi Yao,Shunyu Liu,Yingjie Wang,Baisheng Lai,Jieping Ye,Mingli Song,Dacheng Tao*

Main category: cs.AI

TL;DR: 本文提出了一种自奖励强化学习框架CoVo，通过利用中间推理状态的一致性来增强大语言模型的推理能力，无需外部监督即可实现高性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习在复杂推理任务中依赖外部监督，限制了其广泛应用。本文旨在通过自奖励机制解决这一问题。

Method: 提出CoVo机制，结合一致性和波动性作为内在奖励，并通过好奇心奖励促进多样化探索。

Result: 在多种推理基准测试中，CoVo性能达到或超过有监督强化学习。

Conclusion: CoVo为无监督推理学习提供了可扩展的解决方案，展示了自奖励机制的潜力。

Abstract: Recent advances of Reinforcement Learning (RL) have highlighted its potential
in complex reasoning tasks, yet effective training often relies on external
supervision, which limits the broader applicability. In this work, we propose a
novel self-rewarding reinforcement learning framework to enhance Large Language
Model (LLM) reasoning by leveraging the consistency of intermediate reasoning
states across different reasoning trajectories. Our key insight is that correct
responses often exhibit consistent trajectory patterns in terms of model
likelihood: their intermediate reasoning states tend to converge toward their
own final answers (high consistency) with minimal deviation toward other
candidates (low volatility). Inspired by this observation, we introduce CoVo,
an intrinsic reward mechanism that integrates Consistency and Volatility via a
robust vector-space aggregation strategy, complemented by a curiosity bonus to
promote diverse exploration. CoVo enables LLMs to perform RL in a
self-rewarding manner, offering a scalable pathway for learning to reason
without external supervision. Extensive experiments on diverse reasoning
benchmarks show that CoVo achieves performance comparable to or even surpassing
supervised RL. Our code is available at https://github.com/sastpg/CoVo.

</details>


### [232] [Paths to Causality: Finding Informative Subgraphs Within Knowledge Graphs for Knowledge-Based Causal Discovery](https://arxiv.org/abs/2506.08771)
*Yuni Susanti,Michael Färber*

Main category: cs.AI

TL;DR: 论文提出了一种结合知识图谱（KGs）与大语言模型（LLMs）的新方法，用于提升基于知识的因果发现，通过优化子图选择和零样本提示，显著提高了因果推理的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统基于观测数据的因果发现方法存在局限性，而现有基于LLM的方法结果不稳定。本文旨在通过结合KGs与LLMs，提升因果推理的可靠性和一致性。

Method: 提出了一种新方法，利用KGs中的元路径子图，并通过学习排序模型优化子图选择，将排名靠前的子图融入零样本提示中，增强LLMs的因果推理能力。

Result: 在生物医学和开放领域数据集上的实验表明，该方法在F1分数上比基线方法提升高达44.4分。

Conclusion: 结合KGs与LLMs的方法显著提升了因果发现的性能，为复杂系统中的因果推理提供了更可靠的解决方案。

Abstract: Inferring causal relationships between variable pairs is crucial for
understanding multivariate interactions in complex systems. Knowledge-based
causal discovery -- which involves inferring causal relationships by reasoning
over the metadata of variables (e.g., names or textual context) -- offers a
compelling alternative to traditional methods that rely on observational data.
However, existing methods using Large Language Models (LLMs) often produce
unstable and inconsistent results, compromising their reliability for causal
inference. To address this, we introduce a novel approach that integrates
Knowledge Graphs (KGs) with LLMs to enhance knowledge-based causal discovery.
Our approach identifies informative metapath-based subgraphs within KGs and
further refines the selection of these subgraphs using Learning-to-Rank-based
models. The top-ranked subgraphs are then incorporated into zero-shot prompts,
improving the effectiveness of LLMs in inferring the causal relationship.
Extensive experiments on biomedical and open-domain datasets demonstrate that
our method outperforms most baselines by up to 44.4 points in F1 scores,
evaluated across diverse LLMs and KGs. Our code and datasets are available on
GitHub: https://github.com/susantiyuni/path-to-causality

</details>


### [233] [Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents](https://arxiv.org/abs/2506.08800)
*Irene Testini,José Hernández-Orallo,Lorenzo Pacchiardi*

Main category: cs.AI

TL;DR: 本文综述了大型语言模型（LLMs）在数据科学中作为助手和代理的评估情况，发现存在目标活动范围狭窄、人机协作层次单一以及过度关注替代人类的问题。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在数据科学中的应用现状及其评估方式，揭示当前研究的局限性。

Method: 通过文献综述，分析LLMs在数据科学中的辅助和代理功能，总结评估趋势。

Result: 发现研究集中在少数目标导向活动，忽视数据管理和探索性活动；缺乏中间层次的人机协作；过度关注人类替代而非任务转型。

Conclusion: 建议未来研究应扩展活动范围、探索多层次协作，并关注任务转型以提升自动化水平。

Abstract: Data science aims to extract insights from data to support decision-making
processes. Recently, Large Language Models (LLMs) are increasingly used as
assistants for data science, by suggesting ideas, techniques and small code
snippets, or for the interpretation of results and reporting. Proper automation
of some data-science activities is now promised by the rise of LLM agents,
i.e., AI systems powered by an LLM equipped with additional affordances--such
as code execution and knowledge bases--that can perform self-directed actions
and interact with digital environments. In this paper, we survey the evaluation
of LLM assistants and agents for data science. We find (1) a dominant focus on
a small subset of goal-oriented activities, largely ignoring data management
and exploratory activities; (2) a concentration on pure assistance or fully
autonomous agents, without considering intermediate levels of human-AI
collaboration; and (3) an emphasis on human substitution, therefore neglecting
the possibility of higher levels of automation thanks to task transformation.

</details>


### [234] [FEDTAIL: Federated Long-Tailed Domain Generalization with Sharpness-Guided Gradient Matching](https://arxiv.org/abs/2506.08518)
*Sunny Gupta,Nikita Jangid,Shounak Das,Amit Sethi*

Main category: cs.AI

TL;DR: FedTAIL是一个联邦领域泛化框架，通过锐度引导的梯度对齐优化解决长尾分布和优化冲突问题，结合梯度一致性正则化和动态加权方案，显著提升模型在未见目标域上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有领域泛化方法在长尾类分布和优化目标冲突下表现不佳，FedTAIL旨在通过锐度感知优化和动态加权解决这些问题。

Method: FedTAIL结合梯度一致性正则化、类感知锐度最小化和曲率感知动态加权，同时通过熵正则化增强条件分布对齐。

Result: 在标准领域泛化基准测试中，FedTAIL在领域偏移和标签不平衡情况下达到最先进性能。

Conclusion: FedTAIL通过优化协调、类感知正则化和条件对齐，在集中式和联邦式设置中均表现出色。

Abstract: Domain Generalization (DG) seeks to train models that perform reliably on
unseen target domains without access to target data during training. While
recent progress in smoothing the loss landscape has improved generalization,
existing methods often falter under long-tailed class distributions and
conflicting optimization objectives. We introduce FedTAIL, a federated domain
generalization framework that explicitly addresses these challenges through
sharpness-guided, gradient-aligned optimization. Our method incorporates a
gradient coherence regularizer to mitigate conflicts between classification and
adversarial objectives, leading to more stable convergence. To combat class
imbalance, we perform class-wise sharpness minimization and propose a
curvature-aware dynamic weighting scheme that adaptively emphasizes
underrepresented tail classes. Furthermore, we enhance conditional distribution
alignment by integrating sharpness-aware perturbations into entropy
regularization, improving robustness under domain shift. FedTAIL unifies
optimization harmonization, class-aware regularization, and conditional
alignment into a scalable, federated-compatible framework. Extensive
evaluations across standard domain generalization benchmarks demonstrate that
FedTAIL achieves state-of-the-art performance, particularly in the presence of
domain shifts and label imbalance, validating its effectiveness in both
centralized and federated settings. Code: https://github.com/sunnyinAI/FedTail

</details>


### [235] [VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning](https://arxiv.org/abs/2506.09049)
*Li Kang,Xiufeng Song,Heng Zhou,Yiran Qin,Jie Yang,Xiaohong Liu,Philip Torr,Lei Bai,Zhenfei Yin*

Main category: cs.AI

TL;DR: VIKI-Bench是首个为具身多智能体协作设计的层次化基准测试，包含三个层次：智能体激活、任务规划和轨迹感知。VIKI-R框架通过两阶段训练显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（VLMs）在多智能体协作中对多样化具身类型的支持有限，需要更全面的评估方法和框架。

Method: 提出VIKI-Bench基准测试和VIKI-R框架，后者结合了预训练视觉语言模型的微调和强化学习。

Result: VIKI-R在所有任务层次上显著优于基线方法，并展示了异质智能体间的组合协作模式。

Conclusion: VIKI-Bench和VIKI-R为具身AI系统中的多智能体视觉驱动协作提供了统一的测试平台和方法。

Abstract: Coordinating multiple embodied agents in dynamic environments remains a core
challenge in artificial intelligence, requiring both perception-driven
reasoning and scalable cooperation strategies. While recent works have
leveraged large language models (LLMs) for multi-agent planning, a few have
begun to explore vision-language models (VLMs) for visual reasoning. However,
these VLM-based approaches remain limited in their support for diverse
embodiment types. In this work, we introduce VIKI-Bench, the first hierarchical
benchmark tailored for embodied multi-agent cooperation, featuring three
structured levels: agent activation, task planning, and trajectory perception.
VIKI-Bench includes diverse robot embodiments, multi-view visual observations,
and structured supervision signals to evaluate reasoning grounded in visual
inputs. To demonstrate the utility of VIKI-Bench, we propose VIKI-R, a
two-stage framework that fine-tunes a pretrained vision-language model (VLM)
using Chain-of-Thought annotated demonstrations, followed by reinforcement
learning under multi-level reward signals. Our extensive experiments show that
VIKI-R significantly outperforms baselines method across all task levels.
Furthermore, we show that reinforcement learning enables the emergence of
compositional cooperation patterns among heterogeneous agents. Together,
VIKI-Bench and VIKI-R offer a unified testbed and method for advancing
multi-agent, visual-driven cooperation in embodied AI systems.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [236] [PoSyn: Secure Power Side-Channel Aware Synthesis](https://arxiv.org/abs/2506.08252)
*Amisha Srivastava,Samit S. Miftah,Hyunmin Kim,Debjit Pal,Kanad Basu*

Main category: cs.CR

TL;DR: PoSyn是一种新型逻辑合成框架，旨在增强密码硬件对功率侧信道攻击的抵抗力，通过优化映射和最小化泄漏，显著降低攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 传统防护措施（如掩码）存在集成复杂、面积开销大和易被优化移除的问题，需要更高效的方法来抵御功率侧信道攻击。

Method: 采用最优二分映射方法，将易受攻击的RTL组件映射到标准单元库中，结合成本函数优化RTL到网表的转换，同时保持设计功能不变。

Result: 实验显示，PoSyn显著降低了差分功率分析和相关功率分析的成功率（低至3%和6%），并提高了面积效率（最高3.79倍）。

Conclusion: PoSyn通过理论证明和实验验证，有效减少了功率侧信道泄漏，是一种高效且安全的防护方案。

Abstract: Power Side-Channel (PSC) attacks exploit power consumption patterns to
extract sensitive information, posing risks to cryptographic operations crucial
for secure systems. Traditional countermeasures, such as masking, face
challenges including complex integration during synthesis, substantial area
overhead, and susceptibility to optimization removal during logic synthesis. To
address these issues, we introduce PoSyn, a novel logic synthesis framework
designed to enhance cryptographic hardware resistance against PSC attacks. Our
method centers on optimal bipartite mapping of vulnerable RTL components to
standard cells from the technology library, aiming to minimize PSC leakage. By
utilizing a cost function integrating critical characteristics from both the
RTL design and the standard cell library, we strategically modify mapping
criteria during RTL-to-netlist conversion without altering design
functionality. Furthermore, we theoretically establish that PoSyn minimizes
mutual information leakage, strengthening its security against PSC
vulnerabilities. We evaluate PoSyn across various cryptographic hardware
implementations, including AES, RSA, PRESENT, and post-quantum cryptographic
algorithms such as Saber and CRYSTALS-Kyber, at technology nodes of 65nm, 45nm,
and 15nm. Experimental results demonstrate a substantial reduction in success
rates for Differential Power Analysis (DPA) and Correlation Power Analysis
(CPA) attacks, achieving lows of 3% and 6%, respectively. TVLA analysis further
confirms that synthesized netlists exhibit negligible leakage. Additionally,
compared to conventional countermeasures like masking and shuffling, PoSyn
significantly lowers attack success rates, achieving reductions of up to 72%,
while simultaneously enhancing area efficiency by as much as 3.79 times.

</details>


### [237] [GradEscape: A Gradient-Based Evader Against AI-Generated Text Detectors](https://arxiv.org/abs/2506.08188)
*Wenlong Meng,Shuguo Fan,Chengkun Wei,Min Chen,Yuwei Li,Yuanchao Zhang,Zhikun Zhang,Wenzhi Chen*

Main category: cs.CR

TL;DR: GradEscape是一种基于梯度的攻击方法，专门针对AI生成文本检测器，通过加权嵌入和模型参数更新实现高效攻击。


<details>
  <summary>Details</summary>
Motivation: 解决文本离散性导致的不可微计算问题，并适应不同语言模型架构的检测器。

Method: 使用加权嵌入构造检测器输入，结合暖启动方法和标记器推断技术。

Result: 在多个数据集和模型上表现优异，成功攻击商业检测器，参数效率高。

Conclusion: 揭示了训练数据中文本表达风格的差异是主要漏洞，并提出了防御策略。

Abstract: In this paper, we introduce GradEscape, the first gradient-based evader
designed to attack AI-generated text (AIGT) detectors. GradEscape overcomes the
undifferentiable computation problem, caused by the discrete nature of text, by
introducing a novel approach to construct weighted embeddings for the detector
input. It then updates the evader model parameters using feedback from victim
detectors, achieving high attack success with minimal text modification. To
address the issue of tokenizer mismatch between the evader and the detector, we
introduce a warm-started evader method, enabling GradEscape to adapt to
detectors across any language model architecture. Moreover, we employ novel
tokenizer inference and model extraction techniques, facilitating effective
evasion even in query-only access.
  We evaluate GradEscape on four datasets and three widely-used language
models, benchmarking it against four state-of-the-art AIGT evaders.
Experimental results demonstrate that GradEscape outperforms existing evaders
in various scenarios, including with an 11B paraphrase model, while utilizing
only 139M parameters. We have successfully applied GradEscape to two real-world
commercial AIGT detectors. Our analysis reveals that the primary vulnerability
stems from disparity in text expression styles within the training data. We
also propose a potential defense strategy to mitigate the threat of AIGT
evaders. We open-source our GradEscape for developing more robust AIGT
detectors.

</details>


<div id='q-fin.ST'></div>

# q-fin.ST [[Back]](#toc)

### [238] [EDINET-Bench: Evaluating LLMs on Complex Financial Tasks using Japanese Financial Statements](https://arxiv.org/abs/2506.08762)
*Issa Sugiura,Takashi Ishida,Taro Makino,Chieko Tazuke,Takanori Nakagawa,Kosuke Nakago,David Ha*

Main category: q-fin.ST

TL;DR: 论文介绍了EDINET-Bench，一个开源日本金融基准数据集，用于评估大语言模型在金融任务中的表现，结果显示当前模型表现不佳，需领域特定优化。


<details>
  <summary>Details</summary>
Motivation: 金融分析领域缺乏挑战性数据集，尤其是日本金融数据，阻碍了大语言模型在金融分析中的发展和评估。

Method: 通过从日本EDINET系统下载过去10年的年报，自动标注任务标签，构建EDINET-Bench数据集。

Result: 实验表明，即使是先进的大语言模型，在欺诈检测和盈利预测等任务中表现仅略优于逻辑回归。

Conclusion: 研究凸显了大语言模型在金融应用中的挑战，需领域特定优化，并公开数据集和代码以促进未来研究。

Abstract: Financial analysis presents complex challenges that could leverage large
language model (LLM) capabilities. However, the scarcity of challenging
financial datasets, particularly for Japanese financial data, impedes academic
innovation in financial analytics. As LLMs advance, this lack of accessible
research resources increasingly hinders their development and evaluation in
this specialized domain. To address this gap, we introduce EDINET-Bench, an
open-source Japanese financial benchmark designed to evaluate the performance
of LLMs on challenging financial tasks including accounting fraud detection,
earnings forecasting, and industry prediction. EDINET-Bench is constructed by
downloading annual reports from the past 10 years from Japan's Electronic
Disclosure for Investors' NETwork (EDINET) and automatically assigning labels
corresponding to each evaluation task. Our experiments reveal that even
state-of-the-art LLMs struggle, performing only slightly better than logistic
regression in binary classification for fraud detection and earnings
forecasting. These results highlight significant challenges in applying LLMs to
real-world financial applications and underscore the need for domain-specific
adaptation. Our dataset, benchmark construction code, and evaluation code is
publicly available to facilitate future research in finance with LLMs.

</details>


<div id='cs.CY'></div>

# cs.CY [[Back]](#toc)

### [239] [Surgeons Awareness, Expectations, and Involvement with Artificial Intelligence: a Survey Pre and Post the GPT Era](https://arxiv.org/abs/2506.08258)
*Lorenzo Arboit,Dennis N. Schneider,Toby Collins,Daniel A. Hashimoto,Silvana Perretta,Bernard Dallemagne,Jacques Marescaux,EAES Working Group,Nicolas Padoy,Pietro Mascagni*

Main category: cs.CY

TL;DR: 研究通过2021和2024年的全球调查，分析外科医生对AI的认知、期望及参与度变化，发现AI课程意识和参与度提升，但基础概念熟悉度仍有限，伦理问题和基础设施是主要挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在手术中的应用潜力及外科医生对其的认知变化，以促进AI在医疗领域的有效整合。

Method: 2021和2024年分别进行两次全球横断面调查，评估AI意识、期望、参与度及伦理问题。

Result: AI课程意识和参与度显著提升，但基础概念熟悉度不足；伦理问题受关注，基础设施是主要障碍；多数外科医生对AI持乐观态度。

Conclusion: 外科医生对AI的认知正在演变，需通过教育、伦理框架和基础设施发展解决知识差距和实施障碍。

Abstract: Artificial Intelligence (AI) is transforming medicine, with generative AI
models like ChatGPT reshaping perceptions of its potential. This study examines
surgeons' awareness, expectations, and involvement with AI in surgery through
comparative surveys conducted in 2021 and 2024. Two cross-sectional surveys
were distributed globally in 2021 and 2024, the first before an IRCAD webinar
and the second during the annual EAES meeting. The surveys assessed
demographics, AI awareness, expectations, involvement, and ethics (2024 only).
The surveys collected a total of 671 responses from 98 countries, 522 in 2021
and 149 in 2024. Awareness of AI courses rose from 14.5% in 2021 to 44.6% in
2024, while course attendance increased from 12.9% to 23%. Despite this,
familiarity with foundational AI concepts remained limited. Expectations for
AI's role shifted in 2024, with hospital management gaining relevance. Ethical
concerns gained prominence, with 87.2% of 2024 participants emphasizing
accountability and transparency. Infrastructure limitations remained the
primary obstacle to implementation. Interdisciplinary collaboration and
structured training were identified as critical for successful AI adoption.
Optimism about AI's transformative potential remained high, with 79.9% of
respondents believing AI would positively impact surgery and 96.6% willing to
integrate AI into their clinical practice. Surgeons' perceptions of AI are
evolving, driven by the rise of generative AI and advancements in surgical data
science. While enthusiasm for integration is strong, knowledge gaps and
infrastructural challenges persist. Addressing these through education, ethical
frameworks, and infrastructure development is essential.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [240] [PhyBlock: A Progressive Benchmark for Physical Understanding and Planning via 3D Block Assembly](https://arxiv.org/abs/2506.08708)
*Liang Ma,Jiajun Wen,Min Lin,Rongtao Xu,Xiwen Liang,Bingqian Lin,Jun Ma,Yongxin Wang,Ziming Wei,Haokun Lin,Mingfei Han,Meng Cao,Bokui Chen,Ivan Laptev,Xiaodan Liang*

Main category: cs.RO

TL;DR: PhyBlock是一个用于评估视觉语言模型（VLMs）在物理理解和规划能力上的渐进式基准测试，通过3D积木组装任务和视觉问答（VQA）任务，揭示了VLMs在高级规划和空间推理上的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在物理现象理解和结构化3D环境中的能力有限，需要一种评估工具来推动其在具身推理中的发展。

Method: PhyBench包含2600个任务（400个组装任务和2200个VQA任务），通过渐进式认知层次任务评估模型在空间推理和物理理解上的表现。

Result: 实验表明，VLMs在高级规划和空间推理上表现不佳，任务复杂度增加时性能显著下降，且链式思维提示效果有限。

Conclusion: PhyBlock为视觉语言模型在物理问题解决中的能力提供了统一测试平台，揭示了其局限性并推动未来发展。

Abstract: While vision-language models (VLMs) have demonstrated promising capabilities
in reasoning and planning for embodied agents, their ability to comprehend
physical phenomena, particularly within structured 3D environments, remains
severely limited. To close this gap, we introduce PhyBlock, a progressive
benchmark designed to assess VLMs on physical understanding and planning
through robotic 3D block assembly tasks. PhyBlock integrates a novel four-level
cognitive hierarchy assembly task alongside targeted Visual Question Answering
(VQA) samples, collectively aimed at evaluating progressive spatial reasoning
and fundamental physical comprehension, including object properties, spatial
relationships, and holistic scene understanding. PhyBlock includes 2600 block
tasks (400 assembly tasks, 2200 VQA tasks) and evaluates models across three
key dimensions: partial completion, failure diagnosis, and planning robustness.
We benchmark 21 state-of-the-art VLMs, highlighting their strengths and
limitations in physically grounded, multi-step planning. Our empirical findings
indicate that the performance of VLMs exhibits pronounced limitations in
high-level planning and reasoning capabilities, leading to a notable decline in
performance for the growing complexity of the tasks. Error analysis reveals
persistent difficulties in spatial orientation and dependency reasoning.
Surprisingly, chain-of-thought prompting offers minimal improvements,
suggesting spatial tasks heavily rely on intuitive model comprehension. We
position PhyBlock as a unified testbed to advance embodied reasoning, bridging
vision-language understanding and real-world physical problem-solving.

</details>


<div id='q-bio.BM'></div>

# q-bio.BM [[Back]](#toc)

### [241] [Aligning Proteins and Language: A Foundation Model for Protein Retrieval](https://arxiv.org/abs/2506.08023)
*Qifeng Wu,Zhengzhe Liu,Han Zhu,Yizhou Zhao,Daisuke Kihara,Min Xu*

Main category: q-bio.BM

TL;DR: 提出了一种基于CLIP框架的多模态模型，用于从大规模蛋白质数据集中检索结构和语义相似的蛋白质，以辅助功能注释。


<details>
  <summary>Details</summary>
Motivation: 近年来视觉语言模型（VLMs）的进展启发了将3D蛋白质结构与功能注释对齐的需求，以支持结构生物学中的功能解释。

Method: 采用对比学习方法，构建了一个包含约20万蛋白质-描述对的大规模数据集，并在PDB和EMDB数据集上进行了跨数据库检索评估。

Result: 模型在零样本检索任务中表现出色，展示了多模态基础模型在蛋白质结构-功能理解中的潜力。

Conclusion: 该框架为蛋白质生物学中的结构-功能关系研究提供了新工具，具有广泛应用前景。

Abstract: This paper aims to retrieve proteins with similar structures and semantics
from large-scale protein dataset, facilitating the functional interpretation of
protein structures derived by structural determination methods like
cryo-Electron Microscopy (cryo-EM). Motivated by the recent progress of
vision-language models (VLMs), we propose a CLIP-style framework for aligning
3D protein structures with functional annotations using contrastive learning.
For model training, we propose a large-scale dataset of approximately 200,000
protein-caption pairs with rich functional descriptors. We evaluate our model
in both in-domain and more challenging cross-database retrieval on Protein Data
Bank (PDB) and Electron Microscopy Data Bank (EMDB) dataset, respectively. In
both cases, our approach demonstrates promising zero-shot retrieval
performance, highlighting the potential of multimodal foundation models for
structure-function understanding in protein biology.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [242] [Hierarchical Lexical Graph for Enhanced Multi-Hop Retrieval](https://arxiv.org/abs/2506.08074)
*Abdellah Ghassel,Ian Robinson,Gabriel Tanase,Hal Cooper,Bryan Thompson,Zhen Han,Vassilis N. Ioannidis,Soji Adeshina,Huzefa Rangwala*

Main category: cs.IR

TL;DR: 论文提出了一种名为分层词汇图（HLG）的三层索引方法，结合两种检索器（StatementGraphRAG和TopicGraphRAG），显著提升了多文档检索的性能，并通过新数据集验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成（RAG）方法在处理跨文档语义分散信息时表现不佳，需要一种更高效的多文档检索方法。

Method: 提出HLG三层索引结构，结合两种检索器：StatementGraphRAG（细粒度实体搜索）和TopicGraphRAG（粗粒度主题扩展）。同时开发了合成数据集生成流程。

Result: 在五个数据集上的实验表明，该方法比传统RAG在检索召回率和正确性上平均提升23.1%。

Conclusion: HLG和配套检索器有效解决了多文档检索问题，并通过开源工具包推广使用。

Abstract: Retrieval-Augmented Generation (RAG) grounds large language models in
external evidence, yet it still falters when answers must be pieced together
across semantically distant documents. We close this gap with the Hierarchical
Lexical Graph (HLG), a three-tier index that (i) traces every atomic
proposition to its source, (ii) clusters propositions into latent topics, and
(iii) links entities and relations to expose cross-document paths. On top of
HLG we build two complementary, plug-and-play retrievers: StatementGraphRAG,
which performs fine-grained entity-aware beam search over propositions for
high-precision factoid questions, and TopicGraphRAG, which selects coarse
topics before expanding along entity links to supply broad yet relevant context
for exploratory queries. Additionally, existing benchmarks lack the complexity
required to rigorously evaluate multi-hop summarization systems, often focusing
on single-document queries or limited datasets. To address this, we introduce a
synthetic dataset generation pipeline that curates realistic, multi-document
question-answer pairs, enabling robust evaluation of multi-hop retrieval
systems. Extensive experiments across five datasets demonstrate that our
methods outperform naive chunk-based RAG achieving an average relative
improvement of 23.1% in retrieval recall and correctness. Open-source Python
library is available at https://github.com/awslabs/graphrag-toolkit.

</details>
