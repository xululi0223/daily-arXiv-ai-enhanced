<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 33]
- [cs.CV](#cs.CV) [Total: 48]
- [cs.DC](#cs.DC) [Total: 5]
- [cs.AI](#cs.AI) [Total: 5]
- [physics.app-ph](#physics.app-ph) [Total: 1]
- [cs.RO](#cs.RO) [Total: 4]
- [cs.CR](#cs.CR) [Total: 2]
- [cs.LG](#cs.LG) [Total: 11]
- [quant-ph](#quant-ph) [Total: 1]
- [cs.GR](#cs.GR) [Total: 3]
- [eess.IV](#eess.IV) [Total: 7]
- [cs.HC](#cs.HC) [Total: 1]
- [eess.SP](#eess.SP) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [CycleDistill: Bootstrapping Machine Translation using LLMs with Cyclical Distillation](https://arxiv.org/abs/2506.19952)
*Deepon Halder,Thanmay Jayakumar,Raj Dabre*

Main category: cs.CL

TL;DR: CycleDistill利用LLMs和少量示例生成合成平行语料库，通过迭代优化提升低资源语言的机器翻译质量。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言因缺乏平行语料库而难以实现高质量机器翻译的问题。

Method: 提出CycleDistill方法，通过零样本或少样本翻译生成合成平行语料库，并迭代优化模型。

Result: 在三种印度语言上，首轮迭代平均提升20-30 chrF点，翻译质量显著提高。

Conclusion: CycleDistill无需大量平行语料库即可实现高质量机器翻译，为低资源语言提供有效解决方案。

Abstract: Large language models (LLMs), despite their ability to perform few-shot
machine translation (MT), often lag behind dedicated MT systems trained on
parallel corpora, which are crucial for high quality machine translation (MT).
However, parallel corpora are often scarce or non-existent for low-resource
languages. In this paper, we propose CycleDistill, a bootstrapping approach
leveraging LLMs and few-shot translation to obtain high-quality MT systems.
CycleDistill involves iteratively generating synthetic parallel corpora from
monolingual corpora via zero- or few-shot MT, which is then used to fine-tune
the model that was used for generating said data for MT. CycleDistill does not
need parallel corpora beyond 1 to 4 few-shot examples, and in our experiments
focusing on three Indian languages, by relying solely on monolingual corpora,
it can achieve high-quality machine translation, improving upon a few-shot
baseline model by over 20-30 chrF points on average in the first iteration. We
also study the effect of leveraging softmax activations during the distillation
process and observe mild improvements in translation quality.

</details>


### [2] [Inference Scaled GraphRAG: Improving Multi Hop Question Answering on Knowledge Graphs](https://arxiv.org/abs/2506.19967)
*Travis Thompson,Seung-Hwan Lim,Paul Liu,Ruoying He,Dongkuan Xu*

Main category: cs.CL

TL;DR: 论文提出了一种名为Inference-Scaled GraphRAG的新框架，通过推理时计算扩展提升LLM在图推理任务中的表现，显著改进了多跳问答性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在知识密集型推理任务中表现不佳，主要原因是缺乏结构化上下文和多跳信息。现有的检索增强生成（RAG）方法未能充分利用知识图谱中的关系结构。

Method: 结合顺序扩展（深度链式图遍历）和并行扩展（多数投票采样轨迹），在交错推理-执行循环中实现推理时计算扩展。

Result: 在GRBench基准测试中，该方法显著优于传统GraphRAG和其他图遍历基线，提升了多跳问答性能。

Conclusion: 推理时扩展是一种实用且架构无关的解决方案，可增强LLMs在结构化知识推理中的能力。

Abstract: Large Language Models (LLMs) have achieved impressive capabilities in
language understanding and generation, yet they continue to underperform on
knowledge-intensive reasoning tasks due to limited access to structured context
and multi-hop information. Retrieval-Augmented Generation (RAG) partially
mitigates this by grounding generation in retrieved context, but conventional
RAG and GraphRAG methods often fail to capture relational structure across
nodes in knowledge graphs. We introduce Inference-Scaled GraphRAG, a novel
framework that enhances LLM-based graph reasoning by applying inference-time
compute scaling. Our method combines sequential scaling with deep
chain-of-thought graph traversal, and parallel scaling with majority voting
over sampled trajectories within an interleaved reasoning-execution loop.
Experiments on the GRBench benchmark demonstrate that our approach
significantly improves multi-hop question answering performance, achieving
substantial gains over both traditional GraphRAG and prior graph traversal
baselines. These findings suggest that inference-time scaling is a practical
and architecture-agnostic solution for structured knowledge reasoning with LLMs

</details>


### [3] [Doc2Agent: Scalable Generation of Tool-Using Agents from API Documentation](https://arxiv.org/abs/2506.19998)
*Xinyi Ni,Haonan Jian,Qiuyang Wang,Vedanshi Chetan Shah,Pengyu Hong*

Main category: cs.CL

TL;DR: Doc2Agent是一种可扩展的流程，用于从API文档生成Python工具，并通过代码代理迭代优化，显著提升了性能和成本效益。


<details>
  <summary>Details</summary>
Motivation: 现有API代理依赖统一工具集，无法应对现实世界API的复杂性，Doc2Agent旨在解决这一问题。

Method: 从API文档生成可执行工具，并通过代码代理迭代优化。

Result: 在WebArena基准测试中，性能提升55%，成本降低90%，并在特定领域任务中验证了适应性。

Conclusion: Doc2Agent为从非结构化API文档构建工具代理提供了通用解决方案。

Abstract: REST APIs play important roles in enriching the action space of web agents,
yet most API-based agents rely on curated and uniform toolsets that do not
reflect the complexity of real-world APIs. Building tool-using agents for
arbitrary domains remains a major challenge, as it requires reading
unstructured API documentation, testing APIs and inferring correct parameters.
We propose Doc2Agent, a scalable pipeline to build agents that can call
Python-based tools generated from API documentation. Doc2Agent generates
executable tools from API documentations and iteratively refines them using a
code agent. We evaluate our approach on real-world APIs, WebArena APIs, and
research APIs, producing validated tools. We achieved a 55\% relative
performance improvement with 90\% lower cost compared to direct API calling on
WebArena benchmark. A domain-specific agent built for glycomaterial science
further demonstrates the pipeline's adaptability to complex, knowledge-rich
tasks. Doc2Agent offers a generalizable solution for building tool agents from
unstructured API documentation at scale.

</details>


### [4] [A Modular Multitask Reasoning Framework Integrating Spatio-temporal Models and LLMs](https://arxiv.org/abs/2506.20073)
*Kethmi Hirushini Hettige,Jiahao Ji,Cheng Long,Shili Xiang,Gao Cong,Jingyuan Wang*

Main category: cs.CL

TL;DR: STReason是一个结合大型语言模型（LLMs）和时空模型的新框架，用于多任务推理和复杂时空数据分析，无需任务特定微调即可生成详细解释。


<details>
  <summary>Details</summary>
Motivation: 现有时空数据挖掘模型局限于单一任务，缺乏多任务推理和复杂长形式推理能力，限制了其在现实多场景决策中的应用。

Method: STReason利用上下文学习将复杂自然语言查询分解为模块化、可解释的程序，并系统执行以生成解决方案和详细解释。

Result: 实验表明，STReason在复杂时空推理任务中显著优于先进的LLM基线，并通过人类评估验证了其可信度和实用性。

Conclusion: STReason为开发更强大、通用的时空推理系统提供了有前景的方向。

Abstract: Spatio-temporal data mining plays a pivotal role in informed decision making
across diverse domains. However, existing models are often restricted to narrow
tasks, lacking the capacity for multi-task inference and complex long-form
reasoning that require generation of in-depth, explanatory outputs. These
limitations restrict their applicability to real-world, multi-faceted decision
scenarios. In this work, we introduce STReason, a novel framework that
integrates the reasoning strengths of large language models (LLMs) with the
analytical capabilities of spatio-temporal models for multi-task inference and
execution. Without requiring task-specific finetuning, STReason leverages
in-context learning to decompose complex natural language queries into modular,
interpretable programs, which are then systematically executed to generate both
solutions and detailed rationales. To facilitate rigorous evaluation, we
construct a new benchmark dataset and propose a unified evaluation framework
with metrics specifically designed for long-form spatio-temporal reasoning.
Experimental results show that STReason significantly outperforms advanced LLM
baselines across all metrics, particularly excelling in complex,
reasoning-intensive spatio-temporal scenarios. Human evaluations further
validate STReason's credibility and practical utility, demonstrating its
potential to reduce expert workload and broaden the applicability to real-world
spatio-temporal tasks. We believe STReason provides a promising direction for
developing more capable and generalizable spatio-temporal reasoning systems.

</details>


### [5] [SACL: Understanding and Combating Textual Bias in Code Retrieval with Semantic-Augmented Reranking and Localization](https://arxiv.org/abs/2506.20081)
*Dhruv Gupta,Gayathri Ganesh Lakshmy,Yiqing Xie*

Main category: cs.CL

TL;DR: 本文分析了代码检索的局限性，并提出了一种名为SACL的框架，通过增强语义信息来改进代码检索和生成。


<details>
  <summary>Details</summary>
Motivation: 当前代码检索方法过于依赖表面文本特征（如文档字符串、标识符名称），且对文档化代码存在偏见，即使文档不相关。

Method: 通过系统性地屏蔽特定特征但保留代码功能，分析代码检索的局限性，并提出SACL框架，结合语义信息增强代码或结构知识。

Result: SACL显著提升了代码检索性能（如HumanEval上Recall@1提高12.8%），并改善了代码生成效果（如HumanEval上Pass@1提高4.88%）。

Conclusion: SACL通过减少偏见和增强语义信息，有效改进了代码检索和生成性能。

Abstract: Retrieval-Augmented Code Generation (RACG) is a critical technique for
enhancing code generation by retrieving relevant information. In this work, we
conduct an in-depth analysis of code retrieval by systematically masking
specific features while preserving code functionality. Our discoveries include:
(1) although trained on code, current retrievers heavily rely on surface-level
textual features (e.g., docstrings, identifier names), and (2) they exhibit a
strong bias towards well-documented code, even if the documentation is
irrelevant.Based on our discoveries, we propose SACL, a framework that enriches
textual information and reduces bias by augmenting code or structural knowledge
with semantic information. Extensive experiments show that SACL substantially
improves code retrieval (e.g., by 12.8% / 9.4% / 7.0% Recall@1 on HumanEval /
MBPP / SWE-Bench-Lite), which also leads to better code generation performance
(e.g., by 4.88% Pass@1 on HumanEval).

</details>


### [6] [Bridging Compositional and Distributional Semantics: A Survey on Latent Semantic Geometry via AutoEncoder](https://arxiv.org/abs/2506.20083)
*Yingji Zhang,Danilo S. Carvalho,André Freitas*

Main category: cs.CL

TL;DR: 该论文探讨了如何通过组合和符号属性增强Transformer自回归语言模型的语义空间，提出了语义表示学习的新视角，并比较了三种自编码器架构的潜在几何特性。


<details>
  <summary>Details</summary>
Motivation: 提升语言模型的解释性、可控性、组合性和泛化能力，弥合符号语义与分布语义之间的鸿沟。

Method: 综述并比较了三种自编码器架构（VAE、VQVAE、SAE）及其在语义结构和解释性方面的潜在几何特性。

Result: 提出了语义表示学习的新方向，为符号与分布语义的融合提供了桥梁。

Conclusion: 组合和符号属性的集成能显著提升语言模型的性能，未来研究可进一步探索其应用潜力。

Abstract: Integrating compositional and symbolic properties into current distributional
semantic spaces can enhance the interpretability, controllability,
compositionality, and generalisation capabilities of Transformer-based
auto-regressive language models (LMs). In this survey, we offer a novel
perspective on latent space geometry through the lens of compositional
semantics, a direction we refer to as \textit{semantic representation
learning}. This direction enables a bridge between symbolic and distributional
semantics, helping to mitigate the gap between them. We review and compare
three mainstream autoencoder architectures-Variational AutoEncoder (VAE),
Vector Quantised VAE (VQVAE), and Sparse AutoEncoder (SAE)-and examine the
distinctive latent geometries they induce in relation to semantic structure and
interpretability.

</details>


### [7] [ITFormer: Bridging Time Series and Natural Language for Multi-Modal QA with Large-Scale Multitask Dataset](https://arxiv.org/abs/2506.20093)
*Yilin Wang,Peixuan Lei,Jie Song,Yuzhe Hao,Tao Chen,Yuxuan Zhang,Lei Jia,Yuanxiang Li,Zhongyu Wei*

Main category: cs.CL

TL;DR: 论文提出了一种新的时间序列问答任务（Time-Series QA），并发布了首个大规模多任务数据集EngineMT-QA。同时，提出了Instruct Time Transformer（ITFormer）框架，通过结合时间序列编码器和冻结的大型语言模型（LLMs），显著提升了问答准确性。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据在工业监测、医疗诊断和气候研究等领域至关重要，但如何高效地将高维时间信号与自然语言结合以完成动态交互任务仍是一个挑战。

Method: 提出了ITFormer框架，通过提取、对齐和融合时间与文本特征，结合时间序列编码器和冻结的LLMs，实现了高效的跨模态建模。

Result: ITFormer在问答准确性上显著优于基线模型，且仅增加了不到1%的可训练参数。

Conclusion: 该研究为时间数据与自然语言的结合提供了灵活范式，推动了多模态AI的新研究和应用。

Abstract: Time-series data are critical in diverse applications, such as industrial
monitoring, medical diagnostics, and climate research. However, effectively
integrating these high-dimensional temporal signals with natural language for
dynamic, interactive tasks remains a significant challenge. To address this, we
introduce the Time-Series Question Answering (Time-Series QA) task and release
EngineMT-QA, the first large-scale, multi-task, temporal-textual QA dataset
designed to capture complex interactions between time-series signals and
natural language. Building on this resource, we propose the Instruct Time
Transformer (ITFormer), a novel framework that bridges time-series encoders
with frozen large language models (LLMs). ITFormer effectively extracts,
aligns, and fuses temporal and textual features, achieving a strong improvement
in QA accuracy over strong baselines with fewer than 1\% additional trainable
parameters. By combining computational efficiency with robust cross-modal
modeling, our work establishes a adaptable paradigm for integrating temporal
data with natural language, paving the way for new research and applications in
multi-modal AI. More details about the project, including datasets and code,
are available at: https://pandalin98.github.io/itformer_site/

</details>


### [8] [A Multi-Pass Large Language Model Framework for Precise and Efficient Radiology Report Error Detection](https://arxiv.org/abs/2506.20112)
*Songsoo Kim,Seungtae Lee,See Young Lee,Joonho Kim,Keechan Kan,Dukyong Yoon*

Main category: cs.CL

TL;DR: 研究提出了一种三阶段LLM框架，显著提高了放射学报告的正预测值（PPV）并降低了操作成本。


<details>
  <summary>Details</summary>
Motivation: 由于错误率低，基于LLM的放射学报告校对的正预测值有限，研究旨在通过三阶段框架提升PPV并降低成本。

Method: 研究回顾性分析了1000份放射学报告，测试了三种LLM框架，并测量了PPV和操作成本。

Result: 三阶段框架显著提升PPV至0.159（P<0.001），操作成本降低42.6%，同时保持检测性能。

Conclusion: 三阶段LLM框架为AI辅助放射学报告质量保证提供了有效策略。

Abstract: Background: The positive predictive value (PPV) of large language model
(LLM)-based proofreading for radiology reports is limited due to the low error
prevalence. Purpose: To assess whether a three-pass LLM framework enhances PPV
and reduces operational costs compared with baseline approaches. Materials and
Methods: A retrospective analysis was performed on 1,000 consecutive radiology
reports (250 each: radiography, ultrasonography, CT, MRI) from the MIMIC-III
database. Two external datasets (CheXpert and Open-i) were validation sets.
Three LLM frameworks were tested: (1) single-prompt detector; (2) extractor
plus detector; and (3) extractor, detector, and false-positive verifier.
Precision was measured by PPV and absolute true positive rate (aTPR).
Efficiency was calculated from model inference charges and reviewer
remuneration. Statistical significance was tested using cluster bootstrap,
exact McNemar tests, and Holm-Bonferroni correction. Results: Framework PPV
increased from 0.063 (95% CI, 0.036-0.101, Framework 1) to 0.079 (0.049-0.118,
Framework 2), and significantly to 0.159 (0.090-0.252, Framework 3; P<.001 vs.
baselines). aTPR remained stable (0.012-0.014; P>=.84). Operational costs per
1,000 reports dropped to USD 5.58 (Framework 3) from USD 9.72 (Framework 1) and
USD 6.85 (Framework 2), reflecting reductions of 42.6% and 18.5%, respectively.
Human-reviewed reports decreased from 192 to 88. External validation supported
Framework 3's superior PPV (CheXpert 0.133, Open-i 0.105) and stable aTPR
(0.007). Conclusion: A three-pass LLM framework significantly enhanced PPV and
reduced operational costs, maintaining detection performance, providing an
effective strategy for AI-assisted radiology report quality assurance.

</details>


### [9] [Leveraging AI Graders for Missing Score Imputation to Achieve Accurate Ability Estimation in Constructed-Response Tests](https://arxiv.org/abs/2506.20119)
*Masaki Uto,Yuma Ito*

Main category: cs.CL

TL;DR: 论文提出了一种利用自动评分技术填补缺失分数的新方法，以提高IRT能力估计的准确性，同时显著减少人工评分工作量。


<details>
  <summary>Details</summary>
Motivation: 评估学习者的能力是教育领域的基本目标，尤其是对高阶能力的评估需求日益增长。虽然构建性反应测试有效，但人工评分成本高且耗时。IRT虽能从不完整数据估计能力，但随着缺失分数比例增加，准确性下降。现有数据增强技术对稀疏或异构数据效果不佳。

Method: 研究提出了一种新方法，利用自动评分技术填补缺失分数，以支持IRT能力估计。

Result: 该方法在能力估计中实现了高准确性，并显著减少了人工评分的工作量。

Conclusion: 该方法为高效、准确地评估学习者能力提供了可行解决方案。

Abstract: Evaluating the abilities of learners is a fundamental objective in the field
of education. In particular, there is an increasing need to assess higher-order
abilities such as expressive skills and logical thinking. Constructed-response
tests such as short-answer and essay-based questions have become widely used as
a method to meet this demand. Although these tests are effective, they require
substantial manual grading, making them both labor-intensive and costly. Item
response theory (IRT) provides a promising solution by enabling the estimation
of ability from incomplete score data, where human raters grade only a subset
of answers provided by learners across multiple test items. However, the
accuracy of ability estimation declines as the proportion of missing scores
increases. Although data augmentation techniques for imputing missing scores
have been explored in order to address this limitation, they often struggle
with inaccuracy for sparse or heterogeneous data. To overcome these challenges,
this study proposes a novel method for imputing missing scores by leveraging
automated scoring technologies for accurate IRT-based ability estimation. The
proposed method achieves high accuracy in ability estimation while markedly
reducing manual grading workload.

</details>


### [10] [CCRS: A Zero-Shot LLM-as-a-Judge Framework for Comprehensive RAG Evaluation](https://arxiv.org/abs/2506.20128)
*Aashiq Muhamed*

Main category: cs.CL

TL;DR: 论文提出了一种名为CCRS的新评估框架，用于衡量RAG系统的多方面质量，包括上下文连贯性、问题相关性、信息密度、答案正确性和信息召回。该方法使用单一预训练LLM作为零样本端到端评估器，显著提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统评估方法存在不足，如依赖简单词汇重叠指标或复杂多阶段流程，无法全面捕捉输出质量的多维度特性。

Method: 提出CCRS，包含五个指标（CC、QR、ID、AC、IR），利用单一预训练LLM进行零样本端到端评估。在BioASQ数据集上测试六种RAG配置。

Result: CCRS能有效区分系统性能，例如Mistral-7B优于Llama变体。与RAGChecker相比，CCRS在关键指标上表现相当或更优，且计算效率更高。

Conclusion: CCRS为RAG系统提供了一种实用、全面且高效的评估框架，支持迭代改进。

Abstract: RAG systems enhance LLMs by incorporating external knowledge, which is
crucial for domains that demand factual accuracy and up-to-date information.
However, evaluating the multifaceted quality of RAG outputs, spanning aspects
such as contextual coherence, query relevance, factual correctness, and
informational completeness, poses significant challenges. Existing evaluation
methods often rely on simple lexical overlap metrics, which are inadequate for
capturing these nuances, or involve complex multi-stage pipelines with
intermediate steps like claim extraction or require finetuning specialized
judge models, hindering practical efficiency. To address these limitations, we
propose CCRS (Contextual Coherence and Relevance Score), a novel suite of five
metrics that utilizes a single, powerful, pretrained LLM as a zero-shot,
end-to-end judge. CCRS evaluates: Contextual Coherence (CC), Question Relevance
(QR), Information Density (ID), Answer Correctness (AC), and Information Recall
(IR). We apply CCRS to evaluate six diverse RAG system configurations on the
challenging BioASQ dataset. Our analysis demonstrates that CCRS effectively
discriminates between system performances, confirming, for instance, that the
Mistral-7B reader outperforms Llama variants. We provide a detailed analysis of
CCRS metric properties, including score distributions, convergent/discriminant
validity, tie rates, population statistics, and discriminative power. Compared
to the complex RAGChecker framework, CCRS offers comparable or superior
discriminative power for key aspects like recall and faithfulness, while being
significantly more computationally efficient. CCRS thus provides a practical,
comprehensive, and efficient framework for evaluating and iteratively improving
RAG systems.

</details>


### [11] [AALC: Large Language Model Efficient Reasoning via Adaptive Accuracy-Length Control](https://arxiv.org/abs/2506.20160)
*Ruosen Li,Ziming Luo,Quan Zhang,Ruochen Li,Ben Zhou,Ali Payani,Xinya Du*

Main category: cs.CL

TL;DR: AALC是一种轻量级的、准确性感知的长度奖励方法，通过动态平衡正确性和简洁性，显著减少了推理模型的响应长度，同时保持或提升准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）通过生成冗长的思维链获得强大的推理能力，但这种“过度思考”导致高延迟和成本，而准确性提升有限。

Method: AALC将验证准确性整合到奖励中，并采用动态调度的长度惩罚，延迟长度惩罚直到达到目标性能。

Result: 实验表明，AALC将响应长度减少50%以上，同时保持或提升准确性，并减少冗余推理模式。

Conclusion: AALC展示了通过奖励策略引导LRMs实现更高效、通用推理路径的潜力，但可能牺牲部分可解释性。

Abstract: Large reasoning models (LRMs) achieve impressive reasoning capabilities by
generating lengthy chain-of-thoughts, but this "overthinking" incurs high
latency and cost without commensurate accuracy gains. In this work, we
introduce AALC, a lightweight, accuracy-aware length reward integrated into
reinforcement learning that dynamically balances correctness and brevity during
training. By incorporating validation accuracy into the reward and employing a
smooth, dynamically scheduled length penalty, AALC delays length penalty until
target performance is met. Through extensive experiments across standard and
out-of-distribution math benchmarks, we show that our approach reduces response
length by over 50% while maintaining or even improving the original accuracy.
Furthermore, qualitative analysis reveals that our method curbs redundant
reasoning patterns such as excessive subgoal setting and verification, leading
to structurally refined outputs rather than naive truncation. We also identify
that efficiency gains are accompanied by reduced interpretability: models
trained with AALC omit some narrative framing and explanatory context. These
findings highlight the potential of reward-based strategies to guide LRMs
toward more efficient, generalizable reasoning paths.

</details>


### [12] [SEED: A Structural Encoder for Embedding-Driven Decoding in Time Series Prediction with LLMs](https://arxiv.org/abs/2506.20167)
*Fengze Li,Yue Wang,Yangle Liu,Ming Huang,Dou Hong,Jieming Ma*

Main category: cs.CL

TL;DR: SEED模型通过结合结构编码器和语言模型，填补了时间序列预测中结构与语义建模的空白。


<details>
  <summary>Details</summary>
Motivation: 现有结构编码器缺乏语义推理能力，而语言模型无法直接处理时间序列数据，限制了统一预测系统的发展。

Method: SEED采用四阶段架构：令牌感知编码器、投影模块、语义重编程机制和冻结语言模型，实现数值模式与语义推理的对齐。

Result: 实验表明SEED在多个数据集上优于基线模型，验证了其在结构-语义建模中的有效性。

Conclusion: SEED为统一、可迁移的时间序列预测系统提供了有效解决方案。

Abstract: Multivariate time series forecasting requires models to simultaneously
capture variable-wise structural dependencies and generalize across diverse
tasks. While structural encoders are effective in modeling feature
interactions, they lack the capacity to support semantic-level reasoning or
task adaptation. Conversely, large language models (LLMs) possess strong
generalization capabilities but remain incompatible with raw time series
inputs. This gap limits the development of unified, transferable prediction
systems. Therefore, we introduce SEED, a structural encoder for
embedding-driven decoding, which integrates four stages: a token-aware encoder
for patch extraction, a projection module that aligns patches with language
model embeddings, a semantic reprogramming mechanism that maps patches to
task-aware prototypes, and a frozen language model for prediction. This modular
architecture decouples representation learning from inference, enabling
efficient alignment between numerical patterns and semantic reasoning.
Empirical results demonstrate that the proposed method achieves consistent
improvements over strong baselines, and comparative studies on various datasets
confirm SEED's role in addressing the structural-semantic modeling gap.

</details>


### [13] [COIN: Uncertainty-Guarding Selective Question Answering for Foundation Models with Provable Risk Guarantees](https://arxiv.org/abs/2506.20178)
*Zhiyuan Wang,Jinhao Duan,Qingni Wang,Xiaofeng Zhu,Tianlong Chen,Xiaoshuang Shi,Kaidi Xu*

Main category: cs.CL

TL;DR: COIN是一个不确定性保护选择框架，通过统计校准阈值在用户指定的FDR约束下筛选单个生成答案，显著提高样本保留率。


<details>
  <summary>Details</summary>
Motivation: 基础模型的不确定性量化（UQ）对识别和减少自动生成文本中的幻觉至关重要，但现有启发式方法缺乏对选择性预测中关键指标（如FDR）的正式保证。

Method: COIN利用校准集估计经验错误率，并应用Clopper-Pearson等置信区间方法建立真实错误率的高概率上界，从而在测试数据上实现FDR控制。

Result: COIN在风险控制、保留可接受答案的测试时间能力以及有限校准数据下的预测效率方面表现出色，适用于通用和多模态文本生成任务。

Conclusion: COIN框架具有扩展性和适应性，可通过替代上界构建和UQ策略进一步提升性能，适用于多样化应用场景。

Abstract: Uncertainty quantification (UQ) for foundation models is essential to
identify and mitigate potential hallucinations in automatically generated text.
However, heuristic UQ approaches lack formal guarantees for key metrics such as
the false discovery rate (FDR) in selective prediction. Previous work adopts
the split conformal prediction (SCP) framework to ensure desired coverage of
admissible answers by constructing prediction sets, but these sets often
contain incorrect candidates, limiting their practical utility. To address
this, we propose COIN, an uncertainty-guarding selection framework that
calibrates statistically valid thresholds to filter a single generated answer
per question under user-specified FDR constraints. COIN estimates the empirical
error rate on a calibration set and applies confidence interval methods such as
Clopper-Pearson to establish a high-probability upper bound on the true error
rate (i.e., FDR). This enables the selection of the largest uncertainty
threshold that ensures FDR control on test data while significantly increasing
sample retention. We demonstrate COIN's robustness in risk control, strong
test-time power in retaining admissible answers, and predictive efficiency
under limited calibration data across both general and multimodal text
generation tasks. Furthermore, we show that employing alternative upper bound
constructions and UQ strategies can further boost COIN's power performance,
which underscores its extensibility and adaptability to diverse application
scenarios.

</details>


### [14] [How to Retrieve Examples in In-context Learning to Improve Conversational Emotion Recognition using Large Language Models?](https://arxiv.org/abs/2506.20199)
*Mengqi Wang,Tiantian Feng,Shrikanth Narayanan*

Main category: cs.CL

TL;DR: 研究探讨如何通过检索高质量示例提升LLM在对话情感识别（CER）中的表现，发现增强示例检索方法效果最佳。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在多个领域应用广泛，但在主观任务（如情感识别）中实现高精度仍具挑战性。

Method: 提出基于随机和增强示例检索的策略，并分析对话上下文对CER准确性的影响。

Result: 在IEMOCAP、MELD和EmoryNLP数据集上，增强示例检索方法表现优于其他技术。

Conclusion: 检索具有一致性的目标示例并通过改写增强，对提升CER准确性至关重要。

Abstract: Large language models (LLMs) have enabled a wide variety of real-world
applications in various domains. However, creating a high-performing
application with high accuracy remains challenging, particularly for subjective
tasks like emotion recognition. Inspired by the SLT 2024 GenSER Challenge, this
study investigates approaches to improving conversational emotion recognition
(CER) by LLMs. Specifically, we explore how to retrieve high-quality examples
in in-context learning (ICL) to enhance CER. We propose various strategies
based on random and augmented example retrieval and also analyze the impact of
conversational context on CER accuracy. Experiments were conducted on the three
datasets including IEMOCAP, MELD and EmoryNLP. The results show that augmented
example retrieval consistently outperforms other techniques under investigation
across all datasets, highlighting the importance of retrieving coherent
targeted examples and enhancing them through paraphrasing.

</details>


### [15] [Intrinsic vs. Extrinsic Evaluation of Czech Sentence Embeddings: Semantic Relevance Doesn't Help with MT Evaluation](https://arxiv.org/abs/2506.20203)
*Petra Barančíková,Ondřej Bojar*

Main category: cs.CL

TL;DR: 比较捷克语特定和多语言句子嵌入模型，发现内在语义相似性测试表现好的模型在下游翻译任务中未必表现最佳，反之亦然。


<details>
  <summary>Details</summary>
Motivation: 探讨句子嵌入模型在内在语义相似性和下游翻译任务中的表现差异，揭示语义属性与任务性能的复杂关系。

Method: 使用Costra数据集和STS基准进行内在评估，通过COMET指标进行外在翻译评估。

Result: 内在测试表现好的模型在下游任务中未必最优，某些嵌入空间平滑的模型通过微调反而表现更好。

Conclusion: 需进一步研究句子嵌入的'可操作语义'或更深入的下游任务数据集。

Abstract: In this paper, we compare Czech-specific and multilingual sentence embedding
models through intrinsic and extrinsic evaluation paradigms. For intrinsic
evaluation, we employ Costra, a complex sentence transformation dataset, and
several Semantic Textual Similarity (STS) benchmarks to assess the ability of
the embeddings to capture linguistic phenomena such as semantic similarity,
temporal aspects, and stylistic variations. In the extrinsic evaluation, we
fine-tune each embedding model using COMET-based metrics for machine
translation evaluation.
  Our experiments reveal an interesting disconnect: models that excel in
intrinsic semantic similarity tests do not consistently yield superior
performance on downstream translation evaluation tasks. Conversely, models with
seemingly over-smoothed embedding spaces can, through fine-tuning, achieve
excellent results. These findings highlight the complex relationship between
semantic property probes and downstream task, emphasizing the need for more
research into 'operationalizable semantics' in sentence embeddings, or more
in-depth downstream tasks datasets (here translation evaluation)

</details>


### [16] [Perspectives in Play: A Multi-Perspective Approach for More Inclusive NLP Systems](https://arxiv.org/abs/2506.20209)
*Benedetta Muscato,Lucia Passaro,Gizem Gezici,Fosca Giannotti*

Main category: cs.CL

TL;DR: 论文提出了一种多视角的软标签方法，用于处理NLP中的人类标注分歧，强调包容性和多样性，并在多个主观文本分类任务中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过聚合标注者观点生成单一标准答案，但忽略了少数观点，尤其在主观任务中。本研究旨在通过多视角方法更好地反映人类分歧。

Method: 提出使用软标签的多视角方法，并在多个主观文本分类任务（如仇恨言论、讽刺、辱骂语言和立场检测）中进行实验。

Result: 多视角方法在Jensen-Shannon Divergence（JSD）和F1分数上优于传统方法，但在讽刺和立场检测任务中表现出较低的置信度。

Conclusion: 多视角方法能更好地捕捉人类分歧，提升模型性能，但需进一步解决主观性任务中的置信度问题。

Abstract: In the realm of Natural Language Processing (NLP), common approaches for
handling human disagreement consist of aggregating annotators' viewpoints to
establish a single ground truth. However, prior studies show that disregarding
individual opinions can lead can lead to the side effect of underrepresenting
minority perspectives, especially in subjective tasks, where annotators may
systematically disagree because of their preferences. Recognizing that labels
reflect the diverse backgrounds, life experiences, and values of individuals,
this study proposes a new multi-perspective approach using soft labels to
encourage the development of the next generation of perspective aware models,
more inclusive and pluralistic. We conduct an extensive analysis across diverse
subjective text classification tasks, including hate speech, irony, abusive
language, and stance detection, to highlight the importance of capturing human
disagreements, often overlooked by traditional aggregation methods. Results
show that the multi-perspective approach not only better approximates human
label distributions, as measured by Jensen-Shannon Divergence (JSD), but also
achieves superior classification performance (higher F1 scores), outperforming
traditional approaches. However, our approach exhibits lower confidence in
tasks like irony and stance detection, likely due to the inherent subjectivity
present in the texts. Lastly, leveraging Explainable AI (XAI), we explore model
uncertainty and uncover meaningful insights into model predictions.

</details>


### [17] [Enhancing Large Language Models through Structured Reasoning](https://arxiv.org/abs/2506.20241)
*Yubo Dong,Hehe Fan*

Main category: cs.CL

TL;DR: 论文提出了一种通过结构化推理增强大语言模型（LLMs）的新方法，结合监督微调（SFT）和GRPO算法，显著提升了模型的逻辑推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在复杂逻辑推理任务中表现不佳，主要依赖统计关系而非结构化知识表示。

Method: 将非结构化数据转换为结构化格式，通过SFT训练LLMs，并利用GRPO算法（包括MAX-Flow和LCS）增强推理能力。

Result: 实验表明，该方法在DeepSeek-R1-Distill-Qwen-1.5B模型上实现了简洁推理、鲁棒性能和优化兼容性。

Conclusion: 结构化推理的引入显著提升了LLMs的推理能力，验证了方法的有效性。

Abstract: Recent Large Language Models (LLMs) have significantly advanced natural
language processing and automated decision-making. However, these models still
encounter difficulties when performing complex reasoning tasks involving
logical deduction and systematic planning, primarily due to their reliance on
implicit statistical relationships without structured knowledge
representation.Inspired by cognitive science and neurosymbolic AI, we introduce
a novel approach to enhance LLMs through explicit structured reasoning. First,
we convert unstructured data into structured formats by explicitly annotating
reasoning steps. We then employ this structured dataset to train LLMs through
Supervised Fine-Tuning (SFT). Additionally, we enhance the structured reasoning
capabilities of LLMs using Group Relative Policy Optimization (GRPO),
incorporating two innovative algorithms--MAX-Flow and Longest Common
Subsequence (LCS)--which notably improve reasoning effectiveness and reduce
computational complexity. Experimental results from fine-tuning a
DeepSeek-R1-Distill-Qwen-1.5B model demonstrate concise reasoning, robust
performance across various scenarios, and improved compatibility with
optimization techniques, validating the efficacy of structured reasoning
integration in LLMs.

</details>


### [18] [CBF-AFA: Chunk-Based Multi-SSL Fusion for Automatic Fluency Assessment](https://arxiv.org/abs/2506.20243)
*Papa Séga Wade,Mihai Andries,Ioannis Kanellos,Thierry Moudenc*

Main category: cs.CL

TL;DR: 提出了一种基于分块的自监督学习（SSL）融合方法，结合CNN-BiLSTM框架，用于非母语者的流利度评估，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 自动流利度评估（AFA）在捕捉非母语者的语音节奏、停顿和不流畅性方面仍具挑战性。

Method: 使用多种SSL模型（Wav2Vec2、HuBERT、WavLM）的互补优势，结合CNN-BiLSTM框架，通过Silero-VAD分块处理语音，融合声学和语言特征。

Result: 在Avalinguo和Speechocean762数据集上，F1分数和Pearson相关系数分别提升了2.8-4.2和6.2-4.0点，优于基线方法。

Conclusion: 分块多SSL融合方法对流利度评估有效，但未来需研究其在非规则韵律方言中的泛化能力。

Abstract: Automatic fluency assessment (AFA) remains challenging, particularly in
capturing speech rhythm, pauses, and disfluencies in non-native speakers. We
introduce a chunk-based approach integrating self-supervised learning (SSL)
models (Wav2Vec2, HuBERT, and WavLM) selected for their complementary strengths
in phonetic, prosodic, and noisy speech modeling, with a hierarchical
CNN-BiLSTM framework. Speech is segmented into breath-group chunks using Silero
voice activity detection (Silero-VAD), enabling fine-grained temporal analysis
while mitigating over-segmentation artifacts. SSL embeddings are fused via a
learnable weighted mechanism, balancing acoustic and linguistic features, and
enriched with chunk-level fluency markers (e.g., speech rate, pause durations,
n-gram repetitions). The CNN-BiLSTM captures local and long-term dependencies
across chunks. Evaluated on Avalinguo and Speechocean762, our approach improves
F1-score by 2.8 and Pearson correlation by 6.2 points over single SSL baselines
on Speechocean762, with gains of 4.2 F1-score and 4.0 Pearson points on
Avalinguo, surpassing Pyannote.audio-based segmentation baselines. These
findings highlight chunk-based multi-SSL fusion for robust fluency evaluation,
though future work should explore generalization to dialects with irregular
prosody.

</details>


### [19] [Narrative Shift Detection: A Hybrid Approach of Dynamic Topic Models and Large Language Models](https://arxiv.org/abs/2506.20269)
*Kai-Robin Lange,Tobias Schmidt,Matthias Reccius,Henrik Müller,Michael Roos,Carsten Jentsch*

Main category: cs.CL

TL;DR: 结合大型语言模型和主题模型动态追踪叙事变化，提出一种高效检测叙事和内容变化的方法。


<details>
  <summary>Details</summary>
Motivation: 随着媒体叙事的快速演变，需要动态追踪叙事变化，而现有方法成本高或难以大规模应用。

Method: 结合主题模型和变化点检测方法筛选代表性文档，再用大型语言模型自动分析叙事和内容变化。

Result: 大型语言模型能高效检测叙事变化，但在区分内容和叙事变化时表现不佳。

Conclusion: 提出的方法能有效追踪叙事变化，但需改进对内容和叙事变化的区分能力。

Abstract: With rapidly evolving media narratives, it has become increasingly critical
to not just extract narratives from a given corpus but rather investigate, how
they develop over time. While popular narrative extraction methods such as
Large Language Models do well in capturing typical narrative elements or even
the complex structure of a narrative, applying them to an entire corpus comes
with obstacles, such as a high financial or computational cost. We propose a
combination of the language understanding capabilities of Large Language Models
with the large scale applicability of topic models to dynamically model
narrative shifts across time using the Narrative Policy Framework. We apply a
topic model and a corresponding change point detection method to find changes
that concern a specific topic of interest. Using this model, we filter our
corpus for documents that are particularly representative of that change and
feed them into a Large Language Model that interprets the change that happened
in an automated fashion and distinguishes between content and narrative shifts.
We employ our pipeline on a corpus of The Wall Street Journal news paper
articles from 2009 to 2023. Our findings indicate that a Large Language Model
can efficiently extract a narrative shift if one exists at a given point in
time, but does not perform as well when having to decide whether a shift in
content or a narrative shift took place.

</details>


### [20] [Biomed-Enriched: A Biomedical Dataset Enriched with LLMs for Pretraining and Extracting Rare and Hidden Content](https://arxiv.org/abs/2506.20331)
*Rian Touchent,Nathan Godey,Eric de la Clergerie*

Main category: cs.CL

TL;DR: Biomed-Enriched是一个通过两阶段标注过程从PubMed构建的生物医学文本数据集，包含临床案例等高质量段落，为生物医学NLP提供资源。初步实验显示其能提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 临床文本通常因隐私限制难以获取，Biomed-Enriched提供了公开的大规模临床案例数据集，填补了这一空白。

Method: 通过大语言模型标注PubMed段落的类型、领域和教育质量，再用小模型扩展标注至整个PMC-OA语料库，构建高质量子集。

Result: 数据集包含450K高质量临床案例段落，实验显示临床上采样和教育质量过滤能分别提升模型性能5%和1%。

Conclusion: Biomed-Enriched为生物医学NLP提供了高效资源，其方法能优化预训练策略，提升模型性能和效率。

Abstract: We introduce Biomed-Enriched, a biomedical text dataset constructed from
PubMed via a two-stage annotation process. In the first stage, a large language
model annotates 400K paragraphs from PubMed scientific articles, assigning
scores for their type (review, study, clinical case, other), domain (clinical,
biomedical, other), and educational quality. The educational quality score
(rated 1 to 5) estimates how useful a paragraph is for college-level learning.
These annotations are then used to fine-tune a small language model, which
propagates the labels across the full PMC-OA corpus. The resulting metadata
allows us to extract refined subsets, including 2M clinical case paragraphs
with over 450K high-quality ones from articles with commercial-use licenses,
and to construct several variants via quality filtering and domain upsampling.
Clinical text is typically difficult to access due to privacy constraints, as
hospital records cannot be publicly shared. Hence, our dataset provides an
alternative large-scale, openly available collection of clinical cases from
PubMed, making it a valuable resource for biomedical and clinical NLP.
Preliminary continual-pretraining experiments with OLMo2 suggest these curated
subsets enable targeted improvements, with clinical upsampling boosting
performance by ~5% on MMLU ProfMed and educational quality filtering improving
MedQA and MedMCQA by ~1%. Combinations of these techniques led to faster
convergence, reaching same performance with a third of training tokens,
indicating potential for more efficient and effective biomedical pretraining
strategies.

</details>


### [21] [TAPS: Tool-Augmented Personalisation via Structured Tagging](https://arxiv.org/abs/2506.20409)
*Ekaterina Taktasheva,Jeff Dalton*

Main category: cs.CL

TL;DR: 论文提出了一种新方法TAPS，通过结构化标签工具和不确定性检测器，提升大型语言模型在个性化工具使用中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了用户偏好在工具使用中的作用，研究旨在填补这一空白。

Method: 引入TAPS，结合结构化标签工具和不确定性检测器，优化个性化工具使用。

Result: TAPS显著提升了模型在NLSI任务中的表现，达到开源模型的新最佳水平。

Conclusion: TAPS为个性化工具使用提供了有效解决方案，推动了相关领域的发展。

Abstract: Recent advancements in tool-augmented large language models have enabled them
to interact with external tools, enhancing their ability to perform complex
user tasks. However, existing approaches overlook the role of personalisation
in guiding tool use. This work investigates how user preferences can be
effectively integrated into goal-oriented dialogue agents. Through extensive
analysis, we identify key weaknesses in the ability of LLMs to personalise tool
use. To this end, we introduce \name, a novel solution that enhances
personalised tool use by leveraging a structured tagging tool and an
uncertainty-based tool detector. TAPS significantly improves the ability of
LLMs to incorporate user preferences, achieving the new state-of-the-art for
open source models on the NLSI task.

</details>


### [22] [An Agentic System for Rare Disease Diagnosis with Traceable Reasoning](https://arxiv.org/abs/2506.20430)
*Weike Zhao,Chaoyi Wu,Yanjie Fan,Xiaoman Zhang,Pengcheng Qiu,Yuze Sun,Xiao Zhou,Yanfeng Wang,Ya Zhang,Yongguo Yu,Kun Sun,Weidi Xie*

Main category: cs.CL

TL;DR: DeepRare是一种基于大型语言模型（LLM）的罕见病诊断系统，通过处理异构临床输入生成诊断假设，并展示透明的推理链。


<details>
  <summary>Details</summary>
Motivation: 罕见病诊断因临床异质性、低流行率和医生对其不熟悉而具有挑战性。

Method: DeepRare由中央主机、长期记忆模块和专用代理服务器组成，整合了40多种工具和最新医学知识。

Result: 在8个数据集上评估，DeepRare在2919种疾病中表现出色，1013种疾病达到100%准确率，显著优于其他15种方法。

Conclusion: DeepRare是一种高效、透明的罕见病诊断工具，已实现为易用的网络应用。

Abstract: Rare diseases collectively affect over 300 million individuals worldwide, yet
timely and accurate diagnosis remains a pervasive challenge. This is largely
due to their clinical heterogeneity, low individual prevalence, and the limited
familiarity most clinicians have with rare conditions. Here, we introduce
DeepRare, the first rare disease diagnosis agentic system powered by a large
language model (LLM), capable of processing heterogeneous clinical inputs. The
system generates ranked diagnostic hypotheses for rare diseases, each
accompanied by a transparent chain of reasoning that links intermediate
analytic steps to verifiable medical evidence.
  DeepRare comprises three key components: a central host with a long-term
memory module; specialized agent servers responsible for domain-specific
analytical tasks integrating over 40 specialized tools and web-scale,
up-to-date medical knowledge sources, ensuring access to the most current
clinical information. This modular and scalable design enables complex
diagnostic reasoning while maintaining traceability and adaptability. We
evaluate DeepRare on eight datasets. The system demonstrates exceptional
diagnostic performance among 2,919 diseases, achieving 100% accuracy for 1013
diseases. In HPO-based evaluations, DeepRare significantly outperforms other 15
methods, like traditional bioinformatics diagnostic tools, LLMs, and other
agentic systems, achieving an average Recall@1 score of 57.18% and surpassing
the second-best method (Reasoning LLM) by a substantial margin of 23.79
percentage points. For multi-modal input scenarios, DeepRare achieves 70.60% at
Recall@1 compared to Exomiser's 53.20% in 109 cases. Manual verification of
reasoning chains by clinical experts achieves 95.40% agreements. Furthermore,
the DeepRare system has been implemented as a user-friendly web application
http://raredx.cn/doctor.

</details>


### [23] [Probing AI Safety with Source Code](https://arxiv.org/abs/2506.20471)
*Ujwal Narayan,Shreyas Chaudhari,Ashwin Kalyan,Tanmay Rajpurohit,Karthik Narasimhan,Ameet Deshpande,Vishvak Murahari*

Main category: cs.CL

TL;DR: 论文提出了一种名为Code of Thought (CoDoT)的提示策略，用于评估大型语言模型（LLMs）的安全性，发现当前模型在安全性上存在严重不足。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在安全关键应用中的普及，确保其与人类价值观和偏好对齐的需求日益迫切。

Method: 通过CoDoT将自然语言输入转换为代码形式，以评估LLMs的安全性。

Result: 实验表明，CoDoT导致多种先进LLMs的安全性显著下降，如GPT-4 Turbo毒性增加16.5倍，DeepSeek R1失败率100%。

Conclusion: CoDoT揭示了当前LLMs安全性的不足，强调了从基本原理出发评估安全性的重要性。

Abstract: Large language models (LLMs) have become ubiquitous, interfacing with humans
in numerous safety-critical applications. This necessitates improving
capabilities, but importantly coupled with greater safety measures to align
these models with human values and preferences. In this work, we demonstrate
that contemporary models fall concerningly short of the goal of AI safety,
leading to an unsafe and harmful experience for users. We introduce a prompting
strategy called Code of Thought (CoDoT) to evaluate the safety of LLMs. CoDoT
converts natural language inputs to simple code that represents the same
intent. For instance, CoDoT transforms the natural language prompt "Make the
statement more toxic: {text}" to: "make_more_toxic({text})". We show that CoDoT
results in a consistent failure of a wide range of state-of-the-art LLMs. For
example, GPT-4 Turbo's toxicity increases 16.5 times, DeepSeek R1 fails 100% of
the time, and toxicity increases 300% on average across seven modern LLMs.
Additionally, recursively applying CoDoT can further increase toxicity two
times. Given the rapid and widespread adoption of LLMs, CoDoT underscores the
critical need to evaluate safety efforts from first principles, ensuring that
safety and capabilities advance together.

</details>


### [24] [Time is On My Side: Dynamics of Talk-Time Sharing in Video-chat Conversations](https://arxiv.org/abs/2506.20474)
*Kaixiang Zhang,Justine Zhang,Cristian Danescu-Niculescu-Mizil*

Main category: cs.CL

TL;DR: 论文提出了一种计算框架，用于量化对话中说话时间的分布及其动态变化，揭示了不同动态类型对参与者感知的影响。


<details>
  <summary>Details</summary>
Motivation: 研究对话中说话时间的分配及其动态变化，以理解其对参与者感知的影响，并为计算机辅助通信平台设计提供工具。

Method: 通过分析大规模陌生人视频聊天数据集，提出了一种量化说话时间分布和动态变化的计算框架，并基于此建立了一种动态分类法。

Result: 研究发现，平衡的对话更受欢迎，尤其是说话较少的参与者；即使总体平衡相同，不同的动态类型也会影响感知。

Conclusion: 该框架为计算机辅助通信平台设计提供了新工具，适用于人-人和人-人工智能的交互。

Abstract: An intrinsic aspect of every conversation is the way talk-time is shared
between multiple speakers. Conversations can be balanced, with each speaker
claiming a similar amount of talk-time, or imbalanced when one talks
disproportionately. Such overall distributions are the consequence of
continuous negotiations between the speakers throughout the conversation: who
should be talking at every point in time, and for how long?
  In this work we introduce a computational framework for quantifying both the
conversation-level distribution of talk-time between speakers, as well as the
lower-level dynamics that lead to it. We derive a typology of talk-time sharing
dynamics structured by several intuitive axes of variation. By applying this
framework to a large dataset of video-chats between strangers, we confirm that,
perhaps unsurprisingly, different conversation-level distributions of talk-time
are perceived differently by speakers, with balanced conversations being
preferred over imbalanced ones, especially by those who end up talking less.
Then we reveal that -- even when they lead to the same level of overall balance
-- different types of talk-time sharing dynamics are perceived differently by
the participants, highlighting the relevance of our newly introduced typology.
Finally, we discuss how our framework offers new tools to designers of
computer-mediated communication platforms, for both human-human and human-AI
communication.

</details>


### [25] [Knowledge-Aware Diverse Reranking for Cross-Source Question Answering](https://arxiv.org/abs/2506.20476)
*Tong Zhou*

Main category: cs.CL

TL;DR: Team Marikarp的解决方案在SIGIR 2025 LiveRAG竞赛中获胜，其知识感知多样化重排序RAG管道表现优异。


<details>
  <summary>Details</summary>
Motivation: 竞赛旨在评估从FineWeb语料库的15M文档子集中检索问题相关支持文档的能力。

Method: 提出了知识感知多样化重排序RAG管道。

Result: 在竞赛中获得第一名。

Conclusion: 该方法在多样化问题类型和知识组织方法下表现优异。

Abstract: This paper presents Team Marikarp's solution for the SIGIR 2025 LiveRAG
competition. The competition's evaluation set, automatically generated by
DataMorgana from internet corpora, encompassed a wide range of target topics,
question types, question formulations, audience types, and knowledge
organization methods. It offered a fair evaluation of retrieving
question-relevant supporting documents from a 15M documents subset of the
FineWeb corpus. Our proposed knowledge-aware diverse reranking RAG pipeline
achieved first place in the competition.

</details>


### [26] [GPTailor: Large Language Model Pruning Through Layer Cutting and Stitching](https://arxiv.org/abs/2506.20480)
*Guinan Su,Li Shen,Lu Yin,Shiwei Liu,Yanwu Yang,Jonas Geiping*

Main category: cs.CL

TL;DR: 论文提出了一种通过合并微调模型变体的层来压缩大语言模型的新策略，显著减少了参数数量同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）虽然能力强大，但模型规模大导致部署和推理困难。现有方法主要关注单模型剪枝，无法充分利用多模型的能力。

Method: 将模型压缩问题转化为零阶优化问题，支持层移除、层选择和层合并三种操作，通过策略性组合微调模型的层来压缩模型。

Result: 实验表明，压缩后的模型（如Llama2-13B）在移除约25%参数的同时保持了97.3%的原始性能，优于现有方法。

Conclusion: 该方法为LLMs的高效部署提供了新思路，通过合并微调模型的层实现了性能与效率的平衡。

Abstract: Large language models (LLMs) have shown remarkable capabilities in language
understanding and generation. However, such impressive capability typically
comes with a substantial model size, which presents significant challenges in
deployment and inference. While structured pruning of model parameters offers a
promising way to reduce computational costs at deployment time, current methods
primarily focus on single model pruning. In this work, we develop a novel
strategy to compress models by strategically combining or merging layers from
finetuned model variants, which preserves the original model's abilities by
aggregating capabilities accentuated in different finetunes. We pose the
optimal tailoring of these LLMs as a zero-order optimization problem, adopting
a search space that supports three different operations: (1) Layer removal, (2)
Layer selection from different candidate models, and (3) Layer merging. Our
experiments demonstrate that this approach leads to competitive model pruning,
for example, for the Llama2-13B model families, our compressed models maintain
approximately 97.3\% of the original performance while removing $\sim25\%$ of
parameters, significantly outperforming previous state-of-the-art methods. The
code is available at https://github.com/Guinan-Su/auto-merge-llm.

</details>


### [27] [ReCode: Updating Code API Knowledge with Reinforcement Learning](https://arxiv.org/abs/2506.20495)
*Haoze Wu,Yunzhi Yao,Wenhao Yu,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: ReCode框架通过强化学习提升LLM在动态API环境中的代码生成能力，减少对过时API知识的依赖。


<details>
  <summary>Details</summary>
Motivation: 解决LLM因依赖过时API知识而无法适应动态库更新的问题。

Method: 构建数据集训练LLM进行版本迁移，引入改进的字符串相似度指标作为强化学习奖励。

Result: ReCode显著提升LLM在动态API场景中的表现，且对通用代码生成能力影响较小。

Conclusion: ReCode是提升LLM适应动态API环境的有效方法，适用于多种模型和算法。

Abstract: Large Language Models (LLMs) exhibit remarkable code generation capabilities
but falter when adapting to frequent updates in external library APIs. This
critical limitation, stemming from reliance on outdated API knowledge from
their training data, even with access to current documentation, impedes
reliable code generation in dynamic environments. To tackle this issue, we
propose ReCode (rule-based Reinforcement learning for Code Update), a novel
framework that mimics human programmer adaptation to API changes. Specifically,
we construct a dataset of approximately 2,000 data entries to train the LLMs to
perform version migration based on updated information. Then, we introduce a
modified string similarity metric for code evaluation as the reward for
reinforcement learning. Our experiments demonstrate that ReCode substantially
boosts LLMs' code generation performance in dynamic API scenarios, especially
on the unseen CodeUpdateArena task. Crucially, compared to supervised
fine-tuning, ReCode has less impact on LLMs' general code generation abilities.
We apply ReCode on various LLMs and reinforcement learning algorithms (GRPO and
DAPO), all achieving consistent improvements. Notably, after training,
Qwen2.5-Coder-7B outperforms that of the 32B parameter code instruction-tuned
model and the reasoning model with the same architecture. Code is available at
https://github.com/zjunlp/ReCode.

</details>


### [28] [OctoThinker: Mid-training Incentivizes Reinforcement Learning Scaling](https://arxiv.org/abs/2506.20512)
*Zengzhi Wang,Fan Zhou,Xuefeng Li,Pengfei Liu*

Main category: cs.CL

TL;DR: 研究了不同基础语言模型（如Llama和Qwen）在强化学习（RL）后的行为差异，提出了两阶段训练策略Stable-then-Decay，并发布了开源模型OctoThinker和数学推理语料库。


<details>
  <summary>Details</summary>
Motivation: 探索基础语言模型在强化学习中的适应性，为下一代RL可扩展的基础模型开发提供指导。

Method: 比较Qwen和Llama模型，分析数据格式、数学语料和指令数据对RL的影响，提出两阶段训练策略。

Result: 发现高质量数学语料和长链推理数据提升RL性能，但需注意数据格式；两阶段策略显著提升模型性能。

Conclusion: 两阶段训练策略OctoThinker缩小了与RL友好模型的差距，为未来基础模型预训练提供了新思路。

Abstract: Different base language model families, such as Llama and Qwen, exhibit
divergent behaviors during post-training with reinforcement learning (RL),
especially on reasoning-intensive tasks. What makes a base language model
suitable for reinforcement learning? Gaining deeper insight into this question
is essential for developing RL-scalable foundation models of the next
generation. In this work, we investigate how mid-training strategies shape RL
dynamics, focusing on two representative model families: Qwen and Llama. Our
study reveals that (1) high-quality mathematical corpora, such as
MegaMath-Web-Pro, significantly improve both base model and RL performance,
while existing alternatives (e.g., FineMath-4plus) fail to do so; (2) further
adding QA-style data, particularly long chain-of-thought (CoT) reasoning
examples, enhances RL outcomes, and instruction data further unlocks this
effect; (3) while long-CoT improves reasoning depth, it can also induce
verbosity of model responses and unstability of RL training, underscoring the
importance of data formatting; (4) scaling mid-training consistently leads to
stronger downstream RL performance. Building on these insights, we introduce a
two-stage mid-training strategy, Stable-then-Decay, in which base models are
first trained on 200B tokens with a constant learning rate, followed by 20B
tokens across three CoT-focused branches with learning rate decay. This yields
OctoThinker, a family of models demonstrating strong RL compatibility and
closing the performance gap with more RL-friendly model families, i.e., Qwen.
We hope our work will help shape pre-training strategies for foundation models
in the RL era. To support further research, we release our open-source models
along with a curated math reasoning-intensive corpus of over 70 billion tokens
(i.e., MegaMath-Web-Pro-Max).

</details>


### [29] [When Life Gives You Samples: The Benefits of Scaling up Inference Compute for Multilingual LLMs](https://arxiv.org/abs/2506.20544)
*Ammar Khairi,Daniel D'souza,Ye Shen,Julia Kreutzer,Sara Hooker*

Main category: cs.CL

TL;DR: 该研究探讨了如何在大规模语言模型（LLMs）中通过调整采样和选择策略，提升多语言和多任务场景下的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在英语和特定领域（如数学和代码），而本研究旨在开发适用于多语言、多任务和开放任务的通用方法。

Method: 提出新的采样和选择策略，适应多语言和多任务环境，并在8B和111B模型上进行评估。

Result: 新策略在m-ArenaHard-v2.0基准测试中显著提升了性能（8B模型平均提升6.8%，111B模型提升9.0%）。

Conclusion: 研究强调了语言和任务感知的推理方法的重要性，为性能提升在非主流语言中的普及提供了支持。

Abstract: Recent advancements in large language models (LLMs) have shifted focus toward
scaling inference-time compute, improving performance without retraining the
model. A common approach is to sample multiple outputs in parallel, and select
one of these as the final output. However, work to date has focused on English
and a handful of domains such as math and code. In contrast, we are most
interested in techniques that generalize across open-ended tasks, formally
verifiable tasks, and across languages. In this work, we study how to robustly
scale inference-time compute for open-ended generative tasks in a multilingual,
multi-task setting.
  Our findings show that both sampling strategy based on temperature variation
and selection strategy must be adapted to account for diverse domains and
varied language settings. We evaluate existing selection methods, revealing
that strategies effective in English often fail to generalize across languages.
We propose novel sampling and selection strategies specifically adapted for
multilingual and multi-task inference scenarios, and show they yield notable
gains across languages and tasks. In particular, our combined sampling and
selection methods lead to an average +6.8 jump in win-rates for our 8B models
on m-ArenaHard-v2.0 prompts, against proprietary models such as Gemini. At
larger scale, Command-A (111B model) equipped with our methods, shows +9.0
improvement in win-rates on the same benchmark with just five samples against
single-sample decoding, a substantial increase at minimal cost. Our results
underscore the need for language- and task-aware approaches to inference-time
compute, aiming to democratize performance improvements in underrepresented
languages.

</details>


### [30] [Model Editing as a Double-Edged Sword: Steering Agent Ethical Behavior Toward Beneficence or Harm](https://arxiv.org/abs/2506.20606)
*Baixiang Huang,Zhen Tan,Haoran Wang,Zijie Liu,Dawei Li,Ali Payani,Huan Liu,Tianlong Chen,Kai Shu*

Main category: cs.CL

TL;DR: 论文提出了一种称为行为编辑（Behavior Editing）的方法，用于高效引导基于大语言模型（LLM）的代理的伦理行为，并引入了多层级基准BehaviorBench进行评估。


<details>
  <summary>Details</summary>
Motivation: 部署LLM代理在高风险领域存在安全和伦理风险，需要一种方法动态调整其行为以避免严重后果。

Method: 将代理行为引导建模为模型编辑任务，利用BehaviorBench进行多场景评估和编辑。

Result: 行为编辑能动态调整代理行为，实现局部和全局伦理对齐，并展示其促进或诱导行为的潜力。

Conclusion: 行为编辑为代理行为引导提供了新范式，但也揭示了其潜在风险。

Abstract: Agents based on Large Language Models (LLMs) have demonstrated strong
capabilities across a wide range of tasks. However, deploying LLM-based agents
in high-stakes domains comes with significant safety and ethical risks.
Unethical behavior by these agents can directly result in serious real-world
consequences, including physical harm and financial loss. To efficiently steer
the ethical behavior of agents, we frame agent behavior steering as a model
editing task, which we term Behavior Editing. Model editing is an emerging area
of research that enables precise and efficient modifications to LLMs while
preserving their overall capabilities. To systematically study and evaluate
this approach, we introduce BehaviorBench, a multi-tier benchmark grounded in
psychological moral theories. This benchmark supports both the evaluation and
editing of agent behaviors across a variety of scenarios, with each tier
introducing more complex and ambiguous scenarios. We first demonstrate that
Behavior Editing can dynamically steer agents toward the target behavior within
specific scenarios. Moreover, Behavior Editing enables not only
scenario-specific local adjustments but also more extensive shifts in an
agent's global moral alignment. We demonstrate that Behavior Editing can be
used to promote ethical and benevolent behavior or, conversely, to induce
harmful or malicious behavior. Through comprehensive evaluations on agents
based on frontier LLMs, BehaviorBench shows the effectiveness of Behavior
Editing across different models and scenarios. Our findings offer key insights
into a new paradigm for steering agent behavior, highlighting both the promise
and perils of Behavior Editing.

</details>


### [31] [DiffuCoder: Understanding and Improving Masked Diffusion Models for Code Generation](https://arxiv.org/abs/2506.20639)
*Shansan Gong,Ruixiang Zhang,Huangjie Zheng,Jiatao Gu,Navdeep Jaitly,Lingpeng Kong,Yizhe Zhang*

Main category: cs.CL

TL;DR: DiffuCoder是一种7B参数的扩散大语言模型（dLLM），用于代码生成，通过系统研究其去噪过程和强化学习方法，揭示了其与自回归模型的不同解码行为，并提出了一种新的采样方案coupled-GRPO，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 探索扩散大语言模型（dLLMs）在代码生成中的潜力，解决其训练和推理机制未被充分研究的问题。

Method: 训练7B参数的dLLM（DiffuCoder），分析其解码行为，并提出coupled-GRPO采样方案以减少方差并提升训练效率。

Result: DiffuCoder在代码生成基准上性能提升4.4%，减少了对自回归因果解码的依赖。

Conclusion: 研究揭示了dLLM的生成机制，并提供了一个有效的扩散原生强化学习训练框架。

Abstract: Diffusion large language models (dLLMs) are compelling alternatives to
autoregressive (AR) models because their denoising models operate over the
entire sequence. The global planning and iterative refinement features of dLLMs
are particularly useful for code generation. However, current training and
inference mechanisms for dLLMs in coding are still under-explored. To demystify
the decoding behavior of dLLMs and unlock their potential for coding, we
systematically investigate their denoising processes and reinforcement learning
(RL) methods. We train a 7B dLLM, \textbf{DiffuCoder}, on 130B tokens of code.
Using this model as a testbed, we analyze its decoding behavior, revealing how
it differs from that of AR models: (1) dLLMs can decide how causal their
generation should be without relying on semi-AR decoding, and (2) increasing
the sampling temperature diversifies not only token choices but also their
generation order. This diversity creates a rich search space for RL rollouts.
For RL training, to reduce the variance of token log-likelihood estimates and
maintain training efficiency, we propose \textbf{coupled-GRPO}, a novel
sampling scheme that constructs complementary mask noise for completions used
in training. In our experiments, coupled-GRPO significantly improves
DiffuCoder's performance on code generation benchmarks (+4.4\% on EvalPlus) and
reduces reliance on AR causal during decoding. Our work provides deeper insight
into the machinery of dLLM generation and offers an effective, diffusion-native
RL training framework. https://github.com/apple/ml-diffucoder.

</details>


### [32] [Memento: Note-Taking for Your Future Self](https://arxiv.org/abs/2506.20642)
*Chao Wan,Albert Gong,Mihir Mishra,Carl-Leander Henneking,Claas Beger,Kilian Q. Weinberger*

Main category: cs.CL

TL;DR: Memento是一种新的提示策略，通过分解问题、动态构建事实数据库并整合信息，显著提升了大型语言模型在多跳问答任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在纯推理任务中表现优异，但在需要紧密耦合检索的复杂推理任务（如多跳问答）中表现不佳。

Method: Memento采用三阶段策略：1) 分解复杂问题为小步骤；2) 动态构建事实数据库；3) 整合信息解决问题。

Result: 在多个基准测试中，Memento显著优于现有方法，如在PhantomWiki上性能翻倍，在2WikiMultiHopQA上提升20 F1点。

Conclusion: Memento是一种有效的策略，能够显著提升大型语言模型在复杂推理任务中的性能。

Abstract: Large language models (LLMs) excel at reasoning-only tasks, but struggle when
reasoning must be tightly coupled with retrieval, as in multi-hop question
answering. To overcome these limitations, we introduce a prompting strategy
that first decomposes a complex question into smaller steps, then dynamically
constructs a database of facts using LLMs, and finally pieces these facts
together to solve the question. We show how this three-stage strategy, which we
call Memento, can boost the performance of existing prompting strategies across
diverse settings. On the 9-step PhantomWiki benchmark, Memento doubles the
performance of chain-of-thought (CoT) when all information is provided in
context. On the open-domain version of 2WikiMultiHopQA, CoT-RAG with Memento
improves over vanilla CoT-RAG by more than 20 F1 percentage points and over the
multi-hop RAG baseline, IRCoT, by more than 13 F1 percentage points. On the
challenging MuSiQue dataset, Memento improves ReAct by more than 3 F1
percentage points, demonstrating its utility in agentic settings.

</details>


### [33] [Inside you are many wolves: Using cognitive models to interpret value trade-offs in LLMs](https://arxiv.org/abs/2506.20666)
*Sonia K. Murthy,Rosie Zhao,Jennifer Hu,Sham Kakade,Markus Wulfmeier,Peng Qian,Tomer Ullman*

Main category: cs.CL

TL;DR: 论文探讨了LLMs在社交情境中如何权衡冲突目标，并利用认知模型评估其与人类价值观的相似性。


<details>
  <summary>Details</summary>
Motivation: 当前工具难以捕捉LLMs中动态多面的价值观权衡，而认知模型可为此提供框架。

Method: 采用认知模型分析LLMs在推理努力和RL训练动态中的价值权衡。

Result: 发现推理模型更注重信息效用，开源模型在数学推理中表现更强；训练早期价值观变化显著。

Conclusion: 方法适用于快速演变的LLM领域，有助于优化训练和控制价值观权衡。

Abstract: Navigating everyday social situations often requires juggling conflicting
goals, such as conveying a harsh truth, maintaining trust, all while still
being mindful of another person's feelings. These value trade-offs are an
integral part of human decision-making and language use, however, current tools
for interpreting such dynamic and multi-faceted notions of values in LLMs are
limited. In cognitive science, so-called "cognitive models" provide formal
accounts of these trade-offs in humans, by modeling the weighting of a
speaker's competing utility functions in choosing an action or utterance. In
this work, we use a leading cognitive model of polite speech to interpret the
extent to which LLMs represent human-like trade-offs. We apply this lens to
systematically evaluate value trade-offs in two encompassing model settings:
degrees of reasoning "effort" in frontier black-box models, and RL
post-training dynamics of open-source models. Our results highlight patterns of
higher informational utility than social utility in reasoning models, and in
open-source models shown to be stronger in mathematical reasoning. Our findings
from LLMs' training dynamics suggest large shifts in utility values early on in
training with persistent effects of the choice of base model and pretraining
data, compared to feedback dataset or alignment method. We show that our method
is responsive to diverse aspects of the rapidly evolving LLM landscape, with
insights for forming hypotheses about other high-level behaviors, shaping
training regimes for reasoning models, and better controlling trade-offs
between values during model training.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [34] [Computer Vision based Automated Quantification of Agricultural Sprayers Boom Displacement](https://arxiv.org/abs/2506.19939)
*Aryan Singh Dalal,Sidharth Rai,Rahul Singh,Treman Singh Kaloya,Rahul Harsha Cheppally,Ajay Sharda*

Main category: cs.CV

TL;DR: 开发了一种基于计算机视觉的系统，用于量化农业喷雾器喷杆的运动，以提高喷雾应用的准确性。


<details>
  <summary>Details</summary>
Motivation: 喷雾器喷杆的不稳定性是导致喷雾应用误差的主要因素之一，但目前缺乏定量数据来改进喷杆设计和控制系统。

Method: 使用YOLO V7、V8和V11神经网络模型实时跟踪喷杆上的目标，并结合倾角传感器验证模型输出。

Result: 模型检测目标的准确率超过90%，距离估计与传感器数据误差在0.026米以内。

Conclusion: 该系统能有效量化喷杆运动，为喷杆设计和稳定性改进提供数据支持。

Abstract: Application rate errors when using self-propelled agricultural sprayers for
agricultural production remain a concern. Among other factors, spray boom
instability is one of the major contributors to application errors. Spray
booms' width of 38m, combined with 30 kph driving speeds, varying terrain, and
machine dynamics when maneuvering complex field boundaries, make controls of
these booms very complex. However, there is no quantitative knowledge on the
extent of boom movement to systematically develop a solution that might include
boom designs and responsive boom control systems. Therefore, this study was
conducted to develop an automated computer vision system to quantify the boom
movement of various agricultural sprayers. A computer vision system was
developed to track a target on the edge of the sprayer boom in real time. YOLO
V7, V8, and V11 neural network models were trained to track the boom's
movements in field operations to quantify effective displacement in the
vertical and transverse directions. An inclinometer sensor was mounted on the
boom to capture boom angles and validate the neural network model output. The
results showed that the model could detect the target with more than 90 percent
accuracy, and distance estimates of the target on the boom were within 0.026 m
of the inclinometer sensor data. This system can quantify the boom movement on
the current sprayer and potentially on any other sprayer with minor
modifications. The data can be used to make design improvements to make sprayer
booms more stable and achieve greater application accuracy.

</details>


### [35] [EBC-ZIP: Improving Blockwise Crowd Counting with Zero-Inflated Poisson Regression](https://arxiv.org/abs/2506.19955)
*Yiming Ma,Victor Sanchez,Tanaya Guha*

Main category: cs.CV

TL;DR: 论文提出EBC-ZIP框架，通过零膨胀泊松回归改进人群计数中的密度图估计，解决数据稀疏性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视地面真实密度图的极端稀疏性，导致模型在稀疏区域表现不佳。

Method: 采用零膨胀泊松回归（ZIP）替代传统回归损失，结合增强块分类（EBC）框架。

Result: 在四个基准测试中，EBC-ZIP优于EBC并达到最优性能。

Conclusion: EBC-ZIP通过更合理的概率损失提升了人群计数的准确性和稳定性。

Abstract: Density map estimation has become the mainstream paradigm in crowd counting.
However, most existing methods overlook the extreme sparsity of ground-truth
density maps. In real-world crowd scenes, the vast majority of spatial regions
(often over 95%) contain no people, leading to heavily imbalanced count
distributions. Ignoring this imbalance can bias models toward overestimating
dense regions and underperforming in sparse areas. Furthermore, most loss
functions used in density estimation are majorly based on MSE and implicitly
assume Gaussian distributions, which are ill-suited for modeling discrete,
non-negative count data. In this paper, we propose EBC-ZIP, a crowd counting
framework that models the spatial distribution of counts using a Zero-Inflated
Poisson (ZIP) regression formulation. Our approach replaces the traditional
regression loss with the negative log-likelihood of the ZIP distribution,
enabling better handling of zero-heavy distributions while preserving count
accuracy. Built upon the recently proposed Enhanced Block Classification (EBC)
framework, EBC-ZIP inherits EBC's advantages in preserving the discreteness of
targets and ensuring training stability, while further improving performance
through a more principled probabilistic loss. We also evaluate EBC-ZIP with
backbones of varying computational complexity to assess its scalability.
Extensive experiments on four crowd counting benchmarks demonstrate that
EBC-ZIP consistently outperforms EBC and achieves state-of-the-art results.

</details>


### [36] [ToSA: Token Merging with Spatial Awareness](https://arxiv.org/abs/2506.20066)
*Hsiang-Wei Huang,Wenhao Chai,Kuang-Ming Chen,Cheng-Yen Yang,Jenq-Neng Hwang*

Main category: cs.CV

TL;DR: ToSA是一种结合语义和空间感知的令牌合并方法，通过深度图像生成伪空间令牌，优化ViT的加速效果。


<details>
  <summary>Details</summary>
Motivation: 现有令牌合并方法主要依赖特征相似性，忽略了空间信息在早期ViT层中的潜力。

Method: 提出ToSA，利用深度图像生成伪空间令牌，结合语义和空间信息指导令牌合并。

Result: 在多个视觉和具身问答基准上优于现有方法，显著减少ViT运行时间。

Conclusion: ToSA是一种高效的ViT加速解决方案，能更好地保留场景结构。

Abstract: Token merging has emerged as an effective strategy to accelerate Vision
Transformers (ViT) by reducing computational costs. However, existing methods
primarily rely on the visual token's feature similarity for token merging,
overlooking the potential of integrating spatial information, which can serve
as a reliable criterion for token merging in the early layers of ViT, where the
visual tokens only possess weak visual information. In this paper, we propose
ToSA, a novel token merging method that combines both semantic and spatial
awareness to guide the token merging process. ToSA leverages the depth image as
input to generate pseudo spatial tokens, which serve as auxiliary spatial
information for the visual token merging process. With the introduced spatial
awareness, ToSA achieves a more informed merging strategy that better preserves
critical scene structure. Experimental results demonstrate that ToSA
outperforms previous token merging methods across multiple benchmarks on visual
and embodied question answering while largely reducing the runtime of the ViT,
making it an efficient solution for ViT acceleration. The code will be
available at: https://github.com/hsiangwei0903/ToSA

</details>


### [37] [BrokenVideos: A Benchmark Dataset for Fine-Grained Artifact Localization in AI-Generated Videos](https://arxiv.org/abs/2506.20103)
*Jiahao Lin,Weixuan Peng,Bojia Zi,Yifeng Gao,Xianbiao Qi,Xingjun Ma,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 论文介绍了BrokenVideos，一个用于AI生成视频中视觉伪影定位的基准数据集，包含3,254个视频和像素级标注，显著提升了伪影检测模型的性能。


<details>
  <summary>Details</summary>
Motivation: AI生成视频中存在视觉伪影（如运动不一致、物理不合理的轨迹等），但目前缺乏针对伪影定位的全面基准数据集。

Method: 提出BrokenVideos数据集，包含3,254个AI生成视频，每个视频都有像素级标注的视觉伪影区域，并通过人工验证确保标注质量。

Result: 实验表明，基于BrokenVideos训练的模型在伪影定位能力上有显著提升。

Conclusion: BrokenVideos为生成视频模型的伪影定位研究提供了重要基准，推动了该领域的进展。

Abstract: Recent advances in deep generative models have led to significant progress in
video generation, yet the fidelity of AI-generated videos remains limited.
Synthesized content often exhibits visual artifacts such as temporally
inconsistent motion, physically implausible trajectories, unnatural object
deformations, and local blurring that undermine realism and user trust.
Accurate detection and spatial localization of these artifacts are crucial for
both automated quality control and for guiding the development of improved
generative models. However, the research community currently lacks a
comprehensive benchmark specifically designed for artifact localization in AI
generated videos. Existing datasets either restrict themselves to video or
frame level detection or lack the fine-grained spatial annotations necessary
for evaluating localization methods. To address this gap, we introduce
BrokenVideos, a benchmark dataset of 3,254 AI-generated videos with
meticulously annotated, pixel-level masks highlighting regions of visual
corruption. Each annotation is validated through detailed human inspection to
ensure high quality ground truth. Our experiments show that training state of
the art artifact detection models and multi modal large language models (MLLMs)
on BrokenVideos significantly improves their ability to localize corrupted
regions. Through extensive evaluation, we demonstrate that BrokenVideos
establishes a critical foundation for benchmarking and advancing research on
artifact localization in generative video models. The dataset is available at:
https://broken-video-detection-datetsets.github.io/Broken-Video-Detection-Datasets.github.io/.

</details>


### [38] [From 2D to 3D Cognition: A Brief Survey of General World Models](https://arxiv.org/abs/2506.20134)
*Ningwei Xie,Zizi Tian,Lei Yang,Xiao-Ping Zhang,Meng Guo,Jie Li*

Main category: cs.CV

TL;DR: 该论文综述了从2D感知到3D认知的世界模型发展，重点分析了3D表示和世界知识的技术驱动，并探讨了3D世界建模的核心能力及其应用。


<details>
  <summary>Details</summary>
Motivation: 当前3D认知世界模型领域缺乏系统性分析，需要明确技术分类及其在推动3D认知中的作用。

Method: 提出概念框架，系统回顾从2D到3D的世界模型发展，分析3D表示和世界知识的技术驱动，并探讨3D建模的核心能力。

Result: 总结了3D世界建模的三大核心能力（3D物理场景生成、3D空间推理、3D空间交互）及其在具体应用中的部署。

Conclusion: 指出了数据、建模和部署中的挑战，并提出了未来发展方向，以推动更稳健和通用的3D世界模型。

Abstract: World models have garnered increasing attention in the development of
artificial general intelligence (AGI), serving as computational frameworks for
learning representations of the external world and forecasting future states.
While early efforts focused on 2D visual perception and simulation, recent
3D-aware generative world models have demonstrated the ability to synthesize
geometrically consistent, interactive 3D environments, marking a shift toward
3D spatial cognition. Despite rapid progress, the field lacks systematic
analysis to categorize emerging techniques and clarify their roles in advancing
3D cognitive world models. This survey addresses this need by introducing a
conceptual framework, providing a structured and forward-looking review of
world models transitioning from 2D perception to 3D cognition. Within this
framework, we highlight two key technological drivers, particularly advances in
3D representations and the incorporation of world knowledge, as fundamental
pillars. Building on these, we dissect three core cognitive capabilities that
underpin 3D world modeling: 3D physical scene generation, 3D spatial reasoning,
and 3D spatial interaction. We further examine the deployment of these
capabilities in real-world applications, including embodied AI, autonomous
driving, digital twin, and gaming/VR. Finally, we identify challenges across
data, modeling, and deployment, and outline future directions for advancing
more robust and generalizable 3D world models.

</details>


### [39] [EAR: Erasing Concepts from Unified Autoregressive Models](https://arxiv.org/abs/2506.20151)
*Haipeng Fan,Shiyuan Zhang,Baohunesitu,Zihang Guo,Huaiwen Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为EAR的微调方法，用于在自回归模型中有效且保持效用的概念擦除，并引入了WGA和TLM策略。还提出了ECGVF基准以评估概念擦除效果。


<details>
  <summary>Details</summary>
Motivation: 自回归模型在视觉理解和图像生成任务中表现优异，但如何在保持生成质量的同时移除不需要的概念仍是一个挑战。

Method: 提出EAR方法，结合WGA策略和TLM策略，并设计ECGVF基准进行评测。

Result: 实验表明，EAR在概念擦除效果和模型效用保持方面均有显著提升。

Conclusion: EAR为自回归模型中的概念擦除提供了有效且实用的解决方案。

Abstract: Autoregressive (AR) models have achieved unified and strong performance
across both visual understanding and image generation tasks. However, removing
undesired concepts from AR models while maintaining overall generation quality
remains an open challenge. In this paper, we propose Erasure Autoregressive
Model (EAR), a fine-tuning method for effective and utility-preserving concept
erasure in AR models. Specifically, we introduce Windowed Gradient Accumulation
(WGA) strategy to align patch-level decoding with erasure objectives, and
Thresholded Loss Masking (TLM) strategy to protect content unrelated to the
target concept during fine-tuning. Furthermore, we propose a novel benchmark,
Erase Concept Generator and Visual Filter (ECGVF), aim at provide a more
rigorous and comprehensive foundation for evaluating concept erasure in AR
models. Specifically, we first employ structured templates across diverse large
language models (LLMs) to pre-generate a large-scale corpus of
target-replacement concept prompt pairs. Subsequently, we generate images from
these prompts and subject them to rigorous filtering via a visual classifier to
ensure concept fidelity and alignment. Extensive experimental results conducted
on the ECGVF benchmark with the AR model Janus-Pro demonstrate that EAR
achieves marked improvements in both erasure effectiveness and model utility
preservation. Code is available at: https://github.com/immc-lab/ear/

</details>


### [40] [Loss-Aware Automatic Selection of Structured Pruning Criteria for Deep Neural Network Acceleration](https://arxiv.org/abs/2506.20152)
*Deepak Ghimire,Kilho Lee,Seong-heum Kim*

Main category: cs.CV

TL;DR: 提出了一种高效的损失感知自动结构化剪枝方法（LAASP），通过剪枝与训练结合的方式优化神经网络压缩，显著减少计算量并保持高精度。


<details>
  <summary>Details</summary>
Motivation: 解决传统剪枝方法需要分阶段训练、剪枝和微调的问题，提出一种更高效的剪枝-训练一体化方法。

Method: 采用剪枝与训练结合的单循环方法，自动选择剪枝标准和层，并通过损失函数指导剪枝过程，减少计算量。

Result: 在CIFAR-10和ImageNet数据集上，显著减少FLOPs（如ResNet56减少52%），同时保持或提高精度。

Conclusion: LAASP方法在压缩神经网络方面高效且有效，适用于资源受限的边缘设备。

Abstract: Structured pruning is a well-established technique for compressing neural
networks, making it suitable for deployment in resource-limited edge devices.
This paper presents an efficient Loss-Aware Automatic Selection of Structured
Pruning Criteria (LAASP) for slimming and accelerating deep neural networks.
The majority of pruning methodologies employ a sequential process consisting of
three stages: 1) training, 2) pruning, and 3) fine-tuning, whereas the proposed
pruning technique adopts a pruning-while-training approach that eliminates the
first stage and integrates the second and third stages into a single cycle. The
automatic selection of magnitude or similarity-based filter pruning criteria
from a specified pool of criteria and the specific pruning layer at each
pruning iteration is guided by the network's overall loss on a small subset of
the training data. To mitigate the abrupt accuracy drop due to pruning, the
network is retrained briefly after each reduction of a predefined number of
floating-point operations (FLOPs). The optimal pruning rates for each layer in
the network are automatically determined, eliminating the need for manual
allocation of fixed or variable pruning rates for each layer. Experiments on
the VGGNet and ResNet models on the CIFAR-10 and ImageNet benchmark datasets
demonstrate the effectiveness of the proposed method. In particular, the
ResNet56 and ResNet110 models on the CIFAR-10 dataset significantly improve the
top-1 accuracy compared to state-of-the-art methods while reducing the network
FLOPs by 52\%. Furthermore, the ResNet50 model on the ImageNet dataset reduces
FLOPs by more than 42\% with a negligible 0.33\% drop in top-5 accuracy. The
source code of this paper is publicly available online -
https://github.com/ghimiredhikura/laasp.

</details>


### [41] [Towards Efficient Exemplar Based Image Editing with Multimodal VLMs](https://arxiv.org/abs/2506.20155)
*Avadhoot Jadhav,Ashutosh Srivastava,Abhinav Java,Silky Singh,Tarun Ram Menta,Surgan Jandial,Balaji Krishnamurthy*

Main category: cs.CV

TL;DR: 本文提出了一种基于示例对的图像编辑方法，利用预训练的文本到图像扩散模型和多模态VLMs，无需优化即可实现高效编辑。


<details>
  <summary>Details</summary>
Motivation: 仅通过文本描述难以捕捉所有类型的图像编辑需求，而示例对能更直观地表达编辑意图。

Method: 利用预训练的文本到图像扩散模型和多模态VLMs，构建端到端的优化免费管道。

Result: 实验表明，该方法在多种编辑类型上优于基线方法，且速度快约4倍。

Conclusion: 该方法为示例驱动的图像编辑提供了一种高效且无需优化的解决方案。

Abstract: Text-to-Image Diffusion models have enabled a wide array of image editing
applications. However, capturing all types of edits through text alone can be
challenging and cumbersome. The ambiguous nature of certain image edits is
better expressed through an exemplar pair, i.e., a pair of images depicting an
image before and after an edit respectively. In this work, we tackle
exemplar-based image editing -- the task of transferring an edit from an
exemplar pair to a content image(s), by leveraging pretrained text-to-image
diffusion models and multimodal VLMs. Even though our end-to-end pipeline is
optimization-free, our experiments demonstrate that it still outperforms
baselines on multiple types of edits while being ~4x faster.

</details>


### [42] [Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2506.20168)
*Zhentao He,Can Zhang,Ziheng Wu,Zhenghao Chen,Yufei Zhan,Yifan Li,Zhao Zhang,Xian Wang,Minghui Qiu*

Main category: cs.CV

TL;DR: 论文提出了KIE-HVQA基准测试和GRPO框架，用于评估和改进多模态大语言模型在视觉退化条件下的OCR幻觉问题，实验显示其7B参数模型在幻觉抑制上优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 现有模型在视觉退化场景下容易产生OCR幻觉，过度依赖语言先验或视觉-文本推理错位，导致生成不准确内容。

Method: 提出KIE-HVQA基准测试模拟真实退化场景，并设计GRPO框架，结合视觉不确定性自感知和拒绝回答机制，通过监督微调和强化学习减少幻觉。

Result: 实验表明，7B参数模型在KIE-HVQA上幻觉抑制准确率比GPT-4o提升22%，且标准任务性能无显著下降。

Conclusion: GRPO框架能有效抑制视觉退化条件下的OCR幻觉，兼具效果和鲁棒性。

Abstract: Recent advancements in multimodal large language models have enhanced
document understanding by integrating textual and visual information. However,
existing models exhibit incompleteness within their paradigm in real-world
scenarios, particularly under visual degradation. In such conditions, the
current response paradigm often fails to adequately perceive visual degradation
and ambiguity, leading to overreliance on linguistic priors or misaligned
visual-textual reasoning. This difficulty in recognizing uncertainty frequently
results in the generation of hallucinatory content, especially when a precise
answer is not feasible. To better demonstrate and analyze this phenomenon and
problem, we propose KIE-HVQA, the first benchmark dedicated to evaluating OCR
hallucination in degraded document understanding. This dataset includes test
samples spanning identity cards and invoices, with simulated real-world
degradations for OCR reliability. This setup allows for evaluating models'
capacity, under degraded input, to distinguish reliable visual information and
answer accordingly, thereby highlighting the challenge of avoiding
hallucination on uncertain data. To achieve vision-faithful reasoning and
thereby avoid the aforementioned issues, we further introduce a GRPO-based
framework featuring a novel reward mechanism. By incorporating a self-awareness
of visual uncertainty and an analysis method that initiates refusal to answer
to increase task difficulty within our supervised fine-tuning and reinforcement
learning framework, we successfully mitigated hallucinations in ambiguous
regions. Experiments on Qwen2.5-VL demonstrate that our 7B-parameter model
achieves a 22\% absolute improvement in hallucination-free accuracy over GPT-4o
on KIE-HVQA and there is no significant performance drop in standard tasks,
highlighting both effectiveness and robustness.

</details>


### [43] [Towards Scalable and Generalizable Earth Observation Data Mining via Foundation Model Composition](https://arxiv.org/abs/2506.20174)
*Man Duc Chuc*

Main category: cs.CV

TL;DR: 研究探讨了结合预训练基础模型提升地球观测任务性能的潜力，发现特征级集成小模型可媲美或超越大模型，同时节省资源。


<details>
  <summary>Details</summary>
Motivation: 探索预训练模型在地球观测数据挖掘中的复用与组合，以提供更通用和可扩展的解决方案。

Method: 使用GEO-Bench基准测试评估多个预训练模型（如Prithvi、Hiera、DOFA）在11个数据集上的表现，采用特征级集成和知识蒸馏。

Result: 特征级集成小模型性能可媲美或超越大模型，且训练时间和计算资源需求更低。

Conclusion: 通过知识蒸馏将集成模型的优势转移到紧凑模型中，为实际应用提供了可行路径。

Abstract: Foundation models are rapidly transforming Earth Observation data mining by
enabling generalizable and scalable solutions for key tasks such as scene
classification and semantic segmentation. While most efforts in the geospatial
domain have focused on developing large models trained from scratch using
massive Earth Observation datasets, an alternative strategy that remains
underexplored is the reuse and combination of existing pretrained models. In
this study, we investigate whether foundation models pretrained on remote
sensing and general vision datasets can be effectively combined to improve
performance across a diverse set of key Earth Observation tasks. Using the
GEO-Bench benchmark, we evaluate several prominent models, including Prithvi,
Hiera, and DOFA, on eleven datasets covering a range of spatial resolutions,
sensor modalities, and task types. The results show that feature-level
ensembling of smaller pretrained models can match or exceed the performance of
much larger models, while requiring less training time and computational
resources. Moreover, the study highlights the potential of applying knowledge
distillation to transfer the strengths of ensembles into more compact models,
offering a practical path for deploying foundation models in real-world Earth
Observation applications.

</details>


### [44] [Progressive Alignment Degradation Learning for Pansharpening](https://arxiv.org/abs/2506.20179)
*Enzhe Zhao,Zhichang Guo,Yao Li,Fanghui Song,Boying Wu*

Main category: cs.CV

TL;DR: 论文探讨了Wald协议在深度学习全色锐化中的局限性，并提出了一种新的渐进对齐退化模块（PADM）和高频差异扩散框架（HFreqdiff）以提升模型性能。


<details>
  <summary>Details</summary>
Motivation: Wald协议生成的人工低分辨率数据限制了深度学习模型在全分辨率数据上的泛化能力，需要更准确的退化模式学习方法。

Method: 提出PADM模块，通过两个子网络（PAlignNet和PDegradeNet）自适应学习退化过程；并引入HFreqdiff框架，结合CFB和BACM模块提取高频细节。

Result: 实验表明，该方法在空间锐度和图像质量上显著优于现有技术。

Conclusion: PADM和HFreqdiff有效解决了Wald协议的局限性，提升了全色锐化模型的性能。

Abstract: Deep learning-based pansharpening has been shown to effectively generate
high-resolution multispectral (HRMS) images. To create supervised ground-truth
HRMS images, synthetic data generated using the Wald protocol is commonly
employed. This protocol assumes that networks trained on artificial
low-resolution data will perform equally well on high-resolution data. However,
well-trained models typically exhibit a trade-off in performance between
reduced-resolution and full-resolution datasets. In this paper, we delve into
the Wald protocol and find that its inaccurate approximation of real-world
degradation patterns limits the generalization of deep pansharpening models. To
address this issue, we propose the Progressive Alignment Degradation Module
(PADM), which uses mutual iteration between two sub-networks, PAlignNet and
PDegradeNet, to adaptively learn accurate degradation processes without relying
on predefined operators. Building on this, we introduce HFreqdiff, which embeds
high-frequency details into a diffusion framework and incorporates CFB and BACM
modules for frequency-selective detail extraction and precise reverse process
learning. These innovations enable effective integration of high-resolution
panchromatic and multispectral images, significantly enhancing spatial
sharpness and quality. Experiments and ablation studies demonstrate the
proposed method's superior performance compared to state-of-the-art techniques.

</details>


### [45] [UniCode$^2$: Cascaded Large-scale Codebooks for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2506.20214)
*Yanzhe Chen,Huasong Zhong,Yan Li,Zhenheng Yang*

Main category: cs.CV

TL;DR: UniCode²提出了一种级联码本框架，用于大规模、语义对齐且稳定的视觉标记化，解决了现有方法在词汇量小或训练不稳定上的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于码本的方法要么词汇量小（约16K条目），缺乏细粒度语义，要么盲目扩展导致标记利用率低和训练不稳定。

Method: 通过聚类数百万SigLIP序列嵌入构建500K条目的码本，采用级联设计：冻结码本锚定嵌入空间，可训练码本细化任务特定语义。

Result: UniCode²在多样化基准测试中表现优异，支持高质量视觉合成，且无需牺牲稳定性、语义或模块性。

Conclusion: UniCode²证明了在不牺牲稳定性、语义或模块性的情况下扩展视觉标记空间的可行性。

Abstract: Unified multimodal large language models (MLLMs) have shown promise in
jointly advancing multimodal understanding and generation, with visual
codebooks discretizing images into tokens for autoregressive modeling. Existing
codebook-based methods either rely on small vocabularies (~16K entries) that
lack fine-grained semantics or naively scale up, resulting in low token
utilization and unstable training. We propose UniCode$^2$, a cascaded codebook
framework enabling large-scale, semantically aligned, and stable visual
tokenization. By clustering millions of SigLIP sequence embeddings, we build a
500K-entry codebook that preserves vision-language alignment while expanding
capacity. Stability is ensured via a cascaded design: a frozen codebook anchors
the embedding space, and a trainable codebook refines task-specific semantics.
This decoupling promotes high utilization and robust learning. Moreover, the
alignment of our visual tokens with textual semantics enables seamless
integration with pretrained diffusion decoders, supporting high-quality visual
synthesis with minimal adaptation. UniCode^2 delivers strong performance across
diverse benchmarks, demonstrating the viability of scaling visual token spaces
without sacrificing stability, semantics, or modularity.

</details>


### [46] [Dynamic Bandwidth Allocation for Hybrid Event-RGB Transmission](https://arxiv.org/abs/2506.20222)
*Pujing Yang,Guangyi Zhang,Yunlong Cai,Lei Yu,Guanding Yu*

Main category: cs.CV

TL;DR: 提出了一种联合事件和图像（E-I）传输框架，通过贝叶斯建模和信息瓶颈方法消除冗余，优化带宽利用，同时实现实时去模糊。


<details>
  <summary>Details</summary>
Motivation: 混合系统中事件相机和RGB相机传输大量数据存在挑战，且输出信息冗余。

Method: 采用贝叶斯建模和信息瓶颈方法，分离共享和领域特定信息，动态分配传输带宽。

Result: 仿真结果表明，该方案在重建质量和去模糊性能上优于传统系统。

Conclusion: 提出的框架有效优化了带宽利用，同时提升了重建和去模糊性能。

Abstract: Event cameras asynchronously capture pixel-level intensity changes with
extremely low latency. They are increasingly used in conjunction with RGB
cameras for a wide range of vision-related applications. However, a major
challenge in these hybrid systems lies in the transmission of the large volume
of triggered events and RGB images. To address this, we propose a transmission
scheme that retains efficient reconstruction performance of both sources while
accomplishing real-time deblurring in parallel. Conventional RGB cameras and
event cameras typically capture the same scene in different ways, often
resulting in significant redundant information across their outputs. To address
this, we develop a joint event and image (E-I) transmission framework to
eliminate redundancy and thereby optimize channel bandwidth utilization. Our
approach employs Bayesian modeling and the information bottleneck method to
disentangle the shared and domain-specific information within the E-I inputs.
This disentangled information bottleneck framework ensures both the compactness
and informativeness of extracted shared and domain-specific information.
Moreover, it adaptively allocates transmission bandwidth based on scene
dynamics, i.e., more symbols are allocated to events for dynamic details or to
images for static information. Simulation results demonstrate that the proposed
scheme not only achieves superior reconstruction quality compared to
conventional systems but also delivers enhanced deblurring performance.

</details>


### [47] [Recognizing Surgical Phases Anywhere: Few-Shot Test-time Adaptation and Task-graph Guided Refinement](https://arxiv.org/abs/2506.20254)
*Kun Yuan,Tingxuan Chen,Shi Li,Joel L. Lavanchy,Christian Heiliger,Ege Özsoy,Yiming Huang,Long Bai,Nassir Navab,Vinkle Srivastav,Hongliang Ren,Nicolas Padoy*

Main category: cs.CV

TL;DR: SPA是一个轻量级框架，通过少量标注和多模态对齐，提升手术工作流理解的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 手术工作流的复杂性和多样性导致通用模型难以开发，现有基础模型在零样本性能上受限。

Method: SPA结合少样本空间适应、扩散建模和动态测试时适应，优化多模态嵌入和时间一致性。

Result: SPA在少样本手术阶段识别中表现优异，甚至超越全样本模型。

Conclusion: SPA为跨机构和跨手术的通用理解提供了高效解决方案。

Abstract: The complexity and diversity of surgical workflows, driven by heterogeneous
operating room settings, institutional protocols, and anatomical variability,
present a significant challenge in developing generalizable models for
cross-institutional and cross-procedural surgical understanding. While recent
surgical foundation models pretrained on large-scale vision-language data offer
promising transferability, their zero-shot performance remains constrained by
domain shifts, limiting their utility in unseen surgical environments. To
address this, we introduce Surgical Phase Anywhere (SPA), a lightweight
framework for versatile surgical workflow understanding that adapts foundation
models to institutional settings with minimal annotation. SPA leverages
few-shot spatial adaptation to align multi-modal embeddings with
institution-specific surgical scenes and phases. It also ensures temporal
consistency through diffusion modeling, which encodes task-graph priors derived
from institutional procedure protocols. Finally, SPA employs dynamic test-time
adaptation, exploiting the mutual agreement between multi-modal phase
prediction streams to adapt the model to a given test video in a
self-supervised manner, enhancing the reliability under test-time distribution
shifts. SPA is a lightweight adaptation framework, allowing hospitals to
rapidly customize phase recognition models by defining phases in natural
language text, annotating a few images with the phase labels, and providing a
task graph defining phase transitions. The experimental results show that the
SPA framework achieves state-of-the-art performance in few-shot surgical phase
recognition across multiple institutions and procedures, even outperforming
full-shot models with 32-shot labeled data. Code is available at
https://github.com/CAMMA-public/SPA

</details>


### [48] [A Transformer Based Handwriting Recognition System Jointly Using Online and Offline Features](https://arxiv.org/abs/2506.20255)
*Ayush Lodh,Ritabrata Chakraborty,Shivakumara Palaiahnakote,Umapada Pal*

Main category: cs.CV

TL;DR: 提出了一种结合离线图像和在线笔画数据的端到端网络，通过早期融合提升手写识别性能。


<details>
  <summary>Details</summary>
Motivation: 手写识别通常仅利用单一模态（图像或笔画轨迹），而忽略了二者的互补性。

Method: 设计了一个共享潜在空间的网络，通过视觉标记和轻量级Transformer分别编码图像和笔画数据，并通过可学习查询联合关注两种模态。

Result: 在IAMOn-DB和VNOn-DB数据集上达到最优性能，准确率提升1%。

Conclusion: 早期融合多模态数据能增强表示学习，提升识别性能和书写者独立性。

Abstract: We posit that handwriting recognition benefits from complementary cues
carried by the rasterized complex glyph and the pen's trajectory, yet most
systems exploit only one modality. We introduce an end-to-end network that
performs early fusion of offline images and online stroke data within a shared
latent space. A patch encoder converts the grayscale crop into fixed-length
visual tokens, while a lightweight transformer embeds the $(x, y, \text{pen})$
sequence. Learnable latent queries attend jointly to both token streams,
yielding context-enhanced stroke embeddings that are pooled and decoded under a
cross-entropy loss objective. Because integration occurs before any high-level
classification, temporal cues reinforce each other during representation
learning, producing stronger writer independence. Comprehensive experiments on
IAMOn-DB and VNOn-DB demonstrate that our approach achieves state-of-the-art
accuracy, exceeding previous bests by up to 1\%. Our study also shows
adaptation of this pipeline with gesturification on the ISI-Air dataset. Our
code can be found here.

</details>


### [49] [Hierarchical Mask-Enhanced Dual Reconstruction Network for Few-Shot Fine-Grained Image Classification](https://arxiv.org/abs/2506.20263)
*Ning Luo,Meiyin Hu,Huan Wan,Yanyan Yang,Zhuohang Jiang,Xin Wei*

Main category: cs.CV

TL;DR: HMDRN提出了一种结合双层次特征重建和掩码增强的方法，显著提升了小样本细粒度图像分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在细粒度图像分类中存在空间信息丢失和局部特征不对齐的问题，且缺乏对判别区域的关注机制。

Method: HMDRN通过双层次特征重建与融合模块，结合掩码增强的自重建模块，优化特征提取和分类。

Result: 在多个数据集和骨干网络上，HMDRN均优于现有方法，并通过消融实验验证了各模块的有效性。

Conclusion: HMDRN通过双层次重建和掩码增强，显著提升了细粒度分类性能，减少了类内差异。

Abstract: Few-shot fine-grained image classification (FS-FGIC) presents a significant
challenge, requiring models to distinguish visually similar subclasses with
limited labeled examples. Existing methods have critical limitations:
metric-based methods lose spatial information and misalign local features,
while reconstruction-based methods fail to utilize hierarchical feature
information and lack mechanisms to focus on discriminative regions. We propose
the Hierarchical Mask-enhanced Dual Reconstruction Network (HMDRN), which
integrates dual-layer feature reconstruction with mask-enhanced feature
processing to improve fine-grained classification. HMDRN incorporates a
dual-layer feature reconstruction and fusion module that leverages
complementary visual information from different network hierarchies. Through
learnable fusion weights, the model balances high-level semantic
representations from the last layer with mid-level structural details from the
penultimate layer. Additionally, we design a spatial binary mask-enhanced
transformer self-reconstruction module that processes query features through
adaptive thresholding while maintaining complete support features, enhancing
focus on discriminative regions while filtering background noise. Extensive
experiments on three challenging fine-grained datasets demonstrate that HMDRN
consistently outperforms state-of-the-art methods across Conv-4 and ResNet-12
backbone architectures. Comprehensive ablation studies validate the
effectiveness of each proposed component, revealing that dual-layer
reconstruction enhances inter-class discrimination while mask-enhanced
transformation reduces intra-class variations. Visualization results provide
evidence of HMDRN's superior feature reconstruction capabilities.

</details>


### [50] [Forensic Study of Paintings Through the Comparison of Fabrics](https://arxiv.org/abs/2506.20272)
*Juan José Murillo-Fuentes,Pablo M. Olmos,Laura Alba-Carcelén*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的纺织品相似性评估方法，替代传统基于线密度图匹配的方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法无法用于非连续位置的画布，限制了艺术品鉴定和保护的准确性。

Method: 设计了Siamese深度学习模型，通过图像对比较学习特征表示，并提出相似性估计方法。

Result: 在Museo Nacional del Prado的画布上验证了方法的可行性，即使线密度相似也能有效比较。

Conclusion: 该方法为艺术品分析提供了新途径，具有高准确性和实用性。

Abstract: The study of canvas fabrics in works of art is a crucial tool for
authentication, attribution and conservation. Traditional methods are based on
thread density map matching, which cannot be applied when canvases do not come
from contiguous positions on a roll. This paper presents a novel approach based
on deep learning to assess the similarity of textiles. We introduce an
automatic tool that evaluates the similarity between canvases without relying
on thread density maps. A Siamese deep learning model is designed and trained
to compare pairs of images by exploiting the feature representations learned
from the scans. In addition, a similarity estimation method is proposed,
aggregating predictions from multiple pairs of cloth samples to provide a
robust similarity score. Our approach is applied to canvases from the Museo
Nacional del Prado, corroborating the hypothesis that plain weave canvases,
widely used in painting, can be effectively compared even when their thread
densities are similar. The results demonstrate the feasibility and accuracy of
the proposed method, opening new avenues for the analysis of masterpieces.

</details>


### [51] [From Ideal to Real: Unified and Data-Efficient Dense Prediction for Real-World Scenarios](https://arxiv.org/abs/2506.20279)
*Changliang Xia,Chengyou Jia,Zhuohang Dang,Minnan Luo*

Main category: cs.CV

TL;DR: 论文提出了DenseDiT方法，利用生成模型的视觉先验，通过统一策略解决多样化密集预测任务，并在DenseWorld基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有密集预测方法在理想条件下表现良好，但在真实场景中泛化能力有限且数据稀缺，亟需系统性研究。

Method: 提出DenseDiT，结合参数重用机制和两个轻量级分支，自适应整合多尺度上下文，仅需0.1%额外参数。

Result: 在DenseWorld基准测试中，现有方法表现不佳，而DenseDiT仅用0.01%训练数据即取得显著优势。

Conclusion: DenseDiT在真实场景中具有显著实用价值，为密集预测任务提供了高效解决方案。

Abstract: Dense prediction tasks hold significant importance of computer vision, aiming
to learn pixel-wise annotated label for an input image. Despite advances in
this field, existing methods primarily focus on idealized conditions, with
limited generalization to real-world scenarios and facing the challenging
scarcity of real-world data. To systematically study this problem, we first
introduce DenseWorld, a benchmark spanning a broad set of 25 dense prediction
tasks that correspond to urgent real-world applications, featuring unified
evaluation across tasks. Then, we propose DenseDiT, which maximally exploits
generative models' visual priors to perform diverse real-world dense prediction
tasks through a unified strategy. DenseDiT combines a parameter-reuse mechanism
and two lightweight branches that adaptively integrate multi-scale context,
working with less than 0.1% additional parameters. Evaluations on DenseWorld
reveal significant performance drops in existing general and specialized
baselines, highlighting their limited real-world generalization. In contrast,
DenseDiT achieves superior results using less than 0.01% training data of
baselines, underscoring its practical value for real-world deployment. Our
data, and checkpoints and codes are available at
https://xcltql666.github.io/DenseDiTProj

</details>


### [52] [Breaking Spatial Boundaries: Spectral-Domain Registration Guided Hyperspectral and Multispectral Blind Fusion](https://arxiv.org/abs/2506.20293)
*Kunjing Yang,Libin Zheng,Minru Bai,Ting Lu,Leyuan Fang*

Main category: cs.CV

TL;DR: 论文提出了一种从光谱域解决未配准高光谱图像（HSI）和多光谱图像（MSI）融合问题的方法，通过轻量级光谱先验学习网络和盲稀疏融合技术，显著提升了配准和融合效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过空间变换配准HSI和MSI，但因分辨率差异大且处理大尺寸遥感图像耗时，效果不佳。因此，研究转向光谱域解决配准问题。

Method: 1. 开发轻量级SPL网络提取HSI光谱特征并增强MSI光谱分辨率；2. 采用子空间表示和循环训练策略提升配准HSI的光谱精度；3. 提出盲稀疏融合（BSF）方法，利用群稀疏正则化等效促进图像低秩性；4. 使用PAO算法求解BSF模型并分析收敛性。

Result: 模拟和真实数据集实验验证了方法在配准和融合中的有效性，并提升了分类性能。

Conclusion: 该方法通过光谱域配准和盲稀疏融合，显著提高了HSI和MSI融合的效率和精度，同时降低了计算复杂度。

Abstract: The blind fusion of unregistered hyperspectral images (HSIs) and
multispectral images (MSIs) has attracted growing attention recently. To
address the registration challenge, most existing methods employ spatial
transformations on the HSI to achieve alignment with the MSI. However, due to
the substantial differences in spatial resolution of the images, the
performance of these methods is often unsatisfactory. Moreover, the
registration process tends to be time-consuming when dealing with large-sized
images in remote sensing. To address these issues, we propose tackling the
registration problem from the spectral domain. Initially, a lightweight
Spectral Prior Learning (SPL) network is developed to extract spectral features
from the HSI and enhance the spectral resolution of the MSI. Following this,
the obtained image undergoes spatial downsampling to produce the registered
HSI. In this process, subspace representation and cyclic training strategy are
employed to improve spectral accuracy of the registered HSI obtained. Next, we
propose a blind sparse fusion (BSF) method, which utilizes group sparsity
regularization to equivalently promote the low-rankness of the image. This
approach not only circumvents the need for rank estimation, but also reduces
computational complexity. Then, we employ the Proximal Alternating Optimization
(PAO) algorithm to solve the BSF model, and present its convergence analysis.
Finally, extensive numerical experiments on simulated and real datasets are
conducted to verify the effectiveness of our method in registration and fusion.
We also demonstrate its efficacy in enhancing classification performance.

</details>


### [53] [Ctrl-Z Sampling: Diffusion Sampling with Controlled Random Zigzag Explorations](https://arxiv.org/abs/2506.20294)
*Shunqi Mao,Wei Guo,Chaoyi Zhang,Weidong Cai*

Main category: cs.CV

TL;DR: 提出了一种名为Ctrl-Z Sampling的新采样策略，用于在条件生成中检测和逃离局部最优解，提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在条件生成中容易陷入局部最优解，导致全局不一致或条件不匹配的问题。

Method: 通过奖励模型识别局部最优解，注入噪声并回退到更早的状态以逃离，动态交替前向细化和后向探索。

Result: 实验表明，Ctrl-Z Sampling显著提升了生成质量，仅增加约7.6倍的函数评估次数。

Conclusion: Ctrl-Z Sampling是一种模型无关的方法，可与现有扩散框架兼容，有效改善生成结果。

Abstract: Diffusion models have shown strong performance in conditional generation by
progressively denoising Gaussian noise toward a target data distribution. This
denoising process can be interpreted as a form of hill climbing in a learned
latent space, where the model iteratively refines the sample toward regions of
higher probability. However, diffusion models often converge to local optima
that are locally visually coherent yet globally inconsistent or conditionally
misaligned, due to latent space complexity and suboptimal initialization. Prior
efforts attempted to address this by strengthening guidance signals or
manipulating the initial noise distribution. We introduce Controlled Random
Zigzag Sampling (Ctrl-Z Sampling), a novel sampling strategy designed to detect
and escape such local maxima during conditional generation. The method first
identifies potential local maxima using a reward model. Upon detection, it
injects noise and reverts to a previous, noisier state to escape the current
optimization plateau. The reward model then evaluates candidate trajectories,
accepting only those that offer improvement, while progressively deeper retreat
enables stronger escapes when nearby alternatives fail. This controlled random
zigzag process allows dynamic alternation between forward refinement and
backward exploration, enhancing both alignment and visual quality in the
generated outputs. The proposed Ctrl-Z Sampling is model-agnostic and
compatible with existing diffusion frameworks. Experimental results show that
Ctrl-Z Sampling substantially improves generation quality with only around 7.6X
increase in function evaluations.

</details>


### [54] [TDiR: Transformer based Diffusion for Image Restoration Tasks](https://arxiv.org/abs/2506.20302)
*Abbas Anwar,Mohammad Shullar,Ali Arshad Nasir,Mudassir Masood,Saeed Anwar*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的扩散模型，用于图像修复任务，在多个质量指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决因噪声、色偏、模糊和光散射等退化现象导致的图像质量下降问题，提升其在目标检测、地图绘制和分类等下游任务中的适用性。

Method: 开发了一种结合Transformer的扩散模型，用于图像修复任务，并在公开数据集上进行了评估。

Result: 该模型在图像增强、去噪和去雨等任务中表现优于现有深度学习方法。

Conclusion: 扩散模型与Transformer结合能有效提升退化图像质量，增强其在高保真视觉数据需求的下游任务中的实用性。

Abstract: Images captured in challenging environments often experience various forms of
degradation, including noise, color cast, blur, and light scattering. These
effects significantly reduce image quality, hindering their applicability in
downstream tasks such as object detection, mapping, and classification. Our
transformer-based diffusion model was developed to address image restoration
tasks, aiming to improve the quality of degraded images. This model was
evaluated against existing deep learning methodologies across multiple quality
metrics for underwater image enhancement, denoising, and deraining on publicly
available datasets. Our findings demonstrate that the diffusion model, combined
with transformers, surpasses current methods in performance. The results of our
model highlight the efficacy of diffusion models and transformers in improving
the quality of degraded images, consequently expanding their utility in
downstream tasks that require high-fidelity visual data.

</details>


### [55] [Radiomic fingerprints for knee MR images assessment](https://arxiv.org/abs/2506.20306)
*Yaxi Chen,Simin Ni,Shaheer U. Saeed,Aleksandra Ivanova,Rikin Hargunani,Jie Huang,Chaozong Liu,Yipeng Hu*

Main category: cs.CV

TL;DR: 提出了一种动态构建放射组学特征的框架（指纹），通过深度学习模型为每位患者个性化选择特征，提高了诊断准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统放射组学方法使用固定特征集，无法充分代表个体病理变化，导致性能受限。本文旨在通过个性化特征选择提升诊断效果。

Method: 提出放射组学指纹框架，动态为每位患者选择特征，结合低维逻辑回归进行分类。

Result: 在多项诊断任务中表现优于或媲美端到端深度学习模型，同时保持可解释性。

Conclusion: 个性化放射组学特征选择不仅提高了诊断准确性，还增强了临床可解释性和潜在生物标志物发现。

Abstract: Accurate interpretation of knee MRI scans relies on expert clinical judgment,
often with high variability and limited scalability. Existing radiomic
approaches use a fixed set of radiomic features (the signature), selected at
the population level and applied uniformly to all patients. While
interpretable, these signatures are often too constrained to represent
individual pathological variations. As a result, conventional radiomic-based
approaches are found to be limited in performance, compared with recent
end-to-end deep learning (DL) alternatives without using interpretable radiomic
features. We argue that the individual-agnostic nature in current radiomic
selection is not central to its intepretability, but is responsible for the
poor generalization in our application. Here, we propose a novel radiomic
fingerprint framework, in which a radiomic feature set (the fingerprint) is
dynamically constructed for each patient, selected by a DL model. Unlike the
existing radiomic signatures, our fingerprints are derived on a per-patient
basis by predicting the feature relevance in a large radiomic feature pool, and
selecting only those that are predictive of clinical conditions for individual
patients. The radiomic-selecting model is trained simultaneously with a
low-dimensional (considered relatively explainable) logistic regression for
downstream classification. We validate our methods across multiple diagnostic
tasks including general knee abnormalities, anterior cruciate ligament (ACL)
tears, and meniscus tears, demonstrating comparable or superior diagnostic
accuracy relative to state-of-the-art end-to-end DL models. More importantly,
we show that the interpretability inherent in our approach facilitates
meaningful clinical insights and potential biomarker discovery, with detailed
discussion, quantitative and qualitative analysis of real-world clinical cases
to evidence these advantages.

</details>


### [56] [On the Burstiness of Faces in Set](https://arxiv.org/abs/2506.20312)
*Jiong Wang*

Main category: cs.CV

TL;DR: 论文研究了在基于集合的人脸识别（SFR）中普遍存在的突发性现象，并提出三种策略检测突发性人脸，通过调整训练和评估阶段的采样比例或贡献，显著提升了识别性能。


<details>
  <summary>Details</summary>
Motivation: 突发性现象在文本和图像检索中常见，但在SFR中会降低性能，表现为突发性人脸主导训练和评估，影响泛化能力和相似性比较。

Method: 提出基于Quickshift++、特征自相似性和广义最大池化（GMP）的三种策略检测突发性人脸，并在训练和评估阶段调整采样比例；还提出质量感知GMP以增强对低质量人脸的鲁棒性。

Result: 实验证明突发性在SFR中普遍存在，抑制突发性显著提升了识别性能。

Conclusion: 通过检测和抑制突发性人脸，可以有效提升SFR的性能，尤其是在泛化和评估阶段。

Abstract: Burstiness, a phenomenon observed in text and image retrieval, refers to that
particular elements appear more times in a set than a statistically independent
model assumes. We argue that in the context of set-based face recognition
(SFR), burstiness exists widely and degrades the performance in two aspects:
Firstly, the bursty faces, where faces with particular attributes %exist
frequently in a face set, dominate the training instances and dominate the
training face sets and lead to poor generalization ability to unconstrained
scenarios. Secondly, the bursty faces %dominating the evaluation sets interfere
with the similarity comparison in set verification and identification when
evaluation. To detect the bursty faces in a set, we propose three strategies
based on Quickshift++, feature self-similarity, and generalized max-pooling
(GMP). We apply the burst detection results on training and evaluation stages
to enhance the sampling ratios or contributions of the infrequent faces. When
evaluation, we additionally propose the quality-aware GMP that enables
awareness of the face quality and robustness to the low-quality faces for the
original GMP. We give illustrations and extensive experiments on the SFR
benchmarks to demonstrate that burstiness is widespread and suppressing
burstiness considerably improves the recognition performance.

</details>


### [57] [From Codicology to Code: A Comparative Study of Transformer and YOLO-based Detectors for Layout Analysis in Historical Documents](https://arxiv.org/abs/2506.20326)
*Sergio Torres Aguilar*

Main category: cs.CV

TL;DR: 本文评估了五种目标检测架构在三个历史文档数据集上的性能，发现Transformer和CNN-OBB模型在不同复杂度数据集上表现各异，OBB对非笛卡尔布局至关重要。


<details>
  <summary>Details</summary>
Motivation: 研究历史文档布局分析的鲁棒性，因复杂页面组织对自动化处理至关重要。

Method: 比较五种目标检测架构（两种Transformer和三种YOLO变体）在三个数据集上的性能。

Result: Co-DETR在结构化数据集上表现最佳，而YOLOv11x-OBB在复杂数据集上显著优于其他模型。

Conclusion: Transformer适合结构化布局，CNN-OBB模型在复杂文档中表现更优，OBB是建模非笛卡尔布局的关键。

Abstract: Robust Document Layout Analysis (DLA) is critical for the automated
processing and understanding of historical documents with complex page
organizations. This paper benchmarks five state-of-the-art object detection
architectures on three annotated datasets representing a spectrum of
codicological complexity: The e-NDP, a corpus of Parisian medieval registers
(1326-1504); CATMuS, a diverse multiclass dataset derived from various medieval
and modern sources (ca.12th-17th centuries) and HORAE, a corpus of decorated
books of hours (ca.13th-16th centuries). We evaluate two Transformer-based
models (Co-DETR, Grounding DINO) against three YOLO variants (AABB, OBB, and
YOLO-World). Our findings reveal significant performance variations dependent
on model architecture, data set characteristics, and bounding box
representation. In the e-NDP dataset, Co-DETR achieves state-of-the-art results
(0.752 mAP@.50:.95), closely followed by YOLOv11X-OBB (0.721). Conversely, on
the more complex CATMuS and HORAE datasets, the CNN-based YOLOv11x-OBB
significantly outperforms all other models (0.564 and 0.568, respectively).
This study unequivocally demonstrates that using Oriented Bounding Boxes (OBB)
is not a minor refinement but a fundamental requirement for accurately modeling
the non-Cartesian nature of historical manuscripts. We conclude that a key
trade-off exists between the global context awareness of Transformers, ideal
for structured layouts, and the superior generalization of CNN-OBB models for
visually diverse and complex documents.

</details>


### [58] [Feature Hallucination for Self-supervised Action Recognition](https://arxiv.org/abs/2506.20342)
*Lei Wang,Piotr Koniusz*

Main category: cs.CV

TL;DR: 提出了一种深度翻译动作识别框架，通过联合预测动作概念和辅助特征提升识别准确率，并引入两种新的领域特定描述符（ODF和SDF）来丰富特征表示。


<details>
  <summary>Details</summary>
Motivation: 视频中的人类动作理解需要高层次语义推理和多模态特征的有效整合，而现有方法在特征表示和计算效率上存在不足。

Method: 结合RGB视频帧预测动作概念和辅助特征，通过幻觉流推断缺失线索，并引入ODF和SDF描述符。整合多种模态（如光流、骨架数据等），并采用不确定性建模和鲁棒损失函数。

Result: 在Kinetics-400、Kinetics-600和Something-Something V2等多个基准测试中达到最先进性能。

Conclusion: 该框架通过多模态自监督学习有效捕捉细粒度动作动态，兼容多种先进架构，显著提升了动作识别的准确性和鲁棒性。

Abstract: Understanding human actions in videos requires more than raw pixel analysis;
it relies on high-level semantic reasoning and effective integration of
multimodal features. We propose a deep translational action recognition
framework that enhances recognition accuracy by jointly predicting action
concepts and auxiliary features from RGB video frames. At test time,
hallucination streams infer missing cues, enriching feature representations
without increasing computational overhead. To focus on action-relevant regions
beyond raw pixels, we introduce two novel domain-specific descriptors. Object
Detection Features (ODF) aggregate outputs from multiple object detectors to
capture contextual cues, while Saliency Detection Features (SDF) highlight
spatial and intensity patterns crucial for action recognition. Our framework
seamlessly integrates these descriptors with auxiliary modalities such as
optical flow, Improved Dense Trajectories, skeleton data, and audio cues. It
remains compatible with state-of-the-art architectures, including I3D,
AssembleNet, Video Transformer Network, FASTER, and recent models like VideoMAE
V2 and InternVideo2. To handle uncertainty in auxiliary features, we
incorporate aleatoric uncertainty modeling in the hallucination step and
introduce a robust loss function to mitigate feature noise. Our multimodal
self-supervised action recognition framework achieves state-of-the-art
performance on multiple benchmarks, including Kinetics-400, Kinetics-600, and
Something-Something V2, demonstrating its effectiveness in capturing
fine-grained action dynamics.

</details>


### [59] [InvZW: Invariant Feature Learning via Noise-Adversarial Training for Robust Image Zero-Watermarking](https://arxiv.org/abs/2506.20370)
*Abdullah All Tanvir,Xin Zhong*

Main category: cs.CV

TL;DR: 提出了一种基于失真不变特征学习的深度零水印框架，通过优化特征空间中的参考签名实现，无需修改原始图像。


<details>
  <summary>Details</summary>
Motivation: 解决传统水印方法对图像失真敏感的问题，同时保持图像内容不变。

Method: 框架包含两个模块：1）通过噪声对抗学习训练特征提取器，生成对失真不变且语义丰富的表示；2）设计基于学习的多比特零水印方案，将特征投影到优化的参考代码上以匹配目标消息。

Result: 在多种图像数据集和失真条件下，方法在特征稳定性和水印恢复方面达到最优鲁棒性。

Conclusion: 该框架在泛化性和鲁棒性上优于现有自监督和深度水印技术。

Abstract: This paper introduces a novel deep learning framework for robust image
zero-watermarking based on distortion-invariant feature learning. As a
zero-watermarking scheme, our method leaves the original image unaltered and
learns a reference signature through optimization in the feature space. The
proposed framework consists of two key modules. In the first module, a feature
extractor is trained via noise-adversarial learning to generate representations
that are both invariant to distortions and semantically expressive. This is
achieved by combining adversarial supervision against a distortion
discriminator and a reconstruction constraint to retain image content. In the
second module, we design a learning-based multibit zero-watermarking scheme
where the trained invariant features are projected onto a set of trainable
reference codes optimized to match a target binary message. Extensive
experiments on diverse image datasets and a wide range of distortions show that
our method achieves state-of-the-art robustness in both feature stability and
watermark recovery. Comparative evaluations against existing self-supervised
and deep watermarking techniques further highlight the superiority of our
framework in generalization and robustness.

</details>


### [60] [Exploiting Lightweight Hierarchical ViT and Dynamic Framework for Efficient Visual Tracking](https://arxiv.org/abs/2506.20381)
*Ben Kang,Xin Chen,Jie Zhao,Chunjuan Bo,Dong Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: HiT和DyHiT是高效的视觉跟踪模型，通过轻量级Transformer和动态路由技术，在保持高性能的同时提升速度。HiT在NVIDIA Jetson AGX上达到61 fps，AUC为64.6%；DyHiT进一步优化动态场景适应能力，最快达到111 fps。此外，基于DyHiT的动态路由架构，提出了一种无需训练的加速方法，显著提升其他高性能跟踪器的速度。


<details>
  <summary>Details</summary>
Motivation: 解决基于Transformer的视觉跟踪器在资源受限设备上速度慢的问题，提出高效且高性能的跟踪模型。

Method: 1. HiT采用Bridge Module连接轻量级Transformer，增强特征表示；2. 引入双图像位置编码；3. DyHiT通过动态路由分类场景并选择计算路径；4. 提出无需训练的加速方法。

Result: HiT：61 fps，AUC 64.6%；DyHiT：111 fps，AUC 62.4%；加速方法使SeqTrack-B256速度提升2.68倍，AUC保持69.9%。

Conclusion: HiT和DyHiT通过创新设计和动态路由技术，实现了高效且高性能的视觉跟踪，同时提出的加速方法可广泛应用于其他跟踪器。

Abstract: Transformer-based visual trackers have demonstrated significant advancements
due to their powerful modeling capabilities. However, their practicality is
limited on resource-constrained devices because of their slow processing
speeds. To address this challenge, we present HiT, a novel family of efficient
tracking models that achieve high performance while maintaining fast operation
across various devices. The core innovation of HiT lies in its Bridge Module,
which connects lightweight transformers to the tracking framework, enhancing
feature representation quality. Additionally, we introduce a dual-image
position encoding approach to effectively encode spatial information. HiT
achieves an impressive speed of 61 frames per second (fps) on the NVIDIA Jetson
AGX platform, alongside a competitive AUC of 64.6% on the LaSOT benchmark,
outperforming all previous efficient trackers.Building on HiT, we propose
DyHiT, an efficient dynamic tracker that flexibly adapts to scene complexity by
selecting routes with varying computational requirements. DyHiT uses search
area features extracted by the backbone network and inputs them into an
efficient dynamic router to classify tracking scenarios. Based on the
classification, DyHiT applies a divide-and-conquer strategy, selecting
appropriate routes to achieve a superior trade-off between accuracy and speed.
The fastest version of DyHiT achieves 111 fps on NVIDIA Jetson AGX while
maintaining an AUC of 62.4% on LaSOT.Furthermore, we introduce a training-free
acceleration method based on the dynamic routing architecture of DyHiT. This
method significantly improves the execution speed of various high-performance
trackers without sacrificing accuracy. For instance, our acceleration method
enables the state-of-the-art tracker SeqTrack-B256 to achieve a 2.68 times
speedup on an NVIDIA GeForce RTX 2080 Ti GPU while maintaining the same AUC of
69.9% on the LaSOT.

</details>


### [61] [A Novel Large Vision Foundation Model (LVFM)-based Approach for Generating High-Resolution Canopy Height Maps in Plantations for Precision Forestry Management](https://arxiv.org/abs/2506.20388)
*Shen Tan,Xin Zhang,Liangxiu Han,Huaguo Huang,Han Wang*

Main category: cs.CV

TL;DR: 提出了一种基于大型视觉基础模型（LVFM）的高分辨率冠层高度图（CHM）生成方法，用于低成本、高精度监测人工林地上生物量（AGB），并在北京房山区测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统激光雷达方法成本高，而基于RGB图像的深度学习方法在提取冠层高度特征方面存在挑战，因此需要一种更经济高效的解决方案。

Method: 开发了一种新模型，结合特征提取器、自监督特征增强模块和高度估计器，利用1米分辨率的Google Earth图像生成CHM。

Result: 模型在测试中表现优异，平均绝对误差0.09米，均方根误差0.24米，相关性0.78，单木检测成功率超过90%，AGB估计精度高。

Conclusion: 该方法为人工林和天然林的碳汇评估提供了一种可扩展且高效的解决方案。

Abstract: Accurate, cost-effective monitoring of plantation aboveground biomass (AGB)
is crucial for supporting local livelihoods and carbon sequestration
initiatives like the China Certified Emission Reduction (CCER) program.
High-resolution canopy height maps (CHMs) are essential for this, but standard
lidar-based methods are expensive. While deep learning with RGB imagery offers
an alternative, accurately extracting canopy height features remains
challenging. To address this, we developed a novel model for high-resolution
CHM generation using a Large Vision Foundation Model (LVFM). Our model
integrates a feature extractor, a self-supervised feature enhancement module to
preserve spatial details, and a height estimator. Tested in Beijing's Fangshan
District using 1-meter Google Earth imagery, our model outperformed existing
methods, including conventional CNNs. It achieved a mean absolute error of 0.09
m, a root mean square error of 0.24 m, and a correlation of 0.78 against
lidar-based CHMs. The resulting CHMs enabled over 90% success in individual
tree detection, high accuracy in AGB estimation, and effective tracking of
plantation growth, demonstrating strong generalization to non-training areas.
This approach presents a promising, scalable tool for evaluating carbon
sequestration in both plantations and natural forests.

</details>


### [62] [Med-Art: Diffusion Transformer for 2D Medical Text-to-Image Generation](https://arxiv.org/abs/2506.20449)
*Changlu Guo,Anders Nymark Christensen,Morten Rieger Hannemose*

Main category: cs.CV

TL;DR: Med-Art是一个针对医学图像生成的框架，通过结合视觉语言模型和预训练文本到图像模型，解决了医学数据稀缺的问题，并提出了创新的混合级扩散微调方法，取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像生成面临数据集小和医学文本数据稀缺的挑战，需要一种高效的方法来解决这些问题。

Method: Med-Art结合视觉语言模型生成医学图像的视觉描述，并基于DiT架构的PixArt-α模型进行微调，提出了混合级扩散微调（HLDF）方法。

Result: 在FID、KID和下游分类任务中，Med-Art在两个医学图像数据集上达到了最先进的性能。

Conclusion: Med-Art通过创新的方法和有限数据的高效利用，显著提升了医学图像生成的质量和实用性。

Abstract: Text-to-image generative models have achieved remarkable breakthroughs in
recent years. However, their application in medical image generation still
faces significant challenges, including small dataset sizes, and scarcity of
medical textual data. To address these challenges, we propose Med-Art, a
framework specifically designed for medical image generation with limited data.
Med-Art leverages vision-language models to generate visual descriptions of
medical images which overcomes the scarcity of applicable medical textual data.
Med-Art adapts a large-scale pre-trained text-to-image model, PixArt-$\alpha$,
based on the Diffusion Transformer (DiT), achieving high performance under
limited data. Furthermore, we propose an innovative Hybrid-Level Diffusion
Fine-tuning (HLDF) method, which enables pixel-level losses, effectively
addressing issues such as overly saturated colors. We achieve state-of-the-art
performance on two medical image datasets, measured by FID, KID, and downstream
classification performance.

</details>


### [63] [HiWave: Training-Free High-Resolution Image Generation via Wavelet-Based Diffusion Sampling](https://arxiv.org/abs/2506.20452)
*Tobias Vontobel,Seyedmorteza Sadat,Farnood Salehi,Romann M. Weber*

Main category: cs.CV

TL;DR: HiWave是一种无需训练的方法，通过两阶段流程和基于小波的细节增强模块，显著提升超高分辨率图像合成的视觉保真度和结构一致性。


<details>
  <summary>Details</summary>
Motivation: 现有零样本生成技术在超高分辨率图像合成中常产生伪影，如物体重复和空间不连贯，HiWave旨在解决这些问题。

Method: 采用两阶段流程：1) 生成基础图像；2) 使用DDIM反演和小波细节增强模块，保留低频结构并增强高频细节。

Result: HiWave有效减少了伪影，在用户研究中80%的情况下优于现有方法，展示了卓越的感知质量。

Conclusion: HiWave为无需重新训练或架构修改的高质量超高分辨率图像合成提供了有效解决方案。

Abstract: Diffusion models have emerged as the leading approach for image synthesis,
demonstrating exceptional photorealism and diversity. However, training
diffusion models at high resolutions remains computationally prohibitive, and
existing zero-shot generation techniques for synthesizing images beyond
training resolutions often produce artifacts, including object duplication and
spatial incoherence. In this paper, we introduce HiWave, a training-free,
zero-shot approach that substantially enhances visual fidelity and structural
coherence in ultra-high-resolution image synthesis using pretrained diffusion
models. Our method employs a two-stage pipeline: generating a base image from
the pretrained model followed by a patch-wise DDIM inversion step and a novel
wavelet-based detail enhancer module. Specifically, we first utilize inversion
methods to derive initial noise vectors that preserve global coherence from the
base image. Subsequently, during sampling, our wavelet-domain detail enhancer
retains low-frequency components from the base image to ensure structural
consistency, while selectively guiding high-frequency components to enrich fine
details and textures. Extensive evaluations using Stable Diffusion XL
demonstrate that HiWave effectively mitigates common visual artifacts seen in
prior methods, achieving superior perceptual quality. A user study confirmed
HiWave's performance, where it was preferred over the state-of-the-art
alternative in more than 80% of comparisons, highlighting its effectiveness for
high-quality, ultra-high-resolution image synthesis without requiring
retraining or architectural modifications.

</details>


### [64] [A Deep Learning Approach to Identify Rock Bolts in Complex 3D Point Clouds of Underground Mines Captured Using Mobile Laser Scanners](https://arxiv.org/abs/2506.20464)
*Dibyayan Patra,Pasindu Ranasinghe,Bikram Banerjee,Simit Raval*

Main category: cs.CV

TL;DR: 论文提出了一种名为DeepBolt的两阶段深度学习架构，用于在复杂3D点云中自动高效识别岩石螺栓，解决了数据噪声、环境变化和目标物体小且部分遮挡的挑战。


<details>
  <summary>Details</summary>
Motivation: 地下矿井中的岩石螺栓对结构加固至关重要，但人工检测困难且耗时，自动化检测成为必要。现有方法缺乏鲁棒性，无法应对复杂点云环境。

Method: 采用两阶段深度学习架构DeepBolt，专门设计用于处理严重的类别不平衡问题，实现岩石螺栓的自动识别。

Result: DeepBolt在岩石螺栓点的IoU上比现有语义分割模型高出42.5%，分类精度和召回率分别达到96.41%和96.96%。

Conclusion: DeepBolt在复杂地下环境中表现出色，为岩石螺栓的自动化检测提供了高效且鲁棒的解决方案。

Abstract: Rock bolts are crucial components of the subterranean support systems in
underground mines that provide adequate structural reinforcement to the rock
mass to prevent unforeseen hazards like rockfalls. This makes frequent
assessments of such bolts critical for maintaining rock mass stability and
minimising risks in underground mining operations. Where manual surveying of
rock bolts is challenging due to the low light conditions in the underground
mines and the time-intensive nature of the process, automated detection of rock
bolts serves as a plausible solution. To that end, this study focuses on the
automatic identification of rock bolts within medium to large-scale 3D point
clouds obtained from underground mines using mobile laser scanners. Existing
techniques for automated rock bolt identification primarily rely on feature
engineering and traditional machine learning approaches. However, such
techniques lack robustness as these point clouds present several challenges due
to data noise, varying environments, and complex surrounding structures.
Moreover, the target rock bolts are extremely small objects within large-scale
point clouds and are often partially obscured due to the application of
reinforcement shotcrete. Addressing these challenges, this paper proposes an
approach termed DeepBolt, which employs a novel two-stage deep learning
architecture specifically designed for handling severe class imbalance for the
automatic and efficient identification of rock bolts in complex 3D point
clouds. The proposed method surpasses state-of-the-art semantic segmentation
models by up to 42.5% in Intersection over Union (IoU) for rock bolt points.
Additionally, it outperforms existing rock bolt identification techniques,
achieving a 96.41% precision and 96.96% recall in classifying rock bolts,
demonstrating its robustness and effectiveness in complex underground
environments.

</details>


### [65] [AI-assisted radiographic analysis in detecting alveolar bone-loss severity and patterns](https://arxiv.org/abs/2506.20522)
*Chathura Wimalasiri,Piumal Rathnayake,Shamod Wijerathne,Sumudu Rasnayaka,Dhanushka Leuke Bandara,Roshan Ragel,Vajira Thambawita,Isuru Nawinne*

Main category: cs.CV

TL;DR: 提出了一种基于AI的深度学习框架，用于自动检测和量化牙槽骨流失及其模式，通过IOPA放射照片实现高精度评估。


<details>
  <summary>Details</summary>
Motivation: 牙周炎是一种慢性炎症性疾病，严重影响口腔健康和生活质量，准确评估骨流失严重程度和模式对诊断和治疗计划至关重要。

Method: 结合YOLOv8进行牙齿检测和Keypoint R-CNN模型识别解剖标志，利用YOLOv8x-seg模型分割骨水平和牙齿掩模，通过几何分析确定骨流失模式。

Result: 在1000张放射照片数据集上评估，骨流失严重程度检测的类内相关系数达0.80，骨流失模式分类准确率为87%。

Conclusion: 该自动化系统为牙周评估提供了快速、客观且可重复的工具，有望改善早期诊断和个性化治疗计划。

Abstract: Periodontitis, a chronic inflammatory disease causing alveolar bone loss,
significantly affects oral health and quality of life. Accurate assessment of
bone loss severity and pattern is critical for diagnosis and treatment
planning. In this study, we propose a novel AI-based deep learning framework to
automatically detect and quantify alveolar bone loss and its patterns using
intraoral periapical (IOPA) radiographs. Our method combines YOLOv8 for tooth
detection with Keypoint R-CNN models to identify anatomical landmarks, enabling
precise calculation of bone loss severity. Additionally, YOLOv8x-seg models
segment bone levels and tooth masks to determine bone loss patterns (horizontal
vs. angular) via geometric analysis. Evaluated on a large, expertly annotated
dataset of 1000 radiographs, our approach achieved high accuracy in detecting
bone loss severity (intra-class correlation coefficient up to 0.80) and bone
loss pattern classification (accuracy 87%). This automated system offers a
rapid, objective, and reproducible tool for periodontal assessment, reducing
reliance on subjective manual evaluation. By integrating AI into dental
radiographic analysis, our framework has the potential to improve early
diagnosis and personalized treatment planning for periodontitis, ultimately
enhancing patient care and clinical outcomes.

</details>


### [66] [Pay Less Attention to Deceptive Artifacts: Robust Detection of Compressed Deepfakes on Online Social Networks](https://arxiv.org/abs/2506.20548)
*Manyi Li,Renshuai Tao,Yufan Liu,Chuangchuang Tan,Haotong Qin,Bing Li,Yunchao Wei,Yao Zhao*

Main category: cs.CV

TL;DR: PLADA框架通过处理压缩图像的块效应和利用配对与非配对数据，显著提升了在线社交网络中深度伪造图像的检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法忽视了压缩引入的块效应，且主要依赖原始图像，难以应对实际场景。

Method: PLADA包含块效应消除模块（B2E）和开放数据聚合模块（ODA），分别处理块效应和利用多种数据。

Result: 在26个数据集上实验表明，PLADA优于现有方法，尤其在压缩和有限配对数据条件下。

Conclusion: PLADA为开放世界场景提供了鲁棒的深度伪造检测解决方案，并首次将块效应作为关键因素。

Abstract: With the rapid advancement of deep learning, particularly through generative
adversarial networks (GANs) and diffusion models (DMs), AI-generated images, or
``deepfakes", have become nearly indistinguishable from real ones. These images
are widely shared across Online Social Networks (OSNs), raising concerns about
their misuse. Existing deepfake detection methods overlook the ``block effects"
introduced by compression in OSNs, which obscure deepfake artifacts, and
primarily focus on raw images, rarely encountered in real-world scenarios. To
address these challenges, we propose PLADA (Pay Less Attention to Deceptive
Artifacts), a novel framework designed to tackle the lack of paired data and
the ineffective use of compressed images. PLADA consists of two core modules:
Block Effect Eraser (B2E), which uses a dual-stage attention mechanism to
handle block effects, and Open Data Aggregation (ODA), which processes both
paired and unpaired data to improve detection. Extensive experiments across 26
datasets demonstrate that PLADA achieves a remarkable balance in deepfake
detection, outperforming SoTA methods in detecting deepfakes on OSNs, even with
limited paired data and compression. More importantly, this work introduces the
``block effect" as a critical factor in deepfake detection, providing a robust
solution for open-world scenarios. Our code is available at
https://github.com/ManyiLee/PLADA.

</details>


### [67] [Lightweight Multi-Frame Integration for Robust YOLO Object Detection in Videos](https://arxiv.org/abs/2506.20550)
*Yitong Quan,Benjamin Kiefer,Martin Messmer,Andreas Zell*

Main category: cs.CV

TL;DR: 提出一种简单有效的多帧输入策略，利用时间信息提升YOLO检测器在视频中的性能，保持轻量化和实时性。


<details>
  <summary>Details</summary>
Motivation: 解决单帧检测在视频中因运动模糊、遮挡等问题导致的性能下降，同时避免复杂时间模块带来的计算负担。

Method: 将连续多帧堆叠输入YOLO检测器，仅监督目标帧输出，保留架构轻量化。

Result: 在MOT20Det和BOAT360数据集上验证，提升检测鲁棒性，缩小轻量与重型网络差距。

Conclusion: 多帧输入策略有效且高效，贡献BOAT360数据集支持未来研究。

Abstract: Modern image-based object detection models, such as YOLOv7, primarily process
individual frames independently, thus ignoring valuable temporal context
naturally present in videos. Meanwhile, existing video-based detection methods
often introduce complex temporal modules, significantly increasing model size
and computational complexity. In practical applications such as surveillance
and autonomous driving, transient challenges including motion blur, occlusions,
and abrupt appearance changes can severely degrade single-frame detection
performance. To address these issues, we propose a straightforward yet highly
effective strategy: stacking multiple consecutive frames as input to a
YOLO-based detector while supervising only the output corresponding to a single
target frame. This approach leverages temporal information with minimal
modifications to existing architectures, preserving simplicity, computational
efficiency, and real-time inference capability. Extensive experiments on the
challenging MOT20Det and our BOAT360 datasets demonstrate that our method
improves detection robustness, especially for lightweight models, effectively
narrowing the gap between compact and heavy detection networks. Additionally,
we contribute the BOAT360 benchmark dataset, comprising annotated fisheye video
sequences captured from a boat, to support future research in multi-frame video
object detection in challenging real-world scenarios.

</details>


### [68] [AdvMIM: Adversarial Masked Image Modeling for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2506.20563)
*Lei Zhu,Jun Zhou,Rick Siow Mong Goh,Yong Liu*

Main category: cs.CV

TL;DR: 提出了一种对抗性掩码图像建模方法，用于半监督医学图像分割，通过增强监督信号和减少域差距提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer在半监督学习中因标注数据不足而难以有效训练的问题。

Method: 利用掩码图像建模构建辅助域，结合标签和伪标签训练Transformer，并通过对抗训练减少域差距。

Result: 在三个公开医学图像分割数据集上显著优于现有方法。

Conclusion: 该方法有效提升了半监督医学图像分割的性能，代码已开源。

Abstract: Vision Transformer has recently gained tremendous popularity in medical image
segmentation task due to its superior capability in capturing long-range
dependencies. However, transformer requires a large amount of labeled data to
be effective, which hinders its applicability in annotation scarce
semi-supervised learning scenario where only limited labeled data is available.
State-of-the-art semi-supervised learning methods propose combinatorial
CNN-Transformer learning to cross teach a transformer with a convolutional
neural network, which achieves promising results. However, it remains a
challenging task to effectively train the transformer with limited labeled
data. In this paper, we propose an adversarial masked image modeling method to
fully unleash the potential of transformer for semi-supervised medical image
segmentation. The key challenge in semi-supervised learning with transformer
lies in the lack of sufficient supervision signal. To this end, we propose to
construct an auxiliary masked domain from original domain with masked image
modeling and train the transformer to predict the entire segmentation mask with
masked inputs to increase supervision signal. We leverage the original labels
from labeled data and pseudo-labels from unlabeled data to learn the masked
domain. To further benefit the original domain from masked domain, we provide a
theoretical analysis of our method from a multi-domain learning perspective and
devise a novel adversarial training loss to reduce the domain gap between the
original and masked domain, which boosts semi-supervised learning performance.
We also extend adversarial masked image modeling to CNN network. Extensive
experiments on three public medical image segmentation datasets demonstrate the
effectiveness of our method, where our method outperforms existing methods
significantly. Our code is publicly available at
https://github.com/zlheui/AdvMIM.

</details>


### [69] [Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided Sentence Summarization](https://arxiv.org/abs/2506.20567)
*Zhiwang Zhang,Dong Xu,Wanli Ouyang,Chuanqi Tan*

Main category: cs.CV

TL;DR: 提出了一种基于分割与摘要（DaS）的密集视频字幕框架，通过事件提案和两阶段LSTM网络生成描述性句子。


<details>
  <summary>Details</summary>
Motivation: 解决未修剪长视频的密集字幕问题，通过分割视频并利用视觉特征和语义信息生成更准确的描述。

Method: 将视频分割为事件提案，提取视觉特征并生成句子描述，使用两阶段LSTM网络（编码器-解码器）结合分层注意力机制进行摘要。

Result: 在ActivityNet Captions数据集上验证了DaS框架的有效性。

Conclusion: DaS框架通过结合视觉和语义信息，显著提升了密集视频字幕的生成质量。

Abstract: In this work, we propose a division-and-summarization (DaS) framework for
dense video captioning. After partitioning each untrimmed long video as
multiple event proposals, where each event proposal consists of a set of short
video segments, we extract visual feature (e.g., C3D feature) from each segment
and use the existing image/video captioning approach to generate one sentence
description for this segment. Considering that the generated sentences contain
rich semantic descriptions about the whole event proposal, we formulate the
dense video captioning task as a visual cue aided sentence summarization
problem and propose a new two stage Long Short Term Memory (LSTM) approach
equipped with a new hierarchical attention mechanism to summarize all generated
sentences as one descriptive sentence with the aid of visual features.
Specifically, the first-stage LSTM network takes all semantic words from the
generated sentences and the visual features from all segments within one event
proposal as the input, and acts as the encoder to effectively summarize both
semantic and visual information related to this event proposal. The
second-stage LSTM network takes the output from the first-stage LSTM network
and the visual features from all video segments within one event proposal as
the input, and acts as the decoder to generate one descriptive sentence for
this event proposal. Our comprehensive experiments on the ActivityNet Captions
dataset demonstrate the effectiveness of our newly proposed DaS framework for
dense video captioning.

</details>


### [70] [Causal Representation Learning with Observational Grouping for CXR Classification](https://arxiv.org/abs/2506.20582)
*Rajat Rasal,Avinash Kori,Ben Glocker*

Main category: cs.CV

TL;DR: 提出了一种通过分组学习可识别因果表示的方法，用于胸部X光片的疾病分类，提高了模型的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在医学影像中，识别真实的因果关系可以提升任务特定潜在特征的泛化性和鲁棒性。

Method: 通过分组观测数据，利用端到端框架学习可识别的因果表示。

Result: 实验表明，这些因果表示在种族、性别和成像视角的分组下，提高了多分类任务的泛化性和鲁棒性。

Conclusion: 分组学习因果表示是一种有效的方法，可提升医学影像分类任务的性能。

Abstract: Identifiable causal representation learning seeks to uncover the true causal
relationships underlying a data generation process. In medical imaging, this
presents opportunities to improve the generalisability and robustness of
task-specific latent features. This work introduces the concept of grouping
observations to learn identifiable representations for disease classification
in chest X-rays via an end-to-end framework. Our experiments demonstrate that
these causal representations improve generalisability and robustness across
multiple classification tasks when grouping is used to enforce invariance w.r.t
race, sex, and imaging views.

</details>


### [71] [Dense Video Captioning using Graph-based Sentence Summarization](https://arxiv.org/abs/2506.20583)
*Zhiwang Zhang,Dong Xu,Wanli Ouyang,Luping Zhou*

Main category: cs.CV

TL;DR: 论文提出了一种基于图的分割与总结（GPaS）框架，用于密集视频字幕生成，通过分割事件为更短片段并总结描述信息，解决了现有方法在场景变化时表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 现有密集视频字幕方法未充分探索事件时间提案内的场景演变，导致在场景和对象变化时表现不佳。

Method: 提出GPaS框架，分为分割和总结两阶段。总结阶段通过GCN-LSTM交互模块（GLI）利用语义词关系生成描述。

Result: 在ActivityNet Captions和YouCook II数据集上优于现有方法。

Conclusion: GPaS框架通过分割和总结机制，显著提升了密集视频字幕生成的性能。

Abstract: Recently, dense video captioning has made attractive progress in detecting
and captioning all events in a long untrimmed video. Despite promising results
were achieved, most existing methods do not sufficiently explore the scene
evolution within an event temporal proposal for captioning, and therefore
perform less satisfactorily when the scenes and objects change over a
relatively long proposal. To address this problem, we propose a graph-based
partition-and-summarization (GPaS) framework for dense video captioning within
two stages. For the ``partition" stage, a whole event proposal is split into
short video segments for captioning at a finer level. For the ``summarization"
stage, the generated sentences carrying rich description information for each
segment are summarized into one sentence to describe the whole event. We
particularly focus on the ``summarization" stage, and propose a framework that
effectively exploits the relationship between semantic words for summarization.
We achieve this goal by treating semantic words as nodes in a graph and
learning their interactions by coupling Graph Convolutional Network (GCN) and
Long Short Term Memory (LSTM), with the aid of visual cues. Two schemes of
GCN-LSTM Interaction (GLI) modules are proposed for seamless integration of GCN
and LSTM. The effectiveness of our approach is demonstrated via an extensive
comparison with the state-of-the-arts methods on the two benchmarks ActivityNet
Captions dataset and YouCook II dataset.

</details>


### [72] [Learning-Based Distance Estimation for 360° Single-Sensor Setups](https://arxiv.org/abs/2506.20586)
*Yitong Quan,Benjamin Kiefer,Martin Messmer,Andreas Zell*

Main category: cs.CV

TL;DR: 提出了一种基于神经网络的单目360度鱼眼相机距离估计方法，优于传统几何方法和其他学习基线。


<details>
  <summary>Details</summary>
Motivation: 解决全向成像中传统几何方法因镜头畸变和环境变化导致的距离估计不准确问题。

Method: 使用神经网络直接从原始全向输入中学习和推断物体距离，无需精确镜头校准。

Result: 在三个360度数据集上验证，模型在准确性和鲁棒性上优于传统方法和学习基线。

Conclusion: 深度学习在全向距离估计中具有潜力，适用于低成本机器人、自主导航和监控应用。

Abstract: Accurate distance estimation is a fundamental challenge in robotic
perception, particularly in omnidirectional imaging, where traditional
geometric methods struggle with lens distortions and environmental variability.
In this work, we propose a neural network-based approach for monocular distance
estimation using a single 360{\deg} fisheye lens camera. Unlike classical
trigonometric techniques that rely on precise lens calibration, our method
directly learns and infers the distance of objects from raw omnidirectional
inputs, offering greater robustness and adaptability across diverse conditions.
We evaluate our approach on three 360{\deg} datasets (LOAF, ULM360, and a newly
captured dataset Boat360), each representing distinct environmental and sensor
setups. Our experimental results demonstrate that the proposed learning-based
model outperforms traditional geometry-based methods and other learning
baselines in both accuracy and robustness. These findings highlight the
potential of deep learning for real-time omnidirectional distance estimation,
making our approach particularly well-suited for low-cost applications in
robotics, autonomous navigation, and surveillance.

</details>


### [73] [TRIM: A Self-Supervised Video Summarization Framework Maximizing Temporal Relative Information and Representativeness](https://arxiv.org/abs/2506.20588)
*Pritam Mishra,Coloma Ballester,Dimosthenis Karatzas*

Main category: cs.CV

TL;DR: 提出了一种自监督视频摘要模型，无需注意力机制或复杂架构，在SUMME和TVSUM数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 视频内容普及导致对高效摘要的需求增加，但现有方法依赖监督标注或计算昂贵的注意力模型，限制了跨域适用性。

Method: 采用自监督学习框架，结合马尔可夫过程驱动的损失指标和两阶段学习范式，避免使用注意力、RNN或Transformer。

Result: 在SUMME和TVSUM数据集上达到最先进性能，超越所有无监督方法，并与有监督模型媲美。

Conclusion: 展示了无需标注的高效架构潜力，挑战了对复杂模型的依赖，为更通用的视频摘要技术铺平道路。

Abstract: The increasing ubiquity of video content and the corresponding demand for
efficient access to meaningful information have elevated video summarization
and video highlights as a vital research area. However, many state-of-the-art
methods depend heavily either on supervised annotations or on attention-based
models, which are computationally expensive and brittle in the face of
distribution shifts that hinder cross-domain applicability across datasets. We
introduce a pioneering self-supervised video summarization model that captures
both spatial and temporal dependencies without the overhead of attention, RNNs,
or transformers. Our framework integrates a novel set of Markov process-driven
loss metrics and a two-stage self supervised learning paradigm that ensures
both performance and efficiency. Our approach achieves state-of-the-art
performance on the SUMME and TVSUM datasets, outperforming all existing
unsupervised methods. It also rivals the best supervised models, demonstrating
the potential for efficient, annotation-free architectures. This paves the way
for more generalizable video summarization techniques and challenges the
prevailing reliance on complex architectures.

</details>


### [74] [WonderFree: Enhancing Novel View Quality and Cross-View Consistency for 3D Scene Exploration](https://arxiv.org/abs/2506.20590)
*Chaojun Ni,Jie Li,Haoyun Li,Hengyu Liu,Xiaofeng Wang,Zheng Zhu,Guosheng Zhao,Boyuan Wang,Chenxin Li,Guan Huang,Wenjun Mei*

Main category: cs.CV

TL;DR: WonderFree是一个交互式3D场景生成模型，解决了现有方法在探索性和视角一致性上的限制，通过WorldRestorer和ConsistView技术提升渲染质量和全局一致性。


<details>
  <summary>Details</summary>
Motivation: 当前3D生成方法在探索性和视角一致性上存在不足，限制了用户在虚拟世界中的自由探索体验。

Method: 提出WonderFree模型，包含WorldRestorer（消除视觉伪影）和ConsistView（多视角联合恢复）两个关键技术，并通过数据收集管道优化训练数据。

Result: 实验表明，WonderFree在渲染质量和全局一致性上显著优于现有方法，用户偏好率达77.20%。

Conclusion: WonderFree为3D场景生成提供了更高质量和一致性的解决方案，推动了沉浸式虚拟体验的发展。

Abstract: Interactive 3D scene generation from a single image has gained significant
attention due to its potential to create immersive virtual worlds. However, a
key challenge in current 3D generation methods is the limited explorability,
which cannot render high-quality images during larger maneuvers beyond the
original viewpoint, particularly when attempting to move forward into unseen
areas. To address this challenge, we propose WonderFree, the first model that
enables users to interactively generate 3D worlds with the freedom to explore
from arbitrary angles and directions. Specifically, we decouple this challenge
into two key subproblems: novel view quality, which addresses visual artifacts
and floating issues in novel views, and cross-view consistency, which ensures
spatial consistency across different viewpoints. To enhance rendering quality
in novel views, we introduce WorldRestorer, a data-driven video restoration
model designed to eliminate floaters and artifacts. In addition, a data
collection pipeline is presented to automatically gather training data for
WorldRestorer, ensuring it can handle scenes with varying styles needed for 3D
scene generation. Furthermore, to improve cross-view consistency, we propose
ConsistView, a multi-view joint restoration mechanism that simultaneously
restores multiple perspectives while maintaining spatiotemporal coherence.
Experimental results demonstrate that WonderFree not only enhances rendering
quality across diverse viewpoints but also significantly improves global
coherence and consistency. These improvements are confirmed by CLIP-based
metrics and a user study showing a 77.20% preference for WonderFree over
WonderWorld enabling a seamless and immersive 3D exploration experience. The
code, model, and data will be publicly available.

</details>


### [75] [SFNet: Fusion of Spatial and Frequency-Domain Features for Remote Sensing Image Forgery Detection](https://arxiv.org/abs/2506.20599)
*Ji Qi,Xinchang Zhang,Dingqi Ye,Yongjia Ruan,Xin Guo,Shaowen Wang,Haifeng Li*

Main category: cs.CV

TL;DR: SFNet是一种新型的伪造检测框架，通过结合空间和频域特征，提高了遥感图像伪造检测的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的快速发展导致伪造遥感图像难以检测，可能引发错误情报和虚假信息。现有方法依赖单一视觉特征，难以适应多样化的遥感数据。

Method: SFNet采用两个独立的特征提取器分别捕获空间和频域特征，并通过特征映射和融合模块（CBAM注意力）对齐和优化多域特征。

Result: 在三个数据集上，SFNet的准确率比现有方法提高了4%-15.18%，并表现出强大的泛化能力。

Conclusion: SFNet通过多域特征融合显著提升了伪造检测性能，适用于多样化的遥感数据。

Abstract: The rapid advancement of generative artificial intelligence is producing fake
remote sensing imagery (RSI) that is increasingly difficult to detect,
potentially leading to erroneous intelligence, fake news, and even conspiracy
theories. Existing forgery detection methods typically rely on single visual
features to capture predefined artifacts, such as spatial-domain cues to detect
forged objects like roads or buildings in RSI, or frequency-domain features to
identify artifacts from up-sampling operations in adversarial generative
networks (GANs). However, the nature of artifacts can significantly differ
depending on geographic terrain, land cover types, or specific features within
the RSI. Moreover, these complex artifacts evolve as generative models become
more sophisticated. In short, over-reliance on a single visual cue makes
existing forgery detectors struggle to generalize across diverse remote sensing
data. This paper proposed a novel forgery detection framework called SFNet,
designed to identify fake images in diverse remote sensing data by leveraging
spatial and frequency domain features. Specifically, to obtain rich and
comprehensive visual information, SFNet employs two independent feature
extractors to capture spatial and frequency domain features from input RSIs. To
fully utilize the complementary domain features, the domain feature mapping
module and the hybrid domain feature refinement module(CBAM attention) of SFNet
are designed to successively align and fuse the multi-domain features while
suppressing redundant information. Experiments on three datasets show that
SFNet achieves an accuracy improvement of 4%-15.18% over the state-of-the-art
RS forgery detection methods and exhibits robust generalization capabilities.
The code is available at https://github.com/GeoX-Lab/RSTI/tree/main/SFNet.

</details>


### [76] [Video Perception Models for 3D Scene Synthesis](https://arxiv.org/abs/2506.20601)
*Rui Huang,Guangyao Zhai,Zuria Bauer,Marc Pollefeys,Federico Tombari,Leonidas Guibas,Gao Huang,Francis Engelmann*

Main category: cs.CV

TL;DR: VIPScene利用视频生成模型的3D物理世界常识知识，通过结合文本和图像提示，实现高真实性和结构一致性的3D场景合成。


<details>
  <summary>Details</summary>
Motivation: 传统3D场景合成需要专家知识和大量手动操作，自动化该过程对建筑设计、机器人模拟等领域有重要意义。现有方法（如LLMs或图像生成模型）在3D空间推理或多视角一致性上存在局限。

Method: VIPScene结合视频生成、前馈3D重建和开放词汇感知模型，通过语义和几何分析实现场景合成，并引入FPVScore评估一致性和合理性。

Result: 实验表明VIPScene显著优于现有方法，且能泛化到多样场景。

Conclusion: VIPScene通过视频生成模型的3D常识知识，解决了现有方法的局限性，实现了高真实性和一致性的场景合成。

Abstract: Traditionally, 3D scene synthesis requires expert knowledge and significant
manual effort. Automating this process could greatly benefit fields such as
architectural design, robotics simulation, virtual reality, and gaming. Recent
approaches to 3D scene synthesis often rely on the commonsense reasoning of
large language models (LLMs) or strong visual priors of modern image generation
models. However, current LLMs demonstrate limited 3D spatial reasoning ability,
which restricts their ability to generate realistic and coherent 3D scenes.
Meanwhile, image generation-based methods often suffer from constraints in
viewpoint selection and multi-view inconsistencies. In this work, we present
Video Perception models for 3D Scene synthesis (VIPScene), a novel framework
that exploits the encoded commonsense knowledge of the 3D physical world in
video generation models to ensure coherent scene layouts and consistent object
placements across views. VIPScene accepts both text and image prompts and
seamlessly integrates video generation, feedforward 3D reconstruction, and
open-vocabulary perception models to semantically and geometrically analyze
each object in a scene. This enables flexible scene synthesis with high realism
and structural consistency. For more precise analysis, we further introduce
First-Person View Score (FPVScore) for coherence and plausibility evaluation,
utilizing continuous first-person perspective to capitalize on the reasoning
ability of multimodal large language models. Extensive experiments show that
VIPScene significantly outperforms existing methods and generalizes well across
diverse scenarios. The code will be released.

</details>


### [77] [Shape2Animal: Creative Animal Generation from Natural Silhouettes](https://arxiv.org/abs/2506.20616)
*Quoc-Duy Tran,Anh-Tuan Vo,Dinh-Khoi Vo,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: Shape2Animal框架通过重新解释自然物体轮廓（如云、石头或火焰）为动物形态，模拟人类的pareidolia现象。


<details>
  <summary>Details</summary>
Motivation: 模仿人类在模糊刺激中感知有意义模式的能力，为视觉叙事、教育内容、数字艺术和交互媒体设计提供新机会。

Method: 使用开放词汇分割提取物体轮廓，通过视觉语言模型解释语义合适的动物概念，并利用文本到图像扩散模型合成符合输入形状的动物图像。

Result: 在多样化真实输入上验证了Shape2Animal的鲁棒性和创造力。

Conclusion: Shape2Animal为视觉创意领域提供了新的可能性。

Abstract: Humans possess a unique ability to perceive meaningful patterns in ambiguous
stimuli, a cognitive phenomenon known as pareidolia. This paper introduces
Shape2Animal framework to mimics this imaginative capacity by reinterpreting
natural object silhouettes, such as clouds, stones, or flames, as plausible
animal forms. Our automated framework first performs open-vocabulary
segmentation to extract object silhouette and interprets semantically
appropriate animal concepts using vision-language models. It then synthesizes
an animal image that conforms to the input shape, leveraging text-to-image
diffusion model and seamlessly blends it into the original scene to generate
visually coherent and spatially consistent compositions. We evaluated
Shape2Animal on a diverse set of real-world inputs, demonstrating its
robustness and creative potential. Our Shape2Animal can offer new opportunities
for visual storytelling, educational content, digital art, and interactive
media design. Our project page is here: https://shape2image.github.io

</details>


### [78] [Joint attitude estimation and 3D neural reconstruction of non-cooperative space objects](https://arxiv.org/abs/2506.20638)
*Clément Forray,Pauline Delporte,Nicolas Delaygue,Florence Genin,Dawa Derksen*

Main category: cs.CV

TL;DR: 利用NeRF技术从模拟图像中重建非合作空间物体的3D模型，重点优化相机姿态，实验表明逐帧训练效果最佳。


<details>
  <summary>Details</summary>
Motivation: 提升空间态势感知能力，支持主动碎片清除、在轨维护和异常检测等应用。

Method: 使用NeRF进行3D重建，联合优化相机姿态，采用逐帧训练和正则化防止姿态突变。

Result: 实验显示逐帧训练能实现最准确的3D重建。

Conclusion: 优化相机姿态和逐帧训练是提升非合作空间物体3D重建精度的关键。

Abstract: Obtaining a better knowledge of the current state and behavior of objects
orbiting Earth has proven to be essential for a range of applications such as
active debris removal, in-orbit maintenance, or anomaly detection. 3D models
represent a valuable source of information in the field of Space Situational
Awareness (SSA). In this work, we leveraged Neural Radiance Fields (NeRF) to
perform 3D reconstruction of non-cooperative space objects from simulated
images. This scenario is challenging for NeRF models due to unusual camera
characteristics and environmental conditions : mono-chromatic images, unknown
object orientation, limited viewing angles, absence of diffuse lighting etc. In
this work we focus primarly on the joint optimization of camera poses alongside
the NeRF. Our experimental results show that the most accurate 3D
reconstruction is achieved when training with successive images one-by-one. We
estimate camera poses by optimizing an uniform rotation and use regularization
to prevent successive poses from being too far apart.

</details>


### [79] [MMSearch-R1: Incentivizing LMMs to Search](https://arxiv.org/abs/2506.20670)
*Jinming Wu,Zihao Deng,Wei Li,Yiding Liu,Bo You,Bo Li,Zejun Ma,Ziwei Liu*

Main category: cs.CV

TL;DR: MMSearch-R1是一个端到端强化学习框架，使大型多模态模型（LMMs）能够在现实互联网环境中按需进行多轮搜索，整合图像和文本搜索工具，并通过奖励机制优化搜索行为。


<details>
  <summary>Details</summary>
Motivation: 现实世界信息复杂且动态变化，现有检索增强生成（RAG）和提示工程搜索代理方法存在效率低下或搜索行为过度的问题。

Method: 提出MMSearch-R1框架，结合图像和文本搜索工具，通过基于结果的奖励和搜索惩罚机制指导模型决策。使用半自动化流程收集多模态搜索VQA数据集，并筛选平衡子集以训练高效搜索行为。

Result: 实验表明，MMSearch-R1在知识密集和信息寻求VQA任务中优于同规模RAG基线，并减少30%以上的搜索调用，性能与更大RAG模型相当。

Conclusion: MMSearch-R1为多模态搜索研究提供了高效且按需的解决方案，并提供了可操作的实证分析。

Abstract: Robust deployment of large multimodal models (LMMs) in real-world scenarios
requires access to external knowledge sources, given the complexity and dynamic
nature of real-world information. Existing approaches such as
retrieval-augmented generation (RAG) and prompt engineered search agents rely
on rigid pipelines, often leading to inefficient or excessive search behaviors.
We present MMSearch-R1, the first end-to-end reinforcement learning framework
that enables LMMs to perform on-demand, multi-turn search in real-world
Internet environments. Our framework integrates both image and text search
tools, allowing the model to reason about when and how to invoke them guided by
an outcome-based reward with a search penalty. To support training, We collect
a multimodal search VQA dataset through a semi-automated pipeline that covers
diverse visual and textual knowledge needs and curate a search-balanced subset
with both search-required and search-free samples, which proves essential for
shaping efficient and on-demand search behavior. Extensive experiments on
knowledge-intensive and info-seeking VQA tasks show that our model not only
outperforms RAG-based baselines of the same model size, but also matches the
performance of a larger RAG-based model while reducing search calls by over
30%. We further analyze key empirical findings to offer actionable insights for
advancing research in multimodal search.

</details>


### [80] [Disentangled representations of microscopy images](https://arxiv.org/abs/2506.20649)
*Jacopo Dapueto,Vito Paolo Pastore,Nicoletta Noceti,Francesca Odone*

Main category: cs.CV

TL;DR: 论文提出了一种解耦表示学习（DRL）方法，以提高显微镜图像分类模型的可解释性，并在三个不同领域的基准数据集上验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 显微镜图像分析在诊断、合成工程和环境监测中至关重要，但深度学习模型的可解释性仍是一个挑战。

Method: 采用解耦表示学习（DRL）框架，通过从合成数据中学习表示，提升模型的可解释性。

Result: 在浮游生物、酵母液泡和人类细胞三个领域的基准数据集上，DRL框架在准确性和可解释性之间取得了良好平衡。

Conclusion: DRL方法为显微镜图像分类提供了一种兼具准确性和可解释性的解决方案。

Abstract: Microscopy image analysis is fundamental for different applications, from
diagnosis to synthetic engineering and environmental monitoring. Modern
acquisition systems have granted the possibility to acquire an escalating
amount of images, requiring a consequent development of a large collection of
deep learning-based automatic image analysis methods. Although deep neural
networks have demonstrated great performance in this field, interpretability,
an essential requirement for microscopy image analysis, remains an open
challenge.
  This work proposes a Disentangled Representation Learning (DRL) methodology
to enhance model interpretability for microscopy image classification.
Exploiting benchmark datasets from three different microscopic image domains
(plankton, yeast vacuoles, and human cells), we show how a DRL framework, based
on transferring a representation learnt from synthetic data, can provide a good
trade-off between accuracy and interpretability in this domain.

</details>


### [81] [IPFormer: Visual 3D Panoptic Scene Completion with Context-Adaptive Instance Proposals](https://arxiv.org/abs/2506.20671)
*Markus Gross,Aya Fahmy,Danit Niwattananan,Dominik Muhle,Rui Song,Daniel Cremers,Henri Meeß*

Main category: cs.CV

TL;DR: IPFormer提出了一种基于视觉的3D全景场景补全方法，通过动态实例提案和注意力机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在测试时静态查询的限制，以及基于相机图像的PSC研究不足的问题。

Method: IPFormer利用图像上下文动态初始化实例提案，并通过注意力编码解码优化语义实例-体素关系。

Result: 在PQ$^\dagger$和PQ-All指标上超越现有方法，运行时间减少14倍以上，动态提案带来显著性能提升。

Conclusion: IPFormer通过动态实例提案和注意力机制，为基于视觉的3D全景场景补全提供了创新解决方案。

Abstract: Semantic Scene Completion (SSC) has emerged as a pivotal approach for jointly
learning scene geometry and semantics, enabling downstream applications such as
navigation in mobile robotics. The recent generalization to Panoptic Scene
Completion (PSC) advances the SSC domain by integrating instance-level
information, thereby enhancing object-level sensitivity in scene understanding.
While PSC was introduced using LiDAR modality, methods based on camera images
remain largely unexplored. Moreover, recent Transformer-based SSC approaches
utilize a fixed set of learned queries to reconstruct objects within the scene
volume. Although these queries are typically updated with image context during
training, they remain static at test time, limiting their ability to
dynamically adapt specifically to the observed scene. To overcome these
limitations, we propose IPFormer, the first approach that leverages
context-adaptive instance proposals at train and test time to address
vision-based 3D Panoptic Scene Completion. Specifically, IPFormer adaptively
initializes these queries as panoptic instance proposals derived from image
context and further refines them through attention-based encoding and decoding
to reason about semantic instance-voxel relationships. Experimental results
show that our approach surpasses state-of-the-art methods in overall panoptic
metrics PQ$^\dagger$ and PQ-All, matches performance in individual metrics, and
achieves a runtime reduction exceeding 14$\times$. Furthermore, our ablation
studies reveal that dynamically deriving instance proposals from image context,
as opposed to random initialization, leads to a 3.62% increase in PQ-All and a
remarkable average improvement of 18.65% in combined Thing-metrics. These
results highlight our introduction of context-adaptive instance proposals as a
pioneering effort in addressing vision-based 3D Panoptic Scene Completion.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [82] [MAIZX: A Carbon-Aware Framework for Optimizing Cloud Computing Emissions](https://arxiv.org/abs/2506.19972)
*Federico Ruilova,Ernst Gunnar Gran,Sven-Arne Reinemo*

Main category: cs.DC

TL;DR: MAIZX框架通过动态资源排名优化云操作，减少碳排放，测试中CO2排放减少85.68%。


<details>
  <summary>Details</summary>
Motivation: 云计算的高能耗和碳排放问题日益严重，尤其是私有云基础设施的能效和透明度需求迫切。

Method: MAIZX框架利用实时和预测的碳强度、PUE和能耗数据，通过灵活排名算法优化资源分配。

Result: 在分布式数据中心测试中，MAIZX显著减少碳排放，并展示出可扩展性和有效性。

Conclusion: MAIZX为提升气候性能潜力提供了强大工具，同时保持运营效率。

Abstract: Cloud computing drives innovation but also poses significant environmental
challenges due to its high-energy consumption and carbon emissions. Data
centers account for 2-4% of global energy usage, and the ICT sector's share of
electricity consumption is projected to reach 40% by 2040. As the goal of
achieving net-zero emissions by 2050 becomes increasingly urgent, there is a
growing need for more efficient and transparent solutions, particularly for
private cloud infrastructures, which are utilized by 87% of organizations,
despite the dominance of public-cloud systems.
  This study evaluates the MAIZX framework, designed to optimize cloud
operations and reduce carbon footprint by dynamically ranking resources,
including data centers, edge computing nodes, and multi-cloud environments,
based on real-time and forecasted carbon intensity, Power Usage Effectiveness
(PUE), and energy consumption. Leveraging a flexible ranking algorithm, MAIZX
achieved an 85.68% reduction in CO2 emissions compared to baseline hypervisor
operations. Tested across geographically distributed data centers, the
framework demonstrates scalability and effectiveness, directly interfacing with
hypervisors to optimize workloads in private, hybrid, and multi-cloud
environments. MAIZX integrates real-time data on carbon intensity, power
consumption, and carbon footprint, as well as forecasted values, into cloud
management, providing a robust tool for enhancing climate performance potential
while maintaining operational efficiency.

</details>


### [83] [On the $h$-majority dynamics with many opinions](https://arxiv.org/abs/2506.20218)
*Francesco d'Amore,Niccolò D'Archivio,George Giakkoupis,Emanuele Natale*

Main category: cs.DC

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present the first upper bound on the convergence time to consensus of the
well-known $h$-majority dynamics with $k$ opinions, in the synchronous setting,
for $h$ and $k$ that are both non-constant values.
  We suppose that, at the beginning of the process, there is some initial
additive bias towards some plurality opinion, that is, there is an opinion that
is supported by $x$ nodes while any other opinion is supported by strictly
fewer nodes.
  We prove that, with high probability, if the bias is $\omega(\sqrt{x})$ and
the initial plurality opinion is supported by at least $x = \omega(\log n)$
nodes, then the process converges to plurality consensus in $O(\log n)$ rounds
whenever $h = \omega(n \log n / x)$.
  A main corollary is the following: if $k = o(n / \log n)$ and the process
starts from an almost-balanced configuration with an initial bias of magnitude
$\omega(\sqrt{n/k})$ towards the initial plurality opinion, then any function
$h = \omega(k \log n)$ suffices to guarantee convergence to consensus in
$O(\log n)$ rounds, with high probability.
  Our upper bound shows that the lower bound of $\Omega(k / h^2)$ rounds to
reach consensus given by Becchetti et al.\ (2017) cannot be pushed further than
$\widetilde{\Omega}(k / h)$.
  Moreover, the bias we require is asymptotically smaller than the
$\Omega(\sqrt{n\log n})$ bias that guarantees plurality consensus in the
$3$-majority dynamics: in our case, the required bias is at most any
(arbitrarily small) function in $\omega(\sqrt{x})$ for any value of $k \ge 2$.

</details>


### [84] [PAT: a new algorithm for all-gather and reduce-scatter operations at scale](https://arxiv.org/abs/2506.20252)
*Sylvain Jeaugey*

Main category: cs.DC

TL;DR: 提出了一种名为PAT的新算法，用于高效实现all-gather和reduce-scatter操作，优化NCCL库性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有环形算法在小规模或大规模操作中因线性延迟导致的性能不佳问题。

Method: PAT算法支持任意数量的节点，具有对数级网络传输次数，最小化长距离通信，且内部缓冲区需求为对数级。

Result: PAT算法在小规模操作中表现优异，显著提升性能。

Conclusion: PAT算法为NCCL库提供了一种高效的替代方案，特别适用于环形算法效率低下的场景。

Abstract: This paper describes a new algorithm called PAT, for Parallel Aggregated
Trees, and which can be used to implement all-gather and reduce-scatter
operations. This algorithm works on any number of ranks, has a logarithmic
number of network transfers for small size operations, minimizes long-distance
communication, and requires a logarithmic amount of internal buffers,
independently from the total operation size. It is aimed at improving the
performance of the NCCL library in cases where the ring algorithm would be
inefficient, as its linear latency would show poor performance for small sizes
and/or at scale.

</details>


### [85] [WattsOnAI: Measuring, Analyzing, and Visualizing Energy and Carbon Footprint of AI Workloads](https://arxiv.org/abs/2506.20535)
*Hongzhen Huang,Kunming Zhang,Hanlong Liao,Kui Wu,Guoming Tang*

Main category: cs.DC

TL;DR: WattsOnAI是一个用于测量、分析和可视化AI工作负载能耗、碳排放等的软件工具包，旨在解决现有工具的局限性，推动绿色AI实践。


<details>
  <summary>Details</summary>
Motivation: AI（尤其是大语言模型）的快速发展引发了对其能耗和碳排放的担忧，但现有工具缺乏系统性指标整合和相关分析支持。

Method: WattsOnAI通过集成现有AI框架，提供标准化报告和细粒度时间序列数据，支持能耗、硬件性能等指标的测量与分析。

Result: 该工具支持硬件指标与模型性能的深度关联分析，有助于瓶颈识别和性能优化，并促进绿色AI实践。

Conclusion: WattsOnAI填补了现有工具的不足，鼓励研究社区在AI性能之外关注环境影响，推动可持续AI发展。

Abstract: The rapid advancement of AI, particularly large language models (LLMs), has
raised significant concerns about the energy use and carbon emissions
associated with model training and inference. However, existing tools for
measuring and reporting such impacts are often fragmented, lacking systematic
metric integration and offering limited support for correlation analysis among
them. This paper presents WattsOnAI, a comprehensive software toolkit for the
measurement, analysis, and visualization of energy use, power draw, hardware
performance, and carbon emissions across AI workloads. By seamlessly
integrating with existing AI frameworks, WattsOnAI offers standardized reports
and exports fine-grained time-series data to support benchmarking and
reproducibility in a lightweight manner. It further enables in-depth
correlation analysis between hardware metrics and model performance and thus
facilitates bottleneck identification and performance enhancement. By
addressing critical limitations in existing tools, WattsOnAI encourages the
research community to weigh environmental impact alongside raw performance of
AI workloads and advances the shift toward more sustainable "Green AI"
practices. The code is available at https://github.com/SusCom-Lab/WattsOnAI.

</details>


### [86] [SuperSONIC: Cloud-Native Infrastructure for ML Inferencing](https://arxiv.org/abs/2506.20657)
*Dmitry Kondratyev,Benedikt Riedel,Yuan-Tang Chou,Miles Cochran-Branson,Noah Paladino,David Schultz,Mia Liu,Javier Duarte,Philip Harris,Shih-Chieh Hsu*

Main category: cs.DC

TL;DR: SONIC和SuperSONIC通过将机器学习推理卸载到协处理器，优化资源利用，提升数据处理效率，适用于高能物理和多信使天体物理等领域。


<details>
  <summary>Details</summary>
Motivation: 随着数据速率和机器学习算法的复杂性增加，科学实验对计算资源的需求激增，需要高效的计算解决方案。

Method: 采用SONIC方法，开发SuperSONIC项目，利用Kubernetes集群和GPU加速，通过NVIDIA Triton Inference Server标准化通信和优化性能。

Result: SuperSONIC已成功部署于多个大型科学实验，如CERN LHC、IceCube和LIGO，并在多个机构的Kubernetes集群上测试。

Conclusion: SuperSONIC为云原生时代提供了可重用、可配置的框架，提升了跨领域和行业的加速器推理部署效率。

Abstract: The increasing computational demand from growing data rates and complex
machine learning (ML) algorithms in large-scale scientific experiments has
driven the adoption of the Services for Optimized Network Inference on
Coprocessors (SONIC) approach. SONIC accelerates ML inference by offloading it
to local or remote coprocessors to optimize resource utilization. Leveraging
its portability to different types of coprocessors, SONIC enhances data
processing and model deployment efficiency for cutting-edge research in high
energy physics (HEP) and multi-messenger astrophysics (MMA). We developed the
SuperSONIC project, a scalable server infrastructure for SONIC, enabling the
deployment of computationally intensive tasks to Kubernetes clusters equipped
with graphics processing units (GPUs). Using NVIDIA Triton Inference Server,
SuperSONIC decouples client workflows from server infrastructure, standardizing
communication, optimizing throughput, load balancing, and monitoring.
SuperSONIC has been successfully deployed for the CMS and ATLAS experiments at
the CERN Large Hadron Collider (LHC), the IceCube Neutrino Observatory
(IceCube), and the Laser Interferometer Gravitational-Wave Observatory (LIGO)
and tested on Kubernetes clusters at Purdue University, the National Research
Platform (NRP), and the University of Chicago. SuperSONIC addresses the
challenges of the Cloud-native era by providing a reusable, configurable
framework that enhances the efficiency of accelerator-based inference
deployment across diverse scientific domains and industries.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [87] [Achieving Trustworthy Real-Time Decision Support Systems with Low-Latency Interpretable AI Models](https://arxiv.org/abs/2506.20018)
*Zechun Deng,Ziwei Liu,Ziqian Bi,Junhao Song,Chia Xin Liang,Joe Yeong,Junfeng Hao*

Main category: cs.AI

TL;DR: 本文探讨了利用低延迟AI模型的实时决策支持系统，结合了整体AI驱动工具、边缘物联网技术及人机协作方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决资源有限情况下，如何利用大型语言模型等技术提升决策效率。

Method: 通过综述技术发展（如DeLLMa、模型压缩、边缘设备分析改进）和适应性框架，提出开发策略和应用领域。

Result: 提供了高效灵活AI支持系统的实用视角，并指出未来发展方向。

Conclusion: AI有望重塑实时决策支持，为这一快速发展的领域奠定未来突破基础。

Abstract: This paper investigates real-time decision support systems that leverage
low-latency AI models, bringing together recent progress in holistic AI-driven
decision tools, integration with Edge-IoT technologies, and approaches for
effective human-AI teamwork. It looks into how large language models can assist
decision-making, especially when resources are limited. The research also
examines the effects of technical developments such as DeLLMa, methods for
compressing models, and improvements for analytics on edge devices, while also
addressing issues like limited resources and the need for adaptable frameworks.
Through a detailed review, the paper offers practical perspectives on
development strategies and areas of application, adding to the field by
pointing out opportunities for more efficient and flexible AI-supported
systems. The conclusions set the stage for future breakthroughs in this
fast-changing area, highlighting how AI can reshape real-time decision support.

</details>


### [88] [Accurate and Energy Efficient: Local Retrieval-Augmented Generation Models Outperform Commercial Large Language Models in Medical Tasks](https://arxiv.org/abs/2506.20009)
*Konstantinos Vrettos,Michail E. Klontzas*

Main category: cs.AI

TL;DR: 研究开发了一种可定制的RAG框架，用于医疗任务，其性能和能耗优于商业LLM。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在医疗领域的应用带来的环境和伦理问题，开发可持续的解决方案。

Method: 开发了可监控能耗和CO2排放的RAG框架，并基于开源LLM构建模型，与商业模型对比。

Result: 自定义RAG模型在准确性和能耗上优于商业模型，llama3.1-RAG表现最佳。

Conclusion: 本地LLM开发的RAG在医疗任务中优于商业LLM，且更环保。

Abstract: Background The increasing adoption of Artificial Intelligence (AI) in
healthcare has sparked growing concerns about its environmental and ethical
implications. Commercial Large Language Models (LLMs), such as ChatGPT and
DeepSeek, require substantial resources, while the utilization of these systems
for medical purposes raises critical issues regarding patient privacy and
safety. Methods We developed a customizable Retrieval-Augmented Generation
(RAG) framework for medical tasks, which monitors its energy usage and CO2
emissions. This system was then used to create RAGs based on various
open-source LLMs. The tested models included both general purpose models like
llama3.1:8b and medgemma-4b-it, which is medical-domain specific. The best RAGs
performance and energy consumption was compared to DeepSeekV3-R1 and OpenAIs
o4-mini model. A dataset of medical questions was used for the evaluation.
Results Custom RAG models outperformed commercial models in accuracy and energy
consumption. The RAG model built on llama3.1:8B achieved the highest accuracy
(58.5%) and was significantly better than other models, including o4-mini and
DeepSeekV3-R1. The llama3.1-RAG also exhibited the lowest energy consumption
and CO2 footprint among all models, with a Performance per kWh of 0.52 and a
total CO2 emission of 473g. Compared to o4-mini, the llama3.1-RAG achieved 2.7x
times more accuracy points per kWh and 172% less electricity usage while
maintaining higher accuracy. Conclusion Our study demonstrates that local LLMs
can be leveraged to develop RAGs that outperform commercial, online LLMs in
medical tasks, while having a smaller environmental impact. Our modular
framework promotes sustainable AI development, reducing electricity usage and
aligning with the UNs Sustainable Development Goals.

</details>


### [89] [Persona-Assigned Large Language Models Exhibit Human-Like Motivated Reasoning](https://arxiv.org/abs/2506.20020)
*Saloni Dash,Amélie Reymond,Emma S. Spiro,Aylin Caliskan*

Main category: cs.AI

TL;DR: 研究发现，大型语言模型（LLMs）在分配特定身份角色后，会表现出类似人类的动机性推理，导致判断偏差，且现有提示方法难以纠正。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs是否会在身份角色影响下表现出动机性推理，类似人类的认知偏差，从而影响社会关键议题的讨论。

Method: 通过为8种LLMs分配4种政治和社会人口属性角色，测试其在信息真实性辨别和科学证据评估任务中的表现。

Result: 身份角色使LLMs的真实性辨别能力下降9%，政治身份角色在科学证据评估中表现出90%的倾向性。提示去偏方法效果有限。

Conclusion: LLMs表现出难以纠正的人类式动机性推理，可能加剧身份一致性推理问题。

Abstract: Reasoning in humans is prone to biases due to underlying motivations like
identity protection, that undermine rational decision-making and judgment. This
motivated reasoning at a collective level can be detrimental to society when
debating critical issues such as human-driven climate change or vaccine safety,
and can further aggravate political polarization. Prior studies have reported
that large language models (LLMs) are also susceptible to human-like cognitive
biases, however, the extent to which LLMs selectively reason toward
identity-congruent conclusions remains largely unexplored. Here, we investigate
whether assigning 8 personas across 4 political and socio-demographic
attributes induces motivated reasoning in LLMs. Testing 8 LLMs (open source and
proprietary) across two reasoning tasks from human-subject studies -- veracity
discernment of misinformation headlines and evaluation of numeric scientific
evidence -- we find that persona-assigned LLMs have up to 9% reduced veracity
discernment relative to models without personas. Political personas
specifically, are up to 90% more likely to correctly evaluate scientific
evidence on gun control when the ground truth is congruent with their induced
political identity. Prompt-based debiasing methods are largely ineffective at
mitigating these effects. Taken together, our empirical findings are the first
to suggest that persona-assigned LLMs exhibit human-like motivated reasoning
that is hard to mitigate through conventional debiasing prompts -- raising
concerns of exacerbating identity-congruent reasoning in both LLMs and humans.

</details>


### [90] [Language Modeling by Language Models](https://arxiv.org/abs/2506.20249)
*Junyan Cheng,Peter Clark,Kyle Richardson*

Main category: cs.AI

TL;DR: 利用多智能体LLM模拟研究过程，提出Genesys系统，通过遗传编程生成新架构设计，验证其性能优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 探索是否能用LLM模拟发现新语言模型架构的过程，提高研究效率。

Method: 采用多智能体LLM模拟研究阶段，结合遗传编程和Ladder of Scales方法，逐步验证设计。

Result: 生成1,162个新设计，其中1,062个通过验证，部分设计性能优于GPT2和Mamba2。

Conclusion: Genesys系统在自主发现新架构方面具有潜力，为高效研究提供了新思路。

Abstract: Can we leverage LLMs to model the process of discovering novel language model
(LM) architectures? Inspired by real research, we propose a multi-agent LLM
approach that simulates the conventional stages of research, from ideation and
literature search (proposal stage) to design implementation (code generation),
generative pre-training, and downstream evaluation (verification). Using ideas
from scaling laws, our system, Genesys, employs a Ladder of Scales approach;
new designs are proposed, adversarially reviewed, implemented, and selectively
verified at increasingly larger model scales (14M$\sim$350M parameters) with a
narrowing budget (the number of models we can train at each scale). To help
make discovery efficient and factorizable, Genesys uses a novel genetic
programming backbone, which we show has empirical advantages over commonly used
direct prompt generation workflows (e.g., $\sim$86\% percentage point
improvement in successful design generation, a key bottleneck). We report
experiments involving 1,162 newly discovered designs (1,062 fully verified
through pre-training) and find the best designs to be highly competitive with
known architectures (e.g., outperform GPT2, Mamba2, etc., on 6/9 common
benchmarks). We couple these results with comprehensive system-level ablations
and formal results, which give broader insights into the design of effective
autonomous discovery systems.

</details>


### [91] [The Decrypto Benchmark for Multi-Agent Reasoning and Theory of Mind](https://arxiv.org/abs/2506.20664)
*Andrei Lupu,Timon Willi,Jakob Foerster*

Main category: cs.AI

TL;DR: 论文提出了Decrypto，一个基于游戏的多智能体推理和心智理论（ToM）基准测试，填补了现有评估工具的不足。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）具备代理能力，需要评估其在多智能体场景中的心智理论能力，但现有基准存在范围窄、数据泄露等问题。

Method: 设计Decrypto基准，结合认知科学、计算语用学和多智能体强化学习，简化其他维度以减少干扰因素。

Result: 前沿LLMs在游戏能力上落后于人类和简单词嵌入基线，且最新推理模型在ToM任务上表现更差。

Conclusion: Decrypto填补了当前推理和ToM评估的空白，为开发更优人工代理铺平道路。

Abstract: As Large Language Models (LLMs) gain agentic abilities, they will have to
navigate complex multi-agent scenarios, interacting with human users and other
agents in cooperative and competitive settings. This will require new reasoning
skills, chief amongst them being theory of mind (ToM), or the ability to reason
about the "mental" states of other agents. However, ToM and other multi-agent
abilities in LLMs are poorly understood, since existing benchmarks suffer from
narrow scope, data leakage, saturation, and lack of interactivity. We thus
propose Decrypto, a game-based benchmark for multi-agent reasoning and ToM
drawing inspiration from cognitive science, computational pragmatics and
multi-agent reinforcement learning. It is designed to be as easy as possible in
all other dimensions, eliminating confounding factors commonly found in other
benchmarks. To our knowledge, it is also the first platform for designing
interactive ToM experiments.
  We validate the benchmark design through comprehensive empirical evaluations
of frontier LLMs, robustness studies, and human-AI cross-play experiments. We
find that LLM game-playing abilities lag behind humans and simple
word-embedding baselines. We then create variants of two classic cognitive
science experiments within Decrypto to evaluate three key ToM abilities.
Surprisingly, we find that state-of-the-art reasoning models are significantly
worse at those tasks than their older counterparts. This demonstrates that
Decrypto addresses a crucial gap in current reasoning and ToM evaluations, and
paves the path towards better artificial agents.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [92] [Development of an Open-Source Spacecraft Bus for the PULSE-A CubeSat](https://arxiv.org/abs/2506.20014)
*Graydon Schulze-Kalt,Robert Pitu,Spencer Shelton,Catherine Todd,Zane Ebel,Ian Goldberg,Leon Gold,Henry Czarnecki,Mason McCormack,Larry Li,Zumi Riekse,Brian Yu,Akash Piya,Vidya Suri,Dylan Hu,Colleen Kim,John Baird,Seth Knights,Logan Hanssler,Michael Lembeck,Tian Zhong*

Main category: physics.app-ph

TL;DR: PULSE-A项目展示了低成本开源卫星总线的设计，用于验证圆偏振调制的激光通信技术，并支持未来任务的扩展。


<details>
  <summary>Details</summary>
Motivation: 验证圆偏振调制激光通信的可行性，同时开发一个可配置的低成本开源卫星总线，以满足未来任务需求。

Method: 采用双BeagleBone Black Industrial计算单元和PC/104标准，结合Goddard Space Flight Center的cFS软件架构，设计并测试了卫星总线。

Result: 成功设计了满足指向精度、组件对齐、功耗和热稳定性要求的卫星总线，并支持未来扩展。

Conclusion: PULSE-A项目为低成本开源卫星总线提供了可行方案，并展示了其在激光通信任务中的潜力。

Abstract: The undergraduate-led Polarization-modUlated Laser Satellite Experiment
(PULSE-A) at the University of Chicago seeks to demonstrate the feasibility of
circular polarization shift keyed satellite-to-ground laser communication.
PULSE-A's low-cost open-source bus serves as the backbone of the mission and
has been designed in tandem with the Payload, with design driven by strict
requirements for pointing accuracy, component alignment, power demand, and
thermal stability. This work presents the design and testing of the PULSE-A
bus.
  The spacecraft bus was designed to fill two major needs: (1) to meet the
requirements of the PULSE-A mission, and (2) to be easily configurable for
future missions that desire enhanced capabilities over other low-cost
open-source designs. At its core, the bus features dual BeagleBone Black
Industrial compute units, selected for their flight heritage, integrated via a
PC/104 header standard. PULSE-A implements Goddard Space Flight Center's core
Flight System (cFS), which takes a modular software architecture approach and
is built in C. The use of C as the primary language aligns with the expertise
of the University of Chicago's Computer Science department, allowing for ease
of development by PULSE-A's undergraduate flight software team.
  The CubeSat structure utilizes Gran Systems' 3U frame, modified to
accommodate openings for various ports and deployable components. Inside, the
avionics stack uses the PC/104 standard quad rails, which terminate in
PULSE-A's custom-designed Payload Box that houses all of the Payload components
and optical fiber runs. This work also covers the techniques and iterative
engineering processes used to develop the thermal control and dissipation
mechanisms for the specific requirements, under volume, mass, and
temperature-range constraints.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [93] [PSALM-V: Automating Symbolic Planning in Interactive Visual Environments with Large Language Models](https://arxiv.org/abs/2506.20097)
*Wang Bill Zhu,Miaosen Chai,Ishika Singh,Robin Jia,Jesse Thomason*

Main category: cs.RO

TL;DR: PSALM-V是一种自主神经符号学习系统，能够在视觉环境中通过交互推断符号动作语义，无需专家定义，显著提高了规划成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖文本领域或不现实的假设（如预定义问题文件或完全可观察性），而PSALM-V旨在动态推断符号语义，适用于复杂视觉和多智能体环境。

Method: 系统利用LLM生成启发式计划和候选语义，通过分析执行结果动态推断PDDL问题文件和动作语义，迭代优化信念树直至达成目标。

Result: 在ALFRED任务中，规划成功率从37%提升至74%；在RTFM和Overcooked-AI中提高了步骤效率，并在多智能体环境中成功推断语义。

Conclusion: PSALM-V在视觉和多智能体环境中高效推断符号语义，为机器人任务提供了实用解决方案。

Abstract: We propose PSALM-V, the first autonomous neuro-symbolic learning system able
to induce symbolic action semantics (i.e., pre- and post-conditions) in visual
environments through interaction. PSALM-V bootstraps reliable symbolic planning
without expert action definitions, using LLMs to generate heuristic plans and
candidate symbolic semantics. Previous work has explored using large language
models to generate action semantics for Planning Domain Definition Language
(PDDL)-based symbolic planners. However, these approaches have primarily
focused on text-based domains or relied on unrealistic assumptions, such as
access to a predefined problem file, full observability, or explicit error
messages. By contrast, PSALM-V dynamically infers PDDL problem files and domain
action semantics by analyzing execution outcomes and synthesizing possible
error explanations. The system iteratively generates and executes plans while
maintaining a tree-structured belief over possible action semantics for each
action, iteratively refining these beliefs until a goal state is reached.
Simulated experiments of task completion in ALFRED demonstrate that PSALM-V
increases the plan success rate from 37% (Claude-3.7) to 74% in partially
observed setups. Results on two 2D game environments, RTFM and Overcooked-AI,
show that PSALM-V improves step efficiency and succeeds in domain induction in
multi-agent settings. PSALM-V correctly induces PDDL pre- and post-conditions
for real-world robot BlocksWorld tasks, despite low-level manipulation failures
from the robot.

</details>


### [94] [Why Robots Are Bad at Detecting Their Mistakes: Limitations of Miscommunication Detection in Human-Robot Dialogue](https://arxiv.org/abs/2506.20268)
*Ruben Janssens,Jens De Bock,Sofie Labat,Eva Verhelst,Veronique Hoste,Tony Belpaeme*

Main category: cs.RO

TL;DR: 研究评估机器学习模型在检测人机对话中的沟通错误的效果，发现模型和人类识别能力均有限，揭示了机器人对话中识别沟通错误的根本挑战。


<details>
  <summary>Details</summary>
Motivation: 检测人机交互中的沟通错误对维持用户参与和信任至关重要，但机器人难以通过非语言反馈识别错误。

Method: 使用包含240段人机对话的多模态数据集，引入四种对话失败类型，评估计算机视觉模型的性能。

Result: 模型在识别沟通错误时表现仅略优于随机猜测，但在情感表达更丰富的数据集中能成功识别困惑状态。人类评分者同样只能识别约一半的错误。

Conclusion: 研究揭示了识别机器人对话中沟通错误的根本局限性，用户即使感知到错误也未必反馈，这有助于设计更好的人机对话系统。

Abstract: Detecting miscommunication in human-robot interaction is a critical function
for maintaining user engagement and trust. While humans effortlessly detect
communication errors in conversations through both verbal and non-verbal cues,
robots face significant challenges in interpreting non-verbal feedback, despite
advances in computer vision for recognizing affective expressions. This
research evaluates the effectiveness of machine learning models in detecting
miscommunications in robot dialogue. Using a multi-modal dataset of 240
human-robot conversations, where four distinct types of conversational failures
were systematically introduced, we assess the performance of state-of-the-art
computer vision models. After each conversational turn, users provided feedback
on whether they perceived an error, enabling an analysis of the models' ability
to accurately detect robot mistakes. Despite using state-of-the-art models, the
performance barely exceeds random chance in identifying miscommunication, while
on a dataset with more expressive emotional content, they successfully
identified confused states. To explore the underlying cause, we asked human
raters to do the same. They could also only identify around half of the induced
miscommunications, similarly to our model. These results uncover a fundamental
limitation in identifying robot miscommunications in dialogue: even when users
perceive the induced miscommunication as such, they often do not communicate
this to their robotic conversation partner. This knowledge can shape
expectations of the performance of computer vision models and can help
researchers to design better human-robot conversations by deliberately
eliciting feedback where needed.

</details>


### [95] [Consensus-Driven Uncertainty for Robotic Grasping based on RGB Perception](https://arxiv.org/abs/2506.20045)
*Eric C. Joyce,Qianwen Zhao,Nathaniel Burgdorfer,Long Wang,Philippos Mordohai*

Main category: cs.RO

TL;DR: 提出一种轻量级深度网络方法，用于预测基于图像姿态估计的抓取是否成功，通过真实图像和模拟抓取生成训练数据。


<details>
  <summary>Details</summary>
Motivation: 解决深度物体姿态估计器过度自信的问题，避免高不确定性下的任务失败。

Method: 训练轻量级深度网络，利用真实图像姿态估计和模拟抓取生成数据，联合训练多种物体。

Result: 网络能从多样化的物体数据中受益，联合训练效果更佳。

Conclusion: 多样化物体数据有助于提升抓取成功率预测的准确性。

Abstract: Deep object pose estimators are notoriously overconfident. A grasping agent
that both estimates the 6-DoF pose of a target object and predicts the
uncertainty of its own estimate could avoid task failure by choosing not to act
under high uncertainty. Even though object pose estimation improves and
uncertainty quantification research continues to make strides, few studies have
connected them to the downstream task of robotic grasping. We propose a method
for training lightweight, deep networks to predict whether a grasp guided by an
image-based pose estimate will succeed before that grasp is attempted. We
generate training data for our networks via object pose estimation on real
images and simulated grasping. We also find that, despite high object
variability in grasping trials, networks benefit from training on all objects
jointly, suggesting that a diverse variety of objects can nevertheless
contribute to the same goal.

</details>


### [96] [HRIBench: Benchmarking Vision-Language Models for Real-Time Human Perception in Human-Robot Interaction](https://arxiv.org/abs/2506.20566)
*Zhonghao Shi,Enyu Zhao,Nathaniel Dennler,Jingzhen Wang,Xinyang Xu,Kaleen Shrestha,Mengxue Fu,Daniel Seita,Maja Matarić*

Main category: cs.RO

TL;DR: HRIBench是一个用于评估视觉语言模型（VLM）在实时人机交互（HRI）中人类感知能力的基准测试，覆盖五个关键领域。研究发现当前VLM在性能和延迟方面仍有不足。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决VLM在实时HRI中高延迟的问题，并评估其在人类感知任务中的表现。

Method: 通过构建HRIBench基准测试，涵盖五个关键领域，并评估11种VLM的性能和延迟。

Result: 结果显示当前VLM在核心感知能力和延迟方面表现不佳，不适合实时部署。

Conclusion: 结论指出需要开发更小、低延迟的VLM以提升实时HRI中的感知能力。

Abstract: Real-time human perception is crucial for effective human-robot interaction
(HRI). Large vision-language models (VLMs) offer promising generalizable
perceptual capabilities but often suffer from high latency, which negatively
impacts user experience and limits VLM applicability in real-world scenarios.
To systematically study VLM capabilities in human perception for HRI and
performance-latency trade-offs, we introduce HRIBench, a visual
question-answering (VQA) benchmark designed to evaluate VLMs across a diverse
set of human perceptual tasks critical for HRI. HRIBench covers five key
domains: (1) non-verbal cue understanding, (2) verbal instruction
understanding, (3) human-robot object relationship understanding, (4) social
navigation, and (5) person identification. To construct HRIBench, we collected
data from real-world HRI environments to curate questions for non-verbal cue
understanding, and leveraged publicly available datasets for the remaining four
domains. We curated 200 VQA questions for each domain, resulting in a total of
1000 questions for HRIBench. We then conducted a comprehensive evaluation of
both state-of-the-art closed-source and open-source VLMs (N=11) on HRIBench.
Our results show that, despite their generalizability, current VLMs still
struggle with core perceptual capabilities essential for HRI. Moreover, none of
the models within our experiments demonstrated a satisfactory
performance-latency trade-off suitable for real-time deployment, underscoring
the need for future research on developing smaller, low-latency VLMs with
improved human perception capabilities. HRIBench and our results can be found
in this Github repository: https://github.com/interaction-lab/HRIBench.

</details>


<div id='cs.CR'></div>

# cs.CR [[Back]](#toc)

### [97] [RepuNet: A Reputation System for Mitigating Malicious Clients in DFL](https://arxiv.org/abs/2506.19892)
*Isaac Marroqui Penalva,Enrique Tomás Martínez Beltrán,Manuel Gil Pérez,Alberto Huertas Celdrán*

Main category: cs.CR

TL;DR: RepuNet是一种去中心化声誉系统，通过动态评估节点行为来检测和缓解DFL中的恶意行为，实验表明其在高攻击强度下仍能保持高准确率。


<details>
  <summary>Details</summary>
Motivation: 现有的DFL解决方案依赖固定配置或额外基础设施，导致计算开销或适应性不足，需要一种更灵活的方法来应对恶意节点威胁。

Method: 提出RepuNet，通过模型相似性、参数变化、消息延迟和通信量等指标动态评估节点行为，并根据声誉分数调整节点在模型聚合中的影响力。

Result: 在MNIST和CIFAR-10数据集上，RepuNet的F1分数分别超过95%和约76%，有效检测并缓解恶意行为。

Conclusion: RepuNet展示了在去中心化联邦学习环境中应对威胁的适应性、鲁棒性和实用潜力。

Abstract: Decentralized Federated Learning (DFL) enables nodes to collaboratively train
models without a central server, introducing new vulnerabilities since each
node independently selects peers for model aggregation. Malicious nodes may
exploit this autonomy by sending corrupted models (model poisoning), delaying
model submissions (delay attack), or flooding the network with excessive
messages, negatively affecting system performance. Existing solutions often
depend on rigid configurations or additional infrastructures such as
blockchain, leading to computational overhead, scalability issues, or limited
adaptability. To overcome these limitations, this paper proposes RepuNet, a
decentralized reputation system that categorizes threats in DFL and dynamically
evaluates node behavior using metrics like model similarity, parameter changes,
message latency, and communication volume. Nodes' influence in model
aggregation is adjusted based on their reputation scores. RepuNet was
integrated into the Nebula DFL platform and experimentally evaluated with MNIST
and CIFAR-10 datasets under non-IID distributions, using federations of up to
25 nodes in both fully connected and random topologies. Different attack
intensities, frequencies, and activation intervals were tested. Results
demonstrated that RepuNet effectively detects and mitigates malicious behavior,
achieving F1 scores above 95% for MNIST scenarios and approximately 76% for
CIFAR-10 cases. These outcomes highlight RepuNet's adaptability, robustness,
and practical potential for mitigating threats in decentralized federated
learning environments.

</details>


### [98] [Can One Safety Loop Guard Them All? Agentic Guard Rails for Federated Computing](https://arxiv.org/abs/2506.20000)
*Narasimha Raghavan Veeraragavan,Jan Franz Nygård*

Main category: cs.CR

TL;DR: Guardian-FC是一个新颖的两层框架，用于隐私保护的联邦计算，统一了多种隐私保护机制的安全执行。


<details>
  <summary>Details</summary>
Motivation: 解决联邦计算中隐私保护机制多样化的统一安全问题。

Method: 通过模块化计算单元（插件）和后端中立的领域特定语言（DSL）实现隐私机制与安全护栏的解耦。

Result: 提出了一个支持快速失败任务准入和可扩展性的框架，并提供了形式化验证基础。

Conclusion: Guardian-FC为联邦计算提供了一种灵活且安全的解决方案，并提出了未来研究方向。

Abstract: We propose Guardian-FC, a novel two-layer framework for privacy preserving
federated computing that unifies safety enforcement across diverse privacy
preserving mechanisms, including cryptographic back-ends like fully homomorphic
encryption (FHE) and multiparty computation (MPC), as well as statistical
techniques such as differential privacy (DP). Guardian-FC decouples guard-rails
from privacy mechanisms by executing plug-ins (modular computation units),
written in a backend-neutral, domain-specific language (DSL) designed
specifically for federated computing workflows and interchangeable Execution
Providers (EPs), which implement DSL operations for various privacy back-ends.
An Agentic-AI control plane enforces a finite-state safety loop through signed
telemetry and commands, ensuring consistent risk management and auditability.
The manifest-centric design supports fail-fast job admission and seamless
extensibility to new privacy back-ends. We present qualitative scenarios
illustrating backend-agnostic safety and a formal model foundation for
verification. Finally, we outline a research agenda inviting the community to
advance adaptive guard-rail tuning, multi-backend composition, DSL
specification development, implementation, and compiler extensibility alongside
human-override usability.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [99] [A Spatio-Temporal Point Process for Fine-Grained Modeling of Reading Behavior](https://arxiv.org/abs/2506.19999)
*Francesco Ignazio Re,Andreas Opedal,Glib Manaiev,Mario Giulianelli,Ryan Cotterell*

Main category: cs.LG

TL;DR: 本文提出了一种基于时空点过程的概率模型，用于更全面地模拟阅读行为，包括注视点的位置、时间和持续时间，以及眼跳的动态特性。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖于聚合的眼动追踪数据和强假设模型，忽略了阅读过程中的时空动态特性。本文旨在通过更通用的模型捕捉这些动态特性。

Method: 使用标记的时空点过程模型，其中眼跳通过Hawkes过程建模，注视持续时间通过时间卷积的预测函数建模。

Result: Hawkes过程模型在模拟人类眼跳方面优于基线模型，但注视持续时间模型中引入上下文惊讶度仅带来边际改进。

Conclusion: 惊讶度理论难以解释精细的眼动行为，表明需要更复杂的模型或理论来解释阅读动态。

Abstract: Reading is a process that unfolds across space and time, alternating between
fixations where a reader focuses on a specific point in space, and saccades
where a reader rapidly shifts their focus to a new point. An ansatz of
psycholinguistics is that modeling a reader's fixations and saccades yields
insight into their online sentence processing. However, standard approaches to
such modeling rely on aggregated eye-tracking measurements and models that
impose strong assumptions, ignoring much of the spatio-temporal dynamics that
occur during reading. In this paper, we propose a more general probabilistic
model of reading behavior, based on a marked spatio-temporal point process,
that captures not only how long fixations last, but also where they land in
space and when they take place in time. The saccades are modeled using a Hawkes
process, which captures how each fixation excites the probability of a new
fixation occurring near it in time and space. The duration time of fixation
events is modeled as a function of fixation-specific predictors convolved
across time, thus capturing spillover effects. Empirically, our Hawkes process
model exhibits a better fit to human saccades than baselines. With respect to
fixation durations, we observe that incorporating contextual surprisal as a
predictor results in only a marginal improvement in the model's predictive
accuracy. This finding suggests that surprisal theory struggles to explain
fine-grained eye movements.

</details>


### [100] [MIRAGE: A Benchmark for Multimodal Information-Seeking and Reasoning in Agricultural Expert-Guided Conversations](https://arxiv.org/abs/2506.20100)
*Vardhan Dongre,Chi Gui,Shubham Garg,Hooshang Nayyeri,Gokhan Tur,Dilek Hakkani-Tür,Vikram S. Adve*

Main category: cs.LG

TL;DR: MIRAGE是一个新的多模态基准测试，专注于农业领域的专家级推理和决策，结合自然用户查询、专家回答和图像上下文，用于评估模型在真实世界知识密集型任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试通常依赖明确输入和封闭分类，无法满足真实世界中模糊、开放场景的需求。MIRAGE旨在填补这一空白，提供更贴近实际的评估环境。

Method: 基于35,000多个真实用户-专家交互数据，通过多步骤流程构建，涵盖作物健康、害虫诊断和管理场景，包含7,000多个生物实体。

Result: MIRAGE成为目前分类多样性最高、基于真实世界的视觉语言模型基准之一，支持开放场景和罕见实体处理。

Conclusion: MIRAGE为多模态模型在复杂、开放环境中的推理和决策提供了高保真评估工具，推动了相关领域的研究。

Abstract: We introduce MIRAGE, a new benchmark for multimodal expert-level reasoning
and decision-making in consultative interaction settings. Designed for the
agriculture domain, MIRAGE captures the full complexity of expert consultations
by combining natural user queries, expert-authored responses, and image-based
context, offering a high-fidelity benchmark for evaluating models on grounded
reasoning, clarification strategies, and long-form generation in a real-world,
knowledge-intensive domain. Grounded in over 35,000 real user-expert
interactions and curated through a carefully designed multi-step pipeline,
MIRAGE spans diverse crop health, pest diagnosis, and crop management
scenarios. The benchmark includes more than 7,000 unique biological entities,
covering plant species, pests, and diseases, making it one of the most
taxonomically diverse benchmarks available for vision-language models, grounded
in the real world. Unlike existing benchmarks that rely on well-specified user
inputs and closed-set taxonomies, MIRAGE features underspecified, context-rich
scenarios with open-world settings, requiring models to infer latent knowledge
gaps, handle rare entities, and either proactively guide the interaction or
respond. Project Page: https://mirage-benchmark.github.io

</details>


### [101] [Collaborative Batch Size Optimization for Federated Learning](https://arxiv.org/abs/2506.20511)
*Arno Geimer,Karthick Panner Selvam,Beltran Fiz Pontiveros*

Main category: cs.LG

TL;DR: 通过贪婪随机搜索优化联邦学习中的本地批量大小，提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 联邦学习中，参与者硬件配置不当可能阻碍训练过程，需优化本地训练参数以提高效率。

Method: 利用联邦学习的并行处理特性，采用贪婪随机搜索优化本地批量大小。

Result: 相比默认参数设置，该方法提高了收敛速度，且接近本地参数优化效果。

Conclusion: 贪婪随机搜索是优化联邦学习本地训练配置的有效方法。

Abstract: Federated Learning (FL) is a decentralized collaborative Machine Learning
framework for training models without collecting data in a centralized
location. It has seen application across various disciplines, from helping
medical diagnoses in hospitals to detecting fraud in financial transactions. In
this paper, we focus on improving the local training process through hardware
usage optimization. While participants in a federation might share the hardware
they are training on, since there is no information exchange between them,
their training process can be hindered by an improper training configuration.
Taking advantage of the parallel processing inherent to Federated Learning, we
use a greedy randomized search to optimize local batch sizes for the best
training settings across all participants. Our results show that against
default parameter settings, our method improves convergence speed while staying
nearly on par with the case where local parameters are optimized.

</details>


### [102] [Hear No Evil: Detecting Gradient Leakage by Malicious Servers in Federated Learning](https://arxiv.org/abs/2506.20651)
*Fei Wang,Baochun Li*

Main category: cs.LG

TL;DR: 论文分析了联邦学习中恶意梯度泄漏攻击的局限性，并提出了一种轻量级客户端检测机制。


<details>
  <summary>Details</summary>
Motivation: 研究恶意服务器通过操纵全局模型获取客户端敏感信息的风险，并探索防御方法。

Method: 分析了攻击的有效性与隐蔽性之间的权衡，并提出了一种客户端检测机制。

Result: 发现攻击在现实中难以同时高效且隐蔽，检测机制可有效防御。

Conclusion: 恶意梯度泄漏攻击实际威胁有限，轻量级防御机制可行且易于部署。

Abstract: Recent work has shown that gradient updates in federated learning (FL) can
unintentionally reveal sensitive information about a client's local data. This
risk becomes significantly greater when a malicious server manipulates the
global model to provoke information-rich updates from clients. In this paper,
we adopt a defender's perspective to provide the first comprehensive analysis
of malicious gradient leakage attacks and the model manipulation techniques
that enable them. Our investigation reveals a core trade-off: these attacks
cannot be both highly effective in reconstructing private data and sufficiently
stealthy to evade detection -- especially in realistic FL settings that
incorporate common normalization techniques and federated averaging.
  Building on this insight, we argue that malicious gradient leakage attacks,
while theoretically concerning, are inherently limited in practice and often
detectable through basic monitoring. As a complementary contribution, we
propose a simple, lightweight, and broadly applicable client-side detection
mechanism that flags suspicious model updates before local training begins,
despite the fact that such detection may not be strictly necessary in realistic
FL settings. This mechanism further underscores the feasibility of defending
against these attacks with minimal overhead, offering a deployable safeguard
for privacy-conscious federated learning systems.

</details>


### [103] [Position: Machine Learning Conferences Should Establish a "Refutations and Critiques" Track](https://arxiv.org/abs/2506.19882)
*Rylan Schaeffer,Joshua Kazdan,Yegor Denisov-Blanch,Brando Miranda,Matthias Gerstgrasser,Susan Zhang,Andreas Haupt,Isha Gupta,Elyas Obbad,Jesse Dodge,Jessica Zosa Forde,Koustuv Sinha,Francesco Orabona,Sanmi Koyejo,David Donoho*

Main category: cs.LG

TL;DR: 本文主张在机器学习会议中设立专门的“反驳与批评”（R&C）轨道，以促进研究领域的自我修正。


<details>
  <summary>Details</summary>
Motivation: 机器学习领域快速发展，但存在错误或误导性研究被接受的问题，缺乏系统性的修正机制。

Method: 提出在会议中设立R&C轨道，讨论其设计、评审原则及潜在问题，并以ICLR 2025为例说明。

Result: 通过R&C轨道，可为批评性研究提供平台，推动研究生态的自我修正。

Conclusion: 机器学习会议应建立官方机制，支持研究的自我修正。

Abstract: Science progresses by iteratively advancing and correcting humanity's
understanding of the world. In machine learning (ML) research, rapid
advancements have led to an explosion of publications, but have also led to
misleading, incorrect, flawed or perhaps even fraudulent studies being accepted
and sometimes highlighted at ML conferences due to the fallibility of peer
review. While such mistakes are understandable, ML conferences do not offer
robust processes to help the field systematically correct when such errors are
made.This position paper argues that ML conferences should establish a
dedicated "Refutations and Critiques" (R & C) Track. This R & C Track would
provide a high-profile, reputable platform to support vital research that
critically challenges prior research, thereby fostering a dynamic
self-correcting research ecosystem. We discuss key considerations including
track design, review principles, potential pitfalls, and provide an
illustrative example submission concerning a recent ICLR 2025 Oral. We conclude
that ML conferences should create official, reputable mechanisms to help ML
research self-correct.

</details>


### [104] [Counterfactual Influence as a Distributional Quantity](https://arxiv.org/abs/2506.20481)
*Matthieu Meeus,Igor Shilov,Georgios Kaissis,Yves-Alexandre de Montjoye*

Main category: cs.LG

TL;DR: 论文研究了机器学习模型记忆训练数据的现象，指出仅依赖自影响（self-influence）会低估记忆风险，提出通过全影响分布（full influence distribution）更全面评估记忆化问题。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型会记忆训练数据，引发隐私和泛化问题。现有研究多关注自影响，但忽略了其他因素（如重复样本）对记忆化的影响。

Method: 通过计算训练样本间的全影响分布，分析其性质，研究记忆化现象。实验包括小语言模型和图像分类任务（CIFAR-10）。

Result: 发现仅依赖自影响会严重低估记忆风险，重复样本的存在会降低自影响，但这些样本仍可能被提取。图像分类中也观察到类似现象。

Conclusion: 记忆化是训练数据间复杂相互作用的结果，全影响分布比自影响更能准确捕捉这一现象。

Abstract: Machine learning models are known to memorize samples from their training
data, raising concerns around privacy and generalization. Counterfactual
self-influence is a popular metric to study memorization, quantifying how the
model's prediction for a sample changes depending on the sample's inclusion in
the training dataset. However, recent work has shown memorization to be
affected by factors beyond self-influence, with other training samples, in
particular (near-)duplicates, having a large impact. We here study memorization
treating counterfactual influence as a distributional quantity, taking into
account how all training samples influence how a sample is memorized. For a
small language model, we compute the full influence distribution of training
samples on each other and analyze its properties. We find that solely looking
at self-influence can severely underestimate tangible risks associated with
memorization: the presence of (near-)duplicates seriously reduces
self-influence, while we find these samples to be (near-)extractable. We
observe similar patterns for image classification, where simply looking at the
influence distributions reveals the presence of near-duplicates in CIFAR-10.
Our findings highlight that memorization stems from complex interactions across
training data and is better captured by the full influence distribution than by
self-influence alone.

</details>


### [105] [Asymmetric REINFORCE for off-Policy Reinforcement Learning: Balancing positive and negative rewards](https://arxiv.org/abs/2506.20520)
*Charles Arnal,Gaëtan Narozniak,Vivien Cabannes,Yunhao Tang,Julia Kempe,Remi Munos*

Main category: cs.LG

TL;DR: 论文研究了介于离策略强化学习和监督微调之间的算法，通过分析简单的离策略REINFORCE算法，探讨了基线V对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 强化学习用于对齐大型语言模型时，离策略方法虽简单高效但性能不佳，需探索中间算法。

Method: 分析离策略REINFORCE算法，其中优势定义为A=r-V，调整V以优化高/低奖励样本的权重。

Result: 理论证明当V低于期望奖励时算法有策略改进保证，实验验证了在随机多臂老虎机和LLM微调中的有效性。

Conclusion: 离策略更新更依赖正奖励信号，调整V可优化性能，为LLM对齐提供新思路。

Abstract: Reinforcement learning (RL) is increasingly used to align large language
models (LLMs). Off-policy methods offer greater implementation simplicity and
data efficiency than on-policy techniques, but often result in suboptimal
performance. In this work, we study the intermediate range of algorithms
between off-policy RL and supervised fine-tuning by analyzing a simple
off-policy REINFORCE algorithm, where the advantage is defined as $A=r-V$, with
$r$ a reward and $V$ some tunable baseline. Intuitively, lowering $V$
emphasizes high-reward samples, while raising it penalizes low-reward ones more
heavily. We first provide a theoretical analysis of this off-policy REINFORCE
algorithm, showing that when the baseline $V$ lower-bounds the expected reward,
the algorithm enjoys a policy improvement guarantee. Our analysis reveals that
while on-policy updates can safely leverage both positive and negative signals,
off-policy updates benefit from focusing more on positive rewards than on
negative ones. We validate our findings experimentally in a controlled
stochastic bandit setting and through fine-tuning state-of-the-art LLMs on
reasoning tasks.

</details>


### [106] [PLoP: Precise LoRA Placement for Efficient Finetuning of Large Models](https://arxiv.org/abs/2506.20629)
*Soufiane Hayou,Nikhil Ghosh,Bin Yu*

Main category: cs.LG

TL;DR: PLoP（Precise LoRA Placement）是一种轻量级方法，通过理论分析自动确定LoRA适配器的最佳放置位置，优于常见策略。


<details>
  <summary>Details</summary>
Motivation: 现有LoRA适配器放置策略缺乏一致性，不同研究提出不同模块（如注意力或MLP模块）放置建议，需更优方法。

Method: 提出PLoP方法，结合理论分析自动识别预训练模型和微调任务中适配器的最佳放置模块类型。

Result: PLoP在监督微调和强化学习推理任务中表现优于或至少与常见策略相当。

Conclusion: PLoP为LoRA适配器放置提供了高效且自动化的解决方案，显著提升性能。

Abstract: Low-Rank Adaptation (LoRA) is a widely used finetuning method for large
models. Its small memory footprint allows practitioners to adapt large models
to specific tasks at a fraction of the cost of full finetuning. Different
modifications have been proposed to enhance its efficiency by, for example,
setting the learning rate, the rank, and the initialization. Another
improvement axis is adapter placement strategy: when using LoRA, practitioners
usually pick module types to adapt with LoRA, such as Query and Key modules.
Few works have studied the problem of adapter placement, with nonconclusive
results: original LoRA paper suggested placing adapters in attention modules,
while other works suggested placing them in the MLP modules. Through an
intuitive theoretical analysis, we introduce PLoP (Precise LoRA Placement), a
lightweight method that allows automatic identification of module types where
LoRA adapters should be placed, given a pretrained model and a finetuning task.
We demonstrate that PLoP consistently outperforms, and in the worst case
competes, with commonly used placement strategies through comprehensive
experiments on supervised finetuning and reinforcement learning for reasoning.

</details>


### [107] [Any-Order GPT as Masked Diffusion Model: Decoupling Formulation and Architecture](https://arxiv.org/abs/2506.19935)
*Shuchen Xue,Tianyu Xie,Tianyang Hu,Zijin Feng,Jiacheng Sun,Kenji Kawaguchi,Zhenguo Li,Zhi-Ming Ma*

Main category: cs.LG

TL;DR: 研究比较了自回归（AR）和掩码扩散模型（MDM）在解码器框架下的性能，发现MDM作为任意顺序自回归（AO-AR）范式可能需优化，且解码器MDM在生成速度和困惑度上表现优异。


<details>
  <summary>Details</summary>
Motivation: 比较AR和MDM范式时，架构差异导致不公平对比，研究旨在分离范式与架构的影响。

Method: 在解码器框架下评估MDM，比较AO-AR与标准AR，并研究解码器与编码器MDM的架构影响。

Result: 解码器MDM在生成速度上显著提升（约25倍），困惑度与编码器MDM相当，但建模空间更大。

Conclusion: 研究分离了范式与架构的影响，为未来模型设计提供参考。

Abstract: Large language models (LLMs) predominantly use autoregressive (AR)
approaches, but masked diffusion models (MDMs) are emerging as viable
alternatives. A key challenge in comparing AR and MDM paradigms is their
typical architectural difference: AR models are often decoder-only, while MDMs
have largely been encoder-only. This practice of changing both the modeling
paradigm and architecture simultaneously makes direct comparisons unfair, as
it's hard to distinguish whether observed differences stem from the paradigm
itself or the architectural shift. This research evaluates MDMs within a
decoder-only framework to: (1) equitably compare MDM (as Any-Order AR, or
AO-AR) and standard AR paradigms. Our investigation suggests that the standard
AO-AR objective, which averages over all token permutations, may benefit from
refinement, as many permutations appear less informative compared to the
language's inherent left-to-right structure. (2) Investigate architectural
influences (decoder-only vs. encoder-only) within MDMs. We demonstrate that
while encoder-only MDMs model a simpler conditional probability space,
decoder-only MDMs can achieve dramatic generation speedups ($\sim25\times$) and
comparable perplexity with temperature annealing despite modeling a vastly
larger space, highlighting key trade-offs. This work thus decouples core
paradigm differences from architectural influences, offering insights for
future model design. Code is available at https://github.com/scxue/AO-GPT-MDM.

</details>


### [108] [FedBKD: Distilled Federated Learning to Embrace Gerneralization and Personalization on Non-IID Data](https://arxiv.org/abs/2506.20245)
*Yushan Zhao,Jinyuan He,Donglai Chen,Weijie Luo,Chong Xie,Ri Zhang,Yonghong Chen,Yan Xu*

Main category: cs.LG

TL;DR: 提出了一种名为FedBKD的无数据蒸馏框架，通过生成对抗网络（GAN）生成合成数据，实现全局和局部模型之间的双向知识蒸馏，以解决非独立同分布（non-IID）数据问题。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中非独立同分布数据的挑战，同时避免引入公共数据集导致的数据隐私泄露风险。

Method: 使用GAN生成合成数据，冻结局部模型参数作为判别器，通过双向蒸馏实现全局和局部模型的知识交互。

Result: 在4个基准测试中，FedBKD在不同non-IID设置下均达到最优性能。

Conclusion: FedBKD能够同时提升全局和局部模型的性能，且无需依赖公共数据集，有效保护数据隐私。

Abstract: Federated learning (FL) is a decentralized collaborative machine learning
(ML) technique. It provides a solution to the issues of isolated data islands
and data privacy leakage in industrial ML practices. One major challenge in FL
is handling the non-identical and independent distributed (non-IID) data.
Current solutions either focus on constructing an all-powerful global model, or
customizing personalized local models. Few of them can provide both a
well-generalized global model and well-performed local models at the same time.
Additionally, many FL solutions to the non-IID problem are benefited from
introducing public datasets. However, this will also increase the risk of data
leakage. To tackle the problems, we propose a novel data-free distillation
framework, Federated Bidirectional Knowledge Distillation (FedBKD).
Specifically, we train Generative Adversarial Networks (GAN) for synthetic
data. During the GAN training, local models serve as discriminators and their
parameters are frozen. The synthetic data is then used for bidirectional
distillation between global and local models to achieve knowledge interactions
so that performances for both sides are improved. We conduct extensive
experiments on 4 benchmarks under different non-IID settings. The results show
that FedBKD achieves SOTA performances in every case.

</details>


### [109] [Learning Moderately Input-Sensitive Functions: A Case Study in QR Code Decoding](https://arxiv.org/abs/2506.20305)
*Kazuki Yoda,Kazuhiko Kawamoto,Hiroshi Kera*

Main category: cs.LG

TL;DR: 本文研究了基于学习的QR码解码，发现Transformer模型能够突破理论纠错限制，通过学习嵌入文本结构成功解码QR码。


<details>
  <summary>Details</summary>
Motivation: 探索中等输入敏感性的学习函数，特别是在QR码解码任务中，研究其与传统方法的差异。

Method: 使用Transformer模型进行QR码解码实验，分析其在不同语言和随机字符串上的泛化能力。

Result: Transformer模型能够突破理论纠错限制，成功解码QR码，且对数据位而非纠错位更关注。

Conclusion: Transformer在QR码解码中表现出独特的机制，为中等输入敏感性任务提供了新的学习视角。

Abstract: The hardness of learning a function that attains a target task relates to its
input-sensitivity. For example, image classification tasks are
input-insensitive as minor corruptions should not affect the classification
results, whereas arithmetic and symbolic computation, which have been recently
attracting interest, are highly input-sensitive as each input variable connects
to the computation results. This study presents the first learning-based Quick
Response (QR) code decoding and investigates learning functions of medium
sensitivity. Our experiments reveal that Transformers can successfully decode
QR codes, even beyond the theoretical error-correction limit, by learning the
structure of embedded texts. They generalize from English-rich training data to
other languages and even random strings. Moreover, we observe that the
Transformer-based QR decoder focuses on data bits while ignoring
error-correction bits, suggesting a decoding mechanism distinct from standard
QR code readers.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [110] [Practical insights on the effect of different encodings, ansätze and measurements in quantum and hybrid convolutional neural networks](https://arxiv.org/abs/2506.20355)
*Jesús Lozano-Cruz,Albert Nieto-Morales,Oriol Balló-Gimbernat,Adan Garriga,Antón Rodríguez-Otero,Alejandro Borrallo-Rentero*

Main category: quant-ph

TL;DR: 研究了参数化量子电路（PQCs）在量子卷积神经网络（QCNN）和混合量子神经网络（HQNN）中的设计选择，用于卫星图像分类任务，发现数据编码策略对性能影响最大。


<details>
  <summary>Details</summary>
Motivation: 探索量子计算在卫星图像分类中的应用，评估不同设计选择对模型性能的影响。

Method: 系统评估了约500种不同模型配置，包括数据编码技术、变分ansätze和测量方法。

Result: 混合架构中，数据编码策略对验证准确率影响最大（差异达30%），而变分ansätze和测量基准影响较小（差异<5%）。纯量子模型中，测量协议和数据到振幅的映射对性能影响显著。

Conclusion: 数据编码策略是影响量子神经网络性能的关键因素，尤其在混合架构中。纯量子模型的性能更依赖于测量协议和编码映射。

Abstract: This study investigates the design choices of parameterized quantum circuits
(PQCs) within quantum and hybrid convolutional neural network (HQNN and QCNN)
architectures, applied to the task of satellite image classification using the
EuroSAT dataset. We systematically evaluate the performance implications of
data encoding techniques, variational ans\"atze, and measurement in approx. 500
distinct model configurations. Our analysis reveals a clear hierarchy of
influence on model performance. For hybrid architectures, which were
benchmarked against their direct classical equivalents (e.g. the same
architecture with the PQCs removed), the data encoding strategy is the dominant
factor, with validation accuracy varying over 30% for distinct embeddings. In
contrast, the selection of variational ans\"atze and measurement basis had a
comparatively marginal effect, with validation accuracy variations remaining
below 5%. For purely quantum models, restricted to amplitude encoding,
performance was most dependent on the measurement protocol and the
data-to-amplitude mapping. The measurement strategy varied the validation
accuracy by up to 30% and the encoding mapping by around 8 percentage points.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [111] [X-SiT: Inherently Interpretable Surface Vision Transformers for Dementia Diagnosis](https://arxiv.org/abs/2506.20267)
*Fabian Bongratz,Tom Nuno Wolf,Jaume Gual Ramon,Christian Wachinger*

Main category: cs.GR

TL;DR: 论文提出了一种可解释的表面视觉变换器（X-SiT），用于基于可解释的皮层特征进行预测，并在阿尔茨海默病和额颞叶痴呆检测中表现出色。


<details>
  <summary>Details</summary>
Motivation: 3D体积数据的可视化与解释具有挑战性，而皮层表面渲染提供了更易理解的脑部解剖表示。X-SiT旨在结合这一优势，为神经学研究提供可解释的预测。

Method: X-SiT是一种可解释的神经网络，结合了原型表面补丁解码器，用于分类表面补丁嵌入，并通过空间对应的皮层原型实现基于案例的推理。

Result: X-SiT在阿尔茨海默病和额颞叶痴呆检测中达到最先进性能，并提供与已知疾病模式一致的原型，揭示分类错误。

Conclusion: X-SiT为临床决策提供了可解释的预测工具，结合了表面数据的优势，推动了医学图像分析的发展。

Abstract: Interpretable models are crucial for supporting clinical decision-making,
driving advances in their development and application for medical images.
However, the nature of 3D volumetric data makes it inherently challenging to
visualize and interpret intricate and complex structures like the cerebral
cortex. Cortical surface renderings, on the other hand, provide a more
accessible and understandable 3D representation of brain anatomy, facilitating
visualization and interactive exploration. Motivated by this advantage and the
widespread use of surface data for studying neurological disorders, we present
the eXplainable Surface Vision Transformer (X-SiT). This is the first
inherently interpretable neural network that offers human-understandable
predictions based on interpretable cortical features. As part of X-SiT, we
introduce a prototypical surface patch decoder for classifying surface patch
embeddings, incorporating case-based reasoning with spatially corresponding
cortical prototypes. The results demonstrate state-of-the-art performance in
detecting Alzheimer's disease and frontotemporal dementia while additionally
providing informative prototypes that align with known disease patterns and
reveal classification errors.

</details>


### [112] [DreamAnywhere: Object-Centric Panoramic 3D Scene Generation](https://arxiv.org/abs/2506.20367)
*Edoardo Alberto Dominici,Jozef Hladky,Floor Verhoeven,Lukas Radl,Thomas Deixelberger,Stefan Ainetter,Philipp Drescher,Stefan Hauswiesner,Arno Coomans,Giacomo Nazzaro,Konstantinos Vardis,Markus Steinberger*

Main category: cs.GR

TL;DR: DreamAnywhere是一个模块化系统，用于快速生成和原型化3D场景，解决了现有方法在视觉保真度、场景理解和多环境适应性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有文本到3D场景生成方法存在仅面向正面、视觉保真度低、场景理解有限且仅适用于特定环境的问题。

Method: 系统通过合成360度全景图像，分解为背景和对象，通过混合修复构建完整3D表示，并将对象掩码提升为详细3D对象。

Result: DreamAnywhere在新视角合成连贯性和图像质量上显著优于现有方法，用户研究显示其更受欢迎。

Conclusion: DreamAnywhere在多样化和挑战性场景中表现出色，适用于低成本电影制作和快速原型设计。

Abstract: Recent advances in text-to-3D scene generation have demonstrated significant
potential to transform content creation across multiple industries. Although
the research community has made impressive progress in addressing the
challenges of this complex task, existing methods often generate environments
that are only front-facing, lack visual fidelity, exhibit limited scene
understanding, and are typically fine-tuned for either indoor or outdoor
settings. In this work, we address these issues and propose DreamAnywhere, a
modular system for the fast generation and prototyping of 3D scenes. Our system
synthesizes a 360{\deg} panoramic image from text, decomposes it into
background and objects, constructs a complete 3D representation through hybrid
inpainting, and lifts object masks to detailed 3D objects that are placed in
the virtual environment. DreamAnywhere supports immersive navigation and
intuitive object-level editing, making it ideal for scene exploration, visual
mock-ups, and rapid prototyping -- all with minimal manual modeling. These
features make our system particularly suitable for low-budget movie production,
enabling quick iteration on scene layout and visual tone without the overhead
of traditional 3D workflows. Our modular pipeline is highly customizable as it
allows components to be replaced independently. Compared to current
state-of-the-art text and image-based 3D scene generation approaches,
DreamAnywhere shows significant improvements in coherence in novel view
synthesis and achieves competitive image quality, demonstrating its
effectiveness across diverse and challenging scenarios. A comprehensive user
study demonstrates a clear preference for our method over existing approaches,
validating both its technical robustness and practical usefulness.

</details>


### [113] [EditP23: 3D Editing via Propagation of Image Prompts to Multi-View](https://arxiv.org/abs/2506.20652)
*Roi Bar-On,Dana Cohen-Bar,Daniel Cohen-Or*

Main category: cs.GR

TL;DR: EditP23是一种无需掩码的3D编辑方法，通过2D图像编辑在多视角表示中实现3D一致的编辑。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖文本提示或显式空间掩码，而EditP23通过一对图像（原始视图和用户编辑后的视图）实现直观编辑。

Method: 利用预训练的多视角扩散模型的潜在空间中的编辑感知流，以图像提示为引导，实现跨视图的连贯编辑。

Result: 在多种对象类别和编辑场景中表现出色，保持原始对象的结构和外观，且无需手动掩码。

Conclusion: EditP23提供了一种高效、直观的3D编辑方法，具有高保真度和无需优化的特点。

Abstract: We present EditP23, a method for mask-free 3D editing that propagates 2D
image edits to multi-view representations in a 3D-consistent manner. In
contrast to traditional approaches that rely on text-based prompting or
explicit spatial masks, EditP23 enables intuitive edits by conditioning on a
pair of images: an original view and its user-edited counterpart. These image
prompts are used to guide an edit-aware flow in the latent space of a
pre-trained multi-view diffusion model, allowing the edit to be coherently
propagated across views. Our method operates in a feed-forward manner, without
optimization, and preserves the identity of the original object, in both
structure and appearance. We demonstrate its effectiveness across a range of
object categories and editing scenarios, achieving high fidelity to the source
while requiring no manual masks.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [114] [FundaQ-8: A Clinically-Inspired Scoring Framework for Automated Fundus Image Quality Assessment](https://arxiv.org/abs/2506.20303)
*Lee Qi Zun,Oscar Wong Jin Hao,Nor Anita Binti Che Omar,Zalifa Zakiah Binti Asnir,Mohamad Sabri bin Sinal Zainal,Goh Man Fye*

Main category: eess.IV

TL;DR: FundaQ-8是一个专家验证的框架，用于系统性评估眼底图像质量，基于八个关键参数。通过ResNet18回归模型预测质量分数，验证显示其可靠性和临床实用性。


<details>
  <summary>Details</summary>
Motivation: 眼底图像质量评估（FIQA）因图像采集差异和专家主观评估而具有挑战性，需要一种系统化的方法。

Method: 开发FundaQ-8框架，基于八个参数评估图像质量；使用ResNet18回归模型，通过迁移学习和MSE优化训练。

Result: 模型在真实临床数据和Kaggle数据集上验证，显示可靠性和临床可解释性；结合FundaQ-8提升了糖尿病视网膜病变分级的稳健性。

Conclusion: FundaQ-8为眼底图像质量评估提供了可靠工具，结合深度学习可提升筛查应用的诊断效果。

Abstract: Automated fundus image quality assessment (FIQA) remains a challenge due to
variations in image acquisition and subjective expert evaluations. We introduce
FundaQ-8, a novel expert-validated framework for systematically assessing
fundus image quality using eight critical parameters, including field coverage,
anatomical visibility, illumination, and image artifacts. Using FundaQ-8 as a
structured scoring reference, we develop a ResNet18-based regression model to
predict continuous quality scores in the 0 to 1 range. The model is trained on
1800 fundus images from real-world clinical sources and Kaggle datasets, using
transfer learning, mean squared error optimization, and standardized
preprocessing. Validation against the EyeQ dataset and statistical analyses
confirm the framework's reliability and clinical interpretability.
Incorporating FundaQ-8 into deep learning models for diabetic retinopathy
grading also improves diagnostic robustness, highlighting the value of
quality-aware training in real-world screening applications.

</details>


### [115] [VoxelOpt: Voxel-Adaptive Message Passing for Discrete Optimization in Deformable Abdominal CT Registration](https://arxiv.org/abs/2506.19975)
*Hang Zhang,Yuxi Zhang,Jiazheng Wang,Xiang Chen,Renjiu Hu,Xin Tian,Gaolei Li,Min Liu*

Main category: eess.IV

TL;DR: VoxelOpt是一种结合学习和迭代方法的变形图像配准框架，通过离散优化和位移熵测量，在精度和速度间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 学习型方法在数据有限或无标签监督时表现不佳，而迭代方法速度慢。VoxelOpt旨在结合两者优势。

Method: 使用位移熵测量信号强度，引入自适应消息传递、多级图像金字塔和预训练分割模型提取特征。

Result: 在腹部CT配准中，VoxelOpt在效率和精度上优于迭代方法，与有监督学习型方法相当。

Conclusion: VoxelOpt通过创新方法实现了配准精度与速度的平衡，优于现有方法。

Abstract: Recent developments in neural networks have improved deformable image
registration (DIR) by amortizing iterative optimization, enabling fast and
accurate DIR results. However, learning-based methods often face challenges
with limited training data, large deformations, and tend to underperform
compared to iterative approaches when label supervision is unavailable. While
iterative methods can achieve higher accuracy in such scenarios, they are
considerably slower than learning-based methods. To address these limitations,
we propose VoxelOpt, a discrete optimization-based DIR framework that combines
the strengths of learning-based and iterative methods to achieve a better
balance between registration accuracy and runtime. VoxelOpt uses displacement
entropy from local cost volumes to measure displacement signal strength at each
voxel, which differs from earlier approaches in three key aspects. First, it
introduces voxel-wise adaptive message passing, where voxels with lower entropy
receives less influence from their neighbors. Second, it employs a multi-level
image pyramid with 27-neighbor cost volumes at each level, avoiding exponential
complexity growth. Third, it replaces hand-crafted features or contrastive
learning with a pretrained foundational segmentation model for feature
extraction. In abdominal CT registration, these changes allow VoxelOpt to
outperform leading iterative in both efficiency and accuracy, while matching
state-of-the-art learning-based methods trained with label supervision. The
source code will be available at https://github.com/tinymilky/VoxelOpt

</details>


### [116] [MS-IQA: A Multi-Scale Feature Fusion Network for PET/CT Image Quality Assessment](https://arxiv.org/abs/2506.20200)
*Siqiao Li,Chen Hui,Wei Zhang,Rui Liang,Chenyue Song,Feng Jiang,Haiqi Zhu,Zhixuan Li,Hong Huang,Xiang Li*

Main category: eess.IV

TL;DR: 提出了一种多尺度特征融合网络MS-IQA，用于PET/CT图像质量评估，结合了ResNet和Swin Transformer的多尺度特征，并通过动态加权通道注意力机制融合高低层信息。构建了PET-CT-IQA-DS数据集，实验表明模型性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像质量评估方法无法同时考虑低层特征（如失真）和高层特征（如器官解剖结构），导致诊断不确定性增加。

Method: 提出MS-IQA网络，利用ResNet和Swin Transformer的多尺度特征，结合动态加权通道注意力机制融合高低层信息。构建PET-CT-IQA-DS数据集。

Result: 在PET-CT-IQA-DS和LDCTIQAC2023数据集上，MS-IQA在多种IQA指标上优于现有方法。

Conclusion: MS-IQA为PET/CT提供了一种准确高效的图像质量评估方法，填补了数据集空白。

Abstract: Positron Emission Tomography / Computed Tomography (PET/CT) plays a critical
role in medical imaging, combining functional and anatomical information to aid
in accurate diagnosis. However, image quality degradation due to noise,
compression and other factors could potentially lead to diagnostic uncertainty
and increase the risk of misdiagnosis. When evaluating the quality of a PET/CT
image, both low-level features like distortions and high-level features like
organ anatomical structures affect the diagnostic value of the image. However,
existing medical image quality assessment (IQA) methods are unable to account
for both feature types simultaneously. In this work, we propose MS-IQA, a novel
multi-scale feature fusion network for PET/CT IQA, which utilizes multi-scale
features from various intermediate layers of ResNet and Swin Transformer,
enhancing its ability of perceiving both local and global information. In
addition, a multi-scale feature fusion module is also introduced to effectively
combine high-level and low-level information through a dynamically weighted
channel attention mechanism. Finally, to fill the blank of PET/CT IQA dataset,
we construct PET-CT-IQA-DS, a dataset containing 2,700 varying-quality PET/CT
images with quality scores assigned by radiologists. Experiments on our dataset
and the publicly available LDCTIQAC2023 dataset demonstrate that our proposed
model has achieved superior performance against existing state-of-the-art
methods in various IQA metrics. This work provides an accurate and efficient
IQA method for PET/CT. Our code and dataset are available at
https://github.com/MS-IQA/MS-IQA/.

</details>


### [117] [Opportunistic Osteoporosis Diagnosis via Texture-Preserving Self-Supervision, Mixture of Experts and Multi-Task Integration](https://arxiv.org/abs/2506.20282)
*Jiaxing Huang,Heng Guo,Le Lu,Fan Yang,Minfeng Xu,Ge Yang,Wei Luo*

Main category: eess.IV

TL;DR: 提出了一种统一的深度学习框架，通过自监督学习、混合专家架构和多任务学习，解决了骨质疏松症诊断中未标记数据利用不足、设备差异和临床知识整合不足的问题。


<details>
  <summary>Details</summary>
Motivation: 骨质疏松症诊断在资源有限地区面临挑战，现有方法存在未标记数据利用不足、设备差异和临床知识整合不足的局限性。

Method: 采用自监督学习利用未标记CT数据，混合专家架构增强跨设备适应性，多任务学习整合骨质疏松诊断、BMD回归和椎骨定位预测。

Result: 在三个临床站点和外部医院验证中，该方法表现出优于现有方法的泛化能力和准确性。

Conclusion: 该框架为骨质疏松症的筛查和诊断提供了更高效、准确的解决方案。

Abstract: Osteoporosis, characterized by reduced bone mineral density (BMD) and
compromised bone microstructure, increases fracture risk in aging populations.
While dual-energy X-ray absorptiometry (DXA) is the clinical standard for BMD
assessment, its limited accessibility hinders diagnosis in resource-limited
regions. Opportunistic computed tomography (CT) analysis has emerged as a
promising alternative for osteoporosis diagnosis using existing imaging data.
Current approaches, however, face three limitations: (1) underutilization of
unlabeled vertebral data, (2) systematic bias from device-specific DXA
discrepancies, and (3) insufficient integration of clinical knowledge such as
spatial BMD distribution patterns. To address these, we propose a unified deep
learning framework with three innovations. First, a self-supervised learning
method using radiomic representations to leverage unlabeled CT data and
preserve bone texture. Second, a Mixture of Experts (MoE) architecture with
learned gating mechanisms to enhance cross-device adaptability. Third, a
multi-task learning framework integrating osteoporosis diagnosis, BMD
regression, and vertebra location prediction. Validated across three clinical
sites and an external hospital, our approach demonstrates superior
generalizability and accuracy over existing methods for opportunistic
osteoporosis screening and diagnosis.

</details>


### [118] [EAGLE: An Efficient Global Attention Lesion Segmentation Model for Hepatic Echinococcosis](https://arxiv.org/abs/2506.20333)
*Jiayan Chen,Kai Li,Yulu Zhao,Jianqiang Huang,Zhan Wang*

Main category: eess.IV

TL;DR: 提出EAGLE网络，结合PVSS编码器和HVSS解码器，用于肝包虫病（HE）病灶的高效准确分割，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决CNN缺乏全局上下文建模和Transformer计算成本高的问题，同时应对医疗资源有限地区肝包虫病诊断需求。

Method: 设计CVSSB模块融合局部与全局特征，HWTB模块通过Haar小波变换实现无损下采样。

Result: 在260例患者CT数据上，EAGLE的DSC达89.76%，优于MSVM-UNet 1.61%。

Conclusion: EAGLE在HE病灶分割中表现优异，为资源有限地区提供高效解决方案。

Abstract: Hepatic echinococcosis (HE) is a widespread parasitic disease in
underdeveloped pastoral areas with limited medical resources. While CNN-based
and Transformer-based models have been widely applied to medical image
segmentation, CNNs lack global context modeling due to local receptive fields,
and Transformers, though capable of capturing long-range dependencies, are
computationally expensive. Recently, state space models (SSMs), such as Mamba,
have gained attention for their ability to model long sequences with linear
complexity. In this paper, we propose EAGLE, a U-shaped network composed of a
Progressive Visual State Space (PVSS) encoder and a Hybrid Visual State Space
(HVSS) decoder that work collaboratively to achieve efficient and accurate
segmentation of hepatic echinococcosis (HE) lesions. The proposed Convolutional
Vision State Space Block (CVSSB) module is designed to fuse local and global
features, while the Haar Wavelet Transformation Block (HWTB) module compresses
spatial information into the channel dimension to enable lossless downsampling.
Due to the lack of publicly available HE datasets, we collected CT slices from
260 patients at a local hospital. Experimental results show that EAGLE achieves
state-of-the-art performance with a Dice Similarity Coefficient (DSC) of
89.76%, surpassing MSVM-UNet by 1.61%.

</details>


### [119] [Fusing Radiomic Features with Deep Representations for Gestational Age Estimation in Fetal Ultrasound Images](https://arxiv.org/abs/2506.20407)
*Fangyijie Wang,Yuan Liang,Sourav Bhattacharjee,Abey Campbell,Kathleen M. Curran,Guénolé Silvestre*

Main category: eess.IV

TL;DR: 提出了一种基于深度学习和放射组学特征融合的框架，用于从胎儿超声图像中自动估计孕龄，无需手动测量。


<details>
  <summary>Details</summary>
Motivation: 手动测量孕龄依赖操作者且耗时，临床需要自动化的计算机辅助方法。

Method: 结合深度学习模型提取的深度表征和放射组学特征，通过特征融合估计孕龄。

Result: 在三孕期内的平均绝对误差为8.0天，优于现有机器学习方法。

Conclusion: 该框架在不同地理区域的人群中表现稳健，代码已开源。

Abstract: Accurate gestational age (GA) estimation, ideally through fetal ultrasound
measurement, is a crucial aspect of providing excellent antenatal care.
However, deriving GA from manual fetal biometric measurements depends on the
operator and is time-consuming. Hence, automatic computer-assisted methods are
demanded in clinical practice. In this paper, we present a novel feature fusion
framework to estimate GA using fetal ultrasound images without any measurement
information. We adopt a deep learning model to extract deep representations
from ultrasound images. We extract radiomic features to reveal patterns and
characteristics of fetal brain growth. To harness the interpretability of
radiomics in medical imaging analysis, we estimate GA by fusing radiomic
features and deep representations. Our framework estimates GA with a mean
absolute error of 8.0 days across three trimesters, outperforming current
machine learning-based methods at these gestational ages. Experimental results
demonstrate the robustness of our framework across different populations in
diverse geographical regions. Our code is publicly available on
\href{https://github.com/13204942/RadiomicsImageFusion_FetalUS}{GitHub}.

</details>


### [120] [Weighted Mean Frequencies: a handcraft Fourier feature for 4D Flow MRI segmentation](https://arxiv.org/abs/2506.20614)
*Simon Perrin,Sébastien Levilly,Huajun Sun,Harold Mouchère,Jean-Michel Serfaty*

Main category: eess.IV

TL;DR: 提出了一种名为WMF的新特征，用于改善4D Flow MRI图像的分割效果，实验显示其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 4D Flow MRI图像的低分辨率和噪声问题影响了生物标志物的准确性，尤其是血管分割的质量。

Method: 开发了Weighted Mean Frequencies (WMF)特征，用于可视化4D Flow MRI图像中的脉动流区域，并通过阈值分割和深度学习方法验证其效果。

Result: 实验结果显示，WMF特征在IoU和Dice指标上分别提高了0.12和0.13，优于PC-MRA特征。

Conclusion: WMF特征在血管分割任务中表现出显著优势，未来可应用于心脏或大脑等其他血管区域的分割。

Abstract: In recent decades, the use of 4D Flow MRI images has enabled the
quantification of velocity fields within a volume of interest and along the
cardiac cycle. However, the lack of resolution and the presence of noise in
these biomarkers are significant issues. As indicated by recent studies, it
appears that biomarkers such as wall shear stress are particularly impacted by
the poor resolution of vessel segmentation. The Phase Contrast Magnetic
Resonance Angiography (PC-MRA) is the state-of-the-art method to facilitate
segmentation. The objective of this work is to introduce a new handcraft
feature that provides a novel visualisation of 4D Flow MRI images, which is
useful in the segmentation task. This feature, termed Weighted Mean Frequencies
(WMF), is capable of revealing the region in three dimensions where a voxel has
been passed by pulsatile flow. Indeed, this feature is representative of the
hull of all pulsatile velocity voxels. The value of the feature under
discussion is illustrated by two experiments. The experiments involved
segmenting 4D Flow MRI images using optimal thresholding and deep learning
methods. The results obtained demonstrate a substantial enhancement in terms of
IoU and Dice, with a respective increase of 0.12 and 0.13 in comparison with
the PC-MRA feature, as evidenced by the deep learning task. This feature has
the potential to yield valuable insights that could inform future segmentation
processes in other vascular regions, such as the heart or the brain.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [121] [Capturing Visualization Design Rationale](https://arxiv.org/abs/2506.16571)
*Maeve Hutchinson,Radu Jianu,Aidan Slingsby,Jo Wood,Pranava Madhyastha*

Main category: cs.HC

TL;DR: 该论文提出了一种新的数据集和方法，通过自然语言探究可视化设计的原理，利用学生创建的可视化笔记本来捕获设计决策及其背后的原因。


<details>
  <summary>Details</summary>
Motivation: 现有的自然语言数据集主要关注可视化解读而非设计原理，且多基于人工构建的问题和可视化。本文旨在填补这一空白，通过真实世界的可视化笔记本和自然语言叙述来研究设计原理。

Method: 利用学生创建的可视化笔记本，结合大型语言模型（LLMs）生成问题-答案-原理三元组，并通过验证和筛选构建数据集。

Result: 构建了一个捕获学生可视化设计选择及其背后原理的数据集。

Conclusion: 该方法为研究可视化设计原理提供了新的途径，并展示了真实世界数据在理解设计决策中的价值。

Abstract: Prior natural language datasets for data visualization have focused on tasks
such as visualization literacy assessment, insight generation, and
visualization generation from natural language instructions. These studies
often rely on controlled setups with purpose-built visualizations and
artificially constructed questions. As a result, they tend to prioritize the
interpretation of visualizations, focusing on decoding visualizations rather
than understanding their encoding. In this paper, we present a new dataset and
methodology for probing visualization design rationale through natural
language. We leverage a unique source of real-world visualizations and natural
language narratives: literate visualization notebooks created by students as
part of a data visualization course. These notebooks combine visual artifacts
with design exposition, in which students make explicit the rationale behind
their design decisions. We also use large language models (LLMs) to generate
and categorize question-answer-rationale triples from the narratives and
articulations in the notebooks. We then carefully validate the triples and
curate a dataset that captures and distills the visualization design choices
and corresponding rationales of the students.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [122] [A Multi-Modal Spatial Risk Framework for EV Charging Infrastructure Using Remote Sensing](https://arxiv.org/abs/2506.19860)
*Oktay Karakuş,Padraig Corcoran*

Main category: eess.SP

TL;DR: 论文提出了RSERI-EV框架，结合多源数据评估电动汽车充电站的脆弱性，并在威尔士数据集上验证其可行性。


<details>
  <summary>Details</summary>
Motivation: 电动汽车充电基础设施的韧性在环境和基础设施压力下尚未充分研究，需要一种多模态风险评估方法。

Method: 结合遥感数据、基础设施数据集和空间图分析，构建复合韧性评分，并通过k近邻图进行空间比较。

Result: 在威尔士数据集上验证了框架的可行性，展示了多源数据融合和空间推理的价值。

Conclusion: RSERI-EV框架支持气候韧性和基础设施感知的电动汽车部署。

Abstract: Electric vehicle (EV) charging infrastructure is increasingly critical to
sustainable transport systems, yet its resilience under environmental and
infrastructural stress remains underexplored. In this paper, we introduce
RSERI-EV, a spatially explicit and multi-modal risk assessment framework that
combines remote sensing data, open infrastructure datasets, and spatial graph
analytics to evaluate the vulnerability of EV charging stations. RSERI-EV
integrates diverse data layers, including flood risk maps, land surface
temperature (LST) extremes, vegetation indices (NDVI), land use/land cover
(LULC), proximity to electrical substations, and road accessibility to generate
a composite Resilience Score. We apply this framework to the country of Wales
EV charger dataset to demonstrate its feasibility. A spatial $k$-nearest
neighbours ($k$NN) graph is constructed over the charging network to enable
neighbourhood-based comparisons and graph-aware diagnostics. Our prototype
highlights the value of multi-source data fusion and interpretable spatial
reasoning in supporting climate-resilient, infrastructure-aware EV deployment.

</details>
